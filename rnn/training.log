tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 597, val: 32, test: 0	
vocab size: 136	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 285832	
cloning rnn	
cloning criterion	
1/29850 (epoch 0.002), train_loss = 4.92245910, grad/param norm = 6.2125e-01, time/batch = 0.6914s	
2/29850 (epoch 0.003), train_loss = 4.47604115, grad/param norm = 2.2303e+00, time/batch = 0.6445s	
3/29850 (epoch 0.005), train_loss = 3.63971311, grad/param norm = 1.2878e+00, time/batch = 0.6414s	
4/29850 (epoch 0.007), train_loss = 3.46975906, grad/param norm = 8.9179e-01, time/batch = 0.6521s	
5/29850 (epoch 0.008), train_loss = 3.46015504, grad/param norm = 8.1715e-01, time/batch = 0.6533s	
6/29850 (epoch 0.010), train_loss = 3.36897929, grad/param norm = 7.9235e-01, time/batch = 0.6475s	
7/29850 (epoch 0.012), train_loss = 3.42288052, grad/param norm = 6.9665e-01, time/batch = 0.6489s	
8/29850 (epoch 0.013), train_loss = 3.32434433, grad/param norm = 8.0277e-01, time/batch = 0.6427s	
9/29850 (epoch 0.015), train_loss = 3.20368607, grad/param norm = 7.6464e-01, time/batch = 0.6459s	
10/29850 (epoch 0.017), train_loss = 3.31352782, grad/param norm = 7.2120e-01, time/batch = 0.6611s	
11/29850 (epoch 0.018), train_loss = 3.37115034, grad/param norm = 7.9528e-01, time/batch = 0.6650s	
12/29850 (epoch 0.020), train_loss = 3.25758726, grad/param norm = 5.1009e-01, time/batch = 0.6523s	
13/29850 (epoch 0.022), train_loss = 3.27785895, grad/param norm = 7.6259e-01, time/batch = 0.6346s	
14/29850 (epoch 0.023), train_loss = 3.32117622, grad/param norm = 7.1835e-01, time/batch = 0.6501s	
15/29850 (epoch 0.025), train_loss = 3.31396608, grad/param norm = 4.4768e-01, time/batch = 0.6542s	
16/29850 (epoch 0.027), train_loss = 3.27858515, grad/param norm = 6.5741e-01, time/batch = 0.6416s	
17/29850 (epoch 0.028), train_loss = 3.28243608, grad/param norm = 6.8689e-01, time/batch = 0.6361s	
18/29850 (epoch 0.030), train_loss = 3.27059345, grad/param norm = 6.8145e-01, time/batch = 0.6354s	
19/29850 (epoch 0.032), train_loss = 3.34364639, grad/param norm = 7.1071e-01, time/batch = 0.6464s	
20/29850 (epoch 0.034), train_loss = 3.16653878, grad/param norm = 6.6729e-01, time/batch = 0.6661s	
21/29850 (epoch 0.035), train_loss = 3.37483672, grad/param norm = 5.5645e-01, time/batch = 0.6627s	
22/29850 (epoch 0.037), train_loss = 3.17999817, grad/param norm = 5.1384e-01, time/batch = 0.6434s	
23/29850 (epoch 0.039), train_loss = 3.28829704, grad/param norm = 4.5826e-01, time/batch = 0.6392s	
24/29850 (epoch 0.040), train_loss = 3.21564146, grad/param norm = 6.2084e-01, time/batch = 0.6403s	
25/29850 (epoch 0.042), train_loss = 3.31192580, grad/param norm = 6.1264e-01, time/batch = 0.6396s	
26/29850 (epoch 0.044), train_loss = 3.28923916, grad/param norm = 7.1470e-01, time/batch = 0.6370s	
27/29850 (epoch 0.045), train_loss = 3.32185992, grad/param norm = 5.8922e-01, time/batch = 0.6385s	
28/29850 (epoch 0.047), train_loss = 3.31122212, grad/param norm = 7.0768e-01, time/batch = 0.6409s	
29/29850 (epoch 0.049), train_loss = 3.23457140, grad/param norm = 5.0722e-01, time/batch = 0.6386s	
30/29850 (epoch 0.050), train_loss = 3.26095050, grad/param norm = 7.1096e-01, time/batch = 0.6483s	
31/29850 (epoch 0.052), train_loss = 3.33975992, grad/param norm = 7.0340e-01, time/batch = 0.6698s	
32/29850 (epoch 0.054), train_loss = 3.51887029, grad/param norm = 9.1261e-01, time/batch = 0.6600s	
33/29850 (epoch 0.055), train_loss = 3.26501394, grad/param norm = 6.7029e-01, time/batch = 0.6593s	
34/29850 (epoch 0.057), train_loss = 3.18062772, grad/param norm = 4.9928e-01, time/batch = 0.6477s	
35/29850 (epoch 0.059), train_loss = 3.22306438, grad/param norm = 5.3304e-01, time/batch = 0.6449s	
36/29850 (epoch 0.060), train_loss = 3.26211530, grad/param norm = 5.8088e-01, time/batch = 0.6399s	
37/29850 (epoch 0.062), train_loss = 3.22830390, grad/param norm = 5.5295e-01, time/batch = 0.6406s	
38/29850 (epoch 0.064), train_loss = 3.29886640, grad/param norm = 6.4297e-01, time/batch = 0.6467s	
39/29850 (epoch 0.065), train_loss = 3.18644420, grad/param norm = 5.7316e-01, time/batch = 0.6473s	
40/29850 (epoch 0.067), train_loss = 3.22910387, grad/param norm = 6.4743e-01, time/batch = 0.6441s	
41/29850 (epoch 0.069), train_loss = 3.14044629, grad/param norm = 5.5616e-01, time/batch = 0.6515s	
42/29850 (epoch 0.070), train_loss = 3.19826617, grad/param norm = 5.9643e-01, time/batch = 0.6472s	
43/29850 (epoch 0.072), train_loss = 3.27098300, grad/param norm = 7.0406e-01, time/batch = 0.6429s	
44/29850 (epoch 0.074), train_loss = 3.20410892, grad/param norm = 7.2170e-01, time/batch = 0.6477s	
45/29850 (epoch 0.075), train_loss = 3.18905050, grad/param norm = 5.8888e-01, time/batch = 0.6618s	
46/29850 (epoch 0.077), train_loss = 3.33557611, grad/param norm = 8.8653e-01, time/batch = 0.6583s	
47/29850 (epoch 0.079), train_loss = 3.29593971, grad/param norm = 7.6865e-01, time/batch = 0.6594s	
48/29850 (epoch 0.080), train_loss = 3.24290157, grad/param norm = 7.0475e-01, time/batch = 0.6585s	
49/29850 (epoch 0.082), train_loss = 3.25367880, grad/param norm = 5.5459e-01, time/batch = 0.6474s	
50/29850 (epoch 0.084), train_loss = 3.15837625, grad/param norm = 7.7193e-01, time/batch = 0.6412s	
51/29850 (epoch 0.085), train_loss = 3.38372569, grad/param norm = 9.4397e-01, time/batch = 0.6523s	
52/29850 (epoch 0.087), train_loss = 3.37171604, grad/param norm = 7.5825e-01, time/batch = 0.6408s	
53/29850 (epoch 0.089), train_loss = 3.28455424, grad/param norm = 7.9210e-01, time/batch = 0.6410s	
54/29850 (epoch 0.090), train_loss = 3.54966437, grad/param norm = 7.7015e-01, time/batch = 0.6537s	
55/29850 (epoch 0.092), train_loss = 3.29438567, grad/param norm = 7.2078e-01, time/batch = 0.6464s	
56/29850 (epoch 0.094), train_loss = 3.24131168, grad/param norm = 5.9382e-01, time/batch = 0.6401s	
57/29850 (epoch 0.095), train_loss = 3.39621601, grad/param norm = 5.4771e-01, time/batch = 0.6393s	
58/29850 (epoch 0.097), train_loss = 3.18902198, grad/param norm = 6.8078e-01, time/batch = 0.6402s	
59/29850 (epoch 0.099), train_loss = 3.29840781, grad/param norm = 5.3334e-01, time/batch = 0.6391s	
60/29850 (epoch 0.101), train_loss = 3.37407473, grad/param norm = 5.2626e-01, time/batch = 0.6416s	
61/29850 (epoch 0.102), train_loss = 3.25009354, grad/param norm = 5.4915e-01, time/batch = 0.6432s	
62/29850 (epoch 0.104), train_loss = 3.31870456, grad/param norm = 6.1555e-01, time/batch = 0.6479s	
63/29850 (epoch 0.106), train_loss = 3.21528009, grad/param norm = 5.6503e-01, time/batch = 0.6435s	
64/29850 (epoch 0.107), train_loss = 3.23024851, grad/param norm = 5.0253e-01, time/batch = 0.6452s	
65/29850 (epoch 0.109), train_loss = 3.27388814, grad/param norm = 5.8688e-01, time/batch = 0.6437s	
66/29850 (epoch 0.111), train_loss = 3.39244738, grad/param norm = 6.2794e-01, time/batch = 0.6409s	
67/29850 (epoch 0.112), train_loss = 3.26641744, grad/param norm = 6.0929e-01, time/batch = 0.6390s	
68/29850 (epoch 0.114), train_loss = 3.21913575, grad/param norm = 8.2635e-01, time/batch = 0.6434s	
69/29850 (epoch 0.116), train_loss = 3.25142370, grad/param norm = 6.8949e-01, time/batch = 0.6387s	
70/29850 (epoch 0.117), train_loss = 3.30938897, grad/param norm = 5.8083e-01, time/batch = 0.6433s	
71/29850 (epoch 0.119), train_loss = 3.25595541, grad/param norm = 5.5526e-01, time/batch = 0.6434s	
72/29850 (epoch 0.121), train_loss = 3.18858246, grad/param norm = 4.7729e-01, time/batch = 0.6406s	
73/29850 (epoch 0.122), train_loss = 3.18729694, grad/param norm = 4.1632e-01, time/batch = 0.6353s	
74/29850 (epoch 0.124), train_loss = 3.22757965, grad/param norm = 5.9749e-01, time/batch = 0.6419s	
75/29850 (epoch 0.126), train_loss = 3.18688034, grad/param norm = 4.7930e-01, time/batch = 0.6404s	
76/29850 (epoch 0.127), train_loss = 3.28756787, grad/param norm = 4.4877e-01, time/batch = 0.6473s	
77/29850 (epoch 0.129), train_loss = 3.21332025, grad/param norm = 7.7105e-01, time/batch = 0.6482s	
78/29850 (epoch 0.131), train_loss = 3.25753622, grad/param norm = 6.4140e-01, time/batch = 0.6651s	
79/29850 (epoch 0.132), train_loss = 3.23716117, grad/param norm = 6.2401e-01, time/batch = 0.6725s	
80/29850 (epoch 0.134), train_loss = 3.19333364, grad/param norm = 8.2065e-01, time/batch = 0.6570s	
81/29850 (epoch 0.136), train_loss = 3.19477885, grad/param norm = 5.4826e-01, time/batch = 0.6770s	
82/29850 (epoch 0.137), train_loss = 3.32322406, grad/param norm = 5.9386e-01, time/batch = 0.6787s	
83/29850 (epoch 0.139), train_loss = 3.26530549, grad/param norm = 6.4208e-01, time/batch = 0.6687s	
84/29850 (epoch 0.141), train_loss = 3.31744239, grad/param norm = 6.3657e-01, time/batch = 0.6624s	
85/29850 (epoch 0.142), train_loss = 3.27921244, grad/param norm = 5.3512e-01, time/batch = 0.6521s	
86/29850 (epoch 0.144), train_loss = 3.23271349, grad/param norm = 5.5514e-01, time/batch = 0.6518s	
87/29850 (epoch 0.146), train_loss = 3.17043406, grad/param norm = 4.4845e-01, time/batch = 0.6526s	
88/29850 (epoch 0.147), train_loss = 3.30484462, grad/param norm = 6.4158e-01, time/batch = 0.6543s	
89/29850 (epoch 0.149), train_loss = 3.32745572, grad/param norm = 6.1161e-01, time/batch = 0.6513s	
90/29850 (epoch 0.151), train_loss = 3.18325451, grad/param norm = 5.6241e-01, time/batch = 0.6480s	
91/29850 (epoch 0.152), train_loss = 3.28478745, grad/param norm = 6.2995e-01, time/batch = 0.6501s	
92/29850 (epoch 0.154), train_loss = 3.15444055, grad/param norm = 6.8950e-01, time/batch = 0.6517s	
93/29850 (epoch 0.156), train_loss = 3.38033785, grad/param norm = 6.7888e-01, time/batch = 0.6502s	
94/29850 (epoch 0.157), train_loss = 3.21953005, grad/param norm = 4.0487e-01, time/batch = 0.6438s	
95/29850 (epoch 0.159), train_loss = 3.25538462, grad/param norm = 5.1820e-01, time/batch = 0.6426s	
96/29850 (epoch 0.161), train_loss = 3.29608845, grad/param norm = 5.4577e-01, time/batch = 0.6412s	
97/29850 (epoch 0.162), train_loss = 3.17716519, grad/param norm = 6.7181e-01, time/batch = 0.6391s	
98/29850 (epoch 0.164), train_loss = 3.30686244, grad/param norm = 8.0602e-01, time/batch = 0.6465s	
99/29850 (epoch 0.166), train_loss = 3.36214335, grad/param norm = 7.7256e-01, time/batch = 0.6452s	
100/29850 (epoch 0.168), train_loss = 3.15481368, grad/param norm = 5.9600e-01, time/batch = 0.6437s	
101/29850 (epoch 0.169), train_loss = 3.18192965, grad/param norm = 4.7225e-01, time/batch = 0.6414s	
102/29850 (epoch 0.171), train_loss = 3.38355152, grad/param norm = 5.2787e-01, time/batch = 0.6401s	
103/29850 (epoch 0.173), train_loss = 3.35785757, grad/param norm = 4.4821e-01, time/batch = 0.6426s	
104/29850 (epoch 0.174), train_loss = 3.21428988, grad/param norm = 5.0370e-01, time/batch = 0.6427s	
105/29850 (epoch 0.176), train_loss = 3.34148273, grad/param norm = 5.9064e-01, time/batch = 0.6416s	
106/29850 (epoch 0.178), train_loss = 3.20407120, grad/param norm = 4.6792e-01, time/batch = 0.6415s	
107/29850 (epoch 0.179), train_loss = 3.24251401, grad/param norm = 5.6136e-01, time/batch = 0.6425s	
108/29850 (epoch 0.181), train_loss = 3.30334765, grad/param norm = 6.7763e-01, time/batch = 0.6442s	
109/29850 (epoch 0.183), train_loss = 3.23259870, grad/param norm = 1.1580e+00, time/batch = 0.6527s	
110/29850 (epoch 0.184), train_loss = 3.30735844, grad/param norm = 1.0496e+00, time/batch = 0.6461s	
111/29850 (epoch 0.186), train_loss = 3.25383311, grad/param norm = 4.2138e-01, time/batch = 0.6714s	
112/29850 (epoch 0.188), train_loss = 3.19096195, grad/param norm = 5.5426e-01, time/batch = 0.6527s	
113/29850 (epoch 0.189), train_loss = 3.35394294, grad/param norm = 4.5192e-01, time/batch = 0.6404s	
114/29850 (epoch 0.191), train_loss = 3.21272805, grad/param norm = 4.3591e-01, time/batch = 0.6420s	
115/29850 (epoch 0.193), train_loss = 3.21650451, grad/param norm = 3.8258e-01, time/batch = 0.6412s	
116/29850 (epoch 0.194), train_loss = 3.17925592, grad/param norm = 5.9036e-01, time/batch = 0.6434s	
117/29850 (epoch 0.196), train_loss = 3.20331774, grad/param norm = 5.4014e-01, time/batch = 0.6426s	
118/29850 (epoch 0.198), train_loss = 3.26662559, grad/param norm = 5.4225e-01, time/batch = 0.6418s	
119/29850 (epoch 0.199), train_loss = 3.21976361, grad/param norm = 4.6858e-01, time/batch = 0.6428s	
120/29850 (epoch 0.201), train_loss = 3.41990909, grad/param norm = 6.4111e-01, time/batch = 0.6466s	
121/29850 (epoch 0.203), train_loss = 3.21884345, grad/param norm = 5.0521e-01, time/batch = 0.6571s	
122/29850 (epoch 0.204), train_loss = 3.32957134, grad/param norm = 5.9768e-01, time/batch = 0.6706s	
123/29850 (epoch 0.206), train_loss = 3.20150185, grad/param norm = 9.8349e-01, time/batch = 0.6482s	
124/29850 (epoch 0.208), train_loss = 3.26403278, grad/param norm = 9.3598e-01, time/batch = 0.6485s	
125/29850 (epoch 0.209), train_loss = 3.27447923, grad/param norm = 4.4695e-01, time/batch = 0.6445s	
126/29850 (epoch 0.211), train_loss = 3.18876384, grad/param norm = 6.2161e-01, time/batch = 0.6406s	
127/29850 (epoch 0.213), train_loss = 3.22463095, grad/param norm = 4.5943e-01, time/batch = 0.6444s	
128/29850 (epoch 0.214), train_loss = 3.13149960, grad/param norm = 6.7868e-01, time/batch = 0.6432s	
129/29850 (epoch 0.216), train_loss = 3.10560932, grad/param norm = 5.9432e-01, time/batch = 0.6498s	
130/29850 (epoch 0.218), train_loss = 3.21687402, grad/param norm = 5.1780e-01, time/batch = 0.6439s	
131/29850 (epoch 0.219), train_loss = 3.17268142, grad/param norm = 4.9568e-01, time/batch = 0.6454s	
132/29850 (epoch 0.221), train_loss = 3.20296135, grad/param norm = 7.6563e-01, time/batch = 0.6769s	
133/29850 (epoch 0.223), train_loss = 3.15225814, grad/param norm = 9.0112e-01, time/batch = 0.6621s	
134/29850 (epoch 0.224), train_loss = 3.23986173, grad/param norm = 6.9573e-01, time/batch = 0.6528s	
135/29850 (epoch 0.226), train_loss = 3.29300847, grad/param norm = 4.8882e-01, time/batch = 0.6581s	
136/29850 (epoch 0.228), train_loss = 3.12671348, grad/param norm = 7.4525e-01, time/batch = 0.6464s	
137/29850 (epoch 0.229), train_loss = 3.26109487, grad/param norm = 1.0951e+00, time/batch = 0.6465s	
138/29850 (epoch 0.231), train_loss = 3.13852643, grad/param norm = 1.0678e+00, time/batch = 0.6489s	
139/29850 (epoch 0.233), train_loss = 3.17096717, grad/param norm = 6.6544e-01, time/batch = 0.6520s	
140/29850 (epoch 0.235), train_loss = 3.08864772, grad/param norm = 6.0778e-01, time/batch = 0.6426s	
141/29850 (epoch 0.236), train_loss = 3.09434139, grad/param norm = 4.9941e-01, time/batch = 0.6431s	
142/29850 (epoch 0.238), train_loss = 3.08860582, grad/param norm = 6.2912e-01, time/batch = 0.6471s	
143/29850 (epoch 0.240), train_loss = 3.23985288, grad/param norm = 5.7882e-01, time/batch = 0.6488s	
144/29850 (epoch 0.241), train_loss = 3.24294830, grad/param norm = 4.8502e-01, time/batch = 0.6436s	
145/29850 (epoch 0.243), train_loss = 3.11260125, grad/param norm = 5.3592e-01, time/batch = 0.6436s	
146/29850 (epoch 0.245), train_loss = 3.06921327, grad/param norm = 7.4686e-01, time/batch = 0.6477s	
147/29850 (epoch 0.246), train_loss = 3.12781558, grad/param norm = 1.0535e+00, time/batch = 0.6477s	
148/29850 (epoch 0.248), train_loss = 3.08168832, grad/param norm = 1.0662e+00, time/batch = 0.6434s	
149/29850 (epoch 0.250), train_loss = 3.08744210, grad/param norm = 6.6612e-01, time/batch = 0.6406s	
150/29850 (epoch 0.251), train_loss = 3.03301077, grad/param norm = 4.3371e-01, time/batch = 0.6442s	
151/29850 (epoch 0.253), train_loss = 3.11837143, grad/param norm = 4.2367e-01, time/batch = 0.6565s	
152/29850 (epoch 0.255), train_loss = 3.08171917, grad/param norm = 3.2162e-01, time/batch = 0.6647s	
153/29850 (epoch 0.256), train_loss = 3.03006438, grad/param norm = 3.8549e-01, time/batch = 0.6707s	
154/29850 (epoch 0.258), train_loss = 3.03854031, grad/param norm = 5.1448e-01, time/batch = 0.6712s	
155/29850 (epoch 0.260), train_loss = 3.00851483, grad/param norm = 4.0137e-01, time/batch = 0.6702s	
156/29850 (epoch 0.261), train_loss = 2.94134869, grad/param norm = 4.1852e-01, time/batch = 0.6711s	
157/29850 (epoch 0.263), train_loss = 3.15964888, grad/param norm = 7.6018e-01, time/batch = 0.6618s	
158/29850 (epoch 0.265), train_loss = 3.03503512, grad/param norm = 1.6729e+00, time/batch = 0.6560s	
159/29850 (epoch 0.266), train_loss = 3.10512854, grad/param norm = 1.4201e+00, time/batch = 0.6418s	
160/29850 (epoch 0.268), train_loss = 3.03631827, grad/param norm = 5.4076e-01, time/batch = 0.6376s	
161/29850 (epoch 0.270), train_loss = 3.02740382, grad/param norm = 4.6507e-01, time/batch = 0.6445s	
162/29850 (epoch 0.271), train_loss = 3.03007648, grad/param norm = 4.4286e-01, time/batch = 0.6407s	
163/29850 (epoch 0.273), train_loss = 2.87736040, grad/param norm = 4.2059e-01, time/batch = 0.6473s	
164/29850 (epoch 0.275), train_loss = 2.91557864, grad/param norm = 5.4180e-01, time/batch = 0.6590s	
165/29850 (epoch 0.276), train_loss = 3.11227740, grad/param norm = 6.3084e-01, time/batch = 0.6697s	
166/29850 (epoch 0.278), train_loss = 2.99765319, grad/param norm = 5.5565e-01, time/batch = 0.6538s	
167/29850 (epoch 0.280), train_loss = 3.07289308, grad/param norm = 5.6935e-01, time/batch = 0.6551s	
168/29850 (epoch 0.281), train_loss = 2.84882022, grad/param norm = 6.4690e-01, time/batch = 0.6471s	
169/29850 (epoch 0.283), train_loss = 3.08789883, grad/param norm = 7.5609e-01, time/batch = 0.6666s	
170/29850 (epoch 0.285), train_loss = 3.13674996, grad/param norm = 6.3428e-01, time/batch = 0.6692s	
171/29850 (epoch 0.286), train_loss = 2.93537395, grad/param norm = 6.3196e-01, time/batch = 0.6762s	
172/29850 (epoch 0.288), train_loss = 3.06395211, grad/param norm = 6.2617e-01, time/batch = 0.6641s	
173/29850 (epoch 0.290), train_loss = 2.83789595, grad/param norm = 4.8108e-01, time/batch = 0.6552s	
174/29850 (epoch 0.291), train_loss = 3.08656537, grad/param norm = 4.8922e-01, time/batch = 0.6554s	
175/29850 (epoch 0.293), train_loss = 2.97108609, grad/param norm = 3.4845e-01, time/batch = 0.6711s	
176/29850 (epoch 0.295), train_loss = 2.86087224, grad/param norm = 4.4042e-01, time/batch = 0.6578s	
177/29850 (epoch 0.296), train_loss = 2.92832017, grad/param norm = 7.0267e-01, time/batch = 0.6464s	
178/29850 (epoch 0.298), train_loss = 2.88760923, grad/param norm = 8.4429e-01, time/batch = 0.6444s	
179/29850 (epoch 0.300), train_loss = 2.90455616, grad/param norm = 9.7901e-01, time/batch = 0.6410s	
180/29850 (epoch 0.302), train_loss = 2.95084973, grad/param norm = 8.4558e-01, time/batch = 0.6467s	
181/29850 (epoch 0.303), train_loss = 2.95420001, grad/param norm = 1.0123e+00, time/batch = 0.6472s	
182/29850 (epoch 0.305), train_loss = 2.97256827, grad/param norm = 8.3419e-01, time/batch = 0.6421s	
183/29850 (epoch 0.307), train_loss = 3.02162141, grad/param norm = 7.5374e-01, time/batch = 0.6535s	
184/29850 (epoch 0.308), train_loss = 3.02742994, grad/param norm = 6.5325e-01, time/batch = 0.6585s	
185/29850 (epoch 0.310), train_loss = 2.86666520, grad/param norm = 4.9090e-01, time/batch = 0.6543s	
186/29850 (epoch 0.312), train_loss = 2.88523542, grad/param norm = 5.8375e-01, time/batch = 0.6531s	
187/29850 (epoch 0.313), train_loss = 2.86730650, grad/param norm = 6.3978e-01, time/batch = 0.6450s	
188/29850 (epoch 0.315), train_loss = 2.92707294, grad/param norm = 7.0752e-01, time/batch = 0.6438s	
189/29850 (epoch 0.317), train_loss = 3.00835402, grad/param norm = 5.3047e-01, time/batch = 0.6437s	
190/29850 (epoch 0.318), train_loss = 2.76769630, grad/param norm = 8.8509e-01, time/batch = 0.6418s	
191/29850 (epoch 0.320), train_loss = 2.88992920, grad/param norm = 1.1838e+00, time/batch = 0.6440s	
192/29850 (epoch 0.322), train_loss = 2.92824105, grad/param norm = 1.1358e+00, time/batch = 0.6429s	
193/29850 (epoch 0.323), train_loss = 2.92315551, grad/param norm = 9.6837e-01, time/batch = 0.6392s	
194/29850 (epoch 0.325), train_loss = 2.92181658, grad/param norm = 6.8875e-01, time/batch = 0.6426s	
195/29850 (epoch 0.327), train_loss = 2.99113113, grad/param norm = 9.2085e-01, time/batch = 0.6420s	
196/29850 (epoch 0.328), train_loss = 2.98746528, grad/param norm = 8.5882e-01, time/batch = 0.6423s	
197/29850 (epoch 0.330), train_loss = 2.83744100, grad/param norm = 4.6369e-01, time/batch = 0.6437s	
198/29850 (epoch 0.332), train_loss = 2.71156991, grad/param norm = 4.6963e-01, time/batch = 0.6430s	
199/29850 (epoch 0.333), train_loss = 3.02568080, grad/param norm = 7.4170e-01, time/batch = 0.6444s	
200/29850 (epoch 0.335), train_loss = 3.04365721, grad/param norm = 6.4963e-01, time/batch = 0.6427s	
201/29850 (epoch 0.337), train_loss = 2.87106006, grad/param norm = 6.6671e-01, time/batch = 0.6440s	
202/29850 (epoch 0.338), train_loss = 2.94199845, grad/param norm = 7.2671e-01, time/batch = 0.6441s	
203/29850 (epoch 0.340), train_loss = 2.71543512, grad/param norm = 4.9856e-01, time/batch = 0.6423s	
204/29850 (epoch 0.342), train_loss = 2.88177354, grad/param norm = 3.9292e-01, time/batch = 0.6430s	
205/29850 (epoch 0.343), train_loss = 2.88305872, grad/param norm = 4.8566e-01, time/batch = 0.6419s	
206/29850 (epoch 0.345), train_loss = 2.87947132, grad/param norm = 5.6627e-01, time/batch = 0.6433s	
207/29850 (epoch 0.347), train_loss = 2.76330118, grad/param norm = 9.8751e-01, time/batch = 0.6417s	
208/29850 (epoch 0.348), train_loss = 3.03085507, grad/param norm = 1.2238e+00, time/batch = 0.6488s	
209/29850 (epoch 0.350), train_loss = 2.92565805, grad/param norm = 7.8478e-01, time/batch = 0.6434s	
210/29850 (epoch 0.352), train_loss = 2.77234818, grad/param norm = 3.4017e-01, time/batch = 0.6399s	
211/29850 (epoch 0.353), train_loss = 2.88434585, grad/param norm = 4.7006e-01, time/batch = 0.6447s	
212/29850 (epoch 0.355), train_loss = 2.75334943, grad/param norm = 8.4665e-01, time/batch = 0.6398s	
213/29850 (epoch 0.357), train_loss = 2.93097822, grad/param norm = 9.9785e-01, time/batch = 0.6444s	
214/29850 (epoch 0.358), train_loss = 2.80211487, grad/param norm = 6.3668e-01, time/batch = 0.6438s	
215/29850 (epoch 0.360), train_loss = 2.74253511, grad/param norm = 5.6102e-01, time/batch = 0.6483s	
216/29850 (epoch 0.362), train_loss = 2.92174619, grad/param norm = 6.3250e-01, time/batch = 0.6451s	
217/29850 (epoch 0.363), train_loss = 2.81894915, grad/param norm = 6.4573e-01, time/batch = 0.6451s	
218/29850 (epoch 0.365), train_loss = 2.77972181, grad/param norm = 5.0013e-01, time/batch = 0.6415s	
219/29850 (epoch 0.367), train_loss = 2.81549847, grad/param norm = 5.3426e-01, time/batch = 0.6452s	
220/29850 (epoch 0.369), train_loss = 2.71783228, grad/param norm = 6.4108e-01, time/batch = 0.6386s	
221/29850 (epoch 0.370), train_loss = 2.79474944, grad/param norm = 8.3884e-01, time/batch = 0.6435s	
222/29850 (epoch 0.372), train_loss = 2.74502866, grad/param norm = 9.8565e-01, time/batch = 0.6459s	
223/29850 (epoch 0.374), train_loss = 2.76707645, grad/param norm = 9.9085e-01, time/batch = 0.6712s	
224/29850 (epoch 0.375), train_loss = 2.82859952, grad/param norm = 8.8092e-01, time/batch = 0.6507s	
225/29850 (epoch 0.377), train_loss = 2.76928804, grad/param norm = 7.3497e-01, time/batch = 0.6451s	
226/29850 (epoch 0.379), train_loss = 2.77751529, grad/param norm = 4.9274e-01, time/batch = 0.6481s	
227/29850 (epoch 0.380), train_loss = 2.75561001, grad/param norm = 3.5753e-01, time/batch = 0.6413s	
228/29850 (epoch 0.382), train_loss = 2.80937856, grad/param norm = 4.7470e-01, time/batch = 0.6449s	
229/29850 (epoch 0.384), train_loss = 2.73192438, grad/param norm = 5.6519e-01, time/batch = 0.6458s	
230/29850 (epoch 0.385), train_loss = 2.80955649, grad/param norm = 9.1606e-01, time/batch = 0.6415s	
231/29850 (epoch 0.387), train_loss = 2.83873960, grad/param norm = 8.5954e-01, time/batch = 0.6471s	
232/29850 (epoch 0.389), train_loss = 2.79488315, grad/param norm = 6.8727e-01, time/batch = 0.6411s	
233/29850 (epoch 0.390), train_loss = 2.78445701, grad/param norm = 7.2120e-01, time/batch = 0.6539s	
234/29850 (epoch 0.392), train_loss = 2.67962364, grad/param norm = 5.8064e-01, time/batch = 0.6709s	
235/29850 (epoch 0.394), train_loss = 2.77223087, grad/param norm = 6.4384e-01, time/batch = 0.6443s	
236/29850 (epoch 0.395), train_loss = 2.88330009, grad/param norm = 9.1001e-01, time/batch = 0.6410s	
237/29850 (epoch 0.397), train_loss = 2.70522663, grad/param norm = 8.9770e-01, time/batch = 0.6429s	
238/29850 (epoch 0.399), train_loss = 2.66321481, grad/param norm = 7.6401e-01, time/batch = 0.6413s	
239/29850 (epoch 0.400), train_loss = 2.76912542, grad/param norm = 8.3102e-01, time/batch = 0.6511s	
240/29850 (epoch 0.402), train_loss = 2.72484440, grad/param norm = 4.8389e-01, time/batch = 0.6426s	
241/29850 (epoch 0.404), train_loss = 2.87304702, grad/param norm = 4.8889e-01, time/batch = 0.6416s	
242/29850 (epoch 0.405), train_loss = 2.87123095, grad/param norm = 5.9373e-01, time/batch = 0.6437s	
243/29850 (epoch 0.407), train_loss = 2.89951166, grad/param norm = 7.8545e-01, time/batch = 0.6438s	
244/29850 (epoch 0.409), train_loss = 2.83709027, grad/param norm = 6.7517e-01, time/batch = 0.6427s	
245/29850 (epoch 0.410), train_loss = 2.69165975, grad/param norm = 4.2374e-01, time/batch = 0.6416s	
246/29850 (epoch 0.412), train_loss = 2.68057173, grad/param norm = 4.7177e-01, time/batch = 0.6444s	
247/29850 (epoch 0.414), train_loss = 2.77211465, grad/param norm = 4.8347e-01, time/batch = 0.6417s	
248/29850 (epoch 0.415), train_loss = 2.77643096, grad/param norm = 7.0908e-01, time/batch = 0.6474s	
249/29850 (epoch 0.417), train_loss = 2.67396400, grad/param norm = 6.0651e-01, time/batch = 0.6630s	
250/29850 (epoch 0.419), train_loss = 2.76351466, grad/param norm = 5.8167e-01, time/batch = 0.6568s	
251/29850 (epoch 0.420), train_loss = 2.58206309, grad/param norm = 5.9526e-01, time/batch = 0.6460s	
252/29850 (epoch 0.422), train_loss = 2.69315053, grad/param norm = 4.4022e-01, time/batch = 0.6430s	
253/29850 (epoch 0.424), train_loss = 2.86315242, grad/param norm = 6.4044e-01, time/batch = 0.6422s	
254/29850 (epoch 0.425), train_loss = 2.91160181, grad/param norm = 1.1528e+00, time/batch = 0.6407s	
255/29850 (epoch 0.427), train_loss = 2.70255741, grad/param norm = 1.3878e+00, time/batch = 0.6414s	
256/29850 (epoch 0.429), train_loss = 2.74652983, grad/param norm = 6.8588e-01, time/batch = 0.6416s	
257/29850 (epoch 0.430), train_loss = 2.66201248, grad/param norm = 3.3235e-01, time/batch = 0.6399s	
258/29850 (epoch 0.432), train_loss = 2.69507610, grad/param norm = 3.1149e-01, time/batch = 0.6407s	
259/29850 (epoch 0.434), train_loss = 2.65375538, grad/param norm = 2.7616e-01, time/batch = 0.6406s	
260/29850 (epoch 0.436), train_loss = 2.72092650, grad/param norm = 4.1189e-01, time/batch = 0.6429s	
261/29850 (epoch 0.437), train_loss = 2.66649676, grad/param norm = 5.8612e-01, time/batch = 0.6483s	
262/29850 (epoch 0.439), train_loss = 2.74944840, grad/param norm = 6.6865e-01, time/batch = 0.6668s	
263/29850 (epoch 0.441), train_loss = 2.68513089, grad/param norm = 7.2053e-01, time/batch = 0.6742s	
264/29850 (epoch 0.442), train_loss = 2.69406128, grad/param norm = 7.9174e-01, time/batch = 0.6534s	
265/29850 (epoch 0.444), train_loss = 2.64002917, grad/param norm = 6.5777e-01, time/batch = 0.6483s	
266/29850 (epoch 0.446), train_loss = 2.77257290, grad/param norm = 5.4316e-01, time/batch = 0.6420s	
267/29850 (epoch 0.447), train_loss = 2.68870664, grad/param norm = 7.4877e-01, time/batch = 0.6442s	
268/29850 (epoch 0.449), train_loss = 2.89637173, grad/param norm = 1.0169e+00, time/batch = 0.6431s	
269/29850 (epoch 0.451), train_loss = 2.67824908, grad/param norm = 6.8137e-01, time/batch = 0.6379s	
270/29850 (epoch 0.452), train_loss = 2.69217159, grad/param norm = 5.4792e-01, time/batch = 0.6377s	
271/29850 (epoch 0.454), train_loss = 2.66074255, grad/param norm = 6.5346e-01, time/batch = 0.6415s	
272/29850 (epoch 0.456), train_loss = 2.59743358, grad/param norm = 5.5184e-01, time/batch = 0.6391s	
273/29850 (epoch 0.457), train_loss = 2.87415971, grad/param norm = 5.5305e-01, time/batch = 0.6396s	
274/29850 (epoch 0.459), train_loss = 2.85997933, grad/param norm = 6.6962e-01, time/batch = 0.6504s	
275/29850 (epoch 0.461), train_loss = 2.89221592, grad/param norm = 7.8758e-01, time/batch = 0.6626s	
276/29850 (epoch 0.462), train_loss = 2.71619994, grad/param norm = 8.7130e-01, time/batch = 0.6434s	
277/29850 (epoch 0.464), train_loss = 2.64967815, grad/param norm = 5.0456e-01, time/batch = 0.6516s	
278/29850 (epoch 0.466), train_loss = 2.62213067, grad/param norm = 3.4437e-01, time/batch = 0.6490s	
279/29850 (epoch 0.467), train_loss = 2.62689422, grad/param norm = 4.3941e-01, time/batch = 0.6466s	
280/29850 (epoch 0.469), train_loss = 2.64262439, grad/param norm = 6.2983e-01, time/batch = 0.6413s	
281/29850 (epoch 0.471), train_loss = 2.85276355, grad/param norm = 8.1842e-01, time/batch = 0.6435s	
282/29850 (epoch 0.472), train_loss = 2.65725854, grad/param norm = 6.0422e-01, time/batch = 0.6456s	
283/29850 (epoch 0.474), train_loss = 2.69409378, grad/param norm = 4.8260e-01, time/batch = 0.6429s	
284/29850 (epoch 0.476), train_loss = 2.65449416, grad/param norm = 5.8582e-01, time/batch = 0.6519s	
285/29850 (epoch 0.477), train_loss = 2.80130439, grad/param norm = 8.8580e-01, time/batch = 0.6407s	
286/29850 (epoch 0.479), train_loss = 2.72916631, grad/param norm = 1.2651e+00, time/batch = 0.6403s	
287/29850 (epoch 0.481), train_loss = 2.74654515, grad/param norm = 8.1384e-01, time/batch = 0.6382s	
288/29850 (epoch 0.482), train_loss = 2.56138953, grad/param norm = 2.7297e-01, time/batch = 0.6377s	
289/29850 (epoch 0.484), train_loss = 2.63778617, grad/param norm = 3.7606e-01, time/batch = 0.6415s	
290/29850 (epoch 0.486), train_loss = 2.56140996, grad/param norm = 3.3404e-01, time/batch = 0.6499s	
291/29850 (epoch 0.487), train_loss = 2.45833990, grad/param norm = 4.4412e-01, time/batch = 0.6438s	
292/29850 (epoch 0.489), train_loss = 2.48055631, grad/param norm = 5.2577e-01, time/batch = 0.6442s	
293/29850 (epoch 0.491), train_loss = 2.65386159, grad/param norm = 6.2761e-01, time/batch = 0.6461s	
294/29850 (epoch 0.492), train_loss = 2.80587104, grad/param norm = 8.4580e-01, time/batch = 0.6477s	
295/29850 (epoch 0.494), train_loss = 2.71817688, grad/param norm = 7.9387e-01, time/batch = 0.6466s	
296/29850 (epoch 0.496), train_loss = 2.75427028, grad/param norm = 7.2099e-01, time/batch = 0.6467s	
297/29850 (epoch 0.497), train_loss = 2.60477529, grad/param norm = 6.9212e-01, time/batch = 0.6464s	
298/29850 (epoch 0.499), train_loss = 2.61856344, grad/param norm = 5.3238e-01, time/batch = 0.6491s	
299/29850 (epoch 0.501), train_loss = 2.56877824, grad/param norm = 4.2140e-01, time/batch = 0.6403s	
300/29850 (epoch 0.503), train_loss = 2.62040867, grad/param norm = 4.3545e-01, time/batch = 0.6426s	
301/29850 (epoch 0.504), train_loss = 2.67347001, grad/param norm = 4.0230e-01, time/batch = 0.6429s	
302/29850 (epoch 0.506), train_loss = 2.69453764, grad/param norm = 4.8980e-01, time/batch = 0.6434s	
303/29850 (epoch 0.508), train_loss = 2.75294625, grad/param norm = 9.3164e-01, time/batch = 0.6402s	
304/29850 (epoch 0.509), train_loss = 2.64336363, grad/param norm = 8.1026e-01, time/batch = 0.6375s	
305/29850 (epoch 0.511), train_loss = 2.57532949, grad/param norm = 6.2912e-01, time/batch = 0.6410s	
306/29850 (epoch 0.513), train_loss = 2.64132402, grad/param norm = 9.3886e-01, time/batch = 0.6422s	
307/29850 (epoch 0.514), train_loss = 2.56251764, grad/param norm = 8.7199e-01, time/batch = 0.6369s	
308/29850 (epoch 0.516), train_loss = 2.53492034, grad/param norm = 4.0016e-01, time/batch = 0.6423s	
309/29850 (epoch 0.518), train_loss = 2.58152195, grad/param norm = 2.9392e-01, time/batch = 0.6400s	
310/29850 (epoch 0.519), train_loss = 2.53933551, grad/param norm = 3.0416e-01, time/batch = 0.6565s	
311/29850 (epoch 0.521), train_loss = 2.57033808, grad/param norm = 4.0153e-01, time/batch = 0.6568s	
312/29850 (epoch 0.523), train_loss = 2.53576466, grad/param norm = 4.1173e-01, time/batch = 0.6593s	
313/29850 (epoch 0.524), train_loss = 2.56518228, grad/param norm = 5.2897e-01, time/batch = 0.6552s	
314/29850 (epoch 0.526), train_loss = 2.67748944, grad/param norm = 6.7991e-01, time/batch = 0.6712s	
315/29850 (epoch 0.528), train_loss = 2.62196783, grad/param norm = 5.7642e-01, time/batch = 0.6742s	
316/29850 (epoch 0.529), train_loss = 2.55407169, grad/param norm = 4.4880e-01, time/batch = 0.6808s	
317/29850 (epoch 0.531), train_loss = 2.65975751, grad/param norm = 5.5675e-01, time/batch = 0.6769s	
318/29850 (epoch 0.533), train_loss = 2.62702545, grad/param norm = 8.1697e-01, time/batch = 0.6639s	
319/29850 (epoch 0.534), train_loss = 2.52661162, grad/param norm = 7.4481e-01, time/batch = 0.6679s	
320/29850 (epoch 0.536), train_loss = 2.66429671, grad/param norm = 4.5474e-01, time/batch = 0.6673s	
321/29850 (epoch 0.538), train_loss = 2.54055397, grad/param norm = 4.5727e-01, time/batch = 0.6749s	
322/29850 (epoch 0.539), train_loss = 2.54606547, grad/param norm = 7.1793e-01, time/batch = 0.6725s	
323/29850 (epoch 0.541), train_loss = 2.50622673, grad/param norm = 7.5733e-01, time/batch = 0.6797s	
324/29850 (epoch 0.543), train_loss = 2.50246883, grad/param norm = 5.5772e-01, time/batch = 0.6864s	
325/29850 (epoch 0.544), train_loss = 2.52408596, grad/param norm = 5.3875e-01, time/batch = 0.6836s	
326/29850 (epoch 0.546), train_loss = 2.67389921, grad/param norm = 5.4147e-01, time/batch = 0.6742s	
327/29850 (epoch 0.548), train_loss = 2.45903896, grad/param norm = 4.0895e-01, time/batch = 0.6615s	
328/29850 (epoch 0.549), train_loss = 2.51795054, grad/param norm = 5.0383e-01, time/batch = 0.6634s	
329/29850 (epoch 0.551), train_loss = 2.64723545, grad/param norm = 7.7068e-01, time/batch = 0.6590s	
330/29850 (epoch 0.553), train_loss = 2.50891006, grad/param norm = 6.9336e-01, time/batch = 0.6583s	
331/29850 (epoch 0.554), train_loss = 2.50619659, grad/param norm = 4.2184e-01, time/batch = 0.6688s	
332/29850 (epoch 0.556), train_loss = 2.62114244, grad/param norm = 3.5390e-01, time/batch = 0.6618s	
333/29850 (epoch 0.558), train_loss = 2.46859860, grad/param norm = 4.6817e-01, time/batch = 0.6612s	
334/29850 (epoch 0.559), train_loss = 2.65598921, grad/param norm = 5.2411e-01, time/batch = 0.6683s	
335/29850 (epoch 0.561), train_loss = 2.61216569, grad/param norm = 5.9535e-01, time/batch = 0.6820s	
336/29850 (epoch 0.563), train_loss = 2.54478198, grad/param norm = 7.0779e-01, time/batch = 0.6693s	
337/29850 (epoch 0.564), train_loss = 2.66876744, grad/param norm = 6.6591e-01, time/batch = 0.6678s	
338/29850 (epoch 0.566), train_loss = 2.48528791, grad/param norm = 6.4083e-01, time/batch = 0.6662s	
339/29850 (epoch 0.568), train_loss = 2.50367150, grad/param norm = 5.9892e-01, time/batch = 0.6610s	
340/29850 (epoch 0.570), train_loss = 2.52049944, grad/param norm = 5.4526e-01, time/batch = 0.6644s	
341/29850 (epoch 0.571), train_loss = 2.59071908, grad/param norm = 5.4727e-01, time/batch = 0.6733s	
342/29850 (epoch 0.573), train_loss = 2.62584550, grad/param norm = 6.0042e-01, time/batch = 0.6689s	
343/29850 (epoch 0.575), train_loss = 2.58269422, grad/param norm = 7.1578e-01, time/batch = 0.6697s	
344/29850 (epoch 0.576), train_loss = 2.58387010, grad/param norm = 5.6537e-01, time/batch = 0.6599s	
345/29850 (epoch 0.578), train_loss = 2.61626065, grad/param norm = 3.8688e-01, time/batch = 0.6576s	
346/29850 (epoch 0.580), train_loss = 2.53705400, grad/param norm = 2.9461e-01, time/batch = 0.6556s	
347/29850 (epoch 0.581), train_loss = 2.60928124, grad/param norm = 4.0708e-01, time/batch = 0.6551s	
348/29850 (epoch 0.583), train_loss = 2.43873998, grad/param norm = 4.2812e-01, time/batch = 0.6540s	
349/29850 (epoch 0.585), train_loss = 2.51173086, grad/param norm = 2.9845e-01, time/batch = 0.6523s	
350/29850 (epoch 0.586), train_loss = 2.57849060, grad/param norm = 4.4599e-01, time/batch = 0.6545s	
351/29850 (epoch 0.588), train_loss = 2.50136768, grad/param norm = 6.8689e-01, time/batch = 0.6588s	
352/29850 (epoch 0.590), train_loss = 2.65369475, grad/param norm = 6.9938e-01, time/batch = 0.6629s	
353/29850 (epoch 0.591), train_loss = 2.54149257, grad/param norm = 5.2141e-01, time/batch = 0.6758s	
354/29850 (epoch 0.593), train_loss = 2.46831998, grad/param norm = 3.6626e-01, time/batch = 0.6818s	
355/29850 (epoch 0.595), train_loss = 2.47571942, grad/param norm = 3.7314e-01, time/batch = 0.6865s	
356/29850 (epoch 0.596), train_loss = 2.58673820, grad/param norm = 5.2082e-01, time/batch = 0.6830s	
357/29850 (epoch 0.598), train_loss = 2.54971601, grad/param norm = 6.9447e-01, time/batch = 0.6932s	
358/29850 (epoch 0.600), train_loss = 2.56553382, grad/param norm = 7.1476e-01, time/batch = 0.6996s	
359/29850 (epoch 0.601), train_loss = 2.47991639, grad/param norm = 6.2001e-01, time/batch = 0.6607s	
360/29850 (epoch 0.603), train_loss = 2.71635268, grad/param norm = 6.9469e-01, time/batch = 0.6539s	
361/29850 (epoch 0.605), train_loss = 2.53078929, grad/param norm = 5.5111e-01, time/batch = 0.6576s	
362/29850 (epoch 0.606), train_loss = 2.46002452, grad/param norm = 3.6335e-01, time/batch = 0.6521s	
363/29850 (epoch 0.608), train_loss = 2.56560333, grad/param norm = 3.1979e-01, time/batch = 0.6514s	
364/29850 (epoch 0.610), train_loss = 2.41087088, grad/param norm = 3.7217e-01, time/batch = 0.6650s	
365/29850 (epoch 0.611), train_loss = 2.34482832, grad/param norm = 3.7775e-01, time/batch = 0.6735s	
366/29850 (epoch 0.613), train_loss = 2.37115450, grad/param norm = 5.2858e-01, time/batch = 0.6832s	
367/29850 (epoch 0.615), train_loss = 2.44350196, grad/param norm = 6.9536e-01, time/batch = 0.6731s	
368/29850 (epoch 0.616), train_loss = 2.64128746, grad/param norm = 6.9984e-01, time/batch = 0.6628s	
369/29850 (epoch 0.618), train_loss = 2.54564512, grad/param norm = 6.4472e-01, time/batch = 0.6565s	
370/29850 (epoch 0.620), train_loss = 2.52670019, grad/param norm = 6.5821e-01, time/batch = 0.6557s	
371/29850 (epoch 0.621), train_loss = 2.43988368, grad/param norm = 7.1969e-01, time/batch = 0.6552s	
372/29850 (epoch 0.623), train_loss = 2.52524107, grad/param norm = 4.1577e-01, time/batch = 0.6522s	
373/29850 (epoch 0.625), train_loss = 2.52193533, grad/param norm = 3.4184e-01, time/batch = 0.6516s	
374/29850 (epoch 0.626), train_loss = 2.51725957, grad/param norm = 2.9502e-01, time/batch = 0.6495s	
375/29850 (epoch 0.628), train_loss = 2.45783874, grad/param norm = 3.5795e-01, time/batch = 0.6515s	
376/29850 (epoch 0.630), train_loss = 2.53725428, grad/param norm = 4.3956e-01, time/batch = 0.6673s	
377/29850 (epoch 0.631), train_loss = 2.46531142, grad/param norm = 5.9819e-01, time/batch = 0.6698s	
378/29850 (epoch 0.633), train_loss = 2.58087095, grad/param norm = 6.6395e-01, time/batch = 0.6547s	
379/29850 (epoch 0.635), train_loss = 2.55813969, grad/param norm = 4.4899e-01, time/batch = 0.6548s	
380/29850 (epoch 0.637), train_loss = 2.63758673, grad/param norm = 3.2869e-01, time/batch = 0.6536s	
381/29850 (epoch 0.638), train_loss = 2.32886448, grad/param norm = 3.4950e-01, time/batch = 0.6588s	
382/29850 (epoch 0.640), train_loss = 2.60138539, grad/param norm = 3.5940e-01, time/batch = 0.6628s	
383/29850 (epoch 0.642), train_loss = 2.51624311, grad/param norm = 6.5569e-01, time/batch = 0.6542s	
384/29850 (epoch 0.643), train_loss = 2.41941499, grad/param norm = 6.0823e-01, time/batch = 0.6586s	
385/29850 (epoch 0.645), train_loss = 2.45881170, grad/param norm = 4.4632e-01, time/batch = 0.6603s	
386/29850 (epoch 0.647), train_loss = 2.53462716, grad/param norm = 4.3797e-01, time/batch = 0.6599s	
387/29850 (epoch 0.648), train_loss = 2.31520763, grad/param norm = 4.0660e-01, time/batch = 0.6634s	
388/29850 (epoch 0.650), train_loss = 2.52921524, grad/param norm = 5.2520e-01, time/batch = 0.6656s	
389/29850 (epoch 0.652), train_loss = 2.45295664, grad/param norm = 5.9391e-01, time/batch = 0.6628s	
390/29850 (epoch 0.653), train_loss = 2.54743399, grad/param norm = 4.9533e-01, time/batch = 0.6507s	
391/29850 (epoch 0.655), train_loss = 2.47180371, grad/param norm = 6.1984e-01, time/batch = 0.6570s	
392/29850 (epoch 0.657), train_loss = 2.42550133, grad/param norm = 6.0284e-01, time/batch = 0.6552s	
393/29850 (epoch 0.658), train_loss = 2.54631664, grad/param norm = 5.3451e-01, time/batch = 0.6552s	
394/29850 (epoch 0.660), train_loss = 2.35044000, grad/param norm = 5.2659e-01, time/batch = 0.6500s	
395/29850 (epoch 0.662), train_loss = 2.54965111, grad/param norm = 4.7626e-01, time/batch = 0.6495s	
396/29850 (epoch 0.663), train_loss = 2.45052817, grad/param norm = 4.8411e-01, time/batch = 0.6544s	
397/29850 (epoch 0.665), train_loss = 2.41655829, grad/param norm = 3.1485e-01, time/batch = 0.6568s	
398/29850 (epoch 0.667), train_loss = 2.47903261, grad/param norm = 2.7014e-01, time/batch = 0.6586s	
399/29850 (epoch 0.668), train_loss = 2.53424392, grad/param norm = 3.0940e-01, time/batch = 0.6575s	
400/29850 (epoch 0.670), train_loss = 2.65349120, grad/param norm = 3.3815e-01, time/batch = 0.6554s	
401/29850 (epoch 0.672), train_loss = 2.45183424, grad/param norm = 3.7614e-01, time/batch = 0.6554s	
402/29850 (epoch 0.673), train_loss = 2.53659297, grad/param norm = 3.8617e-01, time/batch = 0.6560s	
403/29850 (epoch 0.675), train_loss = 2.43365347, grad/param norm = 5.5855e-01, time/batch = 0.6544s	
404/29850 (epoch 0.677), train_loss = 2.52416197, grad/param norm = 7.2096e-01, time/batch = 0.6561s	
405/29850 (epoch 0.678), train_loss = 2.54535844, grad/param norm = 6.9886e-01, time/batch = 0.6580s	
406/29850 (epoch 0.680), train_loss = 2.46660271, grad/param norm = 4.8224e-01, time/batch = 0.6561s	
407/29850 (epoch 0.682), train_loss = 2.45153151, grad/param norm = 3.4369e-01, time/batch = 0.6604s	
408/29850 (epoch 0.683), train_loss = 2.59110345, grad/param norm = 3.0914e-01, time/batch = 0.6593s	
409/29850 (epoch 0.685), train_loss = 2.57668157, grad/param norm = 4.3869e-01, time/batch = 0.6609s	
410/29850 (epoch 0.687), train_loss = 2.60891606, grad/param norm = 6.6722e-01, time/batch = 0.6660s	
411/29850 (epoch 0.688), train_loss = 2.42085999, grad/param norm = 4.7338e-01, time/batch = 0.6630s	
412/29850 (epoch 0.690), train_loss = 2.34456397, grad/param norm = 2.6111e-01, time/batch = 0.6627s	
413/29850 (epoch 0.692), train_loss = 2.69479047, grad/param norm = 4.7676e-01, time/batch = 0.6691s	
414/29850 (epoch 0.693), train_loss = 2.49538857, grad/param norm = 4.6723e-01, time/batch = 0.6633s	
415/29850 (epoch 0.695), train_loss = 2.47201472, grad/param norm = 3.0936e-01, time/batch = 0.6653s	
416/29850 (epoch 0.697), train_loss = 2.55047704, grad/param norm = 4.0772e-01, time/batch = 0.6649s	
417/29850 (epoch 0.698), train_loss = 2.48352276, grad/param norm = 4.5602e-01, time/batch = 0.6711s	
418/29850 (epoch 0.700), train_loss = 2.49452221, grad/param norm = 4.5439e-01, time/batch = 0.6756s	
419/29850 (epoch 0.702), train_loss = 2.38097768, grad/param norm = 5.5492e-01, time/batch = 0.6571s	
420/29850 (epoch 0.704), train_loss = 2.39260331, grad/param norm = 5.6914e-01, time/batch = 0.6603s	
421/29850 (epoch 0.705), train_loss = 2.43678878, grad/param norm = 6.0198e-01, time/batch = 0.6595s	
422/29850 (epoch 0.707), train_loss = 2.57701546, grad/param norm = 5.8530e-01, time/batch = 0.6669s	
423/29850 (epoch 0.709), train_loss = 2.46033647, grad/param norm = 3.4658e-01, time/batch = 0.6551s	
424/29850 (epoch 0.710), train_loss = 2.40691671, grad/param norm = 3.4378e-01, time/batch = 0.6572s	
425/29850 (epoch 0.712), train_loss = 2.55558611, grad/param norm = 3.6781e-01, time/batch = 0.6540s	
426/29850 (epoch 0.714), train_loss = 2.45051705, grad/param norm = 5.0145e-01, time/batch = 0.6511s	
427/29850 (epoch 0.715), train_loss = 2.51388097, grad/param norm = 6.3345e-01, time/batch = 0.6526s	
428/29850 (epoch 0.717), train_loss = 2.40759045, grad/param norm = 5.6759e-01, time/batch = 0.6570s	
429/29850 (epoch 0.719), train_loss = 2.50888569, grad/param norm = 5.7360e-01, time/batch = 0.6535s	
430/29850 (epoch 0.720), train_loss = 2.47647464, grad/param norm = 5.2358e-01, time/batch = 0.6567s	
431/29850 (epoch 0.722), train_loss = 2.39309725, grad/param norm = 4.4782e-01, time/batch = 0.6607s	
432/29850 (epoch 0.724), train_loss = 2.40727939, grad/param norm = 3.6392e-01, time/batch = 0.6527s	
433/29850 (epoch 0.725), train_loss = 2.26703629, grad/param norm = 3.7753e-01, time/batch = 0.6514s	
434/29850 (epoch 0.727), train_loss = 2.42302265, grad/param norm = 3.7799e-01, time/batch = 0.6502s	
435/29850 (epoch 0.729), train_loss = 2.24854038, grad/param norm = 2.8623e-01, time/batch = 0.6515s	
436/29850 (epoch 0.730), train_loss = 2.40995544, grad/param norm = 3.7406e-01, time/batch = 0.6529s	
437/29850 (epoch 0.732), train_loss = 2.24639885, grad/param norm = 6.8332e-01, time/batch = 0.6552s	
438/29850 (epoch 0.734), train_loss = 2.63309032, grad/param norm = 1.1150e+00, time/batch = 0.6530s	
439/29850 (epoch 0.735), train_loss = 2.61717239, grad/param norm = 8.5827e-01, time/batch = 0.6534s	
440/29850 (epoch 0.737), train_loss = 2.44520640, grad/param norm = 4.2137e-01, time/batch = 0.6522s	
441/29850 (epoch 0.739), train_loss = 2.45394456, grad/param norm = 3.5150e-01, time/batch = 0.6527s	
442/29850 (epoch 0.740), train_loss = 2.34947435, grad/param norm = 2.9972e-01, time/batch = 0.6533s	
443/29850 (epoch 0.742), train_loss = 2.39339492, grad/param norm = 3.7253e-01, time/batch = 0.6679s	
444/29850 (epoch 0.744), train_loss = 2.39554168, grad/param norm = 3.3868e-01, time/batch = 0.6876s	
445/29850 (epoch 0.745), train_loss = 2.33427128, grad/param norm = 3.1057e-01, time/batch = 0.6887s	
446/29850 (epoch 0.747), train_loss = 2.42331129, grad/param norm = 2.8304e-01, time/batch = 0.6608s	
447/29850 (epoch 0.749), train_loss = 2.32847479, grad/param norm = 2.9815e-01, time/batch = 0.6612s	
448/29850 (epoch 0.750), train_loss = 2.53939373, grad/param norm = 4.7925e-01, time/batch = 0.6638s	
449/29850 (epoch 0.752), train_loss = 2.42481681, grad/param norm = 5.5079e-01, time/batch = 0.6819s	
450/29850 (epoch 0.754), train_loss = 2.37318818, grad/param norm = 5.6255e-01, time/batch = 0.6558s	
451/29850 (epoch 0.755), train_loss = 2.43804132, grad/param norm = 4.5147e-01, time/batch = 0.6601s	
452/29850 (epoch 0.757), train_loss = 2.36582160, grad/param norm = 5.0231e-01, time/batch = 0.6609s	
453/29850 (epoch 0.759), train_loss = 2.53075456, grad/param norm = 5.7564e-01, time/batch = 0.6617s	
454/29850 (epoch 0.760), train_loss = 2.26690943, grad/param norm = 6.1305e-01, time/batch = 0.6636s	
455/29850 (epoch 0.762), train_loss = 2.41119558, grad/param norm = 5.0408e-01, time/batch = 0.6864s	
456/29850 (epoch 0.764), train_loss = 2.46584131, grad/param norm = 3.3988e-01, time/batch = 0.6746s	
457/29850 (epoch 0.765), train_loss = 2.39533590, grad/param norm = 3.3481e-01, time/batch = 0.6627s	
458/29850 (epoch 0.767), train_loss = 2.47147848, grad/param norm = 3.6201e-01, time/batch = 0.6693s	
459/29850 (epoch 0.769), train_loss = 2.37386267, grad/param norm = 3.2081e-01, time/batch = 0.6634s	
460/29850 (epoch 0.771), train_loss = 2.36099444, grad/param norm = 3.2729e-01, time/batch = 0.6732s	
461/29850 (epoch 0.772), train_loss = 2.50829087, grad/param norm = 3.5655e-01, time/batch = 0.6646s	
462/29850 (epoch 0.774), train_loss = 2.35801715, grad/param norm = 4.4374e-01, time/batch = 0.6606s	
463/29850 (epoch 0.776), train_loss = 2.38746054, grad/param norm = 4.7713e-01, time/batch = 0.6686s	
464/29850 (epoch 0.777), train_loss = 2.49478815, grad/param norm = 4.5760e-01, time/batch = 0.6614s	
465/29850 (epoch 0.779), train_loss = 2.31018924, grad/param norm = 4.7602e-01, time/batch = 0.6791s	
466/29850 (epoch 0.781), train_loss = 2.39471980, grad/param norm = 4.5370e-01, time/batch = 0.6820s	
467/29850 (epoch 0.782), train_loss = 2.35922137, grad/param norm = 5.0404e-01, time/batch = 0.6587s	
468/29850 (epoch 0.784), train_loss = 2.36165677, grad/param norm = 6.9119e-01, time/batch = 0.6589s	
469/29850 (epoch 0.786), train_loss = 2.40460482, grad/param norm = 6.6260e-01, time/batch = 0.6614s	
470/29850 (epoch 0.787), train_loss = 2.41904920, grad/param norm = 4.6505e-01, time/batch = 0.6615s	
471/29850 (epoch 0.789), train_loss = 2.25574119, grad/param norm = 2.9820e-01, time/batch = 0.6732s	
472/29850 (epoch 0.791), train_loss = 2.46756620, grad/param norm = 3.1087e-01, time/batch = 0.6591s	
473/29850 (epoch 0.792), train_loss = 2.35247433, grad/param norm = 4.2166e-01, time/batch = 0.6591s	
474/29850 (epoch 0.794), train_loss = 2.35191574, grad/param norm = 4.3538e-01, time/batch = 0.6606s	
475/29850 (epoch 0.796), train_loss = 2.37501702, grad/param norm = 3.8056e-01, time/batch = 0.6611s	
476/29850 (epoch 0.797), train_loss = 2.33432746, grad/param norm = 2.8050e-01, time/batch = 0.6861s	
477/29850 (epoch 0.799), train_loss = 2.34208401, grad/param norm = 3.0823e-01, time/batch = 0.6690s	
478/29850 (epoch 0.801), train_loss = 2.44071242, grad/param norm = 4.1591e-01, time/batch = 0.6606s	
479/29850 (epoch 0.802), train_loss = 2.38316313, grad/param norm = 4.0943e-01, time/batch = 0.6633s	
480/29850 (epoch 0.804), train_loss = 2.49129749, grad/param norm = 3.6267e-01, time/batch = 0.6664s	
481/29850 (epoch 0.806), train_loss = 2.53947466, grad/param norm = 3.9316e-01, time/batch = 0.6702s	
482/29850 (epoch 0.807), train_loss = 2.29363805, grad/param norm = 4.2393e-01, time/batch = 0.6583s	
483/29850 (epoch 0.809), train_loss = 2.45795194, grad/param norm = 5.2825e-01, time/batch = 0.6591s	
484/29850 (epoch 0.811), train_loss = 2.42756868, grad/param norm = 4.2744e-01, time/batch = 0.6614s	
485/29850 (epoch 0.812), train_loss = 2.38478369, grad/param norm = 3.0420e-01, time/batch = 0.6582s	
486/29850 (epoch 0.814), train_loss = 2.38031665, grad/param norm = 3.1952e-01, time/batch = 0.6574s	
487/29850 (epoch 0.816), train_loss = 2.35356156, grad/param norm = 2.7922e-01, time/batch = 0.6571s	
488/29850 (epoch 0.817), train_loss = 2.50542932, grad/param norm = 4.9352e-01, time/batch = 0.6620s	
489/29850 (epoch 0.819), train_loss = 2.40642613, grad/param norm = 5.4085e-01, time/batch = 0.6596s	
490/29850 (epoch 0.821), train_loss = 2.51261496, grad/param norm = 3.8171e-01, time/batch = 0.6607s	
491/29850 (epoch 0.822), train_loss = 2.32566097, grad/param norm = 2.7288e-01, time/batch = 0.6631s	
492/29850 (epoch 0.824), train_loss = 2.42666089, grad/param norm = 3.5754e-01, time/batch = 0.6632s	
493/29850 (epoch 0.826), train_loss = 2.40304142, grad/param norm = 6.7841e-01, time/batch = 0.6720s	
494/29850 (epoch 0.827), train_loss = 2.41946086, grad/param norm = 7.3349e-01, time/batch = 0.6659s	
495/29850 (epoch 0.829), train_loss = 2.42594072, grad/param norm = 4.0201e-01, time/batch = 0.6619s	
496/29850 (epoch 0.831), train_loss = 2.42017298, grad/param norm = 3.0869e-01, time/batch = 0.6766s	
497/29850 (epoch 0.832), train_loss = 2.23401523, grad/param norm = 2.9783e-01, time/batch = 0.6634s	
498/29850 (epoch 0.834), train_loss = 2.25536774, grad/param norm = 3.3901e-01, time/batch = 0.6620s	
499/29850 (epoch 0.836), train_loss = 2.30516617, grad/param norm = 3.4907e-01, time/batch = 0.6675s	
500/29850 (epoch 0.838), train_loss = 2.36647991, grad/param norm = 3.5013e-01, time/batch = 0.6698s	
501/29850 (epoch 0.839), train_loss = 2.38100835, grad/param norm = 3.5999e-01, time/batch = 0.6813s	
502/29850 (epoch 0.841), train_loss = 2.40241512, grad/param norm = 3.2814e-01, time/batch = 0.6643s	
503/29850 (epoch 0.843), train_loss = 2.40738564, grad/param norm = 2.5111e-01, time/batch = 0.6625s	
504/29850 (epoch 0.844), train_loss = 2.38924322, grad/param norm = 2.7564e-01, time/batch = 0.6604s	
505/29850 (epoch 0.846), train_loss = 2.43745196, grad/param norm = 3.0499e-01, time/batch = 0.6599s	
506/29850 (epoch 0.848), train_loss = 2.40616429, grad/param norm = 3.6547e-01, time/batch = 0.6574s	
507/29850 (epoch 0.849), train_loss = 2.39067875, grad/param norm = 4.3719e-01, time/batch = 0.6627s	
508/29850 (epoch 0.851), train_loss = 2.40515095, grad/param norm = 5.3570e-01, time/batch = 0.6579s	
509/29850 (epoch 0.853), train_loss = 2.30470406, grad/param norm = 5.2478e-01, time/batch = 0.6633s	
510/29850 (epoch 0.854), train_loss = 2.38638302, grad/param norm = 6.1629e-01, time/batch = 0.6550s	
511/29850 (epoch 0.856), train_loss = 2.28152209, grad/param norm = 5.9480e-01, time/batch = 0.6604s	
512/29850 (epoch 0.858), train_loss = 2.31847313, grad/param norm = 4.7519e-01, time/batch = 0.6699s	
513/29850 (epoch 0.859), train_loss = 2.38581378, grad/param norm = 4.0289e-01, time/batch = 0.6607s	
514/29850 (epoch 0.861), train_loss = 2.43952354, grad/param norm = 2.9843e-01, time/batch = 0.6683s	
515/29850 (epoch 0.863), train_loss = 2.44697394, grad/param norm = 3.5799e-01, time/batch = 0.6734s	
516/29850 (epoch 0.864), train_loss = 2.35094351, grad/param norm = 3.4577e-01, time/batch = 0.6666s	
517/29850 (epoch 0.866), train_loss = 2.30389856, grad/param norm = 3.3769e-01, time/batch = 0.6575s	
518/29850 (epoch 0.868), train_loss = 2.34243403, grad/param norm = 3.7070e-01, time/batch = 0.6661s	
519/29850 (epoch 0.869), train_loss = 2.30464489, grad/param norm = 4.1535e-01, time/batch = 0.6596s	
520/29850 (epoch 0.871), train_loss = 2.39903727, grad/param norm = 4.1482e-01, time/batch = 0.6591s	
521/29850 (epoch 0.873), train_loss = 2.60912063, grad/param norm = 4.7974e-01, time/batch = 0.6603s	
522/29850 (epoch 0.874), train_loss = 2.41026604, grad/param norm = 5.0735e-01, time/batch = 0.6608s	
523/29850 (epoch 0.876), train_loss = 2.52011471, grad/param norm = 4.3777e-01, time/batch = 0.6592s	
524/29850 (epoch 0.878), train_loss = 2.31993512, grad/param norm = 4.5121e-01, time/batch = 0.6781s	
525/29850 (epoch 0.879), train_loss = 2.45623858, grad/param norm = 3.5439e-01, time/batch = 0.6882s	
526/29850 (epoch 0.881), train_loss = 2.44055239, grad/param norm = 3.5869e-01, time/batch = 0.6800s	
527/29850 (epoch 0.883), train_loss = 2.45471004, grad/param norm = 4.8655e-01, time/batch = 0.6782s	
528/29850 (epoch 0.884), train_loss = 2.28106100, grad/param norm = 5.6101e-01, time/batch = 0.6851s	
529/29850 (epoch 0.886), train_loss = 2.49045951, grad/param norm = 5.2005e-01, time/batch = 0.6854s	
530/29850 (epoch 0.888), train_loss = 2.35882367, grad/param norm = 3.6131e-01, time/batch = 0.6779s	
531/29850 (epoch 0.889), train_loss = 2.27178398, grad/param norm = 3.3380e-01, time/batch = 0.6761s	
532/29850 (epoch 0.891), train_loss = 2.30416253, grad/param norm = 3.3945e-01, time/batch = 0.6678s	
533/29850 (epoch 0.893), train_loss = 2.30555266, grad/param norm = 3.2901e-01, time/batch = 0.6808s	
534/29850 (epoch 0.894), train_loss = 2.40436414, grad/param norm = 3.0990e-01, time/batch = 0.6786s	
535/29850 (epoch 0.896), train_loss = 2.35883609, grad/param norm = 3.4088e-01, time/batch = 0.6641s	
536/29850 (epoch 0.898), train_loss = 2.33999847, grad/param norm = 3.9060e-01, time/batch = 0.6658s	
537/29850 (epoch 0.899), train_loss = 2.33317499, grad/param norm = 4.5810e-01, time/batch = 0.6558s	
538/29850 (epoch 0.901), train_loss = 2.57731560, grad/param norm = 4.6773e-01, time/batch = 0.6599s	
539/29850 (epoch 0.903), train_loss = 2.50509583, grad/param norm = 4.1234e-01, time/batch = 0.6579s	
540/29850 (epoch 0.905), train_loss = 2.58219294, grad/param norm = 4.5953e-01, time/batch = 0.6619s	
541/29850 (epoch 0.906), train_loss = 2.35560319, grad/param norm = 7.0188e-01, time/batch = 0.6720s	
542/29850 (epoch 0.908), train_loss = 2.33684204, grad/param norm = 6.0066e-01, time/batch = 0.6702s	
543/29850 (epoch 0.910), train_loss = 2.50957512, grad/param norm = 3.3384e-01, time/batch = 0.6763s	
544/29850 (epoch 0.911), train_loss = 2.38181278, grad/param norm = 2.4161e-01, time/batch = 0.6724s	
545/29850 (epoch 0.913), train_loss = 2.33021217, grad/param norm = 2.8850e-01, time/batch = 0.6786s	
546/29850 (epoch 0.915), train_loss = 2.31256290, grad/param norm = 2.4602e-01, time/batch = 0.6831s	
547/29850 (epoch 0.916), train_loss = 2.22950191, grad/param norm = 2.4400e-01, time/batch = 0.6871s	
548/29850 (epoch 0.918), train_loss = 2.27998831, grad/param norm = 3.2885e-01, time/batch = 0.6694s	
549/29850 (epoch 0.920), train_loss = 2.44655357, grad/param norm = 4.7167e-01, time/batch = 0.6731s	
550/29850 (epoch 0.921), train_loss = 2.39666124, grad/param norm = 5.0135e-01, time/batch = 0.6594s	
551/29850 (epoch 0.923), train_loss = 2.34807504, grad/param norm = 3.9868e-01, time/batch = 0.6481s	
552/29850 (epoch 0.925), train_loss = 2.33313020, grad/param norm = 2.5466e-01, time/batch = 0.6465s	
553/29850 (epoch 0.926), train_loss = 2.47487331, grad/param norm = 3.2851e-01, time/batch = 0.6469s	
554/29850 (epoch 0.928), train_loss = 2.34397982, grad/param norm = 3.3884e-01, time/batch = 0.6508s	
555/29850 (epoch 0.930), train_loss = 2.52559386, grad/param norm = 4.0972e-01, time/batch = 0.6412s	
556/29850 (epoch 0.931), train_loss = 2.40590134, grad/param norm = 3.7811e-01, time/batch = 0.6389s	
557/29850 (epoch 0.933), train_loss = 2.45444020, grad/param norm = 3.9913e-01, time/batch = 0.6371s	
558/29850 (epoch 0.935), train_loss = 2.48963096, grad/param norm = 3.4266e-01, time/batch = 0.6395s	
559/29850 (epoch 0.936), train_loss = 2.32871129, grad/param norm = 3.9754e-01, time/batch = 0.6513s	
560/29850 (epoch 0.938), train_loss = 2.30852371, grad/param norm = 4.6417e-01, time/batch = 0.6699s	
561/29850 (epoch 0.940), train_loss = 2.25388353, grad/param norm = 4.4980e-01, time/batch = 0.6470s	
562/29850 (epoch 0.941), train_loss = 2.39294249, grad/param norm = 5.1491e-01, time/batch = 0.6442s	
563/29850 (epoch 0.943), train_loss = 2.34109908, grad/param norm = 5.8410e-01, time/batch = 0.6433s	
564/29850 (epoch 0.945), train_loss = 2.44570728, grad/param norm = 3.7880e-01, time/batch = 0.6443s	
565/29850 (epoch 0.946), train_loss = 2.40378651, grad/param norm = 3.9328e-01, time/batch = 0.6397s	
566/29850 (epoch 0.948), train_loss = 2.27662304, grad/param norm = 3.1181e-01, time/batch = 0.6387s	
567/29850 (epoch 0.950), train_loss = 2.33320557, grad/param norm = 3.4122e-01, time/batch = 0.6401s	
568/29850 (epoch 0.951), train_loss = 2.19662095, grad/param norm = 2.4005e-01, time/batch = 0.6408s	
569/29850 (epoch 0.953), train_loss = 2.38730728, grad/param norm = 3.2411e-01, time/batch = 0.6424s	
570/29850 (epoch 0.955), train_loss = 2.24254720, grad/param norm = 2.9398e-01, time/batch = 0.6571s	
571/29850 (epoch 0.956), train_loss = 2.34596151, grad/param norm = 3.9395e-01, time/batch = 0.6712s	
572/29850 (epoch 0.958), train_loss = 2.18979249, grad/param norm = 4.1423e-01, time/batch = 0.6493s	
573/29850 (epoch 0.960), train_loss = 2.40357819, grad/param norm = 3.8245e-01, time/batch = 0.6481s	
574/29850 (epoch 0.961), train_loss = 2.35113858, grad/param norm = 3.7581e-01, time/batch = 0.6450s	
575/29850 (epoch 0.963), train_loss = 2.24972632, grad/param norm = 3.7271e-01, time/batch = 0.6433s	
576/29850 (epoch 0.965), train_loss = 2.27316544, grad/param norm = 2.5021e-01, time/batch = 0.6479s	
577/29850 (epoch 0.966), train_loss = 2.23387220, grad/param norm = 2.5797e-01, time/batch = 0.6485s	
578/29850 (epoch 0.968), train_loss = 2.20565948, grad/param norm = 2.7617e-01, time/batch = 0.6430s	
579/29850 (epoch 0.970), train_loss = 2.27641064, grad/param norm = 2.8829e-01, time/batch = 0.6489s	
580/29850 (epoch 0.972), train_loss = 2.17366315, grad/param norm = 4.7789e-01, time/batch = 0.6516s	
581/29850 (epoch 0.973), train_loss = 2.46580029, grad/param norm = 5.6762e-01, time/batch = 0.6700s	
582/29850 (epoch 0.975), train_loss = 2.18034506, grad/param norm = 3.9054e-01, time/batch = 0.6598s	
583/29850 (epoch 0.977), train_loss = 2.17010748, grad/param norm = 4.0428e-01, time/batch = 0.6430s	
584/29850 (epoch 0.978), train_loss = 2.28882587, grad/param norm = 3.4036e-01, time/batch = 0.6415s	
585/29850 (epoch 0.980), train_loss = 2.15253326, grad/param norm = 4.6696e-01, time/batch = 0.6424s	
586/29850 (epoch 0.982), train_loss = 2.28366809, grad/param norm = 5.6918e-01, time/batch = 0.6439s	
587/29850 (epoch 0.983), train_loss = 2.33997363, grad/param norm = 3.5884e-01, time/batch = 0.6401s	
588/29850 (epoch 0.985), train_loss = 2.35405517, grad/param norm = 4.1616e-01, time/batch = 0.6469s	
589/29850 (epoch 0.987), train_loss = 2.19342067, grad/param norm = 4.6866e-01, time/batch = 0.6384s	
590/29850 (epoch 0.988), train_loss = 2.14150983, grad/param norm = 3.1661e-01, time/batch = 0.6392s	
591/29850 (epoch 0.990), train_loss = 2.15020656, grad/param norm = 2.8546e-01, time/batch = 0.6466s	
592/29850 (epoch 0.992), train_loss = 2.25358414, grad/param norm = 2.8129e-01, time/batch = 0.6709s	
593/29850 (epoch 0.993), train_loss = 2.39206710, grad/param norm = 3.2873e-01, time/batch = 0.6568s	
594/29850 (epoch 0.995), train_loss = 2.32236730, grad/param norm = 3.5986e-01, time/batch = 0.6497s	
595/29850 (epoch 0.997), train_loss = 2.33850741, grad/param norm = 4.0549e-01, time/batch = 0.6464s	
596/29850 (epoch 0.998), train_loss = 2.36555544, grad/param norm = 3.2146e-01, time/batch = 0.6406s	
597/29850 (epoch 1.000), train_loss = 2.25484829, grad/param norm = 3.5647e-01, time/batch = 0.6435s	
598/29850 (epoch 1.002), train_loss = 2.38793365, grad/param norm = 3.8277e-01, time/batch = 0.6437s	
599/29850 (epoch 1.003), train_loss = 2.23245373, grad/param norm = 3.6774e-01, time/batch = 0.6422s	
600/29850 (epoch 1.005), train_loss = 2.23303350, grad/param norm = 3.3361e-01, time/batch = 0.6414s	
601/29850 (epoch 1.007), train_loss = 2.32691851, grad/param norm = 3.3565e-01, time/batch = 0.6469s	
602/29850 (epoch 1.008), train_loss = 2.46255778, grad/param norm = 2.8856e-01, time/batch = 0.6544s	
603/29850 (epoch 1.010), train_loss = 2.23059254, grad/param norm = 3.1663e-01, time/batch = 0.6712s	
604/29850 (epoch 1.012), train_loss = 2.37895027, grad/param norm = 3.8249e-01, time/batch = 0.6477s	
605/29850 (epoch 1.013), train_loss = 2.42440326, grad/param norm = 4.6837e-01, time/batch = 0.6397s	
606/29850 (epoch 1.015), train_loss = 2.28788142, grad/param norm = 3.9523e-01, time/batch = 0.6403s	
607/29850 (epoch 1.017), train_loss = 2.47889738, grad/param norm = 2.9568e-01, time/batch = 0.6410s	
608/29850 (epoch 1.018), train_loss = 2.43290513, grad/param norm = 3.7027e-01, time/batch = 0.6396s	
609/29850 (epoch 1.020), train_loss = 2.21669349, grad/param norm = 4.1320e-01, time/batch = 0.6452s	
610/29850 (epoch 1.022), train_loss = 2.35323920, grad/param norm = 5.0274e-01, time/batch = 0.6453s	
611/29850 (epoch 1.023), train_loss = 2.34323033, grad/param norm = 4.3909e-01, time/batch = 0.6457s	
612/29850 (epoch 1.025), train_loss = 2.25417527, grad/param norm = 2.9190e-01, time/batch = 0.6410s	
613/29850 (epoch 1.027), train_loss = 2.27976446, grad/param norm = 2.5136e-01, time/batch = 0.6420s	
614/29850 (epoch 1.028), train_loss = 2.22419981, grad/param norm = 3.0255e-01, time/batch = 0.6368s	
615/29850 (epoch 1.030), train_loss = 2.30456275, grad/param norm = 2.8240e-01, time/batch = 0.6393s	
616/29850 (epoch 1.032), train_loss = 2.18075829, grad/param norm = 2.6276e-01, time/batch = 0.6413s	
617/29850 (epoch 1.034), train_loss = 2.32536578, grad/param norm = 2.8636e-01, time/batch = 0.6499s	
618/29850 (epoch 1.035), train_loss = 2.30431971, grad/param norm = 2.8349e-01, time/batch = 0.6425s	
619/29850 (epoch 1.037), train_loss = 2.25371508, grad/param norm = 2.9420e-01, time/batch = 0.6388s	
620/29850 (epoch 1.039), train_loss = 2.20309866, grad/param norm = 3.1302e-01, time/batch = 0.6369s	
621/29850 (epoch 1.040), train_loss = 2.18049103, grad/param norm = 3.5769e-01, time/batch = 0.6414s	
622/29850 (epoch 1.042), train_loss = 2.35503546, grad/param norm = 3.5623e-01, time/batch = 0.6460s	
623/29850 (epoch 1.044), train_loss = 2.11230380, grad/param norm = 2.9487e-01, time/batch = 0.6409s	
624/29850 (epoch 1.045), train_loss = 2.33442433, grad/param norm = 3.0009e-01, time/batch = 0.6475s	
625/29850 (epoch 1.047), train_loss = 2.22369640, grad/param norm = 3.3447e-01, time/batch = 0.6659s	
626/29850 (epoch 1.049), train_loss = 2.16156914, grad/param norm = 2.3499e-01, time/batch = 0.6721s	
627/29850 (epoch 1.050), train_loss = 2.24765477, grad/param norm = 2.9543e-01, time/batch = 0.6623s	
628/29850 (epoch 1.052), train_loss = 2.42307176, grad/param norm = 3.4086e-01, time/batch = 0.6522s	
629/29850 (epoch 1.054), train_loss = 2.42890765, grad/param norm = 4.6991e-01, time/batch = 0.6475s	
630/29850 (epoch 1.055), train_loss = 2.28008131, grad/param norm = 5.9014e-01, time/batch = 0.6490s	
631/29850 (epoch 1.057), train_loss = 2.20915894, grad/param norm = 4.5035e-01, time/batch = 0.6492s	
632/29850 (epoch 1.059), train_loss = 2.15069497, grad/param norm = 4.0581e-01, time/batch = 0.6431s	
633/29850 (epoch 1.060), train_loss = 2.25300963, grad/param norm = 4.3162e-01, time/batch = 0.6431s	
634/29850 (epoch 1.062), train_loss = 2.23858553, grad/param norm = 3.3700e-01, time/batch = 0.6411s	
635/29850 (epoch 1.064), train_loss = 2.15737926, grad/param norm = 2.5130e-01, time/batch = 0.6435s	
636/29850 (epoch 1.065), train_loss = 2.18222079, grad/param norm = 3.2486e-01, time/batch = 0.6432s	
637/29850 (epoch 1.067), train_loss = 2.32569031, grad/param norm = 3.3923e-01, time/batch = 0.6414s	
638/29850 (epoch 1.069), train_loss = 2.13818433, grad/param norm = 2.9392e-01, time/batch = 0.6424s	
639/29850 (epoch 1.070), train_loss = 2.21585719, grad/param norm = 3.5687e-01, time/batch = 0.6420s	
640/29850 (epoch 1.072), train_loss = 2.32614305, grad/param norm = 4.9587e-01, time/batch = 0.6485s	
641/29850 (epoch 1.074), train_loss = 2.26531025, grad/param norm = 5.2945e-01, time/batch = 0.6513s	
642/29850 (epoch 1.075), train_loss = 2.17228197, grad/param norm = 3.9089e-01, time/batch = 0.6743s	
643/29850 (epoch 1.077), train_loss = 2.19969079, grad/param norm = 3.5047e-01, time/batch = 0.6643s	
644/29850 (epoch 1.079), train_loss = 2.31325391, grad/param norm = 2.9081e-01, time/batch = 0.6556s	
645/29850 (epoch 1.080), train_loss = 2.23312120, grad/param norm = 3.0525e-01, time/batch = 0.6523s	
646/29850 (epoch 1.082), train_loss = 2.17665068, grad/param norm = 2.5452e-01, time/batch = 0.6485s	
647/29850 (epoch 1.084), train_loss = 2.17987468, grad/param norm = 2.9551e-01, time/batch = 0.6517s	
648/29850 (epoch 1.085), train_loss = 2.11277358, grad/param norm = 4.1130e-01, time/batch = 0.6601s	
649/29850 (epoch 1.087), train_loss = 2.34462503, grad/param norm = 3.6039e-01, time/batch = 0.6580s	
650/29850 (epoch 1.089), train_loss = 2.35213431, grad/param norm = 3.7651e-01, time/batch = 0.6438s	
651/29850 (epoch 1.090), train_loss = 2.25666642, grad/param norm = 2.7686e-01, time/batch = 0.6512s	
652/29850 (epoch 1.092), train_loss = 2.16540002, grad/param norm = 2.3647e-01, time/batch = 0.6432s	
653/29850 (epoch 1.094), train_loss = 2.24000426, grad/param norm = 2.5854e-01, time/batch = 0.6478s	
654/29850 (epoch 1.095), train_loss = 2.40087220, grad/param norm = 3.5643e-01, time/batch = 0.6436s	
655/29850 (epoch 1.097), train_loss = 2.17956954, grad/param norm = 3.1391e-01, time/batch = 0.6425s	
656/29850 (epoch 1.099), train_loss = 2.05745821, grad/param norm = 2.7605e-01, time/batch = 0.6432s	
657/29850 (epoch 1.101), train_loss = 2.38271959, grad/param norm = 4.2625e-01, time/batch = 0.6417s	
658/29850 (epoch 1.102), train_loss = 2.12393586, grad/param norm = 4.1293e-01, time/batch = 0.6448s	
659/29850 (epoch 1.104), train_loss = 2.20015940, grad/param norm = 3.4465e-01, time/batch = 0.6418s	
660/29850 (epoch 1.106), train_loss = 2.31424804, grad/param norm = 4.1896e-01, time/batch = 0.6408s	
661/29850 (epoch 1.107), train_loss = 2.20458502, grad/param norm = 3.1296e-01, time/batch = 0.6725s	
662/29850 (epoch 1.109), train_loss = 2.21005437, grad/param norm = 3.0266e-01, time/batch = 0.6621s	
663/29850 (epoch 1.111), train_loss = 2.29616885, grad/param norm = 3.8247e-01, time/batch = 0.6443s	
664/29850 (epoch 1.112), train_loss = 2.21676822, grad/param norm = 3.8126e-01, time/batch = 0.6474s	
665/29850 (epoch 1.114), train_loss = 2.34818392, grad/param norm = 3.0820e-01, time/batch = 0.6461s	
666/29850 (epoch 1.116), train_loss = 2.28856605, grad/param norm = 3.0632e-01, time/batch = 0.6461s	
667/29850 (epoch 1.117), train_loss = 2.29588030, grad/param norm = 3.3664e-01, time/batch = 0.6646s	
668/29850 (epoch 1.119), train_loss = 2.17627878, grad/param norm = 3.3245e-01, time/batch = 0.6540s	
669/29850 (epoch 1.121), train_loss = 2.12559072, grad/param norm = 2.7500e-01, time/batch = 0.6487s	
670/29850 (epoch 1.122), train_loss = 2.12865052, grad/param norm = 2.9018e-01, time/batch = 0.6581s	
671/29850 (epoch 1.124), train_loss = 2.12437820, grad/param norm = 2.4448e-01, time/batch = 0.6632s	
672/29850 (epoch 1.126), train_loss = 2.19922343, grad/param norm = 2.6592e-01, time/batch = 0.6711s	
673/29850 (epoch 1.127), train_loss = 2.39024732, grad/param norm = 2.4255e-01, time/batch = 0.6528s	
674/29850 (epoch 1.129), train_loss = 2.18937149, grad/param norm = 2.7770e-01, time/batch = 0.6422s	
675/29850 (epoch 1.131), train_loss = 2.16382669, grad/param norm = 2.3910e-01, time/batch = 0.6403s	
676/29850 (epoch 1.132), train_loss = 2.25972618, grad/param norm = 3.8741e-01, time/batch = 0.6469s	
677/29850 (epoch 1.134), train_loss = 2.28218108, grad/param norm = 5.9130e-01, time/batch = 0.6457s	
678/29850 (epoch 1.136), train_loss = 2.27532841, grad/param norm = 5.3665e-01, time/batch = 0.6425s	
679/29850 (epoch 1.137), train_loss = 2.19941443, grad/param norm = 3.3147e-01, time/batch = 0.6600s	
680/29850 (epoch 1.139), train_loss = 2.21159499, grad/param norm = 2.8768e-01, time/batch = 0.6543s	
681/29850 (epoch 1.141), train_loss = 2.25055165, grad/param norm = 3.0916e-01, time/batch = 0.6447s	
682/29850 (epoch 1.142), train_loss = 2.25699212, grad/param norm = 3.1336e-01, time/batch = 0.6597s	
683/29850 (epoch 1.144), train_loss = 2.31949624, grad/param norm = 2.7821e-01, time/batch = 0.6674s	
684/29850 (epoch 1.146), train_loss = 2.15330839, grad/param norm = 2.3909e-01, time/batch = 0.6440s	
685/29850 (epoch 1.147), train_loss = 2.23609467, grad/param norm = 2.7224e-01, time/batch = 0.6437s	
686/29850 (epoch 1.149), train_loss = 2.28891517, grad/param norm = 2.9951e-01, time/batch = 0.6493s	
687/29850 (epoch 1.151), train_loss = 2.17158628, grad/param norm = 3.1509e-01, time/batch = 0.6478s	
688/29850 (epoch 1.152), train_loss = 2.21372120, grad/param norm = 3.0457e-01, time/batch = 0.6479s	
689/29850 (epoch 1.154), train_loss = 2.18986616, grad/param norm = 3.2571e-01, time/batch = 0.6498s	
690/29850 (epoch 1.156), train_loss = 2.10428089, grad/param norm = 3.8469e-01, time/batch = 0.6470s	
691/29850 (epoch 1.157), train_loss = 2.24399401, grad/param norm = 2.6783e-01, time/batch = 0.6563s	
692/29850 (epoch 1.159), train_loss = 2.25516574, grad/param norm = 2.9186e-01, time/batch = 0.6486s	
693/29850 (epoch 1.161), train_loss = 2.29161703, grad/param norm = 3.4577e-01, time/batch = 0.6672s	
694/29850 (epoch 1.162), train_loss = 2.20376521, grad/param norm = 3.1188e-01, time/batch = 0.6578s	
695/29850 (epoch 1.164), train_loss = 2.17584227, grad/param norm = 3.2411e-01, time/batch = 0.6428s	
696/29850 (epoch 1.166), train_loss = 2.24423069, grad/param norm = 3.8540e-01, time/batch = 0.6519s	
697/29850 (epoch 1.168), train_loss = 2.14080976, grad/param norm = 3.6487e-01, time/batch = 0.6399s	
698/29850 (epoch 1.169), train_loss = 2.33006488, grad/param norm = 2.7248e-01, time/batch = 0.6392s	
699/29850 (epoch 1.171), train_loss = 2.29378011, grad/param norm = 2.7900e-01, time/batch = 0.6414s	
700/29850 (epoch 1.173), train_loss = 2.19911981, grad/param norm = 2.6331e-01, time/batch = 0.6438s	
701/29850 (epoch 1.174), train_loss = 2.22239902, grad/param norm = 2.9294e-01, time/batch = 0.6428s	
702/29850 (epoch 1.176), train_loss = 2.25401688, grad/param norm = 3.5842e-01, time/batch = 0.6483s	
703/29850 (epoch 1.178), train_loss = 2.23547831, grad/param norm = 3.6168e-01, time/batch = 0.6542s	
704/29850 (epoch 1.179), train_loss = 2.10668182, grad/param norm = 3.7115e-01, time/batch = 0.6704s	
705/29850 (epoch 1.181), train_loss = 2.11341755, grad/param norm = 3.5542e-01, time/batch = 0.6504s	
706/29850 (epoch 1.183), train_loss = 2.10400059, grad/param norm = 3.6647e-01, time/batch = 0.6431s	
707/29850 (epoch 1.184), train_loss = 2.16085381, grad/param norm = 3.1793e-01, time/batch = 0.6404s	
708/29850 (epoch 1.186), train_loss = 2.13476645, grad/param norm = 2.4802e-01, time/batch = 0.6422s	
709/29850 (epoch 1.188), train_loss = 2.19300480, grad/param norm = 2.8222e-01, time/batch = 0.6402s	
710/29850 (epoch 1.189), train_loss = 2.28200683, grad/param norm = 2.9599e-01, time/batch = 0.6403s	
711/29850 (epoch 1.191), train_loss = 2.12930205, grad/param norm = 3.3435e-01, time/batch = 0.6463s	
712/29850 (epoch 1.193), train_loss = 2.05233115, grad/param norm = 2.9059e-01, time/batch = 0.6436s	
713/29850 (epoch 1.194), train_loss = 2.24988675, grad/param norm = 3.6002e-01, time/batch = 0.6408s	
714/29850 (epoch 1.196), train_loss = 2.16668561, grad/param norm = 3.3426e-01, time/batch = 0.6535s	
715/29850 (epoch 1.198), train_loss = 2.18763091, grad/param norm = 2.5468e-01, time/batch = 0.6704s	
716/29850 (epoch 1.199), train_loss = 2.29544195, grad/param norm = 2.5693e-01, time/batch = 0.6557s	
717/29850 (epoch 1.201), train_loss = 2.32609974, grad/param norm = 3.1557e-01, time/batch = 0.6692s	
718/29850 (epoch 1.203), train_loss = 2.36693733, grad/param norm = 4.1954e-01, time/batch = 0.6735s	
719/29850 (epoch 1.204), train_loss = 2.21494415, grad/param norm = 3.3791e-01, time/batch = 0.6533s	
720/29850 (epoch 1.206), train_loss = 2.19677093, grad/param norm = 2.8408e-01, time/batch = 0.6467s	
721/29850 (epoch 1.208), train_loss = 2.34711834, grad/param norm = 3.1837e-01, time/batch = 0.6474s	
722/29850 (epoch 1.209), train_loss = 2.12924536, grad/param norm = 2.8691e-01, time/batch = 0.6466s	
723/29850 (epoch 1.211), train_loss = 2.10682549, grad/param norm = 3.4582e-01, time/batch = 0.6449s	
724/29850 (epoch 1.213), train_loss = 2.25248796, grad/param norm = 2.7625e-01, time/batch = 0.6426s	
725/29850 (epoch 1.214), train_loss = 2.16739734, grad/param norm = 2.9847e-01, time/batch = 0.6622s	
726/29850 (epoch 1.216), train_loss = 2.19692078, grad/param norm = 3.0613e-01, time/batch = 0.6651s	
727/29850 (epoch 1.218), train_loss = 2.28411952, grad/param norm = 2.9220e-01, time/batch = 0.6446s	
728/29850 (epoch 1.219), train_loss = 2.28771482, grad/param norm = 2.6984e-01, time/batch = 0.6437s	
729/29850 (epoch 1.221), train_loss = 2.15962205, grad/param norm = 2.6360e-01, time/batch = 0.6450s	
730/29850 (epoch 1.223), train_loss = 2.30586051, grad/param norm = 3.4741e-01, time/batch = 0.6445s	
731/29850 (epoch 1.224), train_loss = 2.19776029, grad/param norm = 3.1406e-01, time/batch = 0.6502s	
732/29850 (epoch 1.226), train_loss = 2.21560127, grad/param norm = 2.7043e-01, time/batch = 0.6509s	
733/29850 (epoch 1.228), train_loss = 2.12147560, grad/param norm = 2.3610e-01, time/batch = 0.6452s	
734/29850 (epoch 1.229), train_loss = 2.08046128, grad/param norm = 2.6185e-01, time/batch = 0.6445s	
735/29850 (epoch 1.231), train_loss = 2.15157411, grad/param norm = 2.5416e-01, time/batch = 0.6438s	
736/29850 (epoch 1.233), train_loss = 2.12316707, grad/param norm = 2.6662e-01, time/batch = 0.6697s	
737/29850 (epoch 1.235), train_loss = 2.09806786, grad/param norm = 2.6809e-01, time/batch = 0.6638s	
738/29850 (epoch 1.236), train_loss = 2.36046664, grad/param norm = 2.4870e-01, time/batch = 0.6542s	
739/29850 (epoch 1.238), train_loss = 2.08927759, grad/param norm = 2.9438e-01, time/batch = 0.6447s	
740/29850 (epoch 1.240), train_loss = 2.25815756, grad/param norm = 4.1881e-01, time/batch = 0.6458s	
741/29850 (epoch 1.241), train_loss = 2.46750415, grad/param norm = 4.4475e-01, time/batch = 0.6442s	
742/29850 (epoch 1.243), train_loss = 2.14921005, grad/param norm = 4.2276e-01, time/batch = 0.6428s	
743/29850 (epoch 1.245), train_loss = 2.26980927, grad/param norm = 4.5772e-01, time/batch = 0.6452s	
744/29850 (epoch 1.246), train_loss = 2.22653012, grad/param norm = 4.1717e-01, time/batch = 0.6414s	
745/29850 (epoch 1.248), train_loss = 2.20512663, grad/param norm = 2.6803e-01, time/batch = 0.6440s	
746/29850 (epoch 1.250), train_loss = 2.25143473, grad/param norm = 2.4246e-01, time/batch = 0.6478s	
747/29850 (epoch 1.251), train_loss = 2.08107727, grad/param norm = 2.3522e-01, time/batch = 0.6701s	
748/29850 (epoch 1.253), train_loss = 2.23218666, grad/param norm = 2.8012e-01, time/batch = 0.6488s	
749/29850 (epoch 1.255), train_loss = 2.29376253, grad/param norm = 2.7616e-01, time/batch = 0.6403s	
750/29850 (epoch 1.256), train_loss = 2.18886071, grad/param norm = 2.7247e-01, time/batch = 0.6447s	
751/29850 (epoch 1.258), train_loss = 2.20085502, grad/param norm = 3.0097e-01, time/batch = 0.6441s	
752/29850 (epoch 1.260), train_loss = 2.09207833, grad/param norm = 2.4626e-01, time/batch = 0.6480s	
753/29850 (epoch 1.261), train_loss = 2.14951891, grad/param norm = 2.7123e-01, time/batch = 0.6495s	
754/29850 (epoch 1.263), train_loss = 2.14831190, grad/param norm = 2.3514e-01, time/batch = 0.6458s	
755/29850 (epoch 1.265), train_loss = 2.17039325, grad/param norm = 2.7547e-01, time/batch = 0.6432s	
756/29850 (epoch 1.266), train_loss = 2.13249444, grad/param norm = 3.0604e-01, time/batch = 0.6403s	
757/29850 (epoch 1.268), train_loss = 2.21027674, grad/param norm = 3.4277e-01, time/batch = 0.6427s	
758/29850 (epoch 1.270), train_loss = 2.13696348, grad/param norm = 2.9681e-01, time/batch = 0.6428s	
759/29850 (epoch 1.271), train_loss = 2.17521117, grad/param norm = 3.2081e-01, time/batch = 0.6385s	
760/29850 (epoch 1.273), train_loss = 2.22019491, grad/param norm = 2.9768e-01, time/batch = 0.6404s	
761/29850 (epoch 1.275), train_loss = 2.15242429, grad/param norm = 2.5765e-01, time/batch = 0.6432s	
762/29850 (epoch 1.276), train_loss = 2.10337403, grad/param norm = 2.6566e-01, time/batch = 0.6436s	
763/29850 (epoch 1.278), train_loss = 2.07944193, grad/param norm = 2.7202e-01, time/batch = 0.6440s	
764/29850 (epoch 1.280), train_loss = 2.14607604, grad/param norm = 3.0903e-01, time/batch = 0.6398s	
765/29850 (epoch 1.281), train_loss = 2.07609936, grad/param norm = 3.4507e-01, time/batch = 0.6478s	
766/29850 (epoch 1.283), train_loss = 2.24551250, grad/param norm = 3.2830e-01, time/batch = 0.6412s	
767/29850 (epoch 1.285), train_loss = 2.23196802, grad/param norm = 3.2162e-01, time/batch = 0.6416s	
768/29850 (epoch 1.286), train_loss = 2.15173877, grad/param norm = 2.8614e-01, time/batch = 0.6445s	
769/29850 (epoch 1.288), train_loss = 2.25173954, grad/param norm = 2.6896e-01, time/batch = 0.6417s	
770/29850 (epoch 1.290), train_loss = 2.12705843, grad/param norm = 2.9750e-01, time/batch = 0.6513s	
771/29850 (epoch 1.291), train_loss = 2.33051139, grad/param norm = 2.5238e-01, time/batch = 0.6462s	
772/29850 (epoch 1.293), train_loss = 2.23914274, grad/param norm = 2.6870e-01, time/batch = 0.6442s	
773/29850 (epoch 1.295), train_loss = 2.20977468, grad/param norm = 2.9000e-01, time/batch = 0.6463s	
774/29850 (epoch 1.296), train_loss = 2.06946148, grad/param norm = 2.5919e-01, time/batch = 0.6491s	
775/29850 (epoch 1.298), train_loss = 2.00107671, grad/param norm = 2.6082e-01, time/batch = 0.6463s	
776/29850 (epoch 1.300), train_loss = 2.14621805, grad/param norm = 2.8051e-01, time/batch = 0.6543s	
777/29850 (epoch 1.302), train_loss = 2.01932014, grad/param norm = 2.8311e-01, time/batch = 0.6458s	
778/29850 (epoch 1.303), train_loss = 2.19202429, grad/param norm = 3.0928e-01, time/batch = 0.6458s	
779/29850 (epoch 1.305), train_loss = 2.13712355, grad/param norm = 2.4427e-01, time/batch = 0.6427s	
780/29850 (epoch 1.307), train_loss = 2.22916985, grad/param norm = 3.1568e-01, time/batch = 0.6374s	
781/29850 (epoch 1.308), train_loss = 2.17695266, grad/param norm = 2.7047e-01, time/batch = 0.6477s	
782/29850 (epoch 1.310), train_loss = 2.22998690, grad/param norm = 2.7572e-01, time/batch = 0.6456s	
783/29850 (epoch 1.312), train_loss = 2.14110265, grad/param norm = 3.1972e-01, time/batch = 0.6434s	
784/29850 (epoch 1.313), train_loss = 2.17486621, grad/param norm = 3.4180e-01, time/batch = 0.6432s	
785/29850 (epoch 1.315), train_loss = 2.26125977, grad/param norm = 4.4951e-01, time/batch = 0.6433s	
786/29850 (epoch 1.317), train_loss = 2.34222184, grad/param norm = 4.2285e-01, time/batch = 0.6455s	
787/29850 (epoch 1.318), train_loss = 2.17433764, grad/param norm = 3.7259e-01, time/batch = 0.6611s	
788/29850 (epoch 1.320), train_loss = 1.97272330, grad/param norm = 2.9616e-01, time/batch = 0.6621s	
789/29850 (epoch 1.322), train_loss = 2.14986883, grad/param norm = 2.6879e-01, time/batch = 0.6643s	
790/29850 (epoch 1.323), train_loss = 2.11795867, grad/param norm = 2.6953e-01, time/batch = 0.6548s	
791/29850 (epoch 1.325), train_loss = 2.12418166, grad/param norm = 2.7427e-01, time/batch = 0.6453s	
792/29850 (epoch 1.327), train_loss = 2.26657703, grad/param norm = 2.4682e-01, time/batch = 0.6409s	
793/29850 (epoch 1.328), train_loss = 2.34738076, grad/param norm = 2.9171e-01, time/batch = 0.6453s	
794/29850 (epoch 1.330), train_loss = 2.16079125, grad/param norm = 2.8753e-01, time/batch = 0.6427s	
795/29850 (epoch 1.332), train_loss = 2.04833396, grad/param norm = 2.4754e-01, time/batch = 0.6418s	
796/29850 (epoch 1.333), train_loss = 2.29859888, grad/param norm = 3.1220e-01, time/batch = 0.6589s	
797/29850 (epoch 1.335), train_loss = 2.20785235, grad/param norm = 2.2899e-01, time/batch = 0.6602s	
798/29850 (epoch 1.337), train_loss = 2.14259641, grad/param norm = 2.4177e-01, time/batch = 0.6524s	
799/29850 (epoch 1.338), train_loss = 2.16382472, grad/param norm = 3.4681e-01, time/batch = 0.6444s	
800/29850 (epoch 1.340), train_loss = 1.99450160, grad/param norm = 3.7614e-01, time/batch = 0.6416s	
801/29850 (epoch 1.342), train_loss = 2.25034057, grad/param norm = 3.5769e-01, time/batch = 0.6431s	
802/29850 (epoch 1.343), train_loss = 2.28090595, grad/param norm = 3.2825e-01, time/batch = 0.6448s	
803/29850 (epoch 1.345), train_loss = 2.27549503, grad/param norm = 2.5599e-01, time/batch = 0.6463s	
804/29850 (epoch 1.347), train_loss = 2.10721488, grad/param norm = 2.4816e-01, time/batch = 0.6463s	
805/29850 (epoch 1.348), train_loss = 2.24579286, grad/param norm = 2.5259e-01, time/batch = 0.6641s	
806/29850 (epoch 1.350), train_loss = 2.24353453, grad/param norm = 3.0919e-01, time/batch = 0.6625s	
807/29850 (epoch 1.352), train_loss = 2.20101137, grad/param norm = 3.2416e-01, time/batch = 0.6412s	
808/29850 (epoch 1.353), train_loss = 2.18625839, grad/param norm = 3.3866e-01, time/batch = 0.6482s	
809/29850 (epoch 1.355), train_loss = 2.06174168, grad/param norm = 4.2056e-01, time/batch = 0.6661s	
810/29850 (epoch 1.357), train_loss = 2.31898787, grad/param norm = 3.5406e-01, time/batch = 0.6739s	
811/29850 (epoch 1.358), train_loss = 1.96501970, grad/param norm = 2.1400e-01, time/batch = 0.6580s	
812/29850 (epoch 1.360), train_loss = 2.04443545, grad/param norm = 2.4376e-01, time/batch = 0.6523s	
813/29850 (epoch 1.362), train_loss = 2.11238879, grad/param norm = 3.0064e-01, time/batch = 0.6518s	
814/29850 (epoch 1.363), train_loss = 2.17788673, grad/param norm = 3.1348e-01, time/batch = 0.6639s	
815/29850 (epoch 1.365), train_loss = 2.20547653, grad/param norm = 2.3897e-01, time/batch = 0.6575s	
816/29850 (epoch 1.367), train_loss = 2.10389618, grad/param norm = 2.4915e-01, time/batch = 0.6704s	
817/29850 (epoch 1.369), train_loss = 1.99579651, grad/param norm = 2.7169e-01, time/batch = 0.6655s	
818/29850 (epoch 1.370), train_loss = 2.01699081, grad/param norm = 2.9353e-01, time/batch = 0.6528s	
819/29850 (epoch 1.372), train_loss = 2.22913800, grad/param norm = 2.4546e-01, time/batch = 0.6516s	
820/29850 (epoch 1.374), train_loss = 2.06332443, grad/param norm = 3.3459e-01, time/batch = 0.6461s	
821/29850 (epoch 1.375), train_loss = 2.10429273, grad/param norm = 3.0901e-01, time/batch = 0.6434s	
822/29850 (epoch 1.377), train_loss = 2.13737925, grad/param norm = 3.0690e-01, time/batch = 0.6429s	
823/29850 (epoch 1.379), train_loss = 2.17370432, grad/param norm = 3.1068e-01, time/batch = 0.6426s	
824/29850 (epoch 1.380), train_loss = 2.24254692, grad/param norm = 2.8681e-01, time/batch = 0.6496s	
825/29850 (epoch 1.382), train_loss = 2.22542928, grad/param norm = 2.5966e-01, time/batch = 0.6455s	
826/29850 (epoch 1.384), train_loss = 2.04016618, grad/param norm = 2.4062e-01, time/batch = 0.6544s	
827/29850 (epoch 1.385), train_loss = 2.20193277, grad/param norm = 2.5396e-01, time/batch = 0.6482s	
828/29850 (epoch 1.387), train_loss = 2.11380578, grad/param norm = 2.4895e-01, time/batch = 0.6466s	
829/29850 (epoch 1.389), train_loss = 2.24587898, grad/param norm = 2.9389e-01, time/batch = 0.6512s	
830/29850 (epoch 1.390), train_loss = 2.10010342, grad/param norm = 3.5470e-01, time/batch = 0.6465s	
831/29850 (epoch 1.392), train_loss = 2.06411666, grad/param norm = 2.7118e-01, time/batch = 0.6486s	
832/29850 (epoch 1.394), train_loss = 2.13993875, grad/param norm = 2.8785e-01, time/batch = 0.6548s	
833/29850 (epoch 1.395), train_loss = 2.25399898, grad/param norm = 2.6192e-01, time/batch = 0.6540s	
834/29850 (epoch 1.397), train_loss = 2.12237539, grad/param norm = 2.7829e-01, time/batch = 0.6656s	
835/29850 (epoch 1.399), train_loss = 1.97006442, grad/param norm = 2.4803e-01, time/batch = 0.6543s	
836/29850 (epoch 1.400), train_loss = 2.22089280, grad/param norm = 3.1101e-01, time/batch = 0.6373s	
837/29850 (epoch 1.402), train_loss = 2.20392492, grad/param norm = 2.8123e-01, time/batch = 0.6646s	
838/29850 (epoch 1.404), train_loss = 2.28922690, grad/param norm = 2.3795e-01, time/batch = 0.6653s	
839/29850 (epoch 1.405), train_loss = 2.23778945, grad/param norm = 2.7008e-01, time/batch = 0.6428s	
840/29850 (epoch 1.407), train_loss = 2.26173034, grad/param norm = 3.5584e-01, time/batch = 0.6447s	
841/29850 (epoch 1.409), train_loss = 2.37956396, grad/param norm = 3.3002e-01, time/batch = 0.6432s	
842/29850 (epoch 1.410), train_loss = 2.16737649, grad/param norm = 2.4255e-01, time/batch = 0.6457s	
843/29850 (epoch 1.412), train_loss = 2.06385202, grad/param norm = 2.2209e-01, time/batch = 0.6436s	
844/29850 (epoch 1.414), train_loss = 2.13891134, grad/param norm = 2.9426e-01, time/batch = 0.6455s	
845/29850 (epoch 1.415), train_loss = 2.12297176, grad/param norm = 3.3559e-01, time/batch = 0.6472s	
846/29850 (epoch 1.417), train_loss = 2.14685331, grad/param norm = 2.6756e-01, time/batch = 0.6475s	
847/29850 (epoch 1.419), train_loss = 2.14663277, grad/param norm = 2.7404e-01, time/batch = 0.6564s	
848/29850 (epoch 1.420), train_loss = 2.04499845, grad/param norm = 2.4547e-01, time/batch = 0.6703s	
849/29850 (epoch 1.422), train_loss = 2.11289265, grad/param norm = 2.5471e-01, time/batch = 0.6591s	
850/29850 (epoch 1.424), train_loss = 2.23416377, grad/param norm = 2.4432e-01, time/batch = 0.6526s	
851/29850 (epoch 1.425), train_loss = 2.30879799, grad/param norm = 2.4033e-01, time/batch = 0.6486s	
852/29850 (epoch 1.427), train_loss = 2.00285882, grad/param norm = 2.8005e-01, time/batch = 0.6475s	
853/29850 (epoch 1.429), train_loss = 2.11085798, grad/param norm = 2.5447e-01, time/batch = 0.6515s	
854/29850 (epoch 1.430), train_loss = 2.03551032, grad/param norm = 2.8108e-01, time/batch = 0.6543s	
855/29850 (epoch 1.432), train_loss = 2.17617048, grad/param norm = 3.1729e-01, time/batch = 0.6839s	
856/29850 (epoch 1.434), train_loss = 2.06485168, grad/param norm = 2.7267e-01, time/batch = 0.6701s	
857/29850 (epoch 1.436), train_loss = 2.14406905, grad/param norm = 2.5829e-01, time/batch = 0.6683s	
858/29850 (epoch 1.437), train_loss = 2.01087206, grad/param norm = 2.5682e-01, time/batch = 0.6720s	
859/29850 (epoch 1.439), train_loss = 2.17298070, grad/param norm = 3.6175e-01, time/batch = 0.6721s	
860/29850 (epoch 1.441), train_loss = 2.14438549, grad/param norm = 3.0773e-01, time/batch = 0.6548s	
861/29850 (epoch 1.442), train_loss = 2.15096963, grad/param norm = 2.5639e-01, time/batch = 0.6529s	
862/29850 (epoch 1.444), train_loss = 2.13068999, grad/param norm = 2.3432e-01, time/batch = 0.6578s	
863/29850 (epoch 1.446), train_loss = 2.14415106, grad/param norm = 2.7409e-01, time/batch = 0.6615s	
864/29850 (epoch 1.447), train_loss = 2.16445017, grad/param norm = 2.5831e-01, time/batch = 0.6641s	
865/29850 (epoch 1.449), train_loss = 2.33886529, grad/param norm = 2.9016e-01, time/batch = 0.6594s	
866/29850 (epoch 1.451), train_loss = 2.10214348, grad/param norm = 2.2434e-01, time/batch = 0.6513s	
867/29850 (epoch 1.452), train_loss = 2.10010974, grad/param norm = 2.2198e-01, time/batch = 0.6506s	
868/29850 (epoch 1.454), train_loss = 2.02888987, grad/param norm = 2.6958e-01, time/batch = 0.6560s	
869/29850 (epoch 1.456), train_loss = 2.08464886, grad/param norm = 2.7487e-01, time/batch = 0.6702s	
870/29850 (epoch 1.457), train_loss = 2.33478167, grad/param norm = 2.8271e-01, time/batch = 0.6576s	
871/29850 (epoch 1.459), train_loss = 2.26634112, grad/param norm = 3.0042e-01, time/batch = 0.6435s	
872/29850 (epoch 1.461), train_loss = 2.29980321, grad/param norm = 2.8953e-01, time/batch = 0.6457s	
873/29850 (epoch 1.462), train_loss = 2.14528443, grad/param norm = 3.0086e-01, time/batch = 0.6466s	
874/29850 (epoch 1.464), train_loss = 2.11897085, grad/param norm = 2.6396e-01, time/batch = 0.6438s	
875/29850 (epoch 1.466), train_loss = 2.09313088, grad/param norm = 2.7574e-01, time/batch = 0.6561s	
876/29850 (epoch 1.467), train_loss = 2.08135030, grad/param norm = 3.2847e-01, time/batch = 0.6596s	
877/29850 (epoch 1.469), train_loss = 2.13854533, grad/param norm = 2.6815e-01, time/batch = 0.6513s	
878/29850 (epoch 1.471), train_loss = 2.21489940, grad/param norm = 2.4533e-01, time/batch = 0.6427s	
879/29850 (epoch 1.472), train_loss = 2.02125479, grad/param norm = 2.2302e-01, time/batch = 0.6506s	
880/29850 (epoch 1.474), train_loss = 2.24096057, grad/param norm = 2.7129e-01, time/batch = 0.6708s	
881/29850 (epoch 1.476), train_loss = 2.14683905, grad/param norm = 2.7665e-01, time/batch = 0.6496s	
882/29850 (epoch 1.477), train_loss = 2.23978707, grad/param norm = 2.5266e-01, time/batch = 0.6377s	
883/29850 (epoch 1.479), train_loss = 2.18105038, grad/param norm = 2.5157e-01, time/batch = 0.6429s	
884/29850 (epoch 1.481), train_loss = 2.27075464, grad/param norm = 2.9885e-01, time/batch = 0.6412s	
885/29850 (epoch 1.482), train_loss = 2.07640550, grad/param norm = 2.9087e-01, time/batch = 0.6469s	
886/29850 (epoch 1.484), train_loss = 2.12376185, grad/param norm = 3.0287e-01, time/batch = 0.6447s	
887/29850 (epoch 1.486), train_loss = 2.06637547, grad/param norm = 2.5527e-01, time/batch = 0.6458s	
888/29850 (epoch 1.487), train_loss = 1.95806812, grad/param norm = 2.4868e-01, time/batch = 0.6500s	
889/29850 (epoch 1.489), train_loss = 2.03562995, grad/param norm = 2.4127e-01, time/batch = 0.6466s	
890/29850 (epoch 1.491), train_loss = 2.01053613, grad/param norm = 2.2677e-01, time/batch = 0.6534s	
891/29850 (epoch 1.492), train_loss = 2.20559272, grad/param norm = 2.3180e-01, time/batch = 0.6713s	
892/29850 (epoch 1.494), train_loss = 2.15808052, grad/param norm = 2.2558e-01, time/batch = 0.6491s	
893/29850 (epoch 1.496), train_loss = 2.27648049, grad/param norm = 2.6836e-01, time/batch = 0.6446s	
894/29850 (epoch 1.497), train_loss = 2.10533779, grad/param norm = 3.5698e-01, time/batch = 0.6439s	
895/29850 (epoch 1.499), train_loss = 2.11632353, grad/param norm = 3.0085e-01, time/batch = 0.6460s	
896/29850 (epoch 1.501), train_loss = 2.01511623, grad/param norm = 2.4992e-01, time/batch = 0.6486s	
897/29850 (epoch 1.503), train_loss = 2.12023934, grad/param norm = 2.5371e-01, time/batch = 0.6488s	
898/29850 (epoch 1.504), train_loss = 2.17800684, grad/param norm = 2.0902e-01, time/batch = 0.6460s	
899/29850 (epoch 1.506), train_loss = 2.22841226, grad/param norm = 2.6512e-01, time/batch = 0.6483s	
900/29850 (epoch 1.508), train_loss = 2.16024426, grad/param norm = 3.2401e-01, time/batch = 0.6591s	
901/29850 (epoch 1.509), train_loss = 2.02248348, grad/param norm = 3.5335e-01, time/batch = 0.6732s	
902/29850 (epoch 1.511), train_loss = 2.10079760, grad/param norm = 3.1079e-01, time/batch = 0.6781s	
903/29850 (epoch 1.513), train_loss = 2.17938852, grad/param norm = 3.4697e-01, time/batch = 0.6736s	
904/29850 (epoch 1.514), train_loss = 2.00195490, grad/param norm = 2.9761e-01, time/batch = 0.6737s	
905/29850 (epoch 1.516), train_loss = 2.00881873, grad/param norm = 2.6322e-01, time/batch = 0.6694s	
906/29850 (epoch 1.518), train_loss = 2.03027153, grad/param norm = 2.2261e-01, time/batch = 0.6684s	
907/29850 (epoch 1.519), train_loss = 2.04101655, grad/param norm = 2.5933e-01, time/batch = 0.6509s	
908/29850 (epoch 1.521), train_loss = 2.08298724, grad/param norm = 2.5624e-01, time/batch = 0.6505s	
909/29850 (epoch 1.523), train_loss = 1.95174300, grad/param norm = 2.3197e-01, time/batch = 0.6670s	
910/29850 (epoch 1.524), train_loss = 2.11552692, grad/param norm = 2.6152e-01, time/batch = 0.6848s	
911/29850 (epoch 1.526), train_loss = 2.20910297, grad/param norm = 2.7926e-01, time/batch = 0.6789s	
912/29850 (epoch 1.528), train_loss = 2.11987969, grad/param norm = 2.5120e-01, time/batch = 0.6569s	
913/29850 (epoch 1.529), train_loss = 2.14486549, grad/param norm = 2.8907e-01, time/batch = 0.6604s	
914/29850 (epoch 1.531), train_loss = 2.17906010, grad/param norm = 3.1280e-01, time/batch = 0.6713s	
915/29850 (epoch 1.533), train_loss = 2.05334365, grad/param norm = 2.9886e-01, time/batch = 0.6597s	
916/29850 (epoch 1.534), train_loss = 2.04564257, grad/param norm = 3.7914e-01, time/batch = 0.6564s	
917/29850 (epoch 1.536), train_loss = 2.19640857, grad/param norm = 3.3340e-01, time/batch = 0.6613s	
918/29850 (epoch 1.538), train_loss = 2.09341994, grad/param norm = 2.7934e-01, time/batch = 0.6658s	
919/29850 (epoch 1.539), train_loss = 2.08255366, grad/param norm = 2.3961e-01, time/batch = 0.6794s	
920/29850 (epoch 1.541), train_loss = 1.98142277, grad/param norm = 2.2821e-01, time/batch = 0.6666s	
921/29850 (epoch 1.543), train_loss = 2.02996416, grad/param norm = 2.5374e-01, time/batch = 0.6653s	
922/29850 (epoch 1.544), train_loss = 2.04419626, grad/param norm = 3.0613e-01, time/batch = 0.6582s	
923/29850 (epoch 1.546), train_loss = 2.18779996, grad/param norm = 2.9834e-01, time/batch = 0.6504s	
924/29850 (epoch 1.548), train_loss = 1.99490479, grad/param norm = 3.1086e-01, time/batch = 0.6707s	
925/29850 (epoch 1.549), train_loss = 2.11847031, grad/param norm = 2.3126e-01, time/batch = 0.6665s	
926/29850 (epoch 1.551), train_loss = 2.04682473, grad/param norm = 2.7158e-01, time/batch = 0.6624s	
927/29850 (epoch 1.553), train_loss = 2.12951981, grad/param norm = 2.8092e-01, time/batch = 0.6592s	
928/29850 (epoch 1.554), train_loss = 1.94471847, grad/param norm = 2.7623e-01, time/batch = 0.6602s	
929/29850 (epoch 1.556), train_loss = 2.10353403, grad/param norm = 2.9698e-01, time/batch = 0.6670s	
930/29850 (epoch 1.558), train_loss = 2.03368112, grad/param norm = 3.0155e-01, time/batch = 0.6582s	
931/29850 (epoch 1.559), train_loss = 2.18051234, grad/param norm = 2.4985e-01, time/batch = 0.6571s	
932/29850 (epoch 1.561), train_loss = 2.19034023, grad/param norm = 2.4911e-01, time/batch = 0.6644s	
933/29850 (epoch 1.563), train_loss = 2.12507589, grad/param norm = 2.4789e-01, time/batch = 0.6852s	
934/29850 (epoch 1.564), train_loss = 2.13492553, grad/param norm = 2.5881e-01, time/batch = 0.6675s	
935/29850 (epoch 1.566), train_loss = 2.01970247, grad/param norm = 2.8621e-01, time/batch = 0.6591s	
936/29850 (epoch 1.568), train_loss = 2.14629806, grad/param norm = 2.9319e-01, time/batch = 0.6585s	
937/29850 (epoch 1.570), train_loss = 2.04686862, grad/param norm = 2.7276e-01, time/batch = 0.6629s	
938/29850 (epoch 1.571), train_loss = 2.15505299, grad/param norm = 3.0941e-01, time/batch = 0.6577s	
939/29850 (epoch 1.573), train_loss = 2.20484987, grad/param norm = 2.7214e-01, time/batch = 0.6513s	
940/29850 (epoch 1.575), train_loss = 2.10910552, grad/param norm = 2.6830e-01, time/batch = 0.6534s	
941/29850 (epoch 1.576), train_loss = 2.16537013, grad/param norm = 2.4910e-01, time/batch = 0.6543s	
942/29850 (epoch 1.578), train_loss = 2.14441612, grad/param norm = 2.5375e-01, time/batch = 0.6528s	
943/29850 (epoch 1.580), train_loss = 2.06202896, grad/param norm = 2.3017e-01, time/batch = 0.6821s	
944/29850 (epoch 1.581), train_loss = 2.12102525, grad/param norm = 2.6269e-01, time/batch = 0.6795s	
945/29850 (epoch 1.583), train_loss = 1.94832561, grad/param norm = 2.0299e-01, time/batch = 0.6625s	
946/29850 (epoch 1.585), train_loss = 1.98411257, grad/param norm = 2.1505e-01, time/batch = 0.6631s	
947/29850 (epoch 1.586), train_loss = 2.06165891, grad/param norm = 2.1383e-01, time/batch = 0.6600s	
948/29850 (epoch 1.588), train_loss = 2.03362514, grad/param norm = 2.6016e-01, time/batch = 0.6584s	
949/29850 (epoch 1.590), train_loss = 2.16715159, grad/param norm = 2.5675e-01, time/batch = 0.6577s	
950/29850 (epoch 1.591), train_loss = 2.05050946, grad/param norm = 2.9534e-01, time/batch = 0.6579s	
951/29850 (epoch 1.593), train_loss = 2.03229288, grad/param norm = 2.7565e-01, time/batch = 0.6620s	
952/29850 (epoch 1.595), train_loss = 1.99074850, grad/param norm = 2.3577e-01, time/batch = 0.6600s	
953/29850 (epoch 1.596), train_loss = 2.06034288, grad/param norm = 2.8978e-01, time/batch = 0.6711s	
954/29850 (epoch 1.598), train_loss = 1.97692045, grad/param norm = 2.8644e-01, time/batch = 0.6879s	
955/29850 (epoch 1.600), train_loss = 2.11358695, grad/param norm = 2.7986e-01, time/batch = 0.6618s	
956/29850 (epoch 1.601), train_loss = 2.00496337, grad/param norm = 2.4829e-01, time/batch = 0.6561s	
957/29850 (epoch 1.603), train_loss = 2.16487470, grad/param norm = 2.6673e-01, time/batch = 0.6648s	
958/29850 (epoch 1.605), train_loss = 2.14309255, grad/param norm = 2.4925e-01, time/batch = 0.6642s	
959/29850 (epoch 1.606), train_loss = 1.95242248, grad/param norm = 2.2177e-01, time/batch = 0.6663s	
960/29850 (epoch 1.608), train_loss = 2.05719617, grad/param norm = 2.3062e-01, time/batch = 0.6647s	
961/29850 (epoch 1.610), train_loss = 2.02859684, grad/param norm = 2.3173e-01, time/batch = 0.6618s	
962/29850 (epoch 1.611), train_loss = 1.86726762, grad/param norm = 2.6100e-01, time/batch = 0.6586s	
963/29850 (epoch 1.613), train_loss = 1.89361839, grad/param norm = 2.8061e-01, time/batch = 0.6594s	
964/29850 (epoch 1.615), train_loss = 1.95364315, grad/param norm = 2.9040e-01, time/batch = 0.6827s	
965/29850 (epoch 1.616), train_loss = 2.15852917, grad/param norm = 2.8100e-01, time/batch = 0.6740s	
966/29850 (epoch 1.618), train_loss = 2.07837093, grad/param norm = 2.4817e-01, time/batch = 0.6583s	
967/29850 (epoch 1.620), train_loss = 2.03686073, grad/param norm = 1.9325e-01, time/batch = 0.6590s	
968/29850 (epoch 1.621), train_loss = 1.96611876, grad/param norm = 2.5864e-01, time/batch = 0.6594s	
969/29850 (epoch 1.623), train_loss = 2.06823215, grad/param norm = 3.0536e-01, time/batch = 0.6575s	
970/29850 (epoch 1.625), train_loss = 2.09859843, grad/param norm = 2.9282e-01, time/batch = 0.6648s	
971/29850 (epoch 1.626), train_loss = 2.13218804, grad/param norm = 2.3999e-01, time/batch = 0.6712s	
972/29850 (epoch 1.628), train_loss = 1.91283459, grad/param norm = 2.8903e-01, time/batch = 0.6623s	
973/29850 (epoch 1.630), train_loss = 2.08478760, grad/param norm = 2.6925e-01, time/batch = 0.6740s	
974/29850 (epoch 1.631), train_loss = 2.01772413, grad/param norm = 2.3920e-01, time/batch = 0.6760s	
975/29850 (epoch 1.633), train_loss = 2.18641383, grad/param norm = 2.9072e-01, time/batch = 0.6897s	
976/29850 (epoch 1.635), train_loss = 2.17965758, grad/param norm = 2.7211e-01, time/batch = 0.6715s	
977/29850 (epoch 1.637), train_loss = 2.20408370, grad/param norm = 2.3678e-01, time/batch = 0.6710s	
978/29850 (epoch 1.638), train_loss = 1.88784582, grad/param norm = 2.3578e-01, time/batch = 0.6609s	
979/29850 (epoch 1.640), train_loss = 2.23078317, grad/param norm = 2.4024e-01, time/batch = 0.6596s	
980/29850 (epoch 1.642), train_loss = 2.08458867, grad/param norm = 2.6623e-01, time/batch = 0.6637s	
981/29850 (epoch 1.643), train_loss = 1.93059564, grad/param norm = 2.5367e-01, time/batch = 0.6627s	
982/29850 (epoch 1.645), train_loss = 2.01975095, grad/param norm = 2.1722e-01, time/batch = 0.6633s	
983/29850 (epoch 1.647), train_loss = 2.16996237, grad/param norm = 2.5564e-01, time/batch = 0.6613s	
984/29850 (epoch 1.648), train_loss = 1.92559579, grad/param norm = 2.2182e-01, time/batch = 0.6583s	
985/29850 (epoch 1.650), train_loss = 2.11338044, grad/param norm = 2.7533e-01, time/batch = 0.6852s	
986/29850 (epoch 1.652), train_loss = 1.98232570, grad/param norm = 2.5074e-01, time/batch = 0.6712s	
987/29850 (epoch 1.653), train_loss = 2.13842650, grad/param norm = 2.8594e-01, time/batch = 0.6569s	
988/29850 (epoch 1.655), train_loss = 2.06986250, grad/param norm = 2.3757e-01, time/batch = 0.6640s	
989/29850 (epoch 1.657), train_loss = 1.97477153, grad/param norm = 2.2801e-01, time/batch = 0.6695s	
990/29850 (epoch 1.658), train_loss = 2.09847671, grad/param norm = 2.5683e-01, time/batch = 0.6903s	
991/29850 (epoch 1.660), train_loss = 1.86748971, grad/param norm = 2.6672e-01, time/batch = 0.6954s	
992/29850 (epoch 1.662), train_loss = 2.09555041, grad/param norm = 3.1592e-01, time/batch = 0.6865s	
993/29850 (epoch 1.663), train_loss = 2.05160465, grad/param norm = 2.5694e-01, time/batch = 0.6809s	
994/29850 (epoch 1.665), train_loss = 2.09211695, grad/param norm = 2.5007e-01, time/batch = 0.6718s	
995/29850 (epoch 1.667), train_loss = 2.12446386, grad/param norm = 2.5964e-01, time/batch = 0.6822s	
996/29850 (epoch 1.668), train_loss = 2.18010650, grad/param norm = 2.7067e-01, time/batch = 0.6952s	
997/29850 (epoch 1.670), train_loss = 2.33661111, grad/param norm = 2.7481e-01, time/batch = 0.6916s	
998/29850 (epoch 1.672), train_loss = 2.06446031, grad/param norm = 2.7141e-01, time/batch = 0.6855s	
999/29850 (epoch 1.673), train_loss = 2.13114166, grad/param norm = 2.6580e-01, time/batch = 0.6803s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch1.68_2.1228.t7	
1000/29850 (epoch 1.675), train_loss = 2.08554385, grad/param norm = 2.5481e-01, time/batch = 0.6827s	
1001/29850 (epoch 1.677), train_loss = 2.19390877, grad/param norm = 2.7256e-01, time/batch = 0.6640s	
1002/29850 (epoch 1.678), train_loss = 2.05523038, grad/param norm = 2.5610e-01, time/batch = 0.6636s	
1003/29850 (epoch 1.680), train_loss = 2.02594477, grad/param norm = 2.2861e-01, time/batch = 0.6626s	
1004/29850 (epoch 1.682), train_loss = 2.07895044, grad/param norm = 2.5153e-01, time/batch = 0.6602s	
1005/29850 (epoch 1.683), train_loss = 2.25478243, grad/param norm = 2.6677e-01, time/batch = 0.6632s	
1006/29850 (epoch 1.685), train_loss = 2.20663952, grad/param norm = 2.4137e-01, time/batch = 0.6612s	
1007/29850 (epoch 1.687), train_loss = 2.16205186, grad/param norm = 2.9838e-01, time/batch = 0.6729s	
1008/29850 (epoch 1.688), train_loss = 1.94794287, grad/param norm = 2.5589e-01, time/batch = 0.6768s	
1009/29850 (epoch 1.690), train_loss = 1.98965348, grad/param norm = 2.5695e-01, time/batch = 0.6590s	
1010/29850 (epoch 1.692), train_loss = 2.33086490, grad/param norm = 3.5675e-01, time/batch = 0.6579s	
1011/29850 (epoch 1.693), train_loss = 2.13429880, grad/param norm = 2.5924e-01, time/batch = 0.6658s	
1012/29850 (epoch 1.695), train_loss = 2.10889782, grad/param norm = 2.2838e-01, time/batch = 0.6618s	
1013/29850 (epoch 1.697), train_loss = 2.21391021, grad/param norm = 3.3802e-01, time/batch = 0.6753s	
1014/29850 (epoch 1.698), train_loss = 2.11534944, grad/param norm = 3.1194e-01, time/batch = 0.6708s	
1015/29850 (epoch 1.700), train_loss = 2.14458257, grad/param norm = 2.5093e-01, time/batch = 0.6538s	
1016/29850 (epoch 1.702), train_loss = 1.92568590, grad/param norm = 2.2903e-01, time/batch = 0.6600s	
1017/29850 (epoch 1.704), train_loss = 2.03566161, grad/param norm = 2.4083e-01, time/batch = 0.6572s	
1018/29850 (epoch 1.705), train_loss = 2.06720782, grad/param norm = 2.2382e-01, time/batch = 0.6809s	
1019/29850 (epoch 1.707), train_loss = 2.17335122, grad/param norm = 2.6627e-01, time/batch = 0.6622s	
1020/29850 (epoch 1.709), train_loss = 2.16861601, grad/param norm = 2.6856e-01, time/batch = 0.6520s	
1021/29850 (epoch 1.710), train_loss = 2.02462368, grad/param norm = 2.6533e-01, time/batch = 0.6557s	
1022/29850 (epoch 1.712), train_loss = 2.06906567, grad/param norm = 2.2406e-01, time/batch = 0.6530s	
1023/29850 (epoch 1.714), train_loss = 2.06809879, grad/param norm = 2.9363e-01, time/batch = 0.6524s	
1024/29850 (epoch 1.715), train_loss = 2.08710722, grad/param norm = 2.8268e-01, time/batch = 0.6534s	
1025/29850 (epoch 1.717), train_loss = 2.02522236, grad/param norm = 2.6252e-01, time/batch = 0.6592s	
1026/29850 (epoch 1.719), train_loss = 2.14109655, grad/param norm = 3.0788e-01, time/batch = 0.6580s	
1027/29850 (epoch 1.720), train_loss = 2.09828898, grad/param norm = 3.1294e-01, time/batch = 0.6568s	
1028/29850 (epoch 1.722), train_loss = 1.95709775, grad/param norm = 2.2042e-01, time/batch = 0.6702s	
1029/29850 (epoch 1.724), train_loss = 1.97668729, grad/param norm = 2.4318e-01, time/batch = 0.6774s	
1030/29850 (epoch 1.725), train_loss = 1.91510477, grad/param norm = 2.2736e-01, time/batch = 0.6527s	
1031/29850 (epoch 1.727), train_loss = 2.02972502, grad/param norm = 2.9566e-01, time/batch = 0.6536s	
1032/29850 (epoch 1.729), train_loss = 1.83554377, grad/param norm = 3.0250e-01, time/batch = 0.6546s	
1033/29850 (epoch 1.730), train_loss = 2.00985466, grad/param norm = 2.7709e-01, time/batch = 0.6538s	
1034/29850 (epoch 1.732), train_loss = 1.86326029, grad/param norm = 2.6482e-01, time/batch = 0.6578s	
1035/29850 (epoch 1.734), train_loss = 2.21791951, grad/param norm = 2.8385e-01, time/batch = 0.6542s	
1036/29850 (epoch 1.735), train_loss = 2.13373378, grad/param norm = 2.6414e-01, time/batch = 0.6550s	
1037/29850 (epoch 1.737), train_loss = 1.94543192, grad/param norm = 2.5282e-01, time/batch = 0.6537s	
1038/29850 (epoch 1.739), train_loss = 2.08964629, grad/param norm = 2.5240e-01, time/batch = 0.6521s	
1039/29850 (epoch 1.740), train_loss = 1.98758274, grad/param norm = 2.6424e-01, time/batch = 0.6548s	
1040/29850 (epoch 1.742), train_loss = 2.00582544, grad/param norm = 2.7597e-01, time/batch = 0.6582s	
1041/29850 (epoch 1.744), train_loss = 2.02530577, grad/param norm = 2.4732e-01, time/batch = 0.6579s	
1042/29850 (epoch 1.745), train_loss = 1.99292647, grad/param norm = 2.1820e-01, time/batch = 0.6555s	
1043/29850 (epoch 1.747), train_loss = 2.01205893, grad/param norm = 2.5768e-01, time/batch = 0.6560s	
1044/29850 (epoch 1.749), train_loss = 1.92305972, grad/param norm = 2.4215e-01, time/batch = 0.6551s	
1045/29850 (epoch 1.750), train_loss = 2.13489789, grad/param norm = 3.0109e-01, time/batch = 0.6620s	
1046/29850 (epoch 1.752), train_loss = 2.03997483, grad/param norm = 2.8503e-01, time/batch = 0.6628s	
1047/29850 (epoch 1.754), train_loss = 1.95618362, grad/param norm = 2.5322e-01, time/batch = 0.6659s	
1048/29850 (epoch 1.755), train_loss = 2.04864304, grad/param norm = 2.3849e-01, time/batch = 0.6623s	
1049/29850 (epoch 1.757), train_loss = 1.92455559, grad/param norm = 2.4776e-01, time/batch = 0.6635s	
1050/29850 (epoch 1.759), train_loss = 2.12273217, grad/param norm = 2.6350e-01, time/batch = 0.6553s	
1051/29850 (epoch 1.760), train_loss = 1.88658734, grad/param norm = 2.5962e-01, time/batch = 0.6721s	
1052/29850 (epoch 1.762), train_loss = 1.96597131, grad/param norm = 2.2934e-01, time/batch = 0.6794s	
1053/29850 (epoch 1.764), train_loss = 2.09961796, grad/param norm = 2.5531e-01, time/batch = 0.6496s	
1054/29850 (epoch 1.765), train_loss = 2.04607680, grad/param norm = 2.6152e-01, time/batch = 0.6522s	
1055/29850 (epoch 1.767), train_loss = 2.12153779, grad/param norm = 2.4036e-01, time/batch = 0.6504s	
1056/29850 (epoch 1.769), train_loss = 1.92889768, grad/param norm = 2.1563e-01, time/batch = 0.6512s	
1057/29850 (epoch 1.771), train_loss = 2.05535870, grad/param norm = 2.5172e-01, time/batch = 0.6583s	
1058/29850 (epoch 1.772), train_loss = 2.16262161, grad/param norm = 2.3916e-01, time/batch = 0.6545s	
1059/29850 (epoch 1.774), train_loss = 1.98091828, grad/param norm = 2.4070e-01, time/batch = 0.6576s	
1060/29850 (epoch 1.776), train_loss = 2.01589952, grad/param norm = 2.6085e-01, time/batch = 0.6549s	
1061/29850 (epoch 1.777), train_loss = 2.12676559, grad/param norm = 3.1146e-01, time/batch = 0.6650s	
1062/29850 (epoch 1.779), train_loss = 1.92329987, grad/param norm = 2.9725e-01, time/batch = 0.6590s	
1063/29850 (epoch 1.781), train_loss = 1.96970189, grad/param norm = 2.4047e-01, time/batch = 0.6535s	
1064/29850 (epoch 1.782), train_loss = 1.95440154, grad/param norm = 2.1276e-01, time/batch = 0.6628s	
1065/29850 (epoch 1.784), train_loss = 1.97933914, grad/param norm = 2.5464e-01, time/batch = 0.6839s	
1066/29850 (epoch 1.786), train_loss = 2.00445187, grad/param norm = 3.0666e-01, time/batch = 0.6595s	
1067/29850 (epoch 1.787), train_loss = 2.01782886, grad/param norm = 2.9136e-01, time/batch = 0.6492s	
1068/29850 (epoch 1.789), train_loss = 1.94896725, grad/param norm = 2.3901e-01, time/batch = 0.6526s	
1069/29850 (epoch 1.791), train_loss = 2.12537791, grad/param norm = 2.6653e-01, time/batch = 0.6548s	
1070/29850 (epoch 1.792), train_loss = 2.01387225, grad/param norm = 2.9861e-01, time/batch = 0.6602s	
1071/29850 (epoch 1.794), train_loss = 2.04633790, grad/param norm = 2.8984e-01, time/batch = 0.6830s	
1072/29850 (epoch 1.796), train_loss = 1.95604118, grad/param norm = 2.7110e-01, time/batch = 0.6830s	
1073/29850 (epoch 1.797), train_loss = 1.97055598, grad/param norm = 2.1468e-01, time/batch = 0.6745s	
1074/29850 (epoch 1.799), train_loss = 1.96245359, grad/param norm = 2.2561e-01, time/batch = 0.6604s	
1075/29850 (epoch 1.801), train_loss = 2.10340334, grad/param norm = 2.3469e-01, time/batch = 0.6601s	
1076/29850 (epoch 1.802), train_loss = 1.92311788, grad/param norm = 2.2636e-01, time/batch = 0.6529s	
1077/29850 (epoch 1.804), train_loss = 2.11130265, grad/param norm = 2.6713e-01, time/batch = 0.6589s	
1078/29850 (epoch 1.806), train_loss = 2.11272524, grad/param norm = 2.4579e-01, time/batch = 0.6518s	
1079/29850 (epoch 1.807), train_loss = 1.88744554, grad/param norm = 2.3802e-01, time/batch = 0.6538s	
1080/29850 (epoch 1.809), train_loss = 2.10176768, grad/param norm = 3.3260e-01, time/batch = 0.6554s	
1081/29850 (epoch 1.811), train_loss = 2.11931375, grad/param norm = 3.1510e-01, time/batch = 0.6555s	
1082/29850 (epoch 1.812), train_loss = 2.00773192, grad/param norm = 2.4946e-01, time/batch = 0.6653s	
1083/29850 (epoch 1.814), train_loss = 2.04295163, grad/param norm = 2.4466e-01, time/batch = 0.6748s	
1084/29850 (epoch 1.816), train_loss = 2.04158650, grad/param norm = 2.2916e-01, time/batch = 0.6685s	
1085/29850 (epoch 1.817), train_loss = 2.09968069, grad/param norm = 2.4882e-01, time/batch = 0.6699s	
1086/29850 (epoch 1.819), train_loss = 2.05128210, grad/param norm = 2.2577e-01, time/batch = 0.6870s	
1087/29850 (epoch 1.821), train_loss = 2.11879506, grad/param norm = 2.4118e-01, time/batch = 0.6700s	
1088/29850 (epoch 1.822), train_loss = 1.89632057, grad/param norm = 2.1008e-01, time/batch = 0.6572s	
1089/29850 (epoch 1.824), train_loss = 2.07761628, grad/param norm = 2.3549e-01, time/batch = 0.6586s	
1090/29850 (epoch 1.826), train_loss = 2.03038077, grad/param norm = 2.5533e-01, time/batch = 0.6596s	
1091/29850 (epoch 1.827), train_loss = 1.97181556, grad/param norm = 2.2971e-01, time/batch = 0.6572s	
1092/29850 (epoch 1.829), train_loss = 2.04122384, grad/param norm = 2.3613e-01, time/batch = 0.6553s	
1093/29850 (epoch 1.831), train_loss = 2.04449971, grad/param norm = 2.6714e-01, time/batch = 0.6498s	
1094/29850 (epoch 1.832), train_loss = 1.91100184, grad/param norm = 2.2925e-01, time/batch = 0.6531s	
1095/29850 (epoch 1.834), train_loss = 1.89539009, grad/param norm = 2.3323e-01, time/batch = 0.6547s	
1096/29850 (epoch 1.836), train_loss = 1.95757963, grad/param norm = 2.4946e-01, time/batch = 0.6735s	
1097/29850 (epoch 1.838), train_loss = 2.05884455, grad/param norm = 2.6279e-01, time/batch = 0.6747s	
1098/29850 (epoch 1.839), train_loss = 2.04728240, grad/param norm = 3.0272e-01, time/batch = 0.6537s	
1099/29850 (epoch 1.841), train_loss = 2.06665412, grad/param norm = 2.8274e-01, time/batch = 0.6565s	
1100/29850 (epoch 1.843), train_loss = 2.05528050, grad/param norm = 2.4048e-01, time/batch = 0.6705s	
1101/29850 (epoch 1.844), train_loss = 2.03135972, grad/param norm = 2.3271e-01, time/batch = 0.6665s	
1102/29850 (epoch 1.846), train_loss = 2.12627443, grad/param norm = 2.4868e-01, time/batch = 0.6714s	
1103/29850 (epoch 1.848), train_loss = 2.09303632, grad/param norm = 2.4945e-01, time/batch = 0.6689s	
1104/29850 (epoch 1.849), train_loss = 1.92221092, grad/param norm = 2.8269e-01, time/batch = 0.6746s	
1105/29850 (epoch 1.851), train_loss = 2.04320353, grad/param norm = 2.3575e-01, time/batch = 0.6533s	
1106/29850 (epoch 1.853), train_loss = 1.94064416, grad/param norm = 2.6090e-01, time/batch = 0.6625s	
1107/29850 (epoch 1.854), train_loss = 2.00687022, grad/param norm = 3.0026e-01, time/batch = 0.6811s	
1108/29850 (epoch 1.856), train_loss = 1.98552822, grad/param norm = 3.4205e-01, time/batch = 0.6632s	
1109/29850 (epoch 1.858), train_loss = 1.99385698, grad/param norm = 2.7385e-01, time/batch = 0.6580s	
1110/29850 (epoch 1.859), train_loss = 1.99586425, grad/param norm = 2.5749e-01, time/batch = 0.6608s	
1111/29850 (epoch 1.861), train_loss = 2.13174280, grad/param norm = 2.7112e-01, time/batch = 0.6685s	
1112/29850 (epoch 1.863), train_loss = 2.08417739, grad/param norm = 2.3028e-01, time/batch = 0.6555s	
1113/29850 (epoch 1.864), train_loss = 1.99066698, grad/param norm = 2.3700e-01, time/batch = 0.6508s	
1114/29850 (epoch 1.866), train_loss = 1.93045098, grad/param norm = 2.2975e-01, time/batch = 0.6507s	
1115/29850 (epoch 1.868), train_loss = 2.02666349, grad/param norm = 2.5778e-01, time/batch = 0.6518s	
1116/29850 (epoch 1.869), train_loss = 1.92754415, grad/param norm = 2.4779e-01, time/batch = 0.6507s	
1117/29850 (epoch 1.871), train_loss = 2.07651178, grad/param norm = 3.0277e-01, time/batch = 0.6751s	
1118/29850 (epoch 1.873), train_loss = 2.22460845, grad/param norm = 3.2332e-01, time/batch = 0.6766s	
1119/29850 (epoch 1.874), train_loss = 2.03102994, grad/param norm = 2.7275e-01, time/batch = 0.6548s	
1120/29850 (epoch 1.876), train_loss = 2.14690819, grad/param norm = 2.8861e-01, time/batch = 0.6526s	
1121/29850 (epoch 1.878), train_loss = 1.97547093, grad/param norm = 2.5716e-01, time/batch = 0.6540s	
1122/29850 (epoch 1.879), train_loss = 2.14390394, grad/param norm = 2.3210e-01, time/batch = 0.6558s	
1123/29850 (epoch 1.881), train_loss = 2.09225252, grad/param norm = 2.5280e-01, time/batch = 0.6522s	
1124/29850 (epoch 1.883), train_loss = 2.08717737, grad/param norm = 2.4488e-01, time/batch = 0.6583s	
1125/29850 (epoch 1.884), train_loss = 1.89564493, grad/param norm = 2.5052e-01, time/batch = 0.6527s	
1126/29850 (epoch 1.886), train_loss = 2.16972910, grad/param norm = 2.5417e-01, time/batch = 0.6533s	
1127/29850 (epoch 1.888), train_loss = 1.99074310, grad/param norm = 2.2177e-01, time/batch = 0.6723s	
1128/29850 (epoch 1.889), train_loss = 1.96474634, grad/param norm = 2.5767e-01, time/batch = 0.6810s	
1129/29850 (epoch 1.891), train_loss = 1.96463944, grad/param norm = 2.5844e-01, time/batch = 0.6632s	
1130/29850 (epoch 1.893), train_loss = 1.95097962, grad/param norm = 2.4282e-01, time/batch = 0.6578s	
1131/29850 (epoch 1.894), train_loss = 2.01609023, grad/param norm = 2.2400e-01, time/batch = 0.6585s	
1132/29850 (epoch 1.896), train_loss = 1.97281006, grad/param norm = 2.4816e-01, time/batch = 0.6523s	
1133/29850 (epoch 1.898), train_loss = 2.02028495, grad/param norm = 2.2918e-01, time/batch = 0.6575s	
1134/29850 (epoch 1.899), train_loss = 1.88454859, grad/param norm = 2.9499e-01, time/batch = 0.6516s	
1135/29850 (epoch 1.901), train_loss = 2.31978763, grad/param norm = 3.1871e-01, time/batch = 0.6684s	
1136/29850 (epoch 1.903), train_loss = 2.15694408, grad/param norm = 2.5976e-01, time/batch = 0.6745s	
1137/29850 (epoch 1.905), train_loss = 2.17243849, grad/param norm = 2.4330e-01, time/batch = 0.6770s	
1138/29850 (epoch 1.906), train_loss = 1.87738802, grad/param norm = 2.6910e-01, time/batch = 0.6772s	
1139/29850 (epoch 1.908), train_loss = 2.07846907, grad/param norm = 2.6065e-01, time/batch = 0.6785s	
1140/29850 (epoch 1.910), train_loss = 2.13031369, grad/param norm = 2.5282e-01, time/batch = 0.6744s	
1141/29850 (epoch 1.911), train_loss = 2.06059641, grad/param norm = 2.4166e-01, time/batch = 0.6826s	
1142/29850 (epoch 1.913), train_loss = 1.96777389, grad/param norm = 2.1819e-01, time/batch = 0.6748s	
1143/29850 (epoch 1.915), train_loss = 2.01495041, grad/param norm = 2.2250e-01, time/batch = 0.6805s	
1144/29850 (epoch 1.916), train_loss = 1.89380196, grad/param norm = 2.0820e-01, time/batch = 0.6835s	
1145/29850 (epoch 1.918), train_loss = 1.93077103, grad/param norm = 2.5352e-01, time/batch = 0.6766s	
1146/29850 (epoch 1.920), train_loss = 2.11833711, grad/param norm = 2.7460e-01, time/batch = 0.6531s	
1147/29850 (epoch 1.921), train_loss = 2.06288126, grad/param norm = 2.8038e-01, time/batch = 0.6570s	
1148/29850 (epoch 1.923), train_loss = 2.04663855, grad/param norm = 2.5793e-01, time/batch = 0.6561s	
1149/29850 (epoch 1.925), train_loss = 2.07376320, grad/param norm = 2.2615e-01, time/batch = 0.6757s	
1150/29850 (epoch 1.926), train_loss = 2.11729529, grad/param norm = 2.1178e-01, time/batch = 0.6546s	
1151/29850 (epoch 1.928), train_loss = 2.00925134, grad/param norm = 2.3708e-01, time/batch = 0.6544s	
1152/29850 (epoch 1.930), train_loss = 2.18607141, grad/param norm = 2.5051e-01, time/batch = 0.6537s	
1153/29850 (epoch 1.931), train_loss = 2.09551940, grad/param norm = 2.3078e-01, time/batch = 0.6513s	
1154/29850 (epoch 1.933), train_loss = 2.20790116, grad/param norm = 2.7684e-01, time/batch = 0.6516s	
1155/29850 (epoch 1.935), train_loss = 2.14968828, grad/param norm = 2.6660e-01, time/batch = 0.6552s	
1156/29850 (epoch 1.936), train_loss = 2.10311937, grad/param norm = 2.7853e-01, time/batch = 0.6553s	
1157/29850 (epoch 1.938), train_loss = 1.94458951, grad/param norm = 2.3101e-01, time/batch = 0.6601s	
1158/29850 (epoch 1.940), train_loss = 1.86977928, grad/param norm = 2.2365e-01, time/batch = 0.6591s	
1159/29850 (epoch 1.941), train_loss = 2.05396183, grad/param norm = 2.3823e-01, time/batch = 0.6527s	
1160/29850 (epoch 1.943), train_loss = 2.00556753, grad/param norm = 2.9915e-01, time/batch = 0.6530s	
1161/29850 (epoch 1.945), train_loss = 2.11774546, grad/param norm = 2.7857e-01, time/batch = 0.6853s	
1162/29850 (epoch 1.946), train_loss = 2.00239228, grad/param norm = 3.1118e-01, time/batch = 0.6828s	
1163/29850 (epoch 1.948), train_loss = 1.94289396, grad/param norm = 2.0977e-01, time/batch = 0.6691s	
1164/29850 (epoch 1.950), train_loss = 1.97336461, grad/param norm = 2.2949e-01, time/batch = 0.6595s	
1165/29850 (epoch 1.951), train_loss = 1.89254321, grad/param norm = 2.0573e-01, time/batch = 0.6689s	
1166/29850 (epoch 1.953), train_loss = 2.07631218, grad/param norm = 2.3743e-01, time/batch = 0.6586s	
1167/29850 (epoch 1.955), train_loss = 1.87481327, grad/param norm = 2.2862e-01, time/batch = 0.6563s	
1168/29850 (epoch 1.956), train_loss = 1.99333056, grad/param norm = 2.7704e-01, time/batch = 0.6619s	
1169/29850 (epoch 1.958), train_loss = 1.81421011, grad/param norm = 2.4216e-01, time/batch = 0.6764s	
1170/29850 (epoch 1.960), train_loss = 2.10717256, grad/param norm = 2.2653e-01, time/batch = 0.6691s	
1171/29850 (epoch 1.961), train_loss = 2.02386818, grad/param norm = 2.8307e-01, time/batch = 0.6626s	
1172/29850 (epoch 1.963), train_loss = 1.89517483, grad/param norm = 2.8858e-01, time/batch = 0.6518s	
1173/29850 (epoch 1.965), train_loss = 1.96295747, grad/param norm = 2.2437e-01, time/batch = 0.6588s	
1174/29850 (epoch 1.966), train_loss = 1.92075576, grad/param norm = 2.3106e-01, time/batch = 0.6541s	
1175/29850 (epoch 1.968), train_loss = 1.88123407, grad/param norm = 2.5624e-01, time/batch = 0.6516s	
1176/29850 (epoch 1.970), train_loss = 1.94955467, grad/param norm = 2.4619e-01, time/batch = 0.6554s	
1177/29850 (epoch 1.972), train_loss = 1.86532596, grad/param norm = 3.0644e-01, time/batch = 0.6565s	
1178/29850 (epoch 1.973), train_loss = 2.05773095, grad/param norm = 3.0856e-01, time/batch = 0.6522s	
1179/29850 (epoch 1.975), train_loss = 1.78719959, grad/param norm = 2.2476e-01, time/batch = 0.6591s	
1180/29850 (epoch 1.977), train_loss = 1.85943134, grad/param norm = 2.3851e-01, time/batch = 0.6510s	
1181/29850 (epoch 1.978), train_loss = 1.95335942, grad/param norm = 2.3485e-01, time/batch = 0.6568s	
1182/29850 (epoch 1.980), train_loss = 1.83879068, grad/param norm = 3.1105e-01, time/batch = 0.6561s	
1183/29850 (epoch 1.982), train_loss = 1.86153104, grad/param norm = 3.1252e-01, time/batch = 0.6526s	
1184/29850 (epoch 1.983), train_loss = 2.02039716, grad/param norm = 2.3211e-01, time/batch = 0.6537s	
1185/29850 (epoch 1.985), train_loss = 2.03880552, grad/param norm = 2.5566e-01, time/batch = 0.6534s	
1186/29850 (epoch 1.987), train_loss = 1.83190349, grad/param norm = 2.8916e-01, time/batch = 0.6573s	
1187/29850 (epoch 1.988), train_loss = 1.83414028, grad/param norm = 2.2587e-01, time/batch = 0.6624s	
1188/29850 (epoch 1.990), train_loss = 1.84487262, grad/param norm = 2.4669e-01, time/batch = 0.6623s	
1189/29850 (epoch 1.992), train_loss = 1.92063473, grad/param norm = 2.3501e-01, time/batch = 0.6585s	
1190/29850 (epoch 1.993), train_loss = 2.04244688, grad/param norm = 2.4202e-01, time/batch = 0.6601s	
1191/29850 (epoch 1.995), train_loss = 2.00244498, grad/param norm = 2.5174e-01, time/batch = 0.6575s	
1192/29850 (epoch 1.997), train_loss = 1.99124343, grad/param norm = 2.8519e-01, time/batch = 0.6549s	
1193/29850 (epoch 1.998), train_loss = 2.08584193, grad/param norm = 2.1858e-01, time/batch = 0.6557s	
1194/29850 (epoch 2.000), train_loss = 1.94299880, grad/param norm = 2.3067e-01, time/batch = 0.6566s	
1195/29850 (epoch 2.002), train_loss = 2.12444144, grad/param norm = 2.4782e-01, time/batch = 0.6530s	
1196/29850 (epoch 2.003), train_loss = 1.90707770, grad/param norm = 2.1504e-01, time/batch = 0.6536s	
1197/29850 (epoch 2.005), train_loss = 1.95205436, grad/param norm = 2.3182e-01, time/batch = 0.6539s	
1198/29850 (epoch 2.007), train_loss = 2.00759397, grad/param norm = 2.4486e-01, time/batch = 0.6627s	
1199/29850 (epoch 2.008), train_loss = 2.16627436, grad/param norm = 2.4565e-01, time/batch = 0.6747s	
1200/29850 (epoch 2.010), train_loss = 1.91554447, grad/param norm = 2.7633e-01, time/batch = 0.6802s	
1201/29850 (epoch 2.012), train_loss = 2.09508897, grad/param norm = 2.5181e-01, time/batch = 0.6846s	
1202/29850 (epoch 2.013), train_loss = 2.07367509, grad/param norm = 2.4547e-01, time/batch = 0.6821s	
1203/29850 (epoch 2.015), train_loss = 1.97587316, grad/param norm = 2.5716e-01, time/batch = 0.6827s	
1204/29850 (epoch 2.017), train_loss = 2.15698966, grad/param norm = 2.9475e-01, time/batch = 0.6825s	
1205/29850 (epoch 2.018), train_loss = 2.17738739, grad/param norm = 3.2979e-01, time/batch = 0.6792s	
1206/29850 (epoch 2.020), train_loss = 1.84886317, grad/param norm = 2.5176e-01, time/batch = 0.6693s	
1207/29850 (epoch 2.022), train_loss = 2.06778121, grad/param norm = 3.0656e-01, time/batch = 0.6794s	
1208/29850 (epoch 2.023), train_loss = 1.97701543, grad/param norm = 3.0564e-01, time/batch = 0.6565s	
1209/29850 (epoch 2.025), train_loss = 1.96690011, grad/param norm = 2.3295e-01, time/batch = 0.6603s	
1210/29850 (epoch 2.027), train_loss = 1.90813437, grad/param norm = 2.1771e-01, time/batch = 0.6545s	
1211/29850 (epoch 2.028), train_loss = 1.98186372, grad/param norm = 2.3439e-01, time/batch = 0.6608s	
1212/29850 (epoch 2.030), train_loss = 2.03722154, grad/param norm = 2.3676e-01, time/batch = 0.6579s	
1213/29850 (epoch 2.032), train_loss = 1.87943931, grad/param norm = 2.2397e-01, time/batch = 0.6631s	
1214/29850 (epoch 2.034), train_loss = 2.04034350, grad/param norm = 2.3899e-01, time/batch = 0.6556s	
1215/29850 (epoch 2.035), train_loss = 1.97779087, grad/param norm = 2.1934e-01, time/batch = 0.6721s	
1216/29850 (epoch 2.037), train_loss = 2.02349165, grad/param norm = 2.2426e-01, time/batch = 0.6769s	
1217/29850 (epoch 2.039), train_loss = 1.87633200, grad/param norm = 2.1767e-01, time/batch = 0.6650s	
1218/29850 (epoch 2.040), train_loss = 1.80529857, grad/param norm = 2.1849e-01, time/batch = 0.6685s	
1219/29850 (epoch 2.042), train_loss = 2.00925245, grad/param norm = 2.2996e-01, time/batch = 0.6759s	
1220/29850 (epoch 2.044), train_loss = 1.79071441, grad/param norm = 2.2074e-01, time/batch = 0.6642s	
1221/29850 (epoch 2.045), train_loss = 2.02731160, grad/param norm = 2.1582e-01, time/batch = 0.6710s	
1222/29850 (epoch 2.047), train_loss = 1.85296835, grad/param norm = 2.3328e-01, time/batch = 0.6691s	
1223/29850 (epoch 2.049), train_loss = 1.91443390, grad/param norm = 2.5414e-01, time/batch = 0.6794s	
1224/29850 (epoch 2.050), train_loss = 1.87276612, grad/param norm = 2.3390e-01, time/batch = 0.6615s	
1225/29850 (epoch 2.052), train_loss = 2.18897499, grad/param norm = 2.8224e-01, time/batch = 0.6664s	
1226/29850 (epoch 2.054), train_loss = 2.04980586, grad/param norm = 2.9054e-01, time/batch = 0.6729s	
1227/29850 (epoch 2.055), train_loss = 1.94272037, grad/param norm = 2.5375e-01, time/batch = 0.6616s	
1228/29850 (epoch 2.057), train_loss = 1.88740525, grad/param norm = 2.2335e-01, time/batch = 0.6667s	
1229/29850 (epoch 2.059), train_loss = 1.89877460, grad/param norm = 2.3429e-01, time/batch = 0.6654s	
1230/29850 (epoch 2.060), train_loss = 1.94106436, grad/param norm = 2.6451e-01, time/batch = 0.6643s	
1231/29850 (epoch 2.062), train_loss = 2.01020584, grad/param norm = 2.3627e-01, time/batch = 0.6682s	
1232/29850 (epoch 2.064), train_loss = 1.89713031, grad/param norm = 2.1384e-01, time/batch = 0.6652s	
1233/29850 (epoch 2.065), train_loss = 1.81469016, grad/param norm = 2.4017e-01, time/batch = 0.6751s	
1234/29850 (epoch 2.067), train_loss = 1.95045089, grad/param norm = 2.4227e-01, time/batch = 0.6613s	
1235/29850 (epoch 2.069), train_loss = 1.85279809, grad/param norm = 2.3248e-01, time/batch = 0.6555s	
1236/29850 (epoch 2.070), train_loss = 1.89823081, grad/param norm = 2.4985e-01, time/batch = 0.6546s	
1237/29850 (epoch 2.072), train_loss = 2.06621559, grad/param norm = 3.1126e-01, time/batch = 0.6588s	
1238/29850 (epoch 2.074), train_loss = 1.97656357, grad/param norm = 3.3230e-01, time/batch = 0.6557s	
1239/29850 (epoch 2.075), train_loss = 1.88897795, grad/param norm = 2.4657e-01, time/batch = 0.6568s	
1240/29850 (epoch 2.077), train_loss = 1.82217142, grad/param norm = 2.4463e-01, time/batch = 0.6547s	
1241/29850 (epoch 2.079), train_loss = 2.05618136, grad/param norm = 2.0484e-01, time/batch = 0.6551s	
1242/29850 (epoch 2.080), train_loss = 1.98615800, grad/param norm = 2.5916e-01, time/batch = 0.6574s	
1243/29850 (epoch 2.082), train_loss = 1.88293310, grad/param norm = 2.1672e-01, time/batch = 0.6579s	
1244/29850 (epoch 2.084), train_loss = 1.89886080, grad/param norm = 2.2989e-01, time/batch = 0.6565s	
1245/29850 (epoch 2.085), train_loss = 1.79366516, grad/param norm = 2.4294e-01, time/batch = 0.6548s	
1246/29850 (epoch 2.087), train_loss = 2.01106097, grad/param norm = 2.1215e-01, time/batch = 0.6539s	
1247/29850 (epoch 2.089), train_loss = 2.04711750, grad/param norm = 2.3572e-01, time/batch = 0.6557s	
1248/29850 (epoch 2.090), train_loss = 1.92504925, grad/param norm = 2.2056e-01, time/batch = 0.6543s	
1249/29850 (epoch 2.092), train_loss = 1.83515317, grad/param norm = 2.2810e-01, time/batch = 0.6563s	
1250/29850 (epoch 2.094), train_loss = 1.94338047, grad/param norm = 2.1975e-01, time/batch = 0.6586s	
1251/29850 (epoch 2.095), train_loss = 2.09094920, grad/param norm = 2.4270e-01, time/batch = 0.6729s	
1252/29850 (epoch 2.097), train_loss = 1.82145267, grad/param norm = 2.2204e-01, time/batch = 0.6818s	
1253/29850 (epoch 2.099), train_loss = 1.77666144, grad/param norm = 2.2970e-01, time/batch = 0.6840s	
1254/29850 (epoch 2.101), train_loss = 2.09876665, grad/param norm = 2.9280e-01, time/batch = 0.6650s	
1255/29850 (epoch 2.102), train_loss = 1.86204201, grad/param norm = 2.6417e-01, time/batch = 0.6591s	
1256/29850 (epoch 2.104), train_loss = 1.89576693, grad/param norm = 2.3747e-01, time/batch = 0.6700s	
1257/29850 (epoch 2.106), train_loss = 2.03370782, grad/param norm = 3.0112e-01, time/batch = 0.6620s	
1258/29850 (epoch 2.107), train_loss = 1.93171438, grad/param norm = 2.5318e-01, time/batch = 0.6580s	
1259/29850 (epoch 2.109), train_loss = 1.89060680, grad/param norm = 2.3617e-01, time/batch = 0.6562s	
1260/29850 (epoch 2.111), train_loss = 1.99455914, grad/param norm = 2.6478e-01, time/batch = 0.6584s	
1261/29850 (epoch 2.112), train_loss = 1.86831287, grad/param norm = 2.7311e-01, time/batch = 0.6594s	
1262/29850 (epoch 2.114), train_loss = 2.09965757, grad/param norm = 2.4827e-01, time/batch = 0.6576s	
1263/29850 (epoch 2.116), train_loss = 1.95473743, grad/param norm = 2.6236e-01, time/batch = 0.6586s	
1264/29850 (epoch 2.117), train_loss = 2.01479674, grad/param norm = 2.2633e-01, time/batch = 0.6537s	
1265/29850 (epoch 2.119), train_loss = 1.86121052, grad/param norm = 2.0321e-01, time/batch = 0.6573s	
1266/29850 (epoch 2.121), train_loss = 1.77826010, grad/param norm = 2.0725e-01, time/batch = 0.6600s	
1267/29850 (epoch 2.122), train_loss = 1.86439361, grad/param norm = 2.6089e-01, time/batch = 0.6602s	
1268/29850 (epoch 2.124), train_loss = 1.82012387, grad/param norm = 2.1707e-01, time/batch = 0.6531s	
1269/29850 (epoch 2.126), train_loss = 1.90160302, grad/param norm = 2.2356e-01, time/batch = 0.6588s	
1270/29850 (epoch 2.127), train_loss = 2.15130659, grad/param norm = 2.2186e-01, time/batch = 0.6557s	
1271/29850 (epoch 2.129), train_loss = 1.92510455, grad/param norm = 2.5898e-01, time/batch = 0.6584s	
1272/29850 (epoch 2.131), train_loss = 1.89993049, grad/param norm = 2.3041e-01, time/batch = 0.6553s	
1273/29850 (epoch 2.132), train_loss = 1.94613749, grad/param norm = 2.4261e-01, time/batch = 0.6536s	
1274/29850 (epoch 2.134), train_loss = 1.98713517, grad/param norm = 2.8564e-01, time/batch = 0.6555s	
1275/29850 (epoch 2.136), train_loss = 1.99240857, grad/param norm = 3.0212e-01, time/batch = 0.6536s	
1276/29850 (epoch 2.137), train_loss = 1.90709079, grad/param norm = 2.4230e-01, time/batch = 0.6545s	
1277/29850 (epoch 2.139), train_loss = 1.87263347, grad/param norm = 2.3973e-01, time/batch = 0.6537s	
1278/29850 (epoch 2.141), train_loss = 1.89884014, grad/param norm = 2.3089e-01, time/batch = 0.6523s	
1279/29850 (epoch 2.142), train_loss = 1.97943134, grad/param norm = 2.5451e-01, time/batch = 0.6527s	
1280/29850 (epoch 2.144), train_loss = 2.05246040, grad/param norm = 2.4017e-01, time/batch = 0.6505s	
1281/29850 (epoch 2.146), train_loss = 1.92043022, grad/param norm = 2.4372e-01, time/batch = 0.6552s	
1282/29850 (epoch 2.147), train_loss = 2.03425696, grad/param norm = 2.4268e-01, time/batch = 0.6532s	
1283/29850 (epoch 2.149), train_loss = 2.00071903, grad/param norm = 2.4157e-01, time/batch = 0.6515s	
1284/29850 (epoch 2.151), train_loss = 1.91325238, grad/param norm = 2.5846e-01, time/batch = 0.6541s	
1285/29850 (epoch 2.152), train_loss = 1.91186876, grad/param norm = 2.7209e-01, time/batch = 0.6530s	
1286/29850 (epoch 2.154), train_loss = 1.90888704, grad/param norm = 2.1808e-01, time/batch = 0.6527s	
1287/29850 (epoch 2.156), train_loss = 1.80693829, grad/param norm = 2.3461e-01, time/batch = 0.6550s	
1288/29850 (epoch 2.157), train_loss = 1.96196475, grad/param norm = 1.9282e-01, time/batch = 0.6535s	
1289/29850 (epoch 2.159), train_loss = 1.96610366, grad/param norm = 1.9545e-01, time/batch = 0.6522s	
1290/29850 (epoch 2.161), train_loss = 2.04402667, grad/param norm = 2.4420e-01, time/batch = 0.6564s	
1291/29850 (epoch 2.162), train_loss = 1.97883489, grad/param norm = 2.0961e-01, time/batch = 0.6579s	
1292/29850 (epoch 2.164), train_loss = 1.86367047, grad/param norm = 2.2597e-01, time/batch = 0.6549s	
1293/29850 (epoch 2.166), train_loss = 1.89936845, grad/param norm = 2.2903e-01, time/batch = 0.6570s	
1294/29850 (epoch 2.168), train_loss = 1.78573974, grad/param norm = 2.4393e-01, time/batch = 0.6617s	
1295/29850 (epoch 2.169), train_loss = 2.07926696, grad/param norm = 2.2418e-01, time/batch = 0.6536s	
1296/29850 (epoch 2.171), train_loss = 2.07391890, grad/param norm = 2.3273e-01, time/batch = 0.6583s	
1297/29850 (epoch 2.173), train_loss = 1.93683730, grad/param norm = 2.2648e-01, time/batch = 0.6576s	
1298/29850 (epoch 2.174), train_loss = 2.01747239, grad/param norm = 2.6025e-01, time/batch = 0.6560s	
1299/29850 (epoch 2.176), train_loss = 2.04661514, grad/param norm = 2.7854e-01, time/batch = 0.6593s	
1300/29850 (epoch 2.178), train_loss = 2.01559510, grad/param norm = 2.5261e-01, time/batch = 0.6520s	
1301/29850 (epoch 2.179), train_loss = 1.77235116, grad/param norm = 2.5460e-01, time/batch = 0.6547s	
1302/29850 (epoch 2.181), train_loss = 1.79538936, grad/param norm = 2.3535e-01, time/batch = 0.6546s	
1303/29850 (epoch 2.183), train_loss = 1.82946782, grad/param norm = 2.3669e-01, time/batch = 0.6554s	
1304/29850 (epoch 2.184), train_loss = 1.87808952, grad/param norm = 2.3361e-01, time/batch = 0.6557s	
1305/29850 (epoch 2.186), train_loss = 1.83295029, grad/param norm = 2.2937e-01, time/batch = 0.6630s	
1306/29850 (epoch 2.188), train_loss = 1.91009913, grad/param norm = 2.4872e-01, time/batch = 0.6523s	
1307/29850 (epoch 2.189), train_loss = 2.01210512, grad/param norm = 2.2209e-01, time/batch = 0.6544s	
1308/29850 (epoch 2.191), train_loss = 1.88462843, grad/param norm = 2.2599e-01, time/batch = 0.6515s	
1309/29850 (epoch 2.193), train_loss = 1.74566031, grad/param norm = 1.9960e-01, time/batch = 0.6555s	
1310/29850 (epoch 2.194), train_loss = 2.01449421, grad/param norm = 2.8746e-01, time/batch = 0.6546s	
1311/29850 (epoch 2.196), train_loss = 1.90254980, grad/param norm = 2.4897e-01, time/batch = 0.6586s	
1312/29850 (epoch 2.198), train_loss = 1.88974646, grad/param norm = 1.9163e-01, time/batch = 0.6553s	
1313/29850 (epoch 2.199), train_loss = 2.09039954, grad/param norm = 2.1997e-01, time/batch = 0.6581s	
1314/29850 (epoch 2.201), train_loss = 2.06668406, grad/param norm = 2.6220e-01, time/batch = 0.6511s	
1315/29850 (epoch 2.203), train_loss = 2.04252378, grad/param norm = 2.7502e-01, time/batch = 0.6538s	
1316/29850 (epoch 2.204), train_loss = 1.91966105, grad/param norm = 2.2812e-01, time/batch = 0.6515s	
1317/29850 (epoch 2.206), train_loss = 1.89302646, grad/param norm = 2.3338e-01, time/batch = 0.6538s	
1318/29850 (epoch 2.208), train_loss = 2.13462469, grad/param norm = 2.4026e-01, time/batch = 0.6536s	
1319/29850 (epoch 2.209), train_loss = 1.82211011, grad/param norm = 2.1723e-01, time/batch = 0.6729s	
1320/29850 (epoch 2.211), train_loss = 1.82233110, grad/param norm = 2.3527e-01, time/batch = 0.6674s	
1321/29850 (epoch 2.213), train_loss = 2.05264759, grad/param norm = 2.2433e-01, time/batch = 0.6690s	
1322/29850 (epoch 2.214), train_loss = 1.89750656, grad/param norm = 2.5895e-01, time/batch = 0.6591s	
1323/29850 (epoch 2.216), train_loss = 1.93543263, grad/param norm = 2.4215e-01, time/batch = 0.6516s	
1324/29850 (epoch 2.218), train_loss = 2.01557996, grad/param norm = 2.1967e-01, time/batch = 0.6630s	
1325/29850 (epoch 2.219), train_loss = 2.08976388, grad/param norm = 2.2747e-01, time/batch = 0.6606s	
1326/29850 (epoch 2.221), train_loss = 1.84187743, grad/param norm = 2.0443e-01, time/batch = 0.6537s	
1327/29850 (epoch 2.223), train_loss = 1.99205767, grad/param norm = 2.5134e-01, time/batch = 0.6568s	
1328/29850 (epoch 2.224), train_loss = 1.88346034, grad/param norm = 2.4566e-01, time/batch = 0.6579s	
1329/29850 (epoch 2.226), train_loss = 1.93067257, grad/param norm = 2.1461e-01, time/batch = 0.6577s	
1330/29850 (epoch 2.228), train_loss = 1.83020378, grad/param norm = 1.9357e-01, time/batch = 0.6541s	
1331/29850 (epoch 2.229), train_loss = 1.81480604, grad/param norm = 2.1445e-01, time/batch = 0.6548s	
1332/29850 (epoch 2.231), train_loss = 1.85352413, grad/param norm = 2.2402e-01, time/batch = 0.6581s	
1333/29850 (epoch 2.233), train_loss = 1.88256766, grad/param norm = 2.4697e-01, time/batch = 0.6565s	
1334/29850 (epoch 2.235), train_loss = 1.78950264, grad/param norm = 2.0381e-01, time/batch = 0.6538s	
1335/29850 (epoch 2.236), train_loss = 2.13016058, grad/param norm = 2.5196e-01, time/batch = 0.6514s	
1336/29850 (epoch 2.238), train_loss = 1.80839267, grad/param norm = 2.6725e-01, time/batch = 0.6552s	
1337/29850 (epoch 2.240), train_loss = 1.98968765, grad/param norm = 2.9276e-01, time/batch = 0.6524s	
1338/29850 (epoch 2.241), train_loss = 2.18981257, grad/param norm = 2.6831e-01, time/batch = 0.6501s	
1339/29850 (epoch 2.243), train_loss = 1.87203594, grad/param norm = 2.6742e-01, time/batch = 0.6509s	
1340/29850 (epoch 2.245), train_loss = 1.94752137, grad/param norm = 2.6095e-01, time/batch = 0.6503s	
1341/29850 (epoch 2.246), train_loss = 1.93275516, grad/param norm = 2.3516e-01, time/batch = 0.6535s	
1342/29850 (epoch 2.248), train_loss = 1.92714636, grad/param norm = 2.2966e-01, time/batch = 0.6890s	
1343/29850 (epoch 2.250), train_loss = 2.03826018, grad/param norm = 2.2997e-01, time/batch = 0.6984s	
1344/29850 (epoch 2.251), train_loss = 1.79708813, grad/param norm = 2.1029e-01, time/batch = 0.6909s	
1345/29850 (epoch 2.253), train_loss = 1.95489762, grad/param norm = 2.4269e-01, time/batch = 0.6704s	
1346/29850 (epoch 2.255), train_loss = 1.99281394, grad/param norm = 2.4779e-01, time/batch = 0.6761s	
1347/29850 (epoch 2.256), train_loss = 1.87578461, grad/param norm = 2.2074e-01, time/batch = 0.6934s	
1348/29850 (epoch 2.258), train_loss = 1.85103517, grad/param norm = 2.1450e-01, time/batch = 0.6718s	
1349/29850 (epoch 2.260), train_loss = 1.82444587, grad/param norm = 2.0615e-01, time/batch = 0.6535s	
1350/29850 (epoch 2.261), train_loss = 1.87614257, grad/param norm = 2.4282e-01, time/batch = 0.6566s	
1351/29850 (epoch 2.263), train_loss = 1.82293848, grad/param norm = 2.3162e-01, time/batch = 0.6540s	
1352/29850 (epoch 2.265), train_loss = 1.89302287, grad/param norm = 2.3107e-01, time/batch = 0.6559s	
1353/29850 (epoch 2.266), train_loss = 1.87141924, grad/param norm = 2.5551e-01, time/batch = 0.6527s	
1354/29850 (epoch 2.268), train_loss = 1.88847910, grad/param norm = 2.3776e-01, time/batch = 0.6601s	
1355/29850 (epoch 2.270), train_loss = 1.87047153, grad/param norm = 2.2187e-01, time/batch = 0.6546s	
1356/29850 (epoch 2.271), train_loss = 1.92575722, grad/param norm = 2.3521e-01, time/batch = 0.6523s	
1357/29850 (epoch 2.273), train_loss = 1.93256409, grad/param norm = 2.3860e-01, time/batch = 0.6535s	
1358/29850 (epoch 2.275), train_loss = 1.88661857, grad/param norm = 2.4630e-01, time/batch = 0.6601s	
1359/29850 (epoch 2.276), train_loss = 1.82469776, grad/param norm = 2.3065e-01, time/batch = 0.6540s	
1360/29850 (epoch 2.278), train_loss = 1.79361186, grad/param norm = 2.0114e-01, time/batch = 0.6591s	
1361/29850 (epoch 2.280), train_loss = 1.87209728, grad/param norm = 2.1785e-01, time/batch = 0.6559s	
1362/29850 (epoch 2.281), train_loss = 1.79157237, grad/param norm = 2.2400e-01, time/batch = 0.6561s	
1363/29850 (epoch 2.283), train_loss = 1.95128078, grad/param norm = 2.2375e-01, time/batch = 0.6719s	
1364/29850 (epoch 2.285), train_loss = 1.92449465, grad/param norm = 2.3219e-01, time/batch = 0.6754s	
1365/29850 (epoch 2.286), train_loss = 1.87478828, grad/param norm = 2.1646e-01, time/batch = 0.6826s	
1366/29850 (epoch 2.288), train_loss = 2.04443276, grad/param norm = 2.7884e-01, time/batch = 0.6827s	
1367/29850 (epoch 2.290), train_loss = 1.82829721, grad/param norm = 2.4987e-01, time/batch = 0.6827s	
1368/29850 (epoch 2.291), train_loss = 2.09876725, grad/param norm = 2.1380e-01, time/batch = 0.6797s	
1369/29850 (epoch 2.293), train_loss = 2.01427367, grad/param norm = 2.2358e-01, time/batch = 0.6680s	
1370/29850 (epoch 2.295), train_loss = 2.00782000, grad/param norm = 2.2583e-01, time/batch = 0.6677s	
1371/29850 (epoch 2.296), train_loss = 1.78536464, grad/param norm = 2.0455e-01, time/batch = 0.6610s	
1372/29850 (epoch 2.298), train_loss = 1.68105949, grad/param norm = 1.9979e-01, time/batch = 0.6560s	
1373/29850 (epoch 2.300), train_loss = 1.82208538, grad/param norm = 2.2128e-01, time/batch = 0.6573s	
1374/29850 (epoch 2.302), train_loss = 1.76565637, grad/param norm = 2.0973e-01, time/batch = 0.6563s	
1375/29850 (epoch 2.303), train_loss = 1.91679481, grad/param norm = 2.5145e-01, time/batch = 0.6556s	
1376/29850 (epoch 2.305), train_loss = 1.84598117, grad/param norm = 2.2367e-01, time/batch = 0.6558s	
1377/29850 (epoch 2.307), train_loss = 1.98019354, grad/param norm = 2.5405e-01, time/batch = 0.6605s	
1378/29850 (epoch 2.308), train_loss = 1.95361035, grad/param norm = 2.2252e-01, time/batch = 0.6578s	
1379/29850 (epoch 2.310), train_loss = 1.99848682, grad/param norm = 2.1788e-01, time/batch = 0.6556s	
1380/29850 (epoch 2.312), train_loss = 1.88339234, grad/param norm = 2.2980e-01, time/batch = 0.6547s	
1381/29850 (epoch 2.313), train_loss = 1.91161724, grad/param norm = 2.1907e-01, time/batch = 0.6542s	
1382/29850 (epoch 2.315), train_loss = 1.94214025, grad/param norm = 2.5436e-01, time/batch = 0.6551s	
1383/29850 (epoch 2.317), train_loss = 2.03405870, grad/param norm = 2.3415e-01, time/batch = 0.6506s	
1384/29850 (epoch 2.318), train_loss = 1.91619835, grad/param norm = 2.5715e-01, time/batch = 0.6519s	
1385/29850 (epoch 2.320), train_loss = 1.70635443, grad/param norm = 2.3930e-01, time/batch = 0.6568s	
1386/29850 (epoch 2.322), train_loss = 1.93432113, grad/param norm = 2.0701e-01, time/batch = 0.6555s	
1387/29850 (epoch 2.323), train_loss = 1.89398416, grad/param norm = 2.4447e-01, time/batch = 0.6536s	
1388/29850 (epoch 2.325), train_loss = 1.87697751, grad/param norm = 2.1821e-01, time/batch = 0.6606s	
1389/29850 (epoch 2.327), train_loss = 2.06873964, grad/param norm = 2.4331e-01, time/batch = 0.6524s	
1390/29850 (epoch 2.328), train_loss = 2.12091226, grad/param norm = 2.4606e-01, time/batch = 0.6583s	
1391/29850 (epoch 2.330), train_loss = 1.86761911, grad/param norm = 2.2880e-01, time/batch = 0.6575s	
1392/29850 (epoch 2.332), train_loss = 1.82907408, grad/param norm = 2.1368e-01, time/batch = 0.6604s	
1393/29850 (epoch 2.333), train_loss = 2.01973631, grad/param norm = 2.4286e-01, time/batch = 0.6591s	
1394/29850 (epoch 2.335), train_loss = 1.94485080, grad/param norm = 2.1738e-01, time/batch = 0.6587s	
1395/29850 (epoch 2.337), train_loss = 1.92913412, grad/param norm = 2.3602e-01, time/batch = 0.6558s	
1396/29850 (epoch 2.338), train_loss = 1.88096254, grad/param norm = 2.2193e-01, time/batch = 0.6565s	
1397/29850 (epoch 2.340), train_loss = 1.71408427, grad/param norm = 2.2110e-01, time/batch = 0.6557s	
1398/29850 (epoch 2.342), train_loss = 1.98306833, grad/param norm = 2.8963e-01, time/batch = 0.6560s	
1399/29850 (epoch 2.343), train_loss = 2.01076597, grad/param norm = 2.5812e-01, time/batch = 0.6628s	
1400/29850 (epoch 2.345), train_loss = 2.03644056, grad/param norm = 2.2214e-01, time/batch = 0.6644s	
1401/29850 (epoch 2.347), train_loss = 1.93339266, grad/param norm = 2.2790e-01, time/batch = 0.6597s	
1402/29850 (epoch 2.348), train_loss = 2.01223815, grad/param norm = 2.3081e-01, time/batch = 0.6591s	
1403/29850 (epoch 2.350), train_loss = 2.01466591, grad/param norm = 2.5855e-01, time/batch = 0.6652s	
1404/29850 (epoch 2.352), train_loss = 1.96547385, grad/param norm = 2.4564e-01, time/batch = 0.6572s	
1405/29850 (epoch 2.353), train_loss = 1.92020389, grad/param norm = 2.5264e-01, time/batch = 0.6629s	
1406/29850 (epoch 2.355), train_loss = 1.77350686, grad/param norm = 2.9957e-01, time/batch = 0.6546s	
1407/29850 (epoch 2.357), train_loss = 2.05976151, grad/param norm = 2.3993e-01, time/batch = 0.6694s	
1408/29850 (epoch 2.358), train_loss = 1.69982443, grad/param norm = 1.9461e-01, time/batch = 0.6831s	
1409/29850 (epoch 2.360), train_loss = 1.78680408, grad/param norm = 2.0538e-01, time/batch = 0.6736s	
1410/29850 (epoch 2.362), train_loss = 1.85610937, grad/param norm = 2.1362e-01, time/batch = 0.6725s	
1411/29850 (epoch 2.363), train_loss = 1.91437431, grad/param norm = 2.1420e-01, time/batch = 0.6793s	
1412/29850 (epoch 2.365), train_loss = 1.98558256, grad/param norm = 2.1308e-01, time/batch = 0.6659s	
1413/29850 (epoch 2.367), train_loss = 1.86524761, grad/param norm = 2.2389e-01, time/batch = 0.6579s	
1414/29850 (epoch 2.369), train_loss = 1.75184679, grad/param norm = 2.2587e-01, time/batch = 0.6570s	
1415/29850 (epoch 2.370), train_loss = 1.73171700, grad/param norm = 2.4673e-01, time/batch = 0.6650s	
1416/29850 (epoch 2.372), train_loss = 2.02133671, grad/param norm = 2.0777e-01, time/batch = 0.6563s	
1417/29850 (epoch 2.374), train_loss = 1.80698781, grad/param norm = 2.2163e-01, time/batch = 0.6551s	
1418/29850 (epoch 2.375), train_loss = 1.84794573, grad/param norm = 2.3102e-01, time/batch = 0.6587s	
1419/29850 (epoch 2.377), train_loss = 1.90338408, grad/param norm = 2.3062e-01, time/batch = 0.6608s	
1420/29850 (epoch 2.379), train_loss = 1.97374963, grad/param norm = 2.5377e-01, time/batch = 0.6619s	
1421/29850 (epoch 2.380), train_loss = 1.98907235, grad/param norm = 2.5642e-01, time/batch = 0.6566s	
1422/29850 (epoch 2.382), train_loss = 1.99089775, grad/param norm = 2.3060e-01, time/batch = 0.6560s	
1423/29850 (epoch 2.384), train_loss = 1.79612653, grad/param norm = 2.2028e-01, time/batch = 0.6571s	
1424/29850 (epoch 2.385), train_loss = 1.96748228, grad/param norm = 2.1552e-01, time/batch = 0.6579s	
1425/29850 (epoch 2.387), train_loss = 1.89763077, grad/param norm = 2.3324e-01, time/batch = 0.6596s	
1426/29850 (epoch 2.389), train_loss = 2.05724620, grad/param norm = 2.3625e-01, time/batch = 0.6565s	
1427/29850 (epoch 2.390), train_loss = 1.86234942, grad/param norm = 2.2439e-01, time/batch = 0.6663s	
1428/29850 (epoch 2.392), train_loss = 1.84953429, grad/param norm = 2.1414e-01, time/batch = 0.6551s	
1429/29850 (epoch 2.394), train_loss = 1.88219732, grad/param norm = 2.0589e-01, time/batch = 0.6520s	
1430/29850 (epoch 2.395), train_loss = 2.02293579, grad/param norm = 2.1403e-01, time/batch = 0.6526s	
1431/29850 (epoch 2.397), train_loss = 1.92254439, grad/param norm = 2.3409e-01, time/batch = 0.6587s	
1432/29850 (epoch 2.399), train_loss = 1.75830396, grad/param norm = 2.1012e-01, time/batch = 0.6742s	
1433/29850 (epoch 2.400), train_loss = 2.04410624, grad/param norm = 2.6963e-01, time/batch = 0.6839s	
1434/29850 (epoch 2.402), train_loss = 1.95281725, grad/param norm = 2.4515e-01, time/batch = 0.6854s	
1435/29850 (epoch 2.404), train_loss = 2.02600102, grad/param norm = 2.2032e-01, time/batch = 0.6877s	
1436/29850 (epoch 2.405), train_loss = 2.02449495, grad/param norm = 2.2511e-01, time/batch = 0.6882s	
1437/29850 (epoch 2.407), train_loss = 1.94788735, grad/param norm = 2.5680e-01, time/batch = 0.6712s	
1438/29850 (epoch 2.409), train_loss = 2.16266421, grad/param norm = 2.6916e-01, time/batch = 0.6788s	
1439/29850 (epoch 2.410), train_loss = 1.94904973, grad/param norm = 2.2625e-01, time/batch = 0.6769s	
1440/29850 (epoch 2.412), train_loss = 1.84266529, grad/param norm = 2.3471e-01, time/batch = 0.6714s	
1441/29850 (epoch 2.414), train_loss = 1.92752846, grad/param norm = 2.3199e-01, time/batch = 0.6748s	
1442/29850 (epoch 2.415), train_loss = 1.89691115, grad/param norm = 2.2530e-01, time/batch = 0.6766s	
1443/29850 (epoch 2.417), train_loss = 1.96704650, grad/param norm = 2.0547e-01, time/batch = 0.6766s	
1444/29850 (epoch 2.419), train_loss = 1.88463503, grad/param norm = 2.1260e-01, time/batch = 0.6739s	
1445/29850 (epoch 2.420), train_loss = 1.82603134, grad/param norm = 2.0807e-01, time/batch = 0.6658s	
1446/29850 (epoch 2.422), train_loss = 1.86133173, grad/param norm = 2.1358e-01, time/batch = 0.6511s	
1447/29850 (epoch 2.424), train_loss = 1.97326962, grad/param norm = 2.2863e-01, time/batch = 0.6555s	
1448/29850 (epoch 2.425), train_loss = 2.12009255, grad/param norm = 2.1141e-01, time/batch = 0.6583s	
1449/29850 (epoch 2.427), train_loss = 1.79805972, grad/param norm = 2.5579e-01, time/batch = 0.6570s	
1450/29850 (epoch 2.429), train_loss = 1.84570066, grad/param norm = 2.3895e-01, time/batch = 0.6606s	
1451/29850 (epoch 2.430), train_loss = 1.75321210, grad/param norm = 2.4147e-01, time/batch = 0.6685s	
1452/29850 (epoch 2.432), train_loss = 1.95750688, grad/param norm = 2.4174e-01, time/batch = 0.6735s	
1453/29850 (epoch 2.434), train_loss = 1.82713413, grad/param norm = 2.2125e-01, time/batch = 0.6581s	
1454/29850 (epoch 2.436), train_loss = 1.92924307, grad/param norm = 2.3592e-01, time/batch = 0.6532s	
1455/29850 (epoch 2.437), train_loss = 1.79956529, grad/param norm = 2.2143e-01, time/batch = 0.6515s	
1456/29850 (epoch 2.439), train_loss = 1.92396302, grad/param norm = 2.4375e-01, time/batch = 0.6561s	
1457/29850 (epoch 2.441), train_loss = 1.90056438, grad/param norm = 2.1518e-01, time/batch = 0.6578s	
1458/29850 (epoch 2.442), train_loss = 1.98284392, grad/param norm = 2.2573e-01, time/batch = 0.6669s	
1459/29850 (epoch 2.444), train_loss = 1.86296134, grad/param norm = 1.9904e-01, time/batch = 0.6534s	
1460/29850 (epoch 2.446), train_loss = 1.89385777, grad/param norm = 2.2691e-01, time/batch = 0.6568s	
1461/29850 (epoch 2.447), train_loss = 1.99803055, grad/param norm = 2.4289e-01, time/batch = 0.6579s	
1462/29850 (epoch 2.449), train_loss = 2.08062133, grad/param norm = 2.5409e-01, time/batch = 0.6601s	
1463/29850 (epoch 2.451), train_loss = 1.89278406, grad/param norm = 2.1343e-01, time/batch = 0.6562s	
1464/29850 (epoch 2.452), train_loss = 1.83530605, grad/param norm = 2.2069e-01, time/batch = 0.6610s	
1465/29850 (epoch 2.454), train_loss = 1.81648601, grad/param norm = 2.3993e-01, time/batch = 0.6559s	
1466/29850 (epoch 2.456), train_loss = 1.85696924, grad/param norm = 2.2484e-01, time/batch = 0.6506s	
1467/29850 (epoch 2.457), train_loss = 2.12156780, grad/param norm = 2.5848e-01, time/batch = 0.6520s	
1468/29850 (epoch 2.459), train_loss = 2.07373991, grad/param norm = 2.5554e-01, time/batch = 0.6531s	
1469/29850 (epoch 2.461), train_loss = 2.05282771, grad/param norm = 2.4513e-01, time/batch = 0.6527s	
1470/29850 (epoch 2.462), train_loss = 1.90560118, grad/param norm = 2.2397e-01, time/batch = 0.6537s	
1471/29850 (epoch 2.464), train_loss = 1.86716239, grad/param norm = 1.9418e-01, time/batch = 0.6565s	
1472/29850 (epoch 2.466), train_loss = 1.82261062, grad/param norm = 2.0678e-01, time/batch = 0.6532s	
1473/29850 (epoch 2.467), train_loss = 1.90237080, grad/param norm = 2.4722e-01, time/batch = 0.6562s	
1474/29850 (epoch 2.469), train_loss = 1.92640889, grad/param norm = 2.1675e-01, time/batch = 0.6519s	
1475/29850 (epoch 2.471), train_loss = 1.98540076, grad/param norm = 2.1900e-01, time/batch = 0.6539s	
1476/29850 (epoch 2.472), train_loss = 1.80186633, grad/param norm = 1.9225e-01, time/batch = 0.6551s	
1477/29850 (epoch 2.474), train_loss = 2.05209812, grad/param norm = 2.3790e-01, time/batch = 0.6596s	
1478/29850 (epoch 2.476), train_loss = 1.94507873, grad/param norm = 2.3958e-01, time/batch = 0.6602s	
1479/29850 (epoch 2.477), train_loss = 1.99979095, grad/param norm = 1.9822e-01, time/batch = 0.6627s	
1480/29850 (epoch 2.479), train_loss = 1.96501158, grad/param norm = 2.2225e-01, time/batch = 0.6639s	
1481/29850 (epoch 2.481), train_loss = 2.06950778, grad/param norm = 2.5649e-01, time/batch = 0.6551s	
1482/29850 (epoch 2.482), train_loss = 1.81159416, grad/param norm = 2.2569e-01, time/batch = 0.6601s	
1483/29850 (epoch 2.484), train_loss = 1.91802865, grad/param norm = 2.3116e-01, time/batch = 0.6574s	
1484/29850 (epoch 2.486), train_loss = 1.84971005, grad/param norm = 2.1045e-01, time/batch = 0.6539s	
1485/29850 (epoch 2.487), train_loss = 1.74158262, grad/param norm = 2.1596e-01, time/batch = 0.6600s	
1486/29850 (epoch 2.489), train_loss = 1.84025596, grad/param norm = 2.1232e-01, time/batch = 0.6591s	
1487/29850 (epoch 2.491), train_loss = 1.77651486, grad/param norm = 2.0329e-01, time/batch = 0.6627s	
1488/29850 (epoch 2.492), train_loss = 2.00307562, grad/param norm = 2.0537e-01, time/batch = 0.6633s	
1489/29850 (epoch 2.494), train_loss = 1.98891834, grad/param norm = 2.0289e-01, time/batch = 0.6598s	
1490/29850 (epoch 2.496), train_loss = 2.06279976, grad/param norm = 2.3371e-01, time/batch = 0.6577s	
1491/29850 (epoch 2.497), train_loss = 1.85862578, grad/param norm = 2.6168e-01, time/batch = 0.6609s	
1492/29850 (epoch 2.499), train_loss = 1.90103172, grad/param norm = 2.0938e-01, time/batch = 0.6605s	
1493/29850 (epoch 2.501), train_loss = 1.79711998, grad/param norm = 2.0527e-01, time/batch = 0.6654s	
1494/29850 (epoch 2.503), train_loss = 1.88897596, grad/param norm = 2.2088e-01, time/batch = 0.6630s	
1495/29850 (epoch 2.504), train_loss = 1.98559010, grad/param norm = 1.9524e-01, time/batch = 0.6665s	
1496/29850 (epoch 2.506), train_loss = 2.04744145, grad/param norm = 2.1259e-01, time/batch = 0.6574s	
1497/29850 (epoch 2.508), train_loss = 1.92921012, grad/param norm = 2.1949e-01, time/batch = 0.6565s	
1498/29850 (epoch 2.509), train_loss = 1.72691163, grad/param norm = 2.3162e-01, time/batch = 0.6582s	
1499/29850 (epoch 2.511), train_loss = 1.87291544, grad/param norm = 2.2401e-01, time/batch = 0.6698s	
1500/29850 (epoch 2.513), train_loss = 1.96815080, grad/param norm = 2.2372e-01, time/batch = 0.6842s	
1501/29850 (epoch 2.514), train_loss = 1.73563211, grad/param norm = 2.1059e-01, time/batch = 0.6686s	
1502/29850 (epoch 2.516), train_loss = 1.77855283, grad/param norm = 2.2791e-01, time/batch = 0.6575s	
1503/29850 (epoch 2.518), train_loss = 1.79594204, grad/param norm = 1.9607e-01, time/batch = 0.6639s	
1504/29850 (epoch 2.519), train_loss = 1.79680134, grad/param norm = 2.0870e-01, time/batch = 0.6572s	
1505/29850 (epoch 2.521), train_loss = 1.83467221, grad/param norm = 2.0687e-01, time/batch = 0.6523s	
1506/29850 (epoch 2.523), train_loss = 1.72419286, grad/param norm = 2.0712e-01, time/batch = 0.6596s	
1507/29850 (epoch 2.524), train_loss = 1.90552757, grad/param norm = 2.2847e-01, time/batch = 0.6536s	
1508/29850 (epoch 2.526), train_loss = 1.96510838, grad/param norm = 2.4599e-01, time/batch = 0.6578s	
1509/29850 (epoch 2.528), train_loss = 1.97219254, grad/param norm = 2.5107e-01, time/batch = 0.6517s	
1510/29850 (epoch 2.529), train_loss = 1.97853647, grad/param norm = 2.3293e-01, time/batch = 0.6521s	
1511/29850 (epoch 2.531), train_loss = 1.95533995, grad/param norm = 2.2641e-01, time/batch = 0.6549s	
1512/29850 (epoch 2.533), train_loss = 1.78077826, grad/param norm = 2.0612e-01, time/batch = 0.6527s	
1513/29850 (epoch 2.534), train_loss = 1.81462203, grad/param norm = 2.2964e-01, time/batch = 0.6528s	
1514/29850 (epoch 2.536), train_loss = 1.96515055, grad/param norm = 2.1192e-01, time/batch = 0.6524s	
1515/29850 (epoch 2.538), train_loss = 1.88088589, grad/param norm = 2.0263e-01, time/batch = 0.6537s	
1516/29850 (epoch 2.539), train_loss = 1.89770334, grad/param norm = 2.1594e-01, time/batch = 0.6616s	
1517/29850 (epoch 2.541), train_loss = 1.75636023, grad/param norm = 2.1210e-01, time/batch = 0.6591s	
1518/29850 (epoch 2.543), train_loss = 1.80299121, grad/param norm = 2.1109e-01, time/batch = 0.6622s	
1519/29850 (epoch 2.544), train_loss = 1.86488482, grad/param norm = 2.4020e-01, time/batch = 0.6737s	
1520/29850 (epoch 2.546), train_loss = 1.95525574, grad/param norm = 2.3378e-01, time/batch = 0.6634s	
1521/29850 (epoch 2.548), train_loss = 1.78769706, grad/param norm = 2.3039e-01, time/batch = 0.6559s	
1522/29850 (epoch 2.549), train_loss = 1.90989291, grad/param norm = 1.9335e-01, time/batch = 0.6683s	
1523/29850 (epoch 2.551), train_loss = 1.82285704, grad/param norm = 2.0244e-01, time/batch = 0.6792s	
1524/29850 (epoch 2.553), train_loss = 1.92743722, grad/param norm = 2.2284e-01, time/batch = 0.6840s	
1525/29850 (epoch 2.554), train_loss = 1.66619508, grad/param norm = 2.0587e-01, time/batch = 0.6630s	
1526/29850 (epoch 2.556), train_loss = 1.87283349, grad/param norm = 2.2516e-01, time/batch = 0.6667s	
1527/29850 (epoch 2.558), train_loss = 1.79540604, grad/param norm = 2.2316e-01, time/batch = 0.6563s	
1528/29850 (epoch 2.559), train_loss = 1.96583348, grad/param norm = 2.1499e-01, time/batch = 0.6586s	
1529/29850 (epoch 2.561), train_loss = 1.97310428, grad/param norm = 2.3311e-01, time/batch = 0.6555s	
1530/29850 (epoch 2.563), train_loss = 1.91667479, grad/param norm = 2.3810e-01, time/batch = 0.6566s	
1531/29850 (epoch 2.564), train_loss = 1.94256810, grad/param norm = 2.2878e-01, time/batch = 0.6952s	
1532/29850 (epoch 2.566), train_loss = 1.78539560, grad/param norm = 2.2269e-01, time/batch = 0.6729s	
1533/29850 (epoch 2.568), train_loss = 1.98033549, grad/param norm = 2.3897e-01, time/batch = 0.6600s	
1534/29850 (epoch 2.570), train_loss = 1.85163126, grad/param norm = 2.1300e-01, time/batch = 0.6557s	
1535/29850 (epoch 2.571), train_loss = 1.94124312, grad/param norm = 2.2144e-01, time/batch = 0.6594s	
1536/29850 (epoch 2.573), train_loss = 1.99513614, grad/param norm = 2.0784e-01, time/batch = 0.6610s	
1537/29850 (epoch 2.575), train_loss = 1.92241847, grad/param norm = 2.2264e-01, time/batch = 0.6661s	
1538/29850 (epoch 2.576), train_loss = 1.96703009, grad/param norm = 2.0353e-01, time/batch = 0.6597s	
1539/29850 (epoch 2.578), train_loss = 1.94810253, grad/param norm = 2.1599e-01, time/batch = 0.6593s	
1540/29850 (epoch 2.580), train_loss = 1.88160186, grad/param norm = 1.9913e-01, time/batch = 0.6631s	
1541/29850 (epoch 2.581), train_loss = 1.89717859, grad/param norm = 2.3158e-01, time/batch = 0.6630s	
1542/29850 (epoch 2.583), train_loss = 1.76768004, grad/param norm = 1.8888e-01, time/batch = 0.6573s	
1543/29850 (epoch 2.585), train_loss = 1.78192314, grad/param norm = 2.0864e-01, time/batch = 0.6579s	
1544/29850 (epoch 2.586), train_loss = 1.83805351, grad/param norm = 2.0972e-01, time/batch = 0.6586s	
1545/29850 (epoch 2.588), train_loss = 1.83673120, grad/param norm = 2.2784e-01, time/batch = 0.6544s	
1546/29850 (epoch 2.590), train_loss = 1.95296681, grad/param norm = 2.1663e-01, time/batch = 0.6552s	
1547/29850 (epoch 2.591), train_loss = 1.79897316, grad/param norm = 2.1823e-01, time/batch = 0.6565s	
1548/29850 (epoch 2.593), train_loss = 1.83052642, grad/param norm = 2.1358e-01, time/batch = 0.6573s	
1549/29850 (epoch 2.595), train_loss = 1.77613355, grad/param norm = 2.1939e-01, time/batch = 0.6628s	
1550/29850 (epoch 2.596), train_loss = 1.79399530, grad/param norm = 2.2322e-01, time/batch = 0.6673s	
1551/29850 (epoch 2.598), train_loss = 1.77570436, grad/param norm = 2.7365e-01, time/batch = 0.6698s	
1552/29850 (epoch 2.600), train_loss = 1.95651635, grad/param norm = 2.3772e-01, time/batch = 0.6625s	
1553/29850 (epoch 2.601), train_loss = 1.76402914, grad/param norm = 1.9593e-01, time/batch = 0.6581s	
1554/29850 (epoch 2.603), train_loss = 1.93803579, grad/param norm = 2.1020e-01, time/batch = 0.6541s	
1555/29850 (epoch 2.605), train_loss = 1.98588871, grad/param norm = 2.2959e-01, time/batch = 0.6559s	
1556/29850 (epoch 2.606), train_loss = 1.73522925, grad/param norm = 2.0498e-01, time/batch = 0.6622s	
1557/29850 (epoch 2.608), train_loss = 1.83723804, grad/param norm = 2.0209e-01, time/batch = 0.6764s	
1558/29850 (epoch 2.610), train_loss = 1.84369197, grad/param norm = 1.9972e-01, time/batch = 0.6611s	
1559/29850 (epoch 2.611), train_loss = 1.62252417, grad/param norm = 1.9811e-01, time/batch = 0.6524s	
1560/29850 (epoch 2.613), train_loss = 1.66793307, grad/param norm = 2.0640e-01, time/batch = 0.6644s	
1561/29850 (epoch 2.615), train_loss = 1.73509142, grad/param norm = 2.2674e-01, time/batch = 0.6664s	
1562/29850 (epoch 2.616), train_loss = 1.93830224, grad/param norm = 2.4899e-01, time/batch = 0.6627s	
1563/29850 (epoch 2.618), train_loss = 1.86114664, grad/param norm = 2.1670e-01, time/batch = 0.6671s	
1564/29850 (epoch 2.620), train_loss = 1.84830439, grad/param norm = 1.9166e-01, time/batch = 0.6654s	
1565/29850 (epoch 2.621), train_loss = 1.85788506, grad/param norm = 2.5595e-01, time/batch = 0.6669s	
1566/29850 (epoch 2.623), train_loss = 1.87350695, grad/param norm = 2.2915e-01, time/batch = 0.6635s	
1567/29850 (epoch 2.625), train_loss = 1.93147473, grad/param norm = 2.3168e-01, time/batch = 0.6617s	
1568/29850 (epoch 2.626), train_loss = 1.95814499, grad/param norm = 2.0561e-01, time/batch = 0.6605s	
1569/29850 (epoch 2.628), train_loss = 1.67533849, grad/param norm = 2.1925e-01, time/batch = 0.6695s	
1570/29850 (epoch 2.630), train_loss = 1.85884611, grad/param norm = 2.2825e-01, time/batch = 0.6646s	
1571/29850 (epoch 2.631), train_loss = 1.75615565, grad/param norm = 2.0464e-01, time/batch = 0.6603s	
1572/29850 (epoch 2.633), train_loss = 1.96715345, grad/param norm = 2.2457e-01, time/batch = 0.6545s	
1573/29850 (epoch 2.635), train_loss = 1.94019735, grad/param norm = 2.4118e-01, time/batch = 0.6529s	
1574/29850 (epoch 2.637), train_loss = 2.01439186, grad/param norm = 2.5214e-01, time/batch = 0.6524s	
1575/29850 (epoch 2.638), train_loss = 1.71464354, grad/param norm = 1.8919e-01, time/batch = 0.6571s	
1576/29850 (epoch 2.640), train_loss = 2.05514316, grad/param norm = 2.1047e-01, time/batch = 0.6533s	
1577/29850 (epoch 2.642), train_loss = 1.84907007, grad/param norm = 2.0938e-01, time/batch = 0.6523s	
1578/29850 (epoch 2.643), train_loss = 1.74930905, grad/param norm = 1.9437e-01, time/batch = 0.6524s	
1579/29850 (epoch 2.645), train_loss = 1.84011146, grad/param norm = 1.9749e-01, time/batch = 0.6527s	
1580/29850 (epoch 2.647), train_loss = 1.94875125, grad/param norm = 2.1408e-01, time/batch = 0.6552s	
1581/29850 (epoch 2.648), train_loss = 1.69884515, grad/param norm = 1.9229e-01, time/batch = 0.6652s	
1582/29850 (epoch 2.650), train_loss = 1.90699686, grad/param norm = 2.2076e-01, time/batch = 0.6626s	
1583/29850 (epoch 2.652), train_loss = 1.81020648, grad/param norm = 2.2477e-01, time/batch = 0.6602s	
1584/29850 (epoch 2.653), train_loss = 1.95192634, grad/param norm = 2.2156e-01, time/batch = 0.6628s	
1585/29850 (epoch 2.655), train_loss = 1.84740421, grad/param norm = 2.2216e-01, time/batch = 0.6624s	
1586/29850 (epoch 2.657), train_loss = 1.77806060, grad/param norm = 2.0115e-01, time/batch = 0.6560s	
1587/29850 (epoch 2.658), train_loss = 1.90366716, grad/param norm = 2.0907e-01, time/batch = 0.6561s	
1588/29850 (epoch 2.660), train_loss = 1.66893797, grad/param norm = 2.1225e-01, time/batch = 0.6619s	
1589/29850 (epoch 2.662), train_loss = 1.88620127, grad/param norm = 2.6029e-01, time/batch = 0.6595s	
1590/29850 (epoch 2.663), train_loss = 1.86163029, grad/param norm = 2.2899e-01, time/batch = 0.6596s	
1591/29850 (epoch 2.665), train_loss = 1.89145741, grad/param norm = 2.1480e-01, time/batch = 0.6576s	
1592/29850 (epoch 2.667), train_loss = 1.92471270, grad/param norm = 2.2232e-01, time/batch = 0.6547s	
1593/29850 (epoch 2.668), train_loss = 1.97124846, grad/param norm = 2.2330e-01, time/batch = 0.6554s	
1594/29850 (epoch 2.670), train_loss = 2.15336187, grad/param norm = 2.3102e-01, time/batch = 0.6521s	
1595/29850 (epoch 2.672), train_loss = 1.88841462, grad/param norm = 2.2712e-01, time/batch = 0.6520s	
1596/29850 (epoch 2.673), train_loss = 1.92825402, grad/param norm = 2.0426e-01, time/batch = 0.6619s	
1597/29850 (epoch 2.675), train_loss = 1.86590231, grad/param norm = 2.0440e-01, time/batch = 0.6585s	
1598/29850 (epoch 2.677), train_loss = 1.90294442, grad/param norm = 2.0854e-01, time/batch = 0.6642s	
1599/29850 (epoch 2.678), train_loss = 1.80054505, grad/param norm = 2.0397e-01, time/batch = 0.6694s	
1600/29850 (epoch 2.680), train_loss = 1.85082629, grad/param norm = 2.1568e-01, time/batch = 0.6625s	
1601/29850 (epoch 2.682), train_loss = 1.85328036, grad/param norm = 2.0012e-01, time/batch = 0.6594s	
1602/29850 (epoch 2.683), train_loss = 2.06970954, grad/param norm = 2.3605e-01, time/batch = 0.6607s	
1603/29850 (epoch 2.685), train_loss = 2.02478659, grad/param norm = 2.1367e-01, time/batch = 0.6553s	
1604/29850 (epoch 2.687), train_loss = 1.94235399, grad/param norm = 2.1540e-01, time/batch = 0.6567s	
1605/29850 (epoch 2.688), train_loss = 1.70216362, grad/param norm = 1.8336e-01, time/batch = 0.6560s	
1606/29850 (epoch 2.690), train_loss = 1.78449407, grad/param norm = 2.2169e-01, time/batch = 0.6568s	
1607/29850 (epoch 2.692), train_loss = 2.11664468, grad/param norm = 2.9464e-01, time/batch = 0.6560s	
1608/29850 (epoch 2.693), train_loss = 1.88815744, grad/param norm = 2.2991e-01, time/batch = 0.6573s	
1609/29850 (epoch 2.695), train_loss = 1.87539713, grad/param norm = 2.0478e-01, time/batch = 0.6576s	
1610/29850 (epoch 2.697), train_loss = 2.00599398, grad/param norm = 2.7830e-01, time/batch = 0.6536s	
1611/29850 (epoch 2.698), train_loss = 1.90586478, grad/param norm = 2.3371e-01, time/batch = 0.6555s	
1612/29850 (epoch 2.700), train_loss = 1.96607909, grad/param norm = 2.3012e-01, time/batch = 0.6625s	
1613/29850 (epoch 2.702), train_loss = 1.75747621, grad/param norm = 2.1349e-01, time/batch = 0.6812s	
1614/29850 (epoch 2.704), train_loss = 1.85998366, grad/param norm = 2.1745e-01, time/batch = 0.6839s	
1615/29850 (epoch 2.705), train_loss = 1.86148894, grad/param norm = 1.9245e-01, time/batch = 0.6725s	
1616/29850 (epoch 2.707), train_loss = 1.97973233, grad/param norm = 2.1152e-01, time/batch = 0.6675s	
1617/29850 (epoch 2.709), train_loss = 2.00246241, grad/param norm = 2.1058e-01, time/batch = 0.6577s	
1618/29850 (epoch 2.710), train_loss = 1.84226201, grad/param norm = 2.2579e-01, time/batch = 0.6530s	
1619/29850 (epoch 2.712), train_loss = 1.84885217, grad/param norm = 1.9937e-01, time/batch = 0.6568s	
1620/29850 (epoch 2.714), train_loss = 1.87524640, grad/param norm = 2.3467e-01, time/batch = 0.6554s	
1621/29850 (epoch 2.715), train_loss = 1.93751971, grad/param norm = 2.3367e-01, time/batch = 0.6564s	
1622/29850 (epoch 2.717), train_loss = 1.81531696, grad/param norm = 2.1172e-01, time/batch = 0.6563s	
1623/29850 (epoch 2.719), train_loss = 1.89929273, grad/param norm = 2.3040e-01, time/batch = 0.6559s	
1624/29850 (epoch 2.720), train_loss = 1.89320492, grad/param norm = 2.2338e-01, time/batch = 0.6552s	
1625/29850 (epoch 2.722), train_loss = 1.78573182, grad/param norm = 1.9301e-01, time/batch = 0.6537s	
1626/29850 (epoch 2.724), train_loss = 1.79719278, grad/param norm = 2.0600e-01, time/batch = 0.6568s	
1627/29850 (epoch 2.725), train_loss = 1.70070546, grad/param norm = 1.9674e-01, time/batch = 0.6714s	
1628/29850 (epoch 2.727), train_loss = 1.83292251, grad/param norm = 2.3321e-01, time/batch = 0.6653s	
1629/29850 (epoch 2.729), train_loss = 1.63485465, grad/param norm = 2.2887e-01, time/batch = 0.6575s	
1630/29850 (epoch 2.730), train_loss = 1.78425193, grad/param norm = 2.1648e-01, time/batch = 0.6496s	
1631/29850 (epoch 2.732), train_loss = 1.69847619, grad/param norm = 1.9359e-01, time/batch = 0.6531s	
1632/29850 (epoch 2.734), train_loss = 2.00577804, grad/param norm = 2.3739e-01, time/batch = 0.6490s	
1633/29850 (epoch 2.735), train_loss = 1.92719086, grad/param norm = 2.0621e-01, time/batch = 0.6533s	
1634/29850 (epoch 2.737), train_loss = 1.72296621, grad/param norm = 2.1017e-01, time/batch = 0.6574s	
1635/29850 (epoch 2.739), train_loss = 1.82836729, grad/param norm = 2.1087e-01, time/batch = 0.6620s	
1636/29850 (epoch 2.740), train_loss = 1.77519458, grad/param norm = 2.4202e-01, time/batch = 0.6542s	
1637/29850 (epoch 2.742), train_loss = 1.78261324, grad/param norm = 2.3572e-01, time/batch = 0.6541s	
1638/29850 (epoch 2.744), train_loss = 1.83256868, grad/param norm = 2.1229e-01, time/batch = 0.6554s	
1639/29850 (epoch 2.745), train_loss = 1.84597100, grad/param norm = 1.9476e-01, time/batch = 0.6542s	
1640/29850 (epoch 2.747), train_loss = 1.77710163, grad/param norm = 2.0710e-01, time/batch = 0.6565s	
1641/29850 (epoch 2.749), train_loss = 1.73898906, grad/param norm = 1.9503e-01, time/batch = 0.6610s	
1642/29850 (epoch 2.750), train_loss = 1.90694063, grad/param norm = 2.4774e-01, time/batch = 0.6575s	
1643/29850 (epoch 2.752), train_loss = 1.84429994, grad/param norm = 2.2220e-01, time/batch = 0.6558s	
1644/29850 (epoch 2.754), train_loss = 1.76912958, grad/param norm = 2.0881e-01, time/batch = 0.6570s	
1645/29850 (epoch 2.755), train_loss = 1.84802336, grad/param norm = 2.0920e-01, time/batch = 0.6543s	
1646/29850 (epoch 2.757), train_loss = 1.73107106, grad/param norm = 2.0545e-01, time/batch = 0.6563s	
1647/29850 (epoch 2.759), train_loss = 1.90477981, grad/param norm = 1.9698e-01, time/batch = 0.6593s	
1648/29850 (epoch 2.760), train_loss = 1.67775422, grad/param norm = 1.9237e-01, time/batch = 0.6687s	
1649/29850 (epoch 2.762), train_loss = 1.73833130, grad/param norm = 1.9249e-01, time/batch = 0.6627s	
1650/29850 (epoch 2.764), train_loss = 1.87885744, grad/param norm = 2.1573e-01, time/batch = 0.6562s	
1651/29850 (epoch 2.765), train_loss = 1.82905730, grad/param norm = 2.2120e-01, time/batch = 0.6586s	
1652/29850 (epoch 2.767), train_loss = 1.91551393, grad/param norm = 2.1124e-01, time/batch = 0.6552s	
1653/29850 (epoch 2.769), train_loss = 1.72320282, grad/param norm = 2.0547e-01, time/batch = 0.6575s	
1654/29850 (epoch 2.771), train_loss = 1.86461582, grad/param norm = 2.2551e-01, time/batch = 0.6572s	
1655/29850 (epoch 2.772), train_loss = 1.95321635, grad/param norm = 1.9777e-01, time/batch = 0.6573s	
1656/29850 (epoch 2.774), train_loss = 1.78227822, grad/param norm = 2.0417e-01, time/batch = 0.6583s	
1657/29850 (epoch 2.776), train_loss = 1.80707920, grad/param norm = 2.3268e-01, time/batch = 0.6550s	
1658/29850 (epoch 2.777), train_loss = 1.92133453, grad/param norm = 2.2062e-01, time/batch = 0.6582s	
1659/29850 (epoch 2.779), train_loss = 1.71128614, grad/param norm = 2.2783e-01, time/batch = 0.6566s	
1660/29850 (epoch 2.781), train_loss = 1.74329217, grad/param norm = 2.0495e-01, time/batch = 0.6520s	
1661/29850 (epoch 2.782), train_loss = 1.76216161, grad/param norm = 1.8898e-01, time/batch = 0.6649s	
1662/29850 (epoch 2.784), train_loss = 1.77936163, grad/param norm = 2.0998e-01, time/batch = 0.6799s	
1663/29850 (epoch 2.786), train_loss = 1.77868135, grad/param norm = 2.3663e-01, time/batch = 0.6833s	
1664/29850 (epoch 2.787), train_loss = 1.80146756, grad/param norm = 2.2436e-01, time/batch = 0.6582s	
1665/29850 (epoch 2.789), train_loss = 1.75911009, grad/param norm = 2.1098e-01, time/batch = 0.6673s	
1666/29850 (epoch 2.791), train_loss = 1.92477864, grad/param norm = 2.3164e-01, time/batch = 0.6686s	
1667/29850 (epoch 2.792), train_loss = 1.86491278, grad/param norm = 2.5326e-01, time/batch = 0.6552s	
1668/29850 (epoch 2.794), train_loss = 1.87201935, grad/param norm = 2.3536e-01, time/batch = 0.6543s	
1669/29850 (epoch 2.796), train_loss = 1.74820896, grad/param norm = 2.2746e-01, time/batch = 0.6560s	
1670/29850 (epoch 2.797), train_loss = 1.81664883, grad/param norm = 1.9383e-01, time/batch = 0.6540s	
1671/29850 (epoch 2.799), train_loss = 1.76150154, grad/param norm = 1.9033e-01, time/batch = 0.6578s	
1672/29850 (epoch 2.801), train_loss = 1.94225716, grad/param norm = 2.1478e-01, time/batch = 0.6545s	
1673/29850 (epoch 2.802), train_loss = 1.72458683, grad/param norm = 2.0428e-01, time/batch = 0.6574s	
1674/29850 (epoch 2.804), train_loss = 1.88965981, grad/param norm = 2.2329e-01, time/batch = 0.6585s	
1675/29850 (epoch 2.806), train_loss = 1.86859712, grad/param norm = 1.8915e-01, time/batch = 0.6529s	
1676/29850 (epoch 2.807), train_loss = 1.68273154, grad/param norm = 1.8921e-01, time/batch = 0.6569s	
1677/29850 (epoch 2.809), train_loss = 1.89259894, grad/param norm = 2.5965e-01, time/batch = 0.6584s	
1678/29850 (epoch 2.811), train_loss = 1.93018520, grad/param norm = 2.3535e-01, time/batch = 0.6572s	
1679/29850 (epoch 2.812), train_loss = 1.82187830, grad/param norm = 2.1335e-01, time/batch = 0.6583s	
1680/29850 (epoch 2.814), train_loss = 1.86044471, grad/param norm = 2.1270e-01, time/batch = 0.6547s	
1681/29850 (epoch 2.816), train_loss = 1.84997024, grad/param norm = 2.0511e-01, time/batch = 0.6596s	
1682/29850 (epoch 2.817), train_loss = 1.89508255, grad/param norm = 2.1940e-01, time/batch = 0.6643s	
1683/29850 (epoch 2.819), train_loss = 1.84366835, grad/param norm = 2.1314e-01, time/batch = 0.6688s	
1684/29850 (epoch 2.821), train_loss = 1.95700234, grad/param norm = 2.2985e-01, time/batch = 0.6667s	
1685/29850 (epoch 2.822), train_loss = 1.72288078, grad/param norm = 2.0556e-01, time/batch = 0.6726s	
1686/29850 (epoch 2.824), train_loss = 1.86181559, grad/param norm = 2.2831e-01, time/batch = 0.6578s	
1687/29850 (epoch 2.826), train_loss = 1.84677612, grad/param norm = 2.2842e-01, time/batch = 0.6670s	
1688/29850 (epoch 2.827), train_loss = 1.77144342, grad/param norm = 2.0180e-01, time/batch = 0.6624s	
1689/29850 (epoch 2.829), train_loss = 1.83120930, grad/param norm = 2.1486e-01, time/batch = 0.6593s	
1690/29850 (epoch 2.831), train_loss = 1.84138749, grad/param norm = 2.4550e-01, time/batch = 0.6575s	
1691/29850 (epoch 2.832), train_loss = 1.72632343, grad/param norm = 2.1500e-01, time/batch = 0.6672s	
1692/29850 (epoch 2.834), train_loss = 1.70862613, grad/param norm = 1.9666e-01, time/batch = 0.6599s	
1693/29850 (epoch 2.836), train_loss = 1.74256048, grad/param norm = 1.9235e-01, time/batch = 0.6663s	
1694/29850 (epoch 2.838), train_loss = 1.89699878, grad/param norm = 2.2847e-01, time/batch = 0.6617s	
1695/29850 (epoch 2.839), train_loss = 1.85105411, grad/param norm = 2.2499e-01, time/batch = 0.6535s	
1696/29850 (epoch 2.841), train_loss = 1.85677673, grad/param norm = 2.1949e-01, time/batch = 0.6566s	
1697/29850 (epoch 2.843), train_loss = 1.84431703, grad/param norm = 2.3125e-01, time/batch = 0.6634s	
1698/29850 (epoch 2.844), train_loss = 1.85037274, grad/param norm = 2.1566e-01, time/batch = 0.6528s	
1699/29850 (epoch 2.846), train_loss = 1.92909784, grad/param norm = 2.2703e-01, time/batch = 0.6542s	
1700/29850 (epoch 2.848), train_loss = 1.91530083, grad/param norm = 2.1905e-01, time/batch = 0.6542s	
1701/29850 (epoch 2.849), train_loss = 1.72323604, grad/param norm = 2.2794e-01, time/batch = 0.6562s	
1702/29850 (epoch 2.851), train_loss = 1.87061340, grad/param norm = 2.1780e-01, time/batch = 0.6546s	
1703/29850 (epoch 2.853), train_loss = 1.77617283, grad/param norm = 2.4614e-01, time/batch = 0.6680s	
1704/29850 (epoch 2.854), train_loss = 1.82549201, grad/param norm = 2.3312e-01, time/batch = 0.6820s	
1705/29850 (epoch 2.856), train_loss = 1.82626188, grad/param norm = 2.4338e-01, time/batch = 0.6843s	
1706/29850 (epoch 2.858), train_loss = 1.80875050, grad/param norm = 2.1490e-01, time/batch = 0.6762s	
1707/29850 (epoch 2.859), train_loss = 1.79855332, grad/param norm = 2.3127e-01, time/batch = 0.6762s	
1708/29850 (epoch 2.861), train_loss = 1.96484034, grad/param norm = 2.3481e-01, time/batch = 0.6799s	
1709/29850 (epoch 2.863), train_loss = 1.89695988, grad/param norm = 2.0427e-01, time/batch = 0.6616s	
1710/29850 (epoch 2.864), train_loss = 1.81716076, grad/param norm = 1.9494e-01, time/batch = 0.6647s	
1711/29850 (epoch 2.866), train_loss = 1.75980568, grad/param norm = 2.0028e-01, time/batch = 0.6716s	
1712/29850 (epoch 2.868), train_loss = 1.86613711, grad/param norm = 2.0352e-01, time/batch = 0.6601s	
1713/29850 (epoch 2.869), train_loss = 1.74358826, grad/param norm = 2.0736e-01, time/batch = 0.6548s	
1714/29850 (epoch 2.871), train_loss = 1.84795405, grad/param norm = 2.3169e-01, time/batch = 0.6587s	
1715/29850 (epoch 2.873), train_loss = 1.98474030, grad/param norm = 2.4260e-01, time/batch = 0.6847s	
1716/29850 (epoch 2.874), train_loss = 1.86694693, grad/param norm = 2.1606e-01, time/batch = 0.6679s	
1717/29850 (epoch 2.876), train_loss = 1.93709286, grad/param norm = 2.4002e-01, time/batch = 0.6665s	
1718/29850 (epoch 2.878), train_loss = 1.78656464, grad/param norm = 2.0349e-01, time/batch = 0.6732s	
1719/29850 (epoch 2.879), train_loss = 1.95039379, grad/param norm = 2.1415e-01, time/batch = 0.6647s	
1720/29850 (epoch 2.881), train_loss = 1.91449611, grad/param norm = 2.1729e-01, time/batch = 0.6546s	
1721/29850 (epoch 2.883), train_loss = 1.90391943, grad/param norm = 2.2669e-01, time/batch = 0.6730s	
1722/29850 (epoch 2.884), train_loss = 1.70010609, grad/param norm = 2.0510e-01, time/batch = 0.6602s	
1723/29850 (epoch 2.886), train_loss = 2.03999083, grad/param norm = 2.2365e-01, time/batch = 0.6586s	
1724/29850 (epoch 2.888), train_loss = 1.79630911, grad/param norm = 2.1021e-01, time/batch = 0.6558s	
1725/29850 (epoch 2.889), train_loss = 1.76168769, grad/param norm = 2.2200e-01, time/batch = 0.6572s	
1726/29850 (epoch 2.891), train_loss = 1.76783461, grad/param norm = 2.0421e-01, time/batch = 0.6532s	
1727/29850 (epoch 2.893), train_loss = 1.74560564, grad/param norm = 2.0008e-01, time/batch = 0.6577s	
1728/29850 (epoch 2.894), train_loss = 1.77933469, grad/param norm = 1.9681e-01, time/batch = 0.6518s	
1729/29850 (epoch 2.896), train_loss = 1.74865991, grad/param norm = 2.2148e-01, time/batch = 0.6565s	
1730/29850 (epoch 2.898), train_loss = 1.88265750, grad/param norm = 2.2722e-01, time/batch = 0.6588s	
1731/29850 (epoch 2.899), train_loss = 1.67625833, grad/param norm = 2.3275e-01, time/batch = 0.6567s	
1732/29850 (epoch 2.901), train_loss = 2.15715991, grad/param norm = 2.4352e-01, time/batch = 0.6582s	
1733/29850 (epoch 2.903), train_loss = 1.93392978, grad/param norm = 2.1979e-01, time/batch = 0.6577s	
1734/29850 (epoch 2.905), train_loss = 1.96733579, grad/param norm = 2.3457e-01, time/batch = 0.6610s	
1735/29850 (epoch 2.906), train_loss = 1.68010328, grad/param norm = 2.2310e-01, time/batch = 0.6579s	
1736/29850 (epoch 2.908), train_loss = 1.94249140, grad/param norm = 2.3814e-01, time/batch = 0.6561s	
1737/29850 (epoch 2.910), train_loss = 1.94004492, grad/param norm = 2.1552e-01, time/batch = 0.6569s	
1738/29850 (epoch 2.911), train_loss = 1.91072024, grad/param norm = 2.2910e-01, time/batch = 0.6535s	
1739/29850 (epoch 2.913), train_loss = 1.80271415, grad/param norm = 1.9933e-01, time/batch = 0.6566s	
1740/29850 (epoch 2.915), train_loss = 1.83287484, grad/param norm = 2.1113e-01, time/batch = 0.6551s	
1741/29850 (epoch 2.916), train_loss = 1.74866275, grad/param norm = 2.0249e-01, time/batch = 0.6538s	
1742/29850 (epoch 2.918), train_loss = 1.74474788, grad/param norm = 2.0018e-01, time/batch = 0.6527s	
1743/29850 (epoch 2.920), train_loss = 1.90574577, grad/param norm = 2.0927e-01, time/batch = 0.6527s	
1744/29850 (epoch 2.921), train_loss = 1.88173708, grad/param norm = 2.2745e-01, time/batch = 0.6519s	
1745/29850 (epoch 2.923), train_loss = 1.88187741, grad/param norm = 2.1929e-01, time/batch = 0.6570s	
1746/29850 (epoch 2.925), train_loss = 1.94249071, grad/param norm = 2.2065e-01, time/batch = 0.6619s	
1747/29850 (epoch 2.926), train_loss = 1.95548934, grad/param norm = 2.0552e-01, time/batch = 0.6558s	
1748/29850 (epoch 2.928), train_loss = 1.81529136, grad/param norm = 2.3031e-01, time/batch = 0.6579s	
1749/29850 (epoch 2.930), train_loss = 1.98237572, grad/param norm = 2.1581e-01, time/batch = 0.6521s	
1750/29850 (epoch 2.931), train_loss = 1.91130996, grad/param norm = 1.9772e-01, time/batch = 0.6551s	
1751/29850 (epoch 2.933), train_loss = 2.01429670, grad/param norm = 2.1663e-01, time/batch = 0.6568s	
1752/29850 (epoch 2.935), train_loss = 1.97955109, grad/param norm = 2.1374e-01, time/batch = 0.6571s	
1753/29850 (epoch 2.936), train_loss = 1.95186619, grad/param norm = 2.3155e-01, time/batch = 0.6515s	
1754/29850 (epoch 2.938), train_loss = 1.74823370, grad/param norm = 1.9654e-01, time/batch = 0.6526s	
1755/29850 (epoch 2.940), train_loss = 1.67042603, grad/param norm = 1.9046e-01, time/batch = 0.6547s	
1756/29850 (epoch 2.941), train_loss = 1.85245138, grad/param norm = 2.1270e-01, time/batch = 0.6524s	
1757/29850 (epoch 2.943), train_loss = 1.80104691, grad/param norm = 2.1209e-01, time/batch = 0.6671s	
1758/29850 (epoch 2.945), train_loss = 1.93097263, grad/param norm = 2.1378e-01, time/batch = 0.6657s	
1759/29850 (epoch 2.946), train_loss = 1.76545430, grad/param norm = 2.4428e-01, time/batch = 0.6619s	
1760/29850 (epoch 2.948), train_loss = 1.75204996, grad/param norm = 1.8497e-01, time/batch = 0.6570s	
1761/29850 (epoch 2.950), train_loss = 1.75328447, grad/param norm = 1.8933e-01, time/batch = 0.6689s	
1762/29850 (epoch 2.951), train_loss = 1.73149513, grad/param norm = 1.8772e-01, time/batch = 0.6858s	
1763/29850 (epoch 2.953), train_loss = 1.89688306, grad/param norm = 2.0961e-01, time/batch = 0.6771s	
1764/29850 (epoch 2.955), train_loss = 1.67415349, grad/param norm = 1.9115e-01, time/batch = 0.6726s	
1765/29850 (epoch 2.956), train_loss = 1.75466858, grad/param norm = 2.2866e-01, time/batch = 0.6740s	
1766/29850 (epoch 2.958), train_loss = 1.60938379, grad/param norm = 1.9018e-01, time/batch = 0.6615s	
1767/29850 (epoch 2.960), train_loss = 1.91840047, grad/param norm = 2.3040e-01, time/batch = 0.6558s	
1768/29850 (epoch 2.961), train_loss = 1.85008261, grad/param norm = 2.4443e-01, time/batch = 0.6523s	
1769/29850 (epoch 2.963), train_loss = 1.66993137, grad/param norm = 2.1296e-01, time/batch = 0.6551s	
1770/29850 (epoch 2.965), train_loss = 1.78559354, grad/param norm = 2.1434e-01, time/batch = 0.6523s	
1771/29850 (epoch 2.966), train_loss = 1.74818036, grad/param norm = 2.2716e-01, time/batch = 0.6539s	
1772/29850 (epoch 2.968), train_loss = 1.75356978, grad/param norm = 2.2374e-01, time/batch = 0.6725s	
1773/29850 (epoch 2.970), train_loss = 1.75703726, grad/param norm = 2.0427e-01, time/batch = 0.6780s	
1774/29850 (epoch 2.972), train_loss = 1.68532191, grad/param norm = 2.2208e-01, time/batch = 0.6593s	
1775/29850 (epoch 2.973), train_loss = 1.83782204, grad/param norm = 2.5335e-01, time/batch = 0.6588s	
1776/29850 (epoch 2.975), train_loss = 1.58523480, grad/param norm = 2.0558e-01, time/batch = 0.6544s	
1777/29850 (epoch 2.977), train_loss = 1.72446692, grad/param norm = 2.0501e-01, time/batch = 0.6545s	
1778/29850 (epoch 2.978), train_loss = 1.74147732, grad/param norm = 2.0052e-01, time/batch = 0.6682s	
1779/29850 (epoch 2.980), train_loss = 1.65351439, grad/param norm = 2.2138e-01, time/batch = 0.6591s	
1780/29850 (epoch 2.982), train_loss = 1.66981040, grad/param norm = 2.3937e-01, time/batch = 0.6590s	
1781/29850 (epoch 2.983), train_loss = 1.83264741, grad/param norm = 2.1150e-01, time/batch = 0.6590s	
1782/29850 (epoch 2.985), train_loss = 1.85989661, grad/param norm = 2.2027e-01, time/batch = 0.6632s	
1783/29850 (epoch 2.987), train_loss = 1.65753943, grad/param norm = 2.4442e-01, time/batch = 0.6825s	
1784/29850 (epoch 2.988), train_loss = 1.66849709, grad/param norm = 2.0502e-01, time/batch = 0.6637s	
1785/29850 (epoch 2.990), train_loss = 1.69117935, grad/param norm = 1.9682e-01, time/batch = 0.6557s	
1786/29850 (epoch 2.992), train_loss = 1.75421167, grad/param norm = 2.0324e-01, time/batch = 0.6536s	
1787/29850 (epoch 2.993), train_loss = 1.84952851, grad/param norm = 2.2017e-01, time/batch = 0.6572s	
1788/29850 (epoch 2.995), train_loss = 1.80829998, grad/param norm = 2.0559e-01, time/batch = 0.6575s	
1789/29850 (epoch 2.997), train_loss = 1.79619912, grad/param norm = 2.2768e-01, time/batch = 0.6557s	
1790/29850 (epoch 2.998), train_loss = 1.92372210, grad/param norm = 2.0692e-01, time/batch = 0.6647s	
1791/29850 (epoch 3.000), train_loss = 1.78973813, grad/param norm = 2.0919e-01, time/batch = 0.6541s	
1792/29850 (epoch 3.002), train_loss = 1.97514953, grad/param norm = 2.2345e-01, time/batch = 0.6598s	
1793/29850 (epoch 3.003), train_loss = 1.72692468, grad/param norm = 1.9817e-01, time/batch = 0.6770s	
1794/29850 (epoch 3.005), train_loss = 1.78235548, grad/param norm = 2.0075e-01, time/batch = 0.6848s	
1795/29850 (epoch 3.007), train_loss = 1.84583870, grad/param norm = 2.2427e-01, time/batch = 0.6947s	
1796/29850 (epoch 3.008), train_loss = 1.98031452, grad/param norm = 2.0716e-01, time/batch = 0.6923s	
1797/29850 (epoch 3.010), train_loss = 1.71476888, grad/param norm = 2.2591e-01, time/batch = 0.6832s	
1798/29850 (epoch 3.012), train_loss = 1.90838307, grad/param norm = 2.1274e-01, time/batch = 0.6860s	
1799/29850 (epoch 3.013), train_loss = 1.91064598, grad/param norm = 2.2235e-01, time/batch = 0.6800s	
1800/29850 (epoch 3.015), train_loss = 1.84025840, grad/param norm = 2.2875e-01, time/batch = 0.6732s	
1801/29850 (epoch 3.017), train_loss = 1.96597248, grad/param norm = 2.5236e-01, time/batch = 0.6647s	
1802/29850 (epoch 3.018), train_loss = 2.01989638, grad/param norm = 2.6516e-01, time/batch = 0.6599s	
1803/29850 (epoch 3.020), train_loss = 1.68463786, grad/param norm = 2.1662e-01, time/batch = 0.6667s	
1804/29850 (epoch 3.022), train_loss = 1.88226781, grad/param norm = 2.3947e-01, time/batch = 0.6648s	
1805/29850 (epoch 3.023), train_loss = 1.76650738, grad/param norm = 2.3100e-01, time/batch = 0.6637s	
1806/29850 (epoch 3.025), train_loss = 1.77863762, grad/param norm = 1.9076e-01, time/batch = 0.6692s	
1807/29850 (epoch 3.027), train_loss = 1.70892134, grad/param norm = 1.8908e-01, time/batch = 0.6772s	
1808/29850 (epoch 3.028), train_loss = 1.79712064, grad/param norm = 2.0316e-01, time/batch = 0.6621s	
1809/29850 (epoch 3.030), train_loss = 1.89557496, grad/param norm = 2.0636e-01, time/batch = 0.6772s	
1810/29850 (epoch 3.032), train_loss = 1.72458749, grad/param norm = 2.0568e-01, time/batch = 0.6792s	
1811/29850 (epoch 3.034), train_loss = 1.85849788, grad/param norm = 2.1274e-01, time/batch = 0.6736s	
1812/29850 (epoch 3.035), train_loss = 1.79187524, grad/param norm = 2.1425e-01, time/batch = 0.6746s	
1813/29850 (epoch 3.037), train_loss = 1.85968224, grad/param norm = 1.9381e-01, time/batch = 0.6688s	
1814/29850 (epoch 3.039), train_loss = 1.70286283, grad/param norm = 1.9442e-01, time/batch = 0.6778s	
1815/29850 (epoch 3.040), train_loss = 1.63024051, grad/param norm = 1.8237e-01, time/batch = 0.6660s	
1816/29850 (epoch 3.042), train_loss = 1.79205147, grad/param norm = 2.1089e-01, time/batch = 0.6558s	
1817/29850 (epoch 3.044), train_loss = 1.61818338, grad/param norm = 2.0181e-01, time/batch = 0.6560s	
1818/29850 (epoch 3.045), train_loss = 1.84321523, grad/param norm = 2.2155e-01, time/batch = 0.6678s	
1819/29850 (epoch 3.047), train_loss = 1.66680895, grad/param norm = 2.1976e-01, time/batch = 0.6781s	
1820/29850 (epoch 3.049), train_loss = 1.76130195, grad/param norm = 2.2050e-01, time/batch = 0.6826s	
1821/29850 (epoch 3.050), train_loss = 1.66977198, grad/param norm = 1.8747e-01, time/batch = 0.6798s	
1822/29850 (epoch 3.052), train_loss = 2.03491816, grad/param norm = 2.4249e-01, time/batch = 0.6724s	
1823/29850 (epoch 3.054), train_loss = 1.83977127, grad/param norm = 2.2780e-01, time/batch = 0.6591s	
1824/29850 (epoch 3.055), train_loss = 1.77010002, grad/param norm = 2.2647e-01, time/batch = 0.6626s	
1825/29850 (epoch 3.057), train_loss = 1.74542126, grad/param norm = 2.2181e-01, time/batch = 0.6720s	
1826/29850 (epoch 3.059), train_loss = 1.79678806, grad/param norm = 2.0903e-01, time/batch = 0.6628s	
1827/29850 (epoch 3.060), train_loss = 1.77630305, grad/param norm = 2.1826e-01, time/batch = 0.6690s	
1828/29850 (epoch 3.062), train_loss = 1.89291323, grad/param norm = 2.2001e-01, time/batch = 0.6558s	
1829/29850 (epoch 3.064), train_loss = 1.75855564, grad/param norm = 2.1637e-01, time/batch = 0.6527s	
1830/29850 (epoch 3.065), train_loss = 1.63238573, grad/param norm = 2.0331e-01, time/batch = 0.6521s	
1831/29850 (epoch 3.067), train_loss = 1.75360813, grad/param norm = 2.0632e-01, time/batch = 0.6588s	
1832/29850 (epoch 3.069), train_loss = 1.69876839, grad/param norm = 2.0051e-01, time/batch = 0.6531s	
1833/29850 (epoch 3.070), train_loss = 1.73857327, grad/param norm = 1.9830e-01, time/batch = 0.6536s	
1834/29850 (epoch 3.072), train_loss = 1.89184596, grad/param norm = 2.4564e-01, time/batch = 0.6513s	
1835/29850 (epoch 3.074), train_loss = 1.83238851, grad/param norm = 2.5174e-01, time/batch = 0.6820s	
1836/29850 (epoch 3.075), train_loss = 1.71728895, grad/param norm = 2.2004e-01, time/batch = 0.6743s	
1837/29850 (epoch 3.077), train_loss = 1.64483441, grad/param norm = 2.1229e-01, time/batch = 0.6719s	
1838/29850 (epoch 3.079), train_loss = 1.92214098, grad/param norm = 2.0558e-01, time/batch = 0.6627s	
1839/29850 (epoch 3.080), train_loss = 1.87365861, grad/param norm = 2.2455e-01, time/batch = 0.6600s	
1840/29850 (epoch 3.082), train_loss = 1.73431560, grad/param norm = 1.8921e-01, time/batch = 0.6585s	
1841/29850 (epoch 3.084), train_loss = 1.75215214, grad/param norm = 1.9083e-01, time/batch = 0.6656s	
1842/29850 (epoch 3.085), train_loss = 1.67890934, grad/param norm = 2.0582e-01, time/batch = 0.6624s	
1843/29850 (epoch 3.087), train_loss = 1.84720418, grad/param norm = 1.9194e-01, time/batch = 0.6703s	
1844/29850 (epoch 3.089), train_loss = 1.89474031, grad/param norm = 2.0831e-01, time/batch = 0.6640s	
1845/29850 (epoch 3.090), train_loss = 1.76922928, grad/param norm = 2.1160e-01, time/batch = 0.6700s	
1846/29850 (epoch 3.092), train_loss = 1.67965529, grad/param norm = 2.1929e-01, time/batch = 0.6815s	
1847/29850 (epoch 3.094), train_loss = 1.77879443, grad/param norm = 1.9876e-01, time/batch = 0.6583s	
1848/29850 (epoch 3.095), train_loss = 1.89725205, grad/param norm = 2.2632e-01, time/batch = 0.6582s	
1849/29850 (epoch 3.097), train_loss = 1.62924301, grad/param norm = 1.8781e-01, time/batch = 0.6566s	
1850/29850 (epoch 3.099), train_loss = 1.62279991, grad/param norm = 1.9310e-01, time/batch = 0.6555s	
1851/29850 (epoch 3.101), train_loss = 1.92198110, grad/param norm = 2.3880e-01, time/batch = 0.6683s	
1852/29850 (epoch 3.102), train_loss = 1.73044320, grad/param norm = 2.1350e-01, time/batch = 0.6733s	
1853/29850 (epoch 3.104), train_loss = 1.72468225, grad/param norm = 2.0239e-01, time/batch = 0.6574s	
1854/29850 (epoch 3.106), train_loss = 1.84403804, grad/param norm = 2.3205e-01, time/batch = 0.6499s	
1855/29850 (epoch 3.107), train_loss = 1.74391675, grad/param norm = 2.0624e-01, time/batch = 0.6622s	
1856/29850 (epoch 3.109), train_loss = 1.71545920, grad/param norm = 2.0436e-01, time/batch = 0.6761s	
1857/29850 (epoch 3.111), train_loss = 1.86500919, grad/param norm = 2.3582e-01, time/batch = 0.6666s	
1858/29850 (epoch 3.112), train_loss = 1.70273848, grad/param norm = 2.2014e-01, time/batch = 0.6605s	
1859/29850 (epoch 3.114), train_loss = 1.93601565, grad/param norm = 2.3228e-01, time/batch = 0.6566s	
1860/29850 (epoch 3.116), train_loss = 1.76295712, grad/param norm = 2.3419e-01, time/batch = 0.6619s	
1861/29850 (epoch 3.117), train_loss = 1.83141799, grad/param norm = 1.9725e-01, time/batch = 0.6548s	
1862/29850 (epoch 3.119), train_loss = 1.73651267, grad/param norm = 1.8605e-01, time/batch = 0.6507s	
1863/29850 (epoch 3.121), train_loss = 1.59722191, grad/param norm = 1.8649e-01, time/batch = 0.6549s	
1864/29850 (epoch 3.122), train_loss = 1.67021743, grad/param norm = 2.0125e-01, time/batch = 0.6542s	
1865/29850 (epoch 3.124), train_loss = 1.64904993, grad/param norm = 1.8466e-01, time/batch = 0.6553s	
1866/29850 (epoch 3.126), train_loss = 1.75697978, grad/param norm = 2.0476e-01, time/batch = 0.6557s	
1867/29850 (epoch 3.127), train_loss = 2.00944447, grad/param norm = 2.0966e-01, time/batch = 0.6578s	
1868/29850 (epoch 3.129), train_loss = 1.74813244, grad/param norm = 2.4430e-01, time/batch = 0.6675s	
1869/29850 (epoch 3.131), train_loss = 1.73283500, grad/param norm = 2.0931e-01, time/batch = 0.6541s	
1870/29850 (epoch 3.132), train_loss = 1.77245932, grad/param norm = 2.1688e-01, time/batch = 0.6559s	
1871/29850 (epoch 3.134), train_loss = 1.84198388, grad/param norm = 2.1561e-01, time/batch = 0.6698s	
1872/29850 (epoch 3.136), train_loss = 1.82169985, grad/param norm = 2.3108e-01, time/batch = 0.6702s	
1873/29850 (epoch 3.137), train_loss = 1.73536726, grad/param norm = 2.0770e-01, time/batch = 0.6657s	
1874/29850 (epoch 3.139), train_loss = 1.70609493, grad/param norm = 2.2904e-01, time/batch = 0.6607s	
1875/29850 (epoch 3.141), train_loss = 1.73693332, grad/param norm = 1.9978e-01, time/batch = 0.6618s	
1876/29850 (epoch 3.142), train_loss = 1.82637851, grad/param norm = 2.2632e-01, time/batch = 0.6555s	
1877/29850 (epoch 3.144), train_loss = 1.90923479, grad/param norm = 2.0351e-01, time/batch = 0.6486s	
1878/29850 (epoch 3.146), train_loss = 1.82050982, grad/param norm = 2.1372e-01, time/batch = 0.6483s	
1879/29850 (epoch 3.147), train_loss = 1.88785406, grad/param norm = 2.1268e-01, time/batch = 0.6554s	
1880/29850 (epoch 3.149), train_loss = 1.84623457, grad/param norm = 2.3527e-01, time/batch = 0.6551s	
1881/29850 (epoch 3.151), train_loss = 1.76317114, grad/param norm = 2.3600e-01, time/batch = 0.6687s	
1882/29850 (epoch 3.152), train_loss = 1.72552652, grad/param norm = 2.2419e-01, time/batch = 0.6829s	
1883/29850 (epoch 3.154), train_loss = 1.76039052, grad/param norm = 2.0108e-01, time/batch = 0.6746s	
1884/29850 (epoch 3.156), train_loss = 1.64802920, grad/param norm = 1.9497e-01, time/batch = 0.6847s	
1885/29850 (epoch 3.157), train_loss = 1.78464330, grad/param norm = 1.8299e-01, time/batch = 0.6891s	
1886/29850 (epoch 3.159), train_loss = 1.78400285, grad/param norm = 1.8109e-01, time/batch = 0.6912s	
1887/29850 (epoch 3.161), train_loss = 1.88465983, grad/param norm = 2.2065e-01, time/batch = 0.7019s	
1888/29850 (epoch 3.162), train_loss = 1.85234799, grad/param norm = 2.0155e-01, time/batch = 0.6881s	
1889/29850 (epoch 3.164), train_loss = 1.70016772, grad/param norm = 2.0783e-01, time/batch = 0.6856s	
1890/29850 (epoch 3.166), train_loss = 1.71534841, grad/param norm = 2.1415e-01, time/batch = 0.6882s	
1891/29850 (epoch 3.168), train_loss = 1.58449917, grad/param norm = 1.9808e-01, time/batch = 0.6921s	
1892/29850 (epoch 3.169), train_loss = 1.96234992, grad/param norm = 2.2570e-01, time/batch = 0.6897s	
1893/29850 (epoch 3.171), train_loss = 1.93401699, grad/param norm = 2.1533e-01, time/batch = 0.6905s	
1894/29850 (epoch 3.173), train_loss = 1.79691668, grad/param norm = 2.0914e-01, time/batch = 0.6975s	
1895/29850 (epoch 3.174), train_loss = 1.87366272, grad/param norm = 2.1761e-01, time/batch = 0.6855s	
1896/29850 (epoch 3.176), train_loss = 1.88959771, grad/param norm = 2.3487e-01, time/batch = 0.6855s	
1897/29850 (epoch 3.178), train_loss = 1.89723798, grad/param norm = 2.2334e-01, time/batch = 0.6852s	
1898/29850 (epoch 3.179), train_loss = 1.58855080, grad/param norm = 2.0453e-01, time/batch = 0.6843s	
1899/29850 (epoch 3.181), train_loss = 1.64791145, grad/param norm = 1.9289e-01, time/batch = 0.6710s	
1900/29850 (epoch 3.183), train_loss = 1.68514706, grad/param norm = 2.0012e-01, time/batch = 0.6682s	
1901/29850 (epoch 3.184), train_loss = 1.70717676, grad/param norm = 1.9311e-01, time/batch = 0.6621s	
1902/29850 (epoch 3.186), train_loss = 1.67528649, grad/param norm = 2.3405e-01, time/batch = 0.6571s	
1903/29850 (epoch 3.188), train_loss = 1.78982078, grad/param norm = 2.2976e-01, time/batch = 0.6603s	
1904/29850 (epoch 3.189), train_loss = 1.89397693, grad/param norm = 2.1320e-01, time/batch = 0.6559s	
1905/29850 (epoch 3.191), train_loss = 1.76308550, grad/param norm = 2.1573e-01, time/batch = 0.6567s	
1906/29850 (epoch 3.193), train_loss = 1.60250253, grad/param norm = 1.7919e-01, time/batch = 0.6500s	
1907/29850 (epoch 3.194), train_loss = 1.85808238, grad/param norm = 2.5772e-01, time/batch = 0.6371s	
1908/29850 (epoch 3.196), train_loss = 1.74583530, grad/param norm = 2.2124e-01, time/batch = 0.6409s	
1909/29850 (epoch 3.198), train_loss = 1.71925572, grad/param norm = 1.7130e-01, time/batch = 0.6408s	
1910/29850 (epoch 3.199), train_loss = 1.97386147, grad/param norm = 2.0508e-01, time/batch = 0.6526s	
1911/29850 (epoch 3.201), train_loss = 1.86264525, grad/param norm = 2.4035e-01, time/batch = 0.6488s	
1912/29850 (epoch 3.203), train_loss = 1.85552349, grad/param norm = 2.3722e-01, time/batch = 0.6445s	
1913/29850 (epoch 3.204), train_loss = 1.75641996, grad/param norm = 2.2366e-01, time/batch = 0.6449s	
1914/29850 (epoch 3.206), train_loss = 1.71955898, grad/param norm = 2.0492e-01, time/batch = 0.6443s	
1915/29850 (epoch 3.208), train_loss = 1.98632347, grad/param norm = 2.1119e-01, time/batch = 0.6396s	
1916/29850 (epoch 3.209), train_loss = 1.67289522, grad/param norm = 2.0694e-01, time/batch = 0.6460s	
1917/29850 (epoch 3.211), train_loss = 1.67094553, grad/param norm = 1.8665e-01, time/batch = 0.6452s	
1918/29850 (epoch 3.213), train_loss = 1.92949999, grad/param norm = 2.0773e-01, time/batch = 0.6421s	
1919/29850 (epoch 3.214), train_loss = 1.71864512, grad/param norm = 2.1962e-01, time/batch = 0.6425s	
1920/29850 (epoch 3.216), train_loss = 1.78810892, grad/param norm = 2.1936e-01, time/batch = 0.6441s	
1921/29850 (epoch 3.218), train_loss = 1.85209031, grad/param norm = 2.0207e-01, time/batch = 0.6472s	
1922/29850 (epoch 3.219), train_loss = 1.98410306, grad/param norm = 2.1465e-01, time/batch = 0.6413s	
1923/29850 (epoch 3.221), train_loss = 1.67987969, grad/param norm = 1.9030e-01, time/batch = 0.6476s	
1924/29850 (epoch 3.223), train_loss = 1.81599735, grad/param norm = 2.1321e-01, time/batch = 0.6464s	
1925/29850 (epoch 3.224), train_loss = 1.70605102, grad/param norm = 2.0600e-01, time/batch = 0.6509s	
1926/29850 (epoch 3.226), train_loss = 1.76722318, grad/param norm = 1.9339e-01, time/batch = 0.6742s	
1927/29850 (epoch 3.228), train_loss = 1.67651229, grad/param norm = 1.7847e-01, time/batch = 0.6753s	
1928/29850 (epoch 3.229), train_loss = 1.64900676, grad/param norm = 1.9690e-01, time/batch = 0.6701s	
1929/29850 (epoch 3.231), train_loss = 1.67052863, grad/param norm = 1.8732e-01, time/batch = 0.6599s	
1930/29850 (epoch 3.233), train_loss = 1.72835454, grad/param norm = 2.1310e-01, time/batch = 0.6494s	
1931/29850 (epoch 3.235), train_loss = 1.62906417, grad/param norm = 1.8253e-01, time/batch = 0.6507s	
1932/29850 (epoch 3.236), train_loss = 1.99329595, grad/param norm = 2.3740e-01, time/batch = 0.6496s	
1933/29850 (epoch 3.238), train_loss = 1.62234633, grad/param norm = 2.1432e-01, time/batch = 0.6517s	
1934/29850 (epoch 3.240), train_loss = 1.79099333, grad/param norm = 2.0233e-01, time/batch = 0.6680s	
1935/29850 (epoch 3.241), train_loss = 2.00333055, grad/param norm = 2.1358e-01, time/batch = 0.6602s	
1936/29850 (epoch 3.243), train_loss = 1.71915074, grad/param norm = 1.8629e-01, time/batch = 0.6486s	
1937/29850 (epoch 3.245), train_loss = 1.76168622, grad/param norm = 2.1153e-01, time/batch = 0.6407s	
1938/29850 (epoch 3.246), train_loss = 1.76159210, grad/param norm = 2.0695e-01, time/batch = 0.6399s	
1939/29850 (epoch 3.248), train_loss = 1.76353918, grad/param norm = 2.1104e-01, time/batch = 0.6399s	
1940/29850 (epoch 3.250), train_loss = 1.87198989, grad/param norm = 2.0796e-01, time/batch = 0.6430s	
1941/29850 (epoch 3.251), train_loss = 1.66400263, grad/param norm = 1.9816e-01, time/batch = 0.6465s	
1942/29850 (epoch 3.253), train_loss = 1.79027205, grad/param norm = 2.2144e-01, time/batch = 0.6418s	
1943/29850 (epoch 3.255), train_loss = 1.79110508, grad/param norm = 2.2092e-01, time/batch = 0.6435s	
1944/29850 (epoch 3.256), train_loss = 1.70620868, grad/param norm = 1.9830e-01, time/batch = 0.6414s	
1945/29850 (epoch 3.258), train_loss = 1.69187564, grad/param norm = 2.0198e-01, time/batch = 0.6415s	
1946/29850 (epoch 3.260), train_loss = 1.67494658, grad/param norm = 1.8573e-01, time/batch = 0.6416s	
1947/29850 (epoch 3.261), train_loss = 1.70074479, grad/param norm = 2.1512e-01, time/batch = 0.6419s	
1948/29850 (epoch 3.263), train_loss = 1.62741597, grad/param norm = 2.0532e-01, time/batch = 0.6464s	
1949/29850 (epoch 3.265), train_loss = 1.72671622, grad/param norm = 2.0525e-01, time/batch = 0.6406s	
1950/29850 (epoch 3.266), train_loss = 1.71871783, grad/param norm = 2.3646e-01, time/batch = 0.6528s	
1951/29850 (epoch 3.268), train_loss = 1.71701629, grad/param norm = 2.1751e-01, time/batch = 0.6484s	
1952/29850 (epoch 3.270), train_loss = 1.72840026, grad/param norm = 2.1231e-01, time/batch = 0.6430s	
1953/29850 (epoch 3.271), train_loss = 1.80684217, grad/param norm = 2.1191e-01, time/batch = 0.6404s	
1954/29850 (epoch 3.273), train_loss = 1.74740709, grad/param norm = 2.1666e-01, time/batch = 0.6548s	
1955/29850 (epoch 3.275), train_loss = 1.72670083, grad/param norm = 2.0823e-01, time/batch = 0.6435s	
1956/29850 (epoch 3.276), train_loss = 1.65949121, grad/param norm = 2.0403e-01, time/batch = 0.6400s	
1957/29850 (epoch 3.278), train_loss = 1.64944427, grad/param norm = 1.8996e-01, time/batch = 0.6425s	
1958/29850 (epoch 3.280), train_loss = 1.74463216, grad/param norm = 1.9562e-01, time/batch = 0.6443s	
1959/29850 (epoch 3.281), train_loss = 1.65011790, grad/param norm = 2.0977e-01, time/batch = 0.6462s	
1960/29850 (epoch 3.283), train_loss = 1.79691312, grad/param norm = 2.0651e-01, time/batch = 0.6675s	
1961/29850 (epoch 3.285), train_loss = 1.73435349, grad/param norm = 1.9254e-01, time/batch = 0.6674s	
1962/29850 (epoch 3.286), train_loss = 1.71675100, grad/param norm = 1.8837e-01, time/batch = 0.6449s	
1963/29850 (epoch 3.288), train_loss = 1.91017388, grad/param norm = 2.4850e-01, time/batch = 0.6385s	
1964/29850 (epoch 3.290), train_loss = 1.65574588, grad/param norm = 2.1680e-01, time/batch = 0.6402s	
1965/29850 (epoch 3.291), train_loss = 1.97120314, grad/param norm = 2.0666e-01, time/batch = 0.6435s	
1966/29850 (epoch 3.293), train_loss = 1.84991413, grad/param norm = 2.0865e-01, time/batch = 0.6480s	
1967/29850 (epoch 3.295), train_loss = 1.86342724, grad/param norm = 2.0781e-01, time/batch = 0.6482s	
1968/29850 (epoch 3.296), train_loss = 1.63814465, grad/param norm = 1.8566e-01, time/batch = 0.6460s	
1969/29850 (epoch 3.298), train_loss = 1.51712575, grad/param norm = 1.8550e-01, time/batch = 0.6432s	
1970/29850 (epoch 3.300), train_loss = 1.62743239, grad/param norm = 2.0163e-01, time/batch = 0.6436s	
1971/29850 (epoch 3.302), train_loss = 1.60262573, grad/param norm = 1.9683e-01, time/batch = 0.6710s	
1972/29850 (epoch 3.303), train_loss = 1.75615802, grad/param norm = 2.1404e-01, time/batch = 0.6613s	
1973/29850 (epoch 3.305), train_loss = 1.68287312, grad/param norm = 1.9465e-01, time/batch = 0.6441s	
1974/29850 (epoch 3.307), train_loss = 1.81627702, grad/param norm = 2.2087e-01, time/batch = 0.6586s	
1975/29850 (epoch 3.308), train_loss = 1.81859874, grad/param norm = 2.0897e-01, time/batch = 0.6696s	
1976/29850 (epoch 3.310), train_loss = 1.86159742, grad/param norm = 2.0738e-01, time/batch = 0.6705s	
1977/29850 (epoch 3.312), train_loss = 1.74002207, grad/param norm = 1.9828e-01, time/batch = 0.6409s	
1978/29850 (epoch 3.313), train_loss = 1.76516665, grad/param norm = 1.9894e-01, time/batch = 0.6454s	
1979/29850 (epoch 3.315), train_loss = 1.76580828, grad/param norm = 2.2221e-01, time/batch = 0.6443s	
1980/29850 (epoch 3.317), train_loss = 1.85012085, grad/param norm = 2.0441e-01, time/batch = 0.6436s	
1981/29850 (epoch 3.318), train_loss = 1.77230055, grad/param norm = 2.2320e-01, time/batch = 0.6452s	
1982/29850 (epoch 3.320), train_loss = 1.56796997, grad/param norm = 2.1211e-01, time/batch = 0.6435s	
1983/29850 (epoch 3.322), train_loss = 1.81108444, grad/param norm = 1.8428e-01, time/batch = 0.6401s	
1984/29850 (epoch 3.323), train_loss = 1.75302955, grad/param norm = 2.0742e-01, time/batch = 0.6471s	
1985/29850 (epoch 3.325), train_loss = 1.72614960, grad/param norm = 1.9309e-01, time/batch = 0.6463s	
1986/29850 (epoch 3.327), train_loss = 1.91829897, grad/param norm = 2.3018e-01, time/batch = 0.6409s	
1987/29850 (epoch 3.328), train_loss = 1.95142050, grad/param norm = 2.1193e-01, time/batch = 0.6392s	
1988/29850 (epoch 3.330), train_loss = 1.72271059, grad/param norm = 2.0544e-01, time/batch = 0.6420s	
1989/29850 (epoch 3.332), train_loss = 1.68427977, grad/param norm = 2.0567e-01, time/batch = 0.6441s	
1990/29850 (epoch 3.333), train_loss = 1.86868986, grad/param norm = 2.0593e-01, time/batch = 0.6516s	
1991/29850 (epoch 3.335), train_loss = 1.79470468, grad/param norm = 2.0831e-01, time/batch = 0.6540s	
1992/29850 (epoch 3.337), train_loss = 1.80313313, grad/param norm = 2.1870e-01, time/batch = 0.6531s	
1993/29850 (epoch 3.338), train_loss = 1.73730001, grad/param norm = 1.9462e-01, time/batch = 0.6714s	
1994/29850 (epoch 3.340), train_loss = 1.60234457, grad/param norm = 1.9141e-01, time/batch = 0.6393s	
1995/29850 (epoch 3.342), train_loss = 1.81043086, grad/param norm = 2.1924e-01, time/batch = 0.6385s	
1996/29850 (epoch 3.343), train_loss = 1.84485349, grad/param norm = 2.1052e-01, time/batch = 0.6551s	
1997/29850 (epoch 3.345), train_loss = 1.88876697, grad/param norm = 2.4448e-01, time/batch = 0.6454s	
1998/29850 (epoch 3.347), train_loss = 1.82588659, grad/param norm = 2.1260e-01, time/batch = 0.6404s	
1999/29850 (epoch 3.348), train_loss = 1.83254831, grad/param norm = 1.9659e-01, time/batch = 0.6402s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch3.35_1.8618.t7	
2000/29850 (epoch 3.350), train_loss = 1.85595729, grad/param norm = 2.2627e-01, time/batch = 0.6409s	
2001/29850 (epoch 3.352), train_loss = 1.87216113, grad/param norm = 2.0927e-01, time/batch = 0.6538s	
2002/29850 (epoch 3.353), train_loss = 1.75241988, grad/param norm = 2.1492e-01, time/batch = 0.6596s	
2003/29850 (epoch 3.355), train_loss = 1.61327385, grad/param norm = 2.2407e-01, time/batch = 0.6546s	
2004/29850 (epoch 3.357), train_loss = 1.89422824, grad/param norm = 1.9316e-01, time/batch = 0.6578s	
2005/29850 (epoch 3.358), train_loss = 1.55766506, grad/param norm = 1.7235e-01, time/batch = 0.6480s	
2006/29850 (epoch 3.360), train_loss = 1.64999624, grad/param norm = 1.9409e-01, time/batch = 0.6568s	
2007/29850 (epoch 3.362), train_loss = 1.72423780, grad/param norm = 1.9444e-01, time/batch = 0.6577s	
2008/29850 (epoch 3.363), train_loss = 1.76417182, grad/param norm = 1.9881e-01, time/batch = 0.6507s	
2009/29850 (epoch 3.365), train_loss = 1.88706411, grad/param norm = 2.0459e-01, time/batch = 0.6620s	
2010/29850 (epoch 3.367), train_loss = 1.71248006, grad/param norm = 1.8797e-01, time/batch = 0.6571s	
2011/29850 (epoch 3.369), train_loss = 1.61286263, grad/param norm = 1.9855e-01, time/batch = 0.6568s	
2012/29850 (epoch 3.370), train_loss = 1.56209420, grad/param norm = 2.0830e-01, time/batch = 0.6583s	
2013/29850 (epoch 3.372), train_loss = 1.88208709, grad/param norm = 1.9151e-01, time/batch = 0.6517s	
2014/29850 (epoch 3.374), train_loss = 1.67443365, grad/param norm = 2.0450e-01, time/batch = 0.6476s	
2015/29850 (epoch 3.375), train_loss = 1.70198731, grad/param norm = 2.2190e-01, time/batch = 0.6454s	
2016/29850 (epoch 3.377), train_loss = 1.77689364, grad/param norm = 2.0671e-01, time/batch = 0.6442s	
2017/29850 (epoch 3.379), train_loss = 1.84762901, grad/param norm = 2.2778e-01, time/batch = 0.6413s	
2018/29850 (epoch 3.380), train_loss = 1.80915607, grad/param norm = 2.3322e-01, time/batch = 0.6425s	
2019/29850 (epoch 3.382), train_loss = 1.85774084, grad/param norm = 2.0720e-01, time/batch = 0.6437s	
2020/29850 (epoch 3.384), train_loss = 1.67383572, grad/param norm = 2.0748e-01, time/batch = 0.6430s	
2021/29850 (epoch 3.385), train_loss = 1.81435420, grad/param norm = 2.0047e-01, time/batch = 0.6419s	
2022/29850 (epoch 3.387), train_loss = 1.76246427, grad/param norm = 2.0897e-01, time/batch = 0.6413s	
2023/29850 (epoch 3.389), train_loss = 1.91730749, grad/param norm = 2.1758e-01, time/batch = 0.6398s	
2024/29850 (epoch 3.390), train_loss = 1.72472748, grad/param norm = 1.9321e-01, time/batch = 0.6415s	
2025/29850 (epoch 3.392), train_loss = 1.71591248, grad/param norm = 1.9480e-01, time/batch = 0.6464s	
2026/29850 (epoch 3.394), train_loss = 1.77708435, grad/param norm = 1.9149e-01, time/batch = 0.6446s	
2027/29850 (epoch 3.395), train_loss = 1.85976592, grad/param norm = 1.9404e-01, time/batch = 0.6475s	
2028/29850 (epoch 3.397), train_loss = 1.79455228, grad/param norm = 2.0853e-01, time/batch = 0.6416s	
2029/29850 (epoch 3.399), train_loss = 1.61454363, grad/param norm = 1.9415e-01, time/batch = 0.6404s	
2030/29850 (epoch 3.400), train_loss = 1.93212501, grad/param norm = 2.3005e-01, time/batch = 0.6462s	
2031/29850 (epoch 3.402), train_loss = 1.80586872, grad/param norm = 2.1613e-01, time/batch = 0.6547s	
2032/29850 (epoch 3.404), train_loss = 1.85520548, grad/param norm = 2.0787e-01, time/batch = 0.6443s	
2033/29850 (epoch 3.405), train_loss = 1.87263459, grad/param norm = 1.9865e-01, time/batch = 0.6436s	
2034/29850 (epoch 3.407), train_loss = 1.77245090, grad/param norm = 2.2859e-01, time/batch = 0.6449s	
2035/29850 (epoch 3.409), train_loss = 2.01015673, grad/param norm = 2.3510e-01, time/batch = 0.6522s	
2036/29850 (epoch 3.410), train_loss = 1.82675282, grad/param norm = 2.2725e-01, time/batch = 0.6463s	
2037/29850 (epoch 3.412), train_loss = 1.70434510, grad/param norm = 2.3092e-01, time/batch = 0.6507s	
2038/29850 (epoch 3.414), train_loss = 1.78106462, grad/param norm = 2.0944e-01, time/batch = 0.6534s	
2039/29850 (epoch 3.415), train_loss = 1.75093847, grad/param norm = 1.9890e-01, time/batch = 0.6442s	
2040/29850 (epoch 3.417), train_loss = 1.84805215, grad/param norm = 1.9184e-01, time/batch = 0.6435s	
2041/29850 (epoch 3.419), train_loss = 1.74657765, grad/param norm = 2.0468e-01, time/batch = 0.6494s	
2042/29850 (epoch 3.420), train_loss = 1.69255761, grad/param norm = 1.8609e-01, time/batch = 0.6719s	
2043/29850 (epoch 3.422), train_loss = 1.71833320, grad/param norm = 1.9958e-01, time/batch = 0.6631s	
2044/29850 (epoch 3.424), train_loss = 1.81670891, grad/param norm = 2.1244e-01, time/batch = 0.6465s	
2045/29850 (epoch 3.425), train_loss = 2.01529387, grad/param norm = 2.0852e-01, time/batch = 0.6468s	
2046/29850 (epoch 3.427), train_loss = 1.66031404, grad/param norm = 2.2329e-01, time/batch = 0.6404s	
2047/29850 (epoch 3.429), train_loss = 1.68208598, grad/param norm = 2.0764e-01, time/batch = 0.6397s	
2048/29850 (epoch 3.430), train_loss = 1.57049048, grad/param norm = 1.9318e-01, time/batch = 0.6408s	
2049/29850 (epoch 3.432), train_loss = 1.78528739, grad/param norm = 2.0774e-01, time/batch = 0.6434s	
2050/29850 (epoch 3.434), train_loss = 1.67615480, grad/param norm = 2.0026e-01, time/batch = 0.6413s	
2051/29850 (epoch 3.436), train_loss = 1.79970738, grad/param norm = 2.1607e-01, time/batch = 0.6423s	
2052/29850 (epoch 3.437), train_loss = 1.68282973, grad/param norm = 1.8626e-01, time/batch = 0.6506s	
2053/29850 (epoch 3.439), train_loss = 1.76950328, grad/param norm = 1.9548e-01, time/batch = 0.6703s	
2054/29850 (epoch 3.441), train_loss = 1.76032380, grad/param norm = 1.8844e-01, time/batch = 0.6497s	
2055/29850 (epoch 3.442), train_loss = 1.82299320, grad/param norm = 1.9741e-01, time/batch = 0.6422s	
2056/29850 (epoch 3.444), train_loss = 1.72367451, grad/param norm = 1.8294e-01, time/batch = 0.6458s	
2057/29850 (epoch 3.446), train_loss = 1.74484206, grad/param norm = 2.0086e-01, time/batch = 0.6584s	
2058/29850 (epoch 3.447), train_loss = 1.87765061, grad/param norm = 2.3854e-01, time/batch = 0.6660s	
2059/29850 (epoch 3.449), train_loss = 1.91935211, grad/param norm = 2.2879e-01, time/batch = 0.6710s	
2060/29850 (epoch 3.451), train_loss = 1.74756758, grad/param norm = 1.9281e-01, time/batch = 0.6600s	
2061/29850 (epoch 3.452), train_loss = 1.62079367, grad/param norm = 1.9897e-01, time/batch = 0.6521s	
2062/29850 (epoch 3.454), train_loss = 1.68140940, grad/param norm = 2.1532e-01, time/batch = 0.6474s	
2063/29850 (epoch 3.456), train_loss = 1.75154756, grad/param norm = 1.9746e-01, time/batch = 0.6480s	
2064/29850 (epoch 3.457), train_loss = 1.97063605, grad/param norm = 2.3551e-01, time/batch = 0.6499s	
2065/29850 (epoch 3.459), train_loss = 1.96080531, grad/param norm = 2.5067e-01, time/batch = 0.6436s	
2066/29850 (epoch 3.461), train_loss = 1.93039650, grad/param norm = 2.3508e-01, time/batch = 0.6455s	
2067/29850 (epoch 3.462), train_loss = 1.78297571, grad/param norm = 1.9979e-01, time/batch = 0.6468s	
2068/29850 (epoch 3.464), train_loss = 1.72688701, grad/param norm = 1.8190e-01, time/batch = 0.6458s	
2069/29850 (epoch 3.466), train_loss = 1.66476210, grad/param norm = 1.9439e-01, time/batch = 0.6428s	
2070/29850 (epoch 3.467), train_loss = 1.79015836, grad/param norm = 2.1281e-01, time/batch = 0.6457s	
2071/29850 (epoch 3.469), train_loss = 1.80294003, grad/param norm = 1.8898e-01, time/batch = 0.6447s	
2072/29850 (epoch 3.471), train_loss = 1.83025595, grad/param norm = 1.8986e-01, time/batch = 0.6501s	
2073/29850 (epoch 3.472), train_loss = 1.67032638, grad/param norm = 1.7951e-01, time/batch = 0.6491s	
2074/29850 (epoch 3.474), train_loss = 1.93445228, grad/param norm = 2.1320e-01, time/batch = 0.6683s	
2075/29850 (epoch 3.476), train_loss = 1.80186679, grad/param norm = 2.0974e-01, time/batch = 0.6617s	
2076/29850 (epoch 3.477), train_loss = 1.84241317, grad/param norm = 1.8572e-01, time/batch = 0.6507s	
2077/29850 (epoch 3.479), train_loss = 1.83635707, grad/param norm = 2.1935e-01, time/batch = 0.6532s	
2078/29850 (epoch 3.481), train_loss = 1.91874581, grad/param norm = 2.0607e-01, time/batch = 0.6500s	
2079/29850 (epoch 3.482), train_loss = 1.66935524, grad/param norm = 2.1031e-01, time/batch = 0.6448s	
2080/29850 (epoch 3.484), train_loss = 1.76505267, grad/param norm = 2.0650e-01, time/batch = 0.6417s	
2081/29850 (epoch 3.486), train_loss = 1.71039806, grad/param norm = 1.8859e-01, time/batch = 0.6542s	
2082/29850 (epoch 3.487), train_loss = 1.63447023, grad/param norm = 2.1272e-01, time/batch = 0.6422s	
2083/29850 (epoch 3.489), train_loss = 1.73954893, grad/param norm = 1.9156e-01, time/batch = 0.6451s	
2084/29850 (epoch 3.491), train_loss = 1.63487105, grad/param norm = 1.8155e-01, time/batch = 0.6495s	
2085/29850 (epoch 3.492), train_loss = 1.89012844, grad/param norm = 2.0454e-01, time/batch = 0.6703s	
2086/29850 (epoch 3.494), train_loss = 1.88591323, grad/param norm = 1.9365e-01, time/batch = 0.6512s	
2087/29850 (epoch 3.496), train_loss = 1.92545004, grad/param norm = 2.0974e-01, time/batch = 0.6418s	
2088/29850 (epoch 3.497), train_loss = 1.72917271, grad/param norm = 1.9963e-01, time/batch = 0.6451s	
2089/29850 (epoch 3.499), train_loss = 1.75045250, grad/param norm = 1.9070e-01, time/batch = 0.6415s	
2090/29850 (epoch 3.501), train_loss = 1.67036939, grad/param norm = 1.9194e-01, time/batch = 0.6422s	
2091/29850 (epoch 3.503), train_loss = 1.73136131, grad/param norm = 2.0706e-01, time/batch = 0.6429s	
2092/29850 (epoch 3.504), train_loss = 1.86582204, grad/param norm = 1.8412e-01, time/batch = 0.6402s	
2093/29850 (epoch 3.506), train_loss = 1.94212596, grad/param norm = 2.0194e-01, time/batch = 0.6421s	
2094/29850 (epoch 3.508), train_loss = 1.80412596, grad/param norm = 2.1503e-01, time/batch = 0.6411s	
2095/29850 (epoch 3.509), train_loss = 1.57359590, grad/param norm = 1.9086e-01, time/batch = 0.6507s	
2096/29850 (epoch 3.511), train_loss = 1.74036209, grad/param norm = 2.1231e-01, time/batch = 0.6702s	
2097/29850 (epoch 3.513), train_loss = 1.84292471, grad/param norm = 2.1366e-01, time/batch = 0.6429s	
2098/29850 (epoch 3.514), train_loss = 1.60113810, grad/param norm = 1.9108e-01, time/batch = 0.6370s	
2099/29850 (epoch 3.516), train_loss = 1.61476925, grad/param norm = 2.0144e-01, time/batch = 0.6405s	
2100/29850 (epoch 3.518), train_loss = 1.63990079, grad/param norm = 1.7143e-01, time/batch = 0.6475s	
2101/29850 (epoch 3.519), train_loss = 1.62429342, grad/param norm = 1.8158e-01, time/batch = 0.6469s	
2102/29850 (epoch 3.521), train_loss = 1.68499960, grad/param norm = 2.0042e-01, time/batch = 0.6490s	
2103/29850 (epoch 3.523), train_loss = 1.57862062, grad/param norm = 1.9243e-01, time/batch = 0.6447s	
2104/29850 (epoch 3.524), train_loss = 1.76552803, grad/param norm = 2.0155e-01, time/batch = 0.6472s	
2105/29850 (epoch 3.526), train_loss = 1.82465195, grad/param norm = 2.1790e-01, time/batch = 0.6498s	
2106/29850 (epoch 3.528), train_loss = 1.85231088, grad/param norm = 2.1764e-01, time/batch = 0.6629s	
2107/29850 (epoch 3.529), train_loss = 1.88304089, grad/param norm = 2.2553e-01, time/batch = 0.6678s	
2108/29850 (epoch 3.531), train_loss = 1.81922380, grad/param norm = 2.1345e-01, time/batch = 0.6393s	
2109/29850 (epoch 3.533), train_loss = 1.62361195, grad/param norm = 1.8626e-01, time/batch = 0.6415s	
2110/29850 (epoch 3.534), train_loss = 1.69608941, grad/param norm = 2.1740e-01, time/batch = 0.6439s	
2111/29850 (epoch 3.536), train_loss = 1.80251977, grad/param norm = 1.8890e-01, time/batch = 0.6498s	
2112/29850 (epoch 3.538), train_loss = 1.75587773, grad/param norm = 1.9069e-01, time/batch = 0.6526s	
2113/29850 (epoch 3.539), train_loss = 1.77495455, grad/param norm = 2.0986e-01, time/batch = 0.6446s	
2114/29850 (epoch 3.541), train_loss = 1.59785050, grad/param norm = 2.0622e-01, time/batch = 0.6479s	
2115/29850 (epoch 3.543), train_loss = 1.66694125, grad/param norm = 2.0039e-01, time/batch = 0.6471s	
2116/29850 (epoch 3.544), train_loss = 1.73622592, grad/param norm = 2.0745e-01, time/batch = 0.6456s	
2117/29850 (epoch 3.546), train_loss = 1.82528460, grad/param norm = 2.0352e-01, time/batch = 0.6681s	
2118/29850 (epoch 3.548), train_loss = 1.64384527, grad/param norm = 1.8927e-01, time/batch = 0.6604s	
2119/29850 (epoch 3.549), train_loss = 1.77056992, grad/param norm = 1.9172e-01, time/batch = 0.6464s	
2120/29850 (epoch 3.551), train_loss = 1.69694450, grad/param norm = 1.8479e-01, time/batch = 0.6425s	
2121/29850 (epoch 3.553), train_loss = 1.82514730, grad/param norm = 2.1227e-01, time/batch = 0.6462s	
2122/29850 (epoch 3.554), train_loss = 1.52207667, grad/param norm = 1.8097e-01, time/batch = 0.6444s	
2123/29850 (epoch 3.556), train_loss = 1.73122860, grad/param norm = 2.0165e-01, time/batch = 0.6415s	
2124/29850 (epoch 3.558), train_loss = 1.66420981, grad/param norm = 1.9575e-01, time/batch = 0.6384s	
2125/29850 (epoch 3.559), train_loss = 1.84423255, grad/param norm = 2.1710e-01, time/batch = 0.6411s	
2126/29850 (epoch 3.561), train_loss = 1.83224788, grad/param norm = 2.0445e-01, time/batch = 0.6607s	
2127/29850 (epoch 3.563), train_loss = 1.75424475, grad/param norm = 2.1522e-01, time/batch = 0.6606s	
2128/29850 (epoch 3.564), train_loss = 1.79466335, grad/param norm = 2.2067e-01, time/batch = 0.6556s	
2129/29850 (epoch 3.566), train_loss = 1.63326790, grad/param norm = 1.8992e-01, time/batch = 0.6511s	
2130/29850 (epoch 3.568), train_loss = 1.83456900, grad/param norm = 2.0410e-01, time/batch = 0.6440s	
2131/29850 (epoch 3.570), train_loss = 1.74376880, grad/param norm = 1.9039e-01, time/batch = 0.6453s	
2132/29850 (epoch 3.571), train_loss = 1.80527416, grad/param norm = 1.8997e-01, time/batch = 0.6472s	
2133/29850 (epoch 3.573), train_loss = 1.87986887, grad/param norm = 1.9470e-01, time/batch = 0.6482s	
2134/29850 (epoch 3.575), train_loss = 1.80411013, grad/param norm = 2.0523e-01, time/batch = 0.6420s	
2135/29850 (epoch 3.576), train_loss = 1.86802249, grad/param norm = 1.9668e-01, time/batch = 0.6476s	
2136/29850 (epoch 3.578), train_loss = 1.81610075, grad/param norm = 1.9817e-01, time/batch = 0.6490s	
2137/29850 (epoch 3.580), train_loss = 1.77707345, grad/param norm = 1.9010e-01, time/batch = 0.6478s	
2138/29850 (epoch 3.581), train_loss = 1.74061384, grad/param norm = 2.1022e-01, time/batch = 0.6485s	
2139/29850 (epoch 3.583), train_loss = 1.65094513, grad/param norm = 1.7856e-01, time/batch = 0.6444s	
2140/29850 (epoch 3.585), train_loss = 1.66043077, grad/param norm = 1.9141e-01, time/batch = 0.6421s	
2141/29850 (epoch 3.586), train_loss = 1.70791504, grad/param norm = 2.0649e-01, time/batch = 0.6481s	
2142/29850 (epoch 3.588), train_loss = 1.70573582, grad/param norm = 1.9770e-01, time/batch = 0.6606s	
2143/29850 (epoch 3.590), train_loss = 1.80691824, grad/param norm = 2.1291e-01, time/batch = 0.6429s	
2144/29850 (epoch 3.591), train_loss = 1.65869950, grad/param norm = 1.9095e-01, time/batch = 0.6536s	
2145/29850 (epoch 3.593), train_loss = 1.69181589, grad/param norm = 1.9346e-01, time/batch = 0.6379s	
2146/29850 (epoch 3.595), train_loss = 1.64802695, grad/param norm = 1.8746e-01, time/batch = 0.6504s	
2147/29850 (epoch 3.596), train_loss = 1.64390486, grad/param norm = 1.9491e-01, time/batch = 0.6440s	
2148/29850 (epoch 3.598), train_loss = 1.62989051, grad/param norm = 2.3909e-01, time/batch = 0.6419s	
2149/29850 (epoch 3.600), train_loss = 1.84686348, grad/param norm = 2.1625e-01, time/batch = 0.6562s	
2150/29850 (epoch 3.601), train_loss = 1.60689897, grad/param norm = 1.7634e-01, time/batch = 0.6674s	
2151/29850 (epoch 3.603), train_loss = 1.78218287, grad/param norm = 1.9199e-01, time/batch = 0.6764s	
2152/29850 (epoch 3.605), train_loss = 1.83933654, grad/param norm = 2.1189e-01, time/batch = 0.6608s	
2153/29850 (epoch 3.606), train_loss = 1.58226840, grad/param norm = 1.8661e-01, time/batch = 0.6458s	
2154/29850 (epoch 3.608), train_loss = 1.72593235, grad/param norm = 1.9536e-01, time/batch = 0.6446s	
2155/29850 (epoch 3.610), train_loss = 1.71456566, grad/param norm = 1.9405e-01, time/batch = 0.6508s	
2156/29850 (epoch 3.611), train_loss = 1.49499136, grad/param norm = 1.7893e-01, time/batch = 0.6460s	
2157/29850 (epoch 3.613), train_loss = 1.52746830, grad/param norm = 1.7901e-01, time/batch = 0.6452s	
2158/29850 (epoch 3.615), train_loss = 1.59259816, grad/param norm = 1.9349e-01, time/batch = 0.6428s	
2159/29850 (epoch 3.616), train_loss = 1.77080330, grad/param norm = 2.1400e-01, time/batch = 0.6424s	
2160/29850 (epoch 3.618), train_loss = 1.73227521, grad/param norm = 1.9030e-01, time/batch = 0.6483s	
2161/29850 (epoch 3.620), train_loss = 1.72618736, grad/param norm = 1.9262e-01, time/batch = 0.6716s	
2162/29850 (epoch 3.621), train_loss = 1.75442088, grad/param norm = 2.3213e-01, time/batch = 0.6758s	
2163/29850 (epoch 3.623), train_loss = 1.77238638, grad/param norm = 2.2197e-01, time/batch = 0.6548s	
2164/29850 (epoch 3.625), train_loss = 1.83017510, grad/param norm = 2.1884e-01, time/batch = 0.6432s	
2165/29850 (epoch 3.626), train_loss = 1.82746953, grad/param norm = 2.0589e-01, time/batch = 0.6484s	
2166/29850 (epoch 3.628), train_loss = 1.53890223, grad/param norm = 2.0621e-01, time/batch = 0.6481s	
2167/29850 (epoch 3.630), train_loss = 1.73265576, grad/param norm = 2.1683e-01, time/batch = 0.6489s	
2168/29850 (epoch 3.631), train_loss = 1.60597620, grad/param norm = 1.9897e-01, time/batch = 0.6536s	
2169/29850 (epoch 3.633), train_loss = 1.84268861, grad/param norm = 2.1519e-01, time/batch = 0.6460s	
2170/29850 (epoch 3.635), train_loss = 1.77355006, grad/param norm = 2.1861e-01, time/batch = 0.6443s	
2171/29850 (epoch 3.637), train_loss = 1.87848321, grad/param norm = 2.2868e-01, time/batch = 0.6524s	
2172/29850 (epoch 3.638), train_loss = 1.59966851, grad/param norm = 1.7957e-01, time/batch = 0.6430s	
2173/29850 (epoch 3.640), train_loss = 1.91958446, grad/param norm = 1.9297e-01, time/batch = 0.6400s	
2174/29850 (epoch 3.642), train_loss = 1.69734028, grad/param norm = 1.9442e-01, time/batch = 0.6399s	
2175/29850 (epoch 3.643), train_loss = 1.64474249, grad/param norm = 1.7954e-01, time/batch = 0.6617s	
2176/29850 (epoch 3.645), train_loss = 1.74022645, grad/param norm = 1.8403e-01, time/batch = 0.6632s	
2177/29850 (epoch 3.647), train_loss = 1.82556671, grad/param norm = 1.9595e-01, time/batch = 0.6413s	
2178/29850 (epoch 3.648), train_loss = 1.54854947, grad/param norm = 1.8284e-01, time/batch = 0.6433s	
2179/29850 (epoch 3.650), train_loss = 1.75176645, grad/param norm = 2.1296e-01, time/batch = 0.6448s	
2180/29850 (epoch 3.652), train_loss = 1.69045002, grad/param norm = 2.0760e-01, time/batch = 0.6505s	
2181/29850 (epoch 3.653), train_loss = 1.83006003, grad/param norm = 2.1947e-01, time/batch = 0.6499s	
2182/29850 (epoch 3.655), train_loss = 1.68881833, grad/param norm = 2.0555e-01, time/batch = 0.6391s	
2183/29850 (epoch 3.657), train_loss = 1.64468027, grad/param norm = 1.8693e-01, time/batch = 0.6448s	
2184/29850 (epoch 3.658), train_loss = 1.78156909, grad/param norm = 1.9725e-01, time/batch = 0.6444s	
2185/29850 (epoch 3.660), train_loss = 1.56269749, grad/param norm = 2.0134e-01, time/batch = 0.6410s	
2186/29850 (epoch 3.662), train_loss = 1.74262553, grad/param norm = 2.2810e-01, time/batch = 0.6686s	
2187/29850 (epoch 3.663), train_loss = 1.76201874, grad/param norm = 2.1841e-01, time/batch = 0.6560s	
2188/29850 (epoch 3.665), train_loss = 1.75204910, grad/param norm = 1.9143e-01, time/batch = 0.6424s	
2189/29850 (epoch 3.667), train_loss = 1.81493823, grad/param norm = 2.1367e-01, time/batch = 0.6433s	
2190/29850 (epoch 3.668), train_loss = 1.83688650, grad/param norm = 2.0818e-01, time/batch = 0.6391s	
2191/29850 (epoch 3.670), train_loss = 2.03936623, grad/param norm = 2.1728e-01, time/batch = 0.6472s	
2192/29850 (epoch 3.672), train_loss = 1.77319286, grad/param norm = 2.0523e-01, time/batch = 0.6435s	
2193/29850 (epoch 3.673), train_loss = 1.80244789, grad/param norm = 1.9051e-01, time/batch = 0.6446s	
2194/29850 (epoch 3.675), train_loss = 1.72700219, grad/param norm = 1.9816e-01, time/batch = 0.6442s	
2195/29850 (epoch 3.677), train_loss = 1.74297347, grad/param norm = 1.8484e-01, time/batch = 0.6430s	
2196/29850 (epoch 3.678), train_loss = 1.65862239, grad/param norm = 1.8788e-01, time/batch = 0.6512s	
2197/29850 (epoch 3.680), train_loss = 1.72973091, grad/param norm = 2.0387e-01, time/batch = 0.6710s	
2198/29850 (epoch 3.682), train_loss = 1.71051928, grad/param norm = 1.8625e-01, time/batch = 0.6537s	
2199/29850 (epoch 3.683), train_loss = 1.93875234, grad/param norm = 2.2805e-01, time/batch = 0.6496s	
2200/29850 (epoch 3.685), train_loss = 1.89182270, grad/param norm = 1.9858e-01, time/batch = 0.6436s	
2201/29850 (epoch 3.687), train_loss = 1.80504872, grad/param norm = 2.0154e-01, time/batch = 0.6477s	
2202/29850 (epoch 3.688), train_loss = 1.56682455, grad/param norm = 1.6881e-01, time/batch = 0.6464s	
2203/29850 (epoch 3.690), train_loss = 1.66271492, grad/param norm = 2.1442e-01, time/batch = 0.6577s	
2204/29850 (epoch 3.692), train_loss = 1.96367986, grad/param norm = 2.3789e-01, time/batch = 0.6481s	
2205/29850 (epoch 3.693), train_loss = 1.71626787, grad/param norm = 1.8442e-01, time/batch = 0.6441s	
2206/29850 (epoch 3.695), train_loss = 1.70051193, grad/param norm = 1.9676e-01, time/batch = 0.6455s	
2207/29850 (epoch 3.697), train_loss = 1.87542378, grad/param norm = 2.5308e-01, time/batch = 0.6425s	
2208/29850 (epoch 3.698), train_loss = 1.79003521, grad/param norm = 2.0459e-01, time/batch = 0.6447s	
2209/29850 (epoch 3.700), train_loss = 1.83783309, grad/param norm = 2.1958e-01, time/batch = 0.6443s	
2210/29850 (epoch 3.702), train_loss = 1.65684627, grad/param norm = 2.0485e-01, time/batch = 0.6441s	
2211/29850 (epoch 3.704), train_loss = 1.71699099, grad/param norm = 1.9354e-01, time/batch = 0.6491s	
2212/29850 (epoch 3.705), train_loss = 1.72316484, grad/param norm = 1.8268e-01, time/batch = 0.6463s	
2213/29850 (epoch 3.707), train_loss = 1.82466865, grad/param norm = 2.0029e-01, time/batch = 0.6444s	
2214/29850 (epoch 3.709), train_loss = 1.88539412, grad/param norm = 1.9822e-01, time/batch = 0.6477s	
2215/29850 (epoch 3.710), train_loss = 1.72199673, grad/param norm = 1.9796e-01, time/batch = 0.6435s	
2216/29850 (epoch 3.712), train_loss = 1.70933706, grad/param norm = 1.8055e-01, time/batch = 0.6408s	
2217/29850 (epoch 3.714), train_loss = 1.74485020, grad/param norm = 2.1891e-01, time/batch = 0.6430s	
2218/29850 (epoch 3.715), train_loss = 1.83640536, grad/param norm = 2.0921e-01, time/batch = 0.6409s	
2219/29850 (epoch 3.717), train_loss = 1.65438383, grad/param norm = 1.9542e-01, time/batch = 0.6646s	
2220/29850 (epoch 3.719), train_loss = 1.74129651, grad/param norm = 2.0123e-01, time/batch = 0.6578s	
2221/29850 (epoch 3.720), train_loss = 1.77645612, grad/param norm = 1.9583e-01, time/batch = 0.6632s	
2222/29850 (epoch 3.722), train_loss = 1.66330424, grad/param norm = 1.8380e-01, time/batch = 0.6528s	
2223/29850 (epoch 3.724), train_loss = 1.68335290, grad/param norm = 1.8743e-01, time/batch = 0.6568s	
2224/29850 (epoch 3.725), train_loss = 1.59063626, grad/param norm = 1.8457e-01, time/batch = 0.6435s	
2225/29850 (epoch 3.727), train_loss = 1.69898141, grad/param norm = 1.9735e-01, time/batch = 0.6466s	
2226/29850 (epoch 3.729), train_loss = 1.50873704, grad/param norm = 1.9416e-01, time/batch = 0.6451s	
2227/29850 (epoch 3.730), train_loss = 1.63399536, grad/param norm = 1.9320e-01, time/batch = 0.6436s	
2228/29850 (epoch 3.732), train_loss = 1.60148324, grad/param norm = 1.7493e-01, time/batch = 0.6549s	
2229/29850 (epoch 3.734), train_loss = 1.87811143, grad/param norm = 2.1543e-01, time/batch = 0.6449s	
2230/29850 (epoch 3.735), train_loss = 1.78744025, grad/param norm = 1.8612e-01, time/batch = 0.6501s	
2231/29850 (epoch 3.737), train_loss = 1.57710061, grad/param norm = 1.8441e-01, time/batch = 0.6446s	
2232/29850 (epoch 3.739), train_loss = 1.64993834, grad/param norm = 1.9051e-01, time/batch = 0.6413s	
2233/29850 (epoch 3.740), train_loss = 1.63649638, grad/param norm = 2.1741e-01, time/batch = 0.6477s	
2234/29850 (epoch 3.742), train_loss = 1.63319283, grad/param norm = 2.1219e-01, time/batch = 0.6595s	
2235/29850 (epoch 3.744), train_loss = 1.70970318, grad/param norm = 2.0605e-01, time/batch = 0.6475s	
2236/29850 (epoch 3.745), train_loss = 1.72349927, grad/param norm = 1.9050e-01, time/batch = 0.6557s	
2237/29850 (epoch 3.747), train_loss = 1.64246942, grad/param norm = 1.9757e-01, time/batch = 0.6550s	
2238/29850 (epoch 3.749), train_loss = 1.62800663, grad/param norm = 1.8151e-01, time/batch = 0.6413s	
2239/29850 (epoch 3.750), train_loss = 1.76149246, grad/param norm = 2.0809e-01, time/batch = 0.6418s	
2240/29850 (epoch 3.752), train_loss = 1.70635906, grad/param norm = 1.8966e-01, time/batch = 0.6445s	
2241/29850 (epoch 3.754), train_loss = 1.64137584, grad/param norm = 1.9281e-01, time/batch = 0.6661s	
2242/29850 (epoch 3.755), train_loss = 1.73245333, grad/param norm = 1.9305e-01, time/batch = 0.6780s	
2243/29850 (epoch 3.757), train_loss = 1.62293474, grad/param norm = 1.8507e-01, time/batch = 0.6743s	
2244/29850 (epoch 3.759), train_loss = 1.76471787, grad/param norm = 1.7490e-01, time/batch = 0.6600s	
2245/29850 (epoch 3.760), train_loss = 1.55233189, grad/param norm = 1.8384e-01, time/batch = 0.6623s	
2246/29850 (epoch 3.762), train_loss = 1.60922911, grad/param norm = 1.7811e-01, time/batch = 0.6603s	
2247/29850 (epoch 3.764), train_loss = 1.73401916, grad/param norm = 1.9661e-01, time/batch = 0.6449s	
2248/29850 (epoch 3.765), train_loss = 1.69191178, grad/param norm = 2.0684e-01, time/batch = 0.6477s	
2249/29850 (epoch 3.767), train_loss = 1.77818595, grad/param norm = 1.8637e-01, time/batch = 0.6445s	
2250/29850 (epoch 3.769), train_loss = 1.61961225, grad/param norm = 1.8833e-01, time/batch = 0.6471s	
2251/29850 (epoch 3.771), train_loss = 1.73903450, grad/param norm = 2.0742e-01, time/batch = 0.6533s	
2252/29850 (epoch 3.772), train_loss = 1.82521186, grad/param norm = 1.9464e-01, time/batch = 0.6533s	
2253/29850 (epoch 3.774), train_loss = 1.66799619, grad/param norm = 1.8986e-01, time/batch = 0.6503s	
2254/29850 (epoch 3.776), train_loss = 1.68185294, grad/param norm = 2.2058e-01, time/batch = 0.6601s	
2255/29850 (epoch 3.777), train_loss = 1.78561347, grad/param norm = 1.9857e-01, time/batch = 0.6605s	
2256/29850 (epoch 3.779), train_loss = 1.57096126, grad/param norm = 1.9513e-01, time/batch = 0.6671s	
2257/29850 (epoch 3.781), train_loss = 1.61479554, grad/param norm = 1.9310e-01, time/batch = 0.6573s	
2258/29850 (epoch 3.782), train_loss = 1.65078377, grad/param norm = 1.7946e-01, time/batch = 0.6525s	
2259/29850 (epoch 3.784), train_loss = 1.65636700, grad/param norm = 2.0052e-01, time/batch = 0.6507s	
2260/29850 (epoch 3.786), train_loss = 1.64642841, grad/param norm = 2.0898e-01, time/batch = 0.6593s	
2261/29850 (epoch 3.787), train_loss = 1.66489634, grad/param norm = 1.9648e-01, time/batch = 0.6539s	
2262/29850 (epoch 3.789), train_loss = 1.61741322, grad/param norm = 1.9070e-01, time/batch = 0.6444s	
2263/29850 (epoch 3.791), train_loss = 1.76806042, grad/param norm = 2.1021e-01, time/batch = 0.6425s	
2264/29850 (epoch 3.792), train_loss = 1.74405417, grad/param norm = 2.2900e-01, time/batch = 0.6412s	
2265/29850 (epoch 3.794), train_loss = 1.73460996, grad/param norm = 2.0237e-01, time/batch = 0.6480s	
2266/29850 (epoch 3.796), train_loss = 1.62535396, grad/param norm = 2.0177e-01, time/batch = 0.6658s	
2267/29850 (epoch 3.797), train_loss = 1.69097920, grad/param norm = 1.7835e-01, time/batch = 0.6580s	
2268/29850 (epoch 3.799), train_loss = 1.63216988, grad/param norm = 1.7443e-01, time/batch = 0.6547s	
2269/29850 (epoch 3.801), train_loss = 1.81700079, grad/param norm = 2.0470e-01, time/batch = 0.6423s	
2270/29850 (epoch 3.802), train_loss = 1.61297714, grad/param norm = 1.9633e-01, time/batch = 0.6518s	
2271/29850 (epoch 3.804), train_loss = 1.73521955, grad/param norm = 1.9080e-01, time/batch = 0.6574s	
2272/29850 (epoch 3.806), train_loss = 1.72477672, grad/param norm = 1.7746e-01, time/batch = 0.6427s	
2273/29850 (epoch 3.807), train_loss = 1.54768473, grad/param norm = 1.7832e-01, time/batch = 0.6425s	
2274/29850 (epoch 3.809), train_loss = 1.76000033, grad/param norm = 2.2930e-01, time/batch = 0.6427s	
2275/29850 (epoch 3.811), train_loss = 1.80511786, grad/param norm = 1.9607e-01, time/batch = 0.6546s	
2276/29850 (epoch 3.812), train_loss = 1.71553635, grad/param norm = 2.0343e-01, time/batch = 0.6536s	
2277/29850 (epoch 3.814), train_loss = 1.76384430, grad/param norm = 1.9441e-01, time/batch = 0.6446s	
2278/29850 (epoch 3.816), train_loss = 1.73923651, grad/param norm = 1.9093e-01, time/batch = 0.6458s	
2279/29850 (epoch 3.817), train_loss = 1.77751582, grad/param norm = 2.0645e-01, time/batch = 0.6472s	
2280/29850 (epoch 3.819), train_loss = 1.69298557, grad/param norm = 2.0487e-01, time/batch = 0.6498s	
2281/29850 (epoch 3.821), train_loss = 1.85033183, grad/param norm = 2.1945e-01, time/batch = 0.6419s	
2282/29850 (epoch 3.822), train_loss = 1.61611920, grad/param norm = 1.7839e-01, time/batch = 0.6387s	
2283/29850 (epoch 3.824), train_loss = 1.71162504, grad/param norm = 2.0371e-01, time/batch = 0.6628s	
2284/29850 (epoch 3.826), train_loss = 1.70583608, grad/param norm = 2.0339e-01, time/batch = 0.6481s	
2285/29850 (epoch 3.827), train_loss = 1.63042350, grad/param norm = 1.8824e-01, time/batch = 0.6490s	
2286/29850 (epoch 3.829), train_loss = 1.70512043, grad/param norm = 2.0474e-01, time/batch = 0.6619s	
2287/29850 (epoch 3.831), train_loss = 1.70598333, grad/param norm = 2.1490e-01, time/batch = 0.6533s	
2288/29850 (epoch 3.832), train_loss = 1.58936849, grad/param norm = 1.9218e-01, time/batch = 0.6441s	
2289/29850 (epoch 3.834), train_loss = 1.58202634, grad/param norm = 1.8955e-01, time/batch = 0.6588s	
2290/29850 (epoch 3.836), train_loss = 1.60578250, grad/param norm = 1.7730e-01, time/batch = 0.6635s	
2291/29850 (epoch 3.838), train_loss = 1.78608146, grad/param norm = 2.0551e-01, time/batch = 0.6618s	
2292/29850 (epoch 3.839), train_loss = 1.72907959, grad/param norm = 1.9674e-01, time/batch = 0.6599s	
2293/29850 (epoch 3.841), train_loss = 1.72208999, grad/param norm = 1.8732e-01, time/batch = 0.6586s	
2294/29850 (epoch 3.843), train_loss = 1.71136092, grad/param norm = 1.9446e-01, time/batch = 0.6645s	
2295/29850 (epoch 3.844), train_loss = 1.69162707, grad/param norm = 1.9738e-01, time/batch = 0.6595s	
2296/29850 (epoch 3.846), train_loss = 1.79028048, grad/param norm = 2.1308e-01, time/batch = 0.6580s	
2297/29850 (epoch 3.848), train_loss = 1.78170340, grad/param norm = 2.0419e-01, time/batch = 0.6606s	
2298/29850 (epoch 3.849), train_loss = 1.59780266, grad/param norm = 2.2498e-01, time/batch = 0.6398s	
2299/29850 (epoch 3.851), train_loss = 1.75288726, grad/param norm = 2.2003e-01, time/batch = 0.6564s	
2300/29850 (epoch 3.853), train_loss = 1.65791253, grad/param norm = 2.2774e-01, time/batch = 0.6530s	
2301/29850 (epoch 3.854), train_loss = 1.71005013, grad/param norm = 2.1846e-01, time/batch = 0.6477s	
2302/29850 (epoch 3.856), train_loss = 1.72207489, grad/param norm = 2.1301e-01, time/batch = 0.6491s	
2303/29850 (epoch 3.858), train_loss = 1.68797878, grad/param norm = 1.9113e-01, time/batch = 0.6464s	
2304/29850 (epoch 3.859), train_loss = 1.66329850, grad/param norm = 2.1933e-01, time/batch = 0.6540s	
2305/29850 (epoch 3.861), train_loss = 1.83807859, grad/param norm = 2.2529e-01, time/batch = 0.6483s	
2306/29850 (epoch 3.863), train_loss = 1.78323158, grad/param norm = 1.8286e-01, time/batch = 0.6465s	
2307/29850 (epoch 3.864), train_loss = 1.69030633, grad/param norm = 1.9244e-01, time/batch = 0.6445s	
2308/29850 (epoch 3.866), train_loss = 1.65630060, grad/param norm = 1.8849e-01, time/batch = 0.6464s	
2309/29850 (epoch 3.868), train_loss = 1.75271520, grad/param norm = 1.9253e-01, time/batch = 0.6455s	
2310/29850 (epoch 3.869), train_loss = 1.62711122, grad/param norm = 1.9981e-01, time/batch = 0.6479s	
2311/29850 (epoch 3.871), train_loss = 1.70858937, grad/param norm = 1.9778e-01, time/batch = 0.6487s	
2312/29850 (epoch 3.873), train_loss = 1.81652749, grad/param norm = 2.2062e-01, time/batch = 0.6483s	
2313/29850 (epoch 3.874), train_loss = 1.74447310, grad/param norm = 1.9967e-01, time/batch = 0.6569s	
2314/29850 (epoch 3.876), train_loss = 1.79531225, grad/param norm = 2.2661e-01, time/batch = 0.6513s	
2315/29850 (epoch 3.878), train_loss = 1.66947955, grad/param norm = 1.9587e-01, time/batch = 0.6452s	
2316/29850 (epoch 3.879), train_loss = 1.81502503, grad/param norm = 1.9388e-01, time/batch = 0.6460s	
2317/29850 (epoch 3.881), train_loss = 1.78040609, grad/param norm = 1.9632e-01, time/batch = 0.6458s	
2318/29850 (epoch 3.883), train_loss = 1.80659744, grad/param norm = 2.1262e-01, time/batch = 0.6468s	
2319/29850 (epoch 3.884), train_loss = 1.56913636, grad/param norm = 1.8455e-01, time/batch = 0.6491s	
2320/29850 (epoch 3.886), train_loss = 1.94287479, grad/param norm = 2.0335e-01, time/batch = 0.6566s	
2321/29850 (epoch 3.888), train_loss = 1.64897742, grad/param norm = 1.8928e-01, time/batch = 0.6502s	
2322/29850 (epoch 3.889), train_loss = 1.61168311, grad/param norm = 2.0205e-01, time/batch = 0.6446s	
2323/29850 (epoch 3.891), train_loss = 1.63376044, grad/param norm = 1.9058e-01, time/batch = 0.6504s	
2324/29850 (epoch 3.893), train_loss = 1.59838177, grad/param norm = 1.8989e-01, time/batch = 0.6502s	
2325/29850 (epoch 3.894), train_loss = 1.63529925, grad/param norm = 1.8276e-01, time/batch = 0.6550s	
2326/29850 (epoch 3.896), train_loss = 1.61818554, grad/param norm = 2.0939e-01, time/batch = 0.6683s	
2327/29850 (epoch 3.898), train_loss = 1.79351720, grad/param norm = 2.0658e-01, time/batch = 0.6721s	
2328/29850 (epoch 3.899), train_loss = 1.54074585, grad/param norm = 2.0684e-01, time/batch = 0.6674s	
2329/29850 (epoch 3.901), train_loss = 2.05668843, grad/param norm = 2.3075e-01, time/batch = 0.6654s	
2330/29850 (epoch 3.903), train_loss = 1.80063322, grad/param norm = 2.2886e-01, time/batch = 0.6736s	
2331/29850 (epoch 3.905), train_loss = 1.84384359, grad/param norm = 2.2591e-01, time/batch = 0.6540s	
2332/29850 (epoch 3.906), train_loss = 1.56113661, grad/param norm = 1.9921e-01, time/batch = 0.6441s	
2333/29850 (epoch 3.908), train_loss = 1.84326264, grad/param norm = 2.1649e-01, time/batch = 0.6596s	
2334/29850 (epoch 3.910), train_loss = 1.81231112, grad/param norm = 1.9314e-01, time/batch = 0.6717s	
2335/29850 (epoch 3.911), train_loss = 1.80267492, grad/param norm = 2.0362e-01, time/batch = 0.6859s	
2336/29850 (epoch 3.913), train_loss = 1.67888806, grad/param norm = 1.8706e-01, time/batch = 0.6642s	
2337/29850 (epoch 3.915), train_loss = 1.72849269, grad/param norm = 1.9197e-01, time/batch = 0.6555s	
2338/29850 (epoch 3.916), train_loss = 1.65390233, grad/param norm = 1.8993e-01, time/batch = 0.6581s	
2339/29850 (epoch 3.918), train_loss = 1.61712424, grad/param norm = 1.7599e-01, time/batch = 0.6563s	
2340/29850 (epoch 3.920), train_loss = 1.76121348, grad/param norm = 1.8599e-01, time/batch = 0.6582s	
2341/29850 (epoch 3.921), train_loss = 1.77228635, grad/param norm = 2.1214e-01, time/batch = 0.6621s	
2342/29850 (epoch 3.923), train_loss = 1.75787515, grad/param norm = 1.9351e-01, time/batch = 0.6671s	
2343/29850 (epoch 3.925), train_loss = 1.85095009, grad/param norm = 2.1538e-01, time/batch = 0.6584s	
2344/29850 (epoch 3.926), train_loss = 1.83686280, grad/param norm = 2.0597e-01, time/batch = 0.6595s	
2345/29850 (epoch 3.928), train_loss = 1.67492541, grad/param norm = 2.0168e-01, time/batch = 0.6532s	
2346/29850 (epoch 3.930), train_loss = 1.84546251, grad/param norm = 1.9248e-01, time/batch = 0.6453s	
2347/29850 (epoch 3.931), train_loss = 1.81729023, grad/param norm = 1.9397e-01, time/batch = 0.6463s	
2348/29850 (epoch 3.933), train_loss = 1.88409308, grad/param norm = 2.0302e-01, time/batch = 0.6468s	
2349/29850 (epoch 3.935), train_loss = 1.86473594, grad/param norm = 1.9304e-01, time/batch = 0.6526s	
2350/29850 (epoch 3.936), train_loss = 1.81726377, grad/param norm = 2.0869e-01, time/batch = 0.6530s	
2351/29850 (epoch 3.938), train_loss = 1.59228448, grad/param norm = 1.7550e-01, time/batch = 0.6663s	
2352/29850 (epoch 3.940), train_loss = 1.53845592, grad/param norm = 1.8265e-01, time/batch = 0.6533s	
2353/29850 (epoch 3.941), train_loss = 1.71118326, grad/param norm = 2.0355e-01, time/batch = 0.6492s	
2354/29850 (epoch 3.943), train_loss = 1.67207985, grad/param norm = 1.9885e-01, time/batch = 0.6525s	
2355/29850 (epoch 3.945), train_loss = 1.81099747, grad/param norm = 2.2203e-01, time/batch = 0.6518s	
2356/29850 (epoch 3.946), train_loss = 1.62725609, grad/param norm = 2.2956e-01, time/batch = 0.6645s	
2357/29850 (epoch 3.948), train_loss = 1.61527889, grad/param norm = 1.7326e-01, time/batch = 0.6716s	
2358/29850 (epoch 3.950), train_loss = 1.61536420, grad/param norm = 1.7772e-01, time/batch = 0.6753s	
2359/29850 (epoch 3.951), train_loss = 1.62525352, grad/param norm = 1.9843e-01, time/batch = 0.6748s	
2360/29850 (epoch 3.953), train_loss = 1.76650341, grad/param norm = 2.0255e-01, time/batch = 0.6735s	
2361/29850 (epoch 3.955), train_loss = 1.53941150, grad/param norm = 1.7137e-01, time/batch = 0.6768s	
2362/29850 (epoch 3.956), train_loss = 1.60106824, grad/param norm = 1.9420e-01, time/batch = 0.6721s	
2363/29850 (epoch 3.958), train_loss = 1.47542726, grad/param norm = 1.7095e-01, time/batch = 0.6710s	
2364/29850 (epoch 3.960), train_loss = 1.76711612, grad/param norm = 2.0521e-01, time/batch = 0.6697s	
2365/29850 (epoch 3.961), train_loss = 1.69055273, grad/param norm = 1.9530e-01, time/batch = 0.6640s	
2366/29850 (epoch 3.963), train_loss = 1.53001856, grad/param norm = 1.8347e-01, time/batch = 0.6456s	
2367/29850 (epoch 3.965), train_loss = 1.66231718, grad/param norm = 2.0462e-01, time/batch = 0.6436s	
2368/29850 (epoch 3.966), train_loss = 1.59836147, grad/param norm = 2.0078e-01, time/batch = 0.6472s	
2369/29850 (epoch 3.968), train_loss = 1.65802474, grad/param norm = 2.0346e-01, time/batch = 0.6535s	
2370/29850 (epoch 3.970), train_loss = 1.61051319, grad/param norm = 1.8648e-01, time/batch = 0.6447s	
2371/29850 (epoch 3.972), train_loss = 1.56984262, grad/param norm = 1.9343e-01, time/batch = 0.6455s	
2372/29850 (epoch 3.973), train_loss = 1.68667696, grad/param norm = 2.1118e-01, time/batch = 0.6706s	
2373/29850 (epoch 3.975), train_loss = 1.45401802, grad/param norm = 1.8040e-01, time/batch = 0.6525s	
2374/29850 (epoch 3.977), train_loss = 1.62245288, grad/param norm = 1.9667e-01, time/batch = 0.6428s	
2375/29850 (epoch 3.978), train_loss = 1.59118101, grad/param norm = 1.8103e-01, time/batch = 0.6395s	
2376/29850 (epoch 3.980), train_loss = 1.53952062, grad/param norm = 1.8580e-01, time/batch = 0.6429s	
2377/29850 (epoch 3.982), train_loss = 1.55468934, grad/param norm = 1.9650e-01, time/batch = 0.6443s	
2378/29850 (epoch 3.983), train_loss = 1.71175855, grad/param norm = 2.0528e-01, time/batch = 0.6554s	
2379/29850 (epoch 3.985), train_loss = 1.74532926, grad/param norm = 1.9982e-01, time/batch = 0.6517s	
2380/29850 (epoch 3.987), train_loss = 1.54954767, grad/param norm = 2.1472e-01, time/batch = 0.6555s	
2381/29850 (epoch 3.988), train_loss = 1.52956660, grad/param norm = 1.8749e-01, time/batch = 0.6642s	
2382/29850 (epoch 3.990), train_loss = 1.59606304, grad/param norm = 1.8669e-01, time/batch = 0.6594s	
2383/29850 (epoch 3.992), train_loss = 1.64875384, grad/param norm = 1.8992e-01, time/batch = 0.6739s	
2384/29850 (epoch 3.993), train_loss = 1.72681494, grad/param norm = 2.0168e-01, time/batch = 0.6719s	
2385/29850 (epoch 3.995), train_loss = 1.69734052, grad/param norm = 2.0572e-01, time/batch = 0.6639s	
2386/29850 (epoch 3.997), train_loss = 1.67663914, grad/param norm = 2.0210e-01, time/batch = 0.6497s	
2387/29850 (epoch 3.998), train_loss = 1.80330363, grad/param norm = 1.9406e-01, time/batch = 0.6468s	
2388/29850 (epoch 4.000), train_loss = 1.67441048, grad/param norm = 1.8492e-01, time/batch = 0.6570s	
2389/29850 (epoch 4.002), train_loss = 1.86422690, grad/param norm = 2.0872e-01, time/batch = 0.6597s	
2390/29850 (epoch 4.003), train_loss = 1.61971057, grad/param norm = 1.8949e-01, time/batch = 0.6598s	
2391/29850 (epoch 4.005), train_loss = 1.65617261, grad/param norm = 1.8656e-01, time/batch = 0.6609s	
2392/29850 (epoch 4.007), train_loss = 1.72362803, grad/param norm = 2.0785e-01, time/batch = 0.6658s	
2393/29850 (epoch 4.008), train_loss = 1.85928970, grad/param norm = 1.9837e-01, time/batch = 0.6791s	
2394/29850 (epoch 4.010), train_loss = 1.57083049, grad/param norm = 1.9838e-01, time/batch = 0.6632s	
2395/29850 (epoch 4.012), train_loss = 1.78460541, grad/param norm = 1.9028e-01, time/batch = 0.6514s	
2396/29850 (epoch 4.013), train_loss = 1.81027085, grad/param norm = 2.1444e-01, time/batch = 0.6570s	
2397/29850 (epoch 4.015), train_loss = 1.72964260, grad/param norm = 1.9708e-01, time/batch = 0.6606s	
2398/29850 (epoch 4.017), train_loss = 1.82160299, grad/param norm = 2.2108e-01, time/batch = 0.6606s	
2399/29850 (epoch 4.018), train_loss = 1.90948670, grad/param norm = 2.4395e-01, time/batch = 0.6576s	
2400/29850 (epoch 4.020), train_loss = 1.56946455, grad/param norm = 1.9652e-01, time/batch = 0.6526s	
2401/29850 (epoch 4.022), train_loss = 1.75750426, grad/param norm = 2.0718e-01, time/batch = 0.6708s	
2402/29850 (epoch 4.023), train_loss = 1.65354344, grad/param norm = 1.9454e-01, time/batch = 0.6556s	
2403/29850 (epoch 4.025), train_loss = 1.66832689, grad/param norm = 1.7856e-01, time/batch = 0.6546s	
2404/29850 (epoch 4.027), train_loss = 1.58616439, grad/param norm = 1.8591e-01, time/batch = 0.6560s	
2405/29850 (epoch 4.028), train_loss = 1.68021889, grad/param norm = 1.8565e-01, time/batch = 0.6586s	
2406/29850 (epoch 4.030), train_loss = 1.78266295, grad/param norm = 1.8428e-01, time/batch = 0.6642s	
2407/29850 (epoch 4.032), train_loss = 1.61862768, grad/param norm = 1.9962e-01, time/batch = 0.6588s	
2408/29850 (epoch 4.034), train_loss = 1.74225124, grad/param norm = 1.9972e-01, time/batch = 0.6589s	
2409/29850 (epoch 4.035), train_loss = 1.66444079, grad/param norm = 2.0092e-01, time/batch = 0.6538s	
2410/29850 (epoch 4.037), train_loss = 1.73596315, grad/param norm = 1.8415e-01, time/batch = 0.6579s	
2411/29850 (epoch 4.039), train_loss = 1.57629668, grad/param norm = 1.8817e-01, time/batch = 0.6657s	
2412/29850 (epoch 4.040), train_loss = 1.52465768, grad/param norm = 1.7053e-01, time/batch = 0.6613s	
2413/29850 (epoch 4.042), train_loss = 1.65026446, grad/param norm = 2.0130e-01, time/batch = 0.6610s	
2414/29850 (epoch 4.044), train_loss = 1.50185641, grad/param norm = 1.9496e-01, time/batch = 0.6549s	
2415/29850 (epoch 4.045), train_loss = 1.72240798, grad/param norm = 1.9797e-01, time/batch = 0.6629s	
2416/29850 (epoch 4.047), train_loss = 1.52118131, grad/param norm = 1.8645e-01, time/batch = 0.6592s	
2417/29850 (epoch 4.049), train_loss = 1.65864588, grad/param norm = 2.1592e-01, time/batch = 0.6564s	
2418/29850 (epoch 4.050), train_loss = 1.54384809, grad/param norm = 1.7776e-01, time/batch = 0.6729s	
2419/29850 (epoch 4.052), train_loss = 1.90963415, grad/param norm = 2.2365e-01, time/batch = 0.6639s	
2420/29850 (epoch 4.054), train_loss = 1.72782085, grad/param norm = 2.0802e-01, time/batch = 0.6612s	
2421/29850 (epoch 4.055), train_loss = 1.67906447, grad/param norm = 2.0551e-01, time/batch = 0.6529s	
2422/29850 (epoch 4.057), train_loss = 1.64242024, grad/param norm = 1.9708e-01, time/batch = 0.6563s	
2423/29850 (epoch 4.059), train_loss = 1.73115795, grad/param norm = 1.9916e-01, time/batch = 0.6671s	
2424/29850 (epoch 4.060), train_loss = 1.65373526, grad/param norm = 2.0405e-01, time/batch = 0.6794s	
2425/29850 (epoch 4.062), train_loss = 1.80389009, grad/param norm = 2.1458e-01, time/batch = 0.6828s	
2426/29850 (epoch 4.064), train_loss = 1.65200252, grad/param norm = 1.8586e-01, time/batch = 0.6598s	
2427/29850 (epoch 4.065), train_loss = 1.52727554, grad/param norm = 1.8918e-01, time/batch = 0.6720s	
2428/29850 (epoch 4.067), train_loss = 1.62842577, grad/param norm = 1.8432e-01, time/batch = 0.6563s	
2429/29850 (epoch 4.069), train_loss = 1.59521227, grad/param norm = 1.8664e-01, time/batch = 0.6585s	
2430/29850 (epoch 4.070), train_loss = 1.63603686, grad/param norm = 1.7769e-01, time/batch = 0.6586s	
2431/29850 (epoch 4.072), train_loss = 1.78066584, grad/param norm = 2.1798e-01, time/batch = 0.6542s	
2432/29850 (epoch 4.074), train_loss = 1.73509088, grad/param norm = 2.1707e-01, time/batch = 0.6507s	
2433/29850 (epoch 4.075), train_loss = 1.58121366, grad/param norm = 1.9182e-01, time/batch = 0.6531s	
2434/29850 (epoch 4.077), train_loss = 1.55426135, grad/param norm = 1.9668e-01, time/batch = 0.6531s	
2435/29850 (epoch 4.079), train_loss = 1.83371001, grad/param norm = 2.0003e-01, time/batch = 0.6812s	
2436/29850 (epoch 4.080), train_loss = 1.80083036, grad/param norm = 2.1601e-01, time/batch = 0.6813s	
2437/29850 (epoch 4.082), train_loss = 1.62991179, grad/param norm = 1.7509e-01, time/batch = 0.6737s	
2438/29850 (epoch 4.084), train_loss = 1.66060423, grad/param norm = 1.8120e-01, time/batch = 0.6772s	
2439/29850 (epoch 4.085), train_loss = 1.61902421, grad/param norm = 1.8363e-01, time/batch = 0.6649s	
2440/29850 (epoch 4.087), train_loss = 1.74583245, grad/param norm = 1.8636e-01, time/batch = 0.6601s	
2441/29850 (epoch 4.089), train_loss = 1.76472114, grad/param norm = 1.8105e-01, time/batch = 0.6587s	
2442/29850 (epoch 4.090), train_loss = 1.68346418, grad/param norm = 2.0181e-01, time/batch = 0.6602s	
2443/29850 (epoch 4.092), train_loss = 1.59760614, grad/param norm = 2.0359e-01, time/batch = 0.6746s	
2444/29850 (epoch 4.094), train_loss = 1.67171227, grad/param norm = 1.9154e-01, time/batch = 0.6581s	
2445/29850 (epoch 4.095), train_loss = 1.75289081, grad/param norm = 2.1115e-01, time/batch = 0.6560s	
2446/29850 (epoch 4.097), train_loss = 1.50103056, grad/param norm = 1.7804e-01, time/batch = 0.6579s	
2447/29850 (epoch 4.099), train_loss = 1.53040646, grad/param norm = 1.8409e-01, time/batch = 0.6546s	
2448/29850 (epoch 4.101), train_loss = 1.79843104, grad/param norm = 2.1098e-01, time/batch = 0.6550s	
2449/29850 (epoch 4.102), train_loss = 1.63994940, grad/param norm = 1.9220e-01, time/batch = 0.6581s	
2450/29850 (epoch 4.104), train_loss = 1.62033165, grad/param norm = 1.7728e-01, time/batch = 0.6541s	
2451/29850 (epoch 4.106), train_loss = 1.72035930, grad/param norm = 1.9652e-01, time/batch = 0.6585s	
2452/29850 (epoch 4.107), train_loss = 1.60107760, grad/param norm = 1.8421e-01, time/batch = 0.6605s	
2453/29850 (epoch 4.109), train_loss = 1.59867170, grad/param norm = 1.8680e-01, time/batch = 0.6561s	
2454/29850 (epoch 4.111), train_loss = 1.76829458, grad/param norm = 2.2075e-01, time/batch = 0.6543s	
2455/29850 (epoch 4.112), train_loss = 1.58973736, grad/param norm = 1.9486e-01, time/batch = 0.6563s	
2456/29850 (epoch 4.114), train_loss = 1.80365146, grad/param norm = 2.1109e-01, time/batch = 0.6558s	
2457/29850 (epoch 4.116), train_loss = 1.62326071, grad/param norm = 2.0859e-01, time/batch = 0.6549s	
2458/29850 (epoch 4.117), train_loss = 1.70368408, grad/param norm = 1.7984e-01, time/batch = 0.6520s	
2459/29850 (epoch 4.119), train_loss = 1.64511268, grad/param norm = 1.7605e-01, time/batch = 0.6557s	
2460/29850 (epoch 4.121), train_loss = 1.47571504, grad/param norm = 1.7678e-01, time/batch = 0.6571s	
2461/29850 (epoch 4.122), train_loss = 1.53277343, grad/param norm = 1.8434e-01, time/batch = 0.6830s	
2462/29850 (epoch 4.124), train_loss = 1.53745482, grad/param norm = 1.7285e-01, time/batch = 0.6662s	
2463/29850 (epoch 4.126), train_loss = 1.65322995, grad/param norm = 1.8904e-01, time/batch = 0.6522s	
2464/29850 (epoch 4.127), train_loss = 1.90302417, grad/param norm = 2.0780e-01, time/batch = 0.6505s	
2465/29850 (epoch 4.129), train_loss = 1.62626163, grad/param norm = 2.0821e-01, time/batch = 0.6525s	
2466/29850 (epoch 4.131), train_loss = 1.60807162, grad/param norm = 1.8943e-01, time/batch = 0.6543s	
2467/29850 (epoch 4.132), train_loss = 1.65529385, grad/param norm = 2.0898e-01, time/batch = 0.6537s	
2468/29850 (epoch 4.134), train_loss = 1.73923936, grad/param norm = 1.9519e-01, time/batch = 0.6536s	
2469/29850 (epoch 4.136), train_loss = 1.71584067, grad/param norm = 2.0046e-01, time/batch = 0.6539s	
2470/29850 (epoch 4.137), train_loss = 1.63601767, grad/param norm = 1.9725e-01, time/batch = 0.6545s	
2471/29850 (epoch 4.139), train_loss = 1.59943276, grad/param norm = 2.0346e-01, time/batch = 0.6688s	
2472/29850 (epoch 4.141), train_loss = 1.63586239, grad/param norm = 1.8522e-01, time/batch = 0.6829s	
2473/29850 (epoch 4.142), train_loss = 1.72910109, grad/param norm = 2.0742e-01, time/batch = 0.6519s	
2474/29850 (epoch 4.144), train_loss = 1.82828507, grad/param norm = 1.8681e-01, time/batch = 0.6538s	
2475/29850 (epoch 4.146), train_loss = 1.77157495, grad/param norm = 2.0538e-01, time/batch = 0.6574s	
2476/29850 (epoch 4.147), train_loss = 1.78675132, grad/param norm = 2.0911e-01, time/batch = 0.6594s	
2477/29850 (epoch 4.149), train_loss = 1.73435055, grad/param norm = 2.1142e-01, time/batch = 0.6594s	
2478/29850 (epoch 4.151), train_loss = 1.66256996, grad/param norm = 2.1960e-01, time/batch = 0.6573s	
2479/29850 (epoch 4.152), train_loss = 1.59273197, grad/param norm = 1.9153e-01, time/batch = 0.6528s	
2480/29850 (epoch 4.154), train_loss = 1.63422306, grad/param norm = 1.9124e-01, time/batch = 0.6540s	
2481/29850 (epoch 4.156), train_loss = 1.54845063, grad/param norm = 1.8002e-01, time/batch = 0.6555s	
2482/29850 (epoch 4.157), train_loss = 1.64962407, grad/param norm = 1.7092e-01, time/batch = 0.6548s	
2483/29850 (epoch 4.159), train_loss = 1.67805198, grad/param norm = 1.8035e-01, time/batch = 0.6562s	
2484/29850 (epoch 4.161), train_loss = 1.76901330, grad/param norm = 2.0480e-01, time/batch = 0.6554s	
2485/29850 (epoch 4.162), train_loss = 1.76119787, grad/param norm = 2.0039e-01, time/batch = 0.6575s	
2486/29850 (epoch 4.164), train_loss = 1.60798735, grad/param norm = 2.0563e-01, time/batch = 0.6556s	
2487/29850 (epoch 4.166), train_loss = 1.57014214, grad/param norm = 1.9004e-01, time/batch = 0.6558s	
2488/29850 (epoch 4.168), train_loss = 1.45917763, grad/param norm = 1.8191e-01, time/batch = 0.6549s	
2489/29850 (epoch 4.169), train_loss = 1.86964763, grad/param norm = 2.1119e-01, time/batch = 0.6567s	
2490/29850 (epoch 4.171), train_loss = 1.82870468, grad/param norm = 1.9992e-01, time/batch = 0.6575s	
2491/29850 (epoch 4.173), train_loss = 1.68936461, grad/param norm = 1.8671e-01, time/batch = 0.6577s	
2492/29850 (epoch 4.174), train_loss = 1.77605353, grad/param norm = 1.9722e-01, time/batch = 0.6560s	
2493/29850 (epoch 4.176), train_loss = 1.76538580, grad/param norm = 2.1612e-01, time/batch = 0.6538s	
2494/29850 (epoch 4.178), train_loss = 1.77756154, grad/param norm = 1.9659e-01, time/batch = 0.6547s	
2495/29850 (epoch 4.179), train_loss = 1.47988194, grad/param norm = 1.9145e-01, time/batch = 0.6525s	
2496/29850 (epoch 4.181), train_loss = 1.57091760, grad/param norm = 1.8338e-01, time/batch = 0.6509s	
2497/29850 (epoch 4.183), train_loss = 1.58829320, grad/param norm = 1.9280e-01, time/batch = 0.6540s	
2498/29850 (epoch 4.184), train_loss = 1.59685185, grad/param norm = 1.8145e-01, time/batch = 0.6547s	
2499/29850 (epoch 4.186), train_loss = 1.58181040, grad/param norm = 2.0349e-01, time/batch = 0.6574s	
2500/29850 (epoch 4.188), train_loss = 1.68971101, grad/param norm = 2.1936e-01, time/batch = 0.6685s	
2501/29850 (epoch 4.189), train_loss = 1.81946912, grad/param norm = 2.0883e-01, time/batch = 0.6839s	
2502/29850 (epoch 4.191), train_loss = 1.68048749, grad/param norm = 2.0918e-01, time/batch = 0.6808s	
2503/29850 (epoch 4.193), train_loss = 1.49929536, grad/param norm = 1.7063e-01, time/batch = 0.6655s	
2504/29850 (epoch 4.194), train_loss = 1.73806634, grad/param norm = 2.5648e-01, time/batch = 0.6778s	
2505/29850 (epoch 4.196), train_loss = 1.64033055, grad/param norm = 2.0927e-01, time/batch = 0.6613s	
2506/29850 (epoch 4.198), train_loss = 1.60682211, grad/param norm = 1.6747e-01, time/batch = 0.6649s	
2507/29850 (epoch 4.199), train_loss = 1.88900660, grad/param norm = 1.9238e-01, time/batch = 0.6669s	
2508/29850 (epoch 4.201), train_loss = 1.73432569, grad/param norm = 2.3068e-01, time/batch = 0.6589s	
2509/29850 (epoch 4.203), train_loss = 1.72459784, grad/param norm = 2.1527e-01, time/batch = 0.6602s	
2510/29850 (epoch 4.204), train_loss = 1.66418195, grad/param norm = 2.0939e-01, time/batch = 0.6579s	
2511/29850 (epoch 4.206), train_loss = 1.59431608, grad/param norm = 1.9260e-01, time/batch = 0.6679s	
2512/29850 (epoch 4.208), train_loss = 1.87011941, grad/param norm = 1.8964e-01, time/batch = 0.6648s	
2513/29850 (epoch 4.209), train_loss = 1.57616327, grad/param norm = 2.0524e-01, time/batch = 0.6682s	
2514/29850 (epoch 4.211), train_loss = 1.56884423, grad/param norm = 1.6862e-01, time/batch = 0.6823s	
2515/29850 (epoch 4.213), train_loss = 1.83388665, grad/param norm = 1.9751e-01, time/batch = 0.6858s	
2516/29850 (epoch 4.214), train_loss = 1.60166517, grad/param norm = 1.9180e-01, time/batch = 0.6697s	
2517/29850 (epoch 4.216), train_loss = 1.67413233, grad/param norm = 2.0487e-01, time/batch = 0.6599s	
2518/29850 (epoch 4.218), train_loss = 1.73897494, grad/param norm = 1.9841e-01, time/batch = 0.6642s	
2519/29850 (epoch 4.219), train_loss = 1.89688465, grad/param norm = 2.0911e-01, time/batch = 0.6646s	
2520/29850 (epoch 4.221), train_loss = 1.57859833, grad/param norm = 1.8277e-01, time/batch = 0.6616s	
2521/29850 (epoch 4.223), train_loss = 1.69946030, grad/param norm = 1.8765e-01, time/batch = 0.6648s	
2522/29850 (epoch 4.224), train_loss = 1.58165076, grad/param norm = 1.9253e-01, time/batch = 0.6617s	
2523/29850 (epoch 4.226), train_loss = 1.64895480, grad/param norm = 1.8946e-01, time/batch = 0.6604s	
2524/29850 (epoch 4.228), train_loss = 1.57164433, grad/param norm = 1.7986e-01, time/batch = 0.6605s	
2525/29850 (epoch 4.229), train_loss = 1.51764739, grad/param norm = 1.8906e-01, time/batch = 0.6575s	
2526/29850 (epoch 4.231), train_loss = 1.55427924, grad/param norm = 1.7914e-01, time/batch = 0.6511s	
2527/29850 (epoch 4.233), train_loss = 1.61884228, grad/param norm = 1.9790e-01, time/batch = 0.6662s	
2528/29850 (epoch 4.235), train_loss = 1.52333768, grad/param norm = 1.7616e-01, time/batch = 0.6740s	
2529/29850 (epoch 4.236), train_loss = 1.87479174, grad/param norm = 2.2021e-01, time/batch = 0.6543s	
2530/29850 (epoch 4.238), train_loss = 1.51006128, grad/param norm = 2.0565e-01, time/batch = 0.6617s	
2531/29850 (epoch 4.240), train_loss = 1.66077564, grad/param norm = 1.8271e-01, time/batch = 0.6884s	
2532/29850 (epoch 4.241), train_loss = 1.87099395, grad/param norm = 1.9513e-01, time/batch = 0.6613s	
2533/29850 (epoch 4.243), train_loss = 1.62365523, grad/param norm = 1.8109e-01, time/batch = 0.6650s	
2534/29850 (epoch 4.245), train_loss = 1.64600215, grad/param norm = 1.9142e-01, time/batch = 0.6648s	
2535/29850 (epoch 4.246), train_loss = 1.62637851, grad/param norm = 1.8748e-01, time/batch = 0.6680s	
2536/29850 (epoch 4.248), train_loss = 1.65773496, grad/param norm = 2.0450e-01, time/batch = 0.6534s	
2537/29850 (epoch 4.250), train_loss = 1.74676218, grad/param norm = 1.9734e-01, time/batch = 0.6544s	
2538/29850 (epoch 4.251), train_loss = 1.57147127, grad/param norm = 1.8834e-01, time/batch = 0.6530s	
2539/29850 (epoch 4.253), train_loss = 1.66125510, grad/param norm = 2.1269e-01, time/batch = 0.6522s	
2540/29850 (epoch 4.255), train_loss = 1.65785167, grad/param norm = 2.0647e-01, time/batch = 0.6507s	
2541/29850 (epoch 4.256), train_loss = 1.61105074, grad/param norm = 1.8879e-01, time/batch = 0.6519s	
2542/29850 (epoch 4.258), train_loss = 1.59344025, grad/param norm = 1.9136e-01, time/batch = 0.6522s	
2543/29850 (epoch 4.260), train_loss = 1.57130539, grad/param norm = 1.7204e-01, time/batch = 0.6560s	
2544/29850 (epoch 4.261), train_loss = 1.58604149, grad/param norm = 1.9036e-01, time/batch = 0.6515s	
2545/29850 (epoch 4.263), train_loss = 1.50235265, grad/param norm = 1.8551e-01, time/batch = 0.6533s	
2546/29850 (epoch 4.265), train_loss = 1.61119163, grad/param norm = 1.9335e-01, time/batch = 0.6520s	
2547/29850 (epoch 4.266), train_loss = 1.61104112, grad/param norm = 2.0538e-01, time/batch = 0.6549s	
2548/29850 (epoch 4.268), train_loss = 1.60069954, grad/param norm = 1.9796e-01, time/batch = 0.6534s	
2549/29850 (epoch 4.270), train_loss = 1.61519505, grad/param norm = 2.0829e-01, time/batch = 0.6537s	
2550/29850 (epoch 4.271), train_loss = 1.72597647, grad/param norm = 2.0023e-01, time/batch = 0.6555s	
2551/29850 (epoch 4.273), train_loss = 1.59864004, grad/param norm = 1.9883e-01, time/batch = 0.6545s	
2552/29850 (epoch 4.275), train_loss = 1.61206143, grad/param norm = 1.8684e-01, time/batch = 0.6571s	
2553/29850 (epoch 4.276), train_loss = 1.53423142, grad/param norm = 1.8420e-01, time/batch = 0.6524s	
2554/29850 (epoch 4.278), train_loss = 1.55405335, grad/param norm = 1.7831e-01, time/batch = 0.6539s	
2555/29850 (epoch 4.280), train_loss = 1.67296976, grad/param norm = 1.8307e-01, time/batch = 0.6544s	
2556/29850 (epoch 4.281), train_loss = 1.55449479, grad/param norm = 1.9647e-01, time/batch = 0.6511s	
2557/29850 (epoch 4.283), train_loss = 1.70918092, grad/param norm = 1.9018e-01, time/batch = 0.6574s	
2558/29850 (epoch 4.285), train_loss = 1.61084381, grad/param norm = 1.9086e-01, time/batch = 0.6547s	
2559/29850 (epoch 4.286), train_loss = 1.61142000, grad/param norm = 1.8114e-01, time/batch = 0.6545s	
2560/29850 (epoch 4.288), train_loss = 1.81395483, grad/param norm = 2.3162e-01, time/batch = 0.6666s	
2561/29850 (epoch 4.290), train_loss = 1.55942094, grad/param norm = 2.1585e-01, time/batch = 0.6827s	
2562/29850 (epoch 4.291), train_loss = 1.89783355, grad/param norm = 2.1248e-01, time/batch = 0.6601s	
2563/29850 (epoch 4.293), train_loss = 1.73713463, grad/param norm = 1.9747e-01, time/batch = 0.6674s	
2564/29850 (epoch 4.295), train_loss = 1.76579144, grad/param norm = 1.9885e-01, time/batch = 0.6542s	
2565/29850 (epoch 4.296), train_loss = 1.53844481, grad/param norm = 1.8052e-01, time/batch = 0.6600s	
2566/29850 (epoch 4.298), train_loss = 1.40778521, grad/param norm = 1.7819e-01, time/batch = 0.6656s	
2567/29850 (epoch 4.300), train_loss = 1.50312267, grad/param norm = 1.8146e-01, time/batch = 0.6569s	
2568/29850 (epoch 4.302), train_loss = 1.48835229, grad/param norm = 1.8743e-01, time/batch = 0.6636s	
2569/29850 (epoch 4.303), train_loss = 1.65327891, grad/param norm = 1.9454e-01, time/batch = 0.6606s	
2570/29850 (epoch 4.305), train_loss = 1.56300654, grad/param norm = 1.8718e-01, time/batch = 0.6635s	
2571/29850 (epoch 4.307), train_loss = 1.70847447, grad/param norm = 2.1294e-01, time/batch = 0.6832s	
2572/29850 (epoch 4.308), train_loss = 1.70543258, grad/param norm = 1.9941e-01, time/batch = 0.6708s	
2573/29850 (epoch 4.310), train_loss = 1.74254275, grad/param norm = 2.0615e-01, time/batch = 0.6629s	
2574/29850 (epoch 4.312), train_loss = 1.65343800, grad/param norm = 1.9019e-01, time/batch = 0.6542s	
2575/29850 (epoch 4.313), train_loss = 1.67285442, grad/param norm = 1.8954e-01, time/batch = 0.6573s	
2576/29850 (epoch 4.315), train_loss = 1.65338008, grad/param norm = 2.0200e-01, time/batch = 0.6549s	
2577/29850 (epoch 4.317), train_loss = 1.71954293, grad/param norm = 1.8800e-01, time/batch = 0.6539s	
2578/29850 (epoch 4.318), train_loss = 1.66649290, grad/param norm = 2.0091e-01, time/batch = 0.6550s	
2579/29850 (epoch 4.320), train_loss = 1.46898023, grad/param norm = 1.8431e-01, time/batch = 0.6520s	
2580/29850 (epoch 4.322), train_loss = 1.72446059, grad/param norm = 1.9190e-01, time/batch = 0.6542s	
2581/29850 (epoch 4.323), train_loss = 1.65917168, grad/param norm = 2.0562e-01, time/batch = 0.6562s	
2582/29850 (epoch 4.325), train_loss = 1.61824864, grad/param norm = 1.9111e-01, time/batch = 0.6533s	
2583/29850 (epoch 4.327), train_loss = 1.80678113, grad/param norm = 2.1697e-01, time/batch = 0.6510s	
2584/29850 (epoch 4.328), train_loss = 1.83415970, grad/param norm = 2.0838e-01, time/batch = 0.6655s	
2585/29850 (epoch 4.330), train_loss = 1.61823686, grad/param norm = 1.9052e-01, time/batch = 0.6573s	
2586/29850 (epoch 4.332), train_loss = 1.56604572, grad/param norm = 1.8977e-01, time/batch = 0.6534s	
2587/29850 (epoch 4.333), train_loss = 1.78504831, grad/param norm = 1.9161e-01, time/batch = 0.6606s	
2588/29850 (epoch 4.335), train_loss = 1.69543061, grad/param norm = 2.0052e-01, time/batch = 0.6518s	
2589/29850 (epoch 4.337), train_loss = 1.69804401, grad/param norm = 1.9488e-01, time/batch = 0.6590s	
2590/29850 (epoch 4.338), train_loss = 1.63587707, grad/param norm = 1.8883e-01, time/batch = 0.6578s	
2591/29850 (epoch 4.340), train_loss = 1.51107989, grad/param norm = 1.8304e-01, time/batch = 0.6586s	
2592/29850 (epoch 4.342), train_loss = 1.70131844, grad/param norm = 1.9342e-01, time/batch = 0.6569s	
2593/29850 (epoch 4.343), train_loss = 1.72384864, grad/param norm = 1.9089e-01, time/batch = 0.6855s	
2594/29850 (epoch 4.345), train_loss = 1.78553590, grad/param norm = 2.4610e-01, time/batch = 0.6738s	
2595/29850 (epoch 4.347), train_loss = 1.73433285, grad/param norm = 2.0915e-01, time/batch = 0.6582s	
2596/29850 (epoch 4.348), train_loss = 1.70313004, grad/param norm = 1.9302e-01, time/batch = 0.6591s	
2597/29850 (epoch 4.350), train_loss = 1.75679028, grad/param norm = 2.1428e-01, time/batch = 0.6597s	
2598/29850 (epoch 4.352), train_loss = 1.68933965, grad/param norm = 1.8859e-01, time/batch = 0.6551s	
2599/29850 (epoch 4.353), train_loss = 1.65286334, grad/param norm = 1.9945e-01, time/batch = 0.6542s	
2600/29850 (epoch 4.355), train_loss = 1.51628978, grad/param norm = 2.0709e-01, time/batch = 0.6568s	
2601/29850 (epoch 4.357), train_loss = 1.78741752, grad/param norm = 1.8127e-01, time/batch = 0.6570s	
2602/29850 (epoch 4.358), train_loss = 1.46467862, grad/param norm = 1.6792e-01, time/batch = 0.6564s	
2603/29850 (epoch 4.360), train_loss = 1.56316436, grad/param norm = 1.8437e-01, time/batch = 0.6568s	
2604/29850 (epoch 4.362), train_loss = 1.61780413, grad/param norm = 1.8931e-01, time/batch = 0.6760s	
2605/29850 (epoch 4.363), train_loss = 1.64452300, grad/param norm = 1.8282e-01, time/batch = 0.6814s	
2606/29850 (epoch 4.365), train_loss = 1.80085439, grad/param norm = 2.0530e-01, time/batch = 0.6819s	
2607/29850 (epoch 4.367), train_loss = 1.60030232, grad/param norm = 1.8253e-01, time/batch = 0.6579s	
2608/29850 (epoch 4.369), train_loss = 1.51354509, grad/param norm = 1.8927e-01, time/batch = 0.6547s	
2609/29850 (epoch 4.370), train_loss = 1.44802549, grad/param norm = 1.8202e-01, time/batch = 0.6725s	
2610/29850 (epoch 4.372), train_loss = 1.80182154, grad/param norm = 1.8865e-01, time/batch = 0.6706s	
2611/29850 (epoch 4.374), train_loss = 1.56992637, grad/param norm = 1.8711e-01, time/batch = 0.6535s	
2612/29850 (epoch 4.375), train_loss = 1.60137846, grad/param norm = 2.1682e-01, time/batch = 0.6606s	
2613/29850 (epoch 4.377), train_loss = 1.68124248, grad/param norm = 1.9733e-01, time/batch = 0.6552s	
2614/29850 (epoch 4.379), train_loss = 1.75259365, grad/param norm = 2.0786e-01, time/batch = 0.6527s	
2615/29850 (epoch 4.380), train_loss = 1.68626106, grad/param norm = 2.1780e-01, time/batch = 0.6545s	
2616/29850 (epoch 4.382), train_loss = 1.74743981, grad/param norm = 1.9957e-01, time/batch = 0.6636s	
2617/29850 (epoch 4.384), train_loss = 1.58428123, grad/param norm = 1.9320e-01, time/batch = 0.6603s	
2618/29850 (epoch 4.385), train_loss = 1.70550013, grad/param norm = 1.9188e-01, time/batch = 0.6615s	
2619/29850 (epoch 4.387), train_loss = 1.65778402, grad/param norm = 1.8912e-01, time/batch = 0.6555s	
2620/29850 (epoch 4.389), train_loss = 1.80330135, grad/param norm = 2.0154e-01, time/batch = 0.6567s	
2621/29850 (epoch 4.390), train_loss = 1.62719656, grad/param norm = 1.7555e-01, time/batch = 0.6551s	
2622/29850 (epoch 4.392), train_loss = 1.61981510, grad/param norm = 1.8587e-01, time/batch = 0.6700s	
2623/29850 (epoch 4.394), train_loss = 1.70383292, grad/param norm = 1.8822e-01, time/batch = 0.6678s	
2624/29850 (epoch 4.395), train_loss = 1.74222319, grad/param norm = 1.9083e-01, time/batch = 0.6572s	
2625/29850 (epoch 4.397), train_loss = 1.69414165, grad/param norm = 1.9459e-01, time/batch = 0.6540s	
2626/29850 (epoch 4.399), train_loss = 1.51486719, grad/param norm = 1.8285e-01, time/batch = 0.6560s	
2627/29850 (epoch 4.400), train_loss = 1.84330214, grad/param norm = 2.2647e-01, time/batch = 0.6537s	
2628/29850 (epoch 4.402), train_loss = 1.71852550, grad/param norm = 2.0856e-01, time/batch = 0.6496s	
2629/29850 (epoch 4.404), train_loss = 1.74148951, grad/param norm = 2.0048e-01, time/batch = 0.6501s	
2630/29850 (epoch 4.405), train_loss = 1.77527700, grad/param norm = 1.9615e-01, time/batch = 0.6527s	
2631/29850 (epoch 4.407), train_loss = 1.65003684, grad/param norm = 2.1472e-01, time/batch = 0.6533s	
2632/29850 (epoch 4.409), train_loss = 1.89588083, grad/param norm = 2.1204e-01, time/batch = 0.6508s	
2633/29850 (epoch 4.410), train_loss = 1.73572862, grad/param norm = 1.9423e-01, time/batch = 0.6519s	
2634/29850 (epoch 4.412), train_loss = 1.60487608, grad/param norm = 1.9794e-01, time/batch = 0.6559s	
2635/29850 (epoch 4.414), train_loss = 1.67941290, grad/param norm = 1.9245e-01, time/batch = 0.6530s	
2636/29850 (epoch 4.415), train_loss = 1.64554190, grad/param norm = 1.8496e-01, time/batch = 0.6542s	
2637/29850 (epoch 4.417), train_loss = 1.76486459, grad/param norm = 1.9694e-01, time/batch = 0.6523s	
2638/29850 (epoch 4.419), train_loss = 1.65426583, grad/param norm = 1.9680e-01, time/batch = 0.6657s	
2639/29850 (epoch 4.420), train_loss = 1.60740472, grad/param norm = 1.8194e-01, time/batch = 0.6508s	
2640/29850 (epoch 4.422), train_loss = 1.61260144, grad/param norm = 1.9545e-01, time/batch = 0.6572s	
2641/29850 (epoch 4.424), train_loss = 1.70200965, grad/param norm = 1.9770e-01, time/batch = 0.6612s	
2642/29850 (epoch 4.425), train_loss = 1.92010316, grad/param norm = 1.9169e-01, time/batch = 0.6573s	
2643/29850 (epoch 4.427), train_loss = 1.54148593, grad/param norm = 1.9310e-01, time/batch = 0.6558s	
2644/29850 (epoch 4.429), train_loss = 1.55217895, grad/param norm = 1.8279e-01, time/batch = 0.6516s	
2645/29850 (epoch 4.430), train_loss = 1.45681253, grad/param norm = 1.7732e-01, time/batch = 0.6604s	
2646/29850 (epoch 4.432), train_loss = 1.65106523, grad/param norm = 1.8885e-01, time/batch = 0.6565s	
2647/29850 (epoch 4.434), train_loss = 1.56851816, grad/param norm = 1.9137e-01, time/batch = 0.6556s	
2648/29850 (epoch 4.436), train_loss = 1.69682430, grad/param norm = 2.0472e-01, time/batch = 0.6532s	
2649/29850 (epoch 4.437), train_loss = 1.60411687, grad/param norm = 1.7781e-01, time/batch = 0.6664s	
2650/29850 (epoch 4.439), train_loss = 1.66411200, grad/param norm = 1.8781e-01, time/batch = 0.6816s	
2651/29850 (epoch 4.441), train_loss = 1.66849528, grad/param norm = 1.8330e-01, time/batch = 0.6590s	
2652/29850 (epoch 4.442), train_loss = 1.71048851, grad/param norm = 1.8634e-01, time/batch = 0.6591s	
2653/29850 (epoch 4.444), train_loss = 1.61235123, grad/param norm = 1.7329e-01, time/batch = 0.6608s	
2654/29850 (epoch 4.446), train_loss = 1.65091051, grad/param norm = 1.8338e-01, time/batch = 0.6516s	
2655/29850 (epoch 4.447), train_loss = 1.76836567, grad/param norm = 2.2143e-01, time/batch = 0.6533s	
2656/29850 (epoch 4.449), train_loss = 1.78919164, grad/param norm = 2.0684e-01, time/batch = 0.6520s	
2657/29850 (epoch 4.451), train_loss = 1.64967490, grad/param norm = 1.8921e-01, time/batch = 0.6529s	
2658/29850 (epoch 4.452), train_loss = 1.46516076, grad/param norm = 1.8198e-01, time/batch = 0.6524s	
2659/29850 (epoch 4.454), train_loss = 1.58586369, grad/param norm = 1.9210e-01, time/batch = 0.6524s	
2660/29850 (epoch 4.456), train_loss = 1.66843272, grad/param norm = 1.8069e-01, time/batch = 0.6783s	
2661/29850 (epoch 4.457), train_loss = 1.87226544, grad/param norm = 2.3233e-01, time/batch = 0.6716s	
2662/29850 (epoch 4.459), train_loss = 1.87435230, grad/param norm = 2.2223e-01, time/batch = 0.6547s	
2663/29850 (epoch 4.461), train_loss = 1.82742616, grad/param norm = 2.0465e-01, time/batch = 0.6575s	
2664/29850 (epoch 4.462), train_loss = 1.70131313, grad/param norm = 1.9779e-01, time/batch = 0.6546s	
2665/29850 (epoch 4.464), train_loss = 1.63573818, grad/param norm = 1.7346e-01, time/batch = 0.6645s	
2666/29850 (epoch 4.466), train_loss = 1.54957240, grad/param norm = 1.8119e-01, time/batch = 0.6553s	
2667/29850 (epoch 4.467), train_loss = 1.70333113, grad/param norm = 1.9052e-01, time/batch = 0.6503s	
2668/29850 (epoch 4.469), train_loss = 1.69749936, grad/param norm = 1.8369e-01, time/batch = 0.6535s	
2669/29850 (epoch 4.471), train_loss = 1.70529108, grad/param norm = 1.7868e-01, time/batch = 0.6531s	
2670/29850 (epoch 4.472), train_loss = 1.57932485, grad/param norm = 1.7319e-01, time/batch = 0.6608s	
2671/29850 (epoch 4.474), train_loss = 1.82733056, grad/param norm = 2.0426e-01, time/batch = 0.6842s	
2672/29850 (epoch 4.476), train_loss = 1.69597713, grad/param norm = 1.9607e-01, time/batch = 0.6663s	
2673/29850 (epoch 4.477), train_loss = 1.72987367, grad/param norm = 1.7797e-01, time/batch = 0.6551s	
2674/29850 (epoch 4.479), train_loss = 1.74562774, grad/param norm = 2.0711e-01, time/batch = 0.6626s	
2675/29850 (epoch 4.481), train_loss = 1.80241138, grad/param norm = 1.9788e-01, time/batch = 0.6606s	
2676/29850 (epoch 4.482), train_loss = 1.56664773, grad/param norm = 1.9262e-01, time/batch = 0.6534s	
2677/29850 (epoch 4.484), train_loss = 1.64394535, grad/param norm = 1.8682e-01, time/batch = 0.6540s	
2678/29850 (epoch 4.486), train_loss = 1.61999059, grad/param norm = 1.8669e-01, time/batch = 0.6540s	
2679/29850 (epoch 4.487), train_loss = 1.55422904, grad/param norm = 2.0179e-01, time/batch = 0.6561s	
2680/29850 (epoch 4.489), train_loss = 1.65753263, grad/param norm = 1.8659e-01, time/batch = 0.6544s	
2681/29850 (epoch 4.491), train_loss = 1.53139135, grad/param norm = 1.7263e-01, time/batch = 0.6589s	
2682/29850 (epoch 4.492), train_loss = 1.77735414, grad/param norm = 1.9593e-01, time/batch = 0.6754s	
2683/29850 (epoch 4.494), train_loss = 1.80991071, grad/param norm = 1.7887e-01, time/batch = 0.6613s	
2684/29850 (epoch 4.496), train_loss = 1.82109573, grad/param norm = 1.9013e-01, time/batch = 0.6656s	
2685/29850 (epoch 4.497), train_loss = 1.64589008, grad/param norm = 1.9109e-01, time/batch = 0.6605s	
2686/29850 (epoch 4.499), train_loss = 1.64833905, grad/param norm = 1.8165e-01, time/batch = 0.6570s	
2687/29850 (epoch 4.501), train_loss = 1.58528083, grad/param norm = 1.8330e-01, time/batch = 0.6560s	
2688/29850 (epoch 4.503), train_loss = 1.61791684, grad/param norm = 1.9379e-01, time/batch = 0.6556s	
2689/29850 (epoch 4.504), train_loss = 1.78874062, grad/param norm = 1.8907e-01, time/batch = 0.6529s	
2690/29850 (epoch 4.506), train_loss = 1.86647149, grad/param norm = 2.0302e-01, time/batch = 0.6573s	
2691/29850 (epoch 4.508), train_loss = 1.68552402, grad/param norm = 2.0544e-01, time/batch = 0.6530s	
2692/29850 (epoch 4.509), train_loss = 1.47009676, grad/param norm = 1.7750e-01, time/batch = 0.6522s	
2693/29850 (epoch 4.511), train_loss = 1.63661534, grad/param norm = 1.9464e-01, time/batch = 0.6532s	
2694/29850 (epoch 4.513), train_loss = 1.73704338, grad/param norm = 2.0214e-01, time/batch = 0.6541s	
2695/29850 (epoch 4.514), train_loss = 1.50319799, grad/param norm = 1.7539e-01, time/batch = 0.6718s	
2696/29850 (epoch 4.516), train_loss = 1.48835388, grad/param norm = 1.7264e-01, time/batch = 1.2945s	
2697/29850 (epoch 4.518), train_loss = 1.51904643, grad/param norm = 1.6806e-01, time/batch = 0.7301s	
2698/29850 (epoch 4.519), train_loss = 1.50674627, grad/param norm = 1.7355e-01, time/batch = 0.6714s	
2699/29850 (epoch 4.521), train_loss = 1.57757532, grad/param norm = 1.8216e-01, time/batch = 0.6734s	
2700/29850 (epoch 4.523), train_loss = 1.46255314, grad/param norm = 1.7387e-01, time/batch = 0.6683s	
2701/29850 (epoch 4.524), train_loss = 1.68368633, grad/param norm = 1.9082e-01, time/batch = 0.6611s	
2702/29850 (epoch 4.526), train_loss = 1.72435858, grad/param norm = 1.9575e-01, time/batch = 0.6673s	
2703/29850 (epoch 4.528), train_loss = 1.76176073, grad/param norm = 2.0404e-01, time/batch = 0.6709s	
2704/29850 (epoch 4.529), train_loss = 1.79221859, grad/param norm = 2.2128e-01, time/batch = 0.6636s	
2705/29850 (epoch 4.531), train_loss = 1.71203113, grad/param norm = 2.0804e-01, time/batch = 0.6584s	
2706/29850 (epoch 4.533), train_loss = 1.52670768, grad/param norm = 1.8524e-01, time/batch = 0.6679s	
2707/29850 (epoch 4.534), train_loss = 1.60740403, grad/param norm = 2.0807e-01, time/batch = 0.6695s	
2708/29850 (epoch 4.536), train_loss = 1.68907743, grad/param norm = 1.8824e-01, time/batch = 0.6672s	
2709/29850 (epoch 4.538), train_loss = 1.66854922, grad/param norm = 1.8312e-01, time/batch = 0.6560s	
2710/29850 (epoch 4.539), train_loss = 1.68660032, grad/param norm = 1.9895e-01, time/batch = 0.6645s	
2711/29850 (epoch 4.541), train_loss = 1.48873246, grad/param norm = 1.9611e-01, time/batch = 0.6703s	
2712/29850 (epoch 4.543), train_loss = 1.56871512, grad/param norm = 1.9010e-01, time/batch = 0.6720s	
2713/29850 (epoch 4.544), train_loss = 1.63832579, grad/param norm = 1.8723e-01, time/batch = 0.6662s	
2714/29850 (epoch 4.546), train_loss = 1.73928617, grad/param norm = 1.8861e-01, time/batch = 0.6550s	
2715/29850 (epoch 4.548), train_loss = 1.54193744, grad/param norm = 1.7367e-01, time/batch = 0.6553s	
2716/29850 (epoch 4.549), train_loss = 1.65506789, grad/param norm = 1.8069e-01, time/batch = 0.6555s	
2717/29850 (epoch 4.551), train_loss = 1.60272777, grad/param norm = 1.8572e-01, time/batch = 0.6564s	
2718/29850 (epoch 4.553), train_loss = 1.72452221, grad/param norm = 2.0722e-01, time/batch = 0.6702s	
2719/29850 (epoch 4.554), train_loss = 1.43119219, grad/param norm = 1.6900e-01, time/batch = 0.6730s	
2720/29850 (epoch 4.556), train_loss = 1.63742761, grad/param norm = 2.0220e-01, time/batch = 0.6685s	
2721/29850 (epoch 4.558), train_loss = 1.57747764, grad/param norm = 1.8115e-01, time/batch = 0.6635s	
2722/29850 (epoch 4.559), train_loss = 1.74936908, grad/param norm = 2.0715e-01, time/batch = 0.6780s	
2723/29850 (epoch 4.561), train_loss = 1.73625377, grad/param norm = 1.9813e-01, time/batch = 0.6769s	
2724/29850 (epoch 4.563), train_loss = 1.65047090, grad/param norm = 2.0770e-01, time/batch = 0.6559s	
2725/29850 (epoch 4.564), train_loss = 1.65843832, grad/param norm = 2.0131e-01, time/batch = 0.6540s	
2726/29850 (epoch 4.566), train_loss = 1.54020929, grad/param norm = 1.8243e-01, time/batch = 0.6575s	
2727/29850 (epoch 4.568), train_loss = 1.73336510, grad/param norm = 1.8676e-01, time/batch = 0.6647s	
2728/29850 (epoch 4.570), train_loss = 1.65030863, grad/param norm = 1.7652e-01, time/batch = 0.6630s	
2729/29850 (epoch 4.571), train_loss = 1.72649005, grad/param norm = 1.9206e-01, time/batch = 0.6517s	
2730/29850 (epoch 4.573), train_loss = 1.78623353, grad/param norm = 1.9098e-01, time/batch = 0.6504s	
2731/29850 (epoch 4.575), train_loss = 1.71708254, grad/param norm = 1.9913e-01, time/batch = 0.6509s	
2732/29850 (epoch 4.576), train_loss = 1.79251827, grad/param norm = 1.8781e-01, time/batch = 0.6590s	
2733/29850 (epoch 4.578), train_loss = 1.71434909, grad/param norm = 1.9293e-01, time/batch = 0.6504s	
2734/29850 (epoch 4.580), train_loss = 1.70556829, grad/param norm = 1.8554e-01, time/batch = 0.6507s	
2735/29850 (epoch 4.581), train_loss = 1.62879780, grad/param norm = 2.0503e-01, time/batch = 0.6592s	
2736/29850 (epoch 4.583), train_loss = 1.57133627, grad/param norm = 1.6815e-01, time/batch = 0.6656s	
2737/29850 (epoch 4.585), train_loss = 1.57348912, grad/param norm = 1.8095e-01, time/batch = 0.6735s	
2738/29850 (epoch 4.586), train_loss = 1.61666018, grad/param norm = 1.9040e-01, time/batch = 0.6672s	
2739/29850 (epoch 4.588), train_loss = 1.60059257, grad/param norm = 1.7660e-01, time/batch = 0.6592s	
2740/29850 (epoch 4.590), train_loss = 1.68690919, grad/param norm = 2.0201e-01, time/batch = 0.6664s	
2741/29850 (epoch 4.591), train_loss = 1.57013007, grad/param norm = 1.7674e-01, time/batch = 0.6833s	
2742/29850 (epoch 4.593), train_loss = 1.58890992, grad/param norm = 1.7347e-01, time/batch = 0.6786s	
2743/29850 (epoch 4.595), train_loss = 1.54605434, grad/param norm = 1.7434e-01, time/batch = 0.6756s	
2744/29850 (epoch 4.596), train_loss = 1.54061568, grad/param norm = 1.8495e-01, time/batch = 0.6780s	
2745/29850 (epoch 4.598), train_loss = 1.51583524, grad/param norm = 2.0940e-01, time/batch = 0.6752s	
2746/29850 (epoch 4.600), train_loss = 1.75133482, grad/param norm = 2.1189e-01, time/batch = 0.6679s	
2747/29850 (epoch 4.601), train_loss = 1.50052081, grad/param norm = 1.6145e-01, time/batch = 0.6722s	
2748/29850 (epoch 4.603), train_loss = 1.67468287, grad/param norm = 1.8906e-01, time/batch = 0.6665s	
2749/29850 (epoch 4.605), train_loss = 1.72409010, grad/param norm = 2.0248e-01, time/batch = 0.6636s	
2750/29850 (epoch 4.606), train_loss = 1.46669653, grad/param norm = 1.7710e-01, time/batch = 0.6716s	
2751/29850 (epoch 4.608), train_loss = 1.63538466, grad/param norm = 1.8800e-01, time/batch = 0.6778s	
2752/29850 (epoch 4.610), train_loss = 1.60790038, grad/param norm = 1.8724e-01, time/batch = 0.6804s	
2753/29850 (epoch 4.611), train_loss = 1.40138132, grad/param norm = 1.6929e-01, time/batch = 0.6769s	
2754/29850 (epoch 4.613), train_loss = 1.42508204, grad/param norm = 1.6702e-01, time/batch = 0.6791s	
2755/29850 (epoch 4.615), train_loss = 1.47719484, grad/param norm = 1.7565e-01, time/batch = 0.6657s	
2756/29850 (epoch 4.616), train_loss = 1.64332978, grad/param norm = 1.9863e-01, time/batch = 0.6610s	
2757/29850 (epoch 4.618), train_loss = 1.63263463, grad/param norm = 1.8258e-01, time/batch = 0.6615s	
2758/29850 (epoch 4.620), train_loss = 1.62951993, grad/param norm = 1.9191e-01, time/batch = 0.6652s	
2759/29850 (epoch 4.621), train_loss = 1.67522315, grad/param norm = 2.1403e-01, time/batch = 0.6596s	
2760/29850 (epoch 4.623), train_loss = 1.69381620, grad/param norm = 2.0155e-01, time/batch = 0.6558s	
2761/29850 (epoch 4.625), train_loss = 1.73506173, grad/param norm = 2.0618e-01, time/batch = 0.6594s	
2762/29850 (epoch 4.626), train_loss = 1.72900254, grad/param norm = 2.0895e-01, time/batch = 0.6553s	
2763/29850 (epoch 4.628), train_loss = 1.45084871, grad/param norm = 1.8787e-01, time/batch = 0.6541s	
2764/29850 (epoch 4.630), train_loss = 1.63654922, grad/param norm = 1.9728e-01, time/batch = 0.6551s	
2765/29850 (epoch 4.631), train_loss = 1.51148101, grad/param norm = 1.8429e-01, time/batch = 0.6671s	
2766/29850 (epoch 4.633), train_loss = 1.73732220, grad/param norm = 2.0752e-01, time/batch = 0.6850s	
2767/29850 (epoch 4.635), train_loss = 1.66733488, grad/param norm = 2.0309e-01, time/batch = 0.6647s	
2768/29850 (epoch 4.637), train_loss = 1.76499853, grad/param norm = 2.1271e-01, time/batch = 0.6720s	
2769/29850 (epoch 4.638), train_loss = 1.52367961, grad/param norm = 1.7865e-01, time/batch = 0.6560s	
2770/29850 (epoch 4.640), train_loss = 1.80557643, grad/param norm = 1.8768e-01, time/batch = 0.6589s	
2771/29850 (epoch 4.642), train_loss = 1.59241794, grad/param norm = 1.8883e-01, time/batch = 0.6561s	
2772/29850 (epoch 4.643), train_loss = 1.55861620, grad/param norm = 1.8149e-01, time/batch = 0.6625s	
2773/29850 (epoch 4.645), train_loss = 1.66161955, grad/param norm = 1.7914e-01, time/batch = 0.6665s	
2774/29850 (epoch 4.647), train_loss = 1.74348935, grad/param norm = 1.8183e-01, time/batch = 0.6585s	
2775/29850 (epoch 4.648), train_loss = 1.45333038, grad/param norm = 1.7599e-01, time/batch = 0.6586s	
2776/29850 (epoch 4.650), train_loss = 1.63466320, grad/param norm = 2.1053e-01, time/batch = 0.6621s	
2777/29850 (epoch 4.652), train_loss = 1.59473639, grad/param norm = 1.8945e-01, time/batch = 0.6676s	
2778/29850 (epoch 4.653), train_loss = 1.74396204, grad/param norm = 2.0824e-01, time/batch = 0.6623s	
2779/29850 (epoch 4.655), train_loss = 1.58995514, grad/param norm = 1.8586e-01, time/batch = 0.6588s	
2780/29850 (epoch 4.657), train_loss = 1.55461428, grad/param norm = 1.7158e-01, time/batch = 0.6547s	
2781/29850 (epoch 4.658), train_loss = 1.70405749, grad/param norm = 1.9284e-01, time/batch = 0.6570s	
2782/29850 (epoch 4.660), train_loss = 1.48717499, grad/param norm = 1.9446e-01, time/batch = 0.6565s	
2783/29850 (epoch 4.662), train_loss = 1.63413661, grad/param norm = 2.0598e-01, time/batch = 0.6647s	
2784/29850 (epoch 4.663), train_loss = 1.68556416, grad/param norm = 2.1381e-01, time/batch = 0.6805s	
2785/29850 (epoch 4.665), train_loss = 1.65583653, grad/param norm = 1.8368e-01, time/batch = 0.6882s	
2786/29850 (epoch 4.667), train_loss = 1.73425603, grad/param norm = 2.1044e-01, time/batch = 0.6871s	
2787/29850 (epoch 4.668), train_loss = 1.71802728, grad/param norm = 1.9348e-01, time/batch = 0.6792s	
2788/29850 (epoch 4.670), train_loss = 1.94304518, grad/param norm = 2.0284e-01, time/batch = 0.6706s	
2789/29850 (epoch 4.672), train_loss = 1.68785059, grad/param norm = 1.9761e-01, time/batch = 0.6877s	
2790/29850 (epoch 4.673), train_loss = 1.70966905, grad/param norm = 1.8132e-01, time/batch = 0.6719s	
2791/29850 (epoch 4.675), train_loss = 1.63124871, grad/param norm = 1.9467e-01, time/batch = 0.6751s	
2792/29850 (epoch 4.677), train_loss = 1.63834875, grad/param norm = 1.7404e-01, time/batch = 0.6790s	
2793/29850 (epoch 4.678), train_loss = 1.57286276, grad/param norm = 1.8537e-01, time/batch = 0.6768s	
2794/29850 (epoch 4.680), train_loss = 1.65454492, grad/param norm = 1.9801e-01, time/batch = 0.6744s	
2795/29850 (epoch 4.682), train_loss = 1.61600039, grad/param norm = 1.8337e-01, time/batch = 0.6706s	
2796/29850 (epoch 4.683), train_loss = 1.84336999, grad/param norm = 2.1391e-01, time/batch = 0.6707s	
2797/29850 (epoch 4.685), train_loss = 1.78377200, grad/param norm = 1.8128e-01, time/batch = 0.6592s	
2798/29850 (epoch 4.687), train_loss = 1.70513292, grad/param norm = 2.0139e-01, time/batch = 0.6575s	
2799/29850 (epoch 4.688), train_loss = 1.47072087, grad/param norm = 1.5413e-01, time/batch = 0.6619s	
2800/29850 (epoch 4.690), train_loss = 1.56861869, grad/param norm = 2.1194e-01, time/batch = 0.6847s	
2801/29850 (epoch 4.692), train_loss = 1.84450507, grad/param norm = 2.1599e-01, time/batch = 0.6715s	
2802/29850 (epoch 4.693), train_loss = 1.60594214, grad/param norm = 1.6734e-01, time/batch = 0.6643s	
2803/29850 (epoch 4.695), train_loss = 1.56113999, grad/param norm = 1.8856e-01, time/batch = 0.6592s	
2804/29850 (epoch 4.697), train_loss = 1.76613795, grad/param norm = 2.3413e-01, time/batch = 0.6587s	
2805/29850 (epoch 4.698), train_loss = 1.71875026, grad/param norm = 1.9213e-01, time/batch = 0.6600s	
2806/29850 (epoch 4.700), train_loss = 1.74629436, grad/param norm = 2.0569e-01, time/batch = 0.6614s	
2807/29850 (epoch 4.702), train_loss = 1.57964922, grad/param norm = 1.9407e-01, time/batch = 0.6576s	
2808/29850 (epoch 4.704), train_loss = 1.59575236, grad/param norm = 1.8282e-01, time/batch = 0.6573s	
2809/29850 (epoch 4.705), train_loss = 1.62112736, grad/param norm = 1.7208e-01, time/batch = 0.6573s	
2810/29850 (epoch 4.707), train_loss = 1.68373902, grad/param norm = 1.8998e-01, time/batch = 0.6703s	
2811/29850 (epoch 4.709), train_loss = 1.78921089, grad/param norm = 1.9409e-01, time/batch = 0.6790s	
2812/29850 (epoch 4.710), train_loss = 1.63394867, grad/param norm = 1.9601e-01, time/batch = 0.6634s	
2813/29850 (epoch 4.712), train_loss = 1.60589148, grad/param norm = 1.7729e-01, time/batch = 0.6793s	
2814/29850 (epoch 4.714), train_loss = 1.64759290, grad/param norm = 2.0671e-01, time/batch = 0.6714s	
2815/29850 (epoch 4.715), train_loss = 1.75491193, grad/param norm = 1.9364e-01, time/batch = 0.6694s	
2816/29850 (epoch 4.717), train_loss = 1.54218293, grad/param norm = 1.8768e-01, time/batch = 0.6753s	
2817/29850 (epoch 4.719), train_loss = 1.62974765, grad/param norm = 1.8211e-01, time/batch = 0.6560s	
2818/29850 (epoch 4.720), train_loss = 1.69654008, grad/param norm = 1.9247e-01, time/batch = 0.6494s	
2819/29850 (epoch 4.722), train_loss = 1.56340056, grad/param norm = 1.7743e-01, time/batch = 0.6454s	
2820/29850 (epoch 4.724), train_loss = 1.60213985, grad/param norm = 1.7846e-01, time/batch = 0.6436s	
2821/29850 (epoch 4.725), train_loss = 1.50271498, grad/param norm = 1.7275e-01, time/batch = 0.6707s	
2822/29850 (epoch 4.727), train_loss = 1.60313121, grad/param norm = 1.8704e-01, time/batch = 0.6532s	
2823/29850 (epoch 4.729), train_loss = 1.42739621, grad/param norm = 1.8543e-01, time/batch = 0.6402s	
2824/29850 (epoch 4.730), train_loss = 1.51767413, grad/param norm = 1.7599e-01, time/batch = 0.6437s	
2825/29850 (epoch 4.732), train_loss = 1.54001547, grad/param norm = 1.6877e-01, time/batch = 0.6405s	
2826/29850 (epoch 4.734), train_loss = 1.79288508, grad/param norm = 1.9562e-01, time/batch = 0.6452s	
2827/29850 (epoch 4.735), train_loss = 1.69532466, grad/param norm = 1.8607e-01, time/batch = 0.6408s	
2828/29850 (epoch 4.737), train_loss = 1.48700175, grad/param norm = 1.7226e-01, time/batch = 0.6442s	
2829/29850 (epoch 4.739), train_loss = 1.53242973, grad/param norm = 1.8286e-01, time/batch = 0.6446s	
2830/29850 (epoch 4.740), train_loss = 1.54392946, grad/param norm = 2.0362e-01, time/batch = 0.6416s	
2831/29850 (epoch 4.742), train_loss = 1.52232140, grad/param norm = 1.9562e-01, time/batch = 0.6507s	
2832/29850 (epoch 4.744), train_loss = 1.61414019, grad/param norm = 2.0013e-01, time/batch = 0.6533s	
2833/29850 (epoch 4.745), train_loss = 1.62279941, grad/param norm = 1.9645e-01, time/batch = 0.6559s	
2834/29850 (epoch 4.747), train_loss = 1.54197535, grad/param norm = 1.9871e-01, time/batch = 0.6514s	
2835/29850 (epoch 4.749), train_loss = 1.53757779, grad/param norm = 1.8078e-01, time/batch = 0.6440s	
2836/29850 (epoch 4.750), train_loss = 1.65304776, grad/param norm = 2.0654e-01, time/batch = 0.6455s	
2837/29850 (epoch 4.752), train_loss = 1.60101767, grad/param norm = 1.7954e-01, time/batch = 0.6444s	
2838/29850 (epoch 4.754), train_loss = 1.54159583, grad/param norm = 1.8381e-01, time/batch = 0.6405s	
2839/29850 (epoch 4.755), train_loss = 1.63859668, grad/param norm = 1.8574e-01, time/batch = 0.6409s	
2840/29850 (epoch 4.757), train_loss = 1.54653648, grad/param norm = 1.8313e-01, time/batch = 0.6420s	
2841/29850 (epoch 4.759), train_loss = 1.65183026, grad/param norm = 1.6736e-01, time/batch = 0.6452s	
2842/29850 (epoch 4.760), train_loss = 1.47823965, grad/param norm = 1.8441e-01, time/batch = 0.6609s	
2843/29850 (epoch 4.762), train_loss = 1.52417375, grad/param norm = 1.9017e-01, time/batch = 0.6661s	
2844/29850 (epoch 4.764), train_loss = 1.63024718, grad/param norm = 1.9516e-01, time/batch = 0.6436s	
2845/29850 (epoch 4.765), train_loss = 1.57850446, grad/param norm = 1.9918e-01, time/batch = 0.6465s	
2846/29850 (epoch 4.767), train_loss = 1.66688786, grad/param norm = 1.8234e-01, time/batch = 0.6450s	
2847/29850 (epoch 4.769), train_loss = 1.55256109, grad/param norm = 1.8401e-01, time/batch = 0.6395s	
2848/29850 (epoch 4.771), train_loss = 1.65151474, grad/param norm = 1.9862e-01, time/batch = 0.6423s	
2849/29850 (epoch 4.772), train_loss = 1.73287249, grad/param norm = 1.8927e-01, time/batch = 0.6425s	
2850/29850 (epoch 4.774), train_loss = 1.59522761, grad/param norm = 1.8918e-01, time/batch = 0.6424s	
2851/29850 (epoch 4.776), train_loss = 1.58669148, grad/param norm = 2.0240e-01, time/batch = 0.6474s	
2852/29850 (epoch 4.777), train_loss = 1.68036502, grad/param norm = 1.8842e-01, time/batch = 0.6468s	
2853/29850 (epoch 4.779), train_loss = 1.46177130, grad/param norm = 1.7606e-01, time/batch = 0.6655s	
2854/29850 (epoch 4.781), train_loss = 1.51390582, grad/param norm = 1.8605e-01, time/batch = 0.6610s	
2855/29850 (epoch 4.782), train_loss = 1.56583591, grad/param norm = 1.7224e-01, time/batch = 0.6477s	
2856/29850 (epoch 4.784), train_loss = 1.55654753, grad/param norm = 1.9034e-01, time/batch = 0.6474s	
2857/29850 (epoch 4.786), train_loss = 1.54314578, grad/param norm = 1.8959e-01, time/batch = 0.6492s	
2858/29850 (epoch 4.787), train_loss = 1.55986124, grad/param norm = 1.8904e-01, time/batch = 0.6480s	
2859/29850 (epoch 4.789), train_loss = 1.50325683, grad/param norm = 1.7261e-01, time/batch = 0.6483s	
2860/29850 (epoch 4.791), train_loss = 1.65355940, grad/param norm = 2.0334e-01, time/batch = 0.6426s	
2861/29850 (epoch 4.792), train_loss = 1.64841440, grad/param norm = 2.0402e-01, time/batch = 0.6503s	
2862/29850 (epoch 4.794), train_loss = 1.62602837, grad/param norm = 1.8315e-01, time/batch = 0.6452s	
2863/29850 (epoch 4.796), train_loss = 1.53333033, grad/param norm = 1.9161e-01, time/batch = 0.6505s	
2864/29850 (epoch 4.797), train_loss = 1.58113821, grad/param norm = 1.6408e-01, time/batch = 0.6701s	
2865/29850 (epoch 4.799), train_loss = 1.52636327, grad/param norm = 1.6415e-01, time/batch = 0.6542s	
2866/29850 (epoch 4.801), train_loss = 1.71941178, grad/param norm = 1.9431e-01, time/batch = 0.6488s	
2867/29850 (epoch 4.802), train_loss = 1.51631684, grad/param norm = 1.9723e-01, time/batch = 0.6422s	
2868/29850 (epoch 4.804), train_loss = 1.61400361, grad/param norm = 1.7638e-01, time/batch = 0.6390s	
2869/29850 (epoch 4.806), train_loss = 1.61040866, grad/param norm = 1.8547e-01, time/batch = 0.6370s	
2870/29850 (epoch 4.807), train_loss = 1.45281085, grad/param norm = 1.7095e-01, time/batch = 0.6382s	
2871/29850 (epoch 4.809), train_loss = 1.66964429, grad/param norm = 2.1453e-01, time/batch = 0.6423s	
2872/29850 (epoch 4.811), train_loss = 1.72116615, grad/param norm = 1.8963e-01, time/batch = 0.6433s	
2873/29850 (epoch 4.812), train_loss = 1.62751216, grad/param norm = 1.8247e-01, time/batch = 0.6470s	
2874/29850 (epoch 4.814), train_loss = 1.68680892, grad/param norm = 1.8867e-01, time/batch = 0.6652s	
2875/29850 (epoch 4.816), train_loss = 1.65384358, grad/param norm = 1.8113e-01, time/batch = 0.6703s	
2876/29850 (epoch 4.817), train_loss = 1.66719404, grad/param norm = 1.9407e-01, time/batch = 0.6704s	
2877/29850 (epoch 4.819), train_loss = 1.59381466, grad/param norm = 1.9340e-01, time/batch = 0.6634s	
2878/29850 (epoch 4.821), train_loss = 1.76867486, grad/param norm = 2.0939e-01, time/batch = 0.6473s	
2879/29850 (epoch 4.822), train_loss = 1.54799790, grad/param norm = 1.7289e-01, time/batch = 0.6471s	
2880/29850 (epoch 4.824), train_loss = 1.59311899, grad/param norm = 1.8752e-01, time/batch = 0.6465s	
2881/29850 (epoch 4.826), train_loss = 1.61039895, grad/param norm = 1.8661e-01, time/batch = 0.6514s	
2882/29850 (epoch 4.827), train_loss = 1.53074779, grad/param norm = 1.8382e-01, time/batch = 0.6455s	
2883/29850 (epoch 4.829), train_loss = 1.62874316, grad/param norm = 1.9621e-01, time/batch = 0.6537s	
2884/29850 (epoch 4.831), train_loss = 1.61432509, grad/param norm = 2.0183e-01, time/batch = 0.6635s	
2885/29850 (epoch 4.832), train_loss = 1.48689432, grad/param norm = 1.8550e-01, time/batch = 0.6624s	
2886/29850 (epoch 4.834), train_loss = 1.49358751, grad/param norm = 1.8560e-01, time/batch = 0.6644s	
2887/29850 (epoch 4.836), train_loss = 1.50280841, grad/param norm = 1.7285e-01, time/batch = 0.6443s	
2888/29850 (epoch 4.838), train_loss = 1.67835503, grad/param norm = 1.8786e-01, time/batch = 0.6550s	
2889/29850 (epoch 4.839), train_loss = 1.61542769, grad/param norm = 1.9024e-01, time/batch = 0.6536s	
2890/29850 (epoch 4.841), train_loss = 1.61910944, grad/param norm = 1.8073e-01, time/batch = 0.6539s	
2891/29850 (epoch 4.843), train_loss = 1.60158451, grad/param norm = 1.7110e-01, time/batch = 0.6596s	
2892/29850 (epoch 4.844), train_loss = 1.56190724, grad/param norm = 1.8793e-01, time/batch = 0.6543s	
2893/29850 (epoch 4.846), train_loss = 1.67620173, grad/param norm = 1.9687e-01, time/batch = 0.6523s	
2894/29850 (epoch 4.848), train_loss = 1.67494562, grad/param norm = 1.9155e-01, time/batch = 0.6489s	
2895/29850 (epoch 4.849), train_loss = 1.49715179, grad/param norm = 2.2406e-01, time/batch = 0.6471s	
2896/29850 (epoch 4.851), train_loss = 1.66270651, grad/param norm = 2.0400e-01, time/batch = 0.6473s	
2897/29850 (epoch 4.853), train_loss = 1.56135670, grad/param norm = 2.0212e-01, time/batch = 0.6481s	
2898/29850 (epoch 4.854), train_loss = 1.62767100, grad/param norm = 2.0337e-01, time/batch = 0.6580s	
2899/29850 (epoch 4.856), train_loss = 1.65069408, grad/param norm = 2.1232e-01, time/batch = 0.6523s	
2900/29850 (epoch 4.858), train_loss = 1.59412251, grad/param norm = 1.7877e-01, time/batch = 0.6507s	
2901/29850 (epoch 4.859), train_loss = 1.54718824, grad/param norm = 2.0041e-01, time/batch = 0.6540s	
2902/29850 (epoch 4.861), train_loss = 1.73281407, grad/param norm = 2.1333e-01, time/batch = 0.6482s	
2903/29850 (epoch 4.863), train_loss = 1.70298912, grad/param norm = 1.7577e-01, time/batch = 0.6479s	
2904/29850 (epoch 4.864), train_loss = 1.59980099, grad/param norm = 1.8907e-01, time/batch = 0.6464s	
2905/29850 (epoch 4.866), train_loss = 1.58464749, grad/param norm = 1.8914e-01, time/batch = 0.6464s	
2906/29850 (epoch 4.868), train_loss = 1.67681355, grad/param norm = 1.9236e-01, time/batch = 0.6459s	
2907/29850 (epoch 4.869), train_loss = 1.54102164, grad/param norm = 1.9847e-01, time/batch = 0.6476s	
2908/29850 (epoch 4.871), train_loss = 1.59988996, grad/param norm = 1.8883e-01, time/batch = 0.6442s	
2909/29850 (epoch 4.873), train_loss = 1.69303197, grad/param norm = 2.0497e-01, time/batch = 0.6503s	
2910/29850 (epoch 4.874), train_loss = 1.64877977, grad/param norm = 2.0468e-01, time/batch = 0.6482s	
2911/29850 (epoch 4.876), train_loss = 1.69765993, grad/param norm = 2.1173e-01, time/batch = 0.6485s	
2912/29850 (epoch 4.878), train_loss = 1.58471892, grad/param norm = 1.8860e-01, time/batch = 0.6433s	
2913/29850 (epoch 4.879), train_loss = 1.71548070, grad/param norm = 1.7805e-01, time/batch = 0.6488s	
2914/29850 (epoch 4.881), train_loss = 1.67884854, grad/param norm = 1.8482e-01, time/batch = 0.6515s	
2915/29850 (epoch 4.883), train_loss = 1.71936778, grad/param norm = 1.9269e-01, time/batch = 0.6489s	
2916/29850 (epoch 4.884), train_loss = 1.46649742, grad/param norm = 1.7323e-01, time/batch = 0.6519s	
2917/29850 (epoch 4.886), train_loss = 1.86236051, grad/param norm = 2.0263e-01, time/batch = 0.6614s	
2918/29850 (epoch 4.888), train_loss = 1.55070595, grad/param norm = 1.8449e-01, time/batch = 0.6678s	
2919/29850 (epoch 4.889), train_loss = 1.51847145, grad/param norm = 1.9149e-01, time/batch = 0.6523s	
2920/29850 (epoch 4.891), train_loss = 1.53560669, grad/param norm = 1.8750e-01, time/batch = 0.6499s	
2921/29850 (epoch 4.893), train_loss = 1.49303090, grad/param norm = 1.8922e-01, time/batch = 0.6589s	
2922/29850 (epoch 4.894), train_loss = 1.53670028, grad/param norm = 1.7523e-01, time/batch = 0.6532s	
2923/29850 (epoch 4.896), train_loss = 1.52544709, grad/param norm = 1.8947e-01, time/batch = 0.6495s	
2924/29850 (epoch 4.898), train_loss = 1.71750592, grad/param norm = 1.9979e-01, time/batch = 0.6499s	
2925/29850 (epoch 4.899), train_loss = 1.43991815, grad/param norm = 2.0137e-01, time/batch = 0.6493s	
2926/29850 (epoch 4.901), train_loss = 1.96497237, grad/param norm = 2.2905e-01, time/batch = 0.6546s	
2927/29850 (epoch 4.903), train_loss = 1.68096550, grad/param norm = 2.1373e-01, time/batch = 0.6482s	
2928/29850 (epoch 4.905), train_loss = 1.74774978, grad/param norm = 1.9407e-01, time/batch = 0.6690s	
2929/29850 (epoch 4.906), train_loss = 1.47493261, grad/param norm = 1.9430e-01, time/batch = 0.6582s	
2930/29850 (epoch 4.908), train_loss = 1.76733940, grad/param norm = 2.0240e-01, time/batch = 0.6427s	
2931/29850 (epoch 4.910), train_loss = 1.70671029, grad/param norm = 1.9036e-01, time/batch = 0.6426s	
2932/29850 (epoch 4.911), train_loss = 1.72058354, grad/param norm = 1.9424e-01, time/batch = 0.6422s	
2933/29850 (epoch 4.913), train_loss = 1.60015850, grad/param norm = 1.7769e-01, time/batch = 0.6590s	
2934/29850 (epoch 4.915), train_loss = 1.65549405, grad/param norm = 2.0090e-01, time/batch = 0.6527s	
2935/29850 (epoch 4.916), train_loss = 1.58134466, grad/param norm = 1.8513e-01, time/batch = 0.6456s	
2936/29850 (epoch 4.918), train_loss = 1.52250731, grad/param norm = 1.6562e-01, time/batch = 0.6492s	
2937/29850 (epoch 4.920), train_loss = 1.65770761, grad/param norm = 1.7513e-01, time/batch = 0.6457s	
2938/29850 (epoch 4.921), train_loss = 1.68206393, grad/param norm = 2.0432e-01, time/batch = 0.6444s	
2939/29850 (epoch 4.923), train_loss = 1.66753473, grad/param norm = 1.8392e-01, time/batch = 0.6621s	
2940/29850 (epoch 4.925), train_loss = 1.77477527, grad/param norm = 2.0798e-01, time/batch = 0.6569s	
2941/29850 (epoch 4.926), train_loss = 1.73984371, grad/param norm = 1.9621e-01, time/batch = 0.6461s	
2942/29850 (epoch 4.928), train_loss = 1.57132684, grad/param norm = 1.8645e-01, time/batch = 0.6544s	
2943/29850 (epoch 4.930), train_loss = 1.75259451, grad/param norm = 1.8825e-01, time/batch = 0.6475s	
2944/29850 (epoch 4.931), train_loss = 1.73299730, grad/param norm = 1.9326e-01, time/batch = 0.6485s	
2945/29850 (epoch 4.933), train_loss = 1.78180810, grad/param norm = 1.9471e-01, time/batch = 0.6410s	
2946/29850 (epoch 4.935), train_loss = 1.75933836, grad/param norm = 1.8560e-01, time/batch = 0.6471s	
2947/29850 (epoch 4.936), train_loss = 1.71516333, grad/param norm = 2.0149e-01, time/batch = 0.6451s	
2948/29850 (epoch 4.938), train_loss = 1.49214715, grad/param norm = 1.6829e-01, time/batch = 0.6422s	
2949/29850 (epoch 4.940), train_loss = 1.44174131, grad/param norm = 1.7338e-01, time/batch = 0.6587s	
2950/29850 (epoch 4.941), train_loss = 1.60243676, grad/param norm = 1.9247e-01, time/batch = 0.6703s	
2951/29850 (epoch 4.943), train_loss = 1.56316471, grad/param norm = 1.8481e-01, time/batch = 0.6471s	
2952/29850 (epoch 4.945), train_loss = 1.71002284, grad/param norm = 1.9663e-01, time/batch = 0.6463s	
2953/29850 (epoch 4.946), train_loss = 1.52811410, grad/param norm = 2.1118e-01, time/batch = 0.6433s	
2954/29850 (epoch 4.948), train_loss = 1.53660805, grad/param norm = 1.7430e-01, time/batch = 0.6431s	
2955/29850 (epoch 4.950), train_loss = 1.52379453, grad/param norm = 2.1032e-01, time/batch = 0.6531s	
2956/29850 (epoch 4.951), train_loss = 1.53343243, grad/param norm = 1.9884e-01, time/batch = 0.6470s	
2957/29850 (epoch 4.953), train_loss = 1.66204000, grad/param norm = 1.9028e-01, time/batch = 0.6463s	
2958/29850 (epoch 4.955), train_loss = 1.44141147, grad/param norm = 1.6785e-01, time/batch = 0.6461s	
2959/29850 (epoch 4.956), train_loss = 1.49981027, grad/param norm = 1.8598e-01, time/batch = 0.6423s	
2960/29850 (epoch 4.958), train_loss = 1.37267019, grad/param norm = 1.7329e-01, time/batch = 0.6434s	
2961/29850 (epoch 4.960), train_loss = 1.65934481, grad/param norm = 1.9238e-01, time/batch = 0.6541s	
2962/29850 (epoch 4.961), train_loss = 1.57507725, grad/param norm = 1.7642e-01, time/batch = 0.6457s	
2963/29850 (epoch 4.963), train_loss = 1.44417355, grad/param norm = 1.8389e-01, time/batch = 0.6443s	
2964/29850 (epoch 4.965), train_loss = 1.57783073, grad/param norm = 1.9236e-01, time/batch = 0.6622s	
2965/29850 (epoch 4.966), train_loss = 1.48517216, grad/param norm = 1.8597e-01, time/batch = 0.6504s	
2966/29850 (epoch 4.968), train_loss = 1.58291196, grad/param norm = 1.9321e-01, time/batch = 0.6611s	
2967/29850 (epoch 4.970), train_loss = 1.50089433, grad/param norm = 1.7827e-01, time/batch = 0.6707s	
2968/29850 (epoch 4.972), train_loss = 1.47997456, grad/param norm = 1.7833e-01, time/batch = 0.6756s	
2969/29850 (epoch 4.973), train_loss = 1.56801695, grad/param norm = 1.9626e-01, time/batch = 0.6522s	
2970/29850 (epoch 4.975), train_loss = 1.36057224, grad/param norm = 1.6707e-01, time/batch = 0.6508s	
2971/29850 (epoch 4.977), train_loss = 1.52486102, grad/param norm = 1.8551e-01, time/batch = 0.6743s	
2972/29850 (epoch 4.978), train_loss = 1.48997185, grad/param norm = 1.7569e-01, time/batch = 0.6640s	
2973/29850 (epoch 4.980), train_loss = 1.46059395, grad/param norm = 1.6924e-01, time/batch = 0.6588s	
2974/29850 (epoch 4.982), train_loss = 1.48563553, grad/param norm = 1.8498e-01, time/batch = 0.6493s	
2975/29850 (epoch 4.983), train_loss = 1.62896969, grad/param norm = 2.0459e-01, time/batch = 0.6539s	
2976/29850 (epoch 4.985), train_loss = 1.64934253, grad/param norm = 1.9658e-01, time/batch = 0.6616s	
2977/29850 (epoch 4.987), train_loss = 1.47033551, grad/param norm = 1.9459e-01, time/batch = 0.6597s	
2978/29850 (epoch 4.988), train_loss = 1.42996976, grad/param norm = 1.6928e-01, time/batch = 0.6505s	
2979/29850 (epoch 4.990), train_loss = 1.53021838, grad/param norm = 1.8857e-01, time/batch = 0.6477s	
2980/29850 (epoch 4.992), train_loss = 1.56628993, grad/param norm = 1.8259e-01, time/batch = 0.6572s	
2981/29850 (epoch 4.993), train_loss = 1.64206190, grad/param norm = 1.9691e-01, time/batch = 0.6504s	
2982/29850 (epoch 4.995), train_loss = 1.61746843, grad/param norm = 2.1916e-01, time/batch = 0.6538s	
2983/29850 (epoch 4.997), train_loss = 1.59101350, grad/param norm = 1.9260e-01, time/batch = 0.6507s	
2984/29850 (epoch 4.998), train_loss = 1.70439327, grad/param norm = 1.8928e-01, time/batch = 0.6449s	
2985/29850 (epoch 5.000), train_loss = 1.58209425, grad/param norm = 1.7786e-01, time/batch = 0.6528s	
2986/29850 (epoch 5.002), train_loss = 1.77805993, grad/param norm = 1.9211e-01, time/batch = 0.6504s	
2987/29850 (epoch 5.003), train_loss = 1.54497075, grad/param norm = 1.9649e-01, time/batch = 0.6545s	
2988/29850 (epoch 5.005), train_loss = 1.55634787, grad/param norm = 1.7855e-01, time/batch = 0.6426s	
2989/29850 (epoch 5.007), train_loss = 1.63814843, grad/param norm = 1.9661e-01, time/batch = 0.6425s	
2990/29850 (epoch 5.008), train_loss = 1.76333086, grad/param norm = 1.9874e-01, time/batch = 0.6431s	
2991/29850 (epoch 5.010), train_loss = 1.45200030, grad/param norm = 1.8341e-01, time/batch = 0.6415s	
2992/29850 (epoch 5.012), train_loss = 1.68419215, grad/param norm = 1.8039e-01, time/batch = 0.6538s	
2993/29850 (epoch 5.013), train_loss = 1.72248012, grad/param norm = 2.1340e-01, time/batch = 0.6549s	
2994/29850 (epoch 5.015), train_loss = 1.64683398, grad/param norm = 1.8606e-01, time/batch = 0.6567s	
2995/29850 (epoch 5.017), train_loss = 1.72903281, grad/param norm = 2.1050e-01, time/batch = 0.6565s	
2996/29850 (epoch 5.018), train_loss = 1.80460354, grad/param norm = 2.2236e-01, time/batch = 0.6486s	
2997/29850 (epoch 5.020), train_loss = 1.48075407, grad/param norm = 1.8685e-01, time/batch = 0.6702s	
2998/29850 (epoch 5.022), train_loss = 1.67033532, grad/param norm = 2.0582e-01, time/batch = 0.6538s	
2999/29850 (epoch 5.023), train_loss = 1.56980563, grad/param norm = 1.8306e-01, time/batch = 0.6409s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch5.03_1.7266.t7	
3000/29850 (epoch 5.025), train_loss = 1.57401244, grad/param norm = 1.6923e-01, time/batch = 0.6495s	
3001/29850 (epoch 5.027), train_loss = 1.59974289, grad/param norm = 1.8484e-01, time/batch = 0.6835s	
3002/29850 (epoch 5.028), train_loss = 1.59565744, grad/param norm = 1.7942e-01, time/batch = 0.6849s	
3003/29850 (epoch 5.030), train_loss = 1.68384545, grad/param norm = 1.7254e-01, time/batch = 0.6787s	
3004/29850 (epoch 5.032), train_loss = 1.53993062, grad/param norm = 1.9196e-01, time/batch = 0.6824s	
3005/29850 (epoch 5.034), train_loss = 1.65639041, grad/param norm = 1.9935e-01, time/batch = 0.6800s	
3006/29850 (epoch 5.035), train_loss = 1.55995290, grad/param norm = 1.8918e-01, time/batch = 0.6711s	
3007/29850 (epoch 5.037), train_loss = 1.64971787, grad/param norm = 1.8624e-01, time/batch = 0.6603s	
3008/29850 (epoch 5.039), train_loss = 1.48220320, grad/param norm = 1.8468e-01, time/batch = 0.6667s	
3009/29850 (epoch 5.040), train_loss = 1.44562673, grad/param norm = 1.7073e-01, time/batch = 0.6669s	
3010/29850 (epoch 5.042), train_loss = 1.56164830, grad/param norm = 1.9514e-01, time/batch = 0.6676s	
3011/29850 (epoch 5.044), train_loss = 1.42245849, grad/param norm = 1.9214e-01, time/batch = 0.6678s	
3012/29850 (epoch 5.045), train_loss = 1.62767290, grad/param norm = 1.8308e-01, time/batch = 0.6564s	
3013/29850 (epoch 5.047), train_loss = 1.41583203, grad/param norm = 1.7834e-01, time/batch = 0.6543s	
3014/29850 (epoch 5.049), train_loss = 1.58724435, grad/param norm = 2.1360e-01, time/batch = 0.6568s	
3015/29850 (epoch 5.050), train_loss = 1.46466862, grad/param norm = 1.7799e-01, time/batch = 0.6509s	
3016/29850 (epoch 5.052), train_loss = 1.81834325, grad/param norm = 2.1921e-01, time/batch = 0.6438s	
3017/29850 (epoch 5.054), train_loss = 1.62487691, grad/param norm = 1.9500e-01, time/batch = 0.6429s	
3018/29850 (epoch 5.055), train_loss = 1.60088513, grad/param norm = 1.9645e-01, time/batch = 0.6444s	
3019/29850 (epoch 5.057), train_loss = 1.57111263, grad/param norm = 1.8394e-01, time/batch = 0.6471s	
3020/29850 (epoch 5.059), train_loss = 1.66067355, grad/param norm = 1.9133e-01, time/batch = 0.6389s	
3021/29850 (epoch 5.060), train_loss = 1.56178595, grad/param norm = 2.0289e-01, time/batch = 0.6432s	
3022/29850 (epoch 5.062), train_loss = 1.71988737, grad/param norm = 2.0746e-01, time/batch = 0.6459s	
3023/29850 (epoch 5.064), train_loss = 1.58500187, grad/param norm = 1.8381e-01, time/batch = 0.6449s	
3024/29850 (epoch 5.065), train_loss = 1.45127575, grad/param norm = 1.8647e-01, time/batch = 0.6445s	
3025/29850 (epoch 5.067), train_loss = 1.54963430, grad/param norm = 1.8248e-01, time/batch = 0.6441s	
3026/29850 (epoch 5.069), train_loss = 1.51651518, grad/param norm = 1.7869e-01, time/batch = 0.6461s	
3027/29850 (epoch 5.070), train_loss = 1.56207773, grad/param norm = 1.7565e-01, time/batch = 0.6423s	
3028/29850 (epoch 5.072), train_loss = 1.70446177, grad/param norm = 2.0595e-01, time/batch = 0.6445s	
3029/29850 (epoch 5.074), train_loss = 1.65574793, grad/param norm = 2.0197e-01, time/batch = 0.6447s	
3030/29850 (epoch 5.075), train_loss = 1.48138377, grad/param norm = 1.7931e-01, time/batch = 0.6414s	
3031/29850 (epoch 5.077), train_loss = 1.50273479, grad/param norm = 1.9026e-01, time/batch = 0.6430s	
3032/29850 (epoch 5.079), train_loss = 1.76596855, grad/param norm = 1.9791e-01, time/batch = 0.6410s	
3033/29850 (epoch 5.080), train_loss = 1.73001005, grad/param norm = 2.0850e-01, time/batch = 0.6470s	
3034/29850 (epoch 5.082), train_loss = 1.55205586, grad/param norm = 1.6676e-01, time/batch = 0.6427s	
3035/29850 (epoch 5.084), train_loss = 1.60558419, grad/param norm = 1.8111e-01, time/batch = 0.6446s	
3036/29850 (epoch 5.085), train_loss = 1.56815029, grad/param norm = 1.7920e-01, time/batch = 0.6458s	
3037/29850 (epoch 5.087), train_loss = 1.68411730, grad/param norm = 1.8311e-01, time/batch = 0.6477s	
3038/29850 (epoch 5.089), train_loss = 1.66555714, grad/param norm = 1.7602e-01, time/batch = 0.6437s	
3039/29850 (epoch 5.090), train_loss = 1.62062413, grad/param norm = 1.9695e-01, time/batch = 0.6482s	
3040/29850 (epoch 5.092), train_loss = 1.51489305, grad/param norm = 1.8743e-01, time/batch = 0.6489s	
3041/29850 (epoch 5.094), train_loss = 1.58627364, grad/param norm = 1.8231e-01, time/batch = 0.6414s	
3042/29850 (epoch 5.095), train_loss = 1.63937763, grad/param norm = 1.8067e-01, time/batch = 0.6426s	
3043/29850 (epoch 5.097), train_loss = 1.40717337, grad/param norm = 1.6728e-01, time/batch = 0.6432s	
3044/29850 (epoch 5.099), train_loss = 1.44938360, grad/param norm = 1.7501e-01, time/batch = 0.6453s	
3045/29850 (epoch 5.101), train_loss = 1.71387037, grad/param norm = 2.0192e-01, time/batch = 0.6475s	
3046/29850 (epoch 5.102), train_loss = 1.57459317, grad/param norm = 1.8676e-01, time/batch = 0.6429s	
3047/29850 (epoch 5.104), train_loss = 1.54178467, grad/param norm = 1.6912e-01, time/batch = 0.6451s	
3048/29850 (epoch 5.106), train_loss = 1.63829794, grad/param norm = 1.8504e-01, time/batch = 0.6475s	
3049/29850 (epoch 5.107), train_loss = 1.49844730, grad/param norm = 1.7557e-01, time/batch = 0.6661s	
3050/29850 (epoch 5.109), train_loss = 1.50351021, grad/param norm = 1.7239e-01, time/batch = 0.6744s	
3051/29850 (epoch 5.111), train_loss = 1.68448106, grad/param norm = 2.1509e-01, time/batch = 0.6695s	
3052/29850 (epoch 5.112), train_loss = 1.48602789, grad/param norm = 1.7646e-01, time/batch = 0.6630s	
3053/29850 (epoch 5.114), train_loss = 1.70700312, grad/param norm = 2.0131e-01, time/batch = 0.6644s	
3054/29850 (epoch 5.116), train_loss = 1.51764238, grad/param norm = 1.8939e-01, time/batch = 0.6459s	
3055/29850 (epoch 5.117), train_loss = 1.62958418, grad/param norm = 1.7380e-01, time/batch = 0.6449s	
3056/29850 (epoch 5.119), train_loss = 1.57802644, grad/param norm = 1.7389e-01, time/batch = 0.6465s	
3057/29850 (epoch 5.121), train_loss = 1.39360433, grad/param norm = 1.7604e-01, time/batch = 0.6500s	
3058/29850 (epoch 5.122), train_loss = 1.43681576, grad/param norm = 1.7617e-01, time/batch = 0.6554s	
3059/29850 (epoch 5.124), train_loss = 1.46703377, grad/param norm = 1.7093e-01, time/batch = 0.6684s	
3060/29850 (epoch 5.126), train_loss = 1.57764997, grad/param norm = 1.8248e-01, time/batch = 0.6510s	
3061/29850 (epoch 5.127), train_loss = 1.81090549, grad/param norm = 2.0631e-01, time/batch = 0.6619s	
3062/29850 (epoch 5.129), train_loss = 1.54173116, grad/param norm = 1.8907e-01, time/batch = 0.6448s	
3063/29850 (epoch 5.131), train_loss = 1.52668659, grad/param norm = 1.8738e-01, time/batch = 0.6407s	
3064/29850 (epoch 5.132), train_loss = 1.54589210, grad/param norm = 1.9849e-01, time/batch = 0.6498s	
3065/29850 (epoch 5.134), train_loss = 1.65803780, grad/param norm = 1.8591e-01, time/batch = 0.6489s	
3066/29850 (epoch 5.136), train_loss = 1.62195908, grad/param norm = 1.8572e-01, time/batch = 0.6469s	
3067/29850 (epoch 5.137), train_loss = 1.56357982, grad/param norm = 1.9662e-01, time/batch = 0.6450s	
3068/29850 (epoch 5.139), train_loss = 1.51707586, grad/param norm = 1.8784e-01, time/batch = 0.6460s	
3069/29850 (epoch 5.141), train_loss = 1.55156574, grad/param norm = 1.8097e-01, time/batch = 0.6414s	
3070/29850 (epoch 5.142), train_loss = 1.65574919, grad/param norm = 2.1490e-01, time/batch = 0.6415s	
3071/29850 (epoch 5.144), train_loss = 1.77091705, grad/param norm = 1.9461e-01, time/batch = 0.6397s	
3072/29850 (epoch 5.146), train_loss = 1.72537706, grad/param norm = 2.0315e-01, time/batch = 0.6367s	
3073/29850 (epoch 5.147), train_loss = 1.70151307, grad/param norm = 2.0005e-01, time/batch = 0.6399s	
3074/29850 (epoch 5.149), train_loss = 1.65085771, grad/param norm = 1.9917e-01, time/batch = 0.6448s	
3075/29850 (epoch 5.151), train_loss = 1.59027887, grad/param norm = 2.1625e-01, time/batch = 0.6411s	
3076/29850 (epoch 5.152), train_loss = 1.49454394, grad/param norm = 1.7546e-01, time/batch = 0.6436s	
3077/29850 (epoch 5.154), train_loss = 1.53456424, grad/param norm = 1.8558e-01, time/batch = 0.6430s	
3078/29850 (epoch 5.156), train_loss = 1.46843855, grad/param norm = 1.7063e-01, time/batch = 0.6504s	
3079/29850 (epoch 5.157), train_loss = 1.55945526, grad/param norm = 1.6521e-01, time/batch = 0.6497s	
3080/29850 (epoch 5.159), train_loss = 1.60853992, grad/param norm = 1.7349e-01, time/batch = 0.6431s	
3081/29850 (epoch 5.161), train_loss = 1.68148461, grad/param norm = 1.9300e-01, time/batch = 0.6503s	
3082/29850 (epoch 5.162), train_loss = 1.69110040, grad/param norm = 1.9630e-01, time/batch = 0.6473s	
3083/29850 (epoch 5.164), train_loss = 1.54584719, grad/param norm = 1.9730e-01, time/batch = 0.6437s	
3084/29850 (epoch 5.166), train_loss = 1.45729349, grad/param norm = 1.7036e-01, time/batch = 0.6445s	
3085/29850 (epoch 5.168), train_loss = 1.36057038, grad/param norm = 1.6567e-01, time/batch = 0.6466s	
3086/29850 (epoch 5.169), train_loss = 1.78156236, grad/param norm = 2.0593e-01, time/batch = 0.6450s	
3087/29850 (epoch 5.171), train_loss = 1.73671885, grad/param norm = 1.9119e-01, time/batch = 0.6431s	
3088/29850 (epoch 5.173), train_loss = 1.60972761, grad/param norm = 1.8005e-01, time/batch = 0.6479s	
3089/29850 (epoch 5.174), train_loss = 1.71276874, grad/param norm = 1.9206e-01, time/batch = 0.6464s	
3090/29850 (epoch 5.176), train_loss = 1.65252544, grad/param norm = 2.0141e-01, time/batch = 0.6443s	
3091/29850 (epoch 5.178), train_loss = 1.66864314, grad/param norm = 1.8816e-01, time/batch = 0.6450s	
3092/29850 (epoch 5.179), train_loss = 1.38345851, grad/param norm = 1.8529e-01, time/batch = 0.6459s	
3093/29850 (epoch 5.181), train_loss = 1.50895367, grad/param norm = 1.7506e-01, time/batch = 0.6443s	
3094/29850 (epoch 5.183), train_loss = 1.50633995, grad/param norm = 1.7721e-01, time/batch = 0.6429s	
3095/29850 (epoch 5.184), train_loss = 1.51887218, grad/param norm = 1.7973e-01, time/batch = 0.6476s	
3096/29850 (epoch 5.186), train_loss = 1.51265208, grad/param norm = 1.9518e-01, time/batch = 0.6503s	
3097/29850 (epoch 5.188), train_loss = 1.61141575, grad/param norm = 2.0775e-01, time/batch = 0.6489s	
3098/29850 (epoch 5.189), train_loss = 1.75083072, grad/param norm = 2.0364e-01, time/batch = 0.6522s	
3099/29850 (epoch 5.191), train_loss = 1.61096978, grad/param norm = 2.0135e-01, time/batch = 0.6505s	
3100/29850 (epoch 5.193), train_loss = 1.41364148, grad/param norm = 1.6685e-01, time/batch = 0.6508s	
3101/29850 (epoch 5.194), train_loss = 1.65125095, grad/param norm = 2.5282e-01, time/batch = 0.6497s	
3102/29850 (epoch 5.196), train_loss = 1.55432988, grad/param norm = 2.0536e-01, time/batch = 0.6556s	
3103/29850 (epoch 5.198), train_loss = 1.52293464, grad/param norm = 1.6470e-01, time/batch = 0.6464s	
3104/29850 (epoch 5.199), train_loss = 1.82868277, grad/param norm = 1.9492e-01, time/batch = 0.6406s	
3105/29850 (epoch 5.201), train_loss = 1.62107081, grad/param norm = 2.2211e-01, time/batch = 0.6580s	
3106/29850 (epoch 5.203), train_loss = 1.62652009, grad/param norm = 2.0213e-01, time/batch = 0.6698s	
3107/29850 (epoch 5.204), train_loss = 1.58053788, grad/param norm = 1.9623e-01, time/batch = 0.6414s	
3108/29850 (epoch 5.206), train_loss = 1.51377142, grad/param norm = 1.8586e-01, time/batch = 0.6438s	
3109/29850 (epoch 5.208), train_loss = 1.78759163, grad/param norm = 1.7785e-01, time/batch = 0.6477s	
3110/29850 (epoch 5.209), train_loss = 1.49265183, grad/param norm = 1.9902e-01, time/batch = 0.6452s	
3111/29850 (epoch 5.211), train_loss = 1.49328869, grad/param norm = 1.6133e-01, time/batch = 0.6497s	
3112/29850 (epoch 5.213), train_loss = 1.76209129, grad/param norm = 1.9263e-01, time/batch = 0.6426s	
3113/29850 (epoch 5.214), train_loss = 1.50848498, grad/param norm = 1.8086e-01, time/batch = 0.6434s	
3114/29850 (epoch 5.216), train_loss = 1.58976753, grad/param norm = 1.9885e-01, time/batch = 0.6410s	
3115/29850 (epoch 5.218), train_loss = 1.66463890, grad/param norm = 1.9312e-01, time/batch = 0.6392s	
3116/29850 (epoch 5.219), train_loss = 1.81866174, grad/param norm = 2.0623e-01, time/batch = 0.6592s	
3117/29850 (epoch 5.221), train_loss = 1.50582831, grad/param norm = 1.8205e-01, time/batch = 0.6661s	
3118/29850 (epoch 5.223), train_loss = 1.61392804, grad/param norm = 1.7763e-01, time/batch = 0.6523s	
3119/29850 (epoch 5.224), train_loss = 1.47895825, grad/param norm = 1.8052e-01, time/batch = 0.6597s	
3120/29850 (epoch 5.226), train_loss = 1.56020572, grad/param norm = 1.9160e-01, time/batch = 0.6593s	
3121/29850 (epoch 5.228), train_loss = 1.49054841, grad/param norm = 1.7028e-01, time/batch = 0.6570s	
3122/29850 (epoch 5.229), train_loss = 1.42474950, grad/param norm = 1.8026e-01, time/batch = 0.6440s	
3123/29850 (epoch 5.231), train_loss = 1.46647501, grad/param norm = 1.7269e-01, time/batch = 0.6439s	
3124/29850 (epoch 5.233), train_loss = 1.54550554, grad/param norm = 1.8852e-01, time/batch = 0.6450s	
3125/29850 (epoch 5.235), train_loss = 1.44663453, grad/param norm = 1.6504e-01, time/batch = 0.6472s	
3126/29850 (epoch 5.236), train_loss = 1.77550699, grad/param norm = 2.1268e-01, time/batch = 0.6485s	
3127/29850 (epoch 5.238), train_loss = 1.42621895, grad/param norm = 2.0366e-01, time/batch = 0.6690s	
3128/29850 (epoch 5.240), train_loss = 1.57184147, grad/param norm = 1.7585e-01, time/batch = 0.6561s	
3129/29850 (epoch 5.241), train_loss = 1.77494848, grad/param norm = 1.8796e-01, time/batch = 0.6494s	
3130/29850 (epoch 5.243), train_loss = 1.54649966, grad/param norm = 1.7551e-01, time/batch = 0.6713s	
3131/29850 (epoch 5.245), train_loss = 1.56252888, grad/param norm = 1.8602e-01, time/batch = 0.6601s	
3132/29850 (epoch 5.246), train_loss = 1.52810862, grad/param norm = 1.8167e-01, time/batch = 0.6524s	
3133/29850 (epoch 5.248), train_loss = 1.55885229, grad/param norm = 1.9001e-01, time/batch = 0.6423s	
3134/29850 (epoch 5.250), train_loss = 1.64769436, grad/param norm = 1.9208e-01, time/batch = 0.6458s	
3135/29850 (epoch 5.251), train_loss = 1.48391133, grad/param norm = 1.7520e-01, time/batch = 0.6513s	
3136/29850 (epoch 5.253), train_loss = 1.56191051, grad/param norm = 2.0060e-01, time/batch = 0.6526s	
3137/29850 (epoch 5.255), train_loss = 1.53843984, grad/param norm = 1.7947e-01, time/batch = 0.6570s	
3138/29850 (epoch 5.256), train_loss = 1.55074799, grad/param norm = 1.8444e-01, time/batch = 0.6691s	
3139/29850 (epoch 5.258), train_loss = 1.52792144, grad/param norm = 1.8219e-01, time/batch = 0.6470s	
3140/29850 (epoch 5.260), train_loss = 1.49840017, grad/param norm = 1.6018e-01, time/batch = 0.6494s	
3141/29850 (epoch 5.261), train_loss = 1.49387841, grad/param norm = 1.7434e-01, time/batch = 0.6678s	
3142/29850 (epoch 5.263), train_loss = 1.41400132, grad/param norm = 1.7953e-01, time/batch = 0.6778s	
3143/29850 (epoch 5.265), train_loss = 1.52554610, grad/param norm = 1.9494e-01, time/batch = 0.6847s	
3144/29850 (epoch 5.266), train_loss = 1.53211550, grad/param norm = 1.9648e-01, time/batch = 0.6761s	
3145/29850 (epoch 5.268), train_loss = 1.51752742, grad/param norm = 1.9127e-01, time/batch = 0.6715s	
3146/29850 (epoch 5.270), train_loss = 1.51178284, grad/param norm = 1.9275e-01, time/batch = 0.6668s	
3147/29850 (epoch 5.271), train_loss = 1.65587045, grad/param norm = 1.9137e-01, time/batch = 0.6439s	
3148/29850 (epoch 5.273), train_loss = 1.47635340, grad/param norm = 1.8097e-01, time/batch = 0.6445s	
3149/29850 (epoch 5.275), train_loss = 1.52438318, grad/param norm = 1.8266e-01, time/batch = 0.6461s	
3150/29850 (epoch 5.276), train_loss = 1.44022010, grad/param norm = 1.7326e-01, time/batch = 0.6577s	
3151/29850 (epoch 5.278), train_loss = 1.48452050, grad/param norm = 1.7014e-01, time/batch = 0.6663s	
3152/29850 (epoch 5.280), train_loss = 1.61869851, grad/param norm = 1.7752e-01, time/batch = 0.6770s	
3153/29850 (epoch 5.281), train_loss = 1.48805752, grad/param norm = 1.8464e-01, time/batch = 0.6666s	
3154/29850 (epoch 5.283), train_loss = 1.63684559, grad/param norm = 1.8581e-01, time/batch = 0.6677s	
3155/29850 (epoch 5.285), train_loss = 1.52041070, grad/param norm = 1.9554e-01, time/batch = 0.6576s	
3156/29850 (epoch 5.286), train_loss = 1.53270291, grad/param norm = 1.7626e-01, time/batch = 0.6729s	
3157/29850 (epoch 5.288), train_loss = 1.72880100, grad/param norm = 2.2254e-01, time/batch = 0.6468s	
3158/29850 (epoch 5.290), train_loss = 1.47449460, grad/param norm = 2.0492e-01, time/batch = 0.6541s	
3159/29850 (epoch 5.291), train_loss = 1.82533525, grad/param norm = 1.9714e-01, time/batch = 0.6681s	
3160/29850 (epoch 5.293), train_loss = 1.66059483, grad/param norm = 1.8725e-01, time/batch = 0.6496s	
3161/29850 (epoch 5.295), train_loss = 1.68315498, grad/param norm = 1.8945e-01, time/batch = 0.6436s	
3162/29850 (epoch 5.296), train_loss = 1.45890186, grad/param norm = 1.7363e-01, time/batch = 0.6403s	
3163/29850 (epoch 5.298), train_loss = 1.31813108, grad/param norm = 1.7381e-01, time/batch = 0.6381s	
3164/29850 (epoch 5.300), train_loss = 1.41538448, grad/param norm = 1.6533e-01, time/batch = 0.6408s	
3165/29850 (epoch 5.302), train_loss = 1.40584132, grad/param norm = 1.7291e-01, time/batch = 0.6514s	
3166/29850 (epoch 5.303), train_loss = 1.56315663, grad/param norm = 1.8055e-01, time/batch = 0.6550s	
3167/29850 (epoch 5.305), train_loss = 1.47588647, grad/param norm = 1.7302e-01, time/batch = 0.6551s	
3168/29850 (epoch 5.307), train_loss = 1.63521064, grad/param norm = 2.0572e-01, time/batch = 0.6499s	
3169/29850 (epoch 5.308), train_loss = 1.61585139, grad/param norm = 1.9854e-01, time/batch = 0.6604s	
3170/29850 (epoch 5.310), train_loss = 1.62919166, grad/param norm = 1.9755e-01, time/batch = 0.6679s	
3171/29850 (epoch 5.312), train_loss = 1.58952700, grad/param norm = 1.8674e-01, time/batch = 0.6495s	
3172/29850 (epoch 5.313), train_loss = 1.60600594, grad/param norm = 1.9241e-01, time/batch = 0.6470s	
3173/29850 (epoch 5.315), train_loss = 1.56286863, grad/param norm = 1.8169e-01, time/batch = 0.6411s	
3174/29850 (epoch 5.317), train_loss = 1.62390214, grad/param norm = 1.8706e-01, time/batch = 0.6645s	
3175/29850 (epoch 5.318), train_loss = 1.59539526, grad/param norm = 1.9375e-01, time/batch = 0.6620s	
3176/29850 (epoch 5.320), train_loss = 1.39450543, grad/param norm = 1.7217e-01, time/batch = 0.6507s	
3177/29850 (epoch 5.322), train_loss = 1.65445412, grad/param norm = 1.9277e-01, time/batch = 0.6381s	
3178/29850 (epoch 5.323), train_loss = 1.58399530, grad/param norm = 2.0508e-01, time/batch = 0.6396s	
3179/29850 (epoch 5.325), train_loss = 1.52986673, grad/param norm = 1.8259e-01, time/batch = 0.6389s	
3180/29850 (epoch 5.327), train_loss = 1.71652439, grad/param norm = 2.1572e-01, time/batch = 0.6657s	
3181/29850 (epoch 5.328), train_loss = 1.73200791, grad/param norm = 2.0104e-01, time/batch = 0.6576s	
3182/29850 (epoch 5.330), train_loss = 1.54477603, grad/param norm = 1.8390e-01, time/batch = 0.6386s	
3183/29850 (epoch 5.332), train_loss = 1.46980036, grad/param norm = 1.8284e-01, time/batch = 0.6415s	
3184/29850 (epoch 5.333), train_loss = 1.72138621, grad/param norm = 1.8713e-01, time/batch = 0.6422s	
3185/29850 (epoch 5.335), train_loss = 1.61744412, grad/param norm = 1.9573e-01, time/batch = 0.6443s	
3186/29850 (epoch 5.337), train_loss = 1.61402187, grad/param norm = 1.8439e-01, time/batch = 0.6416s	
3187/29850 (epoch 5.338), train_loss = 1.54703387, grad/param norm = 1.7936e-01, time/batch = 0.6428s	
3188/29850 (epoch 5.340), train_loss = 1.43067619, grad/param norm = 1.7765e-01, time/batch = 0.6437s	
3189/29850 (epoch 5.342), train_loss = 1.61511823, grad/param norm = 1.9303e-01, time/batch = 0.6466s	
3190/29850 (epoch 5.343), train_loss = 1.63897325, grad/param norm = 1.9031e-01, time/batch = 0.6473s	
3191/29850 (epoch 5.345), train_loss = 1.69859870, grad/param norm = 1.9320e-01, time/batch = 0.6490s	
3192/29850 (epoch 5.347), train_loss = 1.65206930, grad/param norm = 1.9930e-01, time/batch = 0.6446s	
3193/29850 (epoch 5.348), train_loss = 1.59604651, grad/param norm = 1.8258e-01, time/batch = 0.6450s	
3194/29850 (epoch 5.350), train_loss = 1.67228213, grad/param norm = 2.0471e-01, time/batch = 0.6433s	
3195/29850 (epoch 5.352), train_loss = 1.60366635, grad/param norm = 1.8520e-01, time/batch = 0.6433s	
3196/29850 (epoch 5.353), train_loss = 1.59083975, grad/param norm = 1.8841e-01, time/batch = 0.6418s	
3197/29850 (epoch 5.355), train_loss = 1.43378842, grad/param norm = 1.9267e-01, time/batch = 0.6442s	
3198/29850 (epoch 5.357), train_loss = 1.70580276, grad/param norm = 1.7963e-01, time/batch = 0.6455s	
3199/29850 (epoch 5.358), train_loss = 1.39824224, grad/param norm = 1.7148e-01, time/batch = 0.6435s	
3200/29850 (epoch 5.360), train_loss = 1.49849479, grad/param norm = 1.7819e-01, time/batch = 0.6482s	
3201/29850 (epoch 5.362), train_loss = 1.53716428, grad/param norm = 1.8616e-01, time/batch = 0.6448s	
3202/29850 (epoch 5.363), train_loss = 1.55505739, grad/param norm = 1.7958e-01, time/batch = 0.6468s	
3203/29850 (epoch 5.365), train_loss = 1.72090287, grad/param norm = 2.0084e-01, time/batch = 0.6417s	
3204/29850 (epoch 5.367), train_loss = 1.50246567, grad/param norm = 1.6465e-01, time/batch = 0.6553s	
3205/29850 (epoch 5.369), train_loss = 1.45363346, grad/param norm = 1.8823e-01, time/batch = 0.6422s	
3206/29850 (epoch 5.370), train_loss = 1.36029991, grad/param norm = 1.7411e-01, time/batch = 0.6442s	
3207/29850 (epoch 5.372), train_loss = 1.73912662, grad/param norm = 1.9712e-01, time/batch = 0.6430s	
3208/29850 (epoch 5.374), train_loss = 1.49057840, grad/param norm = 1.7835e-01, time/batch = 0.6407s	
3209/29850 (epoch 5.375), train_loss = 1.52598807, grad/param norm = 2.0306e-01, time/batch = 0.6451s	
3210/29850 (epoch 5.377), train_loss = 1.61086602, grad/param norm = 1.8977e-01, time/batch = 0.6417s	
3211/29850 (epoch 5.379), train_loss = 1.68284947, grad/param norm = 1.9537e-01, time/batch = 0.6427s	
3212/29850 (epoch 5.380), train_loss = 1.60252496, grad/param norm = 1.9812e-01, time/batch = 0.6578s	
3213/29850 (epoch 5.382), train_loss = 1.65887116, grad/param norm = 1.9515e-01, time/batch = 0.6679s	
3214/29850 (epoch 5.384), train_loss = 1.51617430, grad/param norm = 1.8787e-01, time/batch = 0.6425s	
3215/29850 (epoch 5.385), train_loss = 1.61479974, grad/param norm = 1.8567e-01, time/batch = 0.6426s	
3216/29850 (epoch 5.387), train_loss = 1.58897409, grad/param norm = 1.8855e-01, time/batch = 0.6443s	
3217/29850 (epoch 5.389), train_loss = 1.71336956, grad/param norm = 1.9155e-01, time/batch = 0.6442s	
3218/29850 (epoch 5.390), train_loss = 1.55466635, grad/param norm = 1.7028e-01, time/batch = 0.6436s	
3219/29850 (epoch 5.392), train_loss = 1.54385290, grad/param norm = 1.8293e-01, time/batch = 0.6484s	
3220/29850 (epoch 5.394), train_loss = 1.63309822, grad/param norm = 1.8266e-01, time/batch = 0.6441s	
3221/29850 (epoch 5.395), train_loss = 1.64725705, grad/param norm = 1.9151e-01, time/batch = 0.6485s	
3222/29850 (epoch 5.397), train_loss = 1.60312246, grad/param norm = 1.8634e-01, time/batch = 0.6508s	
3223/29850 (epoch 5.399), train_loss = 1.44360094, grad/param norm = 1.7835e-01, time/batch = 0.6691s	
3224/29850 (epoch 5.400), train_loss = 1.77337077, grad/param norm = 2.2684e-01, time/batch = 0.6632s	
3225/29850 (epoch 5.402), train_loss = 1.65095431, grad/param norm = 2.0025e-01, time/batch = 0.6469s	
3226/29850 (epoch 5.404), train_loss = 1.64678671, grad/param norm = 1.9416e-01, time/batch = 0.6446s	
3227/29850 (epoch 5.405), train_loss = 1.68807621, grad/param norm = 1.8871e-01, time/batch = 0.6399s	
3228/29850 (epoch 5.407), train_loss = 1.55650872, grad/param norm = 2.0766e-01, time/batch = 0.6434s	
3229/29850 (epoch 5.409), train_loss = 1.80758445, grad/param norm = 1.9674e-01, time/batch = 0.6407s	
3230/29850 (epoch 5.410), train_loss = 1.67707373, grad/param norm = 1.8775e-01, time/batch = 0.6350s	
3231/29850 (epoch 5.412), train_loss = 1.54275138, grad/param norm = 1.9353e-01, time/batch = 0.6450s	
3232/29850 (epoch 5.414), train_loss = 1.60754600, grad/param norm = 1.8945e-01, time/batch = 0.6592s	
3233/29850 (epoch 5.415), train_loss = 1.57020487, grad/param norm = 1.7606e-01, time/batch = 0.6678s	
3234/29850 (epoch 5.417), train_loss = 1.70428664, grad/param norm = 1.9691e-01, time/batch = 0.6695s	
3235/29850 (epoch 5.419), train_loss = 1.58281809, grad/param norm = 1.9095e-01, time/batch = 0.6518s	
3236/29850 (epoch 5.420), train_loss = 1.53762105, grad/param norm = 1.7522e-01, time/batch = 0.6492s	
3237/29850 (epoch 5.422), train_loss = 1.52774364, grad/param norm = 1.8099e-01, time/batch = 0.6509s	
3238/29850 (epoch 5.424), train_loss = 1.62328829, grad/param norm = 1.8839e-01, time/batch = 0.6786s	
3239/29850 (epoch 5.425), train_loss = 1.82384181, grad/param norm = 1.8113e-01, time/batch = 0.6635s	
3240/29850 (epoch 5.427), train_loss = 1.44906792, grad/param norm = 1.9002e-01, time/batch = 0.6747s	
3241/29850 (epoch 5.429), train_loss = 1.45631766, grad/param norm = 1.7503e-01, time/batch = 0.6727s	
3242/29850 (epoch 5.430), train_loss = 1.38250672, grad/param norm = 1.7251e-01, time/batch = 0.6632s	
3243/29850 (epoch 5.432), train_loss = 1.55232048, grad/param norm = 1.8240e-01, time/batch = 0.6657s	
3244/29850 (epoch 5.434), train_loss = 1.48138442, grad/param norm = 1.7709e-01, time/batch = 0.6673s	
3245/29850 (epoch 5.436), train_loss = 1.61257527, grad/param norm = 1.9299e-01, time/batch = 0.6600s	
3246/29850 (epoch 5.437), train_loss = 1.53789656, grad/param norm = 1.7145e-01, time/batch = 0.6601s	
3247/29850 (epoch 5.439), train_loss = 1.58592285, grad/param norm = 1.8274e-01, time/batch = 0.6602s	
3248/29850 (epoch 5.441), train_loss = 1.60059661, grad/param norm = 1.8242e-01, time/batch = 0.6611s	
3249/29850 (epoch 5.442), train_loss = 1.63019426, grad/param norm = 1.8377e-01, time/batch = 0.6548s	
3250/29850 (epoch 5.444), train_loss = 1.53066681, grad/param norm = 1.7077e-01, time/batch = 0.6694s	
3251/29850 (epoch 5.446), train_loss = 1.57359990, grad/param norm = 1.7975e-01, time/batch = 0.6654s	
3252/29850 (epoch 5.447), train_loss = 1.68246066, grad/param norm = 2.0554e-01, time/batch = 0.6623s	
3253/29850 (epoch 5.449), train_loss = 1.68974592, grad/param norm = 1.8594e-01, time/batch = 0.6573s	
3254/29850 (epoch 5.451), train_loss = 1.55639220, grad/param norm = 1.8278e-01, time/batch = 0.6471s	
3255/29850 (epoch 5.452), train_loss = 1.35424739, grad/param norm = 1.7136e-01, time/batch = 0.6647s	
3256/29850 (epoch 5.454), train_loss = 1.49740972, grad/param norm = 1.7654e-01, time/batch = 0.6588s	
3257/29850 (epoch 5.456), train_loss = 1.60563508, grad/param norm = 1.8080e-01, time/batch = 0.6398s	
3258/29850 (epoch 5.457), train_loss = 1.78154069, grad/param norm = 2.5606e-01, time/batch = 0.6453s	
3259/29850 (epoch 5.459), train_loss = 1.80244265, grad/param norm = 2.0946e-01, time/batch = 0.6456s	
3260/29850 (epoch 5.461), train_loss = 1.75675461, grad/param norm = 2.0534e-01, time/batch = 0.6470s	
3261/29850 (epoch 5.462), train_loss = 1.62693546, grad/param norm = 1.9986e-01, time/batch = 0.6476s	
3262/29850 (epoch 5.464), train_loss = 1.56498266, grad/param norm = 1.6548e-01, time/batch = 0.6444s	
3263/29850 (epoch 5.466), train_loss = 1.46941417, grad/param norm = 1.8255e-01, time/batch = 0.6425s	
3264/29850 (epoch 5.467), train_loss = 1.62393991, grad/param norm = 1.8154e-01, time/batch = 0.6491s	
3265/29850 (epoch 5.469), train_loss = 1.61206156, grad/param norm = 1.7725e-01, time/batch = 0.6472s	
3266/29850 (epoch 5.471), train_loss = 1.60136174, grad/param norm = 1.7298e-01, time/batch = 0.6467s	
3267/29850 (epoch 5.472), train_loss = 1.50374817, grad/param norm = 1.7061e-01, time/batch = 0.6434s	
3268/29850 (epoch 5.474), train_loss = 1.73941223, grad/param norm = 1.9547e-01, time/batch = 0.6467s	
3269/29850 (epoch 5.476), train_loss = 1.60886912, grad/param norm = 1.8886e-01, time/batch = 0.6417s	
3270/29850 (epoch 5.477), train_loss = 1.63836059, grad/param norm = 1.7452e-01, time/batch = 0.6398s	
3271/29850 (epoch 5.479), train_loss = 1.65780473, grad/param norm = 1.9735e-01, time/batch = 0.6413s	
3272/29850 (epoch 5.481), train_loss = 1.69821406, grad/param norm = 1.9179e-01, time/batch = 0.6423s	
3273/29850 (epoch 5.482), train_loss = 1.48148183, grad/param norm = 1.7658e-01, time/batch = 0.6429s	
3274/29850 (epoch 5.484), train_loss = 1.55215572, grad/param norm = 1.7807e-01, time/batch = 0.6414s	
3275/29850 (epoch 5.486), train_loss = 1.54592013, grad/param norm = 1.8215e-01, time/batch = 0.6431s	
3276/29850 (epoch 5.487), train_loss = 1.48904986, grad/param norm = 1.9239e-01, time/batch = 0.6410s	
3277/29850 (epoch 5.489), train_loss = 1.57802833, grad/param norm = 1.8270e-01, time/batch = 0.6387s	
3278/29850 (epoch 5.491), train_loss = 1.44394335, grad/param norm = 1.7037e-01, time/batch = 0.6442s	
3279/29850 (epoch 5.492), train_loss = 1.67916693, grad/param norm = 1.8591e-01, time/batch = 0.6444s	
3280/29850 (epoch 5.494), train_loss = 1.74273942, grad/param norm = 1.6724e-01, time/batch = 0.6492s	
3281/29850 (epoch 5.496), train_loss = 1.74107576, grad/param norm = 1.8166e-01, time/batch = 0.6511s	
3282/29850 (epoch 5.497), train_loss = 1.57078643, grad/param norm = 1.8402e-01, time/batch = 0.6650s	
3283/29850 (epoch 5.499), train_loss = 1.57808189, grad/param norm = 1.7774e-01, time/batch = 0.6515s	
3284/29850 (epoch 5.501), train_loss = 1.50438044, grad/param norm = 1.8254e-01, time/batch = 0.6496s	
3285/29850 (epoch 5.503), train_loss = 1.54146407, grad/param norm = 1.8866e-01, time/batch = 0.6433s	
3286/29850 (epoch 5.504), train_loss = 1.72844386, grad/param norm = 1.9483e-01, time/batch = 0.6448s	
3287/29850 (epoch 5.506), train_loss = 1.79357586, grad/param norm = 1.9196e-01, time/batch = 0.6450s	
3288/29850 (epoch 5.508), train_loss = 1.59118265, grad/param norm = 1.8585e-01, time/batch = 0.6512s	
3289/29850 (epoch 5.509), train_loss = 1.38324832, grad/param norm = 1.7210e-01, time/batch = 0.6513s	
3290/29850 (epoch 5.511), train_loss = 1.55421858, grad/param norm = 1.8622e-01, time/batch = 0.6405s	
3291/29850 (epoch 5.513), train_loss = 1.66268642, grad/param norm = 1.9515e-01, time/batch = 0.6449s	
3292/29850 (epoch 5.514), train_loss = 1.42819927, grad/param norm = 1.6724e-01, time/batch = 0.6452s	
3293/29850 (epoch 5.516), train_loss = 1.40623168, grad/param norm = 1.6147e-01, time/batch = 0.6462s	
3294/29850 (epoch 5.518), train_loss = 1.43031906, grad/param norm = 1.6643e-01, time/batch = 0.6438s	
3295/29850 (epoch 5.519), train_loss = 1.43205601, grad/param norm = 1.6781e-01, time/batch = 0.6418s	
3296/29850 (epoch 5.521), train_loss = 1.49010372, grad/param norm = 1.7068e-01, time/batch = 0.6439s	
3297/29850 (epoch 5.523), train_loss = 1.38387967, grad/param norm = 1.6718e-01, time/batch = 0.6426s	
3298/29850 (epoch 5.524), train_loss = 1.61020440, grad/param norm = 1.8360e-01, time/batch = 0.6658s	
3299/29850 (epoch 5.526), train_loss = 1.64767087, grad/param norm = 1.8571e-01, time/batch = 0.6580s	
3300/29850 (epoch 5.528), train_loss = 1.69639236, grad/param norm = 2.0452e-01, time/batch = 0.6436s	
3301/29850 (epoch 5.529), train_loss = 1.71001999, grad/param norm = 2.1471e-01, time/batch = 0.6444s	
3302/29850 (epoch 5.531), train_loss = 1.63495479, grad/param norm = 2.0324e-01, time/batch = 0.6468s	
3303/29850 (epoch 5.533), train_loss = 1.45728955, grad/param norm = 1.8522e-01, time/batch = 0.6591s	
3304/29850 (epoch 5.534), train_loss = 1.53638589, grad/param norm = 1.9923e-01, time/batch = 0.6740s	
3305/29850 (epoch 5.536), train_loss = 1.60067574, grad/param norm = 1.8826e-01, time/batch = 0.6638s	
3306/29850 (epoch 5.538), train_loss = 1.60014178, grad/param norm = 1.7673e-01, time/batch = 0.6485s	
3307/29850 (epoch 5.539), train_loss = 1.62069290, grad/param norm = 1.8910e-01, time/batch = 0.6628s	
3308/29850 (epoch 5.541), train_loss = 1.40534845, grad/param norm = 1.7106e-01, time/batch = 0.6692s	
3309/29850 (epoch 5.543), train_loss = 1.48885055, grad/param norm = 1.7710e-01, time/batch = 0.6692s	
3310/29850 (epoch 5.544), train_loss = 1.57404774, grad/param norm = 1.8028e-01, time/batch = 0.6683s	
3311/29850 (epoch 5.546), train_loss = 1.66507921, grad/param norm = 1.8411e-01, time/batch = 0.6727s	
3312/29850 (epoch 5.548), train_loss = 1.46035403, grad/param norm = 1.6968e-01, time/batch = 0.6626s	
3313/29850 (epoch 5.549), train_loss = 1.55959296, grad/param norm = 1.7877e-01, time/batch = 0.6491s	
3314/29850 (epoch 5.551), train_loss = 1.51855809, grad/param norm = 1.8577e-01, time/batch = 0.6385s	
3315/29850 (epoch 5.553), train_loss = 1.63281980, grad/param norm = 1.9393e-01, time/batch = 0.6385s	
3316/29850 (epoch 5.554), train_loss = 1.35879345, grad/param norm = 1.5984e-01, time/batch = 0.6448s	
3317/29850 (epoch 5.556), train_loss = 1.57310066, grad/param norm = 2.0680e-01, time/batch = 0.6403s	
3318/29850 (epoch 5.558), train_loss = 1.50193234, grad/param norm = 1.7517e-01, time/batch = 0.6375s	
3319/29850 (epoch 5.559), train_loss = 1.65669384, grad/param norm = 1.9763e-01, time/batch = 0.6584s	
3320/29850 (epoch 5.561), train_loss = 1.64985443, grad/param norm = 1.8272e-01, time/batch = 0.6674s	
3321/29850 (epoch 5.563), train_loss = 1.56177886, grad/param norm = 1.9577e-01, time/batch = 0.6507s	
3322/29850 (epoch 5.564), train_loss = 1.56606301, grad/param norm = 1.9308e-01, time/batch = 0.6471s	
3323/29850 (epoch 5.566), train_loss = 1.47349317, grad/param norm = 1.8205e-01, time/batch = 0.6555s	
3324/29850 (epoch 5.568), train_loss = 1.65121709, grad/param norm = 1.7888e-01, time/batch = 0.6636s	
3325/29850 (epoch 5.570), train_loss = 1.57739166, grad/param norm = 1.7419e-01, time/batch = 0.6722s	
3326/29850 (epoch 5.571), train_loss = 1.63928020, grad/param norm = 1.8499e-01, time/batch = 0.6652s	
3327/29850 (epoch 5.573), train_loss = 1.72503954, grad/param norm = 1.9232e-01, time/batch = 0.6421s	
3328/29850 (epoch 5.575), train_loss = 1.64758169, grad/param norm = 1.8959e-01, time/batch = 0.6618s	
3329/29850 (epoch 5.576), train_loss = 1.72865412, grad/param norm = 1.8020e-01, time/batch = 0.6597s	
3330/29850 (epoch 5.578), train_loss = 1.63594133, grad/param norm = 1.8697e-01, time/batch = 0.6701s	
3331/29850 (epoch 5.580), train_loss = 1.64303178, grad/param norm = 1.9933e-01, time/batch = 0.6507s	
3332/29850 (epoch 5.581), train_loss = 1.55251533, grad/param norm = 2.0088e-01, time/batch = 0.6511s	
3333/29850 (epoch 5.583), train_loss = 1.50257548, grad/param norm = 1.6277e-01, time/batch = 0.6551s	
3334/29850 (epoch 5.585), train_loss = 1.50527141, grad/param norm = 1.6832e-01, time/batch = 0.6514s	
3335/29850 (epoch 5.586), train_loss = 1.55552114, grad/param norm = 1.8642e-01, time/batch = 0.6509s	
3336/29850 (epoch 5.588), train_loss = 1.51994483, grad/param norm = 1.6828e-01, time/batch = 0.6431s	
3337/29850 (epoch 5.590), train_loss = 1.59447897, grad/param norm = 1.8825e-01, time/batch = 0.6511s	
3338/29850 (epoch 5.591), train_loss = 1.49475150, grad/param norm = 1.7192e-01, time/batch = 0.6460s	
3339/29850 (epoch 5.593), train_loss = 1.51161415, grad/param norm = 1.7186e-01, time/batch = 0.6412s	
3340/29850 (epoch 5.595), train_loss = 1.45838825, grad/param norm = 1.6655e-01, time/batch = 0.6515s	
3341/29850 (epoch 5.596), train_loss = 1.44709395, grad/param norm = 1.7562e-01, time/batch = 0.6718s	
3342/29850 (epoch 5.598), train_loss = 1.43680572, grad/param norm = 1.9842e-01, time/batch = 0.6470s	
3343/29850 (epoch 5.600), train_loss = 1.68039036, grad/param norm = 1.9903e-01, time/batch = 0.6482s	
3344/29850 (epoch 5.601), train_loss = 1.43043623, grad/param norm = 1.6199e-01, time/batch = 0.6498s	
3345/29850 (epoch 5.603), train_loss = 1.58346032, grad/param norm = 1.7983e-01, time/batch = 0.6514s	
3346/29850 (epoch 5.605), train_loss = 1.63298986, grad/param norm = 2.0096e-01, time/batch = 0.6426s	
3347/29850 (epoch 5.606), train_loss = 1.37710618, grad/param norm = 1.7236e-01, time/batch = 0.6502s	
3348/29850 (epoch 5.608), train_loss = 1.55935856, grad/param norm = 1.8025e-01, time/batch = 0.6560s	
3349/29850 (epoch 5.610), train_loss = 1.52900304, grad/param norm = 1.8302e-01, time/batch = 0.6520s	
3350/29850 (epoch 5.611), train_loss = 1.32660326, grad/param norm = 1.6066e-01, time/batch = 0.6545s	
3351/29850 (epoch 5.613), train_loss = 1.34936483, grad/param norm = 1.6668e-01, time/batch = 0.6676s	
3352/29850 (epoch 5.615), train_loss = 1.39339127, grad/param norm = 1.6612e-01, time/batch = 0.6653s	
3353/29850 (epoch 5.616), train_loss = 1.54981243, grad/param norm = 1.8650e-01, time/batch = 0.6469s	
3354/29850 (epoch 5.618), train_loss = 1.55372848, grad/param norm = 1.7659e-01, time/batch = 0.6425s	
3355/29850 (epoch 5.620), train_loss = 1.55852299, grad/param norm = 1.9112e-01, time/batch = 0.6406s	
3356/29850 (epoch 5.621), train_loss = 1.62487251, grad/param norm = 2.1059e-01, time/batch = 0.6412s	
3357/29850 (epoch 5.623), train_loss = 1.62661494, grad/param norm = 1.9341e-01, time/batch = 0.6438s	
3358/29850 (epoch 5.625), train_loss = 1.65470453, grad/param norm = 1.9954e-01, time/batch = 0.6500s	
3359/29850 (epoch 5.626), train_loss = 1.65050762, grad/param norm = 2.0005e-01, time/batch = 0.6432s	
3360/29850 (epoch 5.628), train_loss = 1.38020834, grad/param norm = 1.7371e-01, time/batch = 0.6431s	
3361/29850 (epoch 5.630), train_loss = 1.56151422, grad/param norm = 1.8725e-01, time/batch = 0.6429s	
3362/29850 (epoch 5.631), train_loss = 1.44242001, grad/param norm = 1.8288e-01, time/batch = 0.6412s	
3363/29850 (epoch 5.633), train_loss = 1.64812727, grad/param norm = 1.9847e-01, time/batch = 0.6444s	
3364/29850 (epoch 5.635), train_loss = 1.57452233, grad/param norm = 1.9400e-01, time/batch = 0.6404s	
3365/29850 (epoch 5.637), train_loss = 1.65867434, grad/param norm = 1.9422e-01, time/batch = 0.6428s	
3366/29850 (epoch 5.638), train_loss = 1.45671719, grad/param norm = 1.7261e-01, time/batch = 0.6407s	
3367/29850 (epoch 5.640), train_loss = 1.72234511, grad/param norm = 1.8305e-01, time/batch = 0.6461s	
3368/29850 (epoch 5.642), train_loss = 1.52025797, grad/param norm = 1.7995e-01, time/batch = 0.6459s	
3369/29850 (epoch 5.643), train_loss = 1.47282228, grad/param norm = 1.7812e-01, time/batch = 0.6417s	
3370/29850 (epoch 5.645), train_loss = 1.58694879, grad/param norm = 1.7440e-01, time/batch = 0.6425s	
3371/29850 (epoch 5.647), train_loss = 1.67943417, grad/param norm = 1.8032e-01, time/batch = 0.6515s	
3372/29850 (epoch 5.648), train_loss = 1.38648053, grad/param norm = 1.6760e-01, time/batch = 0.6465s	
3373/29850 (epoch 5.650), train_loss = 1.54550055, grad/param norm = 2.0354e-01, time/batch = 0.6463s	
3374/29850 (epoch 5.652), train_loss = 1.53078332, grad/param norm = 1.7550e-01, time/batch = 0.6435s	
3375/29850 (epoch 5.653), train_loss = 1.65729023, grad/param norm = 1.8964e-01, time/batch = 0.6407s	
3376/29850 (epoch 5.655), train_loss = 1.52195955, grad/param norm = 1.8014e-01, time/batch = 0.6564s	
3377/29850 (epoch 5.657), train_loss = 1.48751133, grad/param norm = 1.6612e-01, time/batch = 0.6627s	
3378/29850 (epoch 5.658), train_loss = 1.64277819, grad/param norm = 1.9166e-01, time/batch = 0.6595s	
3379/29850 (epoch 5.660), train_loss = 1.42984189, grad/param norm = 1.8682e-01, time/batch = 0.6734s	
3380/29850 (epoch 5.662), train_loss = 1.53897286, grad/param norm = 1.9137e-01, time/batch = 0.6704s	
3381/29850 (epoch 5.663), train_loss = 1.61990825, grad/param norm = 2.0043e-01, time/batch = 0.6665s	
3382/29850 (epoch 5.665), train_loss = 1.57621257, grad/param norm = 1.8317e-01, time/batch = 0.6604s	
3383/29850 (epoch 5.667), train_loss = 1.65250633, grad/param norm = 2.0402e-01, time/batch = 0.6566s	
3384/29850 (epoch 5.668), train_loss = 1.61257438, grad/param norm = 1.8059e-01, time/batch = 0.6549s	
3385/29850 (epoch 5.670), train_loss = 1.86029424, grad/param norm = 1.9866e-01, time/batch = 0.6564s	
3386/29850 (epoch 5.672), train_loss = 1.62119186, grad/param norm = 1.9624e-01, time/batch = 0.6569s	
3387/29850 (epoch 5.673), train_loss = 1.62619001, grad/param norm = 1.7256e-01, time/batch = 0.6595s	
3388/29850 (epoch 5.675), train_loss = 1.54087384, grad/param norm = 1.7847e-01, time/batch = 0.6537s	
3389/29850 (epoch 5.677), train_loss = 1.55814233, grad/param norm = 1.7605e-01, time/batch = 0.6535s	
3390/29850 (epoch 5.678), train_loss = 1.51088074, grad/param norm = 1.8833e-01, time/batch = 0.6546s	
3391/29850 (epoch 5.680), train_loss = 1.58793359, grad/param norm = 1.9624e-01, time/batch = 0.6550s	
3392/29850 (epoch 5.682), train_loss = 1.53818016, grad/param norm = 1.7715e-01, time/batch = 0.6526s	
3393/29850 (epoch 5.683), train_loss = 1.76473842, grad/param norm = 2.0147e-01, time/batch = 0.6528s	
3394/29850 (epoch 5.685), train_loss = 1.69677857, grad/param norm = 1.7221e-01, time/batch = 0.6533s	
3395/29850 (epoch 5.687), train_loss = 1.62788992, grad/param norm = 1.9654e-01, time/batch = 0.6557s	
3396/29850 (epoch 5.688), train_loss = 1.39351311, grad/param norm = 1.4719e-01, time/batch = 0.6524s	
3397/29850 (epoch 5.690), train_loss = 1.48076457, grad/param norm = 1.9903e-01, time/batch = 0.6537s	
3398/29850 (epoch 5.692), train_loss = 1.75880489, grad/param norm = 2.0398e-01, time/batch = 0.6619s	
3399/29850 (epoch 5.693), train_loss = 1.52516348, grad/param norm = 1.6367e-01, time/batch = 0.6842s	
3400/29850 (epoch 5.695), train_loss = 1.45691176, grad/param norm = 1.8567e-01, time/batch = 0.6601s	
3401/29850 (epoch 5.697), train_loss = 1.66507984, grad/param norm = 2.1038e-01, time/batch = 0.6567s	
3402/29850 (epoch 5.698), train_loss = 1.66102493, grad/param norm = 1.9012e-01, time/batch = 0.6671s	
3403/29850 (epoch 5.700), train_loss = 1.66271710, grad/param norm = 1.9927e-01, time/batch = 0.6590s	
3404/29850 (epoch 5.702), train_loss = 1.52000978, grad/param norm = 1.9552e-01, time/batch = 0.6569s	
3405/29850 (epoch 5.704), train_loss = 1.49566810, grad/param norm = 1.8714e-01, time/batch = 0.6546s	
3406/29850 (epoch 5.705), train_loss = 1.54247524, grad/param norm = 1.6907e-01, time/batch = 0.6569s	
3407/29850 (epoch 5.707), train_loss = 1.58021366, grad/param norm = 1.8198e-01, time/batch = 0.6549s	
3408/29850 (epoch 5.709), train_loss = 1.70324411, grad/param norm = 1.9352e-01, time/batch = 0.6627s	
3409/29850 (epoch 5.710), train_loss = 1.54681638, grad/param norm = 1.9046e-01, time/batch = 0.6751s	
3410/29850 (epoch 5.712), train_loss = 1.53252151, grad/param norm = 1.7279e-01, time/batch = 0.6717s	
3411/29850 (epoch 5.714), train_loss = 1.57461399, grad/param norm = 1.9950e-01, time/batch = 0.6527s	
3412/29850 (epoch 5.715), train_loss = 1.67682846, grad/param norm = 1.9326e-01, time/batch = 0.6519s	
3413/29850 (epoch 5.717), train_loss = 1.44997435, grad/param norm = 1.8052e-01, time/batch = 0.6554s	
3414/29850 (epoch 5.719), train_loss = 1.55146922, grad/param norm = 1.7800e-01, time/batch = 0.6596s	
3415/29850 (epoch 5.720), train_loss = 1.61286336, grad/param norm = 1.8735e-01, time/batch = 0.6740s	
3416/29850 (epoch 5.722), train_loss = 1.47835221, grad/param norm = 1.7268e-01, time/batch = 0.6834s	
3417/29850 (epoch 5.724), train_loss = 1.54351396, grad/param norm = 1.7704e-01, time/batch = 0.6796s	
3418/29850 (epoch 5.725), train_loss = 1.42638396, grad/param norm = 1.6480e-01, time/batch = 0.6628s	
3419/29850 (epoch 5.727), train_loss = 1.52886681, grad/param norm = 1.8458e-01, time/batch = 0.6667s	
3420/29850 (epoch 5.729), train_loss = 1.35371834, grad/param norm = 1.7043e-01, time/batch = 0.6817s	
3421/29850 (epoch 5.730), train_loss = 1.43111264, grad/param norm = 1.6802e-01, time/batch = 0.6665s	
3422/29850 (epoch 5.732), train_loss = 1.49397999, grad/param norm = 1.6495e-01, time/batch = 0.6622s	
3423/29850 (epoch 5.734), train_loss = 1.73000439, grad/param norm = 1.8554e-01, time/batch = 0.6615s	
3424/29850 (epoch 5.735), train_loss = 1.61084401, grad/param norm = 1.8390e-01, time/batch = 0.6623s	
3425/29850 (epoch 5.737), train_loss = 1.42432409, grad/param norm = 1.7087e-01, time/batch = 0.6561s	
3426/29850 (epoch 5.739), train_loss = 1.44461936, grad/param norm = 1.7877e-01, time/batch = 0.6611s	
3427/29850 (epoch 5.740), train_loss = 1.46892328, grad/param norm = 1.9398e-01, time/batch = 0.6544s	
3428/29850 (epoch 5.742), train_loss = 1.44460427, grad/param norm = 1.8685e-01, time/batch = 0.6552s	
3429/29850 (epoch 5.744), train_loss = 1.54677584, grad/param norm = 1.9540e-01, time/batch = 0.6549s	
3430/29850 (epoch 5.745), train_loss = 1.53833388, grad/param norm = 1.9576e-01, time/batch = 0.6565s	
3431/29850 (epoch 5.747), train_loss = 1.46943995, grad/param norm = 1.8969e-01, time/batch = 0.6572s	
3432/29850 (epoch 5.749), train_loss = 1.46149748, grad/param norm = 1.8630e-01, time/batch = 0.6529s	
3433/29850 (epoch 5.750), train_loss = 1.56770105, grad/param norm = 1.9523e-01, time/batch = 0.6536s	
3434/29850 (epoch 5.752), train_loss = 1.50946156, grad/param norm = 1.6739e-01, time/batch = 0.6553s	
3435/29850 (epoch 5.754), train_loss = 1.46791747, grad/param norm = 1.8005e-01, time/batch = 0.6566s	
3436/29850 (epoch 5.755), train_loss = 1.54708128, grad/param norm = 1.7539e-01, time/batch = 0.6603s	
3437/29850 (epoch 5.757), train_loss = 1.48271433, grad/param norm = 1.7842e-01, time/batch = 0.6617s	
3438/29850 (epoch 5.759), train_loss = 1.56737498, grad/param norm = 1.6063e-01, time/batch = 0.6559s	
3439/29850 (epoch 5.760), train_loss = 1.41850477, grad/param norm = 1.7519e-01, time/batch = 0.6508s	
3440/29850 (epoch 5.762), train_loss = 1.45732546, grad/param norm = 2.0782e-01, time/batch = 0.6484s	
3441/29850 (epoch 5.764), train_loss = 1.53672186, grad/param norm = 1.9690e-01, time/batch = 0.6528s	
3442/29850 (epoch 5.765), train_loss = 1.48554533, grad/param norm = 2.0640e-01, time/batch = 0.6510s	
3443/29850 (epoch 5.767), train_loss = 1.56368267, grad/param norm = 1.7293e-01, time/batch = 0.6551s	
3444/29850 (epoch 5.769), train_loss = 1.48622309, grad/param norm = 1.8386e-01, time/batch = 0.6535s	
3445/29850 (epoch 5.771), train_loss = 1.58077290, grad/param norm = 1.9599e-01, time/batch = 0.6554s	
3446/29850 (epoch 5.772), train_loss = 1.65412043, grad/param norm = 1.8514e-01, time/batch = 0.6542s	
3447/29850 (epoch 5.774), train_loss = 1.51812505, grad/param norm = 1.8694e-01, time/batch = 0.6524s	
3448/29850 (epoch 5.776), train_loss = 1.50570503, grad/param norm = 1.9134e-01, time/batch = 0.6539s	
3449/29850 (epoch 5.777), train_loss = 1.59392136, grad/param norm = 1.7565e-01, time/batch = 0.6569s	
3450/29850 (epoch 5.779), train_loss = 1.37822630, grad/param norm = 1.7060e-01, time/batch = 0.6524s	
3451/29850 (epoch 5.781), train_loss = 1.43678044, grad/param norm = 1.7409e-01, time/batch = 0.6651s	
3452/29850 (epoch 5.782), train_loss = 1.50585671, grad/param norm = 1.6907e-01, time/batch = 0.6577s	
3453/29850 (epoch 5.784), train_loss = 1.47200428, grad/param norm = 1.8523e-01, time/batch = 0.6527s	
3454/29850 (epoch 5.786), train_loss = 1.46276456, grad/param norm = 1.8048e-01, time/batch = 0.6573s	
3455/29850 (epoch 5.787), train_loss = 1.48157455, grad/param norm = 1.8803e-01, time/batch = 0.6570s	
3456/29850 (epoch 5.789), train_loss = 1.41188619, grad/param norm = 1.6893e-01, time/batch = 0.6608s	
3457/29850 (epoch 5.791), train_loss = 1.56480434, grad/param norm = 1.9696e-01, time/batch = 0.6548s	
3458/29850 (epoch 5.792), train_loss = 1.57983879, grad/param norm = 1.9194e-01, time/batch = 0.6554s	
3459/29850 (epoch 5.794), train_loss = 1.53906756, grad/param norm = 1.8152e-01, time/batch = 0.6588s	
3460/29850 (epoch 5.796), train_loss = 1.44736468, grad/param norm = 1.8244e-01, time/batch = 0.6735s	
3461/29850 (epoch 5.797), train_loss = 1.48486353, grad/param norm = 1.5652e-01, time/batch = 0.6577s	
3462/29850 (epoch 5.799), train_loss = 1.44741530, grad/param norm = 1.6329e-01, time/batch = 0.6575s	
3463/29850 (epoch 5.801), train_loss = 1.63574953, grad/param norm = 1.8919e-01, time/batch = 0.6620s	
3464/29850 (epoch 5.802), train_loss = 1.42245479, grad/param norm = 1.9164e-01, time/batch = 0.6580s	
3465/29850 (epoch 5.804), train_loss = 1.51173902, grad/param norm = 1.7141e-01, time/batch = 0.6585s	
3466/29850 (epoch 5.806), train_loss = 1.51535361, grad/param norm = 1.7358e-01, time/batch = 0.6666s	
3467/29850 (epoch 5.807), train_loss = 1.37031436, grad/param norm = 1.6542e-01, time/batch = 0.6819s	
3468/29850 (epoch 5.809), train_loss = 1.58315306, grad/param norm = 2.0349e-01, time/batch = 0.6582s	
3469/29850 (epoch 5.811), train_loss = 1.63867302, grad/param norm = 1.8243e-01, time/batch = 0.6538s	
3470/29850 (epoch 5.812), train_loss = 1.54533054, grad/param norm = 1.8051e-01, time/batch = 0.6534s	
3471/29850 (epoch 5.814), train_loss = 1.61829831, grad/param norm = 1.8881e-01, time/batch = 0.6556s	
3472/29850 (epoch 5.816), train_loss = 1.57830386, grad/param norm = 1.7147e-01, time/batch = 0.6647s	
3473/29850 (epoch 5.817), train_loss = 1.56858081, grad/param norm = 1.8180e-01, time/batch = 0.6698s	
3474/29850 (epoch 5.819), train_loss = 1.51435579, grad/param norm = 1.8523e-01, time/batch = 0.6731s	
3475/29850 (epoch 5.821), train_loss = 1.69293785, grad/param norm = 2.0185e-01, time/batch = 0.6748s	
3476/29850 (epoch 5.822), train_loss = 1.49089856, grad/param norm = 1.6402e-01, time/batch = 0.6766s	
3477/29850 (epoch 5.824), train_loss = 1.51180449, grad/param norm = 1.8232e-01, time/batch = 0.6726s	
3478/29850 (epoch 5.826), train_loss = 1.53338580, grad/param norm = 1.7958e-01, time/batch = 0.6705s	
3479/29850 (epoch 5.827), train_loss = 1.46028208, grad/param norm = 1.8348e-01, time/batch = 0.6652s	
3480/29850 (epoch 5.829), train_loss = 1.56364378, grad/param norm = 1.9119e-01, time/batch = 0.6678s	
3481/29850 (epoch 5.831), train_loss = 1.54741036, grad/param norm = 1.9065e-01, time/batch = 0.6686s	
3482/29850 (epoch 5.832), train_loss = 1.41012440, grad/param norm = 1.7746e-01, time/batch = 0.6706s	
3483/29850 (epoch 5.834), train_loss = 1.42363699, grad/param norm = 1.8401e-01, time/batch = 0.6752s	
3484/29850 (epoch 5.836), train_loss = 1.41912943, grad/param norm = 1.6680e-01, time/batch = 0.6784s	
3485/29850 (epoch 5.838), train_loss = 1.59112884, grad/param norm = 1.7941e-01, time/batch = 0.6769s	
3486/29850 (epoch 5.839), train_loss = 1.52427160, grad/param norm = 1.8631e-01, time/batch = 0.6725s	
3487/29850 (epoch 5.841), train_loss = 1.53164843, grad/param norm = 1.8043e-01, time/batch = 0.6748s	
3488/29850 (epoch 5.843), train_loss = 1.50988105, grad/param norm = 1.6442e-01, time/batch = 0.6752s	
3489/29850 (epoch 5.844), train_loss = 1.48250284, grad/param norm = 1.8379e-01, time/batch = 0.6619s	
3490/29850 (epoch 5.846), train_loss = 1.58775458, grad/param norm = 1.9137e-01, time/batch = 0.6552s	
3491/29850 (epoch 5.848), train_loss = 1.58698689, grad/param norm = 1.8831e-01, time/batch = 0.6569s	
3492/29850 (epoch 5.849), train_loss = 1.41937191, grad/param norm = 2.0574e-01, time/batch = 0.6552s	
3493/29850 (epoch 5.851), train_loss = 1.58105868, grad/param norm = 1.8656e-01, time/batch = 0.6592s	
3494/29850 (epoch 5.853), train_loss = 1.48485229, grad/param norm = 1.9359e-01, time/batch = 0.6596s	
3495/29850 (epoch 5.854), train_loss = 1.56193154, grad/param norm = 1.9486e-01, time/batch = 0.6570s	
3496/29850 (epoch 5.856), train_loss = 1.58849021, grad/param norm = 2.0272e-01, time/batch = 0.6566s	
3497/29850 (epoch 5.858), train_loss = 1.51918758, grad/param norm = 1.8396e-01, time/batch = 0.6590s	
3498/29850 (epoch 5.859), train_loss = 1.46511492, grad/param norm = 1.9741e-01, time/batch = 0.6576s	
3499/29850 (epoch 5.861), train_loss = 1.64800274, grad/param norm = 2.0198e-01, time/batch = 0.6636s	
3500/29850 (epoch 5.863), train_loss = 1.62983160, grad/param norm = 1.7226e-01, time/batch = 0.6601s	
3501/29850 (epoch 5.864), train_loss = 1.52929431, grad/param norm = 1.8666e-01, time/batch = 0.6634s	
3502/29850 (epoch 5.866), train_loss = 1.51955885, grad/param norm = 1.8031e-01, time/batch = 0.6580s	
3503/29850 (epoch 5.868), train_loss = 1.62697316, grad/param norm = 1.9333e-01, time/batch = 0.6632s	
3504/29850 (epoch 5.869), train_loss = 1.46957843, grad/param norm = 1.9520e-01, time/batch = 0.6712s	
3505/29850 (epoch 5.871), train_loss = 1.52549511, grad/param norm = 1.8024e-01, time/batch = 0.6779s	
3506/29850 (epoch 5.873), train_loss = 1.59675631, grad/param norm = 1.9434e-01, time/batch = 0.6791s	
3507/29850 (epoch 5.874), train_loss = 1.56583736, grad/param norm = 1.9346e-01, time/batch = 0.6908s	
3508/29850 (epoch 5.876), train_loss = 1.61576442, grad/param norm = 2.0777e-01, time/batch = 0.6775s	
3509/29850 (epoch 5.878), train_loss = 1.51409428, grad/param norm = 1.7664e-01, time/batch = 0.6773s	
3510/29850 (epoch 5.879), train_loss = 1.63293654, grad/param norm = 1.7033e-01, time/batch = 0.6548s	
3511/29850 (epoch 5.881), train_loss = 1.60472842, grad/param norm = 1.8386e-01, time/batch = 0.6539s	
3512/29850 (epoch 5.883), train_loss = 1.64707416, grad/param norm = 1.8622e-01, time/batch = 0.6539s	
3513/29850 (epoch 5.884), train_loss = 1.39646927, grad/param norm = 1.7032e-01, time/batch = 0.6542s	
3514/29850 (epoch 5.886), train_loss = 1.77278464, grad/param norm = 2.0702e-01, time/batch = 0.6600s	
3515/29850 (epoch 5.888), train_loss = 1.48915578, grad/param norm = 1.9169e-01, time/batch = 0.6555s	
3516/29850 (epoch 5.889), train_loss = 1.45560760, grad/param norm = 1.8591e-01, time/batch = 0.6562s	
3517/29850 (epoch 5.891), train_loss = 1.46907468, grad/param norm = 1.8176e-01, time/batch = 0.6583s	
3518/29850 (epoch 5.893), train_loss = 1.41544327, grad/param norm = 1.8205e-01, time/batch = 0.6560s	
3519/29850 (epoch 5.894), train_loss = 1.46226370, grad/param norm = 1.7130e-01, time/batch = 0.6820s	
3520/29850 (epoch 5.896), train_loss = 1.44892507, grad/param norm = 1.7927e-01, time/batch = 0.6781s	
3521/29850 (epoch 5.898), train_loss = 1.65307234, grad/param norm = 1.9528e-01, time/batch = 0.6568s	
3522/29850 (epoch 5.899), train_loss = 1.35729890, grad/param norm = 1.8903e-01, time/batch = 0.6569s	
3523/29850 (epoch 5.901), train_loss = 1.89528187, grad/param norm = 2.2543e-01, time/batch = 0.6554s	
3524/29850 (epoch 5.903), train_loss = 1.58513076, grad/param norm = 2.0392e-01, time/batch = 0.6716s	
3525/29850 (epoch 5.905), train_loss = 1.67151805, grad/param norm = 1.7909e-01, time/batch = 0.6664s	
3526/29850 (epoch 5.906), train_loss = 1.40979334, grad/param norm = 1.9197e-01, time/batch = 0.6720s	
3527/29850 (epoch 5.908), train_loss = 1.69367417, grad/param norm = 1.9814e-01, time/batch = 0.6636s	
3528/29850 (epoch 5.910), train_loss = 1.62535068, grad/param norm = 1.8109e-01, time/batch = 0.6568s	
3529/29850 (epoch 5.911), train_loss = 1.64884492, grad/param norm = 1.8754e-01, time/batch = 0.6719s	
3530/29850 (epoch 5.913), train_loss = 1.54199745, grad/param norm = 1.7720e-01, time/batch = 0.6783s	
3531/29850 (epoch 5.915), train_loss = 1.58330055, grad/param norm = 1.9083e-01, time/batch = 0.6581s	
3532/29850 (epoch 5.916), train_loss = 1.51733986, grad/param norm = 1.8373e-01, time/batch = 0.6530s	
3533/29850 (epoch 5.918), train_loss = 1.45324814, grad/param norm = 1.6181e-01, time/batch = 0.6586s	
3534/29850 (epoch 5.920), train_loss = 1.58202605, grad/param norm = 1.6825e-01, time/batch = 0.6560s	
3535/29850 (epoch 5.921), train_loss = 1.60440604, grad/param norm = 1.9595e-01, time/batch = 0.6593s	
3536/29850 (epoch 5.923), train_loss = 1.59342128, grad/param norm = 1.8072e-01, time/batch = 0.6563s	
3537/29850 (epoch 5.925), train_loss = 1.69424117, grad/param norm = 1.9138e-01, time/batch = 0.6573s	
3538/29850 (epoch 5.926), train_loss = 1.66432995, grad/param norm = 1.8882e-01, time/batch = 0.6551s	
3539/29850 (epoch 5.928), train_loss = 1.51221749, grad/param norm = 1.9104e-01, time/batch = 0.6583s	
3540/29850 (epoch 5.930), train_loss = 1.67481967, grad/param norm = 1.9217e-01, time/batch = 0.6830s	
3541/29850 (epoch 5.931), train_loss = 1.64992036, grad/param norm = 1.9165e-01, time/batch = 0.6760s	
3542/29850 (epoch 5.933), train_loss = 1.70976770, grad/param norm = 1.9270e-01, time/batch = 0.6803s	
3543/29850 (epoch 5.935), train_loss = 1.68261555, grad/param norm = 1.8133e-01, time/batch = 0.6734s	
3544/29850 (epoch 5.936), train_loss = 1.62629119, grad/param norm = 1.9241e-01, time/batch = 0.6611s	
3545/29850 (epoch 5.938), train_loss = 1.42174697, grad/param norm = 1.6952e-01, time/batch = 0.6585s	
3546/29850 (epoch 5.940), train_loss = 1.37222255, grad/param norm = 1.7129e-01, time/batch = 0.6579s	
3547/29850 (epoch 5.941), train_loss = 1.51164862, grad/param norm = 1.8880e-01, time/batch = 0.6579s	
3548/29850 (epoch 5.943), train_loss = 1.47566097, grad/param norm = 1.7934e-01, time/batch = 0.6621s	
3549/29850 (epoch 5.945), train_loss = 1.62233131, grad/param norm = 1.9061e-01, time/batch = 0.6674s	
3550/29850 (epoch 5.946), train_loss = 1.45235685, grad/param norm = 2.1130e-01, time/batch = 0.6666s	
3551/29850 (epoch 5.948), train_loss = 1.46899391, grad/param norm = 1.7212e-01, time/batch = 0.6640s	
3552/29850 (epoch 5.950), train_loss = 1.44841573, grad/param norm = 1.7571e-01, time/batch = 0.6597s	
3553/29850 (epoch 5.951), train_loss = 1.44262476, grad/param norm = 1.7544e-01, time/batch = 0.6638s	
3554/29850 (epoch 5.953), train_loss = 1.57897853, grad/param norm = 1.8058e-01, time/batch = 0.6642s	
3555/29850 (epoch 5.955), train_loss = 1.36240761, grad/param norm = 1.6351e-01, time/batch = 0.6779s	
3556/29850 (epoch 5.956), train_loss = 1.41515920, grad/param norm = 1.7522e-01, time/batch = 0.6679s	
3557/29850 (epoch 5.958), train_loss = 1.28986577, grad/param norm = 1.6443e-01, time/batch = 0.6567s	
3558/29850 (epoch 5.960), train_loss = 1.59387289, grad/param norm = 1.8841e-01, time/batch = 0.6631s	
3559/29850 (epoch 5.961), train_loss = 1.48839047, grad/param norm = 1.6358e-01, time/batch = 0.6526s	
3560/29850 (epoch 5.963), train_loss = 1.37793824, grad/param norm = 1.8330e-01, time/batch = 0.6520s	
3561/29850 (epoch 5.965), train_loss = 1.50198422, grad/param norm = 1.8598e-01, time/batch = 0.6550s	
3562/29850 (epoch 5.966), train_loss = 1.39271711, grad/param norm = 1.7641e-01, time/batch = 0.6526s	
3563/29850 (epoch 5.968), train_loss = 1.52398838, grad/param norm = 1.9075e-01, time/batch = 0.6604s	
3564/29850 (epoch 5.970), train_loss = 1.41711889, grad/param norm = 1.7694e-01, time/batch = 0.6573s	
3565/29850 (epoch 5.972), train_loss = 1.41154602, grad/param norm = 1.6875e-01, time/batch = 0.6577s	
3566/29850 (epoch 5.973), train_loss = 1.47560883, grad/param norm = 1.8417e-01, time/batch = 0.6578s	
3567/29850 (epoch 5.975), train_loss = 1.28384436, grad/param norm = 1.6242e-01, time/batch = 0.6562s	
3568/29850 (epoch 5.977), train_loss = 1.44983634, grad/param norm = 1.7655e-01, time/batch = 0.6579s	
3569/29850 (epoch 5.978), train_loss = 1.41875431, grad/param norm = 1.8354e-01, time/batch = 0.6563s	
3570/29850 (epoch 5.980), train_loss = 1.39763201, grad/param norm = 1.6326e-01, time/batch = 0.6548s	
3571/29850 (epoch 5.982), train_loss = 1.42225276, grad/param norm = 1.7855e-01, time/batch = 0.6592s	
3572/29850 (epoch 5.983), train_loss = 1.53821819, grad/param norm = 1.9211e-01, time/batch = 0.6579s	
3573/29850 (epoch 5.985), train_loss = 1.57671485, grad/param norm = 1.9414e-01, time/batch = 0.6587s	
3574/29850 (epoch 5.987), train_loss = 1.40877663, grad/param norm = 1.8160e-01, time/batch = 0.6640s	
3575/29850 (epoch 5.988), train_loss = 1.36160186, grad/param norm = 1.6264e-01, time/batch = 0.6601s	
3576/29850 (epoch 5.990), train_loss = 1.46989629, grad/param norm = 1.8849e-01, time/batch = 0.6650s	
3577/29850 (epoch 5.992), train_loss = 1.49817191, grad/param norm = 1.7852e-01, time/batch = 0.6576s	
3578/29850 (epoch 5.993), train_loss = 1.56621677, grad/param norm = 1.9004e-01, time/batch = 0.6554s	
3579/29850 (epoch 5.995), train_loss = 1.55033592, grad/param norm = 2.1505e-01, time/batch = 0.6556s	
3580/29850 (epoch 5.997), train_loss = 1.52996016, grad/param norm = 1.8825e-01, time/batch = 0.6576s	
3581/29850 (epoch 5.998), train_loss = 1.61909514, grad/param norm = 1.8888e-01, time/batch = 0.6581s	
3582/29850 (epoch 6.000), train_loss = 1.49058300, grad/param norm = 1.6818e-01, time/batch = 0.6579s	
3583/29850 (epoch 6.002), train_loss = 1.70353240, grad/param norm = 1.8521e-01, time/batch = 0.6573s	
3584/29850 (epoch 6.003), train_loss = 1.47152173, grad/param norm = 1.9093e-01, time/batch = 0.6534s	
3585/29850 (epoch 6.005), train_loss = 1.48447590, grad/param norm = 1.7460e-01, time/batch = 0.6630s	
3586/29850 (epoch 6.007), train_loss = 1.57627914, grad/param norm = 1.8420e-01, time/batch = 0.6566s	
3587/29850 (epoch 6.008), train_loss = 1.69275434, grad/param norm = 2.0402e-01, time/batch = 0.6614s	
3588/29850 (epoch 6.010), train_loss = 1.35790238, grad/param norm = 1.7250e-01, time/batch = 0.6598s	
3589/29850 (epoch 6.012), train_loss = 1.60094479, grad/param norm = 1.7176e-01, time/batch = 0.6668s	
3590/29850 (epoch 6.013), train_loss = 1.65078717, grad/param norm = 2.0838e-01, time/batch = 0.6506s	
3591/29850 (epoch 6.015), train_loss = 1.57757865, grad/param norm = 1.8343e-01, time/batch = 0.6540s	
3592/29850 (epoch 6.017), train_loss = 1.66635817, grad/param norm = 2.0395e-01, time/batch = 0.6619s	
3593/29850 (epoch 6.018), train_loss = 1.71791967, grad/param norm = 2.1474e-01, time/batch = 0.6833s	
3594/29850 (epoch 6.020), train_loss = 1.40943746, grad/param norm = 1.7751e-01, time/batch = 0.6568s	
3595/29850 (epoch 6.022), train_loss = 1.61449707, grad/param norm = 2.1052e-01, time/batch = 0.6628s	
3596/29850 (epoch 6.023), train_loss = 1.50761786, grad/param norm = 1.8374e-01, time/batch = 0.6835s	
3597/29850 (epoch 6.025), train_loss = 1.48813379, grad/param norm = 1.6064e-01, time/batch = 0.6918s	
3598/29850 (epoch 6.027), train_loss = 1.40208045, grad/param norm = 1.6890e-01, time/batch = 0.6811s	
3599/29850 (epoch 6.028), train_loss = 1.51473116, grad/param norm = 1.7542e-01, time/batch = 0.6978s	
3600/29850 (epoch 6.030), train_loss = 1.60141120, grad/param norm = 1.6696e-01, time/batch = 0.6767s	
3601/29850 (epoch 6.032), train_loss = 1.46321858, grad/param norm = 1.8229e-01, time/batch = 0.6795s	
3602/29850 (epoch 6.034), train_loss = 1.57801134, grad/param norm = 2.0361e-01, time/batch = 0.6586s	
3603/29850 (epoch 6.035), train_loss = 1.45770457, grad/param norm = 1.7990e-01, time/batch = 0.6543s	
3604/29850 (epoch 6.037), train_loss = 1.57811283, grad/param norm = 1.8797e-01, time/batch = 0.6547s	
3605/29850 (epoch 6.039), train_loss = 1.39169182, grad/param norm = 1.7283e-01, time/batch = 0.6491s	
3606/29850 (epoch 6.040), train_loss = 1.36459078, grad/param norm = 1.7165e-01, time/batch = 0.6555s	
3607/29850 (epoch 6.042), train_loss = 1.47931013, grad/param norm = 1.8372e-01, time/batch = 0.6536s	
3608/29850 (epoch 6.044), train_loss = 1.36689964, grad/param norm = 1.8125e-01, time/batch = 0.6536s	
3609/29850 (epoch 6.045), train_loss = 1.54505801, grad/param norm = 1.7690e-01, time/batch = 0.6591s	
3610/29850 (epoch 6.047), train_loss = 1.34076510, grad/param norm = 1.7565e-01, time/batch = 0.6587s	
3611/29850 (epoch 6.049), train_loss = 1.53047624, grad/param norm = 1.9817e-01, time/batch = 0.6611s	
3612/29850 (epoch 6.050), train_loss = 1.39764195, grad/param norm = 1.7731e-01, time/batch = 0.6728s	
3613/29850 (epoch 6.052), train_loss = 1.76106479, grad/param norm = 2.1615e-01, time/batch = 0.6791s	
3614/29850 (epoch 6.054), train_loss = 1.54813575, grad/param norm = 1.9721e-01, time/batch = 0.6839s	
3615/29850 (epoch 6.055), train_loss = 1.52080335, grad/param norm = 1.9516e-01, time/batch = 0.6605s	
3616/29850 (epoch 6.057), train_loss = 1.50658779, grad/param norm = 1.8033e-01, time/batch = 0.6605s	
3617/29850 (epoch 6.059), train_loss = 1.59568350, grad/param norm = 1.8810e-01, time/batch = 0.6639s	
3618/29850 (epoch 6.060), train_loss = 1.49361073, grad/param norm = 2.0139e-01, time/batch = 0.6737s	
3619/29850 (epoch 6.062), train_loss = 1.65718826, grad/param norm = 2.1450e-01, time/batch = 0.6612s	
3620/29850 (epoch 6.064), train_loss = 1.54226976, grad/param norm = 1.8442e-01, time/batch = 0.6576s	
3621/29850 (epoch 6.065), train_loss = 1.38677976, grad/param norm = 1.9060e-01, time/batch = 0.6619s	
3622/29850 (epoch 6.067), train_loss = 1.49762709, grad/param norm = 1.7572e-01, time/batch = 0.6560s	
3623/29850 (epoch 6.069), train_loss = 1.45561788, grad/param norm = 1.7752e-01, time/batch = 0.6663s	
3624/29850 (epoch 6.070), train_loss = 1.49632464, grad/param norm = 1.7162e-01, time/batch = 0.6753s	
3625/29850 (epoch 6.072), train_loss = 1.64668690, grad/param norm = 2.0474e-01, time/batch = 0.6636s	
3626/29850 (epoch 6.074), train_loss = 1.58225242, grad/param norm = 1.8636e-01, time/batch = 0.6561s	
3627/29850 (epoch 6.075), train_loss = 1.39947065, grad/param norm = 1.7172e-01, time/batch = 0.6553s	
3628/29850 (epoch 6.077), train_loss = 1.45539455, grad/param norm = 1.8154e-01, time/batch = 0.6580s	
3629/29850 (epoch 6.079), train_loss = 1.71702917, grad/param norm = 2.0240e-01, time/batch = 0.6542s	
3630/29850 (epoch 6.080), train_loss = 1.66575293, grad/param norm = 2.0090e-01, time/batch = 0.6516s	
3631/29850 (epoch 6.082), train_loss = 1.49156004, grad/param norm = 1.6316e-01, time/batch = 0.6553s	
3632/29850 (epoch 6.084), train_loss = 1.56636555, grad/param norm = 1.8009e-01, time/batch = 0.6541s	
3633/29850 (epoch 6.085), train_loss = 1.51670250, grad/param norm = 1.8110e-01, time/batch = 0.6517s	
3634/29850 (epoch 6.087), train_loss = 1.64147559, grad/param norm = 1.8697e-01, time/batch = 0.6548s	
3635/29850 (epoch 6.089), train_loss = 1.58961571, grad/param norm = 1.7833e-01, time/batch = 0.6519s	
3636/29850 (epoch 6.090), train_loss = 1.55656614, grad/param norm = 1.9032e-01, time/batch = 0.6514s	
3637/29850 (epoch 6.092), train_loss = 1.44912271, grad/param norm = 1.7814e-01, time/batch = 0.6544s	
3638/29850 (epoch 6.094), train_loss = 1.51695682, grad/param norm = 1.7330e-01, time/batch = 0.6523s	
3639/29850 (epoch 6.095), train_loss = 1.56349909, grad/param norm = 1.6744e-01, time/batch = 0.6515s	
3640/29850 (epoch 6.097), train_loss = 1.33387858, grad/param norm = 1.6236e-01, time/batch = 0.6573s	
3641/29850 (epoch 6.099), train_loss = 1.37482420, grad/param norm = 1.6985e-01, time/batch = 0.6629s	
3642/29850 (epoch 6.101), train_loss = 1.64887175, grad/param norm = 2.0195e-01, time/batch = 0.6572s	
3643/29850 (epoch 6.102), train_loss = 1.52856976, grad/param norm = 1.9049e-01, time/batch = 0.6574s	
3644/29850 (epoch 6.104), train_loss = 1.47157607, grad/param norm = 1.6794e-01, time/batch = 0.6563s	
3645/29850 (epoch 6.106), train_loss = 1.57736002, grad/param norm = 1.8018e-01, time/batch = 0.6548s	
3646/29850 (epoch 6.107), train_loss = 1.41417166, grad/param norm = 1.7027e-01, time/batch = 0.6632s	
3647/29850 (epoch 6.109), train_loss = 1.43547386, grad/param norm = 1.6725e-01, time/batch = 0.6609s	
3648/29850 (epoch 6.111), train_loss = 1.61140923, grad/param norm = 2.0574e-01, time/batch = 0.6576s	
3649/29850 (epoch 6.112), train_loss = 1.41263842, grad/param norm = 1.7107e-01, time/batch = 0.6639s	
3650/29850 (epoch 6.114), train_loss = 1.62891367, grad/param norm = 1.9937e-01, time/batch = 0.6821s	
3651/29850 (epoch 6.116), train_loss = 1.43458104, grad/param norm = 1.8551e-01, time/batch = 0.6614s	
3652/29850 (epoch 6.117), train_loss = 1.56758972, grad/param norm = 1.7437e-01, time/batch = 0.6517s	
3653/29850 (epoch 6.119), train_loss = 1.51814981, grad/param norm = 1.7454e-01, time/batch = 0.6557s	
3654/29850 (epoch 6.121), train_loss = 1.32396527, grad/param norm = 1.7833e-01, time/batch = 0.6532s	
3655/29850 (epoch 6.122), train_loss = 1.36996551, grad/param norm = 1.7808e-01, time/batch = 0.6572s	
3656/29850 (epoch 6.124), train_loss = 1.41238318, grad/param norm = 1.7067e-01, time/batch = 0.6558s	
3657/29850 (epoch 6.126), train_loss = 1.50608208, grad/param norm = 1.7875e-01, time/batch = 0.6577s	
3658/29850 (epoch 6.127), train_loss = 1.72992597, grad/param norm = 2.0068e-01, time/batch = 0.6634s	
3659/29850 (epoch 6.129), train_loss = 1.46413755, grad/param norm = 1.7811e-01, time/batch = 0.6582s	
3660/29850 (epoch 6.131), train_loss = 1.46063536, grad/param norm = 1.8808e-01, time/batch = 0.6571s	
3661/29850 (epoch 6.132), train_loss = 1.44749855, grad/param norm = 1.8967e-01, time/batch = 0.6610s	
3662/29850 (epoch 6.134), train_loss = 1.59267886, grad/param norm = 1.8267e-01, time/batch = 0.6621s	
3663/29850 (epoch 6.136), train_loss = 1.56020780, grad/param norm = 1.8550e-01, time/batch = 0.6570s	
3664/29850 (epoch 6.137), train_loss = 1.48697555, grad/param norm = 1.9179e-01, time/batch = 0.6625s	
3665/29850 (epoch 6.139), train_loss = 1.45454336, grad/param norm = 1.9768e-01, time/batch = 0.6577s	
3666/29850 (epoch 6.141), train_loss = 1.49560961, grad/param norm = 1.8565e-01, time/batch = 0.6606s	
3667/29850 (epoch 6.142), train_loss = 1.59020892, grad/param norm = 2.0302e-01, time/batch = 0.6580s	
3668/29850 (epoch 6.144), train_loss = 1.72900792, grad/param norm = 1.9030e-01, time/batch = 0.6558s	
3669/29850 (epoch 6.146), train_loss = 1.68774653, grad/param norm = 2.0464e-01, time/batch = 0.6565s	
3670/29850 (epoch 6.147), train_loss = 1.62437565, grad/param norm = 1.9791e-01, time/batch = 0.6519s	
3671/29850 (epoch 6.149), train_loss = 1.59148404, grad/param norm = 1.9658e-01, time/batch = 0.6585s	
3672/29850 (epoch 6.151), train_loss = 1.53038730, grad/param norm = 2.0756e-01, time/batch = 0.6584s	
3673/29850 (epoch 6.152), train_loss = 1.42178263, grad/param norm = 1.7045e-01, time/batch = 0.6682s	
3674/29850 (epoch 6.154), train_loss = 1.45460867, grad/param norm = 1.7578e-01, time/batch = 0.6604s	
3675/29850 (epoch 6.156), train_loss = 1.40296655, grad/param norm = 1.5963e-01, time/batch = 0.6617s	
3676/29850 (epoch 6.157), train_loss = 1.48965514, grad/param norm = 1.6304e-01, time/batch = 0.6554s	
3677/29850 (epoch 6.159), train_loss = 1.54636598, grad/param norm = 1.7622e-01, time/batch = 0.6556s	
3678/29850 (epoch 6.161), train_loss = 1.59531525, grad/param norm = 1.9043e-01, time/batch = 0.6534s	
3679/29850 (epoch 6.162), train_loss = 1.64127795, grad/param norm = 1.9090e-01, time/batch = 0.6550s	
3680/29850 (epoch 6.164), train_loss = 1.49236246, grad/param norm = 1.9384e-01, time/batch = 0.6603s	
3681/29850 (epoch 6.166), train_loss = 1.37577010, grad/param norm = 1.6298e-01, time/batch = 0.6715s	
3682/29850 (epoch 6.168), train_loss = 1.28426453, grad/param norm = 1.5714e-01, time/batch = 0.6797s	
3683/29850 (epoch 6.169), train_loss = 1.70640041, grad/param norm = 2.0004e-01, time/batch = 0.6532s	
3684/29850 (epoch 6.171), train_loss = 1.66696362, grad/param norm = 1.8813e-01, time/batch = 0.6536s	
3685/29850 (epoch 6.173), train_loss = 1.53508546, grad/param norm = 1.7363e-01, time/batch = 0.6597s	
3686/29850 (epoch 6.174), train_loss = 1.65391556, grad/param norm = 1.8917e-01, time/batch = 0.6821s	
3687/29850 (epoch 6.176), train_loss = 1.56434189, grad/param norm = 1.9227e-01, time/batch = 0.6837s	
3688/29850 (epoch 6.178), train_loss = 1.58563024, grad/param norm = 1.8096e-01, time/batch = 0.6832s	
3689/29850 (epoch 6.179), train_loss = 1.31116617, grad/param norm = 1.7683e-01, time/batch = 0.6801s	
3690/29850 (epoch 6.181), train_loss = 1.45343629, grad/param norm = 1.7294e-01, time/batch = 0.6740s	
3691/29850 (epoch 6.183), train_loss = 1.44326327, grad/param norm = 1.7347e-01, time/batch = 0.6761s	
3692/29850 (epoch 6.184), train_loss = 1.45798169, grad/param norm = 1.8369e-01, time/batch = 0.6648s	
3693/29850 (epoch 6.186), train_loss = 1.44695125, grad/param norm = 1.8127e-01, time/batch = 0.6667s	
3694/29850 (epoch 6.188), train_loss = 1.54803303, grad/param norm = 1.9294e-01, time/batch = 0.6671s	
3695/29850 (epoch 6.189), train_loss = 1.68755474, grad/param norm = 1.9395e-01, time/batch = 0.6726s	
3696/29850 (epoch 6.191), train_loss = 1.54462938, grad/param norm = 1.8725e-01, time/batch = 0.6704s	
3697/29850 (epoch 6.193), train_loss = 1.34993744, grad/param norm = 1.6144e-01, time/batch = 0.6718s	
3698/29850 (epoch 6.194), train_loss = 1.58264334, grad/param norm = 2.1168e-01, time/batch = 0.6702s	
3699/29850 (epoch 6.196), train_loss = 1.48199688, grad/param norm = 1.8488e-01, time/batch = 0.6602s	
3700/29850 (epoch 6.198), train_loss = 1.45556826, grad/param norm = 1.6609e-01, time/batch = 0.6548s	
3701/29850 (epoch 6.199), train_loss = 1.77748440, grad/param norm = 1.9811e-01, time/batch = 0.6553s	
3702/29850 (epoch 6.201), train_loss = 1.51798067, grad/param norm = 1.9237e-01, time/batch = 0.6750s	
3703/29850 (epoch 6.203), train_loss = 1.53675614, grad/param norm = 1.9400e-01, time/batch = 0.6759s	
3704/29850 (epoch 6.204), train_loss = 1.52113760, grad/param norm = 1.9031e-01, time/batch = 0.6557s	
3705/29850 (epoch 6.206), train_loss = 1.43681254, grad/param norm = 1.8085e-01, time/batch = 0.6739s	
3706/29850 (epoch 6.208), train_loss = 1.73031242, grad/param norm = 1.7754e-01, time/batch = 0.6797s	
3707/29850 (epoch 6.209), train_loss = 1.42534821, grad/param norm = 1.8840e-01, time/batch = 0.6774s	
3708/29850 (epoch 6.211), train_loss = 1.43074668, grad/param norm = 1.5696e-01, time/batch = 0.6605s	
3709/29850 (epoch 6.213), train_loss = 1.68919508, grad/param norm = 1.9113e-01, time/batch = 0.6552s	
3710/29850 (epoch 6.214), train_loss = 1.43429178, grad/param norm = 1.7154e-01, time/batch = 0.6531s	
3711/29850 (epoch 6.216), train_loss = 1.52325356, grad/param norm = 1.9175e-01, time/batch = 0.6569s	
3712/29850 (epoch 6.218), train_loss = 1.60873537, grad/param norm = 1.8930e-01, time/batch = 0.6643s	
3713/29850 (epoch 6.219), train_loss = 1.75547624, grad/param norm = 2.0390e-01, time/batch = 0.6624s	
3714/29850 (epoch 6.221), train_loss = 1.46000741, grad/param norm = 1.8496e-01, time/batch = 0.6553s	
3715/29850 (epoch 6.223), train_loss = 1.54126550, grad/param norm = 1.7618e-01, time/batch = 0.6549s	
3716/29850 (epoch 6.224), train_loss = 1.39858575, grad/param norm = 1.7203e-01, time/batch = 0.6605s	
3717/29850 (epoch 6.226), train_loss = 1.46695259, grad/param norm = 1.8461e-01, time/batch = 0.6561s	
3718/29850 (epoch 6.228), train_loss = 1.42934000, grad/param norm = 1.6611e-01, time/batch = 0.6511s	
3719/29850 (epoch 6.229), train_loss = 1.35643489, grad/param norm = 1.7931e-01, time/batch = 0.6564s	
3720/29850 (epoch 6.231), train_loss = 1.40425387, grad/param norm = 1.6838e-01, time/batch = 0.6572s	
3721/29850 (epoch 6.233), train_loss = 1.47862191, grad/param norm = 1.8353e-01, time/batch = 0.6571s	
3722/29850 (epoch 6.235), train_loss = 1.38690973, grad/param norm = 1.5424e-01, time/batch = 0.6562s	
3723/29850 (epoch 6.236), train_loss = 1.69624426, grad/param norm = 2.0454e-01, time/batch = 0.6532s	
3724/29850 (epoch 6.238), train_loss = 1.35305369, grad/param norm = 1.9694e-01, time/batch = 0.6546s	
3725/29850 (epoch 6.240), train_loss = 1.50217793, grad/param norm = 1.7954e-01, time/batch = 0.6554s	
3726/29850 (epoch 6.241), train_loss = 1.69898771, grad/param norm = 1.9484e-01, time/batch = 0.6547s	
3727/29850 (epoch 6.243), train_loss = 1.48447981, grad/param norm = 1.7902e-01, time/batch = 0.6555s	
3728/29850 (epoch 6.245), train_loss = 1.48612120, grad/param norm = 1.8359e-01, time/batch = 0.6541s	
3729/29850 (epoch 6.246), train_loss = 1.43974860, grad/param norm = 1.7945e-01, time/batch = 0.6546s	
3730/29850 (epoch 6.248), train_loss = 1.47709880, grad/param norm = 1.7964e-01, time/batch = 0.6546s	
3731/29850 (epoch 6.250), train_loss = 1.57344610, grad/param norm = 1.8477e-01, time/batch = 0.6587s	
3732/29850 (epoch 6.251), train_loss = 1.39808962, grad/param norm = 1.7087e-01, time/batch = 0.6570s	
3733/29850 (epoch 6.253), train_loss = 1.45952490, grad/param norm = 1.8321e-01, time/batch = 0.6614s	
3734/29850 (epoch 6.255), train_loss = 1.44504305, grad/param norm = 1.6589e-01, time/batch = 0.6598s	
3735/29850 (epoch 6.256), train_loss = 1.50479089, grad/param norm = 1.8346e-01, time/batch = 0.6545s	
3736/29850 (epoch 6.258), train_loss = 1.46604190, grad/param norm = 1.7611e-01, time/batch = 0.6548s	
3737/29850 (epoch 6.260), train_loss = 1.44023261, grad/param norm = 1.6225e-01, time/batch = 0.6524s	
3738/29850 (epoch 6.261), train_loss = 1.42343205, grad/param norm = 1.6574e-01, time/batch = 0.6517s	
3739/29850 (epoch 6.263), train_loss = 1.34400707, grad/param norm = 1.7679e-01, time/batch = 0.6556s	
3740/29850 (epoch 6.265), train_loss = 1.45142663, grad/param norm = 1.8909e-01, time/batch = 0.6527s	
3741/29850 (epoch 6.266), train_loss = 1.46665624, grad/param norm = 1.9500e-01, time/batch = 0.6545s	
3742/29850 (epoch 6.268), train_loss = 1.43759802, grad/param norm = 1.8123e-01, time/batch = 0.6574s	
3743/29850 (epoch 6.270), train_loss = 1.42883111, grad/param norm = 1.8460e-01, time/batch = 0.6611s	
3744/29850 (epoch 6.271), train_loss = 1.58562890, grad/param norm = 1.8887e-01, time/batch = 0.6678s	
3745/29850 (epoch 6.273), train_loss = 1.37700726, grad/param norm = 1.7329e-01, time/batch = 0.6551s	
3746/29850 (epoch 6.275), train_loss = 1.43855917, grad/param norm = 1.7262e-01, time/batch = 0.6541s	
3747/29850 (epoch 6.276), train_loss = 1.37255162, grad/param norm = 1.6598e-01, time/batch = 0.6515s	
3748/29850 (epoch 6.278), train_loss = 1.43530354, grad/param norm = 1.7059e-01, time/batch = 0.6544s	
3749/29850 (epoch 6.280), train_loss = 1.56759496, grad/param norm = 1.7655e-01, time/batch = 0.6573s	
3750/29850 (epoch 6.281), train_loss = 1.44181224, grad/param norm = 1.8357e-01, time/batch = 0.6548s	
3751/29850 (epoch 6.283), train_loss = 1.57674578, grad/param norm = 1.8789e-01, time/batch = 0.6714s	
3752/29850 (epoch 6.285), train_loss = 1.44674867, grad/param norm = 1.9203e-01, time/batch = 0.6575s	
3753/29850 (epoch 6.286), train_loss = 1.47290376, grad/param norm = 1.7398e-01, time/batch = 0.6590s	
3754/29850 (epoch 6.288), train_loss = 1.65515977, grad/param norm = 2.1564e-01, time/batch = 0.6601s	
3755/29850 (epoch 6.290), train_loss = 1.41947247, grad/param norm = 1.9655e-01, time/batch = 0.6544s	
3756/29850 (epoch 6.291), train_loss = 1.75959907, grad/param norm = 1.9072e-01, time/batch = 0.6674s	
3757/29850 (epoch 6.293), train_loss = 1.59615629, grad/param norm = 1.8533e-01, time/batch = 0.6640s	
3758/29850 (epoch 6.295), train_loss = 1.62397068, grad/param norm = 1.8545e-01, time/batch = 0.6538s	
3759/29850 (epoch 6.296), train_loss = 1.39283244, grad/param norm = 1.6334e-01, time/batch = 0.6563s	
3760/29850 (epoch 6.298), train_loss = 1.24635534, grad/param norm = 1.6729e-01, time/batch = 0.6568s	
3761/29850 (epoch 6.300), train_loss = 1.34533802, grad/param norm = 1.5669e-01, time/batch = 0.6584s	
3762/29850 (epoch 6.302), train_loss = 1.33943520, grad/param norm = 1.6553e-01, time/batch = 0.6590s	
3763/29850 (epoch 6.303), train_loss = 1.47789149, grad/param norm = 1.7593e-01, time/batch = 0.6568s	
3764/29850 (epoch 6.305), train_loss = 1.41143143, grad/param norm = 1.7136e-01, time/batch = 0.6568s	
3765/29850 (epoch 6.307), train_loss = 1.57373346, grad/param norm = 1.9904e-01, time/batch = 0.6589s	
3766/29850 (epoch 6.308), train_loss = 1.52912562, grad/param norm = 1.9317e-01, time/batch = 0.6580s	
3767/29850 (epoch 6.310), train_loss = 1.53682275, grad/param norm = 1.9121e-01, time/batch = 0.6583s	
3768/29850 (epoch 6.312), train_loss = 1.54348179, grad/param norm = 1.8713e-01, time/batch = 0.6616s	
3769/29850 (epoch 6.313), train_loss = 1.55075103, grad/param norm = 1.9332e-01, time/batch = 0.6576s	
3770/29850 (epoch 6.315), train_loss = 1.49940383, grad/param norm = 1.7450e-01, time/batch = 0.6630s	
3771/29850 (epoch 6.317), train_loss = 1.54241972, grad/param norm = 1.7840e-01, time/batch = 0.6606s	
3772/29850 (epoch 6.318), train_loss = 1.53540629, grad/param norm = 1.8898e-01, time/batch = 0.6598s	
3773/29850 (epoch 6.320), train_loss = 1.34592838, grad/param norm = 1.6784e-01, time/batch = 0.6542s	
3774/29850 (epoch 6.322), train_loss = 1.59686236, grad/param norm = 1.8509e-01, time/batch = 0.6614s	
3775/29850 (epoch 6.323), train_loss = 1.50903352, grad/param norm = 1.9459e-01, time/batch = 0.6613s	
3776/29850 (epoch 6.325), train_loss = 1.47068458, grad/param norm = 1.8172e-01, time/batch = 0.6769s	
3777/29850 (epoch 6.327), train_loss = 1.64129770, grad/param norm = 2.1061e-01, time/batch = 0.6826s	
3778/29850 (epoch 6.328), train_loss = 1.65162992, grad/param norm = 1.9160e-01, time/batch = 0.6838s	
3779/29850 (epoch 6.330), train_loss = 1.47589667, grad/param norm = 1.7773e-01, time/batch = 0.6829s	
3780/29850 (epoch 6.332), train_loss = 1.39291004, grad/param norm = 1.7723e-01, time/batch = 0.6781s	
3781/29850 (epoch 6.333), train_loss = 1.65689078, grad/param norm = 1.8566e-01, time/batch = 0.6632s	
3782/29850 (epoch 6.335), train_loss = 1.54510080, grad/param norm = 1.9179e-01, time/batch = 0.6579s	
3783/29850 (epoch 6.337), train_loss = 1.54431160, grad/param norm = 1.8853e-01, time/batch = 0.6596s	
3784/29850 (epoch 6.338), train_loss = 1.48356500, grad/param norm = 1.7531e-01, time/batch = 0.6563s	
3785/29850 (epoch 6.340), train_loss = 1.36348500, grad/param norm = 1.7328e-01, time/batch = 0.6604s	
3786/29850 (epoch 6.342), train_loss = 1.53521062, grad/param norm = 1.8988e-01, time/batch = 0.6553s	
3787/29850 (epoch 6.343), train_loss = 1.55268377, grad/param norm = 1.8841e-01, time/batch = 0.6569s	
3788/29850 (epoch 6.345), train_loss = 1.64117144, grad/param norm = 1.8804e-01, time/batch = 0.6580s	
3789/29850 (epoch 6.347), train_loss = 1.58398482, grad/param norm = 1.8877e-01, time/batch = 0.6574s	
3790/29850 (epoch 6.348), train_loss = 1.50727762, grad/param norm = 1.7485e-01, time/batch = 0.6589s	
3791/29850 (epoch 6.350), train_loss = 1.59932341, grad/param norm = 1.9495e-01, time/batch = 0.6765s	
3792/29850 (epoch 6.352), train_loss = 1.52842444, grad/param norm = 1.8195e-01, time/batch = 0.6718s	
3793/29850 (epoch 6.353), train_loss = 1.53621847, grad/param norm = 1.7997e-01, time/batch = 0.6736s	
3794/29850 (epoch 6.355), train_loss = 1.36327580, grad/param norm = 1.8115e-01, time/batch = 0.6665s	
3795/29850 (epoch 6.357), train_loss = 1.62725121, grad/param norm = 1.7787e-01, time/batch = 0.6666s	
3796/29850 (epoch 6.358), train_loss = 1.33878773, grad/param norm = 1.6068e-01, time/batch = 0.6678s	
3797/29850 (epoch 6.360), train_loss = 1.45322570, grad/param norm = 1.7232e-01, time/batch = 0.6647s	
3798/29850 (epoch 6.362), train_loss = 1.46776055, grad/param norm = 1.7934e-01, time/batch = 0.6581s	
3799/29850 (epoch 6.363), train_loss = 1.48946801, grad/param norm = 1.7955e-01, time/batch = 0.6536s	
3800/29850 (epoch 6.365), train_loss = 1.65119253, grad/param norm = 1.9811e-01, time/batch = 0.6534s	
3801/29850 (epoch 6.367), train_loss = 1.43057676, grad/param norm = 1.6308e-01, time/batch = 0.6546s	
3802/29850 (epoch 6.369), train_loss = 1.39372877, grad/param norm = 1.8351e-01, time/batch = 0.6549s	
3803/29850 (epoch 6.370), train_loss = 1.29311329, grad/param norm = 1.7476e-01, time/batch = 0.6520s	
3804/29850 (epoch 6.372), train_loss = 1.67164693, grad/param norm = 1.9875e-01, time/batch = 0.6541s	
3805/29850 (epoch 6.374), train_loss = 1.43154743, grad/param norm = 1.8279e-01, time/batch = 0.6574s	
3806/29850 (epoch 6.375), train_loss = 1.45897874, grad/param norm = 1.8787e-01, time/batch = 0.6639s	
3807/29850 (epoch 6.377), train_loss = 1.55310078, grad/param norm = 1.8788e-01, time/batch = 0.6574s	
3808/29850 (epoch 6.379), train_loss = 1.61357758, grad/param norm = 1.8733e-01, time/batch = 0.6560s	
3809/29850 (epoch 6.380), train_loss = 1.52916967, grad/param norm = 1.8692e-01, time/batch = 0.6556s	
3810/29850 (epoch 6.382), train_loss = 1.57541059, grad/param norm = 1.8661e-01, time/batch = 0.6535s	
3811/29850 (epoch 6.384), train_loss = 1.45585053, grad/param norm = 1.8405e-01, time/batch = 0.6558s	
3812/29850 (epoch 6.385), train_loss = 1.53317919, grad/param norm = 1.7740e-01, time/batch = 0.6541s	
3813/29850 (epoch 6.387), train_loss = 1.53627306, grad/param norm = 1.9484e-01, time/batch = 0.6527s	
3814/29850 (epoch 6.389), train_loss = 1.64995281, grad/param norm = 1.8335e-01, time/batch = 0.6532s	
3815/29850 (epoch 6.390), train_loss = 1.50013495, grad/param norm = 1.7080e-01, time/batch = 0.6560s	
3816/29850 (epoch 6.392), train_loss = 1.47870884, grad/param norm = 1.8498e-01, time/batch = 0.6509s	
3817/29850 (epoch 6.394), train_loss = 1.56903246, grad/param norm = 1.8171e-01, time/batch = 0.6642s	
3818/29850 (epoch 6.395), train_loss = 1.56618957, grad/param norm = 1.9060e-01, time/batch = 0.6574s	
3819/29850 (epoch 6.397), train_loss = 1.53128894, grad/param norm = 1.8044e-01, time/batch = 0.6576s	
3820/29850 (epoch 6.399), train_loss = 1.37868956, grad/param norm = 1.7299e-01, time/batch = 0.6535s	
3821/29850 (epoch 6.400), train_loss = 1.71512404, grad/param norm = 2.1729e-01, time/batch = 0.6582s	
3822/29850 (epoch 6.402), train_loss = 1.59987653, grad/param norm = 1.9887e-01, time/batch = 0.6592s	
3823/29850 (epoch 6.404), train_loss = 1.57554266, grad/param norm = 1.8527e-01, time/batch = 0.6824s	
3824/29850 (epoch 6.405), train_loss = 1.60930824, grad/param norm = 1.8609e-01, time/batch = 0.6763s	
3825/29850 (epoch 6.407), train_loss = 1.48266352, grad/param norm = 1.8910e-01, time/batch = 0.6673s	
3826/29850 (epoch 6.409), train_loss = 1.73538506, grad/param norm = 1.9947e-01, time/batch = 0.6730s	
3827/29850 (epoch 6.410), train_loss = 1.63018145, grad/param norm = 1.8860e-01, time/batch = 0.6622s	
3828/29850 (epoch 6.412), train_loss = 1.48836930, grad/param norm = 1.8549e-01, time/batch = 0.6549s	
3829/29850 (epoch 6.414), train_loss = 1.53828234, grad/param norm = 1.8985e-01, time/batch = 0.6597s	
3830/29850 (epoch 6.415), train_loss = 1.50367442, grad/param norm = 1.7032e-01, time/batch = 0.6564s	
3831/29850 (epoch 6.417), train_loss = 1.64817542, grad/param norm = 1.9180e-01, time/batch = 0.6569s	
3832/29850 (epoch 6.419), train_loss = 1.52555327, grad/param norm = 1.8934e-01, time/batch = 0.6762s	
3833/29850 (epoch 6.420), train_loss = 1.48257501, grad/param norm = 1.7410e-01, time/batch = 0.6751s	
3834/29850 (epoch 6.422), train_loss = 1.45857628, grad/param norm = 1.7509e-01, time/batch = 0.6655s	
3835/29850 (epoch 6.424), train_loss = 1.56544289, grad/param norm = 1.9268e-01, time/batch = 0.6721s	
3836/29850 (epoch 6.425), train_loss = 1.75820241, grad/param norm = 1.7743e-01, time/batch = 0.6694s	
3837/29850 (epoch 6.427), train_loss = 1.38065166, grad/param norm = 1.8756e-01, time/batch = 0.6793s	
3838/29850 (epoch 6.429), train_loss = 1.38698869, grad/param norm = 1.7572e-01, time/batch = 0.6667s	
3839/29850 (epoch 6.430), train_loss = 1.31699659, grad/param norm = 1.7061e-01, time/batch = 0.6634s	
3840/29850 (epoch 6.432), train_loss = 1.48166149, grad/param norm = 1.7622e-01, time/batch = 0.6763s	
3841/29850 (epoch 6.434), train_loss = 1.41163682, grad/param norm = 1.7473e-01, time/batch = 0.6943s	
3842/29850 (epoch 6.436), train_loss = 1.55015625, grad/param norm = 1.8682e-01, time/batch = 0.6907s	
3843/29850 (epoch 6.437), train_loss = 1.48787426, grad/param norm = 1.6535e-01, time/batch = 0.6854s	
3844/29850 (epoch 6.439), train_loss = 1.52628996, grad/param norm = 1.8184e-01, time/batch = 0.6832s	
3845/29850 (epoch 6.441), train_loss = 1.54034856, grad/param norm = 1.8178e-01, time/batch = 0.6831s	
3846/29850 (epoch 6.442), train_loss = 1.56207931, grad/param norm = 1.8420e-01, time/batch = 0.6832s	
3847/29850 (epoch 6.444), train_loss = 1.46610743, grad/param norm = 1.6498e-01, time/batch = 0.6865s	
3848/29850 (epoch 6.446), train_loss = 1.51376247, grad/param norm = 1.8090e-01, time/batch = 0.6898s	
3849/29850 (epoch 6.447), train_loss = 1.63016444, grad/param norm = 1.9990e-01, time/batch = 0.6869s	
3850/29850 (epoch 6.449), train_loss = 1.61741635, grad/param norm = 1.7748e-01, time/batch = 0.6805s	
3851/29850 (epoch 6.451), train_loss = 1.46936322, grad/param norm = 1.7991e-01, time/batch = 0.6573s	
3852/29850 (epoch 6.452), train_loss = 1.26899346, grad/param norm = 1.6146e-01, time/batch = 0.6543s	
3853/29850 (epoch 6.454), train_loss = 1.42315747, grad/param norm = 1.7122e-01, time/batch = 0.6600s	
3854/29850 (epoch 6.456), train_loss = 1.56056873, grad/param norm = 1.8258e-01, time/batch = 0.6826s	
3855/29850 (epoch 6.457), train_loss = 1.69915644, grad/param norm = 2.6186e-01, time/batch = 0.6719s	
3856/29850 (epoch 6.459), train_loss = 1.72674831, grad/param norm = 2.0199e-01, time/batch = 0.6539s	
3857/29850 (epoch 6.461), train_loss = 1.68861588, grad/param norm = 1.9128e-01, time/batch = 0.6579s	
3858/29850 (epoch 6.462), train_loss = 1.55453546, grad/param norm = 1.9823e-01, time/batch = 0.6544s	
3859/29850 (epoch 6.464), train_loss = 1.50810074, grad/param norm = 1.6612e-01, time/batch = 0.6589s	
3860/29850 (epoch 6.466), train_loss = 1.39909242, grad/param norm = 1.8355e-01, time/batch = 0.6568s	
3861/29850 (epoch 6.467), train_loss = 1.55720058, grad/param norm = 1.7940e-01, time/batch = 0.6622s	
3862/29850 (epoch 6.469), train_loss = 1.52942885, grad/param norm = 1.6901e-01, time/batch = 0.6551s	
3863/29850 (epoch 6.471), train_loss = 1.51621101, grad/param norm = 1.7096e-01, time/batch = 0.6578s	
3864/29850 (epoch 6.472), train_loss = 1.43240498, grad/param norm = 1.6763e-01, time/batch = 0.6687s	
3865/29850 (epoch 6.474), train_loss = 1.67247999, grad/param norm = 1.8866e-01, time/batch = 0.6824s	
3866/29850 (epoch 6.476), train_loss = 1.54478679, grad/param norm = 1.8293e-01, time/batch = 0.6805s	
3867/29850 (epoch 6.477), train_loss = 1.57463231, grad/param norm = 1.7993e-01, time/batch = 0.6732s	
3868/29850 (epoch 6.479), train_loss = 1.58688038, grad/param norm = 1.9499e-01, time/batch = 0.6649s	
3869/29850 (epoch 6.481), train_loss = 1.61009195, grad/param norm = 1.8926e-01, time/batch = 0.6575s	
3870/29850 (epoch 6.482), train_loss = 1.41410594, grad/param norm = 1.6593e-01, time/batch = 0.6684s	
3871/29850 (epoch 6.484), train_loss = 1.48607522, grad/param norm = 1.7740e-01, time/batch = 0.6753s	
3872/29850 (epoch 6.486), train_loss = 1.48500871, grad/param norm = 1.7705e-01, time/batch = 0.6770s	
3873/29850 (epoch 6.487), train_loss = 1.44475316, grad/param norm = 1.8902e-01, time/batch = 0.6734s	
3874/29850 (epoch 6.489), train_loss = 1.51134860, grad/param norm = 1.8250e-01, time/batch = 0.6721s	
3875/29850 (epoch 6.491), train_loss = 1.37171001, grad/param norm = 1.7139e-01, time/batch = 0.6715s	
3876/29850 (epoch 6.492), train_loss = 1.60449972, grad/param norm = 1.7926e-01, time/batch = 0.6604s	
3877/29850 (epoch 6.494), train_loss = 1.68459500, grad/param norm = 1.6520e-01, time/batch = 0.6389s	
3878/29850 (epoch 6.496), train_loss = 1.67254514, grad/param norm = 1.7812e-01, time/batch = 0.6467s	
3879/29850 (epoch 6.497), train_loss = 1.51872369, grad/param norm = 1.8167e-01, time/batch = 0.6418s	
3880/29850 (epoch 6.499), train_loss = 1.51255858, grad/param norm = 1.7349e-01, time/batch = 0.6417s	
3881/29850 (epoch 6.501), train_loss = 1.43057948, grad/param norm = 1.7605e-01, time/batch = 0.6480s	
3882/29850 (epoch 6.503), train_loss = 1.48477637, grad/param norm = 1.8819e-01, time/batch = 0.6729s	
3883/29850 (epoch 6.504), train_loss = 1.67507140, grad/param norm = 1.9362e-01, time/batch = 0.6549s	
3884/29850 (epoch 6.506), train_loss = 1.73521650, grad/param norm = 1.8964e-01, time/batch = 0.6521s	
3885/29850 (epoch 6.508), train_loss = 1.51103985, grad/param norm = 1.7923e-01, time/batch = 0.6675s	
3886/29850 (epoch 6.509), train_loss = 1.31314999, grad/param norm = 1.6658e-01, time/batch = 0.6705s	
3887/29850 (epoch 6.511), train_loss = 1.48631525, grad/param norm = 1.8213e-01, time/batch = 0.6527s	
3888/29850 (epoch 6.513), train_loss = 1.60398543, grad/param norm = 1.9339e-01, time/batch = 0.6472s	
3889/29850 (epoch 6.514), train_loss = 1.37697963, grad/param norm = 1.6736e-01, time/batch = 0.6416s	
3890/29850 (epoch 6.516), train_loss = 1.34617604, grad/param norm = 1.5610e-01, time/batch = 0.6556s	
3891/29850 (epoch 6.518), train_loss = 1.36444705, grad/param norm = 1.6536e-01, time/batch = 0.6483s	
3892/29850 (epoch 6.519), train_loss = 1.36906477, grad/param norm = 1.6324e-01, time/batch = 0.6474s	
3893/29850 (epoch 6.521), train_loss = 1.42322495, grad/param norm = 1.6635e-01, time/batch = 0.6443s	
3894/29850 (epoch 6.523), train_loss = 1.32334754, grad/param norm = 1.5515e-01, time/batch = 0.6474s	
3895/29850 (epoch 6.524), train_loss = 1.53740769, grad/param norm = 1.7987e-01, time/batch = 0.6616s	
3896/29850 (epoch 6.526), train_loss = 1.58165694, grad/param norm = 1.8094e-01, time/batch = 0.6714s	
3897/29850 (epoch 6.528), train_loss = 1.65182678, grad/param norm = 2.0251e-01, time/batch = 0.6713s	
3898/29850 (epoch 6.529), train_loss = 1.63965754, grad/param norm = 2.0465e-01, time/batch = 0.6579s	
3899/29850 (epoch 6.531), train_loss = 1.56628730, grad/param norm = 2.0588e-01, time/batch = 0.6597s	
3900/29850 (epoch 6.533), train_loss = 1.40344382, grad/param norm = 1.8133e-01, time/batch = 0.6503s	
3901/29850 (epoch 6.534), train_loss = 1.49227054, grad/param norm = 1.9214e-01, time/batch = 0.6539s	
3902/29850 (epoch 6.536), train_loss = 1.52448692, grad/param norm = 1.8762e-01, time/batch = 0.6542s	
3903/29850 (epoch 6.538), train_loss = 1.55116947, grad/param norm = 1.7729e-01, time/batch = 0.6585s	
3904/29850 (epoch 6.539), train_loss = 1.57783769, grad/param norm = 1.8639e-01, time/batch = 0.6475s	
3905/29850 (epoch 6.541), train_loss = 1.33969378, grad/param norm = 1.6729e-01, time/batch = 0.6439s	
3906/29850 (epoch 6.543), train_loss = 1.43596582, grad/param norm = 1.6542e-01, time/batch = 0.6467s	
3907/29850 (epoch 6.544), train_loss = 1.51128013, grad/param norm = 1.7507e-01, time/batch = 0.6705s	
3908/29850 (epoch 6.546), train_loss = 1.60249792, grad/param norm = 1.8163e-01, time/batch = 0.6501s	
3909/29850 (epoch 6.548), train_loss = 1.40044189, grad/param norm = 1.7097e-01, time/batch = 0.6442s	
3910/29850 (epoch 6.549), train_loss = 1.47628896, grad/param norm = 1.6886e-01, time/batch = 0.6433s	
3911/29850 (epoch 6.551), train_loss = 1.44124048, grad/param norm = 1.8581e-01, time/batch = 0.6441s	
3912/29850 (epoch 6.553), train_loss = 1.55673535, grad/param norm = 1.8831e-01, time/batch = 0.6450s	
3913/29850 (epoch 6.554), train_loss = 1.28942028, grad/param norm = 1.5880e-01, time/batch = 0.6432s	
3914/29850 (epoch 6.556), train_loss = 1.51285528, grad/param norm = 1.9922e-01, time/batch = 0.6518s	
3915/29850 (epoch 6.558), train_loss = 1.44266518, grad/param norm = 1.7482e-01, time/batch = 0.6524s	
3916/29850 (epoch 6.559), train_loss = 1.57995823, grad/param norm = 1.9024e-01, time/batch = 0.6462s	
3917/29850 (epoch 6.561), train_loss = 1.57611485, grad/param norm = 1.7381e-01, time/batch = 0.6584s	
3918/29850 (epoch 6.563), train_loss = 1.48389818, grad/param norm = 1.8415e-01, time/batch = 0.6707s	
3919/29850 (epoch 6.564), train_loss = 1.49143932, grad/param norm = 1.8733e-01, time/batch = 0.6448s	
3920/29850 (epoch 6.566), train_loss = 1.42217665, grad/param norm = 1.7871e-01, time/batch = 0.6425s	
3921/29850 (epoch 6.568), train_loss = 1.58680039, grad/param norm = 1.7825e-01, time/batch = 0.6491s	
3922/29850 (epoch 6.570), train_loss = 1.51107162, grad/param norm = 1.7436e-01, time/batch = 0.6475s	
3923/29850 (epoch 6.571), train_loss = 1.56277413, grad/param norm = 1.7953e-01, time/batch = 0.6474s	
3924/29850 (epoch 6.573), train_loss = 1.66617015, grad/param norm = 1.8619e-01, time/batch = 0.6433s	
3925/29850 (epoch 6.575), train_loss = 1.58950845, grad/param norm = 1.8049e-01, time/batch = 0.6444s	
3926/29850 (epoch 6.576), train_loss = 1.67063921, grad/param norm = 1.7366e-01, time/batch = 0.6447s	
3927/29850 (epoch 6.578), train_loss = 1.57011539, grad/param norm = 1.8480e-01, time/batch = 0.6449s	
3928/29850 (epoch 6.580), train_loss = 1.58295469, grad/param norm = 1.8383e-01, time/batch = 0.6430s	
3929/29850 (epoch 6.581), train_loss = 1.47920953, grad/param norm = 1.8735e-01, time/batch = 0.6393s	
3930/29850 (epoch 6.583), train_loss = 1.45456598, grad/param norm = 1.6959e-01, time/batch = 0.6399s	
3931/29850 (epoch 6.585), train_loss = 1.45500312, grad/param norm = 1.6425e-01, time/batch = 0.6434s	
3932/29850 (epoch 6.586), train_loss = 1.51010187, grad/param norm = 1.8535e-01, time/batch = 0.6422s	
3933/29850 (epoch 6.588), train_loss = 1.44905255, grad/param norm = 1.6864e-01, time/batch = 0.6409s	
3934/29850 (epoch 6.590), train_loss = 1.51591744, grad/param norm = 1.7768e-01, time/batch = 0.6430s	
3935/29850 (epoch 6.591), train_loss = 1.42953193, grad/param norm = 1.6815e-01, time/batch = 0.6411s	
3936/29850 (epoch 6.593), train_loss = 1.44230261, grad/param norm = 1.7104e-01, time/batch = 0.6471s	
3937/29850 (epoch 6.595), train_loss = 1.39466430, grad/param norm = 1.6214e-01, time/batch = 0.6455s	
3938/29850 (epoch 6.596), train_loss = 1.37330385, grad/param norm = 1.7341e-01, time/batch = 0.6530s	
3939/29850 (epoch 6.598), train_loss = 1.36915985, grad/param norm = 1.8215e-01, time/batch = 0.6597s	
3940/29850 (epoch 6.600), train_loss = 1.60864416, grad/param norm = 1.9653e-01, time/batch = 0.6620s	
3941/29850 (epoch 6.601), train_loss = 1.36784309, grad/param norm = 1.6205e-01, time/batch = 0.6643s	
3942/29850 (epoch 6.603), train_loss = 1.50488693, grad/param norm = 1.7200e-01, time/batch = 0.6488s	
3943/29850 (epoch 6.605), train_loss = 1.56284678, grad/param norm = 1.8677e-01, time/batch = 0.6423s	
3944/29850 (epoch 6.606), train_loss = 1.30193255, grad/param norm = 1.6373e-01, time/batch = 0.6531s	
3945/29850 (epoch 6.608), train_loss = 1.49772198, grad/param norm = 1.7395e-01, time/batch = 0.6503s	
3946/29850 (epoch 6.610), train_loss = 1.45930815, grad/param norm = 1.7713e-01, time/batch = 0.6449s	
3947/29850 (epoch 6.611), train_loss = 1.27167694, grad/param norm = 1.5297e-01, time/batch = 0.6740s	
3948/29850 (epoch 6.613), train_loss = 1.27796248, grad/param norm = 1.6507e-01, time/batch = 0.6744s	
3949/29850 (epoch 6.615), train_loss = 1.32070619, grad/param norm = 1.5968e-01, time/batch = 0.6709s	
3950/29850 (epoch 6.616), train_loss = 1.46928311, grad/param norm = 1.8234e-01, time/batch = 0.6590s	
3951/29850 (epoch 6.618), train_loss = 1.49796247, grad/param norm = 1.7149e-01, time/batch = 0.6441s	
3952/29850 (epoch 6.620), train_loss = 1.50699795, grad/param norm = 1.8636e-01, time/batch = 0.6495s	
3953/29850 (epoch 6.621), train_loss = 1.58070030, grad/param norm = 2.0809e-01, time/batch = 0.6421s	
3954/29850 (epoch 6.623), train_loss = 1.56604025, grad/param norm = 1.8681e-01, time/batch = 0.6608s	
3955/29850 (epoch 6.625), train_loss = 1.58033794, grad/param norm = 1.9389e-01, time/batch = 0.6663s	
3956/29850 (epoch 6.626), train_loss = 1.58570707, grad/param norm = 1.9220e-01, time/batch = 0.6442s	
3957/29850 (epoch 6.628), train_loss = 1.32215400, grad/param norm = 1.6846e-01, time/batch = 0.6584s	
3958/29850 (epoch 6.630), train_loss = 1.50233963, grad/param norm = 1.8427e-01, time/batch = 0.6664s	
3959/29850 (epoch 6.631), train_loss = 1.38977391, grad/param norm = 1.7728e-01, time/batch = 0.6680s	
3960/29850 (epoch 6.633), train_loss = 1.58170283, grad/param norm = 1.9431e-01, time/batch = 0.6563s	
3961/29850 (epoch 6.635), train_loss = 1.49482225, grad/param norm = 1.8211e-01, time/batch = 0.6500s	
3962/29850 (epoch 6.637), train_loss = 1.57297134, grad/param norm = 1.8584e-01, time/batch = 0.6415s	
3963/29850 (epoch 6.638), train_loss = 1.40216567, grad/param norm = 1.6834e-01, time/batch = 0.6452s	
3964/29850 (epoch 6.640), train_loss = 1.65009195, grad/param norm = 1.8319e-01, time/batch = 0.6505s	
3965/29850 (epoch 6.642), train_loss = 1.47817923, grad/param norm = 1.8197e-01, time/batch = 0.6707s	
3966/29850 (epoch 6.643), train_loss = 1.39945785, grad/param norm = 1.6759e-01, time/batch = 0.6588s	
3967/29850 (epoch 6.645), train_loss = 1.52825153, grad/param norm = 1.7525e-01, time/batch = 0.6455s	
3968/29850 (epoch 6.647), train_loss = 1.61647415, grad/param norm = 1.8221e-01, time/batch = 0.6505s	
3969/29850 (epoch 6.648), train_loss = 1.33649753, grad/param norm = 1.6264e-01, time/batch = 0.6449s	
3970/29850 (epoch 6.650), train_loss = 1.47300632, grad/param norm = 1.9904e-01, time/batch = 0.6429s	
3971/29850 (epoch 6.652), train_loss = 1.48146075, grad/param norm = 1.7501e-01, time/batch = 0.6447s	
3972/29850 (epoch 6.653), train_loss = 1.57897413, grad/param norm = 1.7571e-01, time/batch = 0.6472s	
3973/29850 (epoch 6.655), train_loss = 1.46426056, grad/param norm = 1.7449e-01, time/batch = 0.6456s	
3974/29850 (epoch 6.657), train_loss = 1.43066430, grad/param norm = 1.6546e-01, time/batch = 0.6473s	
3975/29850 (epoch 6.658), train_loss = 1.58909302, grad/param norm = 1.9122e-01, time/batch = 0.6571s	
3976/29850 (epoch 6.660), train_loss = 1.38904967, grad/param norm = 1.7543e-01, time/batch = 0.6716s	
3977/29850 (epoch 6.662), train_loss = 1.46275242, grad/param norm = 1.8088e-01, time/batch = 0.6569s	
3978/29850 (epoch 6.663), train_loss = 1.56531562, grad/param norm = 1.9074e-01, time/batch = 0.6436s	
3979/29850 (epoch 6.665), train_loss = 1.51967693, grad/param norm = 1.8435e-01, time/batch = 0.6461s	
3980/29850 (epoch 6.667), train_loss = 1.57511466, grad/param norm = 1.9014e-01, time/batch = 0.6615s	
3981/29850 (epoch 6.668), train_loss = 1.52000019, grad/param norm = 1.7029e-01, time/batch = 0.6534s	
3982/29850 (epoch 6.670), train_loss = 1.77974708, grad/param norm = 1.9606e-01, time/batch = 0.6710s	
3983/29850 (epoch 6.672), train_loss = 1.55988648, grad/param norm = 1.9815e-01, time/batch = 0.6603s	
3984/29850 (epoch 6.673), train_loss = 1.56084765, grad/param norm = 1.7365e-01, time/batch = 0.6558s	
3985/29850 (epoch 6.675), train_loss = 1.46815479, grad/param norm = 1.7211e-01, time/batch = 0.6569s	
3986/29850 (epoch 6.677), train_loss = 1.48710777, grad/param norm = 1.7839e-01, time/batch = 0.6759s	
3987/29850 (epoch 6.678), train_loss = 1.45762977, grad/param norm = 1.9009e-01, time/batch = 0.6760s	
3988/29850 (epoch 6.680), train_loss = 1.52634435, grad/param norm = 1.8709e-01, time/batch = 0.6562s	
3989/29850 (epoch 6.682), train_loss = 1.47514647, grad/param norm = 1.7838e-01, time/batch = 0.6656s	
3990/29850 (epoch 6.683), train_loss = 1.69896990, grad/param norm = 2.0535e-01, time/batch = 0.6618s	
3991/29850 (epoch 6.685), train_loss = 1.62993106, grad/param norm = 1.6699e-01, time/batch = 0.6594s	
3992/29850 (epoch 6.687), train_loss = 1.56180102, grad/param norm = 1.8811e-01, time/batch = 0.6599s	
3993/29850 (epoch 6.688), train_loss = 1.33094438, grad/param norm = 1.4370e-01, time/batch = 0.6581s	
3994/29850 (epoch 6.690), train_loss = 1.40388367, grad/param norm = 1.8686e-01, time/batch = 0.6598s	
3995/29850 (epoch 6.692), train_loss = 1.69701878, grad/param norm = 2.0092e-01, time/batch = 0.6554s	
3996/29850 (epoch 6.693), train_loss = 1.46532490, grad/param norm = 1.6279e-01, time/batch = 0.6556s	
3997/29850 (epoch 6.695), train_loss = 1.37380260, grad/param norm = 1.7900e-01, time/batch = 0.6551s	
3998/29850 (epoch 6.697), train_loss = 1.58366212, grad/param norm = 2.0108e-01, time/batch = 0.6524s	
3999/29850 (epoch 6.698), train_loss = 1.60085941, grad/param norm = 1.8952e-01, time/batch = 0.6536s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch6.70_1.6812.t7	
4000/29850 (epoch 6.700), train_loss = 1.59035349, grad/param norm = 1.9927e-01, time/batch = 0.6556s	
4001/29850 (epoch 6.702), train_loss = 1.62383457, grad/param norm = 2.0273e-01, time/batch = 0.6716s	
4002/29850 (epoch 6.704), train_loss = 1.41399858, grad/param norm = 1.7379e-01, time/batch = 0.6616s	
4003/29850 (epoch 6.705), train_loss = 1.48734344, grad/param norm = 1.7102e-01, time/batch = 0.6652s	
4004/29850 (epoch 6.707), train_loss = 1.51720331, grad/param norm = 1.8657e-01, time/batch = 0.6645s	
4005/29850 (epoch 6.709), train_loss = 1.61988737, grad/param norm = 1.9014e-01, time/batch = 0.6691s	
4006/29850 (epoch 6.710), train_loss = 1.47998092, grad/param norm = 1.8199e-01, time/batch = 0.6667s	
4007/29850 (epoch 6.712), train_loss = 1.48367696, grad/param norm = 1.7107e-01, time/batch = 0.6581s	
4008/29850 (epoch 6.714), train_loss = 1.52214046, grad/param norm = 2.0260e-01, time/batch = 0.6594s	
4009/29850 (epoch 6.715), train_loss = 1.60054815, grad/param norm = 1.8954e-01, time/batch = 0.6812s	
4010/29850 (epoch 6.717), train_loss = 1.38037423, grad/param norm = 1.7945e-01, time/batch = 0.6723s	
4011/29850 (epoch 6.719), train_loss = 1.48542387, grad/param norm = 1.7528e-01, time/batch = 0.6588s	
4012/29850 (epoch 6.720), train_loss = 1.53928648, grad/param norm = 1.8376e-01, time/batch = 0.6576s	
4013/29850 (epoch 6.722), train_loss = 1.39738239, grad/param norm = 1.6555e-01, time/batch = 0.6572s	
4014/29850 (epoch 6.724), train_loss = 1.49412531, grad/param norm = 1.7618e-01, time/batch = 0.6618s	
4015/29850 (epoch 6.725), train_loss = 1.36349842, grad/param norm = 1.5882e-01, time/batch = 0.6558s	
4016/29850 (epoch 6.727), train_loss = 1.46334799, grad/param norm = 1.8234e-01, time/batch = 0.6582s	
4017/29850 (epoch 6.729), train_loss = 1.30147843, grad/param norm = 1.6449e-01, time/batch = 0.6629s	
4018/29850 (epoch 6.730), train_loss = 1.35933303, grad/param norm = 1.6354e-01, time/batch = 0.6552s	
4019/29850 (epoch 6.732), train_loss = 1.45633059, grad/param norm = 1.6499e-01, time/batch = 0.6683s	
4020/29850 (epoch 6.734), train_loss = 1.67995562, grad/param norm = 1.9223e-01, time/batch = 0.6819s	
4021/29850 (epoch 6.735), train_loss = 1.54336123, grad/param norm = 1.8584e-01, time/batch = 0.6573s	
4022/29850 (epoch 6.737), train_loss = 1.37194725, grad/param norm = 1.6868e-01, time/batch = 0.6617s	
4023/29850 (epoch 6.739), train_loss = 1.37424417, grad/param norm = 1.7487e-01, time/batch = 0.6610s	
4024/29850 (epoch 6.740), train_loss = 1.39349772, grad/param norm = 1.8318e-01, time/batch = 0.6610s	
4025/29850 (epoch 6.742), train_loss = 1.38152903, grad/param norm = 1.7482e-01, time/batch = 0.6576s	
4026/29850 (epoch 6.744), train_loss = 1.49292319, grad/param norm = 1.9796e-01, time/batch = 0.6554s	
4027/29850 (epoch 6.745), train_loss = 1.47263507, grad/param norm = 1.9371e-01, time/batch = 0.6602s	
4028/29850 (epoch 6.747), train_loss = 1.40774270, grad/param norm = 1.8871e-01, time/batch = 0.6620s	
4029/29850 (epoch 6.749), train_loss = 1.38778570, grad/param norm = 1.8521e-01, time/batch = 0.6620s	
4030/29850 (epoch 6.750), train_loss = 1.49491955, grad/param norm = 1.8623e-01, time/batch = 0.6788s	
4031/29850 (epoch 6.752), train_loss = 1.43031248, grad/param norm = 1.6380e-01, time/batch = 0.6703s	
4032/29850 (epoch 6.754), train_loss = 1.40191910, grad/param norm = 1.7758e-01, time/batch = 0.6539s	
4033/29850 (epoch 6.755), train_loss = 1.47559801, grad/param norm = 1.7022e-01, time/batch = 0.6520s	
4034/29850 (epoch 6.757), train_loss = 1.42924583, grad/param norm = 1.7415e-01, time/batch = 0.6592s	
4035/29850 (epoch 6.759), train_loss = 1.50238848, grad/param norm = 1.5843e-01, time/batch = 0.6585s	
4036/29850 (epoch 6.760), train_loss = 1.35892318, grad/param norm = 1.6870e-01, time/batch = 0.6603s	
4037/29850 (epoch 6.762), train_loss = 1.38734003, grad/param norm = 1.8674e-01, time/batch = 0.6564s	
4038/29850 (epoch 6.764), train_loss = 1.43773912, grad/param norm = 1.8771e-01, time/batch = 0.6600s	
4039/29850 (epoch 6.765), train_loss = 1.42715461, grad/param norm = 1.9469e-01, time/batch = 0.6805s	
4040/29850 (epoch 6.767), train_loss = 1.48272131, grad/param norm = 1.6915e-01, time/batch = 0.6849s	
4041/29850 (epoch 6.769), train_loss = 1.42615183, grad/param norm = 1.8695e-01, time/batch = 0.7030s	
4042/29850 (epoch 6.771), train_loss = 1.53375250, grad/param norm = 1.9332e-01, time/batch = 0.6882s	
4043/29850 (epoch 6.772), train_loss = 1.58816867, grad/param norm = 1.8243e-01, time/batch = 0.6782s	
4044/29850 (epoch 6.774), train_loss = 1.44173169, grad/param norm = 1.8192e-01, time/batch = 0.6821s	
4045/29850 (epoch 6.776), train_loss = 1.41935533, grad/param norm = 1.7985e-01, time/batch = 0.6701s	
4046/29850 (epoch 6.777), train_loss = 1.53622768, grad/param norm = 1.8002e-01, time/batch = 0.6876s	
4047/29850 (epoch 6.779), train_loss = 1.31915441, grad/param norm = 1.6404e-01, time/batch = 0.6734s	
4048/29850 (epoch 6.781), train_loss = 1.38882658, grad/param norm = 1.6995e-01, time/batch = 0.6806s	
4049/29850 (epoch 6.782), train_loss = 1.45022518, grad/param norm = 1.6547e-01, time/batch = 0.6765s	
4050/29850 (epoch 6.784), train_loss = 1.40797834, grad/param norm = 1.8295e-01, time/batch = 0.6649s	
4051/29850 (epoch 6.786), train_loss = 1.40170192, grad/param norm = 1.7473e-01, time/batch = 0.6848s	
4052/29850 (epoch 6.787), train_loss = 1.41227872, grad/param norm = 1.7980e-01, time/batch = 0.6955s	
4053/29850 (epoch 6.789), train_loss = 1.33809111, grad/param norm = 1.6796e-01, time/batch = 0.6654s	
4054/29850 (epoch 6.791), train_loss = 1.49028416, grad/param norm = 1.9312e-01, time/batch = 0.6644s	
4055/29850 (epoch 6.792), train_loss = 1.51739593, grad/param norm = 1.8247e-01, time/batch = 0.6568s	
4056/29850 (epoch 6.794), train_loss = 1.47573165, grad/param norm = 1.7240e-01, time/batch = 0.6621s	
4057/29850 (epoch 6.796), train_loss = 1.37541968, grad/param norm = 1.7822e-01, time/batch = 0.6702s	
4058/29850 (epoch 6.797), train_loss = 1.39934985, grad/param norm = 1.5801e-01, time/batch = 0.6648s	
4059/29850 (epoch 6.799), train_loss = 1.37385385, grad/param norm = 1.6211e-01, time/batch = 0.6563s	
4060/29850 (epoch 6.801), train_loss = 1.56730460, grad/param norm = 1.9550e-01, time/batch = 0.6573s	
4061/29850 (epoch 6.802), train_loss = 1.35060722, grad/param norm = 1.8706e-01, time/batch = 0.6795s	
4062/29850 (epoch 6.804), train_loss = 1.42629350, grad/param norm = 1.6495e-01, time/batch = 0.6696s	
4063/29850 (epoch 6.806), train_loss = 1.43313483, grad/param norm = 1.7082e-01, time/batch = 0.6655s	
4064/29850 (epoch 6.807), train_loss = 1.29631277, grad/param norm = 1.5855e-01, time/batch = 0.6724s	
4065/29850 (epoch 6.809), train_loss = 1.50559663, grad/param norm = 2.0523e-01, time/batch = 0.6656s	
4066/29850 (epoch 6.811), train_loss = 1.57232308, grad/param norm = 1.8694e-01, time/batch = 0.6547s	
4067/29850 (epoch 6.812), train_loss = 1.47960905, grad/param norm = 1.8622e-01, time/batch = 0.6619s	
4068/29850 (epoch 6.814), train_loss = 1.55054937, grad/param norm = 1.9499e-01, time/batch = 0.6658s	
4069/29850 (epoch 6.816), train_loss = 1.51868282, grad/param norm = 1.6691e-01, time/batch = 0.6558s	
4070/29850 (epoch 6.817), train_loss = 1.49583204, grad/param norm = 1.7110e-01, time/batch = 0.6562s	
4071/29850 (epoch 6.819), train_loss = 1.43601053, grad/param norm = 1.8233e-01, time/batch = 0.6638s	
4072/29850 (epoch 6.821), train_loss = 1.63316744, grad/param norm = 2.0065e-01, time/batch = 0.6831s	
4073/29850 (epoch 6.822), train_loss = 1.44383622, grad/param norm = 1.6204e-01, time/batch = 0.6582s	
4074/29850 (epoch 6.824), train_loss = 1.45090142, grad/param norm = 1.8744e-01, time/batch = 0.6559s	
4075/29850 (epoch 6.826), train_loss = 1.46172235, grad/param norm = 1.7624e-01, time/batch = 0.6566s	
4076/29850 (epoch 6.827), train_loss = 1.40184205, grad/param norm = 1.8365e-01, time/batch = 0.6522s	
4077/29850 (epoch 6.829), train_loss = 1.50869790, grad/param norm = 1.9667e-01, time/batch = 0.6627s	
4078/29850 (epoch 6.831), train_loss = 1.49767554, grad/param norm = 1.8995e-01, time/batch = 0.6610s	
4079/29850 (epoch 6.832), train_loss = 1.35378549, grad/param norm = 1.6732e-01, time/batch = 0.6552s	
4080/29850 (epoch 6.834), train_loss = 1.36560738, grad/param norm = 1.8665e-01, time/batch = 0.6511s	
4081/29850 (epoch 6.836), train_loss = 1.34800171, grad/param norm = 1.6404e-01, time/batch = 0.6579s	
4082/29850 (epoch 6.838), train_loss = 1.51661398, grad/param norm = 1.7865e-01, time/batch = 0.6762s	
4083/29850 (epoch 6.839), train_loss = 1.44521574, grad/param norm = 1.7985e-01, time/batch = 0.6806s	
4084/29850 (epoch 6.841), train_loss = 1.44975361, grad/param norm = 1.7590e-01, time/batch = 0.6592s	
4085/29850 (epoch 6.843), train_loss = 1.43418132, grad/param norm = 1.6252e-01, time/batch = 0.6649s	
4086/29850 (epoch 6.844), train_loss = 1.41957075, grad/param norm = 1.7788e-01, time/batch = 0.6634s	
4087/29850 (epoch 6.846), train_loss = 1.51788655, grad/param norm = 1.9871e-01, time/batch = 0.6613s	
4088/29850 (epoch 6.848), train_loss = 1.52600483, grad/param norm = 1.9395e-01, time/batch = 0.6736s	
4089/29850 (epoch 6.849), train_loss = 1.36405917, grad/param norm = 1.8703e-01, time/batch = 0.6598s	
4090/29850 (epoch 6.851), train_loss = 1.51243163, grad/param norm = 1.8676e-01, time/batch = 0.6600s	
4091/29850 (epoch 6.853), train_loss = 1.43267399, grad/param norm = 1.9422e-01, time/batch = 0.6692s	
4092/29850 (epoch 6.854), train_loss = 1.51162915, grad/param norm = 1.9678e-01, time/batch = 0.6666s	
4093/29850 (epoch 6.856), train_loss = 1.52959477, grad/param norm = 1.9487e-01, time/batch = 0.6714s	
4094/29850 (epoch 6.858), train_loss = 1.45171827, grad/param norm = 1.7762e-01, time/batch = 0.6619s	
4095/29850 (epoch 6.859), train_loss = 1.39951496, grad/param norm = 1.9091e-01, time/batch = 0.6566s	
4096/29850 (epoch 6.861), train_loss = 1.57334666, grad/param norm = 1.9220e-01, time/batch = 0.6543s	
4097/29850 (epoch 6.863), train_loss = 1.56426390, grad/param norm = 1.6495e-01, time/batch = 0.6621s	
4098/29850 (epoch 6.864), train_loss = 1.47922007, grad/param norm = 1.8756e-01, time/batch = 0.6611s	
4099/29850 (epoch 6.866), train_loss = 1.46316573, grad/param norm = 1.7971e-01, time/batch = 0.6560s	
4100/29850 (epoch 6.868), train_loss = 1.57886599, grad/param norm = 1.9078e-01, time/batch = 0.6563s	
4101/29850 (epoch 6.869), train_loss = 1.39555513, grad/param norm = 1.8134e-01, time/batch = 0.6574s	
4102/29850 (epoch 6.871), train_loss = 1.45702889, grad/param norm = 1.7441e-01, time/batch = 0.6615s	
4103/29850 (epoch 6.873), train_loss = 1.52327513, grad/param norm = 1.7592e-01, time/batch = 0.6687s	
4104/29850 (epoch 6.874), train_loss = 1.50737712, grad/param norm = 1.8875e-01, time/batch = 0.6572s	
4105/29850 (epoch 6.876), train_loss = 1.54206731, grad/param norm = 2.0554e-01, time/batch = 0.6524s	
4106/29850 (epoch 6.878), train_loss = 1.44883456, grad/param norm = 1.6513e-01, time/batch = 0.6548s	
4107/29850 (epoch 6.879), train_loss = 1.56136730, grad/param norm = 1.6766e-01, time/batch = 0.6575s	
4108/29850 (epoch 6.881), train_loss = 1.54240172, grad/param norm = 1.8601e-01, time/batch = 0.6550s	
4109/29850 (epoch 6.883), train_loss = 1.58095240, grad/param norm = 1.8356e-01, time/batch = 0.6549s	
4110/29850 (epoch 6.884), train_loss = 1.33732830, grad/param norm = 1.7093e-01, time/batch = 0.6549s	
4111/29850 (epoch 6.886), train_loss = 1.68691239, grad/param norm = 2.0558e-01, time/batch = 0.6566s	
4112/29850 (epoch 6.888), train_loss = 1.43640995, grad/param norm = 1.9132e-01, time/batch = 0.6549s	
4113/29850 (epoch 6.889), train_loss = 1.40744290, grad/param norm = 1.8459e-01, time/batch = 0.6531s	
4114/29850 (epoch 6.891), train_loss = 1.41729045, grad/param norm = 1.7748e-01, time/batch = 0.6544s	
4115/29850 (epoch 6.893), train_loss = 1.35280155, grad/param norm = 1.7735e-01, time/batch = 0.6576s	
4116/29850 (epoch 6.894), train_loss = 1.40568802, grad/param norm = 1.7642e-01, time/batch = 0.6531s	
4117/29850 (epoch 6.896), train_loss = 1.39812396, grad/param norm = 1.7662e-01, time/batch = 0.6570s	
4118/29850 (epoch 6.898), train_loss = 1.59135478, grad/param norm = 1.9597e-01, time/batch = 0.6720s	
4119/29850 (epoch 6.899), train_loss = 1.30271396, grad/param norm = 1.8289e-01, time/batch = 0.6809s	
4120/29850 (epoch 6.901), train_loss = 1.82857119, grad/param norm = 2.1303e-01, time/batch = 0.6585s	
4121/29850 (epoch 6.903), train_loss = 1.50639043, grad/param norm = 1.9723e-01, time/batch = 0.6580s	
4122/29850 (epoch 6.905), train_loss = 1.61695613, grad/param norm = 2.1095e-01, time/batch = 0.6639s	
4123/29850 (epoch 6.906), train_loss = 1.35899036, grad/param norm = 1.8953e-01, time/batch = 0.6590s	
4124/29850 (epoch 6.908), train_loss = 1.60978459, grad/param norm = 1.8497e-01, time/batch = 0.6557s	
4125/29850 (epoch 6.910), train_loss = 1.55889219, grad/param norm = 1.7818e-01, time/batch = 0.6627s	
4126/29850 (epoch 6.911), train_loss = 1.59929695, grad/param norm = 1.9257e-01, time/batch = 0.6618s	
4127/29850 (epoch 6.913), train_loss = 1.49284574, grad/param norm = 1.7977e-01, time/batch = 0.6567s	
4128/29850 (epoch 6.915), train_loss = 1.52687377, grad/param norm = 1.9286e-01, time/batch = 0.6611s	
4129/29850 (epoch 6.916), train_loss = 1.47600002, grad/param norm = 1.8992e-01, time/batch = 0.6838s	
4130/29850 (epoch 6.918), train_loss = 1.39696514, grad/param norm = 1.5742e-01, time/batch = 0.6851s	
4131/29850 (epoch 6.920), train_loss = 1.51831563, grad/param norm = 1.6425e-01, time/batch = 0.6701s	
4132/29850 (epoch 6.921), train_loss = 1.53308319, grad/param norm = 1.8401e-01, time/batch = 0.6618s	
4133/29850 (epoch 6.923), train_loss = 1.53123742, grad/param norm = 1.8082e-01, time/batch = 0.6700s	
4134/29850 (epoch 6.925), train_loss = 1.62606136, grad/param norm = 1.8464e-01, time/batch = 0.6758s	
4135/29850 (epoch 6.926), train_loss = 1.61837719, grad/param norm = 1.9502e-01, time/batch = 0.6672s	
4136/29850 (epoch 6.928), train_loss = 1.45633811, grad/param norm = 1.8679e-01, time/batch = 0.6699s	
4137/29850 (epoch 6.930), train_loss = 1.60521579, grad/param norm = 1.8674e-01, time/batch = 0.6704s	
4138/29850 (epoch 6.931), train_loss = 1.57146903, grad/param norm = 1.9127e-01, time/batch = 0.6756s	
4139/29850 (epoch 6.933), train_loss = 1.65529779, grad/param norm = 1.9389e-01, time/batch = 0.6749s	
4140/29850 (epoch 6.935), train_loss = 1.62712049, grad/param norm = 1.8396e-01, time/batch = 0.6689s	
4141/29850 (epoch 6.936), train_loss = 1.56860858, grad/param norm = 1.9154e-01, time/batch = 0.6697s	
4142/29850 (epoch 6.938), train_loss = 1.36021164, grad/param norm = 1.7557e-01, time/batch = 0.6665s	
4143/29850 (epoch 6.940), train_loss = 1.31245636, grad/param norm = 1.6863e-01, time/batch = 0.6610s	
4144/29850 (epoch 6.941), train_loss = 1.44214386, grad/param norm = 1.8753e-01, time/batch = 0.6606s	
4145/29850 (epoch 6.943), train_loss = 1.40243519, grad/param norm = 1.7403e-01, time/batch = 0.6612s	
4146/29850 (epoch 6.945), train_loss = 1.55745942, grad/param norm = 1.8650e-01, time/batch = 0.6583s	
4147/29850 (epoch 6.946), train_loss = 1.37511733, grad/param norm = 1.9928e-01, time/batch = 0.6635s	
4148/29850 (epoch 6.948), train_loss = 1.41327845, grad/param norm = 1.6706e-01, time/batch = 0.6865s	
4149/29850 (epoch 6.950), train_loss = 1.39284433, grad/param norm = 1.7272e-01, time/batch = 0.6767s	
4150/29850 (epoch 6.951), train_loss = 1.36682361, grad/param norm = 1.6566e-01, time/batch = 0.6767s	
4151/29850 (epoch 6.953), train_loss = 1.50678441, grad/param norm = 1.7636e-01, time/batch = 0.6786s	
4152/29850 (epoch 6.955), train_loss = 1.29986923, grad/param norm = 1.6223e-01, time/batch = 0.6716s	
4153/29850 (epoch 6.956), train_loss = 1.34782626, grad/param norm = 1.7476e-01, time/batch = 0.6589s	
4154/29850 (epoch 6.958), train_loss = 1.22638933, grad/param norm = 1.6551e-01, time/batch = 0.6600s	
4155/29850 (epoch 6.960), train_loss = 1.54031270, grad/param norm = 1.8767e-01, time/batch = 0.6610s	
4156/29850 (epoch 6.961), train_loss = 1.42449336, grad/param norm = 1.6586e-01, time/batch = 0.6612s	
4157/29850 (epoch 6.963), train_loss = 1.31637840, grad/param norm = 1.7345e-01, time/batch = 0.6626s	
4158/29850 (epoch 6.965), train_loss = 1.44629011, grad/param norm = 1.8378e-01, time/batch = 0.6566s	
4159/29850 (epoch 6.966), train_loss = 1.31499680, grad/param norm = 1.6834e-01, time/batch = 0.6581s	
4160/29850 (epoch 6.968), train_loss = 1.46192181, grad/param norm = 1.9027e-01, time/batch = 0.6795s	
4161/29850 (epoch 6.970), train_loss = 1.34377536, grad/param norm = 1.7100e-01, time/batch = 0.6788s	
4162/29850 (epoch 6.972), train_loss = 1.35818959, grad/param norm = 1.6602e-01, time/batch = 0.6590s	
4163/29850 (epoch 6.973), train_loss = 1.40253728, grad/param norm = 1.8498e-01, time/batch = 0.6646s	
4164/29850 (epoch 6.975), train_loss = 1.21842346, grad/param norm = 1.6642e-01, time/batch = 0.6647s	
4165/29850 (epoch 6.977), train_loss = 1.39188677, grad/param norm = 1.6995e-01, time/batch = 0.6650s	
4166/29850 (epoch 6.978), train_loss = 1.35474426, grad/param norm = 1.7506e-01, time/batch = 0.6636s	
4167/29850 (epoch 6.980), train_loss = 1.34310670, grad/param norm = 1.5772e-01, time/batch = 0.6661s	
4168/29850 (epoch 6.982), train_loss = 1.37366834, grad/param norm = 1.7709e-01, time/batch = 0.6663s	
4169/29850 (epoch 6.983), train_loss = 1.45863670, grad/param norm = 1.8128e-01, time/batch = 0.6645s	
4170/29850 (epoch 6.985), train_loss = 1.52003670, grad/param norm = 1.8793e-01, time/batch = 0.6720s	
4171/29850 (epoch 6.987), train_loss = 1.35814290, grad/param norm = 1.7293e-01, time/batch = 0.6889s	
4172/29850 (epoch 6.988), train_loss = 1.30594463, grad/param norm = 1.5790e-01, time/batch = 0.6688s	
4173/29850 (epoch 6.990), train_loss = 1.40647716, grad/param norm = 1.7715e-01, time/batch = 0.6632s	
4174/29850 (epoch 6.992), train_loss = 1.43835585, grad/param norm = 1.7011e-01, time/batch = 0.6658s	
4175/29850 (epoch 6.993), train_loss = 1.48881023, grad/param norm = 1.8911e-01, time/batch = 0.6718s	
4176/29850 (epoch 6.995), train_loss = 1.48785063, grad/param norm = 2.1159e-01, time/batch = 0.6673s	
4177/29850 (epoch 6.997), train_loss = 1.47789926, grad/param norm = 1.8259e-01, time/batch = 0.6663s	
4178/29850 (epoch 6.998), train_loss = 1.54119064, grad/param norm = 1.8269e-01, time/batch = 0.6622s	
4179/29850 (epoch 7.000), train_loss = 1.41306991, grad/param norm = 1.6007e-01, time/batch = 0.6584s	
4180/29850 (epoch 7.002), train_loss = 1.64313487, grad/param norm = 1.8293e-01, time/batch = 0.6572s	
4181/29850 (epoch 7.003), train_loss = 1.41216103, grad/param norm = 1.8303e-01, time/batch = 0.6867s	
4182/29850 (epoch 7.005), train_loss = 1.43502429, grad/param norm = 1.7725e-01, time/batch = 0.6745s	
4183/29850 (epoch 7.007), train_loss = 1.51574759, grad/param norm = 1.8496e-01, time/batch = 0.6595s	
4184/29850 (epoch 7.008), train_loss = 1.63669354, grad/param norm = 2.0604e-01, time/batch = 0.6646s	
4185/29850 (epoch 7.010), train_loss = 1.30446901, grad/param norm = 1.6987e-01, time/batch = 0.6599s	
4186/29850 (epoch 7.012), train_loss = 1.53036855, grad/param norm = 1.7020e-01, time/batch = 0.6613s	
4187/29850 (epoch 7.013), train_loss = 1.58048099, grad/param norm = 2.0487e-01, time/batch = 0.6677s	
4188/29850 (epoch 7.015), train_loss = 1.50869916, grad/param norm = 1.8019e-01, time/batch = 0.6609s	
4189/29850 (epoch 7.017), train_loss = 1.61390075, grad/param norm = 2.0434e-01, time/batch = 0.6599s	
4190/29850 (epoch 7.018), train_loss = 1.64088905, grad/param norm = 2.0939e-01, time/batch = 0.6615s	
4191/29850 (epoch 7.020), train_loss = 1.36158339, grad/param norm = 1.7724e-01, time/batch = 0.6746s	
4192/29850 (epoch 7.022), train_loss = 1.56322711, grad/param norm = 2.0600e-01, time/batch = 0.6867s	
4193/29850 (epoch 7.023), train_loss = 1.44992268, grad/param norm = 1.8184e-01, time/batch = 0.6603s	
4194/29850 (epoch 7.025), train_loss = 1.42417726, grad/param norm = 1.6759e-01, time/batch = 0.6617s	
4195/29850 (epoch 7.027), train_loss = 1.32838624, grad/param norm = 1.6216e-01, time/batch = 0.6616s	
4196/29850 (epoch 7.028), train_loss = 1.43233218, grad/param norm = 1.7214e-01, time/batch = 0.6612s	
4197/29850 (epoch 7.030), train_loss = 1.53293877, grad/param norm = 1.6668e-01, time/batch = 0.6614s	
4198/29850 (epoch 7.032), train_loss = 1.39916917, grad/param norm = 1.7256e-01, time/batch = 0.6601s	
4199/29850 (epoch 7.034), train_loss = 1.50304044, grad/param norm = 1.9718e-01, time/batch = 0.6635s	
4200/29850 (epoch 7.035), train_loss = 1.37103991, grad/param norm = 1.7234e-01, time/batch = 0.6614s	
4201/29850 (epoch 7.037), train_loss = 1.52126748, grad/param norm = 1.8870e-01, time/batch = 0.6733s	
4202/29850 (epoch 7.039), train_loss = 1.31676014, grad/param norm = 1.6010e-01, time/batch = 0.6873s	
4203/29850 (epoch 7.040), train_loss = 1.30398228, grad/param norm = 1.7245e-01, time/batch = 0.6750s	
4204/29850 (epoch 7.042), train_loss = 1.40810587, grad/param norm = 1.8156e-01, time/batch = 0.6624s	
4205/29850 (epoch 7.044), train_loss = 1.32376900, grad/param norm = 1.6937e-01, time/batch = 0.6669s	
4206/29850 (epoch 7.045), train_loss = 1.48421565, grad/param norm = 1.7518e-01, time/batch = 0.6667s	
4207/29850 (epoch 7.047), train_loss = 1.28336085, grad/param norm = 1.7340e-01, time/batch = 0.6663s	
4208/29850 (epoch 7.049), train_loss = 1.47318529, grad/param norm = 1.8690e-01, time/batch = 0.6685s	
4209/29850 (epoch 7.050), train_loss = 1.33789167, grad/param norm = 1.7218e-01, time/batch = 0.6674s	
4210/29850 (epoch 7.052), train_loss = 1.70666801, grad/param norm = 2.0702e-01, time/batch = 0.6647s	
4211/29850 (epoch 7.054), train_loss = 1.49067709, grad/param norm = 2.0112e-01, time/batch = 0.6650s	
4212/29850 (epoch 7.055), train_loss = 1.45756281, grad/param norm = 1.9453e-01, time/batch = 0.6590s	
4213/29850 (epoch 7.057), train_loss = 1.45531011, grad/param norm = 1.7856e-01, time/batch = 0.6580s	
4214/29850 (epoch 7.059), train_loss = 1.53969859, grad/param norm = 1.8495e-01, time/batch = 0.6589s	
4215/29850 (epoch 7.060), train_loss = 1.44101788, grad/param norm = 2.0267e-01, time/batch = 0.6660s	
4216/29850 (epoch 7.062), train_loss = 1.59352837, grad/param norm = 2.0497e-01, time/batch = 0.6571s	
4217/29850 (epoch 7.064), train_loss = 1.49914583, grad/param norm = 1.8336e-01, time/batch = 0.6567s	
4218/29850 (epoch 7.065), train_loss = 1.32092966, grad/param norm = 1.7775e-01, time/batch = 0.6808s	
4219/29850 (epoch 7.067), train_loss = 1.44886530, grad/param norm = 1.7020e-01, time/batch = 0.6878s	
4220/29850 (epoch 7.069), train_loss = 1.40821429, grad/param norm = 1.7713e-01, time/batch = 0.6904s	
4221/29850 (epoch 7.070), train_loss = 1.45049937, grad/param norm = 1.6983e-01, time/batch = 0.6635s	
4222/29850 (epoch 7.072), train_loss = 1.58606124, grad/param norm = 2.0548e-01, time/batch = 0.6642s	
4223/29850 (epoch 7.074), train_loss = 1.52471122, grad/param norm = 1.8414e-01, time/batch = 0.6644s	
4224/29850 (epoch 7.075), train_loss = 1.33595414, grad/param norm = 1.6834e-01, time/batch = 0.6603s	
4225/29850 (epoch 7.077), train_loss = 1.42267461, grad/param norm = 1.8175e-01, time/batch = 0.6547s	
4226/29850 (epoch 7.079), train_loss = 1.66334544, grad/param norm = 1.9036e-01, time/batch = 0.6610s	
4227/29850 (epoch 7.080), train_loss = 1.61290087, grad/param norm = 1.9823e-01, time/batch = 0.6752s	
4228/29850 (epoch 7.082), train_loss = 1.43859990, grad/param norm = 1.6181e-01, time/batch = 0.6635s	
4229/29850 (epoch 7.084), train_loss = 1.52247609, grad/param norm = 1.8501e-01, time/batch = 0.6592s	
4230/29850 (epoch 7.085), train_loss = 1.45985122, grad/param norm = 1.7733e-01, time/batch = 0.6579s	
4231/29850 (epoch 7.087), train_loss = 1.59006217, grad/param norm = 1.9016e-01, time/batch = 0.6589s	
4232/29850 (epoch 7.089), train_loss = 1.51949742, grad/param norm = 1.7636e-01, time/batch = 0.6578s	
4233/29850 (epoch 7.090), train_loss = 1.51580354, grad/param norm = 1.9003e-01, time/batch = 0.6621s	
4234/29850 (epoch 7.092), train_loss = 1.38831203, grad/param norm = 1.6919e-01, time/batch = 0.6601s	
4235/29850 (epoch 7.094), train_loss = 1.46855291, grad/param norm = 1.7401e-01, time/batch = 0.6693s	
4236/29850 (epoch 7.095), train_loss = 1.50262944, grad/param norm = 1.6906e-01, time/batch = 0.6642s	
4237/29850 (epoch 7.097), train_loss = 1.27119210, grad/param norm = 1.5900e-01, time/batch = 0.6609s	
4238/29850 (epoch 7.099), train_loss = 1.31588903, grad/param norm = 1.6671e-01, time/batch = 0.6625s	
4239/29850 (epoch 7.101), train_loss = 1.58791840, grad/param norm = 1.9459e-01, time/batch = 0.6653s	
4240/29850 (epoch 7.102), train_loss = 1.48645733, grad/param norm = 1.8543e-01, time/batch = 0.6608s	
4241/29850 (epoch 7.104), train_loss = 1.40368819, grad/param norm = 1.5886e-01, time/batch = 0.6684s	
4242/29850 (epoch 7.106), train_loss = 1.53132056, grad/param norm = 1.7726e-01, time/batch = 0.6613s	
4243/29850 (epoch 7.107), train_loss = 1.33416369, grad/param norm = 1.6499e-01, time/batch = 0.6585s	
4244/29850 (epoch 7.109), train_loss = 1.38168928, grad/param norm = 1.6262e-01, time/batch = 0.6613s	
4245/29850 (epoch 7.111), train_loss = 1.55063973, grad/param norm = 1.9809e-01, time/batch = 0.6697s	
4246/29850 (epoch 7.112), train_loss = 1.34843444, grad/param norm = 1.6969e-01, time/batch = 0.6734s	
4247/29850 (epoch 7.114), train_loss = 1.55587300, grad/param norm = 1.9627e-01, time/batch = 0.6644s	
4248/29850 (epoch 7.116), train_loss = 1.36906635, grad/param norm = 1.7710e-01, time/batch = 0.6667s	
4249/29850 (epoch 7.117), train_loss = 1.49358887, grad/param norm = 1.7349e-01, time/batch = 0.6686s	
4250/29850 (epoch 7.119), train_loss = 1.45433713, grad/param norm = 1.7022e-01, time/batch = 0.6620s	
4251/29850 (epoch 7.121), train_loss = 1.25714208, grad/param norm = 1.7326e-01, time/batch = 0.6667s	
4252/29850 (epoch 7.122), train_loss = 1.30869297, grad/param norm = 1.7144e-01, time/batch = 0.6669s	
4253/29850 (epoch 7.124), train_loss = 1.36802909, grad/param norm = 1.7244e-01, time/batch = 0.6622s	
4254/29850 (epoch 7.126), train_loss = 1.44173696, grad/param norm = 1.8356e-01, time/batch = 0.6607s	
4255/29850 (epoch 7.127), train_loss = 1.65833915, grad/param norm = 2.0197e-01, time/batch = 0.6643s	
4256/29850 (epoch 7.129), train_loss = 1.40446423, grad/param norm = 1.7212e-01, time/batch = 0.6590s	
4257/29850 (epoch 7.131), train_loss = 1.40766202, grad/param norm = 1.8568e-01, time/batch = 0.6588s	
4258/29850 (epoch 7.132), train_loss = 1.37094813, grad/param norm = 1.7907e-01, time/batch = 0.6555s	
4259/29850 (epoch 7.134), train_loss = 1.53683066, grad/param norm = 1.7739e-01, time/batch = 0.6607s	
4260/29850 (epoch 7.136), train_loss = 1.50370764, grad/param norm = 1.8135e-01, time/batch = 0.6604s	
4261/29850 (epoch 7.137), train_loss = 1.41268362, grad/param norm = 1.8432e-01, time/batch = 0.6633s	
4262/29850 (epoch 7.139), train_loss = 1.39681223, grad/param norm = 1.7731e-01, time/batch = 0.6673s	
4263/29850 (epoch 7.141), train_loss = 1.43748972, grad/param norm = 1.8892e-01, time/batch = 0.6607s	
4264/29850 (epoch 7.142), train_loss = 1.54096197, grad/param norm = 1.9465e-01, time/batch = 0.6588s	
4265/29850 (epoch 7.144), train_loss = 1.68979797, grad/param norm = 1.8849e-01, time/batch = 0.6632s	
4266/29850 (epoch 7.146), train_loss = 1.65322852, grad/param norm = 2.0296e-01, time/batch = 0.6636s	
4267/29850 (epoch 7.147), train_loss = 1.56615883, grad/param norm = 1.9798e-01, time/batch = 0.6587s	
4268/29850 (epoch 7.149), train_loss = 1.53329059, grad/param norm = 1.8933e-01, time/batch = 0.6630s	
4269/29850 (epoch 7.151), train_loss = 1.47581314, grad/param norm = 1.9116e-01, time/batch = 0.6653s	
4270/29850 (epoch 7.152), train_loss = 1.36395768, grad/param norm = 1.6910e-01, time/batch = 0.6549s	
4271/29850 (epoch 7.154), train_loss = 1.39052622, grad/param norm = 1.6863e-01, time/batch = 0.6650s	
4272/29850 (epoch 7.156), train_loss = 1.35508042, grad/param norm = 1.5750e-01, time/batch = 0.6700s	
4273/29850 (epoch 7.157), train_loss = 1.43642193, grad/param norm = 1.6347e-01, time/batch = 0.6597s	
4274/29850 (epoch 7.159), train_loss = 1.48617007, grad/param norm = 1.7555e-01, time/batch = 0.6623s	
4275/29850 (epoch 7.161), train_loss = 1.52898979, grad/param norm = 1.9067e-01, time/batch = 0.6615s	
4276/29850 (epoch 7.162), train_loss = 1.60417042, grad/param norm = 1.8716e-01, time/batch = 0.6672s	
4277/29850 (epoch 7.164), train_loss = 1.45398750, grad/param norm = 1.8693e-01, time/batch = 0.6660s	
4278/29850 (epoch 7.166), train_loss = 1.31455351, grad/param norm = 1.5791e-01, time/batch = 0.6660s	
4279/29850 (epoch 7.168), train_loss = 1.22943068, grad/param norm = 1.5541e-01, time/batch = 0.6616s	
4280/29850 (epoch 7.169), train_loss = 1.63808178, grad/param norm = 1.9325e-01, time/batch = 0.6600s	
4281/29850 (epoch 7.171), train_loss = 1.60811281, grad/param norm = 1.8450e-01, time/batch = 0.6678s	
4282/29850 (epoch 7.173), train_loss = 1.47133945, grad/param norm = 1.7842e-01, time/batch = 0.6674s	
4283/29850 (epoch 7.174), train_loss = 1.58663520, grad/param norm = 1.9193e-01, time/batch = 0.6645s	
4284/29850 (epoch 7.176), train_loss = 1.49611950, grad/param norm = 1.8607e-01, time/batch = 0.6606s	
4285/29850 (epoch 7.178), train_loss = 1.51523035, grad/param norm = 1.7954e-01, time/batch = 0.6612s	
4286/29850 (epoch 7.179), train_loss = 1.25567518, grad/param norm = 1.7364e-01, time/batch = 0.6801s	
4287/29850 (epoch 7.181), train_loss = 1.40702117, grad/param norm = 1.6736e-01, time/batch = 0.6856s	
4288/29850 (epoch 7.183), train_loss = 1.39984565, grad/param norm = 1.7499e-01, time/batch = 0.6910s	
4289/29850 (epoch 7.184), train_loss = 1.40165927, grad/param norm = 1.8583e-01, time/batch = 0.6900s	
4290/29850 (epoch 7.186), train_loss = 1.39437795, grad/param norm = 1.7377e-01, time/batch = 0.6873s	
4291/29850 (epoch 7.188), train_loss = 1.50147107, grad/param norm = 1.8878e-01, time/batch = 0.6898s	
4292/29850 (epoch 7.189), train_loss = 1.63336778, grad/param norm = 1.8655e-01, time/batch = 0.6840s	
4293/29850 (epoch 7.191), train_loss = 1.49122166, grad/param norm = 1.8251e-01, time/batch = 0.6636s	
4294/29850 (epoch 7.193), train_loss = 1.30140885, grad/param norm = 1.6130e-01, time/batch = 0.6636s	
4295/29850 (epoch 7.194), train_loss = 1.50994439, grad/param norm = 2.0359e-01, time/batch = 0.6598s	
4296/29850 (epoch 7.196), train_loss = 1.42763154, grad/param norm = 1.8456e-01, time/batch = 0.6635s	
4297/29850 (epoch 7.198), train_loss = 1.40204099, grad/param norm = 1.6713e-01, time/batch = 0.6570s	
4298/29850 (epoch 7.199), train_loss = 1.72188349, grad/param norm = 1.9204e-01, time/batch = 0.6624s	
4299/29850 (epoch 7.201), train_loss = 1.44679968, grad/param norm = 1.7959e-01, time/batch = 0.6558s	
4300/29850 (epoch 7.203), train_loss = 1.45169713, grad/param norm = 1.8791e-01, time/batch = 0.6657s	
4301/29850 (epoch 7.204), train_loss = 1.48033043, grad/param norm = 1.8976e-01, time/batch = 0.6889s	
4302/29850 (epoch 7.206), train_loss = 1.37190070, grad/param norm = 1.7349e-01, time/batch = 0.6648s	
4303/29850 (epoch 7.208), train_loss = 1.68161251, grad/param norm = 1.8107e-01, time/batch = 0.6581s	
4304/29850 (epoch 7.209), train_loss = 1.36910232, grad/param norm = 1.8116e-01, time/batch = 0.6603s	
4305/29850 (epoch 7.211), train_loss = 1.38298854, grad/param norm = 1.6285e-01, time/batch = 0.6656s	
4306/29850 (epoch 7.213), train_loss = 1.62495425, grad/param norm = 1.8785e-01, time/batch = 0.6573s	
4307/29850 (epoch 7.214), train_loss = 1.36048823, grad/param norm = 1.5709e-01, time/batch = 0.6627s	
4308/29850 (epoch 7.216), train_loss = 1.45538475, grad/param norm = 1.8772e-01, time/batch = 0.6824s	
4309/29850 (epoch 7.218), train_loss = 1.54624281, grad/param norm = 1.8319e-01, time/batch = 0.6910s	
4310/29850 (epoch 7.219), train_loss = 1.68484570, grad/param norm = 2.1104e-01, time/batch = 0.6730s	
4311/29850 (epoch 7.221), train_loss = 1.42856255, grad/param norm = 1.9016e-01, time/batch = 0.6871s	
4312/29850 (epoch 7.223), train_loss = 1.47893766, grad/param norm = 1.7758e-01, time/batch = 0.6738s	
4313/29850 (epoch 7.224), train_loss = 1.33816534, grad/param norm = 1.7084e-01, time/batch = 0.6594s	
4314/29850 (epoch 7.226), train_loss = 1.38336186, grad/param norm = 1.7729e-01, time/batch = 0.6594s	
4315/29850 (epoch 7.228), train_loss = 1.37668298, grad/param norm = 1.6323e-01, time/batch = 0.6607s	
4316/29850 (epoch 7.229), train_loss = 1.29356263, grad/param norm = 1.7813e-01, time/batch = 0.6611s	
4317/29850 (epoch 7.231), train_loss = 1.35217674, grad/param norm = 1.6429e-01, time/batch = 0.6630s	
4318/29850 (epoch 7.233), train_loss = 1.42862669, grad/param norm = 1.8078e-01, time/batch = 0.6646s	
4319/29850 (epoch 7.235), train_loss = 1.33383484, grad/param norm = 1.4855e-01, time/batch = 0.6619s	
4320/29850 (epoch 7.236), train_loss = 1.62737782, grad/param norm = 1.9513e-01, time/batch = 0.6762s	
4321/29850 (epoch 7.238), train_loss = 1.29098211, grad/param norm = 1.8688e-01, time/batch = 0.6770s	
4322/29850 (epoch 7.240), train_loss = 1.43043035, grad/param norm = 1.7519e-01, time/batch = 0.6863s	
4323/29850 (epoch 7.241), train_loss = 1.63185971, grad/param norm = 1.9997e-01, time/batch = 0.6638s	
4324/29850 (epoch 7.243), train_loss = 1.42390893, grad/param norm = 1.8210e-01, time/batch = 0.6617s	
4325/29850 (epoch 7.245), train_loss = 1.41755683, grad/param norm = 1.8147e-01, time/batch = 0.6645s	
4326/29850 (epoch 7.246), train_loss = 1.36591145, grad/param norm = 1.7276e-01, time/batch = 0.6722s	
4327/29850 (epoch 7.248), train_loss = 1.40427819, grad/param norm = 1.7641e-01, time/batch = 0.6705s	
4328/29850 (epoch 7.250), train_loss = 1.49697253, grad/param norm = 1.7448e-01, time/batch = 0.6662s	
4329/29850 (epoch 7.251), train_loss = 1.34091104, grad/param norm = 1.7174e-01, time/batch = 0.6632s	
4330/29850 (epoch 7.253), train_loss = 1.37425127, grad/param norm = 1.7618e-01, time/batch = 0.6682s	
4331/29850 (epoch 7.255), train_loss = 1.37220529, grad/param norm = 1.6745e-01, time/batch = 0.6854s	
4332/29850 (epoch 7.256), train_loss = 1.45509715, grad/param norm = 1.8548e-01, time/batch = 0.6654s	
4333/29850 (epoch 7.258), train_loss = 1.41502018, grad/param norm = 1.7008e-01, time/batch = 0.6728s	
4334/29850 (epoch 7.260), train_loss = 1.38851208, grad/param norm = 1.6656e-01, time/batch = 0.6740s	
4335/29850 (epoch 7.261), train_loss = 1.36224430, grad/param norm = 1.6177e-01, time/batch = 0.6665s	
4336/29850 (epoch 7.263), train_loss = 1.28994926, grad/param norm = 1.7398e-01, time/batch = 0.6673s	
4337/29850 (epoch 7.265), train_loss = 1.38850951, grad/param norm = 1.8177e-01, time/batch = 0.6635s	
4338/29850 (epoch 7.266), train_loss = 1.41214793, grad/param norm = 1.8657e-01, time/batch = 0.6676s	
4339/29850 (epoch 7.268), train_loss = 1.37170414, grad/param norm = 1.7093e-01, time/batch = 0.6626s	
4340/29850 (epoch 7.270), train_loss = 1.35247793, grad/param norm = 1.7204e-01, time/batch = 0.6670s	
4341/29850 (epoch 7.271), train_loss = 1.52810057, grad/param norm = 1.8165e-01, time/batch = 0.6699s	
4342/29850 (epoch 7.273), train_loss = 1.30307194, grad/param norm = 1.7004e-01, time/batch = 0.6807s	
4343/29850 (epoch 7.275), train_loss = 1.36042025, grad/param norm = 1.7046e-01, time/batch = 0.6816s	
4344/29850 (epoch 7.276), train_loss = 1.31940503, grad/param norm = 1.6405e-01, time/batch = 0.6575s	
4345/29850 (epoch 7.278), train_loss = 1.38377494, grad/param norm = 1.7030e-01, time/batch = 0.6566s	
4346/29850 (epoch 7.280), train_loss = 1.52564067, grad/param norm = 1.8240e-01, time/batch = 0.6597s	
4347/29850 (epoch 7.281), train_loss = 1.39640482, grad/param norm = 1.8363e-01, time/batch = 0.6624s	
4348/29850 (epoch 7.283), train_loss = 1.51468555, grad/param norm = 1.8937e-01, time/batch = 0.6577s	
4349/29850 (epoch 7.285), train_loss = 1.38531653, grad/param norm = 1.8168e-01, time/batch = 0.6593s	
4350/29850 (epoch 7.286), train_loss = 1.43576668, grad/param norm = 1.7837e-01, time/batch = 0.6586s	
4351/29850 (epoch 7.288), train_loss = 1.59193169, grad/param norm = 2.0974e-01, time/batch = 0.6601s	
4352/29850 (epoch 7.290), train_loss = 1.36300563, grad/param norm = 1.8756e-01, time/batch = 0.6630s	
4353/29850 (epoch 7.291), train_loss = 1.70347972, grad/param norm = 1.8972e-01, time/batch = 0.6870s	
4354/29850 (epoch 7.293), train_loss = 1.53905158, grad/param norm = 1.7799e-01, time/batch = 0.6687s	
4355/29850 (epoch 7.295), train_loss = 1.59056871, grad/param norm = 1.9492e-01, time/batch = 0.6668s	
4356/29850 (epoch 7.296), train_loss = 1.33953967, grad/param norm = 1.6222e-01, time/batch = 0.6619s	
4357/29850 (epoch 7.298), train_loss = 1.20041254, grad/param norm = 1.6550e-01, time/batch = 0.6604s	
4358/29850 (epoch 7.300), train_loss = 1.28438991, grad/param norm = 1.5212e-01, time/batch = 0.6588s	
4359/29850 (epoch 7.302), train_loss = 1.27896371, grad/param norm = 1.6301e-01, time/batch = 0.6589s	
4360/29850 (epoch 7.303), train_loss = 1.41019182, grad/param norm = 1.7367e-01, time/batch = 0.6621s	
4361/29850 (epoch 7.305), train_loss = 1.36039467, grad/param norm = 1.6586e-01, time/batch = 0.6705s	
4362/29850 (epoch 7.307), train_loss = 1.52183074, grad/param norm = 1.8972e-01, time/batch = 0.6697s	
4363/29850 (epoch 7.308), train_loss = 1.45686434, grad/param norm = 1.8706e-01, time/batch = 0.6612s	
4364/29850 (epoch 7.310), train_loss = 1.47210941, grad/param norm = 1.8596e-01, time/batch = 0.6788s	
4365/29850 (epoch 7.312), train_loss = 1.49836401, grad/param norm = 1.8748e-01, time/batch = 0.6665s	
4366/29850 (epoch 7.313), train_loss = 1.49200609, grad/param norm = 1.8488e-01, time/batch = 0.6617s	
4367/29850 (epoch 7.315), train_loss = 1.44612145, grad/param norm = 1.6594e-01, time/batch = 0.6618s	
4368/29850 (epoch 7.317), train_loss = 1.47744095, grad/param norm = 1.8027e-01, time/batch = 0.6640s	
4369/29850 (epoch 7.318), train_loss = 1.47777241, grad/param norm = 1.8649e-01, time/batch = 0.6616s	
4370/29850 (epoch 7.320), train_loss = 1.30383216, grad/param norm = 1.6881e-01, time/batch = 0.6568s	
4371/29850 (epoch 7.322), train_loss = 1.55382808, grad/param norm = 1.8327e-01, time/batch = 0.6663s	
4372/29850 (epoch 7.323), train_loss = 1.44729995, grad/param norm = 1.8989e-01, time/batch = 0.6580s	
4373/29850 (epoch 7.325), train_loss = 1.42692523, grad/param norm = 1.8458e-01, time/batch = 0.6592s	
4374/29850 (epoch 7.327), train_loss = 1.58620893, grad/param norm = 2.0631e-01, time/batch = 0.6559s	
4375/29850 (epoch 7.328), train_loss = 1.58899727, grad/param norm = 1.8221e-01, time/batch = 0.6521s	
4376/29850 (epoch 7.330), train_loss = 1.42050112, grad/param norm = 1.7216e-01, time/batch = 0.6586s	
4377/29850 (epoch 7.332), train_loss = 1.32458598, grad/param norm = 1.6971e-01, time/batch = 0.6540s	
4378/29850 (epoch 7.333), train_loss = 1.59157818, grad/param norm = 1.8258e-01, time/batch = 0.6558s	
4379/29850 (epoch 7.335), train_loss = 1.47989401, grad/param norm = 1.8930e-01, time/batch = 0.6702s	
4380/29850 (epoch 7.337), train_loss = 1.47019532, grad/param norm = 1.8421e-01, time/batch = 0.6683s	
4381/29850 (epoch 7.338), train_loss = 1.42867986, grad/param norm = 1.7121e-01, time/batch = 0.6768s	
4382/29850 (epoch 7.340), train_loss = 1.31296717, grad/param norm = 1.6971e-01, time/batch = 0.6660s	
4383/29850 (epoch 7.342), train_loss = 1.47706248, grad/param norm = 1.8727e-01, time/batch = 0.6593s	
4384/29850 (epoch 7.343), train_loss = 1.48195432, grad/param norm = 1.8349e-01, time/batch = 0.6596s	
4385/29850 (epoch 7.345), train_loss = 1.56454485, grad/param norm = 1.8652e-01, time/batch = 0.6596s	
4386/29850 (epoch 7.347), train_loss = 1.52162960, grad/param norm = 1.8515e-01, time/batch = 0.6608s	
4387/29850 (epoch 7.348), train_loss = 1.42986670, grad/param norm = 1.8059e-01, time/batch = 0.6655s	
4388/29850 (epoch 7.350), train_loss = 1.54198045, grad/param norm = 1.9403e-01, time/batch = 0.6779s	
4389/29850 (epoch 7.352), train_loss = 1.46767731, grad/param norm = 1.7910e-01, time/batch = 0.6876s	
4390/29850 (epoch 7.353), train_loss = 1.48110930, grad/param norm = 1.7911e-01, time/batch = 0.6644s	
4391/29850 (epoch 7.355), train_loss = 1.30106658, grad/param norm = 1.7616e-01, time/batch = 0.6603s	
4392/29850 (epoch 7.357), train_loss = 1.56718379, grad/param norm = 1.7081e-01, time/batch = 0.6596s	
4393/29850 (epoch 7.358), train_loss = 1.28260311, grad/param norm = 1.5827e-01, time/batch = 0.6590s	
4394/29850 (epoch 7.360), train_loss = 1.41727770, grad/param norm = 1.6783e-01, time/batch = 0.6560s	
4395/29850 (epoch 7.362), train_loss = 1.40941807, grad/param norm = 1.7933e-01, time/batch = 0.6650s	
4396/29850 (epoch 7.363), train_loss = 1.43669575, grad/param norm = 1.7921e-01, time/batch = 0.6649s	
4397/29850 (epoch 7.365), train_loss = 1.59538908, grad/param norm = 1.9995e-01, time/batch = 0.6750s	
4398/29850 (epoch 7.367), train_loss = 1.37722316, grad/param norm = 1.6113e-01, time/batch = 0.6765s	
4399/29850 (epoch 7.369), train_loss = 1.33928205, grad/param norm = 1.7569e-01, time/batch = 0.6881s	
4400/29850 (epoch 7.370), train_loss = 1.23372750, grad/param norm = 1.6583e-01, time/batch = 0.7001s	
4401/29850 (epoch 7.372), train_loss = 1.60520957, grad/param norm = 1.9217e-01, time/batch = 0.6952s	
4402/29850 (epoch 7.374), train_loss = 1.38145110, grad/param norm = 1.8583e-01, time/batch = 0.6856s	
4403/29850 (epoch 7.375), train_loss = 1.40479219, grad/param norm = 1.7874e-01, time/batch = 0.6754s	
4404/29850 (epoch 7.377), train_loss = 1.49414170, grad/param norm = 1.8439e-01, time/batch = 0.6656s	
4405/29850 (epoch 7.379), train_loss = 1.53374578, grad/param norm = 1.8078e-01, time/batch = 0.6627s	
4406/29850 (epoch 7.380), train_loss = 1.46961124, grad/param norm = 1.8312e-01, time/batch = 0.6608s	
4407/29850 (epoch 7.382), train_loss = 1.50905675, grad/param norm = 1.7859e-01, time/batch = 0.6652s	
4408/29850 (epoch 7.384), train_loss = 1.41168471, grad/param norm = 1.8391e-01, time/batch = 0.6658s	
4409/29850 (epoch 7.385), train_loss = 1.45998589, grad/param norm = 1.7157e-01, time/batch = 0.6751s	
4410/29850 (epoch 7.387), train_loss = 1.49570023, grad/param norm = 2.0124e-01, time/batch = 0.6862s	
4411/29850 (epoch 7.389), train_loss = 1.59166865, grad/param norm = 1.7629e-01, time/batch = 0.6628s	
4412/29850 (epoch 7.390), train_loss = 1.45685759, grad/param norm = 1.7420e-01, time/batch = 0.6587s	
4413/29850 (epoch 7.392), train_loss = 1.42336386, grad/param norm = 1.8381e-01, time/batch = 0.6582s	
4414/29850 (epoch 7.394), train_loss = 1.51887083, grad/param norm = 1.7857e-01, time/batch = 0.6593s	
4415/29850 (epoch 7.395), train_loss = 1.49738133, grad/param norm = 1.9412e-01, time/batch = 0.6633s	
4416/29850 (epoch 7.397), train_loss = 1.46247344, grad/param norm = 1.7905e-01, time/batch = 0.6638s	
4417/29850 (epoch 7.399), train_loss = 1.32861293, grad/param norm = 1.7308e-01, time/batch = 0.6748s	
4418/29850 (epoch 7.400), train_loss = 1.67525518, grad/param norm = 2.1951e-01, time/batch = 0.6633s	
4419/29850 (epoch 7.402), train_loss = 1.55379059, grad/param norm = 1.9135e-01, time/batch = 0.6632s	
4420/29850 (epoch 7.404), train_loss = 1.52315836, grad/param norm = 1.8204e-01, time/batch = 0.6593s	
4421/29850 (epoch 7.405), train_loss = 1.54241462, grad/param norm = 1.8802e-01, time/batch = 0.6623s	
4422/29850 (epoch 7.407), train_loss = 1.43077126, grad/param norm = 1.9066e-01, time/batch = 0.6614s	
4423/29850 (epoch 7.409), train_loss = 1.66629530, grad/param norm = 2.0119e-01, time/batch = 0.6641s	
4424/29850 (epoch 7.410), train_loss = 1.58669524, grad/param norm = 1.8166e-01, time/batch = 0.6653s	
4425/29850 (epoch 7.412), train_loss = 1.44175908, grad/param norm = 1.8426e-01, time/batch = 0.6779s	
4426/29850 (epoch 7.414), train_loss = 1.48236087, grad/param norm = 1.9180e-01, time/batch = 0.6630s	
4427/29850 (epoch 7.415), train_loss = 1.45034154, grad/param norm = 1.7083e-01, time/batch = 0.6606s	
4428/29850 (epoch 7.417), train_loss = 1.60817767, grad/param norm = 1.9625e-01, time/batch = 0.6806s	
4429/29850 (epoch 7.419), train_loss = 1.47780766, grad/param norm = 1.8938e-01, time/batch = 0.6604s	
4430/29850 (epoch 7.420), train_loss = 1.42879474, grad/param norm = 1.7060e-01, time/batch = 0.6588s	
4431/29850 (epoch 7.422), train_loss = 1.40201050, grad/param norm = 1.7286e-01, time/batch = 0.6604s	
4432/29850 (epoch 7.424), train_loss = 1.49980038, grad/param norm = 1.8600e-01, time/batch = 0.6709s	
4433/29850 (epoch 7.425), train_loss = 1.71291114, grad/param norm = 1.8216e-01, time/batch = 0.6695s	
4434/29850 (epoch 7.427), train_loss = 1.31771849, grad/param norm = 1.8313e-01, time/batch = 0.6854s	
4435/29850 (epoch 7.429), train_loss = 1.33733231, grad/param norm = 1.7651e-01, time/batch = 0.6823s	
4436/29850 (epoch 7.430), train_loss = 1.25896580, grad/param norm = 1.6356e-01, time/batch = 0.6918s	
4437/29850 (epoch 7.432), train_loss = 1.42589911, grad/param norm = 1.7524e-01, time/batch = 0.6829s	
4438/29850 (epoch 7.434), train_loss = 1.35553276, grad/param norm = 1.7001e-01, time/batch = 0.6867s	
4439/29850 (epoch 7.436), train_loss = 1.48975011, grad/param norm = 1.8245e-01, time/batch = 0.6841s	
4440/29850 (epoch 7.437), train_loss = 1.45283846, grad/param norm = 1.6563e-01, time/batch = 0.6705s	
4441/29850 (epoch 7.439), train_loss = 1.47302959, grad/param norm = 1.7864e-01, time/batch = 0.6773s	
4442/29850 (epoch 7.441), train_loss = 1.48470150, grad/param norm = 1.8346e-01, time/batch = 0.6708s	
4443/29850 (epoch 7.442), train_loss = 1.49560064, grad/param norm = 1.8340e-01, time/batch = 0.6714s	
4444/29850 (epoch 7.444), train_loss = 1.41176353, grad/param norm = 1.6173e-01, time/batch = 0.6769s	
4445/29850 (epoch 7.446), train_loss = 1.46868417, grad/param norm = 1.7678e-01, time/batch = 0.6807s	
4446/29850 (epoch 7.447), train_loss = 1.56974442, grad/param norm = 1.9592e-01, time/batch = 0.6737s	
4447/29850 (epoch 7.449), train_loss = 1.56286862, grad/param norm = 1.7511e-01, time/batch = 0.6838s	
4448/29850 (epoch 7.451), train_loss = 1.38744851, grad/param norm = 1.7278e-01, time/batch = 0.6732s	
4449/29850 (epoch 7.452), train_loss = 1.20105461, grad/param norm = 1.5449e-01, time/batch = 0.6609s	
4450/29850 (epoch 7.454), train_loss = 1.35795924, grad/param norm = 1.6180e-01, time/batch = 0.6714s	
4451/29850 (epoch 7.456), train_loss = 1.51973446, grad/param norm = 1.8342e-01, time/batch = 0.6683s	
4452/29850 (epoch 7.457), train_loss = 1.62041093, grad/param norm = 2.0383e-01, time/batch = 0.6616s	
4453/29850 (epoch 7.459), train_loss = 1.65815554, grad/param norm = 2.0177e-01, time/batch = 0.6640s	
4454/29850 (epoch 7.461), train_loss = 1.63039395, grad/param norm = 1.8051e-01, time/batch = 0.6588s	
4455/29850 (epoch 7.462), train_loss = 1.50811458, grad/param norm = 1.8971e-01, time/batch = 0.6613s	
4456/29850 (epoch 7.464), train_loss = 1.45781348, grad/param norm = 1.6856e-01, time/batch = 0.6586s	
4457/29850 (epoch 7.466), train_loss = 1.33197146, grad/param norm = 1.8301e-01, time/batch = 0.6611s	
4458/29850 (epoch 7.467), train_loss = 1.49629890, grad/param norm = 1.7603e-01, time/batch = 0.6586s	
4459/29850 (epoch 7.469), train_loss = 1.46641427, grad/param norm = 1.7021e-01, time/batch = 0.6583s	
4460/29850 (epoch 7.471), train_loss = 1.44655939, grad/param norm = 1.6360e-01, time/batch = 0.6545s	
4461/29850 (epoch 7.472), train_loss = 1.36635979, grad/param norm = 1.6814e-01, time/batch = 0.6604s	
4462/29850 (epoch 7.474), train_loss = 1.61946717, grad/param norm = 1.8531e-01, time/batch = 0.6612s	
4463/29850 (epoch 7.476), train_loss = 1.50063898, grad/param norm = 1.8358e-01, time/batch = 0.6586s	
4464/29850 (epoch 7.477), train_loss = 1.51856451, grad/param norm = 1.7920e-01, time/batch = 0.6555s	
4465/29850 (epoch 7.479), train_loss = 1.53395489, grad/param norm = 1.8652e-01, time/batch = 0.6654s	
4466/29850 (epoch 7.481), train_loss = 1.54373824, grad/param norm = 1.9033e-01, time/batch = 0.6556s	
4467/29850 (epoch 7.482), train_loss = 1.36452826, grad/param norm = 1.6273e-01, time/batch = 0.6552s	
4468/29850 (epoch 7.484), train_loss = 1.42859089, grad/param norm = 1.7272e-01, time/batch = 0.6560s	
4469/29850 (epoch 7.486), train_loss = 1.43976460, grad/param norm = 1.7454e-01, time/batch = 0.6558s	
4470/29850 (epoch 7.487), train_loss = 1.41018858, grad/param norm = 1.8697e-01, time/batch = 0.6617s	
4471/29850 (epoch 7.489), train_loss = 1.46256568, grad/param norm = 1.7911e-01, time/batch = 0.6615s	
4472/29850 (epoch 7.491), train_loss = 1.31059581, grad/param norm = 1.6516e-01, time/batch = 0.6599s	
4473/29850 (epoch 7.492), train_loss = 1.53811759, grad/param norm = 1.7704e-01, time/batch = 0.6625s	
4474/29850 (epoch 7.494), train_loss = 1.61839360, grad/param norm = 1.6532e-01, time/batch = 0.6580s	
4475/29850 (epoch 7.496), train_loss = 1.61794809, grad/param norm = 1.7532e-01, time/batch = 0.6626s	
4476/29850 (epoch 7.497), train_loss = 1.46733124, grad/param norm = 1.7622e-01, time/batch = 0.6654s	
4477/29850 (epoch 7.499), train_loss = 1.46495797, grad/param norm = 1.7114e-01, time/batch = 0.6870s	
4478/29850 (epoch 7.501), train_loss = 1.37495028, grad/param norm = 1.7028e-01, time/batch = 0.6646s	
4479/29850 (epoch 7.503), train_loss = 1.43098193, grad/param norm = 1.8069e-01, time/batch = 0.6629s	
4480/29850 (epoch 7.504), train_loss = 1.63234298, grad/param norm = 1.9049e-01, time/batch = 0.6642s	
4481/29850 (epoch 7.506), train_loss = 1.68234968, grad/param norm = 1.8660e-01, time/batch = 0.6712s	
4482/29850 (epoch 7.508), train_loss = 1.43776534, grad/param norm = 1.6912e-01, time/batch = 0.6648s	
4483/29850 (epoch 7.509), train_loss = 1.25726049, grad/param norm = 1.6650e-01, time/batch = 0.6644s	
4484/29850 (epoch 7.511), train_loss = 1.42864346, grad/param norm = 1.7433e-01, time/batch = 0.6644s	
4485/29850 (epoch 7.513), train_loss = 1.54359526, grad/param norm = 1.9392e-01, time/batch = 0.6696s	
4486/29850 (epoch 7.514), train_loss = 1.32770404, grad/param norm = 1.6574e-01, time/batch = 0.6611s	
4487/29850 (epoch 7.516), train_loss = 1.29786669, grad/param norm = 1.5827e-01, time/batch = 0.6836s	
4488/29850 (epoch 7.518), train_loss = 1.30824009, grad/param norm = 1.6546e-01, time/batch = 0.6898s	
4489/29850 (epoch 7.519), train_loss = 1.30915004, grad/param norm = 1.6236e-01, time/batch = 0.6874s	
4490/29850 (epoch 7.521), train_loss = 1.35851177, grad/param norm = 1.6026e-01, time/batch = 0.6690s	
4491/29850 (epoch 7.523), train_loss = 1.28260362, grad/param norm = 1.5419e-01, time/batch = 0.6650s	
4492/29850 (epoch 7.524), train_loss = 1.46717466, grad/param norm = 1.8299e-01, time/batch = 0.6649s	
4493/29850 (epoch 7.526), train_loss = 1.52442465, grad/param norm = 1.8053e-01, time/batch = 0.6596s	
4494/29850 (epoch 7.528), train_loss = 1.60617794, grad/param norm = 1.9758e-01, time/batch = 0.6718s	
4495/29850 (epoch 7.529), train_loss = 1.57865833, grad/param norm = 1.9771e-01, time/batch = 0.6651s	
4496/29850 (epoch 7.531), train_loss = 1.49519565, grad/param norm = 1.9795e-01, time/batch = 0.6762s	
4497/29850 (epoch 7.533), train_loss = 1.35935823, grad/param norm = 1.7909e-01, time/batch = 0.6745s	
4498/29850 (epoch 7.534), train_loss = 1.44500508, grad/param norm = 1.8921e-01, time/batch = 0.6642s	
4499/29850 (epoch 7.536), train_loss = 1.46115972, grad/param norm = 1.8533e-01, time/batch = 0.6707s	
4500/29850 (epoch 7.538), train_loss = 1.51161079, grad/param norm = 1.7484e-01, time/batch = 0.6866s	
4501/29850 (epoch 7.539), train_loss = 1.54187128, grad/param norm = 1.8377e-01, time/batch = 0.6783s	
4502/29850 (epoch 7.541), train_loss = 1.28804313, grad/param norm = 1.6671e-01, time/batch = 0.6652s	
4503/29850 (epoch 7.543), train_loss = 1.40388105, grad/param norm = 1.6307e-01, time/batch = 0.6636s	
4504/29850 (epoch 7.544), train_loss = 1.45684229, grad/param norm = 1.7861e-01, time/batch = 0.6620s	
4505/29850 (epoch 7.546), train_loss = 1.54806064, grad/param norm = 1.8173e-01, time/batch = 0.6766s	
4506/29850 (epoch 7.548), train_loss = 1.33946320, grad/param norm = 1.6618e-01, time/batch = 0.6751s	
4507/29850 (epoch 7.549), train_loss = 1.40561727, grad/param norm = 1.6155e-01, time/batch = 0.6646s	
4508/29850 (epoch 7.551), train_loss = 1.37012384, grad/param norm = 1.8318e-01, time/batch = 0.6607s	
4509/29850 (epoch 7.553), train_loss = 1.48498183, grad/param norm = 1.8500e-01, time/batch = 0.6614s	
4510/29850 (epoch 7.554), train_loss = 1.22644196, grad/param norm = 1.5525e-01, time/batch = 0.6737s	
4511/29850 (epoch 7.556), train_loss = 1.44767050, grad/param norm = 1.8641e-01, time/batch = 0.6927s	
4512/29850 (epoch 7.558), train_loss = 1.39326670, grad/param norm = 1.7774e-01, time/batch = 0.6920s	
4513/29850 (epoch 7.559), train_loss = 1.51770073, grad/param norm = 1.8761e-01, time/batch = 0.6914s	
4514/29850 (epoch 7.561), train_loss = 1.51890798, grad/param norm = 1.7826e-01, time/batch = 0.6722s	
4515/29850 (epoch 7.563), train_loss = 1.41985353, grad/param norm = 1.6913e-01, time/batch = 0.6669s	
4516/29850 (epoch 7.564), train_loss = 1.42729690, grad/param norm = 1.8062e-01, time/batch = 0.6641s	
4517/29850 (epoch 7.566), train_loss = 1.37788742, grad/param norm = 1.7203e-01, time/batch = 0.6527s	
4518/29850 (epoch 7.568), train_loss = 1.52757698, grad/param norm = 1.7523e-01, time/batch = 0.6374s	
4519/29850 (epoch 7.570), train_loss = 1.45393000, grad/param norm = 1.7489e-01, time/batch = 0.6418s	
4520/29850 (epoch 7.571), train_loss = 1.49957589, grad/param norm = 1.7165e-01, time/batch = 0.6496s	
4521/29850 (epoch 7.573), train_loss = 1.62073615, grad/param norm = 1.9342e-01, time/batch = 0.6465s	
4522/29850 (epoch 7.575), train_loss = 1.54788314, grad/param norm = 1.7940e-01, time/batch = 0.6386s	
4523/29850 (epoch 7.576), train_loss = 1.61402758, grad/param norm = 1.7395e-01, time/batch = 0.6376s	
4524/29850 (epoch 7.578), train_loss = 1.50702569, grad/param norm = 1.7784e-01, time/batch = 0.6375s	
4525/29850 (epoch 7.580), train_loss = 1.52904005, grad/param norm = 1.8226e-01, time/batch = 0.6399s	
4526/29850 (epoch 7.581), train_loss = 1.40595161, grad/param norm = 1.8173e-01, time/batch = 0.6427s	
4527/29850 (epoch 7.583), train_loss = 1.42331558, grad/param norm = 1.7140e-01, time/batch = 0.6428s	
4528/29850 (epoch 7.585), train_loss = 1.41960596, grad/param norm = 1.6580e-01, time/batch = 0.6452s	
4529/29850 (epoch 7.586), train_loss = 1.46688939, grad/param norm = 1.8113e-01, time/batch = 0.6411s	
4530/29850 (epoch 7.588), train_loss = 1.39144237, grad/param norm = 1.6992e-01, time/batch = 0.6450s	
4531/29850 (epoch 7.590), train_loss = 1.45075738, grad/param norm = 1.7082e-01, time/batch = 0.6430s	
4532/29850 (epoch 7.591), train_loss = 1.37806600, grad/param norm = 1.6616e-01, time/batch = 0.6425s	
4533/29850 (epoch 7.593), train_loss = 1.37897647, grad/param norm = 1.6660e-01, time/batch = 0.6506s	
4534/29850 (epoch 7.595), train_loss = 1.33863830, grad/param norm = 1.5929e-01, time/batch = 0.6692s	
4535/29850 (epoch 7.596), train_loss = 1.30702789, grad/param norm = 1.6797e-01, time/batch = 0.6510s	
4536/29850 (epoch 7.598), train_loss = 1.31771912, grad/param norm = 1.7316e-01, time/batch = 0.6378s	
4537/29850 (epoch 7.600), train_loss = 1.54804822, grad/param norm = 1.9113e-01, time/batch = 0.6421s	
4538/29850 (epoch 7.601), train_loss = 1.31877365, grad/param norm = 1.6225e-01, time/batch = 0.6386s	
4539/29850 (epoch 7.603), train_loss = 1.44633946, grad/param norm = 1.7126e-01, time/batch = 0.6415s	
4540/29850 (epoch 7.605), train_loss = 1.48983455, grad/param norm = 1.7636e-01, time/batch = 0.6460s	
4541/29850 (epoch 7.606), train_loss = 1.24660567, grad/param norm = 1.6944e-01, time/batch = 0.6434s	
4542/29850 (epoch 7.608), train_loss = 1.44140881, grad/param norm = 1.7292e-01, time/batch = 0.6402s	
4543/29850 (epoch 7.610), train_loss = 1.40550736, grad/param norm = 1.7461e-01, time/batch = 0.6453s	
4544/29850 (epoch 7.611), train_loss = 1.23216576, grad/param norm = 1.5251e-01, time/batch = 0.6567s	
4545/29850 (epoch 7.613), train_loss = 1.21426131, grad/param norm = 1.5921e-01, time/batch = 0.6691s	
4546/29850 (epoch 7.615), train_loss = 1.25546974, grad/param norm = 1.5546e-01, time/batch = 0.6554s	
4547/29850 (epoch 7.616), train_loss = 1.41142770, grad/param norm = 1.8422e-01, time/batch = 0.6547s	
4548/29850 (epoch 7.618), train_loss = 1.45186216, grad/param norm = 1.7277e-01, time/batch = 0.6423s	
4549/29850 (epoch 7.620), train_loss = 1.47671942, grad/param norm = 1.8209e-01, time/batch = 0.6426s	
4550/29850 (epoch 7.621), train_loss = 1.51964837, grad/param norm = 2.0478e-01, time/batch = 0.6709s	
4551/29850 (epoch 7.623), train_loss = 1.52001735, grad/param norm = 1.8466e-01, time/batch = 0.6426s	
4552/29850 (epoch 7.625), train_loss = 1.51368136, grad/param norm = 1.8740e-01, time/batch = 0.6516s	
4553/29850 (epoch 7.626), train_loss = 1.53184085, grad/param norm = 1.8672e-01, time/batch = 0.6632s	
4554/29850 (epoch 7.628), train_loss = 1.27812497, grad/param norm = 1.6578e-01, time/batch = 0.6475s	
4555/29850 (epoch 7.630), train_loss = 1.44740804, grad/param norm = 1.9001e-01, time/batch = 0.6647s	
4556/29850 (epoch 7.631), train_loss = 1.34534153, grad/param norm = 1.7060e-01, time/batch = 0.6613s	
4557/29850 (epoch 7.633), train_loss = 1.52695647, grad/param norm = 1.9241e-01, time/batch = 0.6504s	
4558/29850 (epoch 7.635), train_loss = 1.44203565, grad/param norm = 1.8527e-01, time/batch = 0.6368s	
4559/29850 (epoch 7.637), train_loss = 1.49306326, grad/param norm = 1.8171e-01, time/batch = 0.6429s	
4560/29850 (epoch 7.638), train_loss = 1.35070073, grad/param norm = 1.6851e-01, time/batch = 0.6387s	
4561/29850 (epoch 7.640), train_loss = 1.59791530, grad/param norm = 1.8800e-01, time/batch = 0.6463s	
4562/29850 (epoch 7.642), train_loss = 1.43593348, grad/param norm = 1.8574e-01, time/batch = 0.6430s	
4563/29850 (epoch 7.643), train_loss = 1.34401630, grad/param norm = 1.6174e-01, time/batch = 0.6526s	
4564/29850 (epoch 7.645), train_loss = 1.47022476, grad/param norm = 1.7494e-01, time/batch = 0.6422s	
4565/29850 (epoch 7.647), train_loss = 1.55954460, grad/param norm = 1.7891e-01, time/batch = 0.6406s	
4566/29850 (epoch 7.648), train_loss = 1.29615137, grad/param norm = 1.5936e-01, time/batch = 0.6484s	
4567/29850 (epoch 7.650), train_loss = 1.40527239, grad/param norm = 1.8649e-01, time/batch = 0.6480s	
4568/29850 (epoch 7.652), train_loss = 1.42973236, grad/param norm = 1.7390e-01, time/batch = 0.6442s	
4569/29850 (epoch 7.653), train_loss = 1.51978612, grad/param norm = 1.7030e-01, time/batch = 0.6454s	
4570/29850 (epoch 7.655), train_loss = 1.41277883, grad/param norm = 1.6741e-01, time/batch = 0.6416s	
4571/29850 (epoch 7.657), train_loss = 1.37970784, grad/param norm = 1.6653e-01, time/batch = 0.6403s	
4572/29850 (epoch 7.658), train_loss = 1.53508062, grad/param norm = 1.8205e-01, time/batch = 0.6405s	
4573/29850 (epoch 7.660), train_loss = 1.35415747, grad/param norm = 1.7258e-01, time/batch = 0.6407s	
4574/29850 (epoch 7.662), train_loss = 1.41620183, grad/param norm = 1.7589e-01, time/batch = 0.6400s	
4575/29850 (epoch 7.663), train_loss = 1.53041435, grad/param norm = 1.9021e-01, time/batch = 0.6387s	
4576/29850 (epoch 7.665), train_loss = 1.48068614, grad/param norm = 1.8869e-01, time/batch = 0.6481s	
4577/29850 (epoch 7.667), train_loss = 1.52510056, grad/param norm = 1.9763e-01, time/batch = 0.6408s	
4578/29850 (epoch 7.668), train_loss = 1.45100459, grad/param norm = 1.6686e-01, time/batch = 0.6554s	
4579/29850 (epoch 7.670), train_loss = 1.71100472, grad/param norm = 1.9443e-01, time/batch = 0.6697s	
4580/29850 (epoch 7.672), train_loss = 1.50288840, grad/param norm = 1.9387e-01, time/batch = 0.6671s	
4581/29850 (epoch 7.673), train_loss = 1.51239506, grad/param norm = 1.7812e-01, time/batch = 0.6610s	
4582/29850 (epoch 7.675), train_loss = 1.41683112, grad/param norm = 1.6891e-01, time/batch = 0.6649s	
4583/29850 (epoch 7.677), train_loss = 1.42518003, grad/param norm = 1.8021e-01, time/batch = 0.6486s	
4584/29850 (epoch 7.678), train_loss = 1.40617986, grad/param norm = 1.8754e-01, time/batch = 0.6537s	
4585/29850 (epoch 7.680), train_loss = 1.48526937, grad/param norm = 1.8155e-01, time/batch = 0.6584s	
4586/29850 (epoch 7.682), train_loss = 1.41523131, grad/param norm = 1.6951e-01, time/batch = 0.6570s	
4587/29850 (epoch 7.683), train_loss = 1.63485890, grad/param norm = 2.0589e-01, time/batch = 0.6610s	
4588/29850 (epoch 7.685), train_loss = 1.57749434, grad/param norm = 1.6003e-01, time/batch = 0.6600s	
4589/29850 (epoch 7.687), train_loss = 1.50974941, grad/param norm = 1.8068e-01, time/batch = 0.6607s	
4590/29850 (epoch 7.688), train_loss = 1.28157956, grad/param norm = 1.4226e-01, time/batch = 0.6599s	
4591/29850 (epoch 7.690), train_loss = 1.34663156, grad/param norm = 1.8148e-01, time/batch = 0.6643s	
4592/29850 (epoch 7.692), train_loss = 1.62754574, grad/param norm = 1.9522e-01, time/batch = 0.6537s	
4593/29850 (epoch 7.693), train_loss = 1.41364907, grad/param norm = 1.6213e-01, time/batch = 0.6492s	
4594/29850 (epoch 7.695), train_loss = 1.30194201, grad/param norm = 1.6480e-01, time/batch = 0.6460s	
4595/29850 (epoch 7.697), train_loss = 1.51615409, grad/param norm = 1.9085e-01, time/batch = 0.6491s	
4596/29850 (epoch 7.698), train_loss = 1.53486063, grad/param norm = 1.8554e-01, time/batch = 0.6517s	
4597/29850 (epoch 7.700), train_loss = 1.52870741, grad/param norm = 2.0238e-01, time/batch = 0.6472s	
4598/29850 (epoch 7.702), train_loss = 1.41303777, grad/param norm = 1.8497e-01, time/batch = 0.6511s	
4599/29850 (epoch 7.704), train_loss = 1.35274863, grad/param norm = 1.6802e-01, time/batch = 0.6471s	
4600/29850 (epoch 7.705), train_loss = 1.43894830, grad/param norm = 1.6692e-01, time/batch = 0.6465s	
4601/29850 (epoch 7.707), train_loss = 1.44339720, grad/param norm = 1.8538e-01, time/batch = 0.6455s	
4602/29850 (epoch 7.709), train_loss = 1.55867745, grad/param norm = 1.9042e-01, time/batch = 0.6445s	
4603/29850 (epoch 7.710), train_loss = 1.43152552, grad/param norm = 1.8409e-01, time/batch = 0.6478s	
4604/29850 (epoch 7.712), train_loss = 1.44033326, grad/param norm = 1.7297e-01, time/batch = 0.6400s	
4605/29850 (epoch 7.714), train_loss = 1.48020780, grad/param norm = 1.9804e-01, time/batch = 0.6392s	
4606/29850 (epoch 7.715), train_loss = 1.53341893, grad/param norm = 1.8598e-01, time/batch = 0.6547s	
4607/29850 (epoch 7.717), train_loss = 1.30679254, grad/param norm = 1.7221e-01, time/batch = 0.6677s	
4608/29850 (epoch 7.719), train_loss = 1.41937921, grad/param norm = 1.7500e-01, time/batch = 0.6520s	
4609/29850 (epoch 7.720), train_loss = 1.46685841, grad/param norm = 1.7719e-01, time/batch = 0.6473s	
4610/29850 (epoch 7.722), train_loss = 1.33456193, grad/param norm = 1.6306e-01, time/batch = 0.6579s	
4611/29850 (epoch 7.724), train_loss = 1.46484775, grad/param norm = 1.7818e-01, time/batch = 0.6526s	
4612/29850 (epoch 7.725), train_loss = 1.30976286, grad/param norm = 1.5800e-01, time/batch = 0.6469s	
4613/29850 (epoch 7.727), train_loss = 1.40682594, grad/param norm = 1.8440e-01, time/batch = 0.6653s	
4614/29850 (epoch 7.729), train_loss = 1.26438592, grad/param norm = 1.7296e-01, time/batch = 0.6491s	
4615/29850 (epoch 7.730), train_loss = 1.30155353, grad/param norm = 1.6001e-01, time/batch = 0.6428s	
4616/29850 (epoch 7.732), train_loss = 1.42163097, grad/param norm = 1.6453e-01, time/batch = 0.6437s	
4617/29850 (epoch 7.734), train_loss = 1.62693709, grad/param norm = 1.8670e-01, time/batch = 0.6432s	
4618/29850 (epoch 7.735), train_loss = 1.47972026, grad/param norm = 1.8782e-01, time/batch = 0.6411s	
4619/29850 (epoch 7.737), train_loss = 1.32599173, grad/param norm = 1.7102e-01, time/batch = 0.6439s	
4620/29850 (epoch 7.739), train_loss = 1.31205431, grad/param norm = 1.7070e-01, time/batch = 0.6411s	
4621/29850 (epoch 7.740), train_loss = 1.32670700, grad/param norm = 1.7522e-01, time/batch = 0.6425s	
4622/29850 (epoch 7.742), train_loss = 1.31566972, grad/param norm = 1.6677e-01, time/batch = 0.6450s	
4623/29850 (epoch 7.744), train_loss = 1.43838422, grad/param norm = 1.9422e-01, time/batch = 0.6428s	
4624/29850 (epoch 7.745), train_loss = 1.41941487, grad/param norm = 1.9221e-01, time/batch = 0.6423s	
4625/29850 (epoch 7.747), train_loss = 1.36822816, grad/param norm = 1.8314e-01, time/batch = 0.6426s	
4626/29850 (epoch 7.749), train_loss = 1.33528960, grad/param norm = 1.8496e-01, time/batch = 0.6423s	
4627/29850 (epoch 7.750), train_loss = 1.42603660, grad/param norm = 1.8329e-01, time/batch = 0.6548s	
4628/29850 (epoch 7.752), train_loss = 1.35169713, grad/param norm = 1.6369e-01, time/batch = 0.6458s	
4629/29850 (epoch 7.754), train_loss = 1.34399568, grad/param norm = 1.7934e-01, time/batch = 0.6489s	
4630/29850 (epoch 7.755), train_loss = 1.41449621, grad/param norm = 1.7517e-01, time/batch = 0.6419s	
4631/29850 (epoch 7.757), train_loss = 1.38229600, grad/param norm = 1.6915e-01, time/batch = 0.6454s	
4632/29850 (epoch 7.759), train_loss = 1.44286486, grad/param norm = 1.6227e-01, time/batch = 0.6422s	
4633/29850 (epoch 7.760), train_loss = 1.31424492, grad/param norm = 1.7108e-01, time/batch = 0.6428s	
4634/29850 (epoch 7.762), train_loss = 1.32206589, grad/param norm = 1.7005e-01, time/batch = 0.6423s	
4635/29850 (epoch 7.764), train_loss = 1.36483727, grad/param norm = 1.9194e-01, time/batch = 0.6454s	
4636/29850 (epoch 7.765), train_loss = 1.37374339, grad/param norm = 1.9309e-01, time/batch = 0.6416s	
4637/29850 (epoch 7.767), train_loss = 1.41963050, grad/param norm = 1.6800e-01, time/batch = 0.6519s	
4638/29850 (epoch 7.769), train_loss = 1.36785225, grad/param norm = 1.8424e-01, time/batch = 0.6488s	
4639/29850 (epoch 7.771), train_loss = 1.47507753, grad/param norm = 1.8686e-01, time/batch = 0.6460s	
4640/29850 (epoch 7.772), train_loss = 1.53458921, grad/param norm = 1.8131e-01, time/batch = 0.6459s	
4641/29850 (epoch 7.774), train_loss = 1.37949171, grad/param norm = 1.8451e-01, time/batch = 0.6485s	
4642/29850 (epoch 7.776), train_loss = 1.35820598, grad/param norm = 1.7624e-01, time/batch = 0.6456s	
4643/29850 (epoch 7.777), train_loss = 1.48390828, grad/param norm = 1.8663e-01, time/batch = 0.6426s	
4644/29850 (epoch 7.779), train_loss = 1.27927576, grad/param norm = 1.6707e-01, time/batch = 0.6548s	
4645/29850 (epoch 7.781), train_loss = 1.35575015, grad/param norm = 1.7151e-01, time/batch = 0.6498s	
4646/29850 (epoch 7.782), train_loss = 1.40279953, grad/param norm = 1.6574e-01, time/batch = 0.6617s	
4647/29850 (epoch 7.784), train_loss = 1.35626294, grad/param norm = 1.8574e-01, time/batch = 0.6580s	
4648/29850 (epoch 7.786), train_loss = 1.36197629, grad/param norm = 1.7218e-01, time/batch = 0.6591s	
4649/29850 (epoch 7.787), train_loss = 1.34702873, grad/param norm = 1.7280e-01, time/batch = 0.6534s	
4650/29850 (epoch 7.789), train_loss = 1.26756177, grad/param norm = 1.5638e-01, time/batch = 0.6455s	
4651/29850 (epoch 7.791), train_loss = 1.42084412, grad/param norm = 1.8268e-01, time/batch = 0.6434s	
4652/29850 (epoch 7.792), train_loss = 1.46671720, grad/param norm = 1.7654e-01, time/batch = 0.6402s	
4653/29850 (epoch 7.794), train_loss = 1.42196842, grad/param norm = 1.6795e-01, time/batch = 0.6434s	
4654/29850 (epoch 7.796), train_loss = 1.32444726, grad/param norm = 1.7849e-01, time/batch = 0.6461s	
4655/29850 (epoch 7.797), train_loss = 1.31880850, grad/param norm = 1.5931e-01, time/batch = 0.6456s	
4656/29850 (epoch 7.799), train_loss = 1.30173804, grad/param norm = 1.6277e-01, time/batch = 0.6623s	
4657/29850 (epoch 7.801), train_loss = 1.50897284, grad/param norm = 1.9783e-01, time/batch = 0.6687s	
4658/29850 (epoch 7.802), train_loss = 1.28598078, grad/param norm = 1.8119e-01, time/batch = 0.6501s	
4659/29850 (epoch 7.804), train_loss = 1.35901751, grad/param norm = 1.6355e-01, time/batch = 0.6440s	
4660/29850 (epoch 7.806), train_loss = 1.35776164, grad/param norm = 1.6517e-01, time/batch = 0.6463s	
4661/29850 (epoch 7.807), train_loss = 1.22565604, grad/param norm = 1.5043e-01, time/batch = 0.6470s	
4662/29850 (epoch 7.809), train_loss = 1.42906500, grad/param norm = 1.9743e-01, time/batch = 0.6445s	
4663/29850 (epoch 7.811), train_loss = 1.51209532, grad/param norm = 1.8853e-01, time/batch = 0.6499s	
4664/29850 (epoch 7.812), train_loss = 1.42716026, grad/param norm = 1.8331e-01, time/batch = 0.6451s	
4665/29850 (epoch 7.814), train_loss = 1.49314844, grad/param norm = 1.9454e-01, time/batch = 0.6419s	
4666/29850 (epoch 7.816), train_loss = 1.46904383, grad/param norm = 1.6744e-01, time/batch = 0.6419s	
4667/29850 (epoch 7.817), train_loss = 1.43341185, grad/param norm = 1.7057e-01, time/batch = 0.6660s	
4668/29850 (epoch 7.819), train_loss = 1.36671563, grad/param norm = 1.7811e-01, time/batch = 0.6703s	
4669/29850 (epoch 7.821), train_loss = 1.58496234, grad/param norm = 2.1279e-01, time/batch = 0.6470s	
4670/29850 (epoch 7.822), train_loss = 1.40606454, grad/param norm = 1.6506e-01, time/batch = 0.6566s	
4671/29850 (epoch 7.824), train_loss = 1.39329455, grad/param norm = 1.8739e-01, time/batch = 0.6771s	
4672/29850 (epoch 7.826), train_loss = 1.38783402, grad/param norm = 1.7003e-01, time/batch = 0.6620s	
4673/29850 (epoch 7.827), train_loss = 1.34155384, grad/param norm = 1.8140e-01, time/batch = 0.6458s	
4674/29850 (epoch 7.829), train_loss = 1.46256737, grad/param norm = 1.9982e-01, time/batch = 0.6435s	
4675/29850 (epoch 7.831), train_loss = 1.44695868, grad/param norm = 1.8711e-01, time/batch = 0.6394s	
4676/29850 (epoch 7.832), train_loss = 1.31629166, grad/param norm = 1.6536e-01, time/batch = 0.6445s	
4677/29850 (epoch 7.834), train_loss = 1.31078348, grad/param norm = 1.8781e-01, time/batch = 0.6449s	
4678/29850 (epoch 7.836), train_loss = 1.27791006, grad/param norm = 1.5872e-01, time/batch = 0.6701s	
4679/29850 (epoch 7.838), train_loss = 1.45011620, grad/param norm = 1.7505e-01, time/batch = 0.6505s	
4680/29850 (epoch 7.839), train_loss = 1.37358049, grad/param norm = 1.7610e-01, time/batch = 0.6390s	
4681/29850 (epoch 7.841), train_loss = 1.38038599, grad/param norm = 1.7059e-01, time/batch = 0.6515s	
4682/29850 (epoch 7.843), train_loss = 1.37586673, grad/param norm = 1.6418e-01, time/batch = 0.6423s	
4683/29850 (epoch 7.844), train_loss = 1.35994406, grad/param norm = 1.7345e-01, time/batch = 0.6472s	
4684/29850 (epoch 7.846), train_loss = 1.46188153, grad/param norm = 2.1239e-01, time/batch = 0.6440s	
4685/29850 (epoch 7.848), train_loss = 1.47695963, grad/param norm = 1.9484e-01, time/batch = 0.6530s	
4686/29850 (epoch 7.849), train_loss = 1.30776617, grad/param norm = 1.7574e-01, time/batch = 0.6641s	
4687/29850 (epoch 7.851), train_loss = 1.46647916, grad/param norm = 1.8688e-01, time/batch = 0.6605s	
4688/29850 (epoch 7.853), train_loss = 1.38055433, grad/param norm = 1.8922e-01, time/batch = 0.6667s	
4689/29850 (epoch 7.854), train_loss = 1.46456030, grad/param norm = 1.9359e-01, time/batch = 0.6714s	
4690/29850 (epoch 7.856), train_loss = 1.47512162, grad/param norm = 2.0184e-01, time/batch = 0.6521s	
4691/29850 (epoch 7.858), train_loss = 1.40351175, grad/param norm = 1.8474e-01, time/batch = 0.6529s	
4692/29850 (epoch 7.859), train_loss = 1.34684116, grad/param norm = 2.0353e-01, time/batch = 0.6394s	
4693/29850 (epoch 7.861), train_loss = 1.51428791, grad/param norm = 1.8769e-01, time/batch = 0.6388s	
4694/29850 (epoch 7.863), train_loss = 1.51788283, grad/param norm = 1.6413e-01, time/batch = 0.6447s	
4695/29850 (epoch 7.864), train_loss = 1.43901934, grad/param norm = 1.8284e-01, time/batch = 0.6419s	
4696/29850 (epoch 7.866), train_loss = 1.41738021, grad/param norm = 1.8184e-01, time/batch = 0.6408s	
4697/29850 (epoch 7.868), train_loss = 1.51988220, grad/param norm = 1.8347e-01, time/batch = 0.6384s	
4698/29850 (epoch 7.869), train_loss = 1.33046471, grad/param norm = 1.7356e-01, time/batch = 0.6396s	
4699/29850 (epoch 7.871), train_loss = 1.40052171, grad/param norm = 1.7676e-01, time/batch = 0.6631s	
4700/29850 (epoch 7.873), train_loss = 1.46598180, grad/param norm = 1.7333e-01, time/batch = 0.6649s	
4701/29850 (epoch 7.874), train_loss = 1.44810139, grad/param norm = 1.7988e-01, time/batch = 0.6468s	
4702/29850 (epoch 7.876), train_loss = 1.47463114, grad/param norm = 1.9302e-01, time/batch = 0.6484s	
4703/29850 (epoch 7.878), train_loss = 1.39803901, grad/param norm = 1.7165e-01, time/batch = 0.6486s	
4704/29850 (epoch 7.879), train_loss = 1.48948961, grad/param norm = 1.6693e-01, time/batch = 0.6431s	
4705/29850 (epoch 7.881), train_loss = 1.49434682, grad/param norm = 1.8423e-01, time/batch = 0.6420s	
4706/29850 (epoch 7.883), train_loss = 1.52162661, grad/param norm = 1.8599e-01, time/batch = 0.6414s	
4707/29850 (epoch 7.884), train_loss = 1.29142608, grad/param norm = 1.7134e-01, time/batch = 0.6445s	
4708/29850 (epoch 7.886), train_loss = 1.60905121, grad/param norm = 1.9268e-01, time/batch = 0.6496s	
4709/29850 (epoch 7.888), train_loss = 1.38237809, grad/param norm = 1.7747e-01, time/batch = 0.6466s	
4710/29850 (epoch 7.889), train_loss = 1.36370597, grad/param norm = 1.8505e-01, time/batch = 0.6430s	
4711/29850 (epoch 7.891), train_loss = 1.37323003, grad/param norm = 1.7887e-01, time/batch = 0.6420s	
4712/29850 (epoch 7.893), train_loss = 1.29598756, grad/param norm = 1.6744e-01, time/batch = 0.6471s	
4713/29850 (epoch 7.894), train_loss = 1.35255950, grad/param norm = 1.7289e-01, time/batch = 0.6674s	
4714/29850 (epoch 7.896), train_loss = 1.35048423, grad/param norm = 1.7602e-01, time/batch = 0.6622s	
4715/29850 (epoch 7.898), train_loss = 1.53139805, grad/param norm = 1.9527e-01, time/batch = 0.6543s	
4716/29850 (epoch 7.899), train_loss = 1.25183133, grad/param norm = 1.7597e-01, time/batch = 0.6591s	
4717/29850 (epoch 7.901), train_loss = 1.78114484, grad/param norm = 2.1381e-01, time/batch = 0.6561s	
4718/29850 (epoch 7.903), train_loss = 1.44043150, grad/param norm = 1.8943e-01, time/batch = 0.6451s	
4719/29850 (epoch 7.905), train_loss = 1.55226832, grad/param norm = 1.7421e-01, time/batch = 0.6543s	
4720/29850 (epoch 7.906), train_loss = 1.30554501, grad/param norm = 1.8094e-01, time/batch = 0.6624s	
4721/29850 (epoch 7.908), train_loss = 1.53049074, grad/param norm = 1.7846e-01, time/batch = 0.6526s	
4722/29850 (epoch 7.910), train_loss = 1.49769626, grad/param norm = 1.7863e-01, time/batch = 0.6474s	
4723/29850 (epoch 7.911), train_loss = 1.55870130, grad/param norm = 1.9755e-01, time/batch = 0.6479s	
4724/29850 (epoch 7.913), train_loss = 1.43996208, grad/param norm = 1.7921e-01, time/batch = 0.6441s	
4725/29850 (epoch 7.915), train_loss = 1.48827513, grad/param norm = 1.9622e-01, time/batch = 0.6427s	
4726/29850 (epoch 7.916), train_loss = 1.43080131, grad/param norm = 1.8387e-01, time/batch = 0.6505s	
4727/29850 (epoch 7.918), train_loss = 1.35028608, grad/param norm = 1.5861e-01, time/batch = 0.6493s	
4728/29850 (epoch 7.920), train_loss = 1.47303185, grad/param norm = 1.6192e-01, time/batch = 0.6449s	
4729/29850 (epoch 7.921), train_loss = 1.47914303, grad/param norm = 1.8347e-01, time/batch = 0.6509s	
4730/29850 (epoch 7.923), train_loss = 1.47067004, grad/param norm = 1.7825e-01, time/batch = 0.6486s	
4731/29850 (epoch 7.925), train_loss = 1.56553217, grad/param norm = 1.8202e-01, time/batch = 0.6455s	
4732/29850 (epoch 7.926), train_loss = 1.57978997, grad/param norm = 1.9065e-01, time/batch = 0.6430s	
4733/29850 (epoch 7.928), train_loss = 1.41289906, grad/param norm = 1.8352e-01, time/batch = 0.6551s	
4734/29850 (epoch 7.930), train_loss = 1.54628614, grad/param norm = 1.8433e-01, time/batch = 0.6557s	
4735/29850 (epoch 7.931), train_loss = 1.50576176, grad/param norm = 1.8439e-01, time/batch = 0.6491s	
4736/29850 (epoch 7.933), train_loss = 1.59597856, grad/param norm = 1.8323e-01, time/batch = 0.6706s	
4737/29850 (epoch 7.935), train_loss = 1.55856067, grad/param norm = 1.7824e-01, time/batch = 0.6557s	
4738/29850 (epoch 7.936), train_loss = 1.53002492, grad/param norm = 1.9795e-01, time/batch = 0.6436s	
4739/29850 (epoch 7.938), train_loss = 1.30803411, grad/param norm = 1.7477e-01, time/batch = 0.6449s	
4740/29850 (epoch 7.940), train_loss = 1.25477206, grad/param norm = 1.6197e-01, time/batch = 0.6432s	
4741/29850 (epoch 7.941), train_loss = 1.38940944, grad/param norm = 1.8834e-01, time/batch = 0.6467s	
4742/29850 (epoch 7.943), train_loss = 1.33855017, grad/param norm = 1.6876e-01, time/batch = 0.6442s	
4743/29850 (epoch 7.945), train_loss = 1.49919445, grad/param norm = 1.8376e-01, time/batch = 0.6456s	
4744/29850 (epoch 7.946), train_loss = 1.31128155, grad/param norm = 1.8144e-01, time/batch = 0.6439s	
4745/29850 (epoch 7.948), train_loss = 1.36969834, grad/param norm = 1.6219e-01, time/batch = 0.6439s	
4746/29850 (epoch 7.950), train_loss = 1.34029100, grad/param norm = 1.7244e-01, time/batch = 0.6484s	
4747/29850 (epoch 7.951), train_loss = 1.30148992, grad/param norm = 1.5842e-01, time/batch = 0.6545s	
4748/29850 (epoch 7.953), train_loss = 1.44702878, grad/param norm = 1.7628e-01, time/batch = 0.6520s	
4749/29850 (epoch 7.955), train_loss = 1.24393542, grad/param norm = 1.6140e-01, time/batch = 0.6523s	
4750/29850 (epoch 7.956), train_loss = 1.29512105, grad/param norm = 1.7622e-01, time/batch = 0.6533s	
4751/29850 (epoch 7.958), train_loss = 1.16614322, grad/param norm = 1.6320e-01, time/batch = 0.6553s	
4752/29850 (epoch 7.960), train_loss = 1.48529980, grad/param norm = 1.8718e-01, time/batch = 0.6518s	
4753/29850 (epoch 7.961), train_loss = 1.36022383, grad/param norm = 1.6401e-01, time/batch = 0.6491s	
4754/29850 (epoch 7.963), train_loss = 1.26062315, grad/param norm = 1.7150e-01, time/batch = 0.6547s	
4755/29850 (epoch 7.965), train_loss = 1.40316836, grad/param norm = 1.8231e-01, time/batch = 0.6570s	
4756/29850 (epoch 7.966), train_loss = 1.25624261, grad/param norm = 1.6520e-01, time/batch = 0.6513s	
4757/29850 (epoch 7.968), train_loss = 1.40488351, grad/param norm = 1.8409e-01, time/batch = 0.6670s	
4758/29850 (epoch 7.970), train_loss = 1.28638071, grad/param norm = 1.7006e-01, time/batch = 0.6676s	
4759/29850 (epoch 7.972), train_loss = 1.31371417, grad/param norm = 1.6520e-01, time/batch = 0.6487s	
4760/29850 (epoch 7.973), train_loss = 1.34251886, grad/param norm = 1.8282e-01, time/batch = 0.6553s	
4761/29850 (epoch 7.975), train_loss = 1.15996003, grad/param norm = 1.6340e-01, time/batch = 0.6607s	
4762/29850 (epoch 7.977), train_loss = 1.34278495, grad/param norm = 1.6837e-01, time/batch = 0.6717s	
4763/29850 (epoch 7.978), train_loss = 1.29478163, grad/param norm = 1.6458e-01, time/batch = 0.6756s	
4764/29850 (epoch 7.980), train_loss = 1.29531396, grad/param norm = 1.5651e-01, time/batch = 0.6580s	
4765/29850 (epoch 7.982), train_loss = 1.32853898, grad/param norm = 1.7612e-01, time/batch = 0.6542s	
4766/29850 (epoch 7.983), train_loss = 1.38366721, grad/param norm = 1.7089e-01, time/batch = 0.6559s	
4767/29850 (epoch 7.985), train_loss = 1.46449417, grad/param norm = 1.8565e-01, time/batch = 0.6530s	
4768/29850 (epoch 7.987), train_loss = 1.32312074, grad/param norm = 1.7305e-01, time/batch = 0.6580s	
4769/29850 (epoch 7.988), train_loss = 1.25937501, grad/param norm = 1.5733e-01, time/batch = 0.6405s	
4770/29850 (epoch 7.990), train_loss = 1.35865671, grad/param norm = 1.7292e-01, time/batch = 0.6383s	
4771/29850 (epoch 7.992), train_loss = 1.38533406, grad/param norm = 1.6866e-01, time/batch = 0.6439s	
4772/29850 (epoch 7.993), train_loss = 1.41961047, grad/param norm = 1.9135e-01, time/batch = 0.6477s	
4773/29850 (epoch 7.995), train_loss = 1.42591411, grad/param norm = 2.0399e-01, time/batch = 0.6716s	
4774/29850 (epoch 7.997), train_loss = 1.41646521, grad/param norm = 1.7723e-01, time/batch = 0.6577s	
4775/29850 (epoch 7.998), train_loss = 1.48379615, grad/param norm = 1.8676e-01, time/batch = 0.6556s	
4776/29850 (epoch 8.000), train_loss = 1.35830958, grad/param norm = 1.6399e-01, time/batch = 0.6429s	
4777/29850 (epoch 8.002), train_loss = 1.58794297, grad/param norm = 1.8434e-01, time/batch = 0.6432s	
4778/29850 (epoch 8.003), train_loss = 1.35543955, grad/param norm = 1.7816e-01, time/batch = 0.6503s	
4779/29850 (epoch 8.005), train_loss = 1.39389772, grad/param norm = 1.8220e-01, time/batch = 0.6443s	
4780/29850 (epoch 8.007), train_loss = 1.45143591, grad/param norm = 1.8556e-01, time/batch = 0.6480s	
4781/29850 (epoch 8.008), train_loss = 1.58096042, grad/param norm = 1.8633e-01, time/batch = 0.6509s	
4782/29850 (epoch 8.010), train_loss = 1.25579377, grad/param norm = 1.6858e-01, time/batch = 0.6482s	
4783/29850 (epoch 8.012), train_loss = 1.46999885, grad/param norm = 1.7351e-01, time/batch = 0.6441s	
4784/29850 (epoch 8.013), train_loss = 1.50997716, grad/param norm = 1.9834e-01, time/batch = 0.6493s	
4785/29850 (epoch 8.015), train_loss = 1.45144958, grad/param norm = 1.7979e-01, time/batch = 0.6429s	
4786/29850 (epoch 8.017), train_loss = 1.56532236, grad/param norm = 2.0596e-01, time/batch = 0.6493s	
4787/29850 (epoch 8.018), train_loss = 1.59071888, grad/param norm = 2.1226e-01, time/batch = 0.6536s	
4788/29850 (epoch 8.020), train_loss = 1.32050875, grad/param norm = 1.7111e-01, time/batch = 0.6564s	
4789/29850 (epoch 8.022), train_loss = 1.51604969, grad/param norm = 2.0363e-01, time/batch = 0.6655s	
4790/29850 (epoch 8.023), train_loss = 1.39765769, grad/param norm = 1.6849e-01, time/batch = 0.6690s	
4791/29850 (epoch 8.025), train_loss = 1.36763789, grad/param norm = 1.6274e-01, time/batch = 0.6453s	
4792/29850 (epoch 8.027), train_loss = 1.25914679, grad/param norm = 1.5455e-01, time/batch = 0.6435s	
4793/29850 (epoch 8.028), train_loss = 1.36566240, grad/param norm = 1.7051e-01, time/batch = 0.6446s	
4794/29850 (epoch 8.030), train_loss = 1.47261641, grad/param norm = 1.6607e-01, time/batch = 0.6455s	
4795/29850 (epoch 8.032), train_loss = 1.34963380, grad/param norm = 1.6742e-01, time/batch = 0.6448s	
4796/29850 (epoch 8.034), train_loss = 1.42375859, grad/param norm = 1.9023e-01, time/batch = 0.6446s	
4797/29850 (epoch 8.035), train_loss = 1.29186141, grad/param norm = 1.6356e-01, time/batch = 0.6435s	
4798/29850 (epoch 8.037), train_loss = 1.46561213, grad/param norm = 1.8955e-01, time/batch = 0.6447s	
4799/29850 (epoch 8.039), train_loss = 1.24942523, grad/param norm = 1.5151e-01, time/batch = 0.6435s	
4800/29850 (epoch 8.040), train_loss = 1.25993882, grad/param norm = 1.7147e-01, time/batch = 0.6437s	
4801/29850 (epoch 8.042), train_loss = 1.34046602, grad/param norm = 1.7042e-01, time/batch = 0.6494s	
4802/29850 (epoch 8.044), train_loss = 1.28909952, grad/param norm = 1.6788e-01, time/batch = 0.6426s	
4803/29850 (epoch 8.045), train_loss = 1.43353606, grad/param norm = 1.7429e-01, time/batch = 0.6462s	
4804/29850 (epoch 8.047), train_loss = 1.23718543, grad/param norm = 1.7132e-01, time/batch = 0.6448s	
4805/29850 (epoch 8.049), train_loss = 1.42185489, grad/param norm = 1.7485e-01, time/batch = 0.6487s	
4806/29850 (epoch 8.050), train_loss = 1.29195652, grad/param norm = 1.6765e-01, time/batch = 0.6452s	
4807/29850 (epoch 8.052), train_loss = 1.64416174, grad/param norm = 1.9831e-01, time/batch = 0.6464s	
4808/29850 (epoch 8.054), train_loss = 1.43300265, grad/param norm = 1.8426e-01, time/batch = 0.6456s	
4809/29850 (epoch 8.055), train_loss = 1.39742743, grad/param norm = 1.8519e-01, time/batch = 0.6494s	
4810/29850 (epoch 8.057), train_loss = 1.41456437, grad/param norm = 1.7732e-01, time/batch = 0.6550s	
4811/29850 (epoch 8.059), train_loss = 1.49271384, grad/param norm = 1.8888e-01, time/batch = 0.6584s	
4812/29850 (epoch 8.060), train_loss = 1.39524925, grad/param norm = 2.0171e-01, time/batch = 0.6573s	
4813/29850 (epoch 8.062), train_loss = 1.53729905, grad/param norm = 2.0603e-01, time/batch = 0.6543s	
4814/29850 (epoch 8.064), train_loss = 1.44937124, grad/param norm = 1.8156e-01, time/batch = 0.6527s	
4815/29850 (epoch 8.065), train_loss = 1.27651788, grad/param norm = 1.7551e-01, time/batch = 0.6639s	
4816/29850 (epoch 8.067), train_loss = 1.40506214, grad/param norm = 1.7033e-01, time/batch = 0.6459s	
4817/29850 (epoch 8.069), train_loss = 1.36174904, grad/param norm = 1.7327e-01, time/batch = 0.6455s	
4818/29850 (epoch 8.070), train_loss = 1.40718631, grad/param norm = 1.6514e-01, time/batch = 0.6402s	
4819/29850 (epoch 8.072), train_loss = 1.52628271, grad/param norm = 2.0288e-01, time/batch = 0.6627s	
4820/29850 (epoch 8.074), train_loss = 1.47281652, grad/param norm = 1.7782e-01, time/batch = 0.6424s	
4821/29850 (epoch 8.075), train_loss = 1.29614902, grad/param norm = 1.7438e-01, time/batch = 0.6559s	
4822/29850 (epoch 8.077), train_loss = 1.38522220, grad/param norm = 1.8650e-01, time/batch = 0.6611s	
4823/29850 (epoch 8.079), train_loss = 1.62278179, grad/param norm = 1.8455e-01, time/batch = 0.6501s	
4824/29850 (epoch 8.080), train_loss = 1.55276894, grad/param norm = 1.9233e-01, time/batch = 0.6445s	
4825/29850 (epoch 8.082), train_loss = 1.39892234, grad/param norm = 1.5867e-01, time/batch = 0.6434s	
4826/29850 (epoch 8.084), train_loss = 1.48418577, grad/param norm = 1.8694e-01, time/batch = 0.6453s	
4827/29850 (epoch 8.085), train_loss = 1.40809281, grad/param norm = 1.8192e-01, time/batch = 0.6430s	
4828/29850 (epoch 8.087), train_loss = 1.54661567, grad/param norm = 1.8546e-01, time/batch = 0.6417s	
4829/29850 (epoch 8.089), train_loss = 1.47603584, grad/param norm = 1.8368e-01, time/batch = 0.6426s	
4830/29850 (epoch 8.090), train_loss = 1.47367123, grad/param norm = 1.8486e-01, time/batch = 0.6411s	
4831/29850 (epoch 8.092), train_loss = 1.34737870, grad/param norm = 1.6641e-01, time/batch = 0.6456s	
4832/29850 (epoch 8.094), train_loss = 1.42080605, grad/param norm = 1.7268e-01, time/batch = 0.6433s	
4833/29850 (epoch 8.095), train_loss = 1.44540679, grad/param norm = 1.6342e-01, time/batch = 0.6449s	
4834/29850 (epoch 8.097), train_loss = 1.22056117, grad/param norm = 1.5788e-01, time/batch = 0.6455s	
4835/29850 (epoch 8.099), train_loss = 1.26236514, grad/param norm = 1.6099e-01, time/batch = 0.6439s	
4836/29850 (epoch 8.101), train_loss = 1.53087705, grad/param norm = 1.8635e-01, time/batch = 0.6421s	
4837/29850 (epoch 8.102), train_loss = 1.44964016, grad/param norm = 1.8289e-01, time/batch = 0.6704s	
4838/29850 (epoch 8.104), train_loss = 1.35898437, grad/param norm = 1.5962e-01, time/batch = 0.6558s	
4839/29850 (epoch 8.106), train_loss = 1.48904533, grad/param norm = 1.7436e-01, time/batch = 0.6435s	
4840/29850 (epoch 8.107), train_loss = 1.26644167, grad/param norm = 1.6137e-01, time/batch = 0.6392s	
4841/29850 (epoch 8.109), train_loss = 1.33749768, grad/param norm = 1.6221e-01, time/batch = 0.6469s	
4842/29850 (epoch 8.111), train_loss = 1.50583088, grad/param norm = 1.8834e-01, time/batch = 0.6482s	
4843/29850 (epoch 8.112), train_loss = 1.29772270, grad/param norm = 1.7065e-01, time/batch = 0.6527s	
4844/29850 (epoch 8.114), train_loss = 1.48596273, grad/param norm = 2.0145e-01, time/batch = 0.6467s	
4845/29850 (epoch 8.116), train_loss = 1.31796621, grad/param norm = 1.7678e-01, time/batch = 0.6435s	
4846/29850 (epoch 8.117), train_loss = 1.42310762, grad/param norm = 1.7364e-01, time/batch = 0.6401s	
4847/29850 (epoch 8.119), train_loss = 1.39126514, grad/param norm = 1.6243e-01, time/batch = 0.6503s	
4848/29850 (epoch 8.121), train_loss = 1.20606691, grad/param norm = 1.7085e-01, time/batch = 0.6703s	
4849/29850 (epoch 8.122), train_loss = 1.24997425, grad/param norm = 1.5676e-01, time/batch = 0.6511s	
4850/29850 (epoch 8.124), train_loss = 1.33391335, grad/param norm = 1.7382e-01, time/batch = 0.6432s	
4851/29850 (epoch 8.126), train_loss = 1.38240200, grad/param norm = 1.8491e-01, time/batch = 0.6515s	
4852/29850 (epoch 8.127), train_loss = 1.59822996, grad/param norm = 2.0231e-01, time/batch = 0.6437s	
4853/29850 (epoch 8.129), train_loss = 1.35754819, grad/param norm = 1.7410e-01, time/batch = 0.6658s	
4854/29850 (epoch 8.131), train_loss = 1.36934206, grad/param norm = 1.8576e-01, time/batch = 0.6713s	
4855/29850 (epoch 8.132), train_loss = 1.30180049, grad/param norm = 1.7430e-01, time/batch = 0.6751s	
4856/29850 (epoch 8.134), train_loss = 1.49134521, grad/param norm = 1.7711e-01, time/batch = 0.6579s	
4857/29850 (epoch 8.136), train_loss = 1.45333138, grad/param norm = 1.7692e-01, time/batch = 0.6513s	
4858/29850 (epoch 8.137), train_loss = 1.34567136, grad/param norm = 1.8052e-01, time/batch = 0.6491s	
4859/29850 (epoch 8.139), train_loss = 1.34116929, grad/param norm = 1.7536e-01, time/batch = 0.6458s	
4860/29850 (epoch 8.141), train_loss = 1.39001038, grad/param norm = 1.8370e-01, time/batch = 0.6456s	
4861/29850 (epoch 8.142), train_loss = 1.49266130, grad/param norm = 1.9845e-01, time/batch = 0.6512s	
4862/29850 (epoch 8.144), train_loss = 1.64905969, grad/param norm = 1.8892e-01, time/batch = 0.6517s	
4863/29850 (epoch 8.146), train_loss = 1.60980263, grad/param norm = 2.0178e-01, time/batch = 0.6381s	
4864/29850 (epoch 8.147), train_loss = 1.51663165, grad/param norm = 1.9429e-01, time/batch = 0.6428s	
4865/29850 (epoch 8.149), train_loss = 1.48757255, grad/param norm = 1.8119e-01, time/batch = 0.6428s	
4866/29850 (epoch 8.151), train_loss = 1.43163777, grad/param norm = 1.8466e-01, time/batch = 0.6466s	
4867/29850 (epoch 8.152), train_loss = 1.32416306, grad/param norm = 1.7090e-01, time/batch = 0.6698s	
4868/29850 (epoch 8.154), train_loss = 1.33275186, grad/param norm = 1.6757e-01, time/batch = 0.6530s	
4869/29850 (epoch 8.156), train_loss = 1.31159295, grad/param norm = 1.5796e-01, time/batch = 0.6691s	
4870/29850 (epoch 8.157), train_loss = 1.37972752, grad/param norm = 1.6098e-01, time/batch = 0.6595s	
4871/29850 (epoch 8.159), train_loss = 1.42643372, grad/param norm = 1.6915e-01, time/batch = 0.6544s	
4872/29850 (epoch 8.161), train_loss = 1.46300697, grad/param norm = 1.9264e-01, time/batch = 0.6444s	
4873/29850 (epoch 8.162), train_loss = 1.55784159, grad/param norm = 1.8277e-01, time/batch = 0.6408s	
4874/29850 (epoch 8.164), train_loss = 1.41065919, grad/param norm = 1.8269e-01, time/batch = 0.6444s	
4875/29850 (epoch 8.166), train_loss = 1.25797738, grad/param norm = 1.5311e-01, time/batch = 0.6465s	
4876/29850 (epoch 8.168), train_loss = 1.18647539, grad/param norm = 1.5889e-01, time/batch = 0.6421s	
4877/29850 (epoch 8.169), train_loss = 1.58482771, grad/param norm = 1.9384e-01, time/batch = 0.6396s	
4878/29850 (epoch 8.171), train_loss = 1.54455024, grad/param norm = 1.8503e-01, time/batch = 0.6508s	
4879/29850 (epoch 8.173), train_loss = 1.41436199, grad/param norm = 1.8759e-01, time/batch = 0.6628s	
4880/29850 (epoch 8.174), train_loss = 1.51845390, grad/param norm = 1.9356e-01, time/batch = 0.6623s	
4881/29850 (epoch 8.176), train_loss = 1.44971860, grad/param norm = 1.8354e-01, time/batch = 0.6468s	
4882/29850 (epoch 8.178), train_loss = 1.45293601, grad/param norm = 1.7502e-01, time/batch = 0.6485s	
4883/29850 (epoch 8.179), train_loss = 1.20724633, grad/param norm = 1.6688e-01, time/batch = 0.6435s	
4884/29850 (epoch 8.181), train_loss = 1.36146144, grad/param norm = 1.6492e-01, time/batch = 0.6418s	
4885/29850 (epoch 8.183), train_loss = 1.35913105, grad/param norm = 1.7745e-01, time/batch = 0.6415s	
4886/29850 (epoch 8.184), train_loss = 1.35702967, grad/param norm = 1.8253e-01, time/batch = 0.6418s	
4887/29850 (epoch 8.186), train_loss = 1.34527719, grad/param norm = 1.7054e-01, time/batch = 0.6424s	
4888/29850 (epoch 8.188), train_loss = 1.45824495, grad/param norm = 1.8945e-01, time/batch = 0.6400s	
4889/29850 (epoch 8.189), train_loss = 1.58152773, grad/param norm = 1.8505e-01, time/batch = 0.6576s	
4890/29850 (epoch 8.191), train_loss = 1.44888743, grad/param norm = 1.8087e-01, time/batch = 0.6469s	
4891/29850 (epoch 8.193), train_loss = 1.26016978, grad/param norm = 1.6265e-01, time/batch = 0.6453s	
4892/29850 (epoch 8.194), train_loss = 1.45177345, grad/param norm = 2.0017e-01, time/batch = 0.6474s	
4893/29850 (epoch 8.196), train_loss = 1.37952318, grad/param norm = 1.7926e-01, time/batch = 0.6476s	
4894/29850 (epoch 8.198), train_loss = 1.36097246, grad/param norm = 1.7021e-01, time/batch = 0.6491s	
4895/29850 (epoch 8.199), train_loss = 1.66232428, grad/param norm = 1.9940e-01, time/batch = 0.6472s	
4896/29850 (epoch 8.201), train_loss = 1.38771297, grad/param norm = 1.8110e-01, time/batch = 0.6424s	
4897/29850 (epoch 8.203), train_loss = 1.37255564, grad/param norm = 1.8307e-01, time/batch = 0.6471s	
4898/29850 (epoch 8.204), train_loss = 1.44838715, grad/param norm = 1.9184e-01, time/batch = 0.6469s	
4899/29850 (epoch 8.206), train_loss = 1.31804789, grad/param norm = 1.7796e-01, time/batch = 0.6485s	
4900/29850 (epoch 8.208), train_loss = 1.62726964, grad/param norm = 1.8454e-01, time/batch = 0.6446s	
4901/29850 (epoch 8.209), train_loss = 1.32022529, grad/param norm = 1.7337e-01, time/batch = 0.6662s	
4902/29850 (epoch 8.211), train_loss = 1.34194148, grad/param norm = 1.6835e-01, time/batch = 0.6665s	
4903/29850 (epoch 8.213), train_loss = 1.57686419, grad/param norm = 1.9098e-01, time/batch = 0.6503s	
4904/29850 (epoch 8.214), train_loss = 1.30141976, grad/param norm = 1.5207e-01, time/batch = 0.6442s	
4905/29850 (epoch 8.216), train_loss = 1.39352240, grad/param norm = 1.8543e-01, time/batch = 0.6466s	
4906/29850 (epoch 8.218), train_loss = 1.49380492, grad/param norm = 1.7856e-01, time/batch = 0.6507s	
4907/29850 (epoch 8.219), train_loss = 1.62266415, grad/param norm = 2.1013e-01, time/batch = 0.6448s	
4908/29850 (epoch 8.221), train_loss = 1.39293561, grad/param norm = 1.9912e-01, time/batch = 0.6418s	
4909/29850 (epoch 8.223), train_loss = 1.41889447, grad/param norm = 1.8486e-01, time/batch = 0.6421s	
4910/29850 (epoch 8.224), train_loss = 1.28755597, grad/param norm = 1.7257e-01, time/batch = 0.6402s	
4911/29850 (epoch 8.226), train_loss = 1.32113602, grad/param norm = 1.7745e-01, time/batch = 0.6716s	
4912/29850 (epoch 8.228), train_loss = 1.33288164, grad/param norm = 1.6240e-01, time/batch = 0.6610s	
4913/29850 (epoch 8.229), train_loss = 1.23517465, grad/param norm = 1.6892e-01, time/batch = 0.6606s	
4914/29850 (epoch 8.231), train_loss = 1.30798987, grad/param norm = 1.6154e-01, time/batch = 0.6725s	
4915/29850 (epoch 8.233), train_loss = 1.38136138, grad/param norm = 1.7527e-01, time/batch = 0.6661s	
4916/29850 (epoch 8.235), train_loss = 1.29186094, grad/param norm = 1.4648e-01, time/batch = 0.6775s	
4917/29850 (epoch 8.236), train_loss = 1.56625715, grad/param norm = 1.9210e-01, time/batch = 0.6671s	
4918/29850 (epoch 8.238), train_loss = 1.23712745, grad/param norm = 1.8309e-01, time/batch = 0.6651s	
4919/29850 (epoch 8.240), train_loss = 1.36763809, grad/param norm = 1.6737e-01, time/batch = 0.6755s	
4920/29850 (epoch 8.241), train_loss = 1.57626104, grad/param norm = 1.9540e-01, time/batch = 0.6654s	
4921/29850 (epoch 8.243), train_loss = 1.36438743, grad/param norm = 1.7757e-01, time/batch = 0.6641s	
4922/29850 (epoch 8.245), train_loss = 1.35539002, grad/param norm = 1.8442e-01, time/batch = 0.6673s	
4923/29850 (epoch 8.246), train_loss = 1.31637935, grad/param norm = 1.7556e-01, time/batch = 0.6647s	
4924/29850 (epoch 8.248), train_loss = 1.34078856, grad/param norm = 1.7490e-01, time/batch = 0.6637s	
4925/29850 (epoch 8.250), train_loss = 1.42232126, grad/param norm = 1.6513e-01, time/batch = 0.6635s	
4926/29850 (epoch 8.251), train_loss = 1.28896394, grad/param norm = 1.7542e-01, time/batch = 0.6677s	
4927/29850 (epoch 8.253), train_loss = 1.30527347, grad/param norm = 1.7709e-01, time/batch = 0.6566s	
4928/29850 (epoch 8.255), train_loss = 1.30953971, grad/param norm = 1.6945e-01, time/batch = 0.6700s	
4929/29850 (epoch 8.256), train_loss = 1.40221324, grad/param norm = 1.8196e-01, time/batch = 0.6725s	
4930/29850 (epoch 8.258), train_loss = 1.36767064, grad/param norm = 1.6832e-01, time/batch = 0.6680s	
4931/29850 (epoch 8.260), train_loss = 1.33596464, grad/param norm = 1.6690e-01, time/batch = 0.6722s	
4932/29850 (epoch 8.261), train_loss = 1.31022437, grad/param norm = 1.5944e-01, time/batch = 0.6624s	
4933/29850 (epoch 8.263), train_loss = 1.24342322, grad/param norm = 1.7431e-01, time/batch = 0.6625s	
4934/29850 (epoch 8.265), train_loss = 1.33335416, grad/param norm = 1.8185e-01, time/batch = 0.6553s	
4935/29850 (epoch 8.266), train_loss = 1.35998244, grad/param norm = 1.8271e-01, time/batch = 0.6590s	
4936/29850 (epoch 8.268), train_loss = 1.32072511, grad/param norm = 1.6497e-01, time/batch = 0.6560s	
4937/29850 (epoch 8.270), train_loss = 1.29283075, grad/param norm = 1.6830e-01, time/batch = 0.6535s	
4938/29850 (epoch 8.271), train_loss = 1.47631626, grad/param norm = 1.8485e-01, time/batch = 0.6604s	
4939/29850 (epoch 8.273), train_loss = 1.24043281, grad/param norm = 1.6950e-01, time/batch = 0.6541s	
4940/29850 (epoch 8.275), train_loss = 1.29438586, grad/param norm = 1.7674e-01, time/batch = 0.6557s	
4941/29850 (epoch 8.276), train_loss = 1.26932521, grad/param norm = 1.6329e-01, time/batch = 0.6564s	
4942/29850 (epoch 8.278), train_loss = 1.34212079, grad/param norm = 1.7108e-01, time/batch = 0.6557s	
4943/29850 (epoch 8.280), train_loss = 1.48524689, grad/param norm = 1.8417e-01, time/batch = 0.6590s	
4944/29850 (epoch 8.281), train_loss = 1.34702762, grad/param norm = 1.7989e-01, time/batch = 0.6707s	
4945/29850 (epoch 8.283), train_loss = 1.46335083, grad/param norm = 1.8491e-01, time/batch = 0.6807s	
4946/29850 (epoch 8.285), train_loss = 1.33443215, grad/param norm = 1.7185e-01, time/batch = 0.6797s	
4947/29850 (epoch 8.286), train_loss = 1.38986595, grad/param norm = 1.6989e-01, time/batch = 0.6895s	
4948/29850 (epoch 8.288), train_loss = 1.54453491, grad/param norm = 2.2181e-01, time/batch = 0.6599s	
4949/29850 (epoch 8.290), train_loss = 1.31252034, grad/param norm = 1.8316e-01, time/batch = 0.6883s	
4950/29850 (epoch 8.291), train_loss = 1.64956715, grad/param norm = 1.8809e-01, time/batch = 0.6797s	
4951/29850 (epoch 8.293), train_loss = 1.47430683, grad/param norm = 1.7640e-01, time/batch = 0.6828s	
4952/29850 (epoch 8.295), train_loss = 1.55553961, grad/param norm = 1.9463e-01, time/batch = 0.6554s	
4953/29850 (epoch 8.296), train_loss = 1.29848814, grad/param norm = 1.6026e-01, time/batch = 0.6615s	
4954/29850 (epoch 8.298), train_loss = 1.16567245, grad/param norm = 1.6603e-01, time/batch = 0.6830s	
4955/29850 (epoch 8.300), train_loss = 1.23214935, grad/param norm = 1.5262e-01, time/batch = 0.6722s	
4956/29850 (epoch 8.302), train_loss = 1.22717887, grad/param norm = 1.5913e-01, time/batch = 0.6576s	
4957/29850 (epoch 8.303), train_loss = 1.34952621, grad/param norm = 1.7698e-01, time/batch = 0.6533s	
4958/29850 (epoch 8.305), train_loss = 1.31837732, grad/param norm = 1.6234e-01, time/batch = 0.6562s	
4959/29850 (epoch 8.307), train_loss = 1.47466718, grad/param norm = 1.8376e-01, time/batch = 0.6601s	
4960/29850 (epoch 8.308), train_loss = 1.39725672, grad/param norm = 1.8199e-01, time/batch = 0.6605s	
4961/29850 (epoch 8.310), train_loss = 1.41640474, grad/param norm = 1.8187e-01, time/batch = 0.6578s	
4962/29850 (epoch 8.312), train_loss = 1.45000752, grad/param norm = 1.8467e-01, time/batch = 0.6617s	
4963/29850 (epoch 8.313), train_loss = 1.44306168, grad/param norm = 1.8229e-01, time/batch = 0.6624s	
4964/29850 (epoch 8.315), train_loss = 1.39460054, grad/param norm = 1.5720e-01, time/batch = 0.6735s	
4965/29850 (epoch 8.317), train_loss = 1.43041925, grad/param norm = 1.9378e-01, time/batch = 0.6843s	
4966/29850 (epoch 8.318), train_loss = 1.41996504, grad/param norm = 1.8434e-01, time/batch = 0.6750s	
4967/29850 (epoch 8.320), train_loss = 1.26764125, grad/param norm = 1.6834e-01, time/batch = 0.6681s	
4968/29850 (epoch 8.322), train_loss = 1.51913656, grad/param norm = 1.8536e-01, time/batch = 0.6677s	
4969/29850 (epoch 8.323), train_loss = 1.40111249, grad/param norm = 1.8941e-01, time/batch = 0.6648s	
4970/29850 (epoch 8.325), train_loss = 1.37704181, grad/param norm = 1.7834e-01, time/batch = 0.6732s	
4971/29850 (epoch 8.327), train_loss = 1.53347956, grad/param norm = 1.9949e-01, time/batch = 0.6785s	
4972/29850 (epoch 8.328), train_loss = 1.53368075, grad/param norm = 1.8052e-01, time/batch = 0.6586s	
4973/29850 (epoch 8.330), train_loss = 1.36383349, grad/param norm = 1.6959e-01, time/batch = 0.6557s	
4974/29850 (epoch 8.332), train_loss = 1.28066451, grad/param norm = 1.6631e-01, time/batch = 0.6555s	
4975/29850 (epoch 8.333), train_loss = 1.54553090, grad/param norm = 1.8289e-01, time/batch = 0.6518s	
4976/29850 (epoch 8.335), train_loss = 1.41952886, grad/param norm = 1.7749e-01, time/batch = 0.6569s	
4977/29850 (epoch 8.337), train_loss = 1.41235633, grad/param norm = 1.7716e-01, time/batch = 0.6559s	
4978/29850 (epoch 8.338), train_loss = 1.37805655, grad/param norm = 1.6749e-01, time/batch = 0.6591s	
4979/29850 (epoch 8.340), train_loss = 1.26729946, grad/param norm = 1.6723e-01, time/batch = 0.6650s	
4980/29850 (epoch 8.342), train_loss = 1.42884089, grad/param norm = 1.8436e-01, time/batch = 0.6529s	
4981/29850 (epoch 8.343), train_loss = 1.43798668, grad/param norm = 1.9121e-01, time/batch = 0.6567s	
4982/29850 (epoch 8.345), train_loss = 1.49473112, grad/param norm = 1.7990e-01, time/batch = 0.6568s	
4983/29850 (epoch 8.347), train_loss = 1.46865660, grad/param norm = 1.8152e-01, time/batch = 0.6545s	
4984/29850 (epoch 8.348), train_loss = 1.37008675, grad/param norm = 1.7088e-01, time/batch = 0.6527s	
4985/29850 (epoch 8.350), train_loss = 1.48355914, grad/param norm = 1.8311e-01, time/batch = 0.6703s	
4986/29850 (epoch 8.352), train_loss = 1.40759836, grad/param norm = 1.7278e-01, time/batch = 0.6777s	
4987/29850 (epoch 8.353), train_loss = 1.43425143, grad/param norm = 1.7896e-01, time/batch = 0.6666s	
4988/29850 (epoch 8.355), train_loss = 1.25296807, grad/param norm = 1.7380e-01, time/batch = 0.6651s	
4989/29850 (epoch 8.357), train_loss = 1.52569690, grad/param norm = 1.7053e-01, time/batch = 0.6541s	
4990/29850 (epoch 8.358), train_loss = 1.23590523, grad/param norm = 1.5960e-01, time/batch = 0.6564s	
4991/29850 (epoch 8.360), train_loss = 1.37560345, grad/param norm = 1.6840e-01, time/batch = 0.6607s	
4992/29850 (epoch 8.362), train_loss = 1.35371682, grad/param norm = 1.7096e-01, time/batch = 0.6560s	
4993/29850 (epoch 8.363), train_loss = 1.38635037, grad/param norm = 1.7481e-01, time/batch = 0.6596s	
4994/29850 (epoch 8.365), train_loss = 1.54601221, grad/param norm = 2.0425e-01, time/batch = 0.6549s	
4995/29850 (epoch 8.367), train_loss = 1.33343525, grad/param norm = 1.6578e-01, time/batch = 0.6589s	
4996/29850 (epoch 8.369), train_loss = 1.30049545, grad/param norm = 1.8302e-01, time/batch = 0.6620s	
4997/29850 (epoch 8.370), train_loss = 1.19291562, grad/param norm = 1.6826e-01, time/batch = 0.6571s	
4998/29850 (epoch 8.372), train_loss = 1.56101828, grad/param norm = 1.9276e-01, time/batch = 0.6593s	
4999/29850 (epoch 8.374), train_loss = 1.34606921, grad/param norm = 1.9056e-01, time/batch = 0.6613s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch8.38_1.6520.t7	
5000/29850 (epoch 8.375), train_loss = 1.35435932, grad/param norm = 1.6920e-01, time/batch = 0.6620s	
5001/29850 (epoch 8.377), train_loss = 1.66594682, grad/param norm = 2.0339e-01, time/batch = 0.6664s	
5002/29850 (epoch 8.379), train_loss = 1.47932937, grad/param norm = 1.8721e-01, time/batch = 0.6598s	
5003/29850 (epoch 8.380), train_loss = 1.42505216, grad/param norm = 1.8361e-01, time/batch = 0.6574s	
5004/29850 (epoch 8.382), train_loss = 1.45298639, grad/param norm = 1.7410e-01, time/batch = 0.6661s	
5005/29850 (epoch 8.384), train_loss = 1.38211165, grad/param norm = 1.8180e-01, time/batch = 0.6637s	
5006/29850 (epoch 8.385), train_loss = 1.39494349, grad/param norm = 1.7089e-01, time/batch = 0.6522s	
5007/29850 (epoch 8.387), train_loss = 1.44311549, grad/param norm = 1.9976e-01, time/batch = 0.6529s	
5008/29850 (epoch 8.389), train_loss = 1.53706186, grad/param norm = 1.7328e-01, time/batch = 0.6527s	
5009/29850 (epoch 8.390), train_loss = 1.41473386, grad/param norm = 1.7514e-01, time/batch = 0.6501s	
5010/29850 (epoch 8.392), train_loss = 1.37652748, grad/param norm = 1.8166e-01, time/batch = 0.6534s	
5011/29850 (epoch 8.394), train_loss = 1.48705098, grad/param norm = 1.8409e-01, time/batch = 0.6548s	
5012/29850 (epoch 8.395), train_loss = 1.44360467, grad/param norm = 1.9848e-01, time/batch = 0.6568s	
5013/29850 (epoch 8.397), train_loss = 1.40461147, grad/param norm = 1.8220e-01, time/batch = 0.6546s	
5014/29850 (epoch 8.399), train_loss = 1.28462282, grad/param norm = 1.6929e-01, time/batch = 0.6516s	
5015/29850 (epoch 8.400), train_loss = 1.64190543, grad/param norm = 2.1865e-01, time/batch = 0.6531s	
5016/29850 (epoch 8.402), train_loss = 1.51352459, grad/param norm = 1.8744e-01, time/batch = 0.6572s	
5017/29850 (epoch 8.404), train_loss = 1.46819594, grad/param norm = 1.7460e-01, time/batch = 0.6721s	
5018/29850 (epoch 8.405), train_loss = 1.47202008, grad/param norm = 1.8858e-01, time/batch = 0.6629s	
5019/29850 (epoch 8.407), train_loss = 1.38372840, grad/param norm = 1.9113e-01, time/batch = 0.6523s	
5020/29850 (epoch 8.409), train_loss = 1.60614038, grad/param norm = 2.0254e-01, time/batch = 0.6514s	
5021/29850 (epoch 8.410), train_loss = 1.54960834, grad/param norm = 1.7516e-01, time/batch = 0.6546s	
5022/29850 (epoch 8.412), train_loss = 1.40677294, grad/param norm = 1.8189e-01, time/batch = 0.6546s	
5023/29850 (epoch 8.414), train_loss = 1.43516180, grad/param norm = 1.8854e-01, time/batch = 0.6553s	
5024/29850 (epoch 8.415), train_loss = 1.39500673, grad/param norm = 1.6563e-01, time/batch = 0.6566s	
5025/29850 (epoch 8.417), train_loss = 1.56740624, grad/param norm = 1.9431e-01, time/batch = 0.6573s	
5026/29850 (epoch 8.419), train_loss = 1.43789390, grad/param norm = 1.9873e-01, time/batch = 0.6754s	
5027/29850 (epoch 8.420), train_loss = 1.37608286, grad/param norm = 1.6486e-01, time/batch = 0.6793s	
5028/29850 (epoch 8.422), train_loss = 1.35005896, grad/param norm = 1.7310e-01, time/batch = 0.6816s	
5029/29850 (epoch 8.424), train_loss = 1.43350296, grad/param norm = 1.8263e-01, time/batch = 0.6623s	
5030/29850 (epoch 8.425), train_loss = 1.66465287, grad/param norm = 1.8498e-01, time/batch = 0.6641s	
5031/29850 (epoch 8.427), train_loss = 1.27030011, grad/param norm = 1.7837e-01, time/batch = 0.6666s	
5032/29850 (epoch 8.429), train_loss = 1.29243167, grad/param norm = 1.7300e-01, time/batch = 0.6731s	
5033/29850 (epoch 8.430), train_loss = 1.20972435, grad/param norm = 1.6152e-01, time/batch = 0.6843s	
5034/29850 (epoch 8.432), train_loss = 1.37538306, grad/param norm = 1.7938e-01, time/batch = 0.6720s	
5035/29850 (epoch 8.434), train_loss = 1.31049652, grad/param norm = 1.7087e-01, time/batch = 0.6706s	
5036/29850 (epoch 8.436), train_loss = 1.44825737, grad/param norm = 1.8217e-01, time/batch = 0.6703s	
5037/29850 (epoch 8.437), train_loss = 1.42441540, grad/param norm = 1.6916e-01, time/batch = 0.6881s	
5038/29850 (epoch 8.439), train_loss = 1.42379034, grad/param norm = 1.7690e-01, time/batch = 0.6814s	
5039/29850 (epoch 8.441), train_loss = 1.44196599, grad/param norm = 1.9008e-01, time/batch = 0.6680s	
5040/29850 (epoch 8.442), train_loss = 1.43758375, grad/param norm = 1.8118e-01, time/batch = 0.6667s	
5041/29850 (epoch 8.444), train_loss = 1.36920306, grad/param norm = 1.5816e-01, time/batch = 0.6533s	
5042/29850 (epoch 8.446), train_loss = 1.42703643, grad/param norm = 1.7378e-01, time/batch = 0.6544s	
5043/29850 (epoch 8.447), train_loss = 1.51200849, grad/param norm = 1.9574e-01, time/batch = 0.6516s	
5044/29850 (epoch 8.449), train_loss = 1.51881192, grad/param norm = 1.8046e-01, time/batch = 0.6534s	
5045/29850 (epoch 8.451), train_loss = 1.31679364, grad/param norm = 1.7058e-01, time/batch = 0.6581s	
5046/29850 (epoch 8.452), train_loss = 1.14137403, grad/param norm = 1.5016e-01, time/batch = 0.6591s	
5047/29850 (epoch 8.454), train_loss = 1.29028048, grad/param norm = 1.6011e-01, time/batch = 0.6553s	
5048/29850 (epoch 8.456), train_loss = 1.48147943, grad/param norm = 1.8845e-01, time/batch = 0.6584s	
5049/29850 (epoch 8.457), train_loss = 1.54531409, grad/param norm = 2.0984e-01, time/batch = 0.6592s	
5050/29850 (epoch 8.459), train_loss = 1.58844484, grad/param norm = 1.9609e-01, time/batch = 0.6525s	
5051/29850 (epoch 8.461), train_loss = 1.57398098, grad/param norm = 1.7027e-01, time/batch = 0.6797s	
5052/29850 (epoch 8.462), train_loss = 1.48128909, grad/param norm = 1.9461e-01, time/batch = 0.6748s	
5053/29850 (epoch 8.464), train_loss = 1.42090642, grad/param norm = 1.7105e-01, time/batch = 0.6687s	
5054/29850 (epoch 8.466), train_loss = 1.27780216, grad/param norm = 1.7210e-01, time/batch = 0.6664s	
5055/29850 (epoch 8.467), train_loss = 1.43946273, grad/param norm = 1.7472e-01, time/batch = 0.6689s	
5056/29850 (epoch 8.469), train_loss = 1.40385762, grad/param norm = 1.6398e-01, time/batch = 0.6576s	
5057/29850 (epoch 8.471), train_loss = 1.39186429, grad/param norm = 1.6198e-01, time/batch = 0.6619s	
5058/29850 (epoch 8.472), train_loss = 1.30824748, grad/param norm = 1.7332e-01, time/batch = 0.6605s	
5059/29850 (epoch 8.474), train_loss = 1.56631727, grad/param norm = 1.7864e-01, time/batch = 0.6652s	
5060/29850 (epoch 8.476), train_loss = 1.46043381, grad/param norm = 1.8584e-01, time/batch = 0.6598s	
5061/29850 (epoch 8.477), train_loss = 1.46106156, grad/param norm = 1.7653e-01, time/batch = 0.6589s	
5062/29850 (epoch 8.479), train_loss = 1.49456334, grad/param norm = 1.8457e-01, time/batch = 0.6574s	
5063/29850 (epoch 8.481), train_loss = 1.47968792, grad/param norm = 1.8622e-01, time/batch = 0.6545s	
5064/29850 (epoch 8.482), train_loss = 1.31580674, grad/param norm = 1.5702e-01, time/batch = 0.6578s	
5065/29850 (epoch 8.484), train_loss = 1.37543578, grad/param norm = 1.7215e-01, time/batch = 0.6567s	
5066/29850 (epoch 8.486), train_loss = 1.40248353, grad/param norm = 1.7724e-01, time/batch = 0.6576s	
5067/29850 (epoch 8.487), train_loss = 1.37200738, grad/param norm = 1.8592e-01, time/batch = 0.6536s	
5068/29850 (epoch 8.489), train_loss = 1.42300108, grad/param norm = 1.7730e-01, time/batch = 0.6553s	
5069/29850 (epoch 8.491), train_loss = 1.26075102, grad/param norm = 1.6167e-01, time/batch = 0.6562s	
5070/29850 (epoch 8.492), train_loss = 1.48002334, grad/param norm = 1.7774e-01, time/batch = 0.6581s	
5071/29850 (epoch 8.494), train_loss = 1.56967632, grad/param norm = 1.6812e-01, time/batch = 0.6577s	
5072/29850 (epoch 8.496), train_loss = 1.57518133, grad/param norm = 1.7443e-01, time/batch = 0.6588s	
5073/29850 (epoch 8.497), train_loss = 1.42833046, grad/param norm = 1.7266e-01, time/batch = 0.6549s	
5074/29850 (epoch 8.499), train_loss = 1.42534776, grad/param norm = 1.7131e-01, time/batch = 0.6566s	
5075/29850 (epoch 8.501), train_loss = 1.33538159, grad/param norm = 1.6722e-01, time/batch = 0.6608s	
5076/29850 (epoch 8.503), train_loss = 1.38304603, grad/param norm = 1.7473e-01, time/batch = 0.6711s	
5077/29850 (epoch 8.504), train_loss = 1.58971065, grad/param norm = 1.8610e-01, time/batch = 0.6706s	
5078/29850 (epoch 8.506), train_loss = 1.64116932, grad/param norm = 1.9343e-01, time/batch = 0.6630s	
5079/29850 (epoch 8.508), train_loss = 1.37818747, grad/param norm = 1.7206e-01, time/batch = 0.6691s	
5080/29850 (epoch 8.509), train_loss = 1.21206110, grad/param norm = 1.6633e-01, time/batch = 0.6587s	
5081/29850 (epoch 8.511), train_loss = 1.38150868, grad/param norm = 1.6851e-01, time/batch = 0.6602s	
5082/29850 (epoch 8.513), train_loss = 1.49296211, grad/param norm = 1.9449e-01, time/batch = 0.6575s	
5083/29850 (epoch 8.514), train_loss = 1.27450566, grad/param norm = 1.6526e-01, time/batch = 0.6637s	
5084/29850 (epoch 8.516), train_loss = 1.26513386, grad/param norm = 1.6181e-01, time/batch = 0.6558s	
5085/29850 (epoch 8.518), train_loss = 1.25590719, grad/param norm = 1.6491e-01, time/batch = 0.6622s	
5086/29850 (epoch 8.519), train_loss = 1.25737765, grad/param norm = 1.6579e-01, time/batch = 0.6575s	
5087/29850 (epoch 8.521), train_loss = 1.29665627, grad/param norm = 1.5535e-01, time/batch = 0.6591s	
5088/29850 (epoch 8.523), train_loss = 1.23838992, grad/param norm = 1.5024e-01, time/batch = 0.6600s	
5089/29850 (epoch 8.524), train_loss = 1.40468677, grad/param norm = 1.8565e-01, time/batch = 0.6550s	
5090/29850 (epoch 8.526), train_loss = 1.47378448, grad/param norm = 1.8203e-01, time/batch = 0.6562s	
5091/29850 (epoch 8.528), train_loss = 1.57169543, grad/param norm = 1.9620e-01, time/batch = 0.6603s	
5092/29850 (epoch 8.529), train_loss = 1.52090380, grad/param norm = 1.9264e-01, time/batch = 0.6606s	
5093/29850 (epoch 8.531), train_loss = 1.43759901, grad/param norm = 1.9396e-01, time/batch = 0.6639s	
5094/29850 (epoch 8.533), train_loss = 1.32807343, grad/param norm = 1.8465e-01, time/batch = 0.6580s	
5095/29850 (epoch 8.534), train_loss = 1.39162325, grad/param norm = 1.8018e-01, time/batch = 0.6552s	
5096/29850 (epoch 8.536), train_loss = 1.39763612, grad/param norm = 1.7936e-01, time/batch = 0.6536s	
5097/29850 (epoch 8.538), train_loss = 1.47802744, grad/param norm = 1.7435e-01, time/batch = 0.6815s	
5098/29850 (epoch 8.539), train_loss = 1.50441774, grad/param norm = 1.8170e-01, time/batch = 0.6686s	
5099/29850 (epoch 8.541), train_loss = 1.23662238, grad/param norm = 1.6399e-01, time/batch = 0.6516s	
5100/29850 (epoch 8.543), train_loss = 1.37228174, grad/param norm = 1.6534e-01, time/batch = 0.6522s	
5101/29850 (epoch 8.544), train_loss = 1.41091974, grad/param norm = 1.7803e-01, time/batch = 0.6538s	
5102/29850 (epoch 8.546), train_loss = 1.49213217, grad/param norm = 1.7662e-01, time/batch = 0.6533s	
5103/29850 (epoch 8.548), train_loss = 1.28742929, grad/param norm = 1.6524e-01, time/batch = 0.6580s	
5104/29850 (epoch 8.549), train_loss = 1.35088547, grad/param norm = 1.5858e-01, time/batch = 0.6565s	
5105/29850 (epoch 8.551), train_loss = 1.31582956, grad/param norm = 1.8093e-01, time/batch = 0.6637s	
5106/29850 (epoch 8.553), train_loss = 1.42714689, grad/param norm = 1.8236e-01, time/batch = 0.6673s	
5107/29850 (epoch 8.554), train_loss = 1.17239478, grad/param norm = 1.5387e-01, time/batch = 0.6637s	
5108/29850 (epoch 8.556), train_loss = 1.38979756, grad/param norm = 1.8100e-01, time/batch = 0.6538s	
5109/29850 (epoch 8.558), train_loss = 1.34902959, grad/param norm = 1.7614e-01, time/batch = 0.6535s	
5110/29850 (epoch 8.559), train_loss = 1.45892816, grad/param norm = 1.8624e-01, time/batch = 0.6548s	
5111/29850 (epoch 8.561), train_loss = 1.46700670, grad/param norm = 1.7736e-01, time/batch = 0.6559s	
5112/29850 (epoch 8.563), train_loss = 1.37416230, grad/param norm = 1.6738e-01, time/batch = 0.6587s	
5113/29850 (epoch 8.564), train_loss = 1.36584228, grad/param norm = 1.6645e-01, time/batch = 0.6590s	
5114/29850 (epoch 8.566), train_loss = 1.34142337, grad/param norm = 1.6786e-01, time/batch = 0.6680s	
5115/29850 (epoch 8.568), train_loss = 1.46408500, grad/param norm = 1.6442e-01, time/batch = 0.6652s	
5116/29850 (epoch 8.570), train_loss = 1.40681820, grad/param norm = 1.7529e-01, time/batch = 0.6763s	
5117/29850 (epoch 8.571), train_loss = 1.44817297, grad/param norm = 1.7086e-01, time/batch = 0.7055s	
5118/29850 (epoch 8.573), train_loss = 1.56706887, grad/param norm = 1.9647e-01, time/batch = 0.6861s	
5119/29850 (epoch 8.575), train_loss = 1.50848943, grad/param norm = 1.7731e-01, time/batch = 0.6619s	
5120/29850 (epoch 8.576), train_loss = 1.56359926, grad/param norm = 1.8116e-01, time/batch = 0.6556s	
5121/29850 (epoch 8.578), train_loss = 1.45512677, grad/param norm = 1.7530e-01, time/batch = 0.6627s	
5122/29850 (epoch 8.580), train_loss = 1.48727827, grad/param norm = 1.8050e-01, time/batch = 0.6571s	
5123/29850 (epoch 8.581), train_loss = 1.34253082, grad/param norm = 1.7627e-01, time/batch = 0.6497s	
5124/29850 (epoch 8.583), train_loss = 1.38887680, grad/param norm = 1.7511e-01, time/batch = 0.6507s	
5125/29850 (epoch 8.585), train_loss = 1.39039268, grad/param norm = 1.6288e-01, time/batch = 0.6492s	
5126/29850 (epoch 8.586), train_loss = 1.42979009, grad/param norm = 1.7704e-01, time/batch = 0.6502s	
5127/29850 (epoch 8.588), train_loss = 1.34453719, grad/param norm = 1.7253e-01, time/batch = 0.6511s	
5128/29850 (epoch 8.590), train_loss = 1.41137023, grad/param norm = 1.7362e-01, time/batch = 0.6530s	
5129/29850 (epoch 8.591), train_loss = 1.32994163, grad/param norm = 1.6133e-01, time/batch = 0.6521s	
5130/29850 (epoch 8.593), train_loss = 1.32505965, grad/param norm = 1.6007e-01, time/batch = 0.6554s	
5131/29850 (epoch 8.595), train_loss = 1.28108602, grad/param norm = 1.5116e-01, time/batch = 0.6565s	
5132/29850 (epoch 8.596), train_loss = 1.25143364, grad/param norm = 1.6797e-01, time/batch = 0.6700s	
5133/29850 (epoch 8.598), train_loss = 1.27192743, grad/param norm = 1.6903e-01, time/batch = 0.6839s	
5134/29850 (epoch 8.600), train_loss = 1.50950489, grad/param norm = 1.9097e-01, time/batch = 0.6741s	
5135/29850 (epoch 8.601), train_loss = 1.27395916, grad/param norm = 1.5989e-01, time/batch = 0.6609s	
5136/29850 (epoch 8.603), train_loss = 1.39061609, grad/param norm = 1.6849e-01, time/batch = 0.6574s	
5137/29850 (epoch 8.605), train_loss = 1.42945504, grad/param norm = 1.7513e-01, time/batch = 0.6612s	
5138/29850 (epoch 8.606), train_loss = 1.19479504, grad/param norm = 1.7212e-01, time/batch = 0.6626s	
5139/29850 (epoch 8.608), train_loss = 1.39382808, grad/param norm = 1.7184e-01, time/batch = 0.6583s	
5140/29850 (epoch 8.610), train_loss = 1.36570535, grad/param norm = 1.7519e-01, time/batch = 0.6554s	
5141/29850 (epoch 8.611), train_loss = 1.18834202, grad/param norm = 1.5183e-01, time/batch = 0.6565s	
5142/29850 (epoch 8.613), train_loss = 1.15516971, grad/param norm = 1.5393e-01, time/batch = 0.6526s	
5143/29850 (epoch 8.615), train_loss = 1.21034822, grad/param norm = 1.5403e-01, time/batch = 0.6553s	
5144/29850 (epoch 8.616), train_loss = 1.36084196, grad/param norm = 1.8810e-01, time/batch = 0.6553s	
5145/29850 (epoch 8.618), train_loss = 1.39991898, grad/param norm = 1.7602e-01, time/batch = 0.6588s	
5146/29850 (epoch 8.620), train_loss = 1.42877346, grad/param norm = 1.7453e-01, time/batch = 0.6599s	
5147/29850 (epoch 8.621), train_loss = 1.45284297, grad/param norm = 1.9098e-01, time/batch = 0.6547s	
5148/29850 (epoch 8.623), train_loss = 1.47320088, grad/param norm = 1.8412e-01, time/batch = 0.6600s	
5149/29850 (epoch 8.625), train_loss = 1.44851476, grad/param norm = 1.8242e-01, time/batch = 0.6550s	
5150/29850 (epoch 8.626), train_loss = 1.47737335, grad/param norm = 1.8620e-01, time/batch = 0.6533s	
5151/29850 (epoch 8.628), train_loss = 1.24085420, grad/param norm = 1.6737e-01, time/batch = 0.6602s	
5152/29850 (epoch 8.630), train_loss = 1.39223555, grad/param norm = 1.8173e-01, time/batch = 0.6705s	
5153/29850 (epoch 8.631), train_loss = 1.30090506, grad/param norm = 1.6371e-01, time/batch = 0.6781s	
5154/29850 (epoch 8.633), train_loss = 1.47991614, grad/param norm = 1.8992e-01, time/batch = 0.6588s	
5155/29850 (epoch 8.635), train_loss = 1.40121635, grad/param norm = 1.9167e-01, time/batch = 0.6754s	
5156/29850 (epoch 8.637), train_loss = 1.42489165, grad/param norm = 1.8090e-01, time/batch = 0.6724s	
5157/29850 (epoch 8.638), train_loss = 1.30941610, grad/param norm = 1.6875e-01, time/batch = 0.6612s	
5158/29850 (epoch 8.640), train_loss = 1.55125535, grad/param norm = 1.9464e-01, time/batch = 0.6556s	
5159/29850 (epoch 8.642), train_loss = 1.38342279, grad/param norm = 1.8582e-01, time/batch = 0.6577s	
5160/29850 (epoch 8.643), train_loss = 1.30180007, grad/param norm = 1.6240e-01, time/batch = 0.6644s	
5161/29850 (epoch 8.645), train_loss = 1.41863865, grad/param norm = 1.7603e-01, time/batch = 0.6684s	
5162/29850 (epoch 8.647), train_loss = 1.51423056, grad/param norm = 1.7815e-01, time/batch = 0.6605s	
5163/29850 (epoch 8.648), train_loss = 1.25532275, grad/param norm = 1.5676e-01, time/batch = 0.6556s	
5164/29850 (epoch 8.650), train_loss = 1.35545484, grad/param norm = 1.8634e-01, time/batch = 0.6536s	
5165/29850 (epoch 8.652), train_loss = 1.38962278, grad/param norm = 1.7665e-01, time/batch = 0.6553s	
5166/29850 (epoch 8.653), train_loss = 1.48235484, grad/param norm = 1.7486e-01, time/batch = 0.6578s	
5167/29850 (epoch 8.655), train_loss = 1.36372408, grad/param norm = 1.6167e-01, time/batch = 0.6672s	
5168/29850 (epoch 8.657), train_loss = 1.33295580, grad/param norm = 1.6440e-01, time/batch = 0.6601s	
5169/29850 (epoch 8.658), train_loss = 1.48480248, grad/param norm = 1.7846e-01, time/batch = 0.6553s	
5170/29850 (epoch 8.660), train_loss = 1.31628755, grad/param norm = 1.7798e-01, time/batch = 0.6607s	
5171/29850 (epoch 8.662), train_loss = 1.38635924, grad/param norm = 1.7638e-01, time/batch = 0.6572s	
5172/29850 (epoch 8.663), train_loss = 1.49228667, grad/param norm = 1.9141e-01, time/batch = 0.6572s	
5173/29850 (epoch 8.665), train_loss = 1.44565260, grad/param norm = 1.9141e-01, time/batch = 0.6561s	
5174/29850 (epoch 8.667), train_loss = 1.47292537, grad/param norm = 2.0131e-01, time/batch = 0.6707s	
5175/29850 (epoch 8.668), train_loss = 1.39800595, grad/param norm = 1.6843e-01, time/batch = 0.6736s	
5176/29850 (epoch 8.670), train_loss = 1.64962545, grad/param norm = 1.9237e-01, time/batch = 0.6640s	
5177/29850 (epoch 8.672), train_loss = 1.45694561, grad/param norm = 1.9685e-01, time/batch = 0.6693s	
5178/29850 (epoch 8.673), train_loss = 1.47479468, grad/param norm = 1.8302e-01, time/batch = 0.6779s	
5179/29850 (epoch 8.675), train_loss = 1.37324054, grad/param norm = 1.6628e-01, time/batch = 0.6695s	
5180/29850 (epoch 8.677), train_loss = 1.37148375, grad/param norm = 1.7909e-01, time/batch = 0.6678s	
5181/29850 (epoch 8.678), train_loss = 1.35480789, grad/param norm = 1.8461e-01, time/batch = 0.6773s	
5182/29850 (epoch 8.680), train_loss = 1.43966048, grad/param norm = 1.7681e-01, time/batch = 0.6683s	
5183/29850 (epoch 8.682), train_loss = 1.36719485, grad/param norm = 1.6194e-01, time/batch = 0.6671s	
5184/29850 (epoch 8.683), train_loss = 1.56942580, grad/param norm = 2.0373e-01, time/batch = 0.6708s	
5185/29850 (epoch 8.685), train_loss = 1.52283247, grad/param norm = 1.5527e-01, time/batch = 0.6608s	
5186/29850 (epoch 8.687), train_loss = 1.46825205, grad/param norm = 1.8041e-01, time/batch = 0.6695s	
5187/29850 (epoch 8.688), train_loss = 1.24613371, grad/param norm = 1.4359e-01, time/batch = 0.6671s	
5188/29850 (epoch 8.690), train_loss = 1.29186266, grad/param norm = 1.7604e-01, time/batch = 0.6737s	
5189/29850 (epoch 8.692), train_loss = 1.55622355, grad/param norm = 1.8737e-01, time/batch = 0.6692s	
5190/29850 (epoch 8.693), train_loss = 1.37359905, grad/param norm = 1.6295e-01, time/batch = 0.6656s	
5191/29850 (epoch 8.695), train_loss = 1.23855549, grad/param norm = 1.6134e-01, time/batch = 0.6585s	
5192/29850 (epoch 8.697), train_loss = 1.45689053, grad/param norm = 1.8708e-01, time/batch = 0.6583s	
5193/29850 (epoch 8.698), train_loss = 1.48437878, grad/param norm = 1.8158e-01, time/batch = 0.6574s	
5194/29850 (epoch 8.700), train_loss = 1.46952179, grad/param norm = 2.0089e-01, time/batch = 0.6563s	
5195/29850 (epoch 8.702), train_loss = 1.36817061, grad/param norm = 1.8217e-01, time/batch = 0.6605s	
5196/29850 (epoch 8.704), train_loss = 1.30210993, grad/param norm = 1.6852e-01, time/batch = 0.6559s	
5197/29850 (epoch 8.705), train_loss = 1.39321021, grad/param norm = 1.6346e-01, time/batch = 0.6608s	
5198/29850 (epoch 8.707), train_loss = 1.37705077, grad/param norm = 1.8249e-01, time/batch = 0.6609s	
5199/29850 (epoch 8.709), train_loss = 1.49951629, grad/param norm = 1.9150e-01, time/batch = 0.6682s	
5200/29850 (epoch 8.710), train_loss = 1.37681680, grad/param norm = 1.7937e-01, time/batch = 0.6642s	
5201/29850 (epoch 8.712), train_loss = 1.40395856, grad/param norm = 1.7380e-01, time/batch = 0.6577s	
5202/29850 (epoch 8.714), train_loss = 1.44433013, grad/param norm = 1.8363e-01, time/batch = 0.6617s	
5203/29850 (epoch 8.715), train_loss = 1.47091817, grad/param norm = 1.8277e-01, time/batch = 0.6557s	
5204/29850 (epoch 8.717), train_loss = 1.23734629, grad/param norm = 1.6789e-01, time/batch = 0.6564s	
5205/29850 (epoch 8.719), train_loss = 1.36071544, grad/param norm = 1.7754e-01, time/batch = 0.6565s	
5206/29850 (epoch 8.720), train_loss = 1.39143655, grad/param norm = 1.6360e-01, time/batch = 0.6681s	
5207/29850 (epoch 8.722), train_loss = 1.28569175, grad/param norm = 1.6511e-01, time/batch = 0.6830s	
5208/29850 (epoch 8.724), train_loss = 1.44758548, grad/param norm = 1.8113e-01, time/batch = 0.6891s	
5209/29850 (epoch 8.725), train_loss = 1.27047753, grad/param norm = 1.6039e-01, time/batch = 0.6626s	
5210/29850 (epoch 8.727), train_loss = 1.35505957, grad/param norm = 1.8732e-01, time/batch = 0.6563s	
5211/29850 (epoch 8.729), train_loss = 1.21824987, grad/param norm = 1.7085e-01, time/batch = 0.6830s	
5212/29850 (epoch 8.730), train_loss = 1.24698295, grad/param norm = 1.6238e-01, time/batch = 0.6706s	
5213/29850 (epoch 8.732), train_loss = 1.40457536, grad/param norm = 1.6787e-01, time/batch = 0.6737s	
5214/29850 (epoch 8.734), train_loss = 1.58293531, grad/param norm = 1.9216e-01, time/batch = 0.6584s	
5215/29850 (epoch 8.735), train_loss = 1.42085746, grad/param norm = 1.8953e-01, time/batch = 0.6522s	
5216/29850 (epoch 8.737), train_loss = 1.27460198, grad/param norm = 1.7410e-01, time/batch = 0.6540s	
5217/29850 (epoch 8.739), train_loss = 1.25250101, grad/param norm = 1.6198e-01, time/batch = 0.6565s	
5218/29850 (epoch 8.740), train_loss = 1.27151676, grad/param norm = 1.7027e-01, time/batch = 0.6559s	
5219/29850 (epoch 8.742), train_loss = 1.25972662, grad/param norm = 1.6515e-01, time/batch = 0.6538s	
5220/29850 (epoch 8.744), train_loss = 1.39102990, grad/param norm = 1.9143e-01, time/batch = 0.6541s	
5221/29850 (epoch 8.745), train_loss = 1.37742807, grad/param norm = 1.9406e-01, time/batch = 0.6635s	
5222/29850 (epoch 8.747), train_loss = 1.32710099, grad/param norm = 1.8883e-01, time/batch = 0.6854s	
5223/29850 (epoch 8.749), train_loss = 1.27737480, grad/param norm = 1.7875e-01, time/batch = 0.6622s	
5224/29850 (epoch 8.750), train_loss = 1.36187971, grad/param norm = 1.8653e-01, time/batch = 0.6592s	
5225/29850 (epoch 8.752), train_loss = 1.28905394, grad/param norm = 1.6281e-01, time/batch = 0.6586s	
5226/29850 (epoch 8.754), train_loss = 1.28705874, grad/param norm = 1.7873e-01, time/batch = 0.6543s	
5227/29850 (epoch 8.755), train_loss = 1.35417192, grad/param norm = 1.7695e-01, time/batch = 0.6627s	
5228/29850 (epoch 8.757), train_loss = 1.33139055, grad/param norm = 1.6437e-01, time/batch = 0.6607s	
5229/29850 (epoch 8.759), train_loss = 1.37998390, grad/param norm = 1.6129e-01, time/batch = 0.6616s	
5230/29850 (epoch 8.760), train_loss = 1.26618921, grad/param norm = 1.7518e-01, time/batch = 0.6592s	
5231/29850 (epoch 8.762), train_loss = 1.26993232, grad/param norm = 1.7539e-01, time/batch = 0.6621s	
5232/29850 (epoch 8.764), train_loss = 1.29673223, grad/param norm = 1.8792e-01, time/batch = 0.6744s	
5233/29850 (epoch 8.765), train_loss = 1.32599335, grad/param norm = 1.8478e-01, time/batch = 0.6768s	
5234/29850 (epoch 8.767), train_loss = 1.36943048, grad/param norm = 1.7089e-01, time/batch = 0.6603s	
5235/29850 (epoch 8.769), train_loss = 1.31051787, grad/param norm = 1.7854e-01, time/batch = 0.6633s	
5236/29850 (epoch 8.771), train_loss = 1.41739984, grad/param norm = 1.8700e-01, time/batch = 0.6680s	
5237/29850 (epoch 8.772), train_loss = 1.48079986, grad/param norm = 1.7902e-01, time/batch = 0.6605s	
5238/29850 (epoch 8.774), train_loss = 1.31556338, grad/param norm = 1.8219e-01, time/batch = 0.6620s	
5239/29850 (epoch 8.776), train_loss = 1.31875507, grad/param norm = 1.7808e-01, time/batch = 0.6656s	
5240/29850 (epoch 8.777), train_loss = 1.43348618, grad/param norm = 1.7930e-01, time/batch = 0.6620s	
5241/29850 (epoch 8.779), train_loss = 1.23237279, grad/param norm = 1.6214e-01, time/batch = 0.6687s	
5242/29850 (epoch 8.781), train_loss = 1.32080413, grad/param norm = 1.7207e-01, time/batch = 0.6636s	
5243/29850 (epoch 8.782), train_loss = 1.36420416, grad/param norm = 1.6499e-01, time/batch = 0.6698s	
5244/29850 (epoch 8.784), train_loss = 1.30163326, grad/param norm = 1.7956e-01, time/batch = 0.6653s	
5245/29850 (epoch 8.786), train_loss = 1.32194161, grad/param norm = 1.7258e-01, time/batch = 0.6562s	
5246/29850 (epoch 8.787), train_loss = 1.28527367, grad/param norm = 1.6691e-01, time/batch = 0.6530s	
5247/29850 (epoch 8.789), train_loss = 1.20245590, grad/param norm = 1.5014e-01, time/batch = 0.6561s	
5248/29850 (epoch 8.791), train_loss = 1.36906941, grad/param norm = 1.8293e-01, time/batch = 0.6625s	
5249/29850 (epoch 8.792), train_loss = 1.43217357, grad/param norm = 1.7864e-01, time/batch = 0.6600s	
5250/29850 (epoch 8.794), train_loss = 1.36934633, grad/param norm = 1.6484e-01, time/batch = 0.6746s	
5251/29850 (epoch 8.796), train_loss = 1.27839624, grad/param norm = 1.7700e-01, time/batch = 0.6592s	
5252/29850 (epoch 8.797), train_loss = 1.25086636, grad/param norm = 1.5699e-01, time/batch = 0.6528s	
5253/29850 (epoch 8.799), train_loss = 1.23796956, grad/param norm = 1.5912e-01, time/batch = 0.6605s	
5254/29850 (epoch 8.801), train_loss = 1.45068878, grad/param norm = 1.9404e-01, time/batch = 0.6563s	
5255/29850 (epoch 8.802), train_loss = 1.23210565, grad/param norm = 1.7890e-01, time/batch = 0.6592s	
5256/29850 (epoch 8.804), train_loss = 1.30335437, grad/param norm = 1.6201e-01, time/batch = 0.6566s	
5257/29850 (epoch 8.806), train_loss = 1.29000601, grad/param norm = 1.5929e-01, time/batch = 0.6690s	
5258/29850 (epoch 8.807), train_loss = 1.16154573, grad/param norm = 1.5184e-01, time/batch = 0.6650s	
5259/29850 (epoch 8.809), train_loss = 1.36967455, grad/param norm = 1.9314e-01, time/batch = 0.6777s	
5260/29850 (epoch 8.811), train_loss = 1.46361626, grad/param norm = 1.8573e-01, time/batch = 0.6722s	
5261/29850 (epoch 8.812), train_loss = 1.37949765, grad/param norm = 1.8434e-01, time/batch = 0.6636s	
5262/29850 (epoch 8.814), train_loss = 1.44133070, grad/param norm = 1.9242e-01, time/batch = 0.6676s	
5263/29850 (epoch 8.816), train_loss = 1.42630725, grad/param norm = 1.6937e-01, time/batch = 0.6634s	
5264/29850 (epoch 8.817), train_loss = 1.38332645, grad/param norm = 1.7033e-01, time/batch = 0.6587s	
5265/29850 (epoch 8.819), train_loss = 1.30507653, grad/param norm = 1.7822e-01, time/batch = 0.6587s	
5266/29850 (epoch 8.821), train_loss = 1.52788674, grad/param norm = 1.9706e-01, time/batch = 0.6561s	
5267/29850 (epoch 8.822), train_loss = 1.36715284, grad/param norm = 1.6143e-01, time/batch = 0.6538s	
5268/29850 (epoch 8.824), train_loss = 1.33217355, grad/param norm = 1.8257e-01, time/batch = 0.6544s	
5269/29850 (epoch 8.826), train_loss = 1.33060218, grad/param norm = 1.7023e-01, time/batch = 0.6531s	
5270/29850 (epoch 8.827), train_loss = 1.28589589, grad/param norm = 1.7836e-01, time/batch = 0.6539s	
5271/29850 (epoch 8.829), train_loss = 1.41277860, grad/param norm = 2.0076e-01, time/batch = 0.6531s	
5272/29850 (epoch 8.831), train_loss = 1.39618620, grad/param norm = 1.8686e-01, time/batch = 0.6572s	
5273/29850 (epoch 8.832), train_loss = 1.27849586, grad/param norm = 1.6020e-01, time/batch = 0.6575s	
5274/29850 (epoch 8.834), train_loss = 1.25650391, grad/param norm = 1.8357e-01, time/batch = 0.6582s	
5275/29850 (epoch 8.836), train_loss = 1.23209007, grad/param norm = 1.6422e-01, time/batch = 0.6586s	
5276/29850 (epoch 8.838), train_loss = 1.39697038, grad/param norm = 1.7201e-01, time/batch = 0.6624s	
5277/29850 (epoch 8.839), train_loss = 1.31204848, grad/param norm = 1.7101e-01, time/batch = 0.6604s	
5278/29850 (epoch 8.841), train_loss = 1.32618124, grad/param norm = 1.6911e-01, time/batch = 0.6618s	
5279/29850 (epoch 8.843), train_loss = 1.31727199, grad/param norm = 1.6258e-01, time/batch = 0.6762s	
5280/29850 (epoch 8.844), train_loss = 1.32258041, grad/param norm = 1.7601e-01, time/batch = 0.6595s	
5281/29850 (epoch 8.846), train_loss = 1.40071605, grad/param norm = 2.1139e-01, time/batch = 0.6726s	
5282/29850 (epoch 8.848), train_loss = 1.42636978, grad/param norm = 1.9100e-01, time/batch = 0.6616s	
5283/29850 (epoch 8.849), train_loss = 1.25749011, grad/param norm = 1.7273e-01, time/batch = 0.6592s	
5284/29850 (epoch 8.851), train_loss = 1.43256375, grad/param norm = 1.9195e-01, time/batch = 0.6628s	
5285/29850 (epoch 8.853), train_loss = 1.33363097, grad/param norm = 1.9657e-01, time/batch = 0.6670s	
5286/29850 (epoch 8.854), train_loss = 1.42579858, grad/param norm = 1.8940e-01, time/batch = 0.6637s	
5287/29850 (epoch 8.856), train_loss = 1.42423341, grad/param norm = 1.9652e-01, time/batch = 0.6798s	
5288/29850 (epoch 8.858), train_loss = 1.34183351, grad/param norm = 1.8829e-01, time/batch = 0.6782s	
5289/29850 (epoch 8.859), train_loss = 1.29390453, grad/param norm = 1.9156e-01, time/batch = 0.6842s	
5290/29850 (epoch 8.861), train_loss = 1.46587358, grad/param norm = 1.8543e-01, time/batch = 0.6819s	
5291/29850 (epoch 8.863), train_loss = 1.47581781, grad/param norm = 1.6851e-01, time/batch = 0.6848s	
5292/29850 (epoch 8.864), train_loss = 1.40580191, grad/param norm = 1.8294e-01, time/batch = 0.6839s	
5293/29850 (epoch 8.866), train_loss = 1.37031027, grad/param norm = 1.8329e-01, time/batch = 0.6735s	
5294/29850 (epoch 8.868), train_loss = 1.47076458, grad/param norm = 1.7912e-01, time/batch = 0.6665s	
5295/29850 (epoch 8.869), train_loss = 1.28407996, grad/param norm = 1.7457e-01, time/batch = 0.6566s	
5296/29850 (epoch 8.871), train_loss = 1.35030271, grad/param norm = 1.7547e-01, time/batch = 0.6735s	
5297/29850 (epoch 8.873), train_loss = 1.41571451, grad/param norm = 1.7395e-01, time/batch = 0.6851s	
5298/29850 (epoch 8.874), train_loss = 1.40419252, grad/param norm = 1.7596e-01, time/batch = 0.6856s	
5299/29850 (epoch 8.876), train_loss = 1.40453090, grad/param norm = 1.9598e-01, time/batch = 0.6622s	
5300/29850 (epoch 8.878), train_loss = 1.36459178, grad/param norm = 1.7805e-01, time/batch = 0.6687s	
5301/29850 (epoch 8.879), train_loss = 1.43140398, grad/param norm = 1.7035e-01, time/batch = 0.6701s	
5302/29850 (epoch 8.881), train_loss = 1.45592632, grad/param norm = 1.7769e-01, time/batch = 0.6796s	
5303/29850 (epoch 8.883), train_loss = 1.46678505, grad/param norm = 1.9511e-01, time/batch = 0.6821s	
5304/29850 (epoch 8.884), train_loss = 1.25244705, grad/param norm = 1.7251e-01, time/batch = 0.6817s	
5305/29850 (epoch 8.886), train_loss = 1.55540208, grad/param norm = 1.8942e-01, time/batch = 0.6611s	
5306/29850 (epoch 8.888), train_loss = 1.33407930, grad/param norm = 1.7247e-01, time/batch = 0.6539s	
5307/29850 (epoch 8.889), train_loss = 1.32261568, grad/param norm = 1.8365e-01, time/batch = 0.6601s	
5308/29850 (epoch 8.891), train_loss = 1.33300588, grad/param norm = 1.8432e-01, time/batch = 0.6600s	
5309/29850 (epoch 8.893), train_loss = 1.24888201, grad/param norm = 1.6398e-01, time/batch = 0.6579s	
5310/29850 (epoch 8.894), train_loss = 1.30500315, grad/param norm = 1.6684e-01, time/batch = 0.6630s	
5311/29850 (epoch 8.896), train_loss = 1.30472255, grad/param norm = 1.7994e-01, time/batch = 0.6656s	
5312/29850 (epoch 8.898), train_loss = 1.49016132, grad/param norm = 2.0206e-01, time/batch = 0.6631s	
5313/29850 (epoch 8.899), train_loss = 1.20620603, grad/param norm = 1.7076e-01, time/batch = 0.6702s	
5314/29850 (epoch 8.901), train_loss = 1.73601714, grad/param norm = 2.2584e-01, time/batch = 0.6738s	
5315/29850 (epoch 8.903), train_loss = 1.38424384, grad/param norm = 2.1231e-01, time/batch = 0.6736s	
5316/29850 (epoch 8.905), train_loss = 1.50969224, grad/param norm = 1.6570e-01, time/batch = 0.6580s	
5317/29850 (epoch 8.906), train_loss = 1.26767743, grad/param norm = 1.7850e-01, time/batch = 0.6743s	
5318/29850 (epoch 8.908), train_loss = 1.46376231, grad/param norm = 1.7673e-01, time/batch = 0.6648s	
5319/29850 (epoch 8.910), train_loss = 1.44999171, grad/param norm = 1.8333e-01, time/batch = 0.6563s	
5320/29850 (epoch 8.911), train_loss = 1.51106860, grad/param norm = 1.9224e-01, time/batch = 0.6694s	
5321/29850 (epoch 8.913), train_loss = 1.39808257, grad/param norm = 1.8078e-01, time/batch = 0.6875s	
5322/29850 (epoch 8.915), train_loss = 1.44253102, grad/param norm = 1.9416e-01, time/batch = 0.6565s	
5323/29850 (epoch 8.916), train_loss = 1.39101617, grad/param norm = 1.7529e-01, time/batch = 0.6646s	
5324/29850 (epoch 8.918), train_loss = 1.30493043, grad/param norm = 1.5747e-01, time/batch = 0.6733s	
5325/29850 (epoch 8.920), train_loss = 1.43787749, grad/param norm = 1.6646e-01, time/batch = 0.6546s	
5326/29850 (epoch 8.921), train_loss = 1.43293052, grad/param norm = 1.9122e-01, time/batch = 0.6633s	
5327/29850 (epoch 8.923), train_loss = 1.42420747, grad/param norm = 1.7501e-01, time/batch = 0.6588s	
5328/29850 (epoch 8.925), train_loss = 1.51140279, grad/param norm = 1.8202e-01, time/batch = 0.6584s	
5329/29850 (epoch 8.926), train_loss = 1.54709553, grad/param norm = 1.8827e-01, time/batch = 0.6739s	
5330/29850 (epoch 8.928), train_loss = 1.37645461, grad/param norm = 1.8213e-01, time/batch = 0.6603s	
5331/29850 (epoch 8.930), train_loss = 1.49367020, grad/param norm = 1.8339e-01, time/batch = 0.6863s	
5332/29850 (epoch 8.931), train_loss = 1.45285117, grad/param norm = 1.8541e-01, time/batch = 0.6709s	
5333/29850 (epoch 8.933), train_loss = 1.53632933, grad/param norm = 1.8109e-01, time/batch = 0.6554s	
5334/29850 (epoch 8.935), train_loss = 1.50724479, grad/param norm = 1.8542e-01, time/batch = 0.6592s	
5335/29850 (epoch 8.936), train_loss = 1.47203976, grad/param norm = 1.8022e-01, time/batch = 0.6528s	
5336/29850 (epoch 8.938), train_loss = 1.25317210, grad/param norm = 1.6843e-01, time/batch = 0.6601s	
5337/29850 (epoch 8.940), train_loss = 1.21597465, grad/param norm = 1.6168e-01, time/batch = 0.6647s	
5338/29850 (epoch 8.941), train_loss = 1.33236476, grad/param norm = 1.8804e-01, time/batch = 0.6654s	
5339/29850 (epoch 8.943), train_loss = 1.28899764, grad/param norm = 1.6666e-01, time/batch = 0.6645s	
5340/29850 (epoch 8.945), train_loss = 1.44274806, grad/param norm = 1.8462e-01, time/batch = 0.6556s	
5341/29850 (epoch 8.946), train_loss = 1.25877406, grad/param norm = 1.7699e-01, time/batch = 0.6607s	
5342/29850 (epoch 8.948), train_loss = 1.32981555, grad/param norm = 1.6384e-01, time/batch = 0.6575s	
5343/29850 (epoch 8.950), train_loss = 1.28437712, grad/param norm = 1.6995e-01, time/batch = 0.6575s	
5344/29850 (epoch 8.951), train_loss = 1.24825180, grad/param norm = 1.5651e-01, time/batch = 0.6545s	
5345/29850 (epoch 8.953), train_loss = 1.38622601, grad/param norm = 1.7618e-01, time/batch = 0.6574s	
5346/29850 (epoch 8.955), train_loss = 1.19564909, grad/param norm = 1.5509e-01, time/batch = 0.6557s	
5347/29850 (epoch 8.956), train_loss = 1.25044832, grad/param norm = 1.8014e-01, time/batch = 0.6574s	
5348/29850 (epoch 8.958), train_loss = 1.11334219, grad/param norm = 1.6387e-01, time/batch = 0.6666s	
5349/29850 (epoch 8.960), train_loss = 1.43978054, grad/param norm = 1.8212e-01, time/batch = 0.6568s	
5350/29850 (epoch 8.961), train_loss = 1.30255654, grad/param norm = 1.6148e-01, time/batch = 0.6523s	
5351/29850 (epoch 8.963), train_loss = 1.20704996, grad/param norm = 1.6883e-01, time/batch = 0.6549s	
5352/29850 (epoch 8.965), train_loss = 1.34905514, grad/param norm = 1.8208e-01, time/batch = 0.6760s	
5353/29850 (epoch 8.966), train_loss = 1.20804128, grad/param norm = 1.6515e-01, time/batch = 0.6727s	
5354/29850 (epoch 8.968), train_loss = 1.35324136, grad/param norm = 1.8791e-01, time/batch = 0.6647s	
5355/29850 (epoch 8.970), train_loss = 1.23812890, grad/param norm = 1.7045e-01, time/batch = 0.6620s	
5356/29850 (epoch 8.972), train_loss = 1.26660405, grad/param norm = 1.6347e-01, time/batch = 0.6575s	
5357/29850 (epoch 8.973), train_loss = 1.27786362, grad/param norm = 1.7215e-01, time/batch = 0.6607s	
5358/29850 (epoch 8.975), train_loss = 1.12179879, grad/param norm = 1.5613e-01, time/batch = 0.6578s	
5359/29850 (epoch 8.977), train_loss = 1.29871696, grad/param norm = 1.6895e-01, time/batch = 0.6566s	
5360/29850 (epoch 8.978), train_loss = 1.24439490, grad/param norm = 1.6240e-01, time/batch = 0.6598s	
5361/29850 (epoch 8.980), train_loss = 1.25039366, grad/param norm = 1.5543e-01, time/batch = 0.6643s	
5362/29850 (epoch 8.982), train_loss = 1.28815936, grad/param norm = 1.7510e-01, time/batch = 0.6778s	
5363/29850 (epoch 8.983), train_loss = 1.32664216, grad/param norm = 1.6543e-01, time/batch = 0.6714s	
5364/29850 (epoch 8.985), train_loss = 1.41955793, grad/param norm = 1.8614e-01, time/batch = 0.6532s	
5365/29850 (epoch 8.987), train_loss = 1.28747048, grad/param norm = 1.6635e-01, time/batch = 0.6501s	
5366/29850 (epoch 8.988), train_loss = 1.21309121, grad/param norm = 1.5539e-01, time/batch = 0.6549s	
5367/29850 (epoch 8.990), train_loss = 1.31785743, grad/param norm = 1.7083e-01, time/batch = 0.6543s	
5368/29850 (epoch 8.992), train_loss = 1.33095581, grad/param norm = 1.6798e-01, time/batch = 0.6556s	
5369/29850 (epoch 8.993), train_loss = 1.35515516, grad/param norm = 1.8741e-01, time/batch = 0.6571s	
5370/29850 (epoch 8.995), train_loss = 1.37881911, grad/param norm = 1.9679e-01, time/batch = 0.6610s	
5371/29850 (epoch 8.997), train_loss = 1.35620794, grad/param norm = 1.7552e-01, time/batch = 0.6766s	
5372/29850 (epoch 8.998), train_loss = 1.43969510, grad/param norm = 1.8945e-01, time/batch = 0.6630s	
5373/29850 (epoch 9.000), train_loss = 1.30716082, grad/param norm = 1.6153e-01, time/batch = 0.6574s	
5374/29850 (epoch 9.002), train_loss = 1.54011919, grad/param norm = 1.8535e-01, time/batch = 0.6632s	
5375/29850 (epoch 9.003), train_loss = 1.31013979, grad/param norm = 1.7812e-01, time/batch = 0.6666s	
5376/29850 (epoch 9.005), train_loss = 1.35103165, grad/param norm = 1.7910e-01, time/batch = 0.6623s	
5377/29850 (epoch 9.007), train_loss = 1.38969211, grad/param norm = 1.7983e-01, time/batch = 0.6738s	
5378/29850 (epoch 9.008), train_loss = 1.54753046, grad/param norm = 1.8810e-01, time/batch = 0.6762s	
5379/29850 (epoch 9.010), train_loss = 1.21328508, grad/param norm = 1.7214e-01, time/batch = 0.6563s	
5380/29850 (epoch 9.012), train_loss = 1.40856255, grad/param norm = 1.7847e-01, time/batch = 0.6573s	
5381/29850 (epoch 9.013), train_loss = 1.46009915, grad/param norm = 1.9948e-01, time/batch = 0.6602s	
5382/29850 (epoch 9.015), train_loss = 1.40885845, grad/param norm = 1.7923e-01, time/batch = 0.6579s	
5383/29850 (epoch 9.017), train_loss = 1.51378609, grad/param norm = 2.0404e-01, time/batch = 0.6665s	
5384/29850 (epoch 9.018), train_loss = 1.53537388, grad/param norm = 2.0713e-01, time/batch = 0.6835s	
5385/29850 (epoch 9.020), train_loss = 1.28945529, grad/param norm = 1.7284e-01, time/batch = 0.6597s	
5386/29850 (epoch 9.022), train_loss = 1.47259671, grad/param norm = 1.9776e-01, time/batch = 0.6700s	
5387/29850 (epoch 9.023), train_loss = 1.35832571, grad/param norm = 1.6804e-01, time/batch = 0.6804s	
5388/29850 (epoch 9.025), train_loss = 1.32029234, grad/param norm = 1.6475e-01, time/batch = 0.6992s	
5389/29850 (epoch 9.027), train_loss = 1.21098533, grad/param norm = 1.5265e-01, time/batch = 0.6956s	
5390/29850 (epoch 9.028), train_loss = 1.30805425, grad/param norm = 1.6369e-01, time/batch = 0.6847s	
5391/29850 (epoch 9.030), train_loss = 1.41696432, grad/param norm = 1.6589e-01, time/batch = 0.6635s	
5392/29850 (epoch 9.032), train_loss = 1.30841299, grad/param norm = 1.6400e-01, time/batch = 0.6655s	
5393/29850 (epoch 9.034), train_loss = 1.33975679, grad/param norm = 1.8478e-01, time/batch = 0.6590s	
5394/29850 (epoch 9.035), train_loss = 1.22805503, grad/param norm = 1.5856e-01, time/batch = 0.6830s	
5395/29850 (epoch 9.037), train_loss = 1.41451584, grad/param norm = 1.8811e-01, time/batch = 0.6742s	
5396/29850 (epoch 9.039), train_loss = 1.19386151, grad/param norm = 1.4819e-01, time/batch = 0.6649s	
5397/29850 (epoch 9.040), train_loss = 1.22523808, grad/param norm = 1.7466e-01, time/batch = 0.6560s	
5398/29850 (epoch 9.042), train_loss = 1.29084102, grad/param norm = 1.7226e-01, time/batch = 0.6594s	
5399/29850 (epoch 9.044), train_loss = 1.25145271, grad/param norm = 1.6373e-01, time/batch = 0.6920s	
5400/29850 (epoch 9.045), train_loss = 1.38485145, grad/param norm = 1.7414e-01, time/batch = 0.6958s	
5401/29850 (epoch 9.047), train_loss = 1.19803175, grad/param norm = 1.7621e-01, time/batch = 0.6896s	
5402/29850 (epoch 9.049), train_loss = 1.37616624, grad/param norm = 1.7033e-01, time/batch = 0.6688s	
5403/29850 (epoch 9.050), train_loss = 1.24591094, grad/param norm = 1.6501e-01, time/batch = 0.6622s	
5404/29850 (epoch 9.052), train_loss = 1.58773409, grad/param norm = 1.9583e-01, time/batch = 0.6733s	
5405/29850 (epoch 9.054), train_loss = 1.39455468, grad/param norm = 1.8884e-01, time/batch = 0.6726s	
5406/29850 (epoch 9.055), train_loss = 1.34237742, grad/param norm = 1.8106e-01, time/batch = 0.6611s	
5407/29850 (epoch 9.057), train_loss = 1.38519914, grad/param norm = 1.7685e-01, time/batch = 0.6563s	
5408/29850 (epoch 9.059), train_loss = 1.44581345, grad/param norm = 1.8682e-01, time/batch = 0.6650s	
5409/29850 (epoch 9.060), train_loss = 1.35537557, grad/param norm = 1.8754e-01, time/batch = 0.6673s	
5410/29850 (epoch 9.062), train_loss = 1.48519401, grad/param norm = 1.9540e-01, time/batch = 0.6758s	
5411/29850 (epoch 9.064), train_loss = 1.41536045, grad/param norm = 1.8485e-01, time/batch = 0.6673s	
5412/29850 (epoch 9.065), train_loss = 1.23387593, grad/param norm = 1.7513e-01, time/batch = 0.6675s	
5413/29850 (epoch 9.067), train_loss = 1.36210483, grad/param norm = 1.6335e-01, time/batch = 0.6652s	
5414/29850 (epoch 9.069), train_loss = 1.32427410, grad/param norm = 1.7026e-01, time/batch = 0.6679s	
5415/29850 (epoch 9.070), train_loss = 1.36469477, grad/param norm = 1.6194e-01, time/batch = 0.6666s	
5416/29850 (epoch 9.072), train_loss = 1.46859630, grad/param norm = 2.0555e-01, time/batch = 0.6629s	
5417/29850 (epoch 9.074), train_loss = 1.42601769, grad/param norm = 1.7017e-01, time/batch = 0.6705s	
5418/29850 (epoch 9.075), train_loss = 1.25624390, grad/param norm = 1.7395e-01, time/batch = 0.6584s	
5419/29850 (epoch 9.077), train_loss = 1.34912125, grad/param norm = 1.9012e-01, time/batch = 0.6645s	
5420/29850 (epoch 9.079), train_loss = 1.58876088, grad/param norm = 1.8634e-01, time/batch = 0.6689s	
5421/29850 (epoch 9.080), train_loss = 1.50396758, grad/param norm = 1.9773e-01, time/batch = 0.6534s	
5422/29850 (epoch 9.082), train_loss = 1.36608172, grad/param norm = 1.5755e-01, time/batch = 0.6562s	
5423/29850 (epoch 9.084), train_loss = 1.44932788, grad/param norm = 1.8492e-01, time/batch = 0.6550s	
5424/29850 (epoch 9.085), train_loss = 1.37458847, grad/param norm = 1.8617e-01, time/batch = 0.6544s	
5425/29850 (epoch 9.087), train_loss = 1.51036481, grad/param norm = 1.8663e-01, time/batch = 0.6545s	
5426/29850 (epoch 9.089), train_loss = 1.43546212, grad/param norm = 1.8115e-01, time/batch = 0.6558s	
5427/29850 (epoch 9.090), train_loss = 1.43496426, grad/param norm = 1.8293e-01, time/batch = 0.6554s	
5428/29850 (epoch 9.092), train_loss = 1.31058218, grad/param norm = 1.6533e-01, time/batch = 0.6702s	
5429/29850 (epoch 9.094), train_loss = 1.39045728, grad/param norm = 1.7069e-01, time/batch = 0.6802s	
5430/29850 (epoch 9.095), train_loss = 1.40889164, grad/param norm = 1.6491e-01, time/batch = 0.6770s	
5431/29850 (epoch 9.097), train_loss = 1.18235940, grad/param norm = 1.5687e-01, time/batch = 0.6603s	
5432/29850 (epoch 9.099), train_loss = 1.21668607, grad/param norm = 1.5740e-01, time/batch = 0.6581s	
5433/29850 (epoch 9.101), train_loss = 1.48775380, grad/param norm = 1.8277e-01, time/batch = 0.6523s	
5434/29850 (epoch 9.102), train_loss = 1.41402258, grad/param norm = 1.8178e-01, time/batch = 0.6560s	
5435/29850 (epoch 9.104), train_loss = 1.32282501, grad/param norm = 1.6309e-01, time/batch = 0.6580s	
5436/29850 (epoch 9.106), train_loss = 1.44705685, grad/param norm = 1.7399e-01, time/batch = 0.6584s	
5437/29850 (epoch 9.107), train_loss = 1.21742801, grad/param norm = 1.6111e-01, time/batch = 0.6610s	
5438/29850 (epoch 9.109), train_loss = 1.30405518, grad/param norm = 1.6786e-01, time/batch = 0.6628s	
5439/29850 (epoch 9.111), train_loss = 1.45977953, grad/param norm = 1.8774e-01, time/batch = 0.6626s	
5440/29850 (epoch 9.112), train_loss = 1.26237029, grad/param norm = 1.7962e-01, time/batch = 0.6565s	
5441/29850 (epoch 9.114), train_loss = 1.42698855, grad/param norm = 1.9419e-01, time/batch = 0.6574s	
5442/29850 (epoch 9.116), train_loss = 1.27560613, grad/param norm = 1.7293e-01, time/batch = 0.6608s	
5443/29850 (epoch 9.117), train_loss = 1.36959264, grad/param norm = 1.7302e-01, time/batch = 0.6615s	
5444/29850 (epoch 9.119), train_loss = 1.34355498, grad/param norm = 1.6875e-01, time/batch = 0.6562s	
5445/29850 (epoch 9.121), train_loss = 1.16060186, grad/param norm = 1.6821e-01, time/batch = 0.6555s	
5446/29850 (epoch 9.122), train_loss = 1.20592926, grad/param norm = 1.5330e-01, time/batch = 0.6576s	
5447/29850 (epoch 9.124), train_loss = 1.29148988, grad/param norm = 1.7041e-01, time/batch = 0.6573s	
5448/29850 (epoch 9.126), train_loss = 1.33357759, grad/param norm = 1.8643e-01, time/batch = 0.6554s	
5449/29850 (epoch 9.127), train_loss = 1.54162359, grad/param norm = 1.9139e-01, time/batch = 0.6559s	
5450/29850 (epoch 9.129), train_loss = 1.30715440, grad/param norm = 1.7336e-01, time/batch = 0.6538s	
5451/29850 (epoch 9.131), train_loss = 1.32327119, grad/param norm = 1.8439e-01, time/batch = 0.6569s	
5452/29850 (epoch 9.132), train_loss = 1.24629796, grad/param norm = 1.6932e-01, time/batch = 0.6542s	
5453/29850 (epoch 9.134), train_loss = 1.44066672, grad/param norm = 1.7471e-01, time/batch = 0.6567s	
5454/29850 (epoch 9.136), train_loss = 1.40668032, grad/param norm = 1.7280e-01, time/batch = 0.6626s	
5455/29850 (epoch 9.137), train_loss = 1.27515539, grad/param norm = 1.7210e-01, time/batch = 0.6570s	
5456/29850 (epoch 9.139), train_loss = 1.27775347, grad/param norm = 1.7101e-01, time/batch = 0.6559s	
5457/29850 (epoch 9.141), train_loss = 1.33914171, grad/param norm = 1.7703e-01, time/batch = 0.6696s	
5458/29850 (epoch 9.142), train_loss = 1.43826988, grad/param norm = 1.9510e-01, time/batch = 0.6658s	
5459/29850 (epoch 9.144), train_loss = 1.59909805, grad/param norm = 1.9735e-01, time/batch = 0.6574s	
5460/29850 (epoch 9.146), train_loss = 1.56686489, grad/param norm = 2.0488e-01, time/batch = 0.6698s	
5461/29850 (epoch 9.147), train_loss = 1.47439298, grad/param norm = 1.9001e-01, time/batch = 0.6714s	
5462/29850 (epoch 9.149), train_loss = 1.45021106, grad/param norm = 1.7880e-01, time/batch = 0.6662s	
5463/29850 (epoch 9.151), train_loss = 1.39098030, grad/param norm = 1.8281e-01, time/batch = 0.6654s	
5464/29850 (epoch 9.152), train_loss = 1.28707168, grad/param norm = 1.7462e-01, time/batch = 0.6714s	
5465/29850 (epoch 9.154), train_loss = 1.28539477, grad/param norm = 1.6654e-01, time/batch = 0.6635s	
5466/29850 (epoch 9.156), train_loss = 1.27669319, grad/param norm = 1.6165e-01, time/batch = 0.6602s	
5467/29850 (epoch 9.157), train_loss = 1.32462873, grad/param norm = 1.5969e-01, time/batch = 0.6569s	
5468/29850 (epoch 9.159), train_loss = 1.37954247, grad/param norm = 1.6707e-01, time/batch = 0.6573s	
5469/29850 (epoch 9.161), train_loss = 1.41238735, grad/param norm = 1.9636e-01, time/batch = 0.6573s	
5470/29850 (epoch 9.162), train_loss = 1.52064745, grad/param norm = 1.8292e-01, time/batch = 0.6524s	
5471/29850 (epoch 9.164), train_loss = 1.36666148, grad/param norm = 1.8084e-01, time/batch = 0.6559s	
5472/29850 (epoch 9.166), train_loss = 1.21829943, grad/param norm = 1.5250e-01, time/batch = 0.6575s	
5473/29850 (epoch 9.168), train_loss = 1.14708311, grad/param norm = 1.5980e-01, time/batch = 0.6536s	
5474/29850 (epoch 9.169), train_loss = 1.53127534, grad/param norm = 1.8655e-01, time/batch = 0.6542s	
5475/29850 (epoch 9.171), train_loss = 1.49165928, grad/param norm = 1.8379e-01, time/batch = 0.6591s	
5476/29850 (epoch 9.173), train_loss = 1.36084879, grad/param norm = 1.8935e-01, time/batch = 0.6724s	
5477/29850 (epoch 9.174), train_loss = 1.46397093, grad/param norm = 1.9203e-01, time/batch = 0.6863s	
5478/29850 (epoch 9.176), train_loss = 1.41309650, grad/param norm = 1.8312e-01, time/batch = 0.6930s	
5479/29850 (epoch 9.178), train_loss = 1.40920634, grad/param norm = 1.7378e-01, time/batch = 0.6687s	
5480/29850 (epoch 9.179), train_loss = 1.16274493, grad/param norm = 1.6188e-01, time/batch = 0.6787s	
5481/29850 (epoch 9.181), train_loss = 1.32247793, grad/param norm = 1.5940e-01, time/batch = 0.6816s	
5482/29850 (epoch 9.183), train_loss = 1.31657412, grad/param norm = 1.7693e-01, time/batch = 0.6728s	
5483/29850 (epoch 9.184), train_loss = 1.31124013, grad/param norm = 1.8005e-01, time/batch = 0.6699s	
5484/29850 (epoch 9.186), train_loss = 1.29581045, grad/param norm = 1.6428e-01, time/batch = 0.6681s	
5485/29850 (epoch 9.188), train_loss = 1.41942931, grad/param norm = 1.8640e-01, time/batch = 0.6697s	
5486/29850 (epoch 9.189), train_loss = 1.53371266, grad/param norm = 1.8259e-01, time/batch = 0.6706s	
5487/29850 (epoch 9.191), train_loss = 1.40460578, grad/param norm = 1.8082e-01, time/batch = 0.6845s	
5488/29850 (epoch 9.193), train_loss = 1.22558019, grad/param norm = 1.6150e-01, time/batch = 0.6835s	
5489/29850 (epoch 9.194), train_loss = 1.40659072, grad/param norm = 2.3202e-01, time/batch = 0.6809s	
5490/29850 (epoch 9.196), train_loss = 1.33682652, grad/param norm = 1.7619e-01, time/batch = 0.6523s	
5491/29850 (epoch 9.198), train_loss = 1.32495013, grad/param norm = 1.7174e-01, time/batch = 0.6541s	
5492/29850 (epoch 9.199), train_loss = 1.61224954, grad/param norm = 2.0896e-01, time/batch = 0.6571s	
5493/29850 (epoch 9.201), train_loss = 1.33193503, grad/param norm = 1.8018e-01, time/batch = 0.6558s	
5494/29850 (epoch 9.203), train_loss = 1.29804300, grad/param norm = 1.7634e-01, time/batch = 0.6553s	
5495/29850 (epoch 9.204), train_loss = 1.41838225, grad/param norm = 1.9741e-01, time/batch = 0.6580s	
5496/29850 (epoch 9.206), train_loss = 1.26722857, grad/param norm = 1.8236e-01, time/batch = 0.6619s	
5497/29850 (epoch 9.208), train_loss = 1.56682783, grad/param norm = 1.8722e-01, time/batch = 0.6546s	
5498/29850 (epoch 9.209), train_loss = 1.27990625, grad/param norm = 1.7487e-01, time/batch = 0.6586s	
5499/29850 (epoch 9.211), train_loss = 1.30073048, grad/param norm = 1.6554e-01, time/batch = 0.6586s	
5500/29850 (epoch 9.213), train_loss = 1.52909358, grad/param norm = 1.9627e-01, time/batch = 0.6609s	
5501/29850 (epoch 9.214), train_loss = 1.25530822, grad/param norm = 1.5293e-01, time/batch = 0.6584s	
5502/29850 (epoch 9.216), train_loss = 1.33512894, grad/param norm = 1.8396e-01, time/batch = 0.6571s	
5503/29850 (epoch 9.218), train_loss = 1.44288976, grad/param norm = 1.7602e-01, time/batch = 0.6619s	
5504/29850 (epoch 9.219), train_loss = 1.56925436, grad/param norm = 2.0987e-01, time/batch = 0.6737s	
5505/29850 (epoch 9.221), train_loss = 1.34952105, grad/param norm = 1.9963e-01, time/batch = 0.6593s	
5506/29850 (epoch 9.223), train_loss = 1.36289450, grad/param norm = 1.8856e-01, time/batch = 0.6578s	
5507/29850 (epoch 9.224), train_loss = 1.23932586, grad/param norm = 1.7754e-01, time/batch = 0.6592s	
5508/29850 (epoch 9.226), train_loss = 1.26266707, grad/param norm = 1.7011e-01, time/batch = 0.6559s	
5509/29850 (epoch 9.228), train_loss = 1.29560573, grad/param norm = 1.6920e-01, time/batch = 0.6723s	
5510/29850 (epoch 9.229), train_loss = 1.18965318, grad/param norm = 1.6470e-01, time/batch = 0.6821s	
5511/29850 (epoch 9.231), train_loss = 1.26567970, grad/param norm = 1.6035e-01, time/batch = 0.6669s	
5512/29850 (epoch 9.233), train_loss = 1.33904931, grad/param norm = 1.7067e-01, time/batch = 0.6698s	
5513/29850 (epoch 9.235), train_loss = 1.24882268, grad/param norm = 1.4670e-01, time/batch = 0.6621s	
5514/29850 (epoch 9.236), train_loss = 1.50798345, grad/param norm = 1.9620e-01, time/batch = 0.6582s	
5515/29850 (epoch 9.238), train_loss = 1.19409864, grad/param norm = 1.8358e-01, time/batch = 0.6561s	
5516/29850 (epoch 9.240), train_loss = 1.31018415, grad/param norm = 1.6820e-01, time/batch = 0.6545s	
5517/29850 (epoch 9.241), train_loss = 1.52616963, grad/param norm = 1.9575e-01, time/batch = 0.6543s	
5518/29850 (epoch 9.243), train_loss = 1.32146705, grad/param norm = 1.7476e-01, time/batch = 0.6584s	
5519/29850 (epoch 9.245), train_loss = 1.30002855, grad/param norm = 1.8508e-01, time/batch = 0.6607s	
5520/29850 (epoch 9.246), train_loss = 1.27423092, grad/param norm = 1.7830e-01, time/batch = 0.6820s	
5521/29850 (epoch 9.248), train_loss = 1.28611281, grad/param norm = 1.7363e-01, time/batch = 0.6678s	
5522/29850 (epoch 9.250), train_loss = 1.35257988, grad/param norm = 1.6252e-01, time/batch = 0.6626s	
5523/29850 (epoch 9.251), train_loss = 1.24199529, grad/param norm = 1.7756e-01, time/batch = 0.6573s	
5524/29850 (epoch 9.253), train_loss = 1.23228586, grad/param norm = 1.7645e-01, time/batch = 0.6564s	
5525/29850 (epoch 9.255), train_loss = 1.25473341, grad/param norm = 1.6672e-01, time/batch = 0.6684s	
5526/29850 (epoch 9.256), train_loss = 1.36154035, grad/param norm = 1.7849e-01, time/batch = 0.6818s	
5527/29850 (epoch 9.258), train_loss = 1.32528650, grad/param norm = 1.7252e-01, time/batch = 0.6696s	
5528/29850 (epoch 9.260), train_loss = 1.29371493, grad/param norm = 1.6782e-01, time/batch = 0.6588s	
5529/29850 (epoch 9.261), train_loss = 1.27832370, grad/param norm = 1.6510e-01, time/batch = 0.6535s	
5530/29850 (epoch 9.263), train_loss = 1.20758671, grad/param norm = 1.6943e-01, time/batch = 0.6674s	
5531/29850 (epoch 9.265), train_loss = 1.28280018, grad/param norm = 1.8198e-01, time/batch = 0.6556s	
5532/29850 (epoch 9.266), train_loss = 1.31262217, grad/param norm = 1.8694e-01, time/batch = 0.6576s	
5533/29850 (epoch 9.268), train_loss = 1.28261321, grad/param norm = 1.6822e-01, time/batch = 0.6546s	
5534/29850 (epoch 9.270), train_loss = 1.23953212, grad/param norm = 1.6111e-01, time/batch = 0.6583s	
5535/29850 (epoch 9.271), train_loss = 1.43164862, grad/param norm = 1.8073e-01, time/batch = 0.6667s	
5536/29850 (epoch 9.273), train_loss = 1.19196148, grad/param norm = 1.6466e-01, time/batch = 0.6622s	
5537/29850 (epoch 9.275), train_loss = 1.24168823, grad/param norm = 1.7865e-01, time/batch = 0.6579s	
5538/29850 (epoch 9.276), train_loss = 1.22530537, grad/param norm = 1.6527e-01, time/batch = 0.6545s	
5539/29850 (epoch 9.278), train_loss = 1.30312752, grad/param norm = 1.7217e-01, time/batch = 0.6532s	
5540/29850 (epoch 9.280), train_loss = 1.45491335, grad/param norm = 1.9437e-01, time/batch = 0.6561s	
5541/29850 (epoch 9.281), train_loss = 1.30628848, grad/param norm = 1.7547e-01, time/batch = 0.6838s	
5542/29850 (epoch 9.283), train_loss = 1.42156890, grad/param norm = 1.8977e-01, time/batch = 0.6696s	
5543/29850 (epoch 9.285), train_loss = 1.28977012, grad/param norm = 1.7479e-01, time/batch = 0.6613s	
5544/29850 (epoch 9.286), train_loss = 1.34987811, grad/param norm = 1.7025e-01, time/batch = 0.6778s	
5545/29850 (epoch 9.288), train_loss = 1.50936331, grad/param norm = 2.3037e-01, time/batch = 0.6725s	
5546/29850 (epoch 9.290), train_loss = 1.26939336, grad/param norm = 1.7430e-01, time/batch = 0.6695s	
5547/29850 (epoch 9.291), train_loss = 1.60637529, grad/param norm = 1.8582e-01, time/batch = 0.6793s	
5548/29850 (epoch 9.293), train_loss = 1.42228245, grad/param norm = 1.7635e-01, time/batch = 0.6780s	
5549/29850 (epoch 9.295), train_loss = 1.51589061, grad/param norm = 1.8965e-01, time/batch = 0.6712s	
5550/29850 (epoch 9.296), train_loss = 1.26509531, grad/param norm = 1.5624e-01, time/batch = 0.6679s	
5551/29850 (epoch 9.298), train_loss = 1.12901216, grad/param norm = 1.6653e-01, time/batch = 0.6791s	
5552/29850 (epoch 9.300), train_loss = 1.19063440, grad/param norm = 1.4933e-01, time/batch = 0.6773s	
5553/29850 (epoch 9.302), train_loss = 1.18701563, grad/param norm = 1.6029e-01, time/batch = 0.6578s	
5554/29850 (epoch 9.303), train_loss = 1.30169510, grad/param norm = 1.7509e-01, time/batch = 0.6577s	
5555/29850 (epoch 9.305), train_loss = 1.28755884, grad/param norm = 1.6119e-01, time/batch = 0.6603s	
5556/29850 (epoch 9.307), train_loss = 1.42462735, grad/param norm = 1.7984e-01, time/batch = 0.6579s	
5557/29850 (epoch 9.308), train_loss = 1.34893167, grad/param norm = 1.8532e-01, time/batch = 0.6557s	
5558/29850 (epoch 9.310), train_loss = 1.36198893, grad/param norm = 1.7541e-01, time/batch = 0.6571s	
5559/29850 (epoch 9.312), train_loss = 1.42076246, grad/param norm = 1.8436e-01, time/batch = 0.6563s	
5560/29850 (epoch 9.313), train_loss = 1.39814014, grad/param norm = 1.8290e-01, time/batch = 0.6528s	
5561/29850 (epoch 9.315), train_loss = 1.35623962, grad/param norm = 1.5841e-01, time/batch = 0.6606s	
5562/29850 (epoch 9.317), train_loss = 1.38404345, grad/param norm = 1.9483e-01, time/batch = 0.6828s	
5563/29850 (epoch 9.318), train_loss = 1.36367390, grad/param norm = 1.8462e-01, time/batch = 0.6605s	
5564/29850 (epoch 9.320), train_loss = 1.23012338, grad/param norm = 1.7020e-01, time/batch = 0.6565s	
5565/29850 (epoch 9.322), train_loss = 1.48254688, grad/param norm = 1.8476e-01, time/batch = 0.6623s	
5566/29850 (epoch 9.323), train_loss = 1.36713994, grad/param norm = 1.9166e-01, time/batch = 0.6814s	
5567/29850 (epoch 9.325), train_loss = 1.33756793, grad/param norm = 1.7161e-01, time/batch = 0.6858s	
5568/29850 (epoch 9.327), train_loss = 1.48616898, grad/param norm = 1.9770e-01, time/batch = 0.6838s	
5569/29850 (epoch 9.328), train_loss = 1.48226334, grad/param norm = 1.7959e-01, time/batch = 0.6663s	
5570/29850 (epoch 9.330), train_loss = 1.32679369, grad/param norm = 1.7005e-01, time/batch = 0.6608s	
5571/29850 (epoch 9.332), train_loss = 1.24629749, grad/param norm = 1.6467e-01, time/batch = 0.6613s	
5572/29850 (epoch 9.333), train_loss = 1.50525885, grad/param norm = 1.8404e-01, time/batch = 0.6775s	
5573/29850 (epoch 9.335), train_loss = 1.37299072, grad/param norm = 1.7232e-01, time/batch = 0.6743s	
5574/29850 (epoch 9.337), train_loss = 1.36857935, grad/param norm = 1.7793e-01, time/batch = 0.6576s	
5575/29850 (epoch 9.338), train_loss = 1.34344710, grad/param norm = 1.6889e-01, time/batch = 0.6589s	
5576/29850 (epoch 9.340), train_loss = 1.22503760, grad/param norm = 1.7005e-01, time/batch = 0.6625s	
5577/29850 (epoch 9.342), train_loss = 1.37976828, grad/param norm = 1.7822e-01, time/batch = 0.6580s	
5578/29850 (epoch 9.343), train_loss = 1.39227951, grad/param norm = 1.9321e-01, time/batch = 0.6574s	
5579/29850 (epoch 9.345), train_loss = 1.45048746, grad/param norm = 1.9451e-01, time/batch = 0.6589s	
5580/29850 (epoch 9.347), train_loss = 1.43258157, grad/param norm = 1.8608e-01, time/batch = 0.6586s	
5581/29850 (epoch 9.348), train_loss = 1.32102580, grad/param norm = 1.6648e-01, time/batch = 0.6616s	
5582/29850 (epoch 9.350), train_loss = 1.43415688, grad/param norm = 1.8121e-01, time/batch = 0.6679s	
5583/29850 (epoch 9.352), train_loss = 1.35924159, grad/param norm = 1.7015e-01, time/batch = 0.6829s	
5584/29850 (epoch 9.353), train_loss = 1.39491247, grad/param norm = 1.8612e-01, time/batch = 0.6675s	
5585/29850 (epoch 9.355), train_loss = 1.22084833, grad/param norm = 1.7429e-01, time/batch = 0.6579s	
5586/29850 (epoch 9.357), train_loss = 1.48545046, grad/param norm = 1.7733e-01, time/batch = 0.6660s	
5587/29850 (epoch 9.358), train_loss = 1.20541052, grad/param norm = 1.6162e-01, time/batch = 0.6571s	
5588/29850 (epoch 9.360), train_loss = 1.33692988, grad/param norm = 1.7078e-01, time/batch = 0.6566s	
5589/29850 (epoch 9.362), train_loss = 1.30513290, grad/param norm = 1.7008e-01, time/batch = 0.6520s	
5590/29850 (epoch 9.363), train_loss = 1.34643301, grad/param norm = 1.7360e-01, time/batch = 0.6533s	
5591/29850 (epoch 9.365), train_loss = 1.49992737, grad/param norm = 1.9614e-01, time/batch = 0.6577s	
5592/29850 (epoch 9.367), train_loss = 1.29703415, grad/param norm = 1.6533e-01, time/batch = 0.6524s	
5593/29850 (epoch 9.369), train_loss = 1.26800422, grad/param norm = 1.9089e-01, time/batch = 0.6756s	
5594/29850 (epoch 9.370), train_loss = 1.15609056, grad/param norm = 1.6390e-01, time/batch = 0.6772s	
5595/29850 (epoch 9.372), train_loss = 1.52721471, grad/param norm = 1.9381e-01, time/batch = 0.6607s	
5596/29850 (epoch 9.374), train_loss = 1.31277428, grad/param norm = 1.8406e-01, time/batch = 0.6552s	
5597/29850 (epoch 9.375), train_loss = 1.31526371, grad/param norm = 1.6513e-01, time/batch = 0.6598s	
5598/29850 (epoch 9.377), train_loss = 1.39865447, grad/param norm = 1.8771e-01, time/batch = 0.6521s	
5599/29850 (epoch 9.379), train_loss = 1.42264406, grad/param norm = 1.7626e-01, time/batch = 0.6548s	
5600/29850 (epoch 9.380), train_loss = 1.38647420, grad/param norm = 1.8506e-01, time/batch = 0.6559s	
5601/29850 (epoch 9.382), train_loss = 1.40442780, grad/param norm = 1.8372e-01, time/batch = 0.6634s	
5602/29850 (epoch 9.384), train_loss = 1.35435066, grad/param norm = 1.8255e-01, time/batch = 0.6581s	
5603/29850 (epoch 9.385), train_loss = 1.33601182, grad/param norm = 1.7189e-01, time/batch = 0.6588s	
5604/29850 (epoch 9.387), train_loss = 1.40180328, grad/param norm = 2.0711e-01, time/batch = 0.6827s	
5605/29850 (epoch 9.389), train_loss = 1.50309187, grad/param norm = 1.6984e-01, time/batch = 0.6590s	
5606/29850 (epoch 9.390), train_loss = 1.38323962, grad/param norm = 1.7117e-01, time/batch = 0.6512s	
5607/29850 (epoch 9.392), train_loss = 1.32707875, grad/param norm = 1.8254e-01, time/batch = 0.6525s	
5608/29850 (epoch 9.394), train_loss = 1.44447645, grad/param norm = 1.8502e-01, time/batch = 0.6548s	
5609/29850 (epoch 9.395), train_loss = 1.39544049, grad/param norm = 1.9870e-01, time/batch = 0.6579s	
5610/29850 (epoch 9.397), train_loss = 1.34291451, grad/param norm = 1.7724e-01, time/batch = 0.6637s	
5611/29850 (epoch 9.399), train_loss = 1.24267120, grad/param norm = 1.6518e-01, time/batch = 0.6594s	
5612/29850 (epoch 9.400), train_loss = 1.61141296, grad/param norm = 2.1870e-01, time/batch = 0.6551s	
5613/29850 (epoch 9.402), train_loss = 1.47712084, grad/param norm = 1.8349e-01, time/batch = 0.6502s	
5614/29850 (epoch 9.404), train_loss = 1.42583553, grad/param norm = 1.8275e-01, time/batch = 0.6537s	
5615/29850 (epoch 9.405), train_loss = 1.41810876, grad/param norm = 1.9569e-01, time/batch = 0.6566s	
5616/29850 (epoch 9.407), train_loss = 1.34070859, grad/param norm = 1.9068e-01, time/batch = 0.6597s	
5617/29850 (epoch 9.409), train_loss = 1.55217328, grad/param norm = 2.1186e-01, time/batch = 0.6696s	
5618/29850 (epoch 9.410), train_loss = 1.50874024, grad/param norm = 1.7632e-01, time/batch = 0.6754s	
5619/29850 (epoch 9.412), train_loss = 1.37939239, grad/param norm = 1.8415e-01, time/batch = 0.6835s	
5620/29850 (epoch 9.414), train_loss = 1.40214363, grad/param norm = 1.9268e-01, time/batch = 0.6834s	
5621/29850 (epoch 9.415), train_loss = 1.35808542, grad/param norm = 1.6186e-01, time/batch = 0.6866s	
5622/29850 (epoch 9.417), train_loss = 1.52519559, grad/param norm = 1.9835e-01, time/batch = 0.6835s	
5623/29850 (epoch 9.419), train_loss = 1.39228237, grad/param norm = 1.8907e-01, time/batch = 0.6750s	
5624/29850 (epoch 9.420), train_loss = 1.34254617, grad/param norm = 1.6838e-01, time/batch = 0.6655s	
5625/29850 (epoch 9.422), train_loss = 1.31013812, grad/param norm = 1.6942e-01, time/batch = 0.6829s	
5626/29850 (epoch 9.424), train_loss = 1.38288804, grad/param norm = 1.8224e-01, time/batch = 0.6618s	
5627/29850 (epoch 9.425), train_loss = 1.61107603, grad/param norm = 1.8724e-01, time/batch = 0.6565s	
5628/29850 (epoch 9.427), train_loss = 1.22587311, grad/param norm = 1.7528e-01, time/batch = 0.6537s	
5629/29850 (epoch 9.429), train_loss = 1.24381858, grad/param norm = 1.7434e-01, time/batch = 0.6536s	
5630/29850 (epoch 9.430), train_loss = 1.16486753, grad/param norm = 1.5859e-01, time/batch = 0.6598s	
5631/29850 (epoch 9.432), train_loss = 1.33037290, grad/param norm = 1.7458e-01, time/batch = 0.6609s	
5632/29850 (epoch 9.434), train_loss = 1.26291296, grad/param norm = 1.7085e-01, time/batch = 0.6694s	
5633/29850 (epoch 9.436), train_loss = 1.41263011, grad/param norm = 1.8540e-01, time/batch = 0.6742s	
5634/29850 (epoch 9.437), train_loss = 1.39739267, grad/param norm = 1.7068e-01, time/batch = 0.6539s	
5635/29850 (epoch 9.439), train_loss = 1.38120397, grad/param norm = 1.7306e-01, time/batch = 0.6507s	
5636/29850 (epoch 9.441), train_loss = 1.39467973, grad/param norm = 1.9311e-01, time/batch = 0.6507s	
5637/29850 (epoch 9.442), train_loss = 1.39299215, grad/param norm = 1.8334e-01, time/batch = 0.6540s	
5638/29850 (epoch 9.444), train_loss = 1.33122491, grad/param norm = 1.5998e-01, time/batch = 0.6557s	
5639/29850 (epoch 9.446), train_loss = 1.39184946, grad/param norm = 1.7342e-01, time/batch = 0.6551s	
5640/29850 (epoch 9.447), train_loss = 1.46896640, grad/param norm = 2.0075e-01, time/batch = 0.6570s	
5641/29850 (epoch 9.449), train_loss = 1.47365031, grad/param norm = 1.8798e-01, time/batch = 0.6550s	
5642/29850 (epoch 9.451), train_loss = 1.25174582, grad/param norm = 1.7186e-01, time/batch = 0.6543s	
5643/29850 (epoch 9.452), train_loss = 1.09208173, grad/param norm = 1.5106e-01, time/batch = 0.6521s	
5644/29850 (epoch 9.454), train_loss = 1.23012213, grad/param norm = 1.5443e-01, time/batch = 0.6514s	
5645/29850 (epoch 9.456), train_loss = 1.43881789, grad/param norm = 1.8523e-01, time/batch = 0.6552s	
5646/29850 (epoch 9.457), train_loss = 1.47644411, grad/param norm = 1.9914e-01, time/batch = 0.6504s	
5647/29850 (epoch 9.459), train_loss = 1.54114465, grad/param norm = 1.9715e-01, time/batch = 0.6561s	
5648/29850 (epoch 9.461), train_loss = 1.53043700, grad/param norm = 1.7108e-01, time/batch = 0.6570s	
5649/29850 (epoch 9.462), train_loss = 1.45084177, grad/param norm = 1.8690e-01, time/batch = 0.6540s	
5650/29850 (epoch 9.464), train_loss = 1.37693138, grad/param norm = 1.6891e-01, time/batch = 0.6695s	
5651/29850 (epoch 9.466), train_loss = 1.23444108, grad/param norm = 1.7049e-01, time/batch = 0.6537s	
5652/29850 (epoch 9.467), train_loss = 1.38977942, grad/param norm = 1.7555e-01, time/batch = 0.6537s	
5653/29850 (epoch 9.469), train_loss = 1.35396936, grad/param norm = 1.6694e-01, time/batch = 0.6530s	
5654/29850 (epoch 9.471), train_loss = 1.34467331, grad/param norm = 1.6518e-01, time/batch = 0.6577s	
5655/29850 (epoch 9.472), train_loss = 1.26097499, grad/param norm = 1.7361e-01, time/batch = 0.6598s	
5656/29850 (epoch 9.474), train_loss = 1.51509778, grad/param norm = 1.7714e-01, time/batch = 0.6743s	
5657/29850 (epoch 9.476), train_loss = 1.41516424, grad/param norm = 1.8525e-01, time/batch = 0.6834s	
5658/29850 (epoch 9.477), train_loss = 1.40837042, grad/param norm = 1.7990e-01, time/batch = 0.6769s	
5659/29850 (epoch 9.479), train_loss = 1.46377290, grad/param norm = 1.8573e-01, time/batch = 0.6654s	
5660/29850 (epoch 9.481), train_loss = 1.42975101, grad/param norm = 1.8495e-01, time/batch = 0.6558s	
5661/29850 (epoch 9.482), train_loss = 1.27360982, grad/param norm = 1.5489e-01, time/batch = 0.6657s	
5662/29850 (epoch 9.484), train_loss = 1.33145873, grad/param norm = 1.7207e-01, time/batch = 0.6638s	
5663/29850 (epoch 9.486), train_loss = 1.36760560, grad/param norm = 1.7694e-01, time/batch = 0.6567s	
5664/29850 (epoch 9.487), train_loss = 1.32859449, grad/param norm = 1.7767e-01, time/batch = 0.6534s	
5665/29850 (epoch 9.489), train_loss = 1.37520007, grad/param norm = 1.7939e-01, time/batch = 0.6582s	
5666/29850 (epoch 9.491), train_loss = 1.21783049, grad/param norm = 1.6051e-01, time/batch = 0.6504s	
5667/29850 (epoch 9.492), train_loss = 1.42344251, grad/param norm = 1.7333e-01, time/batch = 0.6536s	
5668/29850 (epoch 9.494), train_loss = 1.52340215, grad/param norm = 1.6867e-01, time/batch = 0.6496s	
5669/29850 (epoch 9.496), train_loss = 1.53386227, grad/param norm = 1.7426e-01, time/batch = 0.6517s	
5670/29850 (epoch 9.497), train_loss = 1.40069511, grad/param norm = 1.7609e-01, time/batch = 0.6518s	
5671/29850 (epoch 9.499), train_loss = 1.38770209, grad/param norm = 1.7137e-01, time/batch = 0.6639s	
5672/29850 (epoch 9.501), train_loss = 1.30450706, grad/param norm = 1.6747e-01, time/batch = 0.6883s	
5673/29850 (epoch 9.503), train_loss = 1.33155252, grad/param norm = 1.6778e-01, time/batch = 0.6638s	
5674/29850 (epoch 9.504), train_loss = 1.54145520, grad/param norm = 1.8032e-01, time/batch = 0.6554s	
5675/29850 (epoch 9.506), train_loss = 1.60231944, grad/param norm = 1.9677e-01, time/batch = 0.6559s	
5676/29850 (epoch 9.508), train_loss = 1.33455679, grad/param norm = 1.7144e-01, time/batch = 0.6535s	
5677/29850 (epoch 9.509), train_loss = 1.16488429, grad/param norm = 1.6563e-01, time/batch = 0.6731s	
5678/29850 (epoch 9.511), train_loss = 1.34160758, grad/param norm = 1.6774e-01, time/batch = 0.6787s	
5679/29850 (epoch 9.513), train_loss = 1.44699869, grad/param norm = 1.9857e-01, time/batch = 0.6664s	
5680/29850 (epoch 9.514), train_loss = 1.23839068, grad/param norm = 1.7401e-01, time/batch = 0.6657s	
5681/29850 (epoch 9.516), train_loss = 1.23290691, grad/param norm = 1.5945e-01, time/batch = 0.6712s	
5682/29850 (epoch 9.518), train_loss = 1.21917881, grad/param norm = 1.6555e-01, time/batch = 0.6841s	
5683/29850 (epoch 9.519), train_loss = 1.21664879, grad/param norm = 1.7054e-01, time/batch = 0.6686s	
5684/29850 (epoch 9.521), train_loss = 1.23984885, grad/param norm = 1.5720e-01, time/batch = 0.6602s	
5685/29850 (epoch 9.523), train_loss = 1.19566872, grad/param norm = 1.4710e-01, time/batch = 0.6655s	
5686/29850 (epoch 9.524), train_loss = 1.34765815, grad/param norm = 1.8381e-01, time/batch = 0.6604s	
5687/29850 (epoch 9.526), train_loss = 1.42915594, grad/param norm = 1.8249e-01, time/batch = 0.6567s	
5688/29850 (epoch 9.528), train_loss = 1.52985679, grad/param norm = 1.9346e-01, time/batch = 0.6576s	
5689/29850 (epoch 9.529), train_loss = 1.46809771, grad/param norm = 1.9069e-01, time/batch = 0.6541s	
5690/29850 (epoch 9.531), train_loss = 1.39549784, grad/param norm = 1.9739e-01, time/batch = 0.6544s	
5691/29850 (epoch 9.533), train_loss = 1.29487276, grad/param norm = 1.8347e-01, time/batch = 0.6578s	
5692/29850 (epoch 9.534), train_loss = 1.33584218, grad/param norm = 1.7107e-01, time/batch = 0.6677s	
5693/29850 (epoch 9.536), train_loss = 1.35436308, grad/param norm = 1.8349e-01, time/batch = 0.6837s	
5694/29850 (epoch 9.538), train_loss = 1.44406364, grad/param norm = 1.7260e-01, time/batch = 0.6556s	
5695/29850 (epoch 9.539), train_loss = 1.47176790, grad/param norm = 1.7125e-01, time/batch = 0.6515s	
5696/29850 (epoch 9.541), train_loss = 1.18525311, grad/param norm = 1.6403e-01, time/batch = 0.6497s	
5697/29850 (epoch 9.543), train_loss = 1.33701914, grad/param norm = 1.6871e-01, time/batch = 0.6557s	
5698/29850 (epoch 9.544), train_loss = 1.36952413, grad/param norm = 1.7337e-01, time/batch = 0.6539s	
5699/29850 (epoch 9.546), train_loss = 1.44644201, grad/param norm = 1.7348e-01, time/batch = 0.6515s	
5700/29850 (epoch 9.548), train_loss = 1.23768838, grad/param norm = 1.6581e-01, time/batch = 0.6528s	
5701/29850 (epoch 9.549), train_loss = 1.30939682, grad/param norm = 1.6006e-01, time/batch = 0.6533s	
5702/29850 (epoch 9.551), train_loss = 1.26256965, grad/param norm = 1.7367e-01, time/batch = 0.6526s	
5703/29850 (epoch 9.553), train_loss = 1.38722548, grad/param norm = 1.7879e-01, time/batch = 0.6545s	
5704/29850 (epoch 9.554), train_loss = 1.12618908, grad/param norm = 1.5659e-01, time/batch = 0.6845s	
5705/29850 (epoch 9.556), train_loss = 1.33494232, grad/param norm = 1.7608e-01, time/batch = 0.6678s	
5706/29850 (epoch 9.558), train_loss = 1.29367199, grad/param norm = 1.6538e-01, time/batch = 0.6688s	
5707/29850 (epoch 9.559), train_loss = 1.39895159, grad/param norm = 1.8351e-01, time/batch = 0.6695s	
5708/29850 (epoch 9.561), train_loss = 1.42140502, grad/param norm = 1.7536e-01, time/batch = 0.6569s	
5709/29850 (epoch 9.563), train_loss = 1.32991381, grad/param norm = 1.6705e-01, time/batch = 0.6634s	
5710/29850 (epoch 9.564), train_loss = 1.31912097, grad/param norm = 1.7390e-01, time/batch = 0.6512s	
5711/29850 (epoch 9.566), train_loss = 1.29977897, grad/param norm = 1.6259e-01, time/batch = 0.6662s	
5712/29850 (epoch 9.568), train_loss = 1.42752258, grad/param norm = 1.6575e-01, time/batch = 0.6557s	
5713/29850 (epoch 9.570), train_loss = 1.36504787, grad/param norm = 1.7413e-01, time/batch = 0.6716s	
5714/29850 (epoch 9.571), train_loss = 1.39699766, grad/param norm = 1.7264e-01, time/batch = 0.6531s	
5715/29850 (epoch 9.573), train_loss = 1.51437108, grad/param norm = 1.9616e-01, time/batch = 0.6550s	
5716/29850 (epoch 9.575), train_loss = 1.46439946, grad/param norm = 1.7215e-01, time/batch = 0.6551s	
5717/29850 (epoch 9.576), train_loss = 1.51209609, grad/param norm = 1.8024e-01, time/batch = 0.6582s	
5718/29850 (epoch 9.578), train_loss = 1.39682145, grad/param norm = 1.7130e-01, time/batch = 0.6517s	
5719/29850 (epoch 9.580), train_loss = 1.45568786, grad/param norm = 1.8133e-01, time/batch = 0.6515s	
5720/29850 (epoch 9.581), train_loss = 1.29640102, grad/param norm = 1.7500e-01, time/batch = 0.6535s	
5721/29850 (epoch 9.583), train_loss = 1.34383721, grad/param norm = 1.7872e-01, time/batch = 0.6527s	
5722/29850 (epoch 9.585), train_loss = 1.36148157, grad/param norm = 1.6194e-01, time/batch = 0.6530s	
5723/29850 (epoch 9.586), train_loss = 1.39583536, grad/param norm = 1.7838e-01, time/batch = 0.6557s	
5724/29850 (epoch 9.588), train_loss = 1.29617612, grad/param norm = 1.6817e-01, time/batch = 0.6558s	
5725/29850 (epoch 9.590), train_loss = 1.36166060, grad/param norm = 1.6725e-01, time/batch = 0.6554s	
5726/29850 (epoch 9.591), train_loss = 1.27932027, grad/param norm = 1.6123e-01, time/batch = 0.6538s	
5727/29850 (epoch 9.593), train_loss = 1.27736290, grad/param norm = 1.5883e-01, time/batch = 0.6529s	
5728/29850 (epoch 9.595), train_loss = 1.23811654, grad/param norm = 1.4946e-01, time/batch = 0.6548s	
5729/29850 (epoch 9.596), train_loss = 1.21381403, grad/param norm = 1.6904e-01, time/batch = 0.6584s	
5730/29850 (epoch 9.598), train_loss = 1.23564545, grad/param norm = 1.6576e-01, time/batch = 0.6585s	
5731/29850 (epoch 9.600), train_loss = 1.47261844, grad/param norm = 1.9367e-01, time/batch = 0.6648s	
5732/29850 (epoch 9.601), train_loss = 1.22790025, grad/param norm = 1.6040e-01, time/batch = 0.6594s	
5733/29850 (epoch 9.603), train_loss = 1.34727807, grad/param norm = 1.7163e-01, time/batch = 0.6584s	
5734/29850 (epoch 9.605), train_loss = 1.38347258, grad/param norm = 1.8439e-01, time/batch = 0.6635s	
5735/29850 (epoch 9.606), train_loss = 1.12976885, grad/param norm = 1.7562e-01, time/batch = 0.6615s	
5736/29850 (epoch 9.608), train_loss = 1.33992679, grad/param norm = 1.7215e-01, time/batch = 0.6618s	
5737/29850 (epoch 9.610), train_loss = 1.33062206, grad/param norm = 1.7176e-01, time/batch = 0.6617s	
5738/29850 (epoch 9.611), train_loss = 1.16135832, grad/param norm = 1.5280e-01, time/batch = 0.6659s	
5739/29850 (epoch 9.613), train_loss = 1.10318903, grad/param norm = 1.4504e-01, time/batch = 0.6762s	
5740/29850 (epoch 9.615), train_loss = 1.17808665, grad/param norm = 1.5702e-01, time/batch = 0.6778s	
5741/29850 (epoch 9.616), train_loss = 1.30571254, grad/param norm = 1.8596e-01, time/batch = 0.6565s	
5742/29850 (epoch 9.618), train_loss = 1.34510254, grad/param norm = 1.7715e-01, time/batch = 0.6594s	
5743/29850 (epoch 9.620), train_loss = 1.37611541, grad/param norm = 1.7315e-01, time/batch = 0.6605s	
5744/29850 (epoch 9.621), train_loss = 1.40354082, grad/param norm = 1.8609e-01, time/batch = 0.6614s	
5745/29850 (epoch 9.623), train_loss = 1.43045421, grad/param norm = 1.8686e-01, time/batch = 0.6608s	
5746/29850 (epoch 9.625), train_loss = 1.40103854, grad/param norm = 1.8290e-01, time/batch = 0.6683s	
5747/29850 (epoch 9.626), train_loss = 1.41972410, grad/param norm = 1.8690e-01, time/batch = 0.6758s	
5748/29850 (epoch 9.628), train_loss = 1.20336514, grad/param norm = 1.6562e-01, time/batch = 0.6856s	
5749/29850 (epoch 9.630), train_loss = 1.34374068, grad/param norm = 1.7639e-01, time/batch = 0.6797s	
5750/29850 (epoch 9.631), train_loss = 1.26079047, grad/param norm = 1.6505e-01, time/batch = 0.6859s	
5751/29850 (epoch 9.633), train_loss = 1.44189633, grad/param norm = 1.9385e-01, time/batch = 0.6885s	
5752/29850 (epoch 9.635), train_loss = 1.36685810, grad/param norm = 1.9539e-01, time/batch = 0.6656s	
5753/29850 (epoch 9.637), train_loss = 1.37122353, grad/param norm = 1.8298e-01, time/batch = 0.6669s	
5754/29850 (epoch 9.638), train_loss = 1.28721100, grad/param norm = 1.7453e-01, time/batch = 0.6624s	
5755/29850 (epoch 9.640), train_loss = 1.50633495, grad/param norm = 1.9840e-01, time/batch = 0.6602s	
5756/29850 (epoch 9.642), train_loss = 1.32078294, grad/param norm = 1.7484e-01, time/batch = 0.6590s	
5757/29850 (epoch 9.643), train_loss = 1.25779860, grad/param norm = 1.5950e-01, time/batch = 0.6557s	
5758/29850 (epoch 9.645), train_loss = 1.37267240, grad/param norm = 1.7863e-01, time/batch = 0.6725s	
5759/29850 (epoch 9.647), train_loss = 1.47834884, grad/param norm = 1.7515e-01, time/batch = 0.6586s	
5760/29850 (epoch 9.648), train_loss = 1.21368540, grad/param norm = 1.5469e-01, time/batch = 0.6546s	
5761/29850 (epoch 9.650), train_loss = 1.31360102, grad/param norm = 1.8735e-01, time/batch = 0.6561s	
5762/29850 (epoch 9.652), train_loss = 1.35236979, grad/param norm = 1.7990e-01, time/batch = 0.6558s	
5763/29850 (epoch 9.653), train_loss = 1.45549023, grad/param norm = 1.8365e-01, time/batch = 0.6580s	
5764/29850 (epoch 9.655), train_loss = 1.32448225, grad/param norm = 1.6119e-01, time/batch = 0.6800s	
5765/29850 (epoch 9.657), train_loss = 1.28707054, grad/param norm = 1.6265e-01, time/batch = 0.6781s	
5766/29850 (epoch 9.658), train_loss = 1.43995642, grad/param norm = 1.7743e-01, time/batch = 0.6782s	
5767/29850 (epoch 9.660), train_loss = 1.27845317, grad/param norm = 1.7322e-01, time/batch = 0.6740s	
5768/29850 (epoch 9.662), train_loss = 1.35581038, grad/param norm = 1.8127e-01, time/batch = 0.6669s	
5769/29850 (epoch 9.663), train_loss = 1.45273353, grad/param norm = 1.9000e-01, time/batch = 0.6589s	
5770/29850 (epoch 9.665), train_loss = 1.40738880, grad/param norm = 1.8867e-01, time/batch = 0.6540s	
5771/29850 (epoch 9.667), train_loss = 1.42571740, grad/param norm = 2.0265e-01, time/batch = 0.6531s	
5772/29850 (epoch 9.668), train_loss = 1.36170785, grad/param norm = 1.7376e-01, time/batch = 0.6535s	
5773/29850 (epoch 9.670), train_loss = 1.58798116, grad/param norm = 1.9532e-01, time/batch = 0.6519s	
5774/29850 (epoch 9.672), train_loss = 1.42019200, grad/param norm = 2.0306e-01, time/batch = 0.6579s	
5775/29850 (epoch 9.673), train_loss = 1.44171204, grad/param norm = 1.8509e-01, time/batch = 0.6530s	
5776/29850 (epoch 9.675), train_loss = 1.33204067, grad/param norm = 1.6736e-01, time/batch = 0.6572s	
5777/29850 (epoch 9.677), train_loss = 1.33985838, grad/param norm = 1.8942e-01, time/batch = 0.6559s	
5778/29850 (epoch 9.678), train_loss = 1.32335330, grad/param norm = 1.8503e-01, time/batch = 0.6567s	
5779/29850 (epoch 9.680), train_loss = 1.39035917, grad/param norm = 1.7606e-01, time/batch = 0.6620s	
5780/29850 (epoch 9.682), train_loss = 1.32926389, grad/param norm = 1.7120e-01, time/batch = 0.6549s	
5781/29850 (epoch 9.683), train_loss = 1.52618085, grad/param norm = 2.1063e-01, time/batch = 0.6542s	
5782/29850 (epoch 9.685), train_loss = 1.48266632, grad/param norm = 1.5700e-01, time/batch = 0.6582s	
5783/29850 (epoch 9.687), train_loss = 1.42251539, grad/param norm = 1.7820e-01, time/batch = 0.6559s	
5784/29850 (epoch 9.688), train_loss = 1.21419253, grad/param norm = 1.4517e-01, time/batch = 0.6595s	
5785/29850 (epoch 9.690), train_loss = 1.24786453, grad/param norm = 1.7277e-01, time/batch = 0.6635s	
5786/29850 (epoch 9.692), train_loss = 1.49678412, grad/param norm = 1.8751e-01, time/batch = 0.6620s	
5787/29850 (epoch 9.693), train_loss = 1.33331630, grad/param norm = 1.6091e-01, time/batch = 0.6606s	
5788/29850 (epoch 9.695), train_loss = 1.19003491, grad/param norm = 1.6403e-01, time/batch = 0.6586s	
5789/29850 (epoch 9.697), train_loss = 1.40318048, grad/param norm = 1.7951e-01, time/batch = 0.6665s	
5790/29850 (epoch 9.698), train_loss = 1.42817752, grad/param norm = 1.7876e-01, time/batch = 0.6743s	
5791/29850 (epoch 9.700), train_loss = 1.41349205, grad/param norm = 1.9528e-01, time/batch = 0.6664s	
5792/29850 (epoch 9.702), train_loss = 1.32664303, grad/param norm = 1.8649e-01, time/batch = 0.6578s	
5793/29850 (epoch 9.704), train_loss = 1.26224297, grad/param norm = 1.6717e-01, time/batch = 0.6624s	
5794/29850 (epoch 9.705), train_loss = 1.35780015, grad/param norm = 1.6611e-01, time/batch = 0.6618s	
5795/29850 (epoch 9.707), train_loss = 1.32267633, grad/param norm = 1.7681e-01, time/batch = 0.6612s	
5796/29850 (epoch 9.709), train_loss = 1.44451028, grad/param norm = 1.8887e-01, time/batch = 0.6786s	
5797/29850 (epoch 9.710), train_loss = 1.33051071, grad/param norm = 1.8120e-01, time/batch = 0.6871s	
5798/29850 (epoch 9.712), train_loss = 1.36436871, grad/param norm = 1.6513e-01, time/batch = 0.6703s	
5799/29850 (epoch 9.714), train_loss = 1.41509874, grad/param norm = 1.7652e-01, time/batch = 0.6755s	
5800/29850 (epoch 9.715), train_loss = 1.41619966, grad/param norm = 1.7875e-01, time/batch = 0.6758s	
5801/29850 (epoch 9.717), train_loss = 1.18804846, grad/param norm = 1.6777e-01, time/batch = 0.6804s	
5802/29850 (epoch 9.719), train_loss = 1.30807298, grad/param norm = 1.7633e-01, time/batch = 0.6708s	
5803/29850 (epoch 9.720), train_loss = 1.34141917, grad/param norm = 1.6113e-01, time/batch = 0.6666s	
5804/29850 (epoch 9.722), train_loss = 1.25151433, grad/param norm = 1.6552e-01, time/batch = 0.6733s	
5805/29850 (epoch 9.724), train_loss = 1.42315514, grad/param norm = 1.8430e-01, time/batch = 0.6741s	
5806/29850 (epoch 9.725), train_loss = 1.23589985, grad/param norm = 1.6392e-01, time/batch = 0.6861s	
5807/29850 (epoch 9.727), train_loss = 1.30538569, grad/param norm = 1.8588e-01, time/batch = 0.6699s	
5808/29850 (epoch 9.729), train_loss = 1.18103383, grad/param norm = 1.6815e-01, time/batch = 0.6698s	
5809/29850 (epoch 9.730), train_loss = 1.20264581, grad/param norm = 1.7194e-01, time/batch = 0.6781s	
5810/29850 (epoch 9.732), train_loss = 1.38389463, grad/param norm = 1.6772e-01, time/batch = 0.6709s	
5811/29850 (epoch 9.734), train_loss = 1.54519790, grad/param norm = 1.9835e-01, time/batch = 0.6783s	
5812/29850 (epoch 9.735), train_loss = 1.36618572, grad/param norm = 1.8345e-01, time/batch = 0.6647s	
5813/29850 (epoch 9.737), train_loss = 1.23735707, grad/param norm = 1.7422e-01, time/batch = 0.6605s	
5814/29850 (epoch 9.739), train_loss = 1.19909547, grad/param norm = 1.6317e-01, time/batch = 0.6570s	
5815/29850 (epoch 9.740), train_loss = 1.21937097, grad/param norm = 1.6612e-01, time/batch = 0.6572s	
5816/29850 (epoch 9.742), train_loss = 1.21020722, grad/param norm = 1.5975e-01, time/batch = 0.6581s	
5817/29850 (epoch 9.744), train_loss = 1.33900998, grad/param norm = 1.9316e-01, time/batch = 0.6653s	
5818/29850 (epoch 9.745), train_loss = 1.33503415, grad/param norm = 1.9963e-01, time/batch = 0.6586s	
5819/29850 (epoch 9.747), train_loss = 1.27772568, grad/param norm = 1.8695e-01, time/batch = 0.6638s	
5820/29850 (epoch 9.749), train_loss = 1.22782502, grad/param norm = 1.7147e-01, time/batch = 0.6667s	
5821/29850 (epoch 9.750), train_loss = 1.29787487, grad/param norm = 1.8426e-01, time/batch = 0.6689s	
5822/29850 (epoch 9.752), train_loss = 1.23730846, grad/param norm = 1.6713e-01, time/batch = 0.6661s	
5823/29850 (epoch 9.754), train_loss = 1.23253340, grad/param norm = 1.7529e-01, time/batch = 0.6657s	
5824/29850 (epoch 9.755), train_loss = 1.30092119, grad/param norm = 1.7820e-01, time/batch = 0.6720s	
5825/29850 (epoch 9.757), train_loss = 1.29094129, grad/param norm = 1.6824e-01, time/batch = 0.6786s	
5826/29850 (epoch 9.759), train_loss = 1.32855962, grad/param norm = 1.6169e-01, time/batch = 0.6583s	
5827/29850 (epoch 9.760), train_loss = 1.21877263, grad/param norm = 1.7728e-01, time/batch = 0.6635s	
5828/29850 (epoch 9.762), train_loss = 1.22622231, grad/param norm = 1.7803e-01, time/batch = 0.6653s	
5829/29850 (epoch 9.764), train_loss = 1.23785819, grad/param norm = 1.7821e-01, time/batch = 0.6644s	
5830/29850 (epoch 9.765), train_loss = 1.28742683, grad/param norm = 1.8780e-01, time/batch = 0.6647s	
5831/29850 (epoch 9.767), train_loss = 1.32187958, grad/param norm = 1.7424e-01, time/batch = 0.6643s	
5832/29850 (epoch 9.769), train_loss = 1.27920967, grad/param norm = 1.7841e-01, time/batch = 0.6583s	
5833/29850 (epoch 9.771), train_loss = 1.36814983, grad/param norm = 1.8322e-01, time/batch = 0.6616s	
5834/29850 (epoch 9.772), train_loss = 1.42793074, grad/param norm = 1.8057e-01, time/batch = 0.6653s	
5835/29850 (epoch 9.774), train_loss = 1.27144086, grad/param norm = 1.8553e-01, time/batch = 0.6609s	
5836/29850 (epoch 9.776), train_loss = 1.27486149, grad/param norm = 1.7372e-01, time/batch = 0.6765s	
5837/29850 (epoch 9.777), train_loss = 1.38315454, grad/param norm = 1.8130e-01, time/batch = 0.6872s	
5838/29850 (epoch 9.779), train_loss = 1.19065145, grad/param norm = 1.6125e-01, time/batch = 0.7006s	
5839/29850 (epoch 9.781), train_loss = 1.28201933, grad/param norm = 1.6954e-01, time/batch = 0.6735s	
5840/29850 (epoch 9.782), train_loss = 1.32288579, grad/param norm = 1.6098e-01, time/batch = 0.6822s	
5841/29850 (epoch 9.784), train_loss = 1.24531985, grad/param norm = 1.7360e-01, time/batch = 0.6900s	
5842/29850 (epoch 9.786), train_loss = 1.28472344, grad/param norm = 1.7357e-01, time/batch = 0.6855s	
5843/29850 (epoch 9.787), train_loss = 1.23278846, grad/param norm = 1.6889e-01, time/batch = 0.6906s	
5844/29850 (epoch 9.789), train_loss = 1.15338607, grad/param norm = 1.5236e-01, time/batch = 0.6768s	
5845/29850 (epoch 9.791), train_loss = 1.31955265, grad/param norm = 1.8790e-01, time/batch = 0.6722s	
5846/29850 (epoch 9.792), train_loss = 1.39102632, grad/param norm = 1.7694e-01, time/batch = 0.6572s	
5847/29850 (epoch 9.794), train_loss = 1.32916267, grad/param norm = 1.6568e-01, time/batch = 0.6558s	
5848/29850 (epoch 9.796), train_loss = 1.24253553, grad/param norm = 1.7573e-01, time/batch = 0.6570s	
5849/29850 (epoch 9.797), train_loss = 1.19248210, grad/param norm = 1.5683e-01, time/batch = 0.6598s	
5850/29850 (epoch 9.799), train_loss = 1.19079065, grad/param norm = 1.5891e-01, time/batch = 0.6689s	
5851/29850 (epoch 9.801), train_loss = 1.39716013, grad/param norm = 1.9350e-01, time/batch = 0.6626s	
5852/29850 (epoch 9.802), train_loss = 1.18895824, grad/param norm = 1.7870e-01, time/batch = 0.6643s	
5853/29850 (epoch 9.804), train_loss = 1.24567040, grad/param norm = 1.6163e-01, time/batch = 0.6587s	
5854/29850 (epoch 9.806), train_loss = 1.23155258, grad/param norm = 1.5730e-01, time/batch = 0.6733s	
5855/29850 (epoch 9.807), train_loss = 1.10653683, grad/param norm = 1.5031e-01, time/batch = 0.6785s	
5856/29850 (epoch 9.809), train_loss = 1.30847528, grad/param norm = 1.9145e-01, time/batch = 0.6773s	
5857/29850 (epoch 9.811), train_loss = 1.41549262, grad/param norm = 1.9356e-01, time/batch = 0.6758s	
5858/29850 (epoch 9.812), train_loss = 1.34398967, grad/param norm = 1.9166e-01, time/batch = 0.6707s	
5859/29850 (epoch 9.814), train_loss = 1.40665230, grad/param norm = 1.8998e-01, time/batch = 0.6791s	
5860/29850 (epoch 9.816), train_loss = 1.38503511, grad/param norm = 1.7331e-01, time/batch = 0.6595s	
5861/29850 (epoch 9.817), train_loss = 1.33040628, grad/param norm = 1.6807e-01, time/batch = 0.6604s	
5862/29850 (epoch 9.819), train_loss = 1.25023341, grad/param norm = 1.7855e-01, time/batch = 0.6590s	
5863/29850 (epoch 9.821), train_loss = 1.47564364, grad/param norm = 1.8482e-01, time/batch = 0.6579s	
5864/29850 (epoch 9.822), train_loss = 1.34361102, grad/param norm = 1.6646e-01, time/batch = 0.6593s	
5865/29850 (epoch 9.824), train_loss = 1.28487077, grad/param norm = 1.7718e-01, time/batch = 0.6568s	
5866/29850 (epoch 9.826), train_loss = 1.28366627, grad/param norm = 1.7174e-01, time/batch = 0.6613s	
5867/29850 (epoch 9.827), train_loss = 1.23194106, grad/param norm = 1.7355e-01, time/batch = 0.6626s	
5868/29850 (epoch 9.829), train_loss = 1.35499044, grad/param norm = 1.9297e-01, time/batch = 0.6598s	
5869/29850 (epoch 9.831), train_loss = 1.36087716, grad/param norm = 1.8756e-01, time/batch = 0.6632s	
5870/29850 (epoch 9.832), train_loss = 1.24068547, grad/param norm = 1.5919e-01, time/batch = 0.6603s	
5871/29850 (epoch 9.834), train_loss = 1.20224089, grad/param norm = 1.8446e-01, time/batch = 0.6636s	
5872/29850 (epoch 9.836), train_loss = 1.18623192, grad/param norm = 1.6462e-01, time/batch = 0.6585s	
5873/29850 (epoch 9.838), train_loss = 1.34244988, grad/param norm = 1.7064e-01, time/batch = 0.6562s	
5874/29850 (epoch 9.839), train_loss = 1.25036124, grad/param norm = 1.6911e-01, time/batch = 0.6618s	
5875/29850 (epoch 9.841), train_loss = 1.28345437, grad/param norm = 1.6930e-01, time/batch = 0.6587s	
5876/29850 (epoch 9.843), train_loss = 1.25886676, grad/param norm = 1.6350e-01, time/batch = 0.6610s	
5877/29850 (epoch 9.844), train_loss = 1.27791160, grad/param norm = 1.7714e-01, time/batch = 0.6587s	
5878/29850 (epoch 9.846), train_loss = 1.33995434, grad/param norm = 1.9323e-01, time/batch = 0.6623s	
5879/29850 (epoch 9.848), train_loss = 1.36409980, grad/param norm = 1.8493e-01, time/batch = 0.6607s	
5880/29850 (epoch 9.849), train_loss = 1.21531405, grad/param norm = 1.8182e-01, time/batch = 0.6590s	
5881/29850 (epoch 9.851), train_loss = 1.38659088, grad/param norm = 1.9542e-01, time/batch = 0.6573s	
5882/29850 (epoch 9.853), train_loss = 1.28624184, grad/param norm = 1.9874e-01, time/batch = 0.6591s	
5883/29850 (epoch 9.854), train_loss = 1.39663866, grad/param norm = 1.9079e-01, time/batch = 0.6609s	
5884/29850 (epoch 9.856), train_loss = 1.37542111, grad/param norm = 1.8747e-01, time/batch = 0.6615s	
5885/29850 (epoch 9.858), train_loss = 1.28048389, grad/param norm = 1.7522e-01, time/batch = 0.6624s	
5886/29850 (epoch 9.859), train_loss = 1.24054349, grad/param norm = 1.7629e-01, time/batch = 0.6593s	
5887/29850 (epoch 9.861), train_loss = 1.41289423, grad/param norm = 1.8338e-01, time/batch = 0.6634s	
5888/29850 (epoch 9.863), train_loss = 1.44316689, grad/param norm = 1.6816e-01, time/batch = 0.6647s	
5889/29850 (epoch 9.864), train_loss = 1.37173935, grad/param norm = 1.8424e-01, time/batch = 0.6585s	
5890/29850 (epoch 9.866), train_loss = 1.33892917, grad/param norm = 1.9177e-01, time/batch = 0.6743s	
5891/29850 (epoch 9.868), train_loss = 1.43542166, grad/param norm = 1.8712e-01, time/batch = 0.6630s	
5892/29850 (epoch 9.869), train_loss = 1.24637942, grad/param norm = 1.7049e-01, time/batch = 0.6628s	
5893/29850 (epoch 9.871), train_loss = 1.30767269, grad/param norm = 1.7159e-01, time/batch = 0.6598s	
5894/29850 (epoch 9.873), train_loss = 1.37773328, grad/param norm = 1.8235e-01, time/batch = 0.6649s	
5895/29850 (epoch 9.874), train_loss = 1.36194629, grad/param norm = 1.7586e-01, time/batch = 0.6652s	
5896/29850 (epoch 9.876), train_loss = 1.35263472, grad/param norm = 1.9713e-01, time/batch = 0.6698s	
5897/29850 (epoch 9.878), train_loss = 1.31823582, grad/param norm = 1.7815e-01, time/batch = 0.6689s	
5898/29850 (epoch 9.879), train_loss = 1.37052212, grad/param norm = 1.7200e-01, time/batch = 0.6580s	
5899/29850 (epoch 9.881), train_loss = 1.42323399, grad/param norm = 1.9027e-01, time/batch = 0.6563s	
5900/29850 (epoch 9.883), train_loss = 1.40974811, grad/param norm = 1.9087e-01, time/batch = 0.6618s	
5901/29850 (epoch 9.884), train_loss = 1.21298304, grad/param norm = 1.6978e-01, time/batch = 0.6878s	
5902/29850 (epoch 9.886), train_loss = 1.50419163, grad/param norm = 1.8429e-01, time/batch = 0.6663s	
5903/29850 (epoch 9.888), train_loss = 1.30205960, grad/param norm = 1.6828e-01, time/batch = 0.6658s	
5904/29850 (epoch 9.889), train_loss = 1.28161122, grad/param norm = 1.8062e-01, time/batch = 0.6624s	
5905/29850 (epoch 9.891), train_loss = 1.28891883, grad/param norm = 1.8306e-01, time/batch = 0.6633s	
5906/29850 (epoch 9.893), train_loss = 1.20591308, grad/param norm = 1.6112e-01, time/batch = 0.6604s	
5907/29850 (epoch 9.894), train_loss = 1.26788360, grad/param norm = 1.6578e-01, time/batch = 0.6611s	
5908/29850 (epoch 9.896), train_loss = 1.26351500, grad/param norm = 1.8119e-01, time/batch = 0.6576s	
5909/29850 (epoch 9.898), train_loss = 1.45316748, grad/param norm = 2.0458e-01, time/batch = 0.6594s	
5910/29850 (epoch 9.899), train_loss = 1.16197380, grad/param norm = 1.6529e-01, time/batch = 0.6607s	
5911/29850 (epoch 9.901), train_loss = 1.67770824, grad/param norm = 2.2071e-01, time/batch = 0.6803s	
5912/29850 (epoch 9.903), train_loss = 1.35069180, grad/param norm = 2.1855e-01, time/batch = 0.6807s	
5913/29850 (epoch 9.905), train_loss = 1.49974775, grad/param norm = 1.9020e-01, time/batch = 0.6617s	
5914/29850 (epoch 9.906), train_loss = 1.24181046, grad/param norm = 1.7488e-01, time/batch = 0.6619s	
5915/29850 (epoch 9.908), train_loss = 1.41525061, grad/param norm = 1.7757e-01, time/batch = 0.6607s	
5916/29850 (epoch 9.910), train_loss = 1.41213720, grad/param norm = 1.8636e-01, time/batch = 0.6594s	
5917/29850 (epoch 9.911), train_loss = 1.48254384, grad/param norm = 1.8675e-01, time/batch = 0.6702s	
5918/29850 (epoch 9.913), train_loss = 1.36671871, grad/param norm = 1.7952e-01, time/batch = 0.6630s	
5919/29850 (epoch 9.915), train_loss = 1.40247067, grad/param norm = 1.9262e-01, time/batch = 0.6572s	
5920/29850 (epoch 9.916), train_loss = 1.35803933, grad/param norm = 1.7345e-01, time/batch = 0.6562s	
5921/29850 (epoch 9.918), train_loss = 1.27178257, grad/param norm = 1.6109e-01, time/batch = 0.6600s	
5922/29850 (epoch 9.920), train_loss = 1.39683918, grad/param norm = 1.6877e-01, time/batch = 0.6568s	
5923/29850 (epoch 9.921), train_loss = 1.38410692, grad/param norm = 1.9019e-01, time/batch = 0.6565s	
5924/29850 (epoch 9.923), train_loss = 1.39335525, grad/param norm = 1.7233e-01, time/batch = 0.6633s	
5925/29850 (epoch 9.925), train_loss = 1.46178204, grad/param norm = 1.8661e-01, time/batch = 0.6593s	
5926/29850 (epoch 9.926), train_loss = 1.51131441, grad/param norm = 1.9194e-01, time/batch = 0.6836s	
5927/29850 (epoch 9.928), train_loss = 1.33154240, grad/param norm = 1.7805e-01, time/batch = 0.6839s	
5928/29850 (epoch 9.930), train_loss = 1.45045915, grad/param norm = 1.8580e-01, time/batch = 0.6834s	
5929/29850 (epoch 9.931), train_loss = 1.39730554, grad/param norm = 1.8170e-01, time/batch = 0.6655s	
5930/29850 (epoch 9.933), train_loss = 1.48896525, grad/param norm = 1.7945e-01, time/batch = 0.6799s	
5931/29850 (epoch 9.935), train_loss = 1.45299141, grad/param norm = 1.8714e-01, time/batch = 0.6834s	
5932/29850 (epoch 9.936), train_loss = 1.44116040, grad/param norm = 1.7459e-01, time/batch = 0.6749s	
5933/29850 (epoch 9.938), train_loss = 1.20539419, grad/param norm = 1.6445e-01, time/batch = 0.6765s	
5934/29850 (epoch 9.940), train_loss = 1.18902595, grad/param norm = 1.6975e-01, time/batch = 0.6782s	
5935/29850 (epoch 9.941), train_loss = 1.28464013, grad/param norm = 1.7874e-01, time/batch = 0.6781s	
5936/29850 (epoch 9.943), train_loss = 1.24627855, grad/param norm = 1.6214e-01, time/batch = 0.6936s	
5937/29850 (epoch 9.945), train_loss = 1.37688612, grad/param norm = 1.8412e-01, time/batch = 0.6781s	
5938/29850 (epoch 9.946), train_loss = 1.22858931, grad/param norm = 1.7793e-01, time/batch = 0.6865s	
5939/29850 (epoch 9.948), train_loss = 1.29901659, grad/param norm = 1.6373e-01, time/batch = 0.6847s	
5940/29850 (epoch 9.950), train_loss = 1.24014197, grad/param norm = 1.6909e-01, time/batch = 0.6801s	
5941/29850 (epoch 9.951), train_loss = 1.20644078, grad/param norm = 1.5677e-01, time/batch = 0.6703s	
5942/29850 (epoch 9.953), train_loss = 1.32939523, grad/param norm = 1.7373e-01, time/batch = 0.6675s	
5943/29850 (epoch 9.955), train_loss = 1.16051352, grad/param norm = 1.5151e-01, time/batch = 0.6678s	
5944/29850 (epoch 9.956), train_loss = 1.20046350, grad/param norm = 1.7532e-01, time/batch = 0.6663s	
5945/29850 (epoch 9.958), train_loss = 1.07115205, grad/param norm = 1.6217e-01, time/batch = 0.6672s	
5946/29850 (epoch 9.960), train_loss = 1.39650672, grad/param norm = 1.7986e-01, time/batch = 0.6646s	
5947/29850 (epoch 9.961), train_loss = 1.25480893, grad/param norm = 1.5884e-01, time/batch = 0.6638s	
5948/29850 (epoch 9.963), train_loss = 1.16683626, grad/param norm = 1.6371e-01, time/batch = 0.6630s	
5949/29850 (epoch 9.965), train_loss = 1.28789995, grad/param norm = 1.7830e-01, time/batch = 0.6638s	
5950/29850 (epoch 9.966), train_loss = 1.15929323, grad/param norm = 1.6114e-01, time/batch = 0.6548s	
5951/29850 (epoch 9.968), train_loss = 1.29647194, grad/param norm = 1.8101e-01, time/batch = 0.6600s	
5952/29850 (epoch 9.970), train_loss = 1.20384305, grad/param norm = 1.6736e-01, time/batch = 0.6603s	
5953/29850 (epoch 9.972), train_loss = 1.21876239, grad/param norm = 1.6523e-01, time/batch = 0.6573s	
5954/29850 (epoch 9.973), train_loss = 1.22894477, grad/param norm = 1.6805e-01, time/batch = 0.6585s	
5955/29850 (epoch 9.975), train_loss = 1.07986157, grad/param norm = 1.5176e-01, time/batch = 0.6603s	
5956/29850 (epoch 9.977), train_loss = 1.25328701, grad/param norm = 1.6820e-01, time/batch = 0.6606s	
5957/29850 (epoch 9.978), train_loss = 1.20666034, grad/param norm = 1.6173e-01, time/batch = 0.6663s	
5958/29850 (epoch 9.980), train_loss = 1.21052010, grad/param norm = 1.5577e-01, time/batch = 0.6615s	
5959/29850 (epoch 9.982), train_loss = 1.25363336, grad/param norm = 1.7634e-01, time/batch = 0.6770s	
5960/29850 (epoch 9.983), train_loss = 1.28910955, grad/param norm = 1.6649e-01, time/batch = 0.6610s	
5961/29850 (epoch 9.985), train_loss = 1.37733973, grad/param norm = 1.9182e-01, time/batch = 0.6605s	
5962/29850 (epoch 9.987), train_loss = 1.25560194, grad/param norm = 1.6489e-01, time/batch = 0.6603s	
5963/29850 (epoch 9.988), train_loss = 1.18389471, grad/param norm = 1.5723e-01, time/batch = 0.6664s	
5964/29850 (epoch 9.990), train_loss = 1.27914325, grad/param norm = 1.6909e-01, time/batch = 0.6630s	
5965/29850 (epoch 9.992), train_loss = 1.28383786, grad/param norm = 1.6606e-01, time/batch = 0.6783s	
5966/29850 (epoch 9.993), train_loss = 1.30800416, grad/param norm = 1.8718e-01, time/batch = 0.6801s	
5967/29850 (epoch 9.995), train_loss = 1.34192563, grad/param norm = 1.9161e-01, time/batch = 0.6674s	
5968/29850 (epoch 9.997), train_loss = 1.29963347, grad/param norm = 1.8106e-01, time/batch = 0.6687s	
5969/29850 (epoch 9.998), train_loss = 1.39546379, grad/param norm = 1.8611e-01, time/batch = 0.6726s	
decayed learning rate by a factor 0.97 to 0.00194	
5970/29850 (epoch 10.000), train_loss = 1.25476623, grad/param norm = 1.6157e-01, time/batch = 0.6649s	
5971/29850 (epoch 10.002), train_loss = 1.50573712, grad/param norm = 1.8636e-01, time/batch = 0.6600s	
5972/29850 (epoch 10.003), train_loss = 1.25596645, grad/param norm = 1.7420e-01, time/batch = 0.6668s	
5973/29850 (epoch 10.005), train_loss = 1.31328237, grad/param norm = 1.7652e-01, time/batch = 0.6648s	
5974/29850 (epoch 10.007), train_loss = 1.33867699, grad/param norm = 1.8232e-01, time/batch = 0.6651s	
5975/29850 (epoch 10.008), train_loss = 1.52935652, grad/param norm = 1.9764e-01, time/batch = 0.6770s	
5976/29850 (epoch 10.010), train_loss = 1.17730211, grad/param norm = 1.7208e-01, time/batch = 0.6691s	
5977/29850 (epoch 10.012), train_loss = 1.35772575, grad/param norm = 1.8181e-01, time/batch = 0.6709s	
5978/29850 (epoch 10.013), train_loss = 1.40768365, grad/param norm = 1.9553e-01, time/batch = 0.6748s	
5979/29850 (epoch 10.015), train_loss = 1.36484403, grad/param norm = 1.7939e-01, time/batch = 0.6702s	
5980/29850 (epoch 10.017), train_loss = 1.46259783, grad/param norm = 1.9797e-01, time/batch = 0.6605s	
5981/29850 (epoch 10.018), train_loss = 1.48772095, grad/param norm = 2.0268e-01, time/batch = 0.6730s	
5982/29850 (epoch 10.020), train_loss = 1.26431079, grad/param norm = 1.7697e-01, time/batch = 0.6740s	
5983/29850 (epoch 10.022), train_loss = 1.42508120, grad/param norm = 1.9564e-01, time/batch = 0.6694s	
5984/29850 (epoch 10.023), train_loss = 1.33215856, grad/param norm = 1.6370e-01, time/batch = 0.6856s	
5985/29850 (epoch 10.025), train_loss = 1.27493662, grad/param norm = 1.6167e-01, time/batch = 0.6792s	
5986/29850 (epoch 10.027), train_loss = 1.16104745, grad/param norm = 1.5136e-01, time/batch = 0.6632s	
5987/29850 (epoch 10.028), train_loss = 1.26069193, grad/param norm = 1.5980e-01, time/batch = 0.6634s	
5988/29850 (epoch 10.030), train_loss = 1.37205784, grad/param norm = 1.7306e-01, time/batch = 0.6596s	
5989/29850 (epoch 10.032), train_loss = 1.27840508, grad/param norm = 1.6528e-01, time/batch = 0.6600s	
5990/29850 (epoch 10.034), train_loss = 1.28018696, grad/param norm = 1.8076e-01, time/batch = 0.6571s	
5991/29850 (epoch 10.035), train_loss = 1.17102583, grad/param norm = 1.5268e-01, time/batch = 0.6614s	
5992/29850 (epoch 10.037), train_loss = 1.36357264, grad/param norm = 1.8338e-01, time/batch = 0.6642s	
5993/29850 (epoch 10.039), train_loss = 1.14701161, grad/param norm = 1.4828e-01, time/batch = 0.6581s	
5994/29850 (epoch 10.040), train_loss = 1.19387397, grad/param norm = 1.7117e-01, time/batch = 0.6572s	
5995/29850 (epoch 10.042), train_loss = 1.24691150, grad/param norm = 1.7658e-01, time/batch = 0.6582s	
5996/29850 (epoch 10.044), train_loss = 1.22385606, grad/param norm = 1.6386e-01, time/batch = 0.6635s	
5997/29850 (epoch 10.045), train_loss = 1.34838334, grad/param norm = 1.7626e-01, time/batch = 0.6601s	
5998/29850 (epoch 10.047), train_loss = 1.15679313, grad/param norm = 1.7842e-01, time/batch = 0.6592s	
5999/29850 (epoch 10.049), train_loss = 1.33240846, grad/param norm = 1.6757e-01, time/batch = 0.6601s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch10.05_1.6215.t7	
6000/29850 (epoch 10.050), train_loss = 1.20787428, grad/param norm = 1.6557e-01, time/batch = 0.6640s	
6001/29850 (epoch 10.052), train_loss = 1.72845921, grad/param norm = 2.0984e-01, time/batch = 0.6697s	
6002/29850 (epoch 10.054), train_loss = 1.36364365, grad/param norm = 1.7936e-01, time/batch = 0.6720s	
6003/29850 (epoch 10.055), train_loss = 1.28838586, grad/param norm = 1.7930e-01, time/batch = 0.6727s	
6004/29850 (epoch 10.057), train_loss = 1.35059015, grad/param norm = 1.6882e-01, time/batch = 0.6658s	
6005/29850 (epoch 10.059), train_loss = 1.40774208, grad/param norm = 1.9416e-01, time/batch = 0.6678s	
6006/29850 (epoch 10.060), train_loss = 1.31836532, grad/param norm = 1.7952e-01, time/batch = 0.6757s	
6007/29850 (epoch 10.062), train_loss = 1.44498263, grad/param norm = 2.0258e-01, time/batch = 0.6885s	
6008/29850 (epoch 10.064), train_loss = 1.37113017, grad/param norm = 1.8349e-01, time/batch = 0.6902s	
6009/29850 (epoch 10.065), train_loss = 1.19476993, grad/param norm = 1.6601e-01, time/batch = 0.6753s	
6010/29850 (epoch 10.067), train_loss = 1.32943329, grad/param norm = 1.6363e-01, time/batch = 0.6924s	
6011/29850 (epoch 10.069), train_loss = 1.29717328, grad/param norm = 1.7036e-01, time/batch = 0.6817s	
6012/29850 (epoch 10.070), train_loss = 1.33086302, grad/param norm = 1.5608e-01, time/batch = 0.6807s	
6013/29850 (epoch 10.072), train_loss = 1.40564294, grad/param norm = 1.9423e-01, time/batch = 0.6653s	
6014/29850 (epoch 10.074), train_loss = 1.38522551, grad/param norm = 1.6790e-01, time/batch = 0.6709s	
6015/29850 (epoch 10.075), train_loss = 1.22059566, grad/param norm = 1.6667e-01, time/batch = 0.6690s	
6016/29850 (epoch 10.077), train_loss = 1.31203709, grad/param norm = 1.8495e-01, time/batch = 0.6671s	
6017/29850 (epoch 10.079), train_loss = 1.55289519, grad/param norm = 1.9208e-01, time/batch = 0.6659s	
6018/29850 (epoch 10.080), train_loss = 1.46767639, grad/param norm = 2.0102e-01, time/batch = 0.6777s	
6019/29850 (epoch 10.082), train_loss = 1.34084197, grad/param norm = 1.6192e-01, time/batch = 0.6629s	
6020/29850 (epoch 10.084), train_loss = 1.41782584, grad/param norm = 1.8835e-01, time/batch = 0.6600s	
6021/29850 (epoch 10.085), train_loss = 1.34465108, grad/param norm = 1.8770e-01, time/batch = 0.6620s	
6022/29850 (epoch 10.087), train_loss = 1.46825303, grad/param norm = 1.8002e-01, time/batch = 0.6735s	
6023/29850 (epoch 10.089), train_loss = 1.38226979, grad/param norm = 1.7147e-01, time/batch = 0.6659s	
6024/29850 (epoch 10.090), train_loss = 1.39880651, grad/param norm = 1.9526e-01, time/batch = 0.6626s	
6025/29850 (epoch 10.092), train_loss = 1.28011975, grad/param norm = 1.7191e-01, time/batch = 0.6642s	
6026/29850 (epoch 10.094), train_loss = 1.36842972, grad/param norm = 1.7507e-01, time/batch = 0.6657s	
6027/29850 (epoch 10.095), train_loss = 1.37320045, grad/param norm = 1.6694e-01, time/batch = 0.6773s	
6028/29850 (epoch 10.097), train_loss = 1.13151184, grad/param norm = 1.5017e-01, time/batch = 0.6873s	
6029/29850 (epoch 10.099), train_loss = 1.17233521, grad/param norm = 1.5188e-01, time/batch = 0.6617s	
6030/29850 (epoch 10.101), train_loss = 1.45213677, grad/param norm = 1.8050e-01, time/batch = 0.6578s	
6031/29850 (epoch 10.102), train_loss = 1.38012438, grad/param norm = 1.7550e-01, time/batch = 0.6642s	
6032/29850 (epoch 10.104), train_loss = 1.28611637, grad/param norm = 1.6268e-01, time/batch = 0.6608s	
6033/29850 (epoch 10.106), train_loss = 1.40507308, grad/param norm = 1.7643e-01, time/batch = 0.6590s	
6034/29850 (epoch 10.107), train_loss = 1.16906847, grad/param norm = 1.5432e-01, time/batch = 0.6602s	
6035/29850 (epoch 10.109), train_loss = 1.27462171, grad/param norm = 1.8120e-01, time/batch = 0.6619s	
6036/29850 (epoch 10.111), train_loss = 1.41196975, grad/param norm = 1.7960e-01, time/batch = 0.6612s	
6037/29850 (epoch 10.112), train_loss = 1.22325890, grad/param norm = 1.7355e-01, time/batch = 0.6640s	
6038/29850 (epoch 10.114), train_loss = 1.37248645, grad/param norm = 1.9338e-01, time/batch = 0.6645s	
6039/29850 (epoch 10.116), train_loss = 1.23538380, grad/param norm = 1.7464e-01, time/batch = 0.6640s	
6040/29850 (epoch 10.117), train_loss = 1.32507664, grad/param norm = 1.7304e-01, time/batch = 0.6695s	
6041/29850 (epoch 10.119), train_loss = 1.29703363, grad/param norm = 1.5799e-01, time/batch = 0.6803s	
6042/29850 (epoch 10.121), train_loss = 1.11296806, grad/param norm = 1.6717e-01, time/batch = 0.6625s	
6043/29850 (epoch 10.122), train_loss = 1.16571013, grad/param norm = 1.5476e-01, time/batch = 0.6722s	
6044/29850 (epoch 10.124), train_loss = 1.26067866, grad/param norm = 1.7393e-01, time/batch = 0.6660s	
6045/29850 (epoch 10.126), train_loss = 1.29860913, grad/param norm = 1.8718e-01, time/batch = 0.6585s	
6046/29850 (epoch 10.127), train_loss = 1.47960433, grad/param norm = 1.8654e-01, time/batch = 0.6607s	
6047/29850 (epoch 10.129), train_loss = 1.26677807, grad/param norm = 1.7540e-01, time/batch = 0.6641s	
6048/29850 (epoch 10.131), train_loss = 1.28398059, grad/param norm = 1.8496e-01, time/batch = 0.6679s	
6049/29850 (epoch 10.132), train_loss = 1.20436178, grad/param norm = 1.7436e-01, time/batch = 0.6619s	
6050/29850 (epoch 10.134), train_loss = 1.38488910, grad/param norm = 1.7826e-01, time/batch = 0.6605s	
6051/29850 (epoch 10.136), train_loss = 1.35755826, grad/param norm = 1.7287e-01, time/batch = 0.6628s	
6052/29850 (epoch 10.137), train_loss = 1.21828271, grad/param norm = 1.6876e-01, time/batch = 0.6614s	
6053/29850 (epoch 10.139), train_loss = 1.21960589, grad/param norm = 1.6675e-01, time/batch = 0.6574s	
6054/29850 (epoch 10.141), train_loss = 1.29281564, grad/param norm = 1.7451e-01, time/batch = 0.6669s	
6055/29850 (epoch 10.142), train_loss = 1.38683451, grad/param norm = 1.8318e-01, time/batch = 0.6828s	
6056/29850 (epoch 10.144), train_loss = 1.55374263, grad/param norm = 2.0194e-01, time/batch = 0.6599s	
6057/29850 (epoch 10.146), train_loss = 1.53802853, grad/param norm = 2.0938e-01, time/batch = 0.6630s	
6058/29850 (epoch 10.147), train_loss = 1.43442150, grad/param norm = 1.9501e-01, time/batch = 0.6662s	
6059/29850 (epoch 10.149), train_loss = 1.41015785, grad/param norm = 1.7673e-01, time/batch = 0.6870s	
6060/29850 (epoch 10.151), train_loss = 1.35286102, grad/param norm = 1.8553e-01, time/batch = 0.6770s	
6061/29850 (epoch 10.152), train_loss = 1.24794133, grad/param norm = 1.7414e-01, time/batch = 0.6869s	
6062/29850 (epoch 10.154), train_loss = 1.24781845, grad/param norm = 1.6715e-01, time/batch = 0.6610s	
6063/29850 (epoch 10.156), train_loss = 1.24284009, grad/param norm = 1.6674e-01, time/batch = 0.6556s	
6064/29850 (epoch 10.157), train_loss = 1.28274357, grad/param norm = 1.5649e-01, time/batch = 0.6619s	
6065/29850 (epoch 10.159), train_loss = 1.33690986, grad/param norm = 1.6194e-01, time/batch = 0.6858s	
6066/29850 (epoch 10.161), train_loss = 1.36773173, grad/param norm = 1.9533e-01, time/batch = 0.6788s	
6067/29850 (epoch 10.162), train_loss = 1.48744132, grad/param norm = 1.8761e-01, time/batch = 0.6787s	
6068/29850 (epoch 10.164), train_loss = 1.33598084, grad/param norm = 1.8791e-01, time/batch = 0.6709s	
6069/29850 (epoch 10.166), train_loss = 1.18677008, grad/param norm = 1.5393e-01, time/batch = 0.6654s	
6070/29850 (epoch 10.168), train_loss = 1.11370017, grad/param norm = 1.6131e-01, time/batch = 0.6555s	
6071/29850 (epoch 10.169), train_loss = 1.48384921, grad/param norm = 1.8700e-01, time/batch = 0.6591s	
6072/29850 (epoch 10.171), train_loss = 1.44005118, grad/param norm = 1.8798e-01, time/batch = 0.6545s	
6073/29850 (epoch 10.173), train_loss = 1.32084160, grad/param norm = 2.0036e-01, time/batch = 0.6555s	
6074/29850 (epoch 10.174), train_loss = 1.40950740, grad/param norm = 1.8917e-01, time/batch = 0.6539s	
6075/29850 (epoch 10.176), train_loss = 1.37192367, grad/param norm = 1.8154e-01, time/batch = 0.6552s	
6076/29850 (epoch 10.178), train_loss = 1.37307579, grad/param norm = 1.8098e-01, time/batch = 0.6576s	
6077/29850 (epoch 10.179), train_loss = 1.13147601, grad/param norm = 1.6199e-01, time/batch = 0.6754s	
6078/29850 (epoch 10.181), train_loss = 1.29246977, grad/param norm = 1.6414e-01, time/batch = 0.6588s	
6079/29850 (epoch 10.183), train_loss = 1.27717536, grad/param norm = 1.7590e-01, time/batch = 0.6644s	
6080/29850 (epoch 10.184), train_loss = 1.27354026, grad/param norm = 1.8257e-01, time/batch = 0.6568s	
6081/29850 (epoch 10.186), train_loss = 1.25757633, grad/param norm = 1.6655e-01, time/batch = 0.6568s	
6082/29850 (epoch 10.188), train_loss = 1.38687680, grad/param norm = 1.8599e-01, time/batch = 0.6617s	
6083/29850 (epoch 10.189), train_loss = 1.49606268, grad/param norm = 1.8103e-01, time/batch = 0.6636s	
6084/29850 (epoch 10.191), train_loss = 1.36760461, grad/param norm = 1.8276e-01, time/batch = 0.6632s	
6085/29850 (epoch 10.193), train_loss = 1.20358572, grad/param norm = 1.6268e-01, time/batch = 0.6643s	
6086/29850 (epoch 10.194), train_loss = 1.35157802, grad/param norm = 1.8242e-01, time/batch = 0.6636s	
6087/29850 (epoch 10.196), train_loss = 1.29155511, grad/param norm = 1.7445e-01, time/batch = 0.6631s	
6088/29850 (epoch 10.198), train_loss = 1.29460296, grad/param norm = 1.7284e-01, time/batch = 0.6729s	
6089/29850 (epoch 10.199), train_loss = 1.58213882, grad/param norm = 1.9452e-01, time/batch = 0.6711s	
6090/29850 (epoch 10.201), train_loss = 1.28297947, grad/param norm = 1.8129e-01, time/batch = 0.6633s	
6091/29850 (epoch 10.203), train_loss = 1.22248164, grad/param norm = 1.7044e-01, time/batch = 0.6614s	
6092/29850 (epoch 10.204), train_loss = 1.38422770, grad/param norm = 1.9352e-01, time/batch = 0.6588s	
6093/29850 (epoch 10.206), train_loss = 1.22453300, grad/param norm = 1.8808e-01, time/batch = 0.6527s	
6094/29850 (epoch 10.208), train_loss = 1.51418392, grad/param norm = 1.8509e-01, time/batch = 0.6538s	
6095/29850 (epoch 10.209), train_loss = 1.23406025, grad/param norm = 1.7653e-01, time/batch = 0.6593s	
6096/29850 (epoch 10.211), train_loss = 1.26315836, grad/param norm = 1.6387e-01, time/batch = 0.6783s	
6097/29850 (epoch 10.213), train_loss = 1.46805913, grad/param norm = 1.8941e-01, time/batch = 0.6852s	
6098/29850 (epoch 10.214), train_loss = 1.22194937, grad/param norm = 1.5733e-01, time/batch = 0.6756s	
6099/29850 (epoch 10.216), train_loss = 1.28950639, grad/param norm = 1.8285e-01, time/batch = 0.6611s	
6100/29850 (epoch 10.218), train_loss = 1.38731458, grad/param norm = 1.7370e-01, time/batch = 0.6603s	
6101/29850 (epoch 10.219), train_loss = 1.50278562, grad/param norm = 2.0484e-01, time/batch = 0.6657s	
6102/29850 (epoch 10.221), train_loss = 1.30070986, grad/param norm = 1.9839e-01, time/batch = 0.6640s	
6103/29850 (epoch 10.223), train_loss = 1.30051980, grad/param norm = 1.8333e-01, time/batch = 0.6662s	
6104/29850 (epoch 10.224), train_loss = 1.19783833, grad/param norm = 1.7798e-01, time/batch = 0.6750s	
6105/29850 (epoch 10.226), train_loss = 1.21043997, grad/param norm = 1.6455e-01, time/batch = 0.6622s	
6106/29850 (epoch 10.228), train_loss = 1.25189547, grad/param norm = 1.6474e-01, time/batch = 0.6578s	
6107/29850 (epoch 10.229), train_loss = 1.15257831, grad/param norm = 1.6145e-01, time/batch = 0.6614s	
6108/29850 (epoch 10.231), train_loss = 1.23562287, grad/param norm = 1.6120e-01, time/batch = 0.6525s	
6109/29850 (epoch 10.233), train_loss = 1.28849678, grad/param norm = 1.6691e-01, time/batch = 0.6579s	
6110/29850 (epoch 10.235), train_loss = 1.20481188, grad/param norm = 1.4488e-01, time/batch = 0.6744s	
6111/29850 (epoch 10.236), train_loss = 1.46565281, grad/param norm = 2.0961e-01, time/batch = 0.6676s	
6112/29850 (epoch 10.238), train_loss = 1.15174374, grad/param norm = 1.7707e-01, time/batch = 0.6578s	
6113/29850 (epoch 10.240), train_loss = 1.25279379, grad/param norm = 1.7382e-01, time/batch = 0.6548s	
6114/29850 (epoch 10.241), train_loss = 1.47210298, grad/param norm = 1.9424e-01, time/batch = 0.6542s	
6115/29850 (epoch 10.243), train_loss = 1.29238145, grad/param norm = 1.7762e-01, time/batch = 0.6582s	
6116/29850 (epoch 10.245), train_loss = 1.25855051, grad/param norm = 1.9123e-01, time/batch = 0.6539s	
6117/29850 (epoch 10.246), train_loss = 1.22476435, grad/param norm = 1.8305e-01, time/batch = 0.6578s	
6118/29850 (epoch 10.248), train_loss = 1.23421123, grad/param norm = 1.7192e-01, time/batch = 0.6555s	
6119/29850 (epoch 10.250), train_loss = 1.29605646, grad/param norm = 1.6360e-01, time/batch = 0.6523s	
6120/29850 (epoch 10.251), train_loss = 1.19956817, grad/param norm = 1.7687e-01, time/batch = 0.6536s	
6121/29850 (epoch 10.253), train_loss = 1.16697949, grad/param norm = 1.7843e-01, time/batch = 0.6578s	
6122/29850 (epoch 10.255), train_loss = 1.20839738, grad/param norm = 1.6620e-01, time/batch = 0.6602s	
6123/29850 (epoch 10.256), train_loss = 1.32541774, grad/param norm = 1.7632e-01, time/batch = 0.6578s	
6124/29850 (epoch 10.258), train_loss = 1.28355605, grad/param norm = 1.7005e-01, time/batch = 0.6603s	
6125/29850 (epoch 10.260), train_loss = 1.25799944, grad/param norm = 1.6922e-01, time/batch = 0.6808s	
6126/29850 (epoch 10.261), train_loss = 1.25242033, grad/param norm = 1.7018e-01, time/batch = 0.6684s	
6127/29850 (epoch 10.263), train_loss = 1.16834848, grad/param norm = 1.6356e-01, time/batch = 0.6791s	
6128/29850 (epoch 10.265), train_loss = 1.24559340, grad/param norm = 1.8115e-01, time/batch = 0.6730s	
6129/29850 (epoch 10.266), train_loss = 1.27262676, grad/param norm = 1.8750e-01, time/batch = 0.6611s	
6130/29850 (epoch 10.268), train_loss = 1.23860866, grad/param norm = 1.7134e-01, time/batch = 0.6555s	
6131/29850 (epoch 10.270), train_loss = 1.19363118, grad/param norm = 1.6088e-01, time/batch = 0.6569s	
6132/29850 (epoch 10.271), train_loss = 1.38092711, grad/param norm = 1.7217e-01, time/batch = 0.6637s	
6133/29850 (epoch 10.273), train_loss = 1.14857086, grad/param norm = 1.5821e-01, time/batch = 0.6582s	
6134/29850 (epoch 10.275), train_loss = 1.18074442, grad/param norm = 1.7061e-01, time/batch = 0.6528s	
6135/29850 (epoch 10.276), train_loss = 1.17948864, grad/param norm = 1.6403e-01, time/batch = 0.8147s	
6136/29850 (epoch 10.278), train_loss = 1.25474344, grad/param norm = 1.7031e-01, time/batch = 0.9866s	
6137/29850 (epoch 10.280), train_loss = 1.40844198, grad/param norm = 1.8672e-01, time/batch = 0.9785s	
6138/29850 (epoch 10.281), train_loss = 1.27901562, grad/param norm = 1.7937e-01, time/batch = 0.9604s	
6139/29850 (epoch 10.283), train_loss = 1.38245179, grad/param norm = 1.9566e-01, time/batch = 0.9637s	
6140/29850 (epoch 10.285), train_loss = 1.24782545, grad/param norm = 1.6767e-01, time/batch = 1.2695s	
6141/29850 (epoch 10.286), train_loss = 1.31189901, grad/param norm = 1.7383e-01, time/batch = 1.8096s	
6142/29850 (epoch 10.288), train_loss = 1.47401506, grad/param norm = 2.2409e-01, time/batch = 1.7930s	
6143/29850 (epoch 10.290), train_loss = 1.22231076, grad/param norm = 1.6714e-01, time/batch = 13.1525s	
6144/29850 (epoch 10.291), train_loss = 1.56562058, grad/param norm = 1.8612e-01, time/batch = 15.8477s	
6145/29850 (epoch 10.293), train_loss = 1.37359288, grad/param norm = 1.7937e-01, time/batch = 18.1024s	
6146/29850 (epoch 10.295), train_loss = 1.46845390, grad/param norm = 1.8286e-01, time/batch = 18.7016s	
6147/29850 (epoch 10.296), train_loss = 1.22118121, grad/param norm = 1.5888e-01, time/batch = 18.7051s	
6148/29850 (epoch 10.298), train_loss = 1.08245585, grad/param norm = 1.6613e-01, time/batch = 6.5036s	
6149/29850 (epoch 10.300), train_loss = 1.15383288, grad/param norm = 1.5180e-01, time/batch = 0.6668s	
6150/29850 (epoch 10.302), train_loss = 1.15164647, grad/param norm = 1.6307e-01, time/batch = 0.6646s	
6151/29850 (epoch 10.303), train_loss = 1.24983347, grad/param norm = 1.7121e-01, time/batch = 0.6598s	
6152/29850 (epoch 10.305), train_loss = 1.25861527, grad/param norm = 1.6360e-01, time/batch = 0.6619s	
6153/29850 (epoch 10.307), train_loss = 1.38454213, grad/param norm = 1.7658e-01, time/batch = 0.6673s	
6154/29850 (epoch 10.308), train_loss = 1.29969756, grad/param norm = 1.8261e-01, time/batch = 0.6601s	
6155/29850 (epoch 10.310), train_loss = 1.30877501, grad/param norm = 1.6972e-01, time/batch = 0.7498s	
6156/29850 (epoch 10.312), train_loss = 1.39292134, grad/param norm = 1.8279e-01, time/batch = 0.9767s	
6157/29850 (epoch 10.313), train_loss = 1.34717783, grad/param norm = 1.8620e-01, time/batch = 0.9966s	
6158/29850 (epoch 10.315), train_loss = 1.32604873, grad/param norm = 1.6755e-01, time/batch = 0.9527s	
6159/29850 (epoch 10.317), train_loss = 1.33471923, grad/param norm = 1.9075e-01, time/batch = 0.9680s	
6160/29850 (epoch 10.318), train_loss = 1.30124901, grad/param norm = 1.8231e-01, time/batch = 1.0120s	
6161/29850 (epoch 10.320), train_loss = 1.18953982, grad/param norm = 1.6978e-01, time/batch = 1.8032s	
6162/29850 (epoch 10.322), train_loss = 1.44865854, grad/param norm = 1.9011e-01, time/batch = 1.8196s	
6163/29850 (epoch 10.323), train_loss = 1.33684139, grad/param norm = 1.9195e-01, time/batch = 6.3620s	
6164/29850 (epoch 10.325), train_loss = 1.30392229, grad/param norm = 1.6959e-01, time/batch = 17.8800s	
6165/29850 (epoch 10.327), train_loss = 1.44126856, grad/param norm = 1.9089e-01, time/batch = 16.9523s	
6166/29850 (epoch 10.328), train_loss = 1.44109185, grad/param norm = 1.8072e-01, time/batch = 17.7843s	
6167/29850 (epoch 10.330), train_loss = 1.30086313, grad/param norm = 1.7009e-01, time/batch = 15.1283s	
6168/29850 (epoch 10.332), train_loss = 1.21406305, grad/param norm = 1.6578e-01, time/batch = 18.9624s	
6169/29850 (epoch 10.333), train_loss = 1.45659273, grad/param norm = 1.7866e-01, time/batch = 16.6174s	
6170/29850 (epoch 10.335), train_loss = 1.34074952, grad/param norm = 1.7650e-01, time/batch = 18.7054s	
6171/29850 (epoch 10.337), train_loss = 1.32460296, grad/param norm = 1.7493e-01, time/batch = 16.0587s	
6172/29850 (epoch 10.338), train_loss = 1.30299913, grad/param norm = 1.7084e-01, time/batch = 16.4722s	
6173/29850 (epoch 10.340), train_loss = 1.18287853, grad/param norm = 1.7147e-01, time/batch = 18.6062s	
6174/29850 (epoch 10.342), train_loss = 1.33436725, grad/param norm = 1.7641e-01, time/batch = 16.6414s	
6175/29850 (epoch 10.343), train_loss = 1.34807979, grad/param norm = 1.9649e-01, time/batch = 18.5484s	
6176/29850 (epoch 10.345), train_loss = 1.40712507, grad/param norm = 2.0279e-01, time/batch = 17.5365s	
6177/29850 (epoch 10.347), train_loss = 1.40278149, grad/param norm = 1.8873e-01, time/batch = 18.6187s	
6178/29850 (epoch 10.348), train_loss = 1.26778182, grad/param norm = 1.5872e-01, time/batch = 19.2109s	
6179/29850 (epoch 10.350), train_loss = 1.39187365, grad/param norm = 1.8048e-01, time/batch = 16.2802s	
6180/29850 (epoch 10.352), train_loss = 1.31611511, grad/param norm = 1.7085e-01, time/batch = 17.7970s	
6181/29850 (epoch 10.353), train_loss = 1.36067513, grad/param norm = 1.8006e-01, time/batch = 16.1991s	
6182/29850 (epoch 10.355), train_loss = 1.18919753, grad/param norm = 1.7188e-01, time/batch = 16.9594s	
6183/29850 (epoch 10.357), train_loss = 1.44531425, grad/param norm = 1.7498e-01, time/batch = 16.0188s	
6184/29850 (epoch 10.358), train_loss = 1.16547544, grad/param norm = 1.6065e-01, time/batch = 17.4653s	
6185/29850 (epoch 10.360), train_loss = 1.30762730, grad/param norm = 1.7935e-01, time/batch = 19.7131s	
6186/29850 (epoch 10.362), train_loss = 1.27318412, grad/param norm = 1.7774e-01, time/batch = 17.2164s	
6187/29850 (epoch 10.363), train_loss = 1.31746971, grad/param norm = 1.7406e-01, time/batch = 18.2195s	
6188/29850 (epoch 10.365), train_loss = 1.45443112, grad/param norm = 1.8641e-01, time/batch = 18.7102s	
6189/29850 (epoch 10.367), train_loss = 1.27266984, grad/param norm = 1.7039e-01, time/batch = 17.3725s	
6190/29850 (epoch 10.369), train_loss = 1.21739868, grad/param norm = 1.8358e-01, time/batch = 18.6218s	
6191/29850 (epoch 10.370), train_loss = 1.11977088, grad/param norm = 1.6494e-01, time/batch = 17.9623s	
6192/29850 (epoch 10.372), train_loss = 1.49113927, grad/param norm = 2.0169e-01, time/batch = 17.7011s	
6193/29850 (epoch 10.374), train_loss = 1.28384161, grad/param norm = 1.8706e-01, time/batch = 17.8614s	
6194/29850 (epoch 10.375), train_loss = 1.28768571, grad/param norm = 1.6807e-01, time/batch = 17.5590s	
6195/29850 (epoch 10.377), train_loss = 1.34294986, grad/param norm = 1.8507e-01, time/batch = 20.1973s	
6196/29850 (epoch 10.379), train_loss = 1.37758571, grad/param norm = 1.7528e-01, time/batch = 16.9536s	
6197/29850 (epoch 10.380), train_loss = 1.35547992, grad/param norm = 1.8299e-01, time/batch = 18.2029s	
6198/29850 (epoch 10.382), train_loss = 1.36136957, grad/param norm = 1.8796e-01, time/batch = 17.7181s	
6199/29850 (epoch 10.384), train_loss = 1.32369974, grad/param norm = 1.8554e-01, time/batch = 15.4991s	
6200/29850 (epoch 10.385), train_loss = 1.29124548, grad/param norm = 1.7607e-01, time/batch = 17.2701s	
6201/29850 (epoch 10.387), train_loss = 1.34152596, grad/param norm = 2.0193e-01, time/batch = 16.6431s	
6202/29850 (epoch 10.389), train_loss = 1.46695839, grad/param norm = 1.6918e-01, time/batch = 17.8825s	
6203/29850 (epoch 10.390), train_loss = 1.35030308, grad/param norm = 1.6834e-01, time/batch = 15.8664s	
6204/29850 (epoch 10.392), train_loss = 1.29210492, grad/param norm = 1.8645e-01, time/batch = 19.8718s	
6205/29850 (epoch 10.394), train_loss = 1.39608074, grad/param norm = 1.8008e-01, time/batch = 16.0453s	
6206/29850 (epoch 10.395), train_loss = 1.33476028, grad/param norm = 1.9019e-01, time/batch = 17.7036s	
6207/29850 (epoch 10.397), train_loss = 1.27820793, grad/param norm = 1.7291e-01, time/batch = 18.9564s	
6208/29850 (epoch 10.399), train_loss = 1.20376565, grad/param norm = 1.7107e-01, time/batch = 15.2947s	
6209/29850 (epoch 10.400), train_loss = 1.58292620, grad/param norm = 2.1497e-01, time/batch = 18.2210s	
6210/29850 (epoch 10.402), train_loss = 1.44793662, grad/param norm = 1.8355e-01, time/batch = 17.8718s	
6211/29850 (epoch 10.404), train_loss = 1.38519832, grad/param norm = 1.8371e-01, time/batch = 19.4659s	
6212/29850 (epoch 10.405), train_loss = 1.37036288, grad/param norm = 2.0675e-01, time/batch = 16.8192s	
6213/29850 (epoch 10.407), train_loss = 1.29119155, grad/param norm = 1.9708e-01, time/batch = 16.5404s	
6214/29850 (epoch 10.409), train_loss = 1.48939450, grad/param norm = 2.1682e-01, time/batch = 17.1424s	
6215/29850 (epoch 10.410), train_loss = 1.47419620, grad/param norm = 1.8036e-01, time/batch = 16.6415s	
6216/29850 (epoch 10.412), train_loss = 1.34702267, grad/param norm = 1.8067e-01, time/batch = 17.7789s	
6217/29850 (epoch 10.414), train_loss = 1.37221870, grad/param norm = 1.9848e-01, time/batch = 17.2788s	
6218/29850 (epoch 10.415), train_loss = 1.31687365, grad/param norm = 1.6113e-01, time/batch = 18.3743s	
6219/29850 (epoch 10.417), train_loss = 1.46721891, grad/param norm = 1.8490e-01, time/batch = 16.6029s	
6220/29850 (epoch 10.419), train_loss = 1.36002514, grad/param norm = 1.9147e-01, time/batch = 17.2123s	
6221/29850 (epoch 10.420), train_loss = 1.29700092, grad/param norm = 1.6818e-01, time/batch = 19.7860s	
6222/29850 (epoch 10.422), train_loss = 1.27588808, grad/param norm = 1.6851e-01, time/batch = 17.3795s	
6223/29850 (epoch 10.424), train_loss = 1.33665104, grad/param norm = 1.8139e-01, time/batch = 18.5422s	
6224/29850 (epoch 10.425), train_loss = 1.55701024, grad/param norm = 1.8226e-01, time/batch = 18.0201s	
6225/29850 (epoch 10.427), train_loss = 1.17940755, grad/param norm = 1.9705e-01, time/batch = 14.9618s	
6226/29850 (epoch 10.429), train_loss = 1.20225975, grad/param norm = 1.7076e-01, time/batch = 16.3931s	
6227/29850 (epoch 10.430), train_loss = 1.13495783, grad/param norm = 1.6227e-01, time/batch = 18.0266s	
6228/29850 (epoch 10.432), train_loss = 1.28728176, grad/param norm = 1.7333e-01, time/batch = 18.2098s	
6229/29850 (epoch 10.434), train_loss = 1.20582862, grad/param norm = 1.7185e-01, time/batch = 19.3572s	
6230/29850 (epoch 10.436), train_loss = 1.37177834, grad/param norm = 1.8477e-01, time/batch = 26.4192s	
6231/29850 (epoch 10.437), train_loss = 1.36279033, grad/param norm = 1.6788e-01, time/batch = 22.5856s	
6232/29850 (epoch 10.439), train_loss = 1.33633977, grad/param norm = 1.7187e-01, time/batch = 17.8706s	
6233/29850 (epoch 10.441), train_loss = 1.34149621, grad/param norm = 1.8752e-01, time/batch = 15.8692s	
6234/29850 (epoch 10.442), train_loss = 1.34596195, grad/param norm = 1.8084e-01, time/batch = 15.1241s	
6235/29850 (epoch 10.444), train_loss = 1.29300206, grad/param norm = 1.6095e-01, time/batch = 19.4516s	
6236/29850 (epoch 10.446), train_loss = 1.35575155, grad/param norm = 1.6997e-01, time/batch = 17.1159s	
6237/29850 (epoch 10.447), train_loss = 1.41866079, grad/param norm = 1.9178e-01, time/batch = 17.5523s	
6238/29850 (epoch 10.449), train_loss = 1.42253751, grad/param norm = 1.9017e-01, time/batch = 19.1240s	
6239/29850 (epoch 10.451), train_loss = 1.20113052, grad/param norm = 1.8230e-01, time/batch = 18.1192s	
6240/29850 (epoch 10.452), train_loss = 1.05297776, grad/param norm = 1.5610e-01, time/batch = 19.5190s	
6241/29850 (epoch 10.454), train_loss = 1.17991770, grad/param norm = 1.5216e-01, time/batch = 17.1335s	
6242/29850 (epoch 10.456), train_loss = 1.39633957, grad/param norm = 1.8212e-01, time/batch = 16.2850s	
6243/29850 (epoch 10.457), train_loss = 1.43888484, grad/param norm = 2.2360e-01, time/batch = 17.6884s	
6244/29850 (epoch 10.459), train_loss = 1.50285673, grad/param norm = 1.9503e-01, time/batch = 19.1804s	
6245/29850 (epoch 10.461), train_loss = 1.49581329, grad/param norm = 1.7333e-01, time/batch = 18.6953s	
6246/29850 (epoch 10.462), train_loss = 1.41581310, grad/param norm = 1.8113e-01, time/batch = 16.7108s	
6247/29850 (epoch 10.464), train_loss = 1.33139241, grad/param norm = 1.6507e-01, time/batch = 17.3053s	
6248/29850 (epoch 10.466), train_loss = 1.20500600, grad/param norm = 1.7818e-01, time/batch = 18.4727s	
6249/29850 (epoch 10.467), train_loss = 1.34381577, grad/param norm = 1.7957e-01, time/batch = 18.1316s	
6250/29850 (epoch 10.469), train_loss = 1.30470617, grad/param norm = 1.6807e-01, time/batch = 18.5283s	
6251/29850 (epoch 10.471), train_loss = 1.31455240, grad/param norm = 1.7072e-01, time/batch = 15.3828s	
6252/29850 (epoch 10.472), train_loss = 1.22042201, grad/param norm = 1.7344e-01, time/batch = 16.3815s	
6253/29850 (epoch 10.474), train_loss = 1.46214285, grad/param norm = 1.7607e-01, time/batch = 16.8699s	
6254/29850 (epoch 10.476), train_loss = 1.36867836, grad/param norm = 1.8484e-01, time/batch = 18.0340s	
6255/29850 (epoch 10.477), train_loss = 1.35076018, grad/param norm = 1.8087e-01, time/batch = 19.8658s	
6256/29850 (epoch 10.479), train_loss = 1.42834994, grad/param norm = 1.8168e-01, time/batch = 16.1255s	
6257/29850 (epoch 10.481), train_loss = 1.38744762, grad/param norm = 1.9544e-01, time/batch = 19.7056s	
6258/29850 (epoch 10.482), train_loss = 1.23603564, grad/param norm = 1.5499e-01, time/batch = 18.1255s	
6259/29850 (epoch 10.484), train_loss = 1.29226778, grad/param norm = 1.7401e-01, time/batch = 17.4531s	
6260/29850 (epoch 10.486), train_loss = 1.32354556, grad/param norm = 1.7698e-01, time/batch = 16.3963s	
6261/29850 (epoch 10.487), train_loss = 1.28891988, grad/param norm = 1.7815e-01, time/batch = 18.6383s	
6262/29850 (epoch 10.489), train_loss = 1.32603352, grad/param norm = 1.8155e-01, time/batch = 16.5442s	
6263/29850 (epoch 10.491), train_loss = 1.18017249, grad/param norm = 1.5628e-01, time/batch = 15.7991s	
6264/29850 (epoch 10.492), train_loss = 1.37198437, grad/param norm = 1.7681e-01, time/batch = 15.6458s	
6265/29850 (epoch 10.494), train_loss = 1.47948373, grad/param norm = 1.7063e-01, time/batch = 16.8931s	
6266/29850 (epoch 10.496), train_loss = 1.49229677, grad/param norm = 1.7550e-01, time/batch = 18.2133s	
6267/29850 (epoch 10.497), train_loss = 1.36947776, grad/param norm = 1.7656e-01, time/batch = 15.4509s	
6268/29850 (epoch 10.499), train_loss = 1.34901524, grad/param norm = 1.7005e-01, time/batch = 18.2235s	
6269/29850 (epoch 10.501), train_loss = 1.27068633, grad/param norm = 1.7260e-01, time/batch = 17.0200s	
6270/29850 (epoch 10.503), train_loss = 1.29639831, grad/param norm = 1.6371e-01, time/batch = 17.2875s	
6271/29850 (epoch 10.504), train_loss = 1.50439784, grad/param norm = 1.7550e-01, time/batch = 17.2816s	
6272/29850 (epoch 10.506), train_loss = 1.54743766, grad/param norm = 1.9277e-01, time/batch = 17.3991s	
6273/29850 (epoch 10.508), train_loss = 1.28619097, grad/param norm = 1.6826e-01, time/batch = 17.3682s	
6274/29850 (epoch 10.509), train_loss = 1.12036664, grad/param norm = 1.6380e-01, time/batch = 16.6439s	
6275/29850 (epoch 10.511), train_loss = 1.30842219, grad/param norm = 1.7052e-01, time/batch = 15.1703s	
6276/29850 (epoch 10.513), train_loss = 1.39366716, grad/param norm = 1.9834e-01, time/batch = 18.3854s	
6277/29850 (epoch 10.514), train_loss = 1.19807522, grad/param norm = 1.6987e-01, time/batch = 16.8853s	
6278/29850 (epoch 10.516), train_loss = 1.20249590, grad/param norm = 1.6837e-01, time/batch = 17.4660s	
6279/29850 (epoch 10.518), train_loss = 1.18124513, grad/param norm = 1.6766e-01, time/batch = 18.6304s	
6280/29850 (epoch 10.519), train_loss = 1.17274356, grad/param norm = 1.7292e-01, time/batch = 18.2667s	
6281/29850 (epoch 10.521), train_loss = 1.18268241, grad/param norm = 1.5618e-01, time/batch = 16.2954s	
6282/29850 (epoch 10.523), train_loss = 1.15335779, grad/param norm = 1.4330e-01, time/batch = 16.9504s	
6283/29850 (epoch 10.524), train_loss = 1.29400613, grad/param norm = 1.8554e-01, time/batch = 18.8014s	
6284/29850 (epoch 10.526), train_loss = 1.39169465, grad/param norm = 1.8460e-01, time/batch = 15.5385s	
6285/29850 (epoch 10.528), train_loss = 1.48795526, grad/param norm = 1.9649e-01, time/batch = 19.0436s	
6286/29850 (epoch 10.529), train_loss = 1.41123682, grad/param norm = 1.8303e-01, time/batch = 19.0415s	
6287/29850 (epoch 10.531), train_loss = 1.35193817, grad/param norm = 2.0441e-01, time/batch = 18.5221s	
6288/29850 (epoch 10.533), train_loss = 1.26535803, grad/param norm = 1.8237e-01, time/batch = 17.7175s	
6289/29850 (epoch 10.534), train_loss = 1.28897120, grad/param norm = 1.7645e-01, time/batch = 16.7203s	
6290/29850 (epoch 10.536), train_loss = 1.31671209, grad/param norm = 1.8461e-01, time/batch = 15.8937s	
6291/29850 (epoch 10.538), train_loss = 1.40697499, grad/param norm = 1.7895e-01, time/batch = 15.5530s	
6292/29850 (epoch 10.539), train_loss = 1.44868970, grad/param norm = 1.7125e-01, time/batch = 15.3644s	
6293/29850 (epoch 10.541), train_loss = 1.13719846, grad/param norm = 1.6166e-01, time/batch = 18.4725s	
6294/29850 (epoch 10.543), train_loss = 1.29902622, grad/param norm = 1.6835e-01, time/batch = 16.7725s	
6295/29850 (epoch 10.544), train_loss = 1.33463536, grad/param norm = 1.7105e-01, time/batch = 18.0465s	
6296/29850 (epoch 10.546), train_loss = 1.40147507, grad/param norm = 1.7067e-01, time/batch = 19.8027s	
6297/29850 (epoch 10.548), train_loss = 1.19234550, grad/param norm = 1.6669e-01, time/batch = 18.2209s	
6298/29850 (epoch 10.549), train_loss = 1.25236135, grad/param norm = 1.6047e-01, time/batch = 16.2078s	
6299/29850 (epoch 10.551), train_loss = 1.22305228, grad/param norm = 1.7414e-01, time/batch = 18.2102s	
6300/29850 (epoch 10.553), train_loss = 1.34088550, grad/param norm = 1.7426e-01, time/batch = 18.6347s	
6301/29850 (epoch 10.554), train_loss = 1.08686865, grad/param norm = 1.5342e-01, time/batch = 15.7022s	
6302/29850 (epoch 10.556), train_loss = 1.28254721, grad/param norm = 1.7043e-01, time/batch = 16.3026s	
6303/29850 (epoch 10.558), train_loss = 1.23735235, grad/param norm = 1.6576e-01, time/batch = 17.3529s	
6304/29850 (epoch 10.559), train_loss = 1.34429917, grad/param norm = 1.8597e-01, time/batch = 17.4301s	
6305/29850 (epoch 10.561), train_loss = 1.38998718, grad/param norm = 1.7900e-01, time/batch = 16.1943s	
6306/29850 (epoch 10.563), train_loss = 1.28719779, grad/param norm = 1.6778e-01, time/batch = 19.3810s	
6307/29850 (epoch 10.564), train_loss = 1.27886372, grad/param norm = 1.7354e-01, time/batch = 18.3644s	
6308/29850 (epoch 10.566), train_loss = 1.25072984, grad/param norm = 1.6052e-01, time/batch = 18.1051s	
6309/29850 (epoch 10.568), train_loss = 1.39287466, grad/param norm = 1.6907e-01, time/batch = 17.2668s	
6310/29850 (epoch 10.570), train_loss = 1.32710311, grad/param norm = 1.7197e-01, time/batch = 19.8810s	
6311/29850 (epoch 10.571), train_loss = 1.35136486, grad/param norm = 1.7842e-01, time/batch = 17.8742s	
6312/29850 (epoch 10.573), train_loss = 1.46989412, grad/param norm = 2.0985e-01, time/batch = 18.4660s	
6313/29850 (epoch 10.575), train_loss = 1.42574302, grad/param norm = 1.8009e-01, time/batch = 17.2984s	
6314/29850 (epoch 10.576), train_loss = 1.46933250, grad/param norm = 1.7200e-01, time/batch = 17.8711s	
6315/29850 (epoch 10.578), train_loss = 1.35593297, grad/param norm = 1.6645e-01, time/batch = 16.4784s	
6316/29850 (epoch 10.580), train_loss = 1.41598549, grad/param norm = 1.7398e-01, time/batch = 18.1319s	
6317/29850 (epoch 10.581), train_loss = 1.25155098, grad/param norm = 1.7427e-01, time/batch = 18.5491s	
6318/29850 (epoch 10.583), train_loss = 1.29814624, grad/param norm = 1.8145e-01, time/batch = 15.4483s	
6319/29850 (epoch 10.585), train_loss = 1.32978181, grad/param norm = 1.6686e-01, time/batch = 19.3728s	
6320/29850 (epoch 10.586), train_loss = 1.35801790, grad/param norm = 1.8380e-01, time/batch = 19.2033s	
6321/29850 (epoch 10.588), train_loss = 1.24911196, grad/param norm = 1.6784e-01, time/batch = 17.2199s	
6322/29850 (epoch 10.590), train_loss = 1.31647486, grad/param norm = 1.7054e-01, time/batch = 18.3763s	
6323/29850 (epoch 10.591), train_loss = 1.23200379, grad/param norm = 1.6590e-01, time/batch = 18.5405s	
6324/29850 (epoch 10.593), train_loss = 1.22706093, grad/param norm = 1.6013e-01, time/batch = 18.2211s	
6325/29850 (epoch 10.595), train_loss = 1.20057249, grad/param norm = 1.5339e-01, time/batch = 16.1096s	
6326/29850 (epoch 10.596), train_loss = 1.17812335, grad/param norm = 1.6715e-01, time/batch = 15.0348s	
6327/29850 (epoch 10.598), train_loss = 1.19534987, grad/param norm = 1.6303e-01, time/batch = 17.8861s	
6328/29850 (epoch 10.600), train_loss = 1.42713924, grad/param norm = 1.9864e-01, time/batch = 16.2057s	
6329/29850 (epoch 10.601), train_loss = 1.18493975, grad/param norm = 1.5799e-01, time/batch = 19.5335s	
6330/29850 (epoch 10.603), train_loss = 1.30733198, grad/param norm = 1.8028e-01, time/batch = 18.3747s	
6331/29850 (epoch 10.605), train_loss = 1.33462522, grad/param norm = 1.8987e-01, time/batch = 16.8541s	
6332/29850 (epoch 10.606), train_loss = 1.07442343, grad/param norm = 1.6501e-01, time/batch = 14.6431s	
6333/29850 (epoch 10.608), train_loss = 1.30417347, grad/param norm = 1.7304e-01, time/batch = 17.4657s	
6334/29850 (epoch 10.610), train_loss = 1.29141455, grad/param norm = 1.6593e-01, time/batch = 17.8800s	
6335/29850 (epoch 10.611), train_loss = 1.12892716, grad/param norm = 1.5074e-01, time/batch = 15.2883s	
6336/29850 (epoch 10.613), train_loss = 1.06452996, grad/param norm = 1.4773e-01, time/batch = 19.1210s	
6337/29850 (epoch 10.615), train_loss = 1.14770547, grad/param norm = 1.6085e-01, time/batch = 17.4007s	
6338/29850 (epoch 10.616), train_loss = 1.24729174, grad/param norm = 1.8148e-01, time/batch = 15.8686s	
6339/29850 (epoch 10.618), train_loss = 1.29171048, grad/param norm = 1.6826e-01, time/batch = 17.3062s	
6340/29850 (epoch 10.620), train_loss = 1.33144657, grad/param norm = 1.8183e-01, time/batch = 18.9548s	
6341/29850 (epoch 10.621), train_loss = 1.37060145, grad/param norm = 1.8998e-01, time/batch = 18.7093s	
6342/29850 (epoch 10.623), train_loss = 1.39409835, grad/param norm = 1.8688e-01, time/batch = 18.2989s	
6343/29850 (epoch 10.625), train_loss = 1.35688739, grad/param norm = 1.8208e-01, time/batch = 18.3810s	
6344/29850 (epoch 10.626), train_loss = 1.36349797, grad/param norm = 1.8309e-01, time/batch = 17.9668s	
6345/29850 (epoch 10.628), train_loss = 1.16738158, grad/param norm = 1.6295e-01, time/batch = 16.9313s	
6346/29850 (epoch 10.630), train_loss = 1.30175716, grad/param norm = 1.7642e-01, time/batch = 17.7997s	
6347/29850 (epoch 10.631), train_loss = 1.22685556, grad/param norm = 1.7306e-01, time/batch = 17.3000s	
6348/29850 (epoch 10.633), train_loss = 1.39043261, grad/param norm = 1.8625e-01, time/batch = 17.7626s	
6349/29850 (epoch 10.635), train_loss = 1.31695430, grad/param norm = 1.8809e-01, time/batch = 17.8516s	
6350/29850 (epoch 10.637), train_loss = 1.31577927, grad/param norm = 1.8186e-01, time/batch = 18.9700s	
6351/29850 (epoch 10.638), train_loss = 1.25257128, grad/param norm = 1.7603e-01, time/batch = 18.1171s	
6352/29850 (epoch 10.640), train_loss = 1.45176649, grad/param norm = 1.9523e-01, time/batch = 16.2866s	
6353/29850 (epoch 10.642), train_loss = 1.26908053, grad/param norm = 1.7238e-01, time/batch = 17.0554s	
6354/29850 (epoch 10.643), train_loss = 1.21269897, grad/param norm = 1.6182e-01, time/batch = 18.2210s	
6355/29850 (epoch 10.645), train_loss = 1.33196528, grad/param norm = 1.8359e-01, time/batch = 16.2911s	
6356/29850 (epoch 10.647), train_loss = 1.43610169, grad/param norm = 1.7556e-01, time/batch = 17.0516s	
6357/29850 (epoch 10.648), train_loss = 1.17780441, grad/param norm = 1.5459e-01, time/batch = 17.6500s	
6358/29850 (epoch 10.650), train_loss = 1.28001242, grad/param norm = 1.9053e-01, time/batch = 17.7172s	
6359/29850 (epoch 10.652), train_loss = 1.30883307, grad/param norm = 1.8282e-01, time/batch = 17.4304s	
6360/29850 (epoch 10.653), train_loss = 1.42438559, grad/param norm = 1.8691e-01, time/batch = 16.7184s	
6361/29850 (epoch 10.655), train_loss = 1.28584010, grad/param norm = 1.6061e-01, time/batch = 18.3972s	
6362/29850 (epoch 10.657), train_loss = 1.25110232, grad/param norm = 1.6343e-01, time/batch = 17.6214s	
6363/29850 (epoch 10.658), train_loss = 1.40209350, grad/param norm = 1.7568e-01, time/batch = 18.9577s	
6364/29850 (epoch 10.660), train_loss = 1.24986774, grad/param norm = 1.7426e-01, time/batch = 17.3980s	
6365/29850 (epoch 10.662), train_loss = 1.31907924, grad/param norm = 1.7884e-01, time/batch = 16.9487s	
6366/29850 (epoch 10.663), train_loss = 1.42797332, grad/param norm = 1.8863e-01, time/batch = 16.9687s	
6367/29850 (epoch 10.665), train_loss = 1.36971655, grad/param norm = 1.8852e-01, time/batch = 17.8728s	
6368/29850 (epoch 10.667), train_loss = 1.38647674, grad/param norm = 2.0080e-01, time/batch = 18.2911s	
6369/29850 (epoch 10.668), train_loss = 1.32323733, grad/param norm = 1.7303e-01, time/batch = 16.6947s	
6370/29850 (epoch 10.670), train_loss = 1.53418486, grad/param norm = 1.9852e-01, time/batch = 18.6377s	
6371/29850 (epoch 10.672), train_loss = 1.38812583, grad/param norm = 2.0672e-01, time/batch = 17.5561s	
6372/29850 (epoch 10.673), train_loss = 1.40935877, grad/param norm = 1.8565e-01, time/batch = 16.7891s	
6373/29850 (epoch 10.675), train_loss = 1.28414744, grad/param norm = 1.6499e-01, time/batch = 16.3636s	
6374/29850 (epoch 10.677), train_loss = 1.29949064, grad/param norm = 1.8784e-01, time/batch = 18.9487s	
6375/29850 (epoch 10.678), train_loss = 1.29253242, grad/param norm = 1.8185e-01, time/batch = 17.7779s	
6376/29850 (epoch 10.680), train_loss = 1.34256130, grad/param norm = 1.7599e-01, time/batch = 19.3806s	
6377/29850 (epoch 10.682), train_loss = 1.29423765, grad/param norm = 1.7490e-01, time/batch = 17.1301s	
6378/29850 (epoch 10.683), train_loss = 1.48231769, grad/param norm = 2.1177e-01, time/batch = 16.4495s	
6379/29850 (epoch 10.685), train_loss = 1.44835619, grad/param norm = 1.6502e-01, time/batch = 14.5618s	
6380/29850 (epoch 10.687), train_loss = 1.38034688, grad/param norm = 1.7424e-01, time/batch = 15.0691s	
6381/29850 (epoch 10.688), train_loss = 1.18305381, grad/param norm = 1.4695e-01, time/batch = 17.2240s	
6382/29850 (epoch 10.690), train_loss = 1.21100962, grad/param norm = 1.7807e-01, time/batch = 17.1402s	
6383/29850 (epoch 10.692), train_loss = 1.43883638, grad/param norm = 1.7965e-01, time/batch = 18.4399s	
6384/29850 (epoch 10.693), train_loss = 1.28864654, grad/param norm = 1.5822e-01, time/batch = 18.5868s	
6385/29850 (epoch 10.695), train_loss = 1.14387886, grad/param norm = 1.6608e-01, time/batch = 16.9722s	
6386/29850 (epoch 10.697), train_loss = 1.35473938, grad/param norm = 1.8062e-01, time/batch = 15.3748s	
6387/29850 (epoch 10.698), train_loss = 1.38390455, grad/param norm = 1.7804e-01, time/batch = 19.0522s	
6388/29850 (epoch 10.700), train_loss = 1.36337134, grad/param norm = 1.9038e-01, time/batch = 17.7898s	
6389/29850 (epoch 10.702), train_loss = 1.28325226, grad/param norm = 1.8054e-01, time/batch = 17.7796s	
6390/29850 (epoch 10.704), train_loss = 1.21717655, grad/param norm = 1.6698e-01, time/batch = 16.9453s	
6391/29850 (epoch 10.705), train_loss = 1.33097788, grad/param norm = 1.7336e-01, time/batch = 18.9382s	
6392/29850 (epoch 10.707), train_loss = 1.27063538, grad/param norm = 1.7357e-01, time/batch = 19.1143s	
6393/29850 (epoch 10.709), train_loss = 1.39306000, grad/param norm = 1.8418e-01, time/batch = 16.2212s	
6394/29850 (epoch 10.710), train_loss = 1.28171078, grad/param norm = 1.7236e-01, time/batch = 17.2054s	
6395/29850 (epoch 10.712), train_loss = 1.31880145, grad/param norm = 1.6125e-01, time/batch = 17.7064s	
6396/29850 (epoch 10.714), train_loss = 1.37176692, grad/param norm = 1.7614e-01, time/batch = 16.3622s	
6397/29850 (epoch 10.715), train_loss = 1.37783883, grad/param norm = 1.7735e-01, time/batch = 17.6499s	
6398/29850 (epoch 10.717), train_loss = 1.13992526, grad/param norm = 1.6358e-01, time/batch = 18.3955s	
6399/29850 (epoch 10.719), train_loss = 1.26275783, grad/param norm = 1.7126e-01, time/batch = 17.6247s	
6400/29850 (epoch 10.720), train_loss = 1.29645042, grad/param norm = 1.5697e-01, time/batch = 16.8755s	
6401/29850 (epoch 10.722), train_loss = 1.21617891, grad/param norm = 1.5877e-01, time/batch = 18.3813s	
6402/29850 (epoch 10.724), train_loss = 1.39294047, grad/param norm = 1.8716e-01, time/batch = 17.1404s	
6403/29850 (epoch 10.725), train_loss = 1.19477965, grad/param norm = 1.6614e-01, time/batch = 15.7810s	
6404/29850 (epoch 10.727), train_loss = 1.26120937, grad/param norm = 1.7797e-01, time/batch = 19.1278s	
6405/29850 (epoch 10.729), train_loss = 1.14485980, grad/param norm = 1.6505e-01, time/batch = 17.6969s	
6406/29850 (epoch 10.730), train_loss = 1.16481754, grad/param norm = 1.8264e-01, time/batch = 15.3615s	
6407/29850 (epoch 10.732), train_loss = 1.36041116, grad/param norm = 1.6629e-01, time/batch = 17.2107s	
6408/29850 (epoch 10.734), train_loss = 1.50882122, grad/param norm = 2.0183e-01, time/batch = 18.8808s	
6409/29850 (epoch 10.735), train_loss = 1.32286907, grad/param norm = 1.8786e-01, time/batch = 16.1162s	
6410/29850 (epoch 10.737), train_loss = 1.20398311, grad/param norm = 1.7169e-01, time/batch = 16.4293s	
6411/29850 (epoch 10.739), train_loss = 1.14926151, grad/param norm = 1.6865e-01, time/batch = 15.6948s	
6412/29850 (epoch 10.740), train_loss = 1.17182307, grad/param norm = 1.6596e-01, time/batch = 15.8487s	
6413/29850 (epoch 10.742), train_loss = 1.17016465, grad/param norm = 1.5768e-01, time/batch = 18.4374s	
6414/29850 (epoch 10.744), train_loss = 1.28557061, grad/param norm = 1.9516e-01, time/batch = 17.4706s	
6415/29850 (epoch 10.745), train_loss = 1.28889875, grad/param norm = 2.0022e-01, time/batch = 18.6152s	
6416/29850 (epoch 10.747), train_loss = 1.24087750, grad/param norm = 1.7485e-01, time/batch = 18.2816s	
6417/29850 (epoch 10.749), train_loss = 1.18223733, grad/param norm = 1.7536e-01, time/batch = 17.6938s	
6418/29850 (epoch 10.750), train_loss = 1.25235074, grad/param norm = 1.9318e-01, time/batch = 17.7988s	
6419/29850 (epoch 10.752), train_loss = 1.17807586, grad/param norm = 1.7275e-01, time/batch = 18.2164s	
6420/29850 (epoch 10.754), train_loss = 1.18756206, grad/param norm = 1.7038e-01, time/batch = 15.3720s	
6421/29850 (epoch 10.755), train_loss = 1.24460151, grad/param norm = 1.7067e-01, time/batch = 17.2101s	
6422/29850 (epoch 10.757), train_loss = 1.24956693, grad/param norm = 1.6555e-01, time/batch = 18.7222s	
6423/29850 (epoch 10.759), train_loss = 1.28908922, grad/param norm = 1.7144e-01, time/batch = 17.5590s	
6424/29850 (epoch 10.760), train_loss = 1.17253246, grad/param norm = 1.7307e-01, time/batch = 18.8687s	
6425/29850 (epoch 10.762), train_loss = 1.18704202, grad/param norm = 2.3518e-01, time/batch = 17.9318s	
6426/29850 (epoch 10.764), train_loss = 1.20289652, grad/param norm = 1.9490e-01, time/batch = 17.3723s	
6427/29850 (epoch 10.765), train_loss = 1.25347531, grad/param norm = 1.8724e-01, time/batch = 17.1351s	
6428/29850 (epoch 10.767), train_loss = 1.28878487, grad/param norm = 1.8368e-01, time/batch = 17.7948s	
6429/29850 (epoch 10.769), train_loss = 1.25586398, grad/param norm = 1.8748e-01, time/batch = 16.4540s	
6430/29850 (epoch 10.771), train_loss = 1.33232934, grad/param norm = 1.8697e-01, time/batch = 17.7788s	
6431/29850 (epoch 10.772), train_loss = 1.38166481, grad/param norm = 1.8655e-01, time/batch = 18.9616s	
6432/29850 (epoch 10.774), train_loss = 1.22445519, grad/param norm = 1.8391e-01, time/batch = 19.5320s	
6433/29850 (epoch 10.776), train_loss = 1.25185976, grad/param norm = 1.8157e-01, time/batch = 18.3616s	
6434/29850 (epoch 10.777), train_loss = 1.34751852, grad/param norm = 1.8106e-01, time/batch = 31.2886s	
6435/29850 (epoch 10.779), train_loss = 1.14359427, grad/param norm = 1.5487e-01, time/batch = 18.8007s	
6436/29850 (epoch 10.781), train_loss = 1.24663405, grad/param norm = 1.6832e-01, time/batch = 15.9298s	
6437/29850 (epoch 10.782), train_loss = 1.29224199, grad/param norm = 1.6048e-01, time/batch = 18.1144s	
6438/29850 (epoch 10.784), train_loss = 1.20132192, grad/param norm = 1.7647e-01, time/batch = 19.3002s	
6439/29850 (epoch 10.786), train_loss = 1.24637519, grad/param norm = 1.6913e-01, time/batch = 18.1332s	
6440/29850 (epoch 10.787), train_loss = 1.18559985, grad/param norm = 1.6936e-01, time/batch = 19.1246s	
6441/29850 (epoch 10.789), train_loss = 1.10882310, grad/param norm = 1.5489e-01, time/batch = 15.4539s	
6442/29850 (epoch 10.791), train_loss = 1.26743238, grad/param norm = 1.8557e-01, time/batch = 19.1355s	
6443/29850 (epoch 10.792), train_loss = 1.36364773, grad/param norm = 1.7595e-01, time/batch = 18.0407s	
6444/29850 (epoch 10.794), train_loss = 1.28697384, grad/param norm = 1.6740e-01, time/batch = 17.6438s	
6445/29850 (epoch 10.796), train_loss = 1.20446346, grad/param norm = 1.7789e-01, time/batch = 17.5566s	
6446/29850 (epoch 10.797), train_loss = 1.14362927, grad/param norm = 1.6019e-01, time/batch = 16.3048s	
6447/29850 (epoch 10.799), train_loss = 1.15450690, grad/param norm = 1.6392e-01, time/batch = 18.1256s	
6448/29850 (epoch 10.801), train_loss = 1.33253199, grad/param norm = 1.7918e-01, time/batch = 18.2997s	
6449/29850 (epoch 10.802), train_loss = 1.14143377, grad/param norm = 1.7136e-01, time/batch = 18.7714s	
6450/29850 (epoch 10.804), train_loss = 1.18745989, grad/param norm = 1.5926e-01, time/batch = 17.4524s	
6451/29850 (epoch 10.806), train_loss = 1.17200240, grad/param norm = 1.5406e-01, time/batch = 17.8833s	
6452/29850 (epoch 10.807), train_loss = 1.05675588, grad/param norm = 1.4820e-01, time/batch = 19.0373s	
6453/29850 (epoch 10.809), train_loss = 1.24969449, grad/param norm = 1.8685e-01, time/batch = 16.1646s	
6454/29850 (epoch 10.811), train_loss = 1.35610304, grad/param norm = 2.0652e-01, time/batch = 19.7800s	
6455/29850 (epoch 10.812), train_loss = 1.30227447, grad/param norm = 1.9029e-01, time/batch = 18.3003s	
6456/29850 (epoch 10.814), train_loss = 1.36589415, grad/param norm = 1.8487e-01, time/batch = 15.8710s	
6457/29850 (epoch 10.816), train_loss = 1.34454044, grad/param norm = 1.7322e-01, time/batch = 19.6834s	
6458/29850 (epoch 10.817), train_loss = 1.28261095, grad/param norm = 1.6909e-01, time/batch = 17.1267s	
6459/29850 (epoch 10.819), train_loss = 1.19844791, grad/param norm = 1.7965e-01, time/batch = 17.2988s	
6460/29850 (epoch 10.821), train_loss = 1.43181648, grad/param norm = 1.8956e-01, time/batch = 17.8839s	
6461/29850 (epoch 10.822), train_loss = 1.30898565, grad/param norm = 1.6384e-01, time/batch = 18.1976s	
6462/29850 (epoch 10.824), train_loss = 1.23539413, grad/param norm = 1.7648e-01, time/batch = 17.1164s	
6463/29850 (epoch 10.826), train_loss = 1.23154571, grad/param norm = 1.7198e-01, time/batch = 17.6924s	
6464/29850 (epoch 10.827), train_loss = 1.18961684, grad/param norm = 1.7795e-01, time/batch = 16.5509s	
6465/29850 (epoch 10.829), train_loss = 1.30632200, grad/param norm = 1.8816e-01, time/batch = 18.6187s	
6466/29850 (epoch 10.831), train_loss = 1.32557037, grad/param norm = 1.8854e-01, time/batch = 16.2762s	
6467/29850 (epoch 10.832), train_loss = 1.21628453, grad/param norm = 1.6608e-01, time/batch = 17.1104s	
6468/29850 (epoch 10.834), train_loss = 1.15156339, grad/param norm = 1.8103e-01, time/batch = 17.5554s	
6469/29850 (epoch 10.836), train_loss = 1.14354772, grad/param norm = 1.6718e-01, time/batch = 17.9540s	
6470/29850 (epoch 10.838), train_loss = 1.28934272, grad/param norm = 1.6975e-01, time/batch = 17.5090s	
6471/29850 (epoch 10.839), train_loss = 1.20174694, grad/param norm = 1.6495e-01, time/batch = 18.2868s	
6472/29850 (epoch 10.841), train_loss = 1.23286873, grad/param norm = 1.6784e-01, time/batch = 19.2892s	
6473/29850 (epoch 10.843), train_loss = 1.20606575, grad/param norm = 1.6604e-01, time/batch = 17.4576s	
6474/29850 (epoch 10.844), train_loss = 1.23039436, grad/param norm = 1.7768e-01, time/batch = 18.6414s	
6475/29850 (epoch 10.846), train_loss = 1.29358335, grad/param norm = 1.8032e-01, time/batch = 17.9513s	
6476/29850 (epoch 10.848), train_loss = 1.31527641, grad/param norm = 1.8054e-01, time/batch = 17.4512s	
6477/29850 (epoch 10.849), train_loss = 1.16982503, grad/param norm = 1.9034e-01, time/batch = 17.3667s	
6478/29850 (epoch 10.851), train_loss = 1.35019572, grad/param norm = 2.0269e-01, time/batch = 19.5353s	
6479/29850 (epoch 10.853), train_loss = 1.23745304, grad/param norm = 1.9834e-01, time/batch = 17.8894s	
6480/29850 (epoch 10.854), train_loss = 1.37256740, grad/param norm = 2.0348e-01, time/batch = 16.9564s	
6481/29850 (epoch 10.856), train_loss = 1.34096034, grad/param norm = 1.9392e-01, time/batch = 18.8748s	
6482/29850 (epoch 10.858), train_loss = 1.23820682, grad/param norm = 1.7472e-01, time/batch = 18.3777s	
6483/29850 (epoch 10.859), train_loss = 1.21291330, grad/param norm = 1.8558e-01, time/batch = 15.6787s	
6484/29850 (epoch 10.861), train_loss = 1.35630749, grad/param norm = 1.8204e-01, time/batch = 16.6360s	
6485/29850 (epoch 10.863), train_loss = 1.42309983, grad/param norm = 1.7319e-01, time/batch = 15.9852s	
6486/29850 (epoch 10.864), train_loss = 1.33631321, grad/param norm = 1.7990e-01, time/batch = 17.1222s	
6487/29850 (epoch 10.866), train_loss = 1.30561335, grad/param norm = 1.9321e-01, time/batch = 17.9433s	
6488/29850 (epoch 10.868), train_loss = 1.40181255, grad/param norm = 2.0280e-01, time/batch = 17.6526s	
6489/29850 (epoch 10.869), train_loss = 1.22024148, grad/param norm = 1.7978e-01, time/batch = 18.3911s	
6490/29850 (epoch 10.871), train_loss = 1.27180840, grad/param norm = 1.6990e-01, time/batch = 15.5851s	
6491/29850 (epoch 10.873), train_loss = 1.34517581, grad/param norm = 1.7953e-01, time/batch = 18.9735s	
6492/29850 (epoch 10.874), train_loss = 1.32063846, grad/param norm = 1.7933e-01, time/batch = 17.3975s	
6493/29850 (epoch 10.876), train_loss = 1.30202998, grad/param norm = 2.0011e-01, time/batch = 18.2154s	
6494/29850 (epoch 10.878), train_loss = 1.27116402, grad/param norm = 1.7109e-01, time/batch = 18.6360s	
6495/29850 (epoch 10.879), train_loss = 1.31633963, grad/param norm = 1.7839e-01, time/batch = 18.4597s	
6496/29850 (epoch 10.881), train_loss = 1.37857875, grad/param norm = 1.9167e-01, time/batch = 17.7110s	
6497/29850 (epoch 10.883), train_loss = 1.36205757, grad/param norm = 1.8015e-01, time/batch = 17.3522s	
6498/29850 (epoch 10.884), train_loss = 1.17807395, grad/param norm = 1.6708e-01, time/batch = 17.7251s	
6499/29850 (epoch 10.886), train_loss = 1.44618421, grad/param norm = 1.8056e-01, time/batch = 19.4514s	
6500/29850 (epoch 10.888), train_loss = 1.26684285, grad/param norm = 1.6968e-01, time/batch = 16.3730s	
6501/29850 (epoch 10.889), train_loss = 1.22886591, grad/param norm = 1.8151e-01, time/batch = 17.5415s	
6502/29850 (epoch 10.891), train_loss = 1.24639717, grad/param norm = 1.8001e-01, time/batch = 17.8916s	
6503/29850 (epoch 10.893), train_loss = 1.17245451, grad/param norm = 1.6425e-01, time/batch = 15.5278s	
6504/29850 (epoch 10.894), train_loss = 1.23696008, grad/param norm = 1.6689e-01, time/batch = 18.5315s	
6505/29850 (epoch 10.896), train_loss = 1.23196641, grad/param norm = 1.7825e-01, time/batch = 16.9758s	
6506/29850 (epoch 10.898), train_loss = 1.40847501, grad/param norm = 2.0045e-01, time/batch = 18.6455s	
6507/29850 (epoch 10.899), train_loss = 1.11775156, grad/param norm = 1.6213e-01, time/batch = 16.3696s	
6508/29850 (epoch 10.901), train_loss = 1.61340000, grad/param norm = 2.2451e-01, time/batch = 18.7131s	
6509/29850 (epoch 10.903), train_loss = 1.30551560, grad/param norm = 2.0329e-01, time/batch = 17.4636s	
6510/29850 (epoch 10.905), train_loss = 1.45693622, grad/param norm = 1.7618e-01, time/batch = 16.3627s	
6511/29850 (epoch 10.906), train_loss = 1.20867448, grad/param norm = 1.7525e-01, time/batch = 18.2766s	
6512/29850 (epoch 10.908), train_loss = 1.38037511, grad/param norm = 1.8605e-01, time/batch = 17.1354s	
6513/29850 (epoch 10.910), train_loss = 1.35523883, grad/param norm = 1.8138e-01, time/batch = 18.4494s	
6514/29850 (epoch 10.911), train_loss = 1.44317036, grad/param norm = 1.8324e-01, time/batch = 17.7179s	
6515/29850 (epoch 10.913), train_loss = 1.34402754, grad/param norm = 1.7882e-01, time/batch = 17.3207s	
6516/29850 (epoch 10.915), train_loss = 1.37240145, grad/param norm = 1.8798e-01, time/batch = 18.3027s	
6517/29850 (epoch 10.916), train_loss = 1.32230131, grad/param norm = 1.7296e-01, time/batch = 15.3629s	
6518/29850 (epoch 10.918), train_loss = 1.22145223, grad/param norm = 1.5551e-01, time/batch = 18.2938s	
6519/29850 (epoch 10.920), train_loss = 1.35654102, grad/param norm = 1.7185e-01, time/batch = 16.7865s	
6520/29850 (epoch 10.921), train_loss = 1.33525114, grad/param norm = 1.8914e-01, time/batch = 18.2003s	
6521/29850 (epoch 10.923), train_loss = 1.36043931, grad/param norm = 1.7459e-01, time/batch = 17.0540s	
6522/29850 (epoch 10.925), train_loss = 1.41690877, grad/param norm = 1.8625e-01, time/batch = 19.7114s	
6523/29850 (epoch 10.926), train_loss = 1.46533586, grad/param norm = 1.8897e-01, time/batch = 17.9634s	
6524/29850 (epoch 10.928), train_loss = 1.29247027, grad/param norm = 1.7638e-01, time/batch = 18.5349s	
6525/29850 (epoch 10.930), train_loss = 1.39690339, grad/param norm = 1.8440e-01, time/batch = 17.9858s	
6526/29850 (epoch 10.931), train_loss = 1.35233332, grad/param norm = 1.8052e-01, time/batch = 18.2166s	
6527/29850 (epoch 10.933), train_loss = 1.45503035, grad/param norm = 1.9046e-01, time/batch = 16.5580s	
6528/29850 (epoch 10.935), train_loss = 1.42117303, grad/param norm = 1.8459e-01, time/batch = 17.5534s	
6529/29850 (epoch 10.936), train_loss = 1.41020789, grad/param norm = 1.7552e-01, time/batch = 17.7938s	
6530/29850 (epoch 10.938), train_loss = 1.16271171, grad/param norm = 1.6783e-01, time/batch = 16.6078s	
6531/29850 (epoch 10.940), train_loss = 1.15924954, grad/param norm = 1.7233e-01, time/batch = 17.6119s	
6532/29850 (epoch 10.941), train_loss = 1.24581774, grad/param norm = 1.7763e-01, time/batch = 18.8029s	
6533/29850 (epoch 10.943), train_loss = 1.20920231, grad/param norm = 1.6098e-01, time/batch = 19.2249s	
6534/29850 (epoch 10.945), train_loss = 1.31947442, grad/param norm = 1.8367e-01, time/batch = 18.3388s	
6535/29850 (epoch 10.946), train_loss = 1.18706973, grad/param norm = 1.7857e-01, time/batch = 17.3959s	
6536/29850 (epoch 10.948), train_loss = 1.26058009, grad/param norm = 1.6149e-01, time/batch = 17.6521s	
6537/29850 (epoch 10.950), train_loss = 1.20246084, grad/param norm = 1.6665e-01, time/batch = 15.5301s	
6538/29850 (epoch 10.951), train_loss = 1.16835036, grad/param norm = 1.6134e-01, time/batch = 17.2822s	
6539/29850 (epoch 10.953), train_loss = 1.27957338, grad/param norm = 1.7532e-01, time/batch = 16.9461s	
6540/29850 (epoch 10.955), train_loss = 1.12357901, grad/param norm = 1.5508e-01, time/batch = 17.8011s	
6541/29850 (epoch 10.956), train_loss = 1.15175506, grad/param norm = 1.6316e-01, time/batch = 16.5149s	
6542/29850 (epoch 10.958), train_loss = 1.02847897, grad/param norm = 1.5918e-01, time/batch = 19.6173s	
6543/29850 (epoch 10.960), train_loss = 1.34867995, grad/param norm = 1.8029e-01, time/batch = 18.9599s	
6544/29850 (epoch 10.961), train_loss = 1.21258665, grad/param norm = 1.5935e-01, time/batch = 18.6704s	
6545/29850 (epoch 10.963), train_loss = 1.13383740, grad/param norm = 1.5868e-01, time/batch = 19.2159s	
6546/29850 (epoch 10.965), train_loss = 1.22711818, grad/param norm = 1.7154e-01, time/batch = 16.7344s	
6547/29850 (epoch 10.966), train_loss = 1.11850551, grad/param norm = 1.5776e-01, time/batch = 17.5451s	
6548/29850 (epoch 10.968), train_loss = 1.25850745, grad/param norm = 1.8681e-01, time/batch = 19.0259s	
6549/29850 (epoch 10.970), train_loss = 1.16197010, grad/param norm = 1.6920e-01, time/batch = 17.7234s	
6550/29850 (epoch 10.972), train_loss = 1.17603633, grad/param norm = 1.6852e-01, time/batch = 17.3643s	
6551/29850 (epoch 10.973), train_loss = 1.18870655, grad/param norm = 1.6795e-01, time/batch = 16.2959s	
6552/29850 (epoch 10.975), train_loss = 1.04176721, grad/param norm = 1.5221e-01, time/batch = 17.8055s	
6553/29850 (epoch 10.977), train_loss = 1.20911513, grad/param norm = 1.6617e-01, time/batch = 19.3700s	
6554/29850 (epoch 10.978), train_loss = 1.16494405, grad/param norm = 1.6545e-01, time/batch = 15.4171s	
6555/29850 (epoch 10.980), train_loss = 1.17609363, grad/param norm = 1.5752e-01, time/batch = 16.6377s	
6556/29850 (epoch 10.982), train_loss = 1.21183524, grad/param norm = 1.6958e-01, time/batch = 19.2771s	
6557/29850 (epoch 10.983), train_loss = 1.24757748, grad/param norm = 1.6388e-01, time/batch = 17.5863s	
6558/29850 (epoch 10.985), train_loss = 1.31370685, grad/param norm = 1.8300e-01, time/batch = 15.5476s	
6559/29850 (epoch 10.987), train_loss = 1.21533295, grad/param norm = 1.6128e-01, time/batch = 18.3927s	
6560/29850 (epoch 10.988), train_loss = 1.15539499, grad/param norm = 1.6305e-01, time/batch = 19.9377s	
6561/29850 (epoch 10.990), train_loss = 1.24763302, grad/param norm = 1.6849e-01, time/batch = 18.7837s	
6562/29850 (epoch 10.992), train_loss = 1.24862024, grad/param norm = 1.6498e-01, time/batch = 17.1918s	
6563/29850 (epoch 10.993), train_loss = 1.26458367, grad/param norm = 1.8527e-01, time/batch = 17.6981s	
6564/29850 (epoch 10.995), train_loss = 1.29963502, grad/param norm = 1.8144e-01, time/batch = 17.1155s	
6565/29850 (epoch 10.997), train_loss = 1.25540317, grad/param norm = 1.7802e-01, time/batch = 17.3093s	
6566/29850 (epoch 10.998), train_loss = 1.34549240, grad/param norm = 1.8071e-01, time/batch = 16.6276s	
decayed learning rate by a factor 0.97 to 0.0018818	
6567/29850 (epoch 11.000), train_loss = 1.19991652, grad/param norm = 1.5871e-01, time/batch = 16.6823s	
6568/29850 (epoch 11.002), train_loss = 1.47575078, grad/param norm = 1.8928e-01, time/batch = 19.3682s	
6569/29850 (epoch 11.003), train_loss = 1.20661647, grad/param norm = 1.7357e-01, time/batch = 16.8818s	
6570/29850 (epoch 11.005), train_loss = 1.27258814, grad/param norm = 1.6932e-01, time/batch = 19.2787s	
6571/29850 (epoch 11.007), train_loss = 1.29029167, grad/param norm = 1.9064e-01, time/batch = 17.6036s	
6572/29850 (epoch 11.008), train_loss = 1.51139656, grad/param norm = 2.0124e-01, time/batch = 18.4617s	
6573/29850 (epoch 11.010), train_loss = 1.14269083, grad/param norm = 1.7561e-01, time/batch = 19.5357s	
6574/29850 (epoch 11.012), train_loss = 1.31218969, grad/param norm = 1.8268e-01, time/batch = 16.6124s	
6575/29850 (epoch 11.013), train_loss = 1.35734332, grad/param norm = 1.9051e-01, time/batch = 19.1123s	
6576/29850 (epoch 11.015), train_loss = 1.32358955, grad/param norm = 1.7760e-01, time/batch = 16.8136s	
6577/29850 (epoch 11.017), train_loss = 1.40937465, grad/param norm = 1.9783e-01, time/batch = 17.1884s	
6578/29850 (epoch 11.018), train_loss = 1.44473027, grad/param norm = 2.0369e-01, time/batch = 17.3021s	
6579/29850 (epoch 11.020), train_loss = 1.23663584, grad/param norm = 1.7890e-01, time/batch = 18.0528s	
6580/29850 (epoch 11.022), train_loss = 1.38448795, grad/param norm = 1.9967e-01, time/batch = 19.5403s	
6581/29850 (epoch 11.023), train_loss = 1.28849148, grad/param norm = 1.6196e-01, time/batch = 18.4561s	
6582/29850 (epoch 11.025), train_loss = 1.23711229, grad/param norm = 1.6752e-01, time/batch = 17.8814s	
6583/29850 (epoch 11.027), train_loss = 1.12753170, grad/param norm = 1.5113e-01, time/batch = 18.4703s	
6584/29850 (epoch 11.028), train_loss = 1.22295415, grad/param norm = 1.6217e-01, time/batch = 15.7866s	
6585/29850 (epoch 11.030), train_loss = 1.33188298, grad/param norm = 1.7596e-01, time/batch = 17.4582s	
6586/29850 (epoch 11.032), train_loss = 1.25696307, grad/param norm = 1.6747e-01, time/batch = 16.7147s	
6587/29850 (epoch 11.034), train_loss = 1.22359598, grad/param norm = 1.7326e-01, time/batch = 17.5222s	
6588/29850 (epoch 11.035), train_loss = 1.12137462, grad/param norm = 1.5382e-01, time/batch = 16.8011s	
6589/29850 (epoch 11.037), train_loss = 1.30621530, grad/param norm = 1.8129e-01, time/batch = 18.5603s	
6590/29850 (epoch 11.039), train_loss = 1.10332797, grad/param norm = 1.4845e-01, time/batch = 14.9272s	
6591/29850 (epoch 11.040), train_loss = 1.15496379, grad/param norm = 1.6687e-01, time/batch = 17.4536s	
6592/29850 (epoch 11.042), train_loss = 1.20303489, grad/param norm = 1.6935e-01, time/batch = 19.2191s	
6593/29850 (epoch 11.044), train_loss = 1.19944072, grad/param norm = 1.6703e-01, time/batch = 17.8751s	
6594/29850 (epoch 11.045), train_loss = 1.31904515, grad/param norm = 1.7949e-01, time/batch = 17.0313s	
6595/29850 (epoch 11.047), train_loss = 1.12068050, grad/param norm = 1.8171e-01, time/batch = 16.8686s	
6596/29850 (epoch 11.049), train_loss = 1.30550059, grad/param norm = 1.6899e-01, time/batch = 16.5513s	
6597/29850 (epoch 11.050), train_loss = 1.17990271, grad/param norm = 1.6993e-01, time/batch = 17.3842s	
6598/29850 (epoch 11.052), train_loss = 1.49701508, grad/param norm = 1.9735e-01, time/batch = 16.3481s	
6599/29850 (epoch 11.054), train_loss = 1.33681544, grad/param norm = 2.3915e-01, time/batch = 15.4961s	
6600/29850 (epoch 11.055), train_loss = 1.26041421, grad/param norm = 1.9353e-01, time/batch = 18.1409s	
6601/29850 (epoch 11.057), train_loss = 1.31169759, grad/param norm = 1.6515e-01, time/batch = 17.4438s	
6602/29850 (epoch 11.059), train_loss = 1.35855270, grad/param norm = 1.9764e-01, time/batch = 18.4552s	
6603/29850 (epoch 11.060), train_loss = 1.28737112, grad/param norm = 1.8277e-01, time/batch = 16.5573s	
6604/29850 (epoch 11.062), train_loss = 1.39358829, grad/param norm = 1.8277e-01, time/batch = 19.1306s	
6605/29850 (epoch 11.064), train_loss = 1.33771352, grad/param norm = 1.8389e-01, time/batch = 15.9319s	
6606/29850 (epoch 11.065), train_loss = 1.17409574, grad/param norm = 1.6948e-01, time/batch = 19.3726s	
6607/29850 (epoch 11.067), train_loss = 1.30098182, grad/param norm = 1.7642e-01, time/batch = 17.9556s	
6608/29850 (epoch 11.069), train_loss = 1.26800510, grad/param norm = 1.7420e-01, time/batch = 17.2026s	
6609/29850 (epoch 11.070), train_loss = 1.30427335, grad/param norm = 1.5720e-01, time/batch = 16.9644s	
6610/29850 (epoch 11.072), train_loss = 1.37067450, grad/param norm = 1.9122e-01, time/batch = 19.4724s	
6611/29850 (epoch 11.074), train_loss = 1.35200549, grad/param norm = 1.6595e-01, time/batch = 16.3605s	
6612/29850 (epoch 11.075), train_loss = 1.18254646, grad/param norm = 1.6118e-01, time/batch = 19.3672s	
6613/29850 (epoch 11.077), train_loss = 1.28374404, grad/param norm = 1.7675e-01, time/batch = 17.1280s	
6614/29850 (epoch 11.079), train_loss = 1.51847432, grad/param norm = 1.9588e-01, time/batch = 17.7997s	
6615/29850 (epoch 11.080), train_loss = 1.42635917, grad/param norm = 1.9257e-01, time/batch = 17.6911s	
6616/29850 (epoch 11.082), train_loss = 1.30062808, grad/param norm = 1.6349e-01, time/batch = 19.6220s	
6617/29850 (epoch 11.084), train_loss = 1.37845042, grad/param norm = 1.8854e-01, time/batch = 15.3040s	
6618/29850 (epoch 11.085), train_loss = 1.31455366, grad/param norm = 1.7961e-01, time/batch = 16.7012s	
6619/29850 (epoch 11.087), train_loss = 1.42430251, grad/param norm = 1.7667e-01, time/batch = 19.1213s	
6620/29850 (epoch 11.089), train_loss = 1.34068126, grad/param norm = 1.7359e-01, time/batch = 17.0317s	
6621/29850 (epoch 11.090), train_loss = 1.36262857, grad/param norm = 1.9590e-01, time/batch = 17.3738s	
6622/29850 (epoch 11.092), train_loss = 1.25412075, grad/param norm = 1.7503e-01, time/batch = 17.1048s	
6623/29850 (epoch 11.094), train_loss = 1.34159261, grad/param norm = 1.7717e-01, time/batch = 18.9612s	
6624/29850 (epoch 11.095), train_loss = 1.33612278, grad/param norm = 1.7489e-01, time/batch = 19.1216s	
6625/29850 (epoch 11.097), train_loss = 1.09150268, grad/param norm = 1.5145e-01, time/batch = 18.4450s	
6626/29850 (epoch 11.099), train_loss = 1.13502582, grad/param norm = 1.5365e-01, time/batch = 19.0426s	
6627/29850 (epoch 11.101), train_loss = 1.42001143, grad/param norm = 1.8175e-01, time/batch = 16.6130s	
6628/29850 (epoch 11.102), train_loss = 1.35166369, grad/param norm = 1.7987e-01, time/batch = 17.2773s	
6629/29850 (epoch 11.104), train_loss = 1.25121342, grad/param norm = 1.6436e-01, time/batch = 17.6151s	
6630/29850 (epoch 11.106), train_loss = 1.36485037, grad/param norm = 1.7890e-01, time/batch = 18.2258s	
6631/29850 (epoch 11.107), train_loss = 1.12685065, grad/param norm = 1.4578e-01, time/batch = 17.0519s	
6632/29850 (epoch 11.109), train_loss = 1.24310445, grad/param norm = 1.9406e-01, time/batch = 18.5510s	
6633/29850 (epoch 11.111), train_loss = 1.37565647, grad/param norm = 1.8178e-01, time/batch = 17.2211s	
6634/29850 (epoch 11.112), train_loss = 1.19008229, grad/param norm = 1.7306e-01, time/batch = 19.7917s	
6635/29850 (epoch 11.114), train_loss = 1.34161427, grad/param norm = 2.0189e-01, time/batch = 31.9403s	
6636/29850 (epoch 11.116), train_loss = 1.19328176, grad/param norm = 1.6852e-01, time/batch = 17.7163s	
6637/29850 (epoch 11.117), train_loss = 1.29063970, grad/param norm = 1.7535e-01, time/batch = 17.3728s	
6638/29850 (epoch 11.119), train_loss = 1.24977923, grad/param norm = 1.5622e-01, time/batch = 18.3647s	
6639/29850 (epoch 11.121), train_loss = 1.07257730, grad/param norm = 1.6405e-01, time/batch = 18.9746s	
6640/29850 (epoch 11.122), train_loss = 1.13592815, grad/param norm = 1.5816e-01, time/batch = 17.6207s	
6641/29850 (epoch 11.124), train_loss = 1.22015697, grad/param norm = 1.6685e-01, time/batch = 16.0836s	
6642/29850 (epoch 11.126), train_loss = 1.26673515, grad/param norm = 1.8330e-01, time/batch = 19.2863s	
6643/29850 (epoch 11.127), train_loss = 1.43306422, grad/param norm = 2.0343e-01, time/batch = 17.8021s	
6644/29850 (epoch 11.129), train_loss = 1.23410032, grad/param norm = 1.7336e-01, time/batch = 17.3780s	
6645/29850 (epoch 11.131), train_loss = 1.24424501, grad/param norm = 1.7907e-01, time/batch = 17.5492s	
6646/29850 (epoch 11.132), train_loss = 1.16743562, grad/param norm = 1.8142e-01, time/batch = 18.3775s	
6647/29850 (epoch 11.134), train_loss = 1.33524484, grad/param norm = 1.8161e-01, time/batch = 17.9563s	
6648/29850 (epoch 11.136), train_loss = 1.31590849, grad/param norm = 1.7276e-01, time/batch = 17.5497s	
6649/29850 (epoch 11.137), train_loss = 1.16304366, grad/param norm = 1.6930e-01, time/batch = 18.8058s	
6650/29850 (epoch 11.139), train_loss = 1.17837840, grad/param norm = 1.5984e-01, time/batch = 18.8815s	
6651/29850 (epoch 11.141), train_loss = 1.25267287, grad/param norm = 1.7705e-01, time/batch = 17.2739s	
6652/29850 (epoch 11.142), train_loss = 1.36061487, grad/param norm = 1.8778e-01, time/batch = 18.7214s	
6653/29850 (epoch 11.144), train_loss = 1.52411801, grad/param norm = 1.9919e-01, time/batch = 16.7025s	
6654/29850 (epoch 11.146), train_loss = 1.50771223, grad/param norm = 2.0745e-01, time/batch = 15.2725s	
6655/29850 (epoch 11.147), train_loss = 1.39912118, grad/param norm = 1.9876e-01, time/batch = 17.2967s	
6656/29850 (epoch 11.149), train_loss = 1.37423707, grad/param norm = 1.7959e-01, time/batch = 18.0596s	
6657/29850 (epoch 11.151), train_loss = 1.31061939, grad/param norm = 1.8078e-01, time/batch = 17.3769s	
6658/29850 (epoch 11.152), train_loss = 1.20973827, grad/param norm = 1.7448e-01, time/batch = 17.9750s	
6659/29850 (epoch 11.154), train_loss = 1.21933386, grad/param norm = 1.7010e-01, time/batch = 16.0649s	
6660/29850 (epoch 11.156), train_loss = 1.20049928, grad/param norm = 1.6370e-01, time/batch = 18.0303s	
6661/29850 (epoch 11.157), train_loss = 1.24765014, grad/param norm = 1.5974e-01, time/batch = 17.3649s	
6662/29850 (epoch 11.159), train_loss = 1.29548247, grad/param norm = 1.6332e-01, time/batch = 18.2919s	
6663/29850 (epoch 11.161), train_loss = 1.33397709, grad/param norm = 1.9708e-01, time/batch = 17.7674s	
6664/29850 (epoch 11.162), train_loss = 1.45693467, grad/param norm = 1.9046e-01, time/batch = 17.6242s	
6665/29850 (epoch 11.164), train_loss = 1.29930935, grad/param norm = 1.8937e-01, time/batch = 17.6955s	
6666/29850 (epoch 11.166), train_loss = 1.15992060, grad/param norm = 1.6281e-01, time/batch = 18.8696s	
6667/29850 (epoch 11.168), train_loss = 1.08639378, grad/param norm = 1.6697e-01, time/batch = 17.8793s	
6668/29850 (epoch 11.169), train_loss = 1.45138744, grad/param norm = 1.9134e-01, time/batch = 18.0354s	
6669/29850 (epoch 11.171), train_loss = 1.39806367, grad/param norm = 1.9073e-01, time/batch = 18.0472s	
6670/29850 (epoch 11.173), train_loss = 1.27582365, grad/param norm = 2.1498e-01, time/batch = 18.0440s	
6671/29850 (epoch 11.174), train_loss = 1.37045978, grad/param norm = 1.9107e-01, time/batch = 15.6986s	
6672/29850 (epoch 11.176), train_loss = 1.33219492, grad/param norm = 1.8150e-01, time/batch = 16.2119s	
6673/29850 (epoch 11.178), train_loss = 1.33904527, grad/param norm = 1.8884e-01, time/batch = 17.9594s	
6674/29850 (epoch 11.179), train_loss = 1.10283792, grad/param norm = 1.6288e-01, time/batch = 17.4312s	
6675/29850 (epoch 11.181), train_loss = 1.26539110, grad/param norm = 1.6904e-01, time/batch = 19.2039s	
6676/29850 (epoch 11.183), train_loss = 1.23743360, grad/param norm = 1.7794e-01, time/batch = 19.7773s	
6677/29850 (epoch 11.184), train_loss = 1.23899937, grad/param norm = 1.8027e-01, time/batch = 16.6350s	
6678/29850 (epoch 11.186), train_loss = 1.23359020, grad/param norm = 1.6996e-01, time/batch = 17.9623s	
6679/29850 (epoch 11.188), train_loss = 1.36072484, grad/param norm = 1.9099e-01, time/batch = 17.1492s	
6680/29850 (epoch 11.189), train_loss = 1.45983527, grad/param norm = 1.9375e-01, time/batch = 18.8018s	
6681/29850 (epoch 11.191), train_loss = 1.32746100, grad/param norm = 1.8008e-01, time/batch = 16.7068s	
6682/29850 (epoch 11.193), train_loss = 1.17507779, grad/param norm = 1.6062e-01, time/batch = 19.2848s	
6683/29850 (epoch 11.194), train_loss = 1.32257266, grad/param norm = 2.0933e-01, time/batch = 19.4784s	
6684/29850 (epoch 11.196), train_loss = 1.24306234, grad/param norm = 1.7233e-01, time/batch = 16.6992s	
6685/29850 (epoch 11.198), train_loss = 1.25400582, grad/param norm = 1.7251e-01, time/batch = 17.8999s	
6686/29850 (epoch 11.199), train_loss = 1.56386388, grad/param norm = 2.0115e-01, time/batch = 16.2838s	
6687/29850 (epoch 11.201), train_loss = 1.22077434, grad/param norm = 1.7040e-01, time/batch = 19.1390s	
6688/29850 (epoch 11.203), train_loss = 1.15984821, grad/param norm = 1.6895e-01, time/batch = 18.0135s	
6689/29850 (epoch 11.204), train_loss = 1.34911912, grad/param norm = 2.0101e-01, time/batch = 17.4548s	
6690/29850 (epoch 11.206), train_loss = 1.17781582, grad/param norm = 1.8634e-01, time/batch = 20.0347s	
6691/29850 (epoch 11.208), train_loss = 1.47304481, grad/param norm = 1.8437e-01, time/batch = 18.0447s	
6692/29850 (epoch 11.209), train_loss = 1.18601016, grad/param norm = 1.7227e-01, time/batch = 16.8789s	
6693/29850 (epoch 11.211), train_loss = 1.23831177, grad/param norm = 1.6954e-01, time/batch = 19.0411s	
6694/29850 (epoch 11.213), train_loss = 1.41889027, grad/param norm = 1.9292e-01, time/batch = 17.5464s	
6695/29850 (epoch 11.214), train_loss = 1.18794240, grad/param norm = 1.5929e-01, time/batch = 19.4704s	
6696/29850 (epoch 11.216), train_loss = 1.24237062, grad/param norm = 1.8092e-01, time/batch = 16.5442s	
6697/29850 (epoch 11.218), train_loss = 1.34796753, grad/param norm = 1.8231e-01, time/batch = 17.4241s	
6698/29850 (epoch 11.219), train_loss = 1.44951501, grad/param norm = 1.9933e-01, time/batch = 17.8610s	
6699/29850 (epoch 11.221), train_loss = 1.26361445, grad/param norm = 1.9615e-01, time/batch = 17.1454s	
6700/29850 (epoch 11.223), train_loss = 1.24828663, grad/param norm = 1.8314e-01, time/batch = 16.4835s	
6701/29850 (epoch 11.224), train_loss = 1.16627708, grad/param norm = 1.7540e-01, time/batch = 16.3656s	
6702/29850 (epoch 11.226), train_loss = 1.17395143, grad/param norm = 1.6257e-01, time/batch = 17.3947s	
6703/29850 (epoch 11.228), train_loss = 1.21725353, grad/param norm = 1.6197e-01, time/batch = 16.3695s	
6704/29850 (epoch 11.229), train_loss = 1.12131566, grad/param norm = 1.5901e-01, time/batch = 17.4695s	
6705/29850 (epoch 11.231), train_loss = 1.21499018, grad/param norm = 1.6131e-01, time/batch = 17.0161s	
6706/29850 (epoch 11.233), train_loss = 1.25139909, grad/param norm = 1.6920e-01, time/batch = 14.5816s	
6707/29850 (epoch 11.235), train_loss = 1.17456275, grad/param norm = 1.5068e-01, time/batch = 17.8046s	
6708/29850 (epoch 11.236), train_loss = 1.40837931, grad/param norm = 2.0774e-01, time/batch = 15.2041s	
6709/29850 (epoch 11.238), train_loss = 1.12281898, grad/param norm = 1.7691e-01, time/batch = 17.4496s	
6710/29850 (epoch 11.240), train_loss = 1.19354248, grad/param norm = 1.7466e-01, time/batch = 16.0463s	
6711/29850 (epoch 11.241), train_loss = 1.41988282, grad/param norm = 2.0027e-01, time/batch = 19.3736s	
6712/29850 (epoch 11.243), train_loss = 1.26419200, grad/param norm = 1.8068e-01, time/batch = 18.0370s	
6713/29850 (epoch 11.245), train_loss = 1.21265819, grad/param norm = 1.8459e-01, time/batch = 17.8062s	
6714/29850 (epoch 11.246), train_loss = 1.17880421, grad/param norm = 1.8122e-01, time/batch = 18.2119s	
6715/29850 (epoch 11.248), train_loss = 1.18820482, grad/param norm = 1.6849e-01, time/batch = 17.1261s	
6716/29850 (epoch 11.250), train_loss = 1.25158218, grad/param norm = 1.6481e-01, time/batch = 19.2113s	
6717/29850 (epoch 11.251), train_loss = 1.16643483, grad/param norm = 1.7666e-01, time/batch = 16.8180s	
6718/29850 (epoch 11.253), train_loss = 1.11884220, grad/param norm = 1.8574e-01, time/batch = 17.6972s	
6719/29850 (epoch 11.255), train_loss = 1.16527696, grad/param norm = 1.6469e-01, time/batch = 17.2090s	
6720/29850 (epoch 11.256), train_loss = 1.29547410, grad/param norm = 1.8577e-01, time/batch = 16.2849s	
6721/29850 (epoch 11.258), train_loss = 1.24921264, grad/param norm = 1.6672e-01, time/batch = 17.1406s	
6722/29850 (epoch 11.260), train_loss = 1.22026183, grad/param norm = 1.7108e-01, time/batch = 15.3010s	
6723/29850 (epoch 11.261), train_loss = 1.22022059, grad/param norm = 1.7271e-01, time/batch = 17.8125s	
6724/29850 (epoch 11.263), train_loss = 1.12484974, grad/param norm = 1.6359e-01, time/batch = 17.3066s	
6725/29850 (epoch 11.265), train_loss = 1.21749325, grad/param norm = 1.8886e-01, time/batch = 18.2123s	
6726/29850 (epoch 11.266), train_loss = 1.22576322, grad/param norm = 1.8086e-01, time/batch = 16.6168s	
6727/29850 (epoch 11.268), train_loss = 1.20051993, grad/param norm = 1.6930e-01, time/batch = 18.7667s	
6728/29850 (epoch 11.270), train_loss = 1.15465849, grad/param norm = 1.5722e-01, time/batch = 18.1462s	
6729/29850 (epoch 11.271), train_loss = 1.34279391, grad/param norm = 1.7290e-01, time/batch = 18.5368s	
6730/29850 (epoch 11.273), train_loss = 1.11787698, grad/param norm = 1.6780e-01, time/batch = 16.8980s	
6731/29850 (epoch 11.275), train_loss = 1.13376138, grad/param norm = 1.7059e-01, time/batch = 18.2158s	
6732/29850 (epoch 11.276), train_loss = 1.13588047, grad/param norm = 1.6508e-01, time/batch = 15.8584s	
6733/29850 (epoch 11.278), train_loss = 1.21314037, grad/param norm = 1.7051e-01, time/batch = 18.6367s	
6734/29850 (epoch 11.280), train_loss = 1.37940698, grad/param norm = 2.0141e-01, time/batch = 17.7128s	
6735/29850 (epoch 11.281), train_loss = 1.24761821, grad/param norm = 1.7575e-01, time/batch = 17.7885s	
6736/29850 (epoch 11.283), train_loss = 1.34861185, grad/param norm = 1.9580e-01, time/batch = 16.9445s	
6737/29850 (epoch 11.285), train_loss = 1.21427228, grad/param norm = 1.6972e-01, time/batch = 17.1313s	
6738/29850 (epoch 11.286), train_loss = 1.29328396, grad/param norm = 1.7789e-01, time/batch = 18.5546s	
6739/29850 (epoch 11.288), train_loss = 1.43559254, grad/param norm = 2.1752e-01, time/batch = 15.4704s	
6740/29850 (epoch 11.290), train_loss = 1.19033054, grad/param norm = 1.7018e-01, time/batch = 16.8772s	
6741/29850 (epoch 11.291), train_loss = 1.51819664, grad/param norm = 1.8212e-01, time/batch = 17.6810s	
6742/29850 (epoch 11.293), train_loss = 1.33333341, grad/param norm = 1.7816e-01, time/batch = 16.9727s	
6743/29850 (epoch 11.295), train_loss = 1.42534857, grad/param norm = 1.7802e-01, time/batch = 19.6924s	
6744/29850 (epoch 11.296), train_loss = 1.18720498, grad/param norm = 1.6439e-01, time/batch = 19.1294s	
6745/29850 (epoch 11.298), train_loss = 1.04920877, grad/param norm = 1.6870e-01, time/batch = 18.3645s	
6746/29850 (epoch 11.300), train_loss = 1.11966860, grad/param norm = 1.5705e-01, time/batch = 18.9453s	
6747/29850 (epoch 11.302), train_loss = 1.11885313, grad/param norm = 1.6200e-01, time/batch = 18.3649s	
6748/29850 (epoch 11.303), train_loss = 1.19841722, grad/param norm = 1.6559e-01, time/batch = 18.7165s	
6749/29850 (epoch 11.305), train_loss = 1.24468712, grad/param norm = 1.6698e-01, time/batch = 15.6295s	
6750/29850 (epoch 11.307), train_loss = 1.34678986, grad/param norm = 1.7172e-01, time/batch = 17.4701s	
6751/29850 (epoch 11.308), train_loss = 1.25754714, grad/param norm = 1.8972e-01, time/batch = 19.2102s	
6752/29850 (epoch 11.310), train_loss = 1.27131279, grad/param norm = 1.7934e-01, time/batch = 16.2032s	
6753/29850 (epoch 11.312), train_loss = 1.34968794, grad/param norm = 1.8010e-01, time/batch = 19.1211s	
6754/29850 (epoch 11.313), train_loss = 1.30827640, grad/param norm = 1.8513e-01, time/batch = 15.6310s	
6755/29850 (epoch 11.315), train_loss = 1.28761446, grad/param norm = 1.7850e-01, time/batch = 18.4811s	
6756/29850 (epoch 11.317), train_loss = 1.29959669, grad/param norm = 2.2070e-01, time/batch = 17.2771s	
6757/29850 (epoch 11.318), train_loss = 1.24744452, grad/param norm = 1.7274e-01, time/batch = 18.1368s	
6758/29850 (epoch 11.320), train_loss = 1.14548527, grad/param norm = 1.5997e-01, time/batch = 17.0718s	
6759/29850 (epoch 11.322), train_loss = 1.42656771, grad/param norm = 1.8822e-01, time/batch = 16.1434s	
6760/29850 (epoch 11.323), train_loss = 1.30361373, grad/param norm = 2.0073e-01, time/batch = 17.3659s	
6761/29850 (epoch 11.325), train_loss = 1.26482563, grad/param norm = 1.6830e-01, time/batch = 15.2593s	
6762/29850 (epoch 11.327), train_loss = 1.41669601, grad/param norm = 1.9744e-01, time/batch = 18.8765s	
6763/29850 (epoch 11.328), train_loss = 1.40218370, grad/param norm = 1.8073e-01, time/batch = 18.9447s	
6764/29850 (epoch 11.330), train_loss = 1.26584237, grad/param norm = 1.6915e-01, time/batch = 18.7209s	
6765/29850 (epoch 11.332), train_loss = 1.18755827, grad/param norm = 1.6919e-01, time/batch = 17.7064s	
6766/29850 (epoch 11.333), train_loss = 1.40104906, grad/param norm = 1.7634e-01, time/batch = 16.6229s	
6767/29850 (epoch 11.335), train_loss = 1.31342386, grad/param norm = 1.7635e-01, time/batch = 18.8792s	
6768/29850 (epoch 11.337), train_loss = 1.28610590, grad/param norm = 1.7629e-01, time/batch = 17.4561s	
6769/29850 (epoch 11.338), train_loss = 1.25770669, grad/param norm = 1.6623e-01, time/batch = 17.3000s	
6770/29850 (epoch 11.340), train_loss = 1.14470597, grad/param norm = 1.7408e-01, time/batch = 17.2000s	
6771/29850 (epoch 11.342), train_loss = 1.29647292, grad/param norm = 1.7485e-01, time/batch = 16.0267s	
6772/29850 (epoch 11.343), train_loss = 1.30653185, grad/param norm = 1.9026e-01, time/batch = 17.6186s	
6773/29850 (epoch 11.345), train_loss = 1.35725898, grad/param norm = 1.8673e-01, time/batch = 16.0239s	
6774/29850 (epoch 11.347), train_loss = 1.36076254, grad/param norm = 1.8294e-01, time/batch = 15.8666s	
6775/29850 (epoch 11.348), train_loss = 1.22220333, grad/param norm = 1.5465e-01, time/batch = 18.6412s	
6776/29850 (epoch 11.350), train_loss = 1.35502943, grad/param norm = 1.7523e-01, time/batch = 17.9256s	
6777/29850 (epoch 11.352), train_loss = 1.27550312, grad/param norm = 1.7313e-01, time/batch = 19.1279s	
6778/29850 (epoch 11.353), train_loss = 1.32492118, grad/param norm = 1.7960e-01, time/batch = 17.5588s	
6779/29850 (epoch 11.355), train_loss = 1.16177080, grad/param norm = 1.7333e-01, time/batch = 17.2938s	
6780/29850 (epoch 11.357), train_loss = 1.41463445, grad/param norm = 1.8391e-01, time/batch = 18.0304s	
6781/29850 (epoch 11.358), train_loss = 1.14527117, grad/param norm = 1.6635e-01, time/batch = 17.8135s	
6782/29850 (epoch 11.360), train_loss = 1.26425753, grad/param norm = 1.7364e-01, time/batch = 16.7330s	
6783/29850 (epoch 11.362), train_loss = 1.24673661, grad/param norm = 1.7906e-01, time/batch = 16.8885s	
6784/29850 (epoch 11.363), train_loss = 1.28195077, grad/param norm = 1.7874e-01, time/batch = 18.7898s	
6785/29850 (epoch 11.365), train_loss = 1.42584897, grad/param norm = 1.9536e-01, time/batch = 16.2941s	
6786/29850 (epoch 11.367), train_loss = 1.24289444, grad/param norm = 1.7387e-01, time/batch = 17.6105s	
6787/29850 (epoch 11.369), train_loss = 1.17022751, grad/param norm = 1.7338e-01, time/batch = 17.5284s	
6788/29850 (epoch 11.370), train_loss = 1.08294230, grad/param norm = 1.6075e-01, time/batch = 18.3729s	
6789/29850 (epoch 11.372), train_loss = 1.44230921, grad/param norm = 1.9978e-01, time/batch = 17.7859s	
6790/29850 (epoch 11.374), train_loss = 1.25993815, grad/param norm = 1.9731e-01, time/batch = 16.3570s	
6791/29850 (epoch 11.375), train_loss = 1.26174433, grad/param norm = 1.7754e-01, time/batch = 19.1117s	
6792/29850 (epoch 11.377), train_loss = 1.28530616, grad/param norm = 1.8322e-01, time/batch = 19.0447s	
6793/29850 (epoch 11.379), train_loss = 1.34537584, grad/param norm = 1.7945e-01, time/batch = 15.6192s	
6794/29850 (epoch 11.380), train_loss = 1.33017797, grad/param norm = 1.8920e-01, time/batch = 18.7997s	
6795/29850 (epoch 11.382), train_loss = 1.31952403, grad/param norm = 1.8478e-01, time/batch = 18.9640s	
6796/29850 (epoch 11.384), train_loss = 1.29858857, grad/param norm = 1.8981e-01, time/batch = 17.1334s	
6797/29850 (epoch 11.385), train_loss = 1.25476131, grad/param norm = 1.7665e-01, time/batch = 18.3882s	
6798/29850 (epoch 11.387), train_loss = 1.29268713, grad/param norm = 1.8797e-01, time/batch = 18.3879s	
6799/29850 (epoch 11.389), train_loss = 1.43553832, grad/param norm = 1.7255e-01, time/batch = 17.5444s	
6800/29850 (epoch 11.390), train_loss = 1.30949098, grad/param norm = 1.6421e-01, time/batch = 17.4579s	
6801/29850 (epoch 11.392), train_loss = 1.25901277, grad/param norm = 1.8882e-01, time/batch = 16.7302s	
6802/29850 (epoch 11.394), train_loss = 1.37449407, grad/param norm = 1.8287e-01, time/batch = 20.0428s	
6803/29850 (epoch 11.395), train_loss = 1.28892511, grad/param norm = 1.8496e-01, time/batch = 16.3017s	
6804/29850 (epoch 11.397), train_loss = 1.22766221, grad/param norm = 1.7189e-01, time/batch = 17.8723s	
6805/29850 (epoch 11.399), train_loss = 1.16838982, grad/param norm = 1.8140e-01, time/batch = 18.4547s	
6806/29850 (epoch 11.400), train_loss = 1.56306116, grad/param norm = 2.3105e-01, time/batch = 15.6418s	
6807/29850 (epoch 11.402), train_loss = 1.43073728, grad/param norm = 1.8731e-01, time/batch = 16.2797s	
6808/29850 (epoch 11.404), train_loss = 1.34639735, grad/param norm = 1.8676e-01, time/batch = 17.4475s	
6809/29850 (epoch 11.405), train_loss = 1.31507321, grad/param norm = 1.9816e-01, time/batch = 18.1401s	
6810/29850 (epoch 11.407), train_loss = 1.24549718, grad/param norm = 1.8582e-01, time/batch = 16.9061s	
6811/29850 (epoch 11.409), train_loss = 1.44033239, grad/param norm = 2.1167e-01, time/batch = 18.2919s	
6812/29850 (epoch 11.410), train_loss = 1.44966132, grad/param norm = 1.8209e-01, time/batch = 17.3066s	
6813/29850 (epoch 11.412), train_loss = 1.32735527, grad/param norm = 1.8242e-01, time/batch = 17.0460s	
6814/29850 (epoch 11.414), train_loss = 1.33495942, grad/param norm = 2.0420e-01, time/batch = 17.0425s	
6815/29850 (epoch 11.415), train_loss = 1.28449348, grad/param norm = 1.6353e-01, time/batch = 18.0548s	
6816/29850 (epoch 11.417), train_loss = 1.43765171, grad/param norm = 1.8777e-01, time/batch = 18.0201s	
6817/29850 (epoch 11.419), train_loss = 1.32107102, grad/param norm = 1.7884e-01, time/batch = 17.8021s	
6818/29850 (epoch 11.420), train_loss = 1.26660394, grad/param norm = 1.6929e-01, time/batch = 17.4703s	
6819/29850 (epoch 11.422), train_loss = 1.24286943, grad/param norm = 1.6951e-01, time/batch = 16.7963s	
6820/29850 (epoch 11.424), train_loss = 1.29037400, grad/param norm = 1.8477e-01, time/batch = 16.4495s	
6821/29850 (epoch 11.425), train_loss = 1.49738875, grad/param norm = 1.7649e-01, time/batch = 18.3797s	
6822/29850 (epoch 11.427), train_loss = 1.11748345, grad/param norm = 1.6129e-01, time/batch = 17.6362s	
6823/29850 (epoch 11.429), train_loss = 1.16086968, grad/param norm = 1.6737e-01, time/batch = 14.4898s	
6824/29850 (epoch 11.430), train_loss = 1.10530375, grad/param norm = 1.6851e-01, time/batch = 16.1878s	
6825/29850 (epoch 11.432), train_loss = 1.25635817, grad/param norm = 1.8428e-01, time/batch = 18.9555s	
6826/29850 (epoch 11.434), train_loss = 1.16610245, grad/param norm = 1.7524e-01, time/batch = 16.8071s	
6827/29850 (epoch 11.436), train_loss = 1.33214935, grad/param norm = 1.8271e-01, time/batch = 16.8832s	
6828/29850 (epoch 11.437), train_loss = 1.32939230, grad/param norm = 1.6651e-01, time/batch = 19.1978s	
6829/29850 (epoch 11.439), train_loss = 1.29455138, grad/param norm = 1.7094e-01, time/batch = 18.2239s	
6830/29850 (epoch 11.441), train_loss = 1.29255688, grad/param norm = 1.8315e-01, time/batch = 18.2088s	
6831/29850 (epoch 11.442), train_loss = 1.31007567, grad/param norm = 1.7763e-01, time/batch = 17.0431s	
6832/29850 (epoch 11.444), train_loss = 1.25527727, grad/param norm = 1.5899e-01, time/batch = 17.1096s	
6833/29850 (epoch 11.446), train_loss = 1.31964311, grad/param norm = 1.7672e-01, time/batch = 14.8757s	
6834/29850 (epoch 11.447), train_loss = 1.37572197, grad/param norm = 1.8782e-01, time/batch = 16.8041s	
6835/29850 (epoch 11.449), train_loss = 1.36602174, grad/param norm = 1.9554e-01, time/batch = 18.0292s	
6836/29850 (epoch 11.451), train_loss = 1.16039126, grad/param norm = 1.7881e-01, time/batch = 18.8071s	
6837/29850 (epoch 11.452), train_loss = 1.00983726, grad/param norm = 1.4704e-01, time/batch = 19.1920s	
6838/29850 (epoch 11.454), train_loss = 1.14084864, grad/param norm = 1.5392e-01, time/batch = 31.2943s	
6839/29850 (epoch 11.456), train_loss = 1.35649663, grad/param norm = 1.8685e-01, time/batch = 16.8856s	
6840/29850 (epoch 11.457), train_loss = 1.37899260, grad/param norm = 2.0526e-01, time/batch = 16.1174s	
6841/29850 (epoch 11.459), train_loss = 1.45081380, grad/param norm = 1.8093e-01, time/batch = 19.9513s	
6842/29850 (epoch 11.461), train_loss = 1.44587789, grad/param norm = 1.7507e-01, time/batch = 16.9759s	
6843/29850 (epoch 11.462), train_loss = 1.39030144, grad/param norm = 1.8807e-01, time/batch = 18.1352s	
6844/29850 (epoch 11.464), train_loss = 1.30546139, grad/param norm = 1.6709e-01, time/batch = 16.0152s	
6845/29850 (epoch 11.466), train_loss = 1.18547222, grad/param norm = 1.7897e-01, time/batch = 17.6177s	
6846/29850 (epoch 11.467), train_loss = 1.28932738, grad/param norm = 1.7633e-01, time/batch = 19.0613s	
6847/29850 (epoch 11.469), train_loss = 1.26658874, grad/param norm = 1.7159e-01, time/batch = 17.1950s	
6848/29850 (epoch 11.471), train_loss = 1.29813094, grad/param norm = 1.7574e-01, time/batch = 19.3841s	
6849/29850 (epoch 11.472), train_loss = 1.18349164, grad/param norm = 1.7398e-01, time/batch = 19.2252s	
6850/29850 (epoch 11.474), train_loss = 1.42044864, grad/param norm = 1.8060e-01, time/batch = 17.8631s	
6851/29850 (epoch 11.476), train_loss = 1.32119648, grad/param norm = 1.7624e-01, time/batch = 17.6208s	
6852/29850 (epoch 11.477), train_loss = 1.32037933, grad/param norm = 1.8883e-01, time/batch = 18.2199s	
6853/29850 (epoch 11.479), train_loss = 1.40044801, grad/param norm = 1.8386e-01, time/batch = 18.2083s	
6854/29850 (epoch 11.481), train_loss = 1.34933324, grad/param norm = 2.0079e-01, time/batch = 17.5565s	
6855/29850 (epoch 11.482), train_loss = 1.19755211, grad/param norm = 1.5052e-01, time/batch = 18.6034s	
6856/29850 (epoch 11.484), train_loss = 1.24206089, grad/param norm = 1.7216e-01, time/batch = 16.3837s	
6857/29850 (epoch 11.486), train_loss = 1.28012815, grad/param norm = 1.7737e-01, time/batch = 15.8622s	
6858/29850 (epoch 11.487), train_loss = 1.25392720, grad/param norm = 1.8419e-01, time/batch = 19.1330s	
6859/29850 (epoch 11.489), train_loss = 1.28934538, grad/param norm = 1.8394e-01, time/batch = 16.1129s	
6860/29850 (epoch 11.491), train_loss = 1.13975004, grad/param norm = 1.5631e-01, time/batch = 16.7069s	
6861/29850 (epoch 11.492), train_loss = 1.33047887, grad/param norm = 1.8396e-01, time/batch = 18.4452s	
6862/29850 (epoch 11.494), train_loss = 1.43333879, grad/param norm = 1.7398e-01, time/batch = 18.8853s	
6863/29850 (epoch 11.496), train_loss = 1.45656078, grad/param norm = 1.7770e-01, time/batch = 16.2201s	
6864/29850 (epoch 11.497), train_loss = 1.33031558, grad/param norm = 1.7277e-01, time/batch = 19.1133s	
6865/29850 (epoch 11.499), train_loss = 1.31333620, grad/param norm = 1.7046e-01, time/batch = 17.1962s	
6866/29850 (epoch 11.501), train_loss = 1.23501041, grad/param norm = 1.7816e-01, time/batch = 18.4667s	
6867/29850 (epoch 11.503), train_loss = 1.26542143, grad/param norm = 1.6180e-01, time/batch = 17.7761s	
6868/29850 (epoch 11.504), train_loss = 1.48078453, grad/param norm = 1.7627e-01, time/batch = 15.3740s	
6869/29850 (epoch 11.506), train_loss = 1.49546519, grad/param norm = 1.9050e-01, time/batch = 18.8632s	
6870/29850 (epoch 11.508), train_loss = 1.25418093, grad/param norm = 1.7132e-01, time/batch = 16.6985s	
6871/29850 (epoch 11.509), train_loss = 1.07877467, grad/param norm = 1.6423e-01, time/batch = 18.3441s	
6872/29850 (epoch 11.511), train_loss = 1.27429134, grad/param norm = 1.6621e-01, time/batch = 16.6373s	
6873/29850 (epoch 11.513), train_loss = 1.34424497, grad/param norm = 1.9960e-01, time/batch = 16.8998s	
6874/29850 (epoch 11.514), train_loss = 1.16067593, grad/param norm = 1.6901e-01, time/batch = 15.2807s	
6875/29850 (epoch 11.516), train_loss = 1.17285474, grad/param norm = 1.7659e-01, time/batch = 18.4624s	
6876/29850 (epoch 11.518), train_loss = 1.13668103, grad/param norm = 1.6256e-01, time/batch = 17.8790s	
6877/29850 (epoch 11.519), train_loss = 1.13314043, grad/param norm = 1.7053e-01, time/batch = 16.7941s	
6878/29850 (epoch 11.521), train_loss = 1.12858923, grad/param norm = 1.5804e-01, time/batch = 18.7100s	
6879/29850 (epoch 11.523), train_loss = 1.11689099, grad/param norm = 1.4400e-01, time/batch = 15.1217s	
6880/29850 (epoch 11.524), train_loss = 1.25516159, grad/param norm = 1.8787e-01, time/batch = 16.8918s	
6881/29850 (epoch 11.526), train_loss = 1.34899232, grad/param norm = 1.8673e-01, time/batch = 17.3707s	
6882/29850 (epoch 11.528), train_loss = 1.45356720, grad/param norm = 1.9627e-01, time/batch = 16.7992s	
6883/29850 (epoch 11.529), train_loss = 1.35387731, grad/param norm = 1.7920e-01, time/batch = 18.9641s	
6884/29850 (epoch 11.531), train_loss = 1.31816481, grad/param norm = 2.0613e-01, time/batch = 17.2169s	
6885/29850 (epoch 11.533), train_loss = 1.23706941, grad/param norm = 1.8093e-01, time/batch = 18.2212s	
6886/29850 (epoch 11.534), train_loss = 1.24994900, grad/param norm = 1.7386e-01, time/batch = 18.5510s	
6887/29850 (epoch 11.536), train_loss = 1.28464052, grad/param norm = 1.9247e-01, time/batch = 18.0142s	
6888/29850 (epoch 11.538), train_loss = 1.37349019, grad/param norm = 1.7933e-01, time/batch = 18.4417s	
6889/29850 (epoch 11.539), train_loss = 1.42839778, grad/param norm = 1.7148e-01, time/batch = 15.7074s	
6890/29850 (epoch 11.541), train_loss = 1.09840116, grad/param norm = 1.5919e-01, time/batch = 17.9716s	
6891/29850 (epoch 11.543), train_loss = 1.27444844, grad/param norm = 1.6851e-01, time/batch = 15.7046s	
6892/29850 (epoch 11.544), train_loss = 1.30335278, grad/param norm = 1.7923e-01, time/batch = 19.6194s	
6893/29850 (epoch 11.546), train_loss = 1.36462777, grad/param norm = 1.7038e-01, time/batch = 16.7315s	
6894/29850 (epoch 11.548), train_loss = 1.15347195, grad/param norm = 1.6848e-01, time/batch = 18.0453s	
6895/29850 (epoch 11.549), train_loss = 1.21902057, grad/param norm = 1.6819e-01, time/batch = 19.6139s	
6896/29850 (epoch 11.551), train_loss = 1.18719696, grad/param norm = 1.7484e-01, time/batch = 17.8915s	
6897/29850 (epoch 11.553), train_loss = 1.29526051, grad/param norm = 1.7124e-01, time/batch = 17.0345s	
6898/29850 (epoch 11.554), train_loss = 1.05953329, grad/param norm = 1.5238e-01, time/batch = 16.1265s	
6899/29850 (epoch 11.556), train_loss = 1.23074360, grad/param norm = 1.6969e-01, time/batch = 16.1437s	
6900/29850 (epoch 11.558), train_loss = 1.18777295, grad/param norm = 1.5908e-01, time/batch = 17.6342s	
6901/29850 (epoch 11.559), train_loss = 1.30208747, grad/param norm = 1.8303e-01, time/batch = 16.4736s	
6902/29850 (epoch 11.561), train_loss = 1.35165538, grad/param norm = 1.8878e-01, time/batch = 19.6268s	
6903/29850 (epoch 11.563), train_loss = 1.24482926, grad/param norm = 1.6551e-01, time/batch = 17.0645s	
6904/29850 (epoch 11.564), train_loss = 1.25410317, grad/param norm = 1.7675e-01, time/batch = 17.9556s	
6905/29850 (epoch 11.566), train_loss = 1.21999636, grad/param norm = 1.6540e-01, time/batch = 16.9447s	
6906/29850 (epoch 11.568), train_loss = 1.36290952, grad/param norm = 1.6641e-01, time/batch = 17.5570s	
6907/29850 (epoch 11.570), train_loss = 1.28726709, grad/param norm = 1.7091e-01, time/batch = 18.3851s	
6908/29850 (epoch 11.571), train_loss = 1.30700949, grad/param norm = 1.8179e-01, time/batch = 15.6460s	
6909/29850 (epoch 11.573), train_loss = 1.41773714, grad/param norm = 1.9739e-01, time/batch = 18.2842s	
6910/29850 (epoch 11.575), train_loss = 1.38156028, grad/param norm = 1.7023e-01, time/batch = 17.9811s	
6911/29850 (epoch 11.576), train_loss = 1.41591317, grad/param norm = 1.7765e-01, time/batch = 18.4608s	
6912/29850 (epoch 11.578), train_loss = 1.31306263, grad/param norm = 1.6791e-01, time/batch = 17.8661s	
6913/29850 (epoch 11.580), train_loss = 1.39032688, grad/param norm = 1.7222e-01, time/batch = 19.0376s	
6914/29850 (epoch 11.581), train_loss = 1.20664065, grad/param norm = 1.7668e-01, time/batch = 18.1193s	
6915/29850 (epoch 11.583), train_loss = 1.25079392, grad/param norm = 1.7774e-01, time/batch = 18.7019s	
6916/29850 (epoch 11.585), train_loss = 1.31315529, grad/param norm = 1.7921e-01, time/batch = 19.0378s	
6917/29850 (epoch 11.586), train_loss = 1.32087502, grad/param norm = 1.8211e-01, time/batch = 18.3816s	
6918/29850 (epoch 11.588), train_loss = 1.21706880, grad/param norm = 1.7045e-01, time/batch = 17.3617s	
6919/29850 (epoch 11.590), train_loss = 1.27279966, grad/param norm = 1.6986e-01, time/batch = 18.5435s	
6920/29850 (epoch 11.591), train_loss = 1.19917235, grad/param norm = 1.6766e-01, time/batch = 19.4521s	
6921/29850 (epoch 11.593), train_loss = 1.18276652, grad/param norm = 1.6003e-01, time/batch = 15.5874s	
6922/29850 (epoch 11.595), train_loss = 1.16331531, grad/param norm = 1.5773e-01, time/batch = 17.2272s	
6923/29850 (epoch 11.596), train_loss = 1.13251255, grad/param norm = 1.6627e-01, time/batch = 18.2148s	
6924/29850 (epoch 11.598), train_loss = 1.15725875, grad/param norm = 1.6155e-01, time/batch = 18.1954s	
6925/29850 (epoch 11.600), train_loss = 1.38163761, grad/param norm = 1.9797e-01, time/batch = 18.3787s	
6926/29850 (epoch 11.601), train_loss = 1.13902096, grad/param norm = 1.5922e-01, time/batch = 17.7168s	
6927/29850 (epoch 11.603), train_loss = 1.25825991, grad/param norm = 1.7790e-01, time/batch = 18.7020s	
6928/29850 (epoch 11.605), train_loss = 1.28610035, grad/param norm = 1.8900e-01, time/batch = 17.8766s	
6929/29850 (epoch 11.606), train_loss = 1.04072695, grad/param norm = 1.6471e-01, time/batch = 17.7014s	
6930/29850 (epoch 11.608), train_loss = 1.26800120, grad/param norm = 1.7425e-01, time/batch = 16.7119s	
6931/29850 (epoch 11.610), train_loss = 1.26287274, grad/param norm = 1.6694e-01, time/batch = 17.5271s	
6932/29850 (epoch 11.611), train_loss = 1.10217978, grad/param norm = 1.5284e-01, time/batch = 15.6458s	
6933/29850 (epoch 11.613), train_loss = 1.02326367, grad/param norm = 1.4583e-01, time/batch = 18.1325s	
6934/29850 (epoch 11.615), train_loss = 1.11895803, grad/param norm = 1.6182e-01, time/batch = 17.2032s	
6935/29850 (epoch 11.616), train_loss = 1.18269420, grad/param norm = 1.7351e-01, time/batch = 16.9322s	
6936/29850 (epoch 11.618), train_loss = 1.23998625, grad/param norm = 1.6263e-01, time/batch = 18.2069s	
6937/29850 (epoch 11.620), train_loss = 1.28052327, grad/param norm = 1.8122e-01, time/batch = 18.5651s	
6938/29850 (epoch 11.621), train_loss = 1.34898484, grad/param norm = 1.9141e-01, time/batch = 15.9683s	
6939/29850 (epoch 11.623), train_loss = 1.36138286, grad/param norm = 1.8350e-01, time/batch = 15.8020s	
6940/29850 (epoch 11.625), train_loss = 1.30728251, grad/param norm = 1.7965e-01, time/batch = 17.9493s	
6941/29850 (epoch 11.626), train_loss = 1.30660792, grad/param norm = 1.8188e-01, time/batch = 17.9485s	
6942/29850 (epoch 11.628), train_loss = 1.13811270, grad/param norm = 1.6798e-01, time/batch = 16.2135s	
6943/29850 (epoch 11.630), train_loss = 1.27266392, grad/param norm = 1.8165e-01, time/batch = 18.1513s	
6944/29850 (epoch 11.631), train_loss = 1.19572927, grad/param norm = 1.7932e-01, time/batch = 18.3075s	
6945/29850 (epoch 11.633), train_loss = 1.35035598, grad/param norm = 1.9235e-01, time/batch = 15.1960s	
6946/29850 (epoch 11.635), train_loss = 1.25682244, grad/param norm = 1.7617e-01, time/batch = 18.8698s	
6947/29850 (epoch 11.637), train_loss = 1.25879941, grad/param norm = 1.7903e-01, time/batch = 17.8049s	
6948/29850 (epoch 11.638), train_loss = 1.21561340, grad/param norm = 1.6531e-01, time/batch = 17.5381s	
6949/29850 (epoch 11.640), train_loss = 1.40918280, grad/param norm = 1.9419e-01, time/batch = 19.2852s	
6950/29850 (epoch 11.642), train_loss = 1.21417063, grad/param norm = 1.6581e-01, time/batch = 19.1948s	
6951/29850 (epoch 11.643), train_loss = 1.17274410, grad/param norm = 1.6675e-01, time/batch = 18.1785s	
6952/29850 (epoch 11.645), train_loss = 1.28561051, grad/param norm = 1.8335e-01, time/batch = 19.6004s	
6953/29850 (epoch 11.647), train_loss = 1.39182355, grad/param norm = 1.7537e-01, time/batch = 17.1352s	
6954/29850 (epoch 11.648), train_loss = 1.14556723, grad/param norm = 1.6067e-01, time/batch = 19.2812s	
6955/29850 (epoch 11.650), train_loss = 1.24217148, grad/param norm = 1.8494e-01, time/batch = 8.8872s	
6956/29850 (epoch 11.652), train_loss = 1.27146379, grad/param norm = 1.8379e-01, time/batch = 0.6625s	
6957/29850 (epoch 11.653), train_loss = 1.39196251, grad/param norm = 1.8413e-01, time/batch = 0.6677s	
6958/29850 (epoch 11.655), train_loss = 1.24936626, grad/param norm = 1.6322e-01, time/batch = 0.6721s	
6959/29850 (epoch 11.657), train_loss = 1.22288373, grad/param norm = 1.6448e-01, time/batch = 0.6703s	
6960/29850 (epoch 11.658), train_loss = 1.36838853, grad/param norm = 1.7598e-01, time/batch = 0.6593s	
6961/29850 (epoch 11.660), train_loss = 1.22422125, grad/param norm = 1.8158e-01, time/batch = 0.6531s	
6962/29850 (epoch 11.662), train_loss = 1.29952696, grad/param norm = 1.9177e-01, time/batch = 0.6517s	
6963/29850 (epoch 11.663), train_loss = 1.40004887, grad/param norm = 1.8863e-01, time/batch = 0.9840s	
6964/29850 (epoch 11.665), train_loss = 1.33891265, grad/param norm = 1.8503e-01, time/batch = 0.9559s	
6965/29850 (epoch 11.667), train_loss = 1.35554491, grad/param norm = 2.0945e-01, time/batch = 0.9690s	
6966/29850 (epoch 11.668), train_loss = 1.29434597, grad/param norm = 1.7808e-01, time/batch = 0.9892s	
6967/29850 (epoch 11.670), train_loss = 1.49605402, grad/param norm = 2.0715e-01, time/batch = 0.9661s	
6968/29850 (epoch 11.672), train_loss = 1.35719909, grad/param norm = 1.9567e-01, time/batch = 1.6885s	
6969/29850 (epoch 11.673), train_loss = 1.37760158, grad/param norm = 1.8835e-01, time/batch = 1.8067s	
6970/29850 (epoch 11.675), train_loss = 1.23434278, grad/param norm = 1.6796e-01, time/batch = 2.8393s	
6971/29850 (epoch 11.677), train_loss = 1.25514602, grad/param norm = 1.8351e-01, time/batch = 16.6419s	
6972/29850 (epoch 11.678), train_loss = 1.24958558, grad/param norm = 1.7697e-01, time/batch = 18.3860s	
6973/29850 (epoch 11.680), train_loss = 1.30428594, grad/param norm = 1.8084e-01, time/batch = 15.8516s	
6974/29850 (epoch 11.682), train_loss = 1.26820713, grad/param norm = 1.8333e-01, time/batch = 18.5507s	
6975/29850 (epoch 11.683), train_loss = 1.44780043, grad/param norm = 2.1496e-01, time/batch = 18.6307s	
6976/29850 (epoch 11.685), train_loss = 1.42133028, grad/param norm = 1.7131e-01, time/batch = 16.5652s	
6977/29850 (epoch 11.687), train_loss = 1.34605326, grad/param norm = 1.7703e-01, time/batch = 18.4692s	
6978/29850 (epoch 11.688), train_loss = 1.15502178, grad/param norm = 1.4796e-01, time/batch = 18.6112s	
6979/29850 (epoch 11.690), train_loss = 1.18250841, grad/param norm = 1.8149e-01, time/batch = 17.8589s	
6980/29850 (epoch 11.692), train_loss = 1.39630046, grad/param norm = 1.8236e-01, time/batch = 17.2263s	
6981/29850 (epoch 11.693), train_loss = 1.25348885, grad/param norm = 1.6209e-01, time/batch = 15.8872s	
6982/29850 (epoch 11.695), train_loss = 1.10225284, grad/param norm = 1.5571e-01, time/batch = 18.1258s	
6983/29850 (epoch 11.697), train_loss = 1.31148348, grad/param norm = 1.7761e-01, time/batch = 16.7952s	
6984/29850 (epoch 11.698), train_loss = 1.34370967, grad/param norm = 1.8046e-01, time/batch = 18.3646s	
6985/29850 (epoch 11.700), train_loss = 1.30658450, grad/param norm = 1.8166e-01, time/batch = 19.2922s	
6986/29850 (epoch 11.702), train_loss = 1.24022100, grad/param norm = 1.7445e-01, time/batch = 16.9604s	
6987/29850 (epoch 11.704), train_loss = 1.18015679, grad/param norm = 1.6937e-01, time/batch = 17.5440s	
6988/29850 (epoch 11.705), train_loss = 1.29567975, grad/param norm = 1.7569e-01, time/batch = 17.9729s	
6989/29850 (epoch 11.707), train_loss = 1.22795247, grad/param norm = 1.7291e-01, time/batch = 18.2073s	
6990/29850 (epoch 11.709), train_loss = 1.35346606, grad/param norm = 1.8701e-01, time/batch = 17.3731s	
6991/29850 (epoch 11.710), train_loss = 1.24023735, grad/param norm = 1.7800e-01, time/batch = 18.9478s	
6992/29850 (epoch 11.712), train_loss = 1.27222000, grad/param norm = 1.6720e-01, time/batch = 20.2900s	
6993/29850 (epoch 11.714), train_loss = 1.32852823, grad/param norm = 1.7740e-01, time/batch = 17.7920s	
6994/29850 (epoch 11.715), train_loss = 1.34107889, grad/param norm = 1.8337e-01, time/batch = 16.9532s	
6995/29850 (epoch 11.717), train_loss = 1.09511482, grad/param norm = 1.6445e-01, time/batch = 16.2132s	
6996/29850 (epoch 11.719), train_loss = 1.22656815, grad/param norm = 1.7402e-01, time/batch = 18.2875s	
6997/29850 (epoch 11.720), train_loss = 1.26552843, grad/param norm = 1.6168e-01, time/batch = 19.2102s	
6998/29850 (epoch 11.722), train_loss = 1.18456259, grad/param norm = 1.5685e-01, time/batch = 17.2272s	
6999/29850 (epoch 11.724), train_loss = 1.36001277, grad/param norm = 1.8597e-01, time/batch = 16.8626s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch11.73_1.6390.t7	
7000/29850 (epoch 11.725), train_loss = 1.15557529, grad/param norm = 1.6777e-01, time/batch = 17.5364s	
7001/29850 (epoch 11.727), train_loss = 1.50306057, grad/param norm = 2.0028e-01, time/batch = 18.5486s	
7002/29850 (epoch 11.729), train_loss = 1.10504773, grad/param norm = 1.5613e-01, time/batch = 17.3731s	
7003/29850 (epoch 11.730), train_loss = 1.12633266, grad/param norm = 1.7427e-01, time/batch = 16.6201s	
7004/29850 (epoch 11.732), train_loss = 1.33750356, grad/param norm = 1.6658e-01, time/batch = 17.6090s	
7005/29850 (epoch 11.734), train_loss = 1.47371456, grad/param norm = 1.9946e-01, time/batch = 18.8794s	
7006/29850 (epoch 11.735), train_loss = 1.27573973, grad/param norm = 1.7879e-01, time/batch = 17.7111s	
7007/29850 (epoch 11.737), train_loss = 1.17956897, grad/param norm = 1.7702e-01, time/batch = 14.9430s	
7008/29850 (epoch 11.739), train_loss = 1.10489241, grad/param norm = 1.7835e-01, time/batch = 18.0479s	
7009/29850 (epoch 11.740), train_loss = 1.12440555, grad/param norm = 1.6220e-01, time/batch = 17.3577s	
7010/29850 (epoch 11.742), train_loss = 1.12496197, grad/param norm = 1.6054e-01, time/batch = 17.4814s	
7011/29850 (epoch 11.744), train_loss = 1.22957727, grad/param norm = 1.9618e-01, time/batch = 18.8834s	
7012/29850 (epoch 11.745), train_loss = 1.23766770, grad/param norm = 1.9599e-01, time/batch = 18.5113s	
7013/29850 (epoch 11.747), train_loss = 1.21020199, grad/param norm = 1.9943e-01, time/batch = 17.0114s	
7014/29850 (epoch 11.749), train_loss = 1.13884616, grad/param norm = 1.7397e-01, time/batch = 18.8777s	
7015/29850 (epoch 11.750), train_loss = 1.20489459, grad/param norm = 1.9541e-01, time/batch = 18.3869s	
7016/29850 (epoch 11.752), train_loss = 1.11839839, grad/param norm = 1.6895e-01, time/batch = 15.5936s	
7017/29850 (epoch 11.754), train_loss = 1.13704096, grad/param norm = 1.6581e-01, time/batch = 17.5559s	
7018/29850 (epoch 11.755), train_loss = 1.21681409, grad/param norm = 1.7613e-01, time/batch = 18.8008s	
7019/29850 (epoch 11.757), train_loss = 1.20307972, grad/param norm = 1.6294e-01, time/batch = 17.5652s	
7020/29850 (epoch 11.759), train_loss = 1.23955418, grad/param norm = 1.6907e-01, time/batch = 16.8238s	
7021/29850 (epoch 11.760), train_loss = 1.13126385, grad/param norm = 1.6558e-01, time/batch = 16.6797s	
7022/29850 (epoch 11.762), train_loss = 1.14713516, grad/param norm = 1.8007e-01, time/batch = 18.5405s	
7023/29850 (epoch 11.764), train_loss = 1.13591474, grad/param norm = 1.8368e-01, time/batch = 16.9455s	
7024/29850 (epoch 11.765), train_loss = 1.21489270, grad/param norm = 1.7972e-01, time/batch = 18.5539s	
7025/29850 (epoch 11.767), train_loss = 1.24850553, grad/param norm = 1.7807e-01, time/batch = 19.5530s	
7026/29850 (epoch 11.769), train_loss = 1.20428192, grad/param norm = 1.7411e-01, time/batch = 17.7976s	
7027/29850 (epoch 11.771), train_loss = 1.28638067, grad/param norm = 1.8198e-01, time/batch = 16.4124s	
7028/29850 (epoch 11.772), train_loss = 1.33166520, grad/param norm = 1.8906e-01, time/batch = 18.7243s	
7029/29850 (epoch 11.774), train_loss = 1.17154814, grad/param norm = 1.7786e-01, time/batch = 17.1206s	
7030/29850 (epoch 11.776), train_loss = 1.22465335, grad/param norm = 1.9460e-01, time/batch = 16.5808s	
7031/29850 (epoch 11.777), train_loss = 1.30033419, grad/param norm = 1.7642e-01, time/batch = 17.3185s	
7032/29850 (epoch 11.779), train_loss = 1.09980841, grad/param norm = 1.5617e-01, time/batch = 18.4810s	
7033/29850 (epoch 11.781), train_loss = 1.20544798, grad/param norm = 1.6466e-01, time/batch = 16.7808s	
7034/29850 (epoch 11.782), train_loss = 1.26018916, grad/param norm = 1.6410e-01, time/batch = 17.1393s	
7035/29850 (epoch 11.784), train_loss = 1.15319897, grad/param norm = 1.7247e-01, time/batch = 19.4626s	
7036/29850 (epoch 11.786), train_loss = 1.21273384, grad/param norm = 1.6889e-01, time/batch = 17.6240s	
7037/29850 (epoch 11.787), train_loss = 1.14414439, grad/param norm = 1.6815e-01, time/batch = 15.1635s	
7038/29850 (epoch 11.789), train_loss = 1.07232431, grad/param norm = 1.5530e-01, time/batch = 18.2061s	
7039/29850 (epoch 11.791), train_loss = 1.23138611, grad/param norm = 1.8736e-01, time/batch = 18.7837s	
7040/29850 (epoch 11.792), train_loss = 1.33210499, grad/param norm = 1.8353e-01, time/batch = 18.2013s	
7041/29850 (epoch 11.794), train_loss = 1.25103364, grad/param norm = 1.6921e-01, time/batch = 17.8075s	
7042/29850 (epoch 11.796), train_loss = 1.17471776, grad/param norm = 1.8122e-01, time/batch = 15.6439s	
7043/29850 (epoch 11.797), train_loss = 1.09890702, grad/param norm = 1.6653e-01, time/batch = 16.5381s	
7044/29850 (epoch 11.799), train_loss = 1.11151730, grad/param norm = 1.6530e-01, time/batch = 14.7379s	
7045/29850 (epoch 11.801), train_loss = 1.29412819, grad/param norm = 1.8048e-01, time/batch = 18.7248s	
7046/29850 (epoch 11.802), train_loss = 1.10013713, grad/param norm = 1.6965e-01, time/batch = 19.6727s	
7047/29850 (epoch 11.804), train_loss = 1.13464403, grad/param norm = 1.5903e-01, time/batch = 31.0571s	
7048/29850 (epoch 11.806), train_loss = 1.13276211, grad/param norm = 1.5874e-01, time/batch = 18.3831s	
7049/29850 (epoch 11.807), train_loss = 1.03125982, grad/param norm = 1.5118e-01, time/batch = 16.2789s	
7050/29850 (epoch 11.809), train_loss = 1.19882502, grad/param norm = 1.9005e-01, time/batch = 19.1969s	
7051/29850 (epoch 11.811), train_loss = 1.30425143, grad/param norm = 2.0784e-01, time/batch = 16.1345s	
7052/29850 (epoch 11.812), train_loss = 1.26315062, grad/param norm = 1.8984e-01, time/batch = 18.3643s	
7053/29850 (epoch 11.814), train_loss = 1.33980113, grad/param norm = 1.8554e-01, time/batch = 18.8024s	
7054/29850 (epoch 11.816), train_loss = 1.30618600, grad/param norm = 1.7143e-01, time/batch = 16.0624s	
7055/29850 (epoch 11.817), train_loss = 1.24307297, grad/param norm = 1.7727e-01, time/batch = 18.8591s	
7056/29850 (epoch 11.819), train_loss = 1.15337720, grad/param norm = 1.8208e-01, time/batch = 16.4503s	
7057/29850 (epoch 11.821), train_loss = 1.38913351, grad/param norm = 1.8281e-01, time/batch = 18.2108s	
7058/29850 (epoch 11.822), train_loss = 1.28843245, grad/param norm = 1.6744e-01, time/batch = 18.7961s	
7059/29850 (epoch 11.824), train_loss = 1.19496344, grad/param norm = 1.7156e-01, time/batch = 17.6927s	
7060/29850 (epoch 11.826), train_loss = 1.19192200, grad/param norm = 1.7088e-01, time/batch = 19.1328s	
7061/29850 (epoch 11.827), train_loss = 1.14098093, grad/param norm = 1.7805e-01, time/batch = 17.6463s	
7062/29850 (epoch 11.829), train_loss = 1.25881674, grad/param norm = 1.8570e-01, time/batch = 16.1301s	
7063/29850 (epoch 11.831), train_loss = 1.29920477, grad/param norm = 1.9231e-01, time/batch = 16.5411s	
7064/29850 (epoch 11.832), train_loss = 1.19392005, grad/param norm = 1.6444e-01, time/batch = 18.7025s	
7065/29850 (epoch 11.834), train_loss = 1.10238041, grad/param norm = 1.8201e-01, time/batch = 15.1837s	
7066/29850 (epoch 11.836), train_loss = 1.09806641, grad/param norm = 1.6381e-01, time/batch = 15.1787s	
7067/29850 (epoch 11.838), train_loss = 1.23195989, grad/param norm = 1.6851e-01, time/batch = 16.0931s	
7068/29850 (epoch 11.839), train_loss = 1.16345278, grad/param norm = 1.6621e-01, time/batch = 14.7900s	
7069/29850 (epoch 11.841), train_loss = 1.18474615, grad/param norm = 1.6782e-01, time/batch = 14.7250s	
7070/29850 (epoch 11.843), train_loss = 1.14900020, grad/param norm = 1.6985e-01, time/batch = 14.3668s	
7071/29850 (epoch 11.844), train_loss = 1.19347967, grad/param norm = 1.7699e-01, time/batch = 15.1865s	
7072/29850 (epoch 11.846), train_loss = 1.24495556, grad/param norm = 1.8252e-01, time/batch = 19.3733s	
7073/29850 (epoch 11.848), train_loss = 1.27668113, grad/param norm = 1.7685e-01, time/batch = 18.6339s	
7074/29850 (epoch 11.849), train_loss = 1.14915227, grad/param norm = 2.0239e-01, time/batch = 18.1194s	
7075/29850 (epoch 11.851), train_loss = 1.31660400, grad/param norm = 1.9692e-01, time/batch = 18.0427s	
7076/29850 (epoch 11.853), train_loss = 1.18902239, grad/param norm = 1.9737e-01, time/batch = 16.8053s	
7077/29850 (epoch 11.854), train_loss = 1.34493216, grad/param norm = 2.0962e-01, time/batch = 15.3928s	
7078/29850 (epoch 11.856), train_loss = 1.31388029, grad/param norm = 1.9976e-01, time/batch = 16.8239s	
7079/29850 (epoch 11.858), train_loss = 1.19536220, grad/param norm = 1.6788e-01, time/batch = 17.6407s	
7080/29850 (epoch 11.859), train_loss = 1.17790069, grad/param norm = 1.8808e-01, time/batch = 18.2114s	
7081/29850 (epoch 11.861), train_loss = 1.31132214, grad/param norm = 1.8763e-01, time/batch = 17.1404s	
7082/29850 (epoch 11.863), train_loss = 1.38818442, grad/param norm = 1.7628e-01, time/batch = 17.5627s	
7083/29850 (epoch 11.864), train_loss = 1.30492667, grad/param norm = 1.8158e-01, time/batch = 18.4839s	
7084/29850 (epoch 11.866), train_loss = 1.26254952, grad/param norm = 1.8685e-01, time/batch = 15.0283s	
7085/29850 (epoch 11.868), train_loss = 1.36998856, grad/param norm = 1.9237e-01, time/batch = 17.5667s	
7086/29850 (epoch 11.869), train_loss = 1.18769094, grad/param norm = 1.7629e-01, time/batch = 18.5361s	
7087/29850 (epoch 11.871), train_loss = 1.24714946, grad/param norm = 1.7334e-01, time/batch = 17.9535s	
7088/29850 (epoch 11.873), train_loss = 1.31411900, grad/param norm = 1.8517e-01, time/batch = 17.3698s	
7089/29850 (epoch 11.874), train_loss = 1.28881104, grad/param norm = 1.8400e-01, time/batch = 18.9434s	
7090/29850 (epoch 11.876), train_loss = 1.24989243, grad/param norm = 2.0252e-01, time/batch = 17.5481s	
7091/29850 (epoch 11.878), train_loss = 1.24721571, grad/param norm = 1.7043e-01, time/batch = 19.3000s	
7092/29850 (epoch 11.879), train_loss = 1.27241145, grad/param norm = 1.7880e-01, time/batch = 17.4674s	
7093/29850 (epoch 11.881), train_loss = 1.32827199, grad/param norm = 1.8387e-01, time/batch = 18.3836s	
7094/29850 (epoch 11.883), train_loss = 1.32894212, grad/param norm = 1.9238e-01, time/batch = 17.6340s	
7095/29850 (epoch 11.884), train_loss = 1.13732468, grad/param norm = 1.6628e-01, time/batch = 18.0566s	
7096/29850 (epoch 11.886), train_loss = 1.39190832, grad/param norm = 1.7689e-01, time/batch = 19.1251s	
7097/29850 (epoch 11.888), train_loss = 1.22423015, grad/param norm = 1.6606e-01, time/batch = 17.0364s	
7098/29850 (epoch 11.889), train_loss = 1.19602129, grad/param norm = 1.8358e-01, time/batch = 16.8640s	
7099/29850 (epoch 11.891), train_loss = 1.20904370, grad/param norm = 1.7806e-01, time/batch = 17.7882s	
7100/29850 (epoch 11.893), train_loss = 1.13548789, grad/param norm = 1.6888e-01, time/batch = 15.1993s	
7101/29850 (epoch 11.894), train_loss = 1.19889961, grad/param norm = 1.6505e-01, time/batch = 16.7685s	
7102/29850 (epoch 11.896), train_loss = 1.19771935, grad/param norm = 1.7473e-01, time/batch = 18.5534s	
7103/29850 (epoch 11.898), train_loss = 1.36622677, grad/param norm = 1.9858e-01, time/batch = 18.4427s	
7104/29850 (epoch 11.899), train_loss = 1.07969827, grad/param norm = 1.6723e-01, time/batch = 17.6241s	
7105/29850 (epoch 11.901), train_loss = 1.56003121, grad/param norm = 2.2008e-01, time/batch = 18.7941s	
7106/29850 (epoch 11.903), train_loss = 1.25712600, grad/param norm = 2.2640e-01, time/batch = 18.4636s	
7107/29850 (epoch 11.905), train_loss = 1.44084334, grad/param norm = 1.8604e-01, time/batch = 18.2915s	
7108/29850 (epoch 11.906), train_loss = 1.18027063, grad/param norm = 1.7629e-01, time/batch = 17.6331s	
7109/29850 (epoch 11.908), train_loss = 1.33022543, grad/param norm = 1.8593e-01, time/batch = 19.1304s	
7110/29850 (epoch 11.910), train_loss = 1.31577631, grad/param norm = 1.8108e-01, time/batch = 18.7841s	
7111/29850 (epoch 11.911), train_loss = 1.41309293, grad/param norm = 1.7986e-01, time/batch = 18.1337s	
7112/29850 (epoch 11.913), train_loss = 1.31685060, grad/param norm = 1.7595e-01, time/batch = 17.3058s	
7113/29850 (epoch 11.915), train_loss = 1.34216618, grad/param norm = 1.9160e-01, time/batch = 19.5386s	
7114/29850 (epoch 11.916), train_loss = 1.30832627, grad/param norm = 1.8088e-01, time/batch = 17.1904s	
7115/29850 (epoch 11.918), train_loss = 1.18811459, grad/param norm = 1.5777e-01, time/batch = 17.9780s	
7116/29850 (epoch 11.920), train_loss = 1.32164668, grad/param norm = 1.6899e-01, time/batch = 17.7983s	
7117/29850 (epoch 11.921), train_loss = 1.29436814, grad/param norm = 1.9065e-01, time/batch = 16.1867s	
7118/29850 (epoch 11.923), train_loss = 1.32698048, grad/param norm = 1.7567e-01, time/batch = 18.2743s	
7119/29850 (epoch 11.925), train_loss = 1.38125759, grad/param norm = 1.9286e-01, time/batch = 16.1988s	
7120/29850 (epoch 11.926), train_loss = 1.43197799, grad/param norm = 1.9750e-01, time/batch = 18.3756s	
7121/29850 (epoch 11.928), train_loss = 1.26446789, grad/param norm = 1.7805e-01, time/batch = 17.2032s	
7122/29850 (epoch 11.930), train_loss = 1.35107209, grad/param norm = 1.8753e-01, time/batch = 17.4026s	
7123/29850 (epoch 11.931), train_loss = 1.30202669, grad/param norm = 1.8171e-01, time/batch = 19.8714s	
7124/29850 (epoch 11.933), train_loss = 1.41505927, grad/param norm = 1.9539e-01, time/batch = 17.5398s	
7125/29850 (epoch 11.935), train_loss = 1.38620132, grad/param norm = 1.8139e-01, time/batch = 16.2050s	
7126/29850 (epoch 11.936), train_loss = 1.38043460, grad/param norm = 1.7991e-01, time/batch = 18.3887s	
7127/29850 (epoch 11.938), train_loss = 1.12907668, grad/param norm = 1.7772e-01, time/batch = 17.9604s	
7128/29850 (epoch 11.940), train_loss = 1.12283820, grad/param norm = 1.7811e-01, time/batch = 17.2942s	
7129/29850 (epoch 11.941), train_loss = 1.20831510, grad/param norm = 1.8257e-01, time/batch = 18.4605s	
7130/29850 (epoch 11.943), train_loss = 1.16785647, grad/param norm = 1.5902e-01, time/batch = 18.2309s	
7131/29850 (epoch 11.945), train_loss = 1.27469937, grad/param norm = 1.8640e-01, time/batch = 17.8642s	
7132/29850 (epoch 11.946), train_loss = 1.15619642, grad/param norm = 1.7991e-01, time/batch = 18.8836s	
7133/29850 (epoch 11.948), train_loss = 1.22106061, grad/param norm = 1.6277e-01, time/batch = 17.5223s	
7134/29850 (epoch 11.950), train_loss = 1.16607714, grad/param norm = 1.6033e-01, time/batch = 15.2228s	
7135/29850 (epoch 11.951), train_loss = 1.13222033, grad/param norm = 1.5809e-01, time/batch = 16.6331s	
7136/29850 (epoch 11.953), train_loss = 1.24022124, grad/param norm = 1.9114e-01, time/batch = 17.7935s	
7137/29850 (epoch 11.955), train_loss = 1.09550492, grad/param norm = 1.5995e-01, time/batch = 18.4573s	
7138/29850 (epoch 11.956), train_loss = 1.10947580, grad/param norm = 1.6227e-01, time/batch = 18.3048s	
7139/29850 (epoch 11.958), train_loss = 0.99565741, grad/param norm = 1.6408e-01, time/batch = 17.6398s	
7140/29850 (epoch 11.960), train_loss = 1.31821861, grad/param norm = 1.9116e-01, time/batch = 18.1247s	
7141/29850 (epoch 11.961), train_loss = 1.17668645, grad/param norm = 1.5728e-01, time/batch = 17.4364s	
7142/29850 (epoch 11.963), train_loss = 1.10917497, grad/param norm = 1.5824e-01, time/batch = 17.3233s	
7143/29850 (epoch 11.965), train_loss = 1.18743831, grad/param norm = 1.7517e-01, time/batch = 18.0531s	
7144/29850 (epoch 11.966), train_loss = 1.08131930, grad/param norm = 1.5469e-01, time/batch = 16.2321s	
7145/29850 (epoch 11.968), train_loss = 1.20781147, grad/param norm = 1.8261e-01, time/batch = 17.0478s	
7146/29850 (epoch 11.970), train_loss = 1.13591881, grad/param norm = 1.7935e-01, time/batch = 19.1309s	
7147/29850 (epoch 11.972), train_loss = 1.13086672, grad/param norm = 1.6357e-01, time/batch = 19.0314s	
7148/29850 (epoch 11.973), train_loss = 1.15194568, grad/param norm = 1.7363e-01, time/batch = 16.5447s	
7149/29850 (epoch 11.975), train_loss = 1.00025248, grad/param norm = 1.5177e-01, time/batch = 18.3016s	
7150/29850 (epoch 11.977), train_loss = 1.17519605, grad/param norm = 1.6313e-01, time/batch = 17.4579s	
7151/29850 (epoch 11.978), train_loss = 1.12634842, grad/param norm = 1.6288e-01, time/batch = 15.2834s	
7152/29850 (epoch 11.980), train_loss = 1.14798184, grad/param norm = 1.6147e-01, time/batch = 15.6324s	
7153/29850 (epoch 11.982), train_loss = 1.17239590, grad/param norm = 1.7108e-01, time/batch = 17.4795s	
7154/29850 (epoch 11.983), train_loss = 1.21765624, grad/param norm = 1.6657e-01, time/batch = 15.3652s	
7155/29850 (epoch 11.985), train_loss = 1.26423540, grad/param norm = 1.8196e-01, time/batch = 17.8526s	
7156/29850 (epoch 11.987), train_loss = 1.18705920, grad/param norm = 1.5912e-01, time/batch = 19.1339s	
7157/29850 (epoch 11.988), train_loss = 1.12308076, grad/param norm = 1.6408e-01, time/batch = 17.2233s	
7158/29850 (epoch 11.990), train_loss = 1.21437461, grad/param norm = 1.6683e-01, time/batch = 17.4515s	
7159/29850 (epoch 11.992), train_loss = 1.21938188, grad/param norm = 1.6693e-01, time/batch = 15.2459s	
7160/29850 (epoch 11.993), train_loss = 1.22272976, grad/param norm = 1.7512e-01, time/batch = 18.2057s	
7161/29850 (epoch 11.995), train_loss = 1.25458201, grad/param norm = 1.7274e-01, time/batch = 17.6198s	
7162/29850 (epoch 11.997), train_loss = 1.22321158, grad/param norm = 1.7121e-01, time/batch = 19.8675s	
7163/29850 (epoch 11.998), train_loss = 1.30429945, grad/param norm = 1.8240e-01, time/batch = 17.2947s	
decayed learning rate by a factor 0.97 to 0.001825346	
7164/29850 (epoch 12.000), train_loss = 1.16296379, grad/param norm = 1.6428e-01, time/batch = 18.9731s	
7165/29850 (epoch 12.002), train_loss = 1.44339741, grad/param norm = 1.8854e-01, time/batch = 16.0140s	
7166/29850 (epoch 12.003), train_loss = 1.16734856, grad/param norm = 1.7109e-01, time/batch = 17.3888s	
7167/29850 (epoch 12.005), train_loss = 1.23410885, grad/param norm = 1.6858e-01, time/batch = 17.5574s	
7168/29850 (epoch 12.007), train_loss = 1.25821035, grad/param norm = 2.0934e-01, time/batch = 16.4738s	
7169/29850 (epoch 12.008), train_loss = 1.48941297, grad/param norm = 1.9986e-01, time/batch = 18.6726s	
7170/29850 (epoch 12.010), train_loss = 1.11318916, grad/param norm = 1.7928e-01, time/batch = 15.8799s	
7171/29850 (epoch 12.012), train_loss = 1.27657883, grad/param norm = 1.7402e-01, time/batch = 18.0424s	
7172/29850 (epoch 12.013), train_loss = 1.30683042, grad/param norm = 1.8578e-01, time/batch = 17.5411s	
7173/29850 (epoch 12.015), train_loss = 1.28351577, grad/param norm = 1.7292e-01, time/batch = 18.5518s	
7174/29850 (epoch 12.017), train_loss = 1.36529673, grad/param norm = 2.0275e-01, time/batch = 17.5625s	
7175/29850 (epoch 12.018), train_loss = 1.40672239, grad/param norm = 2.1288e-01, time/batch = 17.1323s	
7176/29850 (epoch 12.020), train_loss = 1.19631881, grad/param norm = 1.7659e-01, time/batch = 18.9500s	
7177/29850 (epoch 12.022), train_loss = 1.34135383, grad/param norm = 1.9081e-01, time/batch = 16.6067s	
7178/29850 (epoch 12.023), train_loss = 1.25702026, grad/param norm = 1.6109e-01, time/batch = 17.7950s	
7179/29850 (epoch 12.025), train_loss = 1.20418463, grad/param norm = 1.6736e-01, time/batch = 18.9458s	
7180/29850 (epoch 12.027), train_loss = 1.08558505, grad/param norm = 1.5080e-01, time/batch = 18.1331s	
7181/29850 (epoch 12.028), train_loss = 1.19425300, grad/param norm = 1.6147e-01, time/batch = 18.7718s	
7182/29850 (epoch 12.030), train_loss = 1.28417867, grad/param norm = 1.7791e-01, time/batch = 18.2724s	
7183/29850 (epoch 12.032), train_loss = 1.23621945, grad/param norm = 1.7100e-01, time/batch = 16.8941s	
7184/29850 (epoch 12.034), train_loss = 1.17840897, grad/param norm = 1.7172e-01, time/batch = 17.4621s	
7185/29850 (epoch 12.035), train_loss = 1.08119309, grad/param norm = 1.5861e-01, time/batch = 16.0282s	
7186/29850 (epoch 12.037), train_loss = 1.25527398, grad/param norm = 1.8229e-01, time/batch = 19.0415s	
7187/29850 (epoch 12.039), train_loss = 1.06522679, grad/param norm = 1.5213e-01, time/batch = 18.5507s	
7188/29850 (epoch 12.040), train_loss = 1.12774507, grad/param norm = 1.6762e-01, time/batch = 17.9571s	
7189/29850 (epoch 12.042), train_loss = 1.16689093, grad/param norm = 1.6859e-01, time/batch = 19.2105s	
7190/29850 (epoch 12.044), train_loss = 1.17430399, grad/param norm = 1.6204e-01, time/batch = 18.4645s	
7191/29850 (epoch 12.045), train_loss = 1.28267995, grad/param norm = 1.7888e-01, time/batch = 17.8446s	
7192/29850 (epoch 12.047), train_loss = 1.06613428, grad/param norm = 1.7427e-01, time/batch = 18.1219s	
7193/29850 (epoch 12.049), train_loss = 1.27124250, grad/param norm = 1.6912e-01, time/batch = 18.2195s	
7194/29850 (epoch 12.050), train_loss = 1.14867143, grad/param norm = 1.7217e-01, time/batch = 19.2129s	
7195/29850 (epoch 12.052), train_loss = 1.43551767, grad/param norm = 1.9272e-01, time/batch = 16.1894s	
7196/29850 (epoch 12.054), train_loss = 1.29409908, grad/param norm = 1.7473e-01, time/batch = 17.6356s	
7197/29850 (epoch 12.055), train_loss = 1.20898210, grad/param norm = 1.8535e-01, time/batch = 18.6303s	
7198/29850 (epoch 12.057), train_loss = 1.27078113, grad/param norm = 1.7258e-01, time/batch = 17.5232s	
7199/29850 (epoch 12.059), train_loss = 1.31361536, grad/param norm = 2.0728e-01, time/batch = 16.9528s	
7200/29850 (epoch 12.060), train_loss = 1.25936005, grad/param norm = 1.8075e-01, time/batch = 17.4733s	
7201/29850 (epoch 12.062), train_loss = 1.36220232, grad/param norm = 1.8795e-01, time/batch = 16.4407s	
7202/29850 (epoch 12.064), train_loss = 1.30122058, grad/param norm = 1.8659e-01, time/batch = 16.0836s	
7203/29850 (epoch 12.065), train_loss = 1.13724980, grad/param norm = 1.6612e-01, time/batch = 16.9723s	
7204/29850 (epoch 12.067), train_loss = 1.27004750, grad/param norm = 1.7833e-01, time/batch = 18.3934s	
7205/29850 (epoch 12.069), train_loss = 1.23321095, grad/param norm = 1.7509e-01, time/batch = 17.5526s	
7206/29850 (epoch 12.070), train_loss = 1.26989150, grad/param norm = 1.6089e-01, time/batch = 16.5250s	
7207/29850 (epoch 12.072), train_loss = 1.32143856, grad/param norm = 1.8917e-01, time/batch = 19.1356s	
7208/29850 (epoch 12.074), train_loss = 1.31768588, grad/param norm = 1.7162e-01, time/batch = 18.6165s	
7209/29850 (epoch 12.075), train_loss = 1.15468865, grad/param norm = 1.6101e-01, time/batch = 18.6441s	
7210/29850 (epoch 12.077), train_loss = 1.26228298, grad/param norm = 1.7980e-01, time/batch = 17.0670s	
7211/29850 (epoch 12.079), train_loss = 1.49562472, grad/param norm = 1.9858e-01, time/batch = 18.2105s	
7212/29850 (epoch 12.080), train_loss = 1.40229971, grad/param norm = 1.9416e-01, time/batch = 16.1179s	
7213/29850 (epoch 12.082), train_loss = 1.27623790, grad/param norm = 1.7066e-01, time/batch = 19.1318s	
7214/29850 (epoch 12.084), train_loss = 1.35079175, grad/param norm = 1.8988e-01, time/batch = 19.4535s	
7215/29850 (epoch 12.085), train_loss = 1.29674586, grad/param norm = 1.9568e-01, time/batch = 15.4302s	
7216/29850 (epoch 12.087), train_loss = 1.37899071, grad/param norm = 1.7235e-01, time/batch = 18.9605s	
7217/29850 (epoch 12.089), train_loss = 1.29899950, grad/param norm = 1.7379e-01, time/batch = 17.5287s	
7218/29850 (epoch 12.090), train_loss = 1.32365936, grad/param norm = 1.9314e-01, time/batch = 17.2838s	
7219/29850 (epoch 12.092), train_loss = 1.22462676, grad/param norm = 1.7476e-01, time/batch = 15.5318s	
7220/29850 (epoch 12.094), train_loss = 1.32130731, grad/param norm = 1.7796e-01, time/batch = 18.4647s	
7221/29850 (epoch 12.095), train_loss = 1.29735800, grad/param norm = 1.7308e-01, time/batch = 19.0476s	
7222/29850 (epoch 12.097), train_loss = 1.05653585, grad/param norm = 1.4965e-01, time/batch = 16.8735s	
7223/29850 (epoch 12.099), train_loss = 1.08954587, grad/param norm = 1.5806e-01, time/batch = 17.6342s	
7224/29850 (epoch 12.101), train_loss = 1.38358406, grad/param norm = 1.8306e-01, time/batch = 16.4458s	
7225/29850 (epoch 12.102), train_loss = 1.30998950, grad/param norm = 1.8558e-01, time/batch = 17.7027s	
7226/29850 (epoch 12.104), train_loss = 1.21834561, grad/param norm = 1.6645e-01, time/batch = 19.5288s	
7227/29850 (epoch 12.106), train_loss = 1.31846685, grad/param norm = 1.7779e-01, time/batch = 15.8789s	
7228/29850 (epoch 12.107), train_loss = 1.09224425, grad/param norm = 1.4773e-01, time/batch = 18.7891s	
7229/29850 (epoch 12.109), train_loss = 1.21843556, grad/param norm = 2.0502e-01, time/batch = 18.4658s	
7230/29850 (epoch 12.111), train_loss = 1.34066894, grad/param norm = 1.7480e-01, time/batch = 18.0536s	
7231/29850 (epoch 12.112), train_loss = 1.15116437, grad/param norm = 1.6830e-01, time/batch = 17.2134s	
7232/29850 (epoch 12.114), train_loss = 1.30764408, grad/param norm = 2.0152e-01, time/batch = 16.2002s	
7233/29850 (epoch 12.116), train_loss = 1.16571694, grad/param norm = 1.6706e-01, time/batch = 16.5583s	
7234/29850 (epoch 12.117), train_loss = 1.25605445, grad/param norm = 1.7943e-01, time/batch = 15.2237s	
7235/29850 (epoch 12.119), train_loss = 1.22000866, grad/param norm = 1.5809e-01, time/batch = 17.4637s	
7236/29850 (epoch 12.121), train_loss = 1.03571240, grad/param norm = 1.6357e-01, time/batch = 15.6822s	
7237/29850 (epoch 12.122), train_loss = 1.10136640, grad/param norm = 1.5913e-01, time/batch = 18.5552s	
7238/29850 (epoch 12.124), train_loss = 1.17981451, grad/param norm = 1.6327e-01, time/batch = 19.9443s	
7239/29850 (epoch 12.126), train_loss = 1.22234043, grad/param norm = 1.7833e-01, time/batch = 17.7063s	
7240/29850 (epoch 12.127), train_loss = 1.37469175, grad/param norm = 1.8484e-01, time/batch = 18.7911s	
7241/29850 (epoch 12.129), train_loss = 1.19964118, grad/param norm = 1.6996e-01, time/batch = 19.1321s	
7242/29850 (epoch 12.131), train_loss = 1.21263997, grad/param norm = 1.7439e-01, time/batch = 17.2767s	
7243/29850 (epoch 12.132), train_loss = 1.14307412, grad/param norm = 1.7709e-01, time/batch = 18.9543s	
7244/29850 (epoch 12.134), train_loss = 1.29214411, grad/param norm = 1.8301e-01, time/batch = 18.8752s	
7245/29850 (epoch 12.136), train_loss = 1.27548792, grad/param norm = 1.7787e-01, time/batch = 18.7867s	
7246/29850 (epoch 12.137), train_loss = 1.11863467, grad/param norm = 1.7831e-01, time/batch = 16.9494s	
7247/29850 (epoch 12.139), train_loss = 1.13684947, grad/param norm = 1.5915e-01, time/batch = 17.9597s	
7248/29850 (epoch 12.141), train_loss = 1.20799291, grad/param norm = 1.7371e-01, time/batch = 19.2963s	
7249/29850 (epoch 12.142), train_loss = 1.34252120, grad/param norm = 1.9865e-01, time/batch = 32.3648s	
7250/29850 (epoch 12.144), train_loss = 1.49326464, grad/param norm = 2.0739e-01, time/batch = 17.5585s	
7251/29850 (epoch 12.146), train_loss = 1.46539215, grad/param norm = 2.0220e-01, time/batch = 17.2999s	
7252/29850 (epoch 12.147), train_loss = 1.37231223, grad/param norm = 2.0061e-01, time/batch = 17.1735s	
7253/29850 (epoch 12.149), train_loss = 1.34747075, grad/param norm = 1.9009e-01, time/batch = 18.5591s	
7254/29850 (epoch 12.151), train_loss = 1.27373552, grad/param norm = 1.8140e-01, time/batch = 18.8821s	
7255/29850 (epoch 12.152), train_loss = 1.16785028, grad/param norm = 1.6998e-01, time/batch = 18.5411s	
7256/29850 (epoch 12.154), train_loss = 1.18735786, grad/param norm = 1.6878e-01, time/batch = 17.1148s	
7257/29850 (epoch 12.156), train_loss = 1.16300257, grad/param norm = 1.6308e-01, time/batch = 17.7309s	
7258/29850 (epoch 12.157), train_loss = 1.22412485, grad/param norm = 1.6281e-01, time/batch = 14.9054s	
7259/29850 (epoch 12.159), train_loss = 1.26135127, grad/param norm = 1.6906e-01, time/batch = 19.7041s	
7260/29850 (epoch 12.161), train_loss = 1.30406424, grad/param norm = 1.9564e-01, time/batch = 16.9656s	
7261/29850 (epoch 12.162), train_loss = 1.41138890, grad/param norm = 1.8734e-01, time/batch = 17.7826s	
7262/29850 (epoch 12.164), train_loss = 1.26399199, grad/param norm = 1.8893e-01, time/batch = 16.3741s	
7263/29850 (epoch 12.166), train_loss = 1.13264474, grad/param norm = 1.6380e-01, time/batch = 17.5475s	
7264/29850 (epoch 12.168), train_loss = 1.05271005, grad/param norm = 1.6204e-01, time/batch = 18.1267s	
7265/29850 (epoch 12.169), train_loss = 1.42388404, grad/param norm = 1.9184e-01, time/batch = 16.9450s	
7266/29850 (epoch 12.171), train_loss = 1.34323118, grad/param norm = 1.9005e-01, time/batch = 18.1944s	
7267/29850 (epoch 12.173), train_loss = 1.22590238, grad/param norm = 2.0235e-01, time/batch = 17.7155s	
7268/29850 (epoch 12.174), train_loss = 1.33427365, grad/param norm = 1.9259e-01, time/batch = 18.2018s	
7269/29850 (epoch 12.176), train_loss = 1.30152753, grad/param norm = 1.8563e-01, time/batch = 16.0402s	
7270/29850 (epoch 12.178), train_loss = 1.31469640, grad/param norm = 1.9617e-01, time/batch = 19.6172s	
7271/29850 (epoch 12.179), train_loss = 1.06439639, grad/param norm = 1.5962e-01, time/batch = 18.1265s	
7272/29850 (epoch 12.181), train_loss = 1.24053947, grad/param norm = 1.7858e-01, time/batch = 17.9767s	
7273/29850 (epoch 12.183), train_loss = 1.19905131, grad/param norm = 1.7720e-01, time/batch = 17.4722s	
7274/29850 (epoch 12.184), train_loss = 1.20707835, grad/param norm = 1.8076e-01, time/batch = 19.4605s	
7275/29850 (epoch 12.186), train_loss = 1.21191157, grad/param norm = 1.6981e-01, time/batch = 18.6149s	
7276/29850 (epoch 12.188), train_loss = 1.32617306, grad/param norm = 1.9232e-01, time/batch = 16.0395s	
7277/29850 (epoch 12.189), train_loss = 1.42555495, grad/param norm = 1.9074e-01, time/batch = 16.1360s	
7278/29850 (epoch 12.191), train_loss = 1.29096019, grad/param norm = 1.7591e-01, time/batch = 17.3796s	
7279/29850 (epoch 12.193), train_loss = 1.15382843, grad/param norm = 1.6451e-01, time/batch = 19.5404s	
7280/29850 (epoch 12.194), train_loss = 1.28038136, grad/param norm = 1.8835e-01, time/batch = 17.6196s	
7281/29850 (epoch 12.196), train_loss = 1.20772995, grad/param norm = 1.8698e-01, time/batch = 17.2989s	
7282/29850 (epoch 12.198), train_loss = 1.22920883, grad/param norm = 1.7572e-01, time/batch = 19.0193s	
7283/29850 (epoch 12.199), train_loss = 1.52126808, grad/param norm = 1.9654e-01, time/batch = 15.1375s	
7284/29850 (epoch 12.201), train_loss = 1.19041745, grad/param norm = 1.7498e-01, time/batch = 17.5345s	
7285/29850 (epoch 12.203), train_loss = 1.10576099, grad/param norm = 1.7335e-01, time/batch = 18.0960s	
7286/29850 (epoch 12.204), train_loss = 1.31629084, grad/param norm = 2.1571e-01, time/batch = 18.6866s	
7287/29850 (epoch 12.206), train_loss = 1.15012954, grad/param norm = 2.0159e-01, time/batch = 16.9634s	
7288/29850 (epoch 12.208), train_loss = 1.43144644, grad/param norm = 1.9238e-01, time/batch = 18.1107s	
7289/29850 (epoch 12.209), train_loss = 1.14879412, grad/param norm = 1.6665e-01, time/batch = 19.7648s	
7290/29850 (epoch 12.211), train_loss = 1.20781376, grad/param norm = 1.6380e-01, time/batch = 18.7950s	
7291/29850 (epoch 12.213), train_loss = 1.37776963, grad/param norm = 1.9948e-01, time/batch = 16.6305s	
7292/29850 (epoch 12.214), train_loss = 1.15656429, grad/param norm = 1.6379e-01, time/batch = 17.4228s	
7293/29850 (epoch 12.216), train_loss = 1.19795473, grad/param norm = 1.8063e-01, time/batch = 16.8974s	
7294/29850 (epoch 12.218), train_loss = 1.30927561, grad/param norm = 1.8421e-01, time/batch = 18.7958s	
7295/29850 (epoch 12.219), train_loss = 1.39489424, grad/param norm = 1.9750e-01, time/batch = 17.4494s	
7296/29850 (epoch 12.221), train_loss = 1.23023317, grad/param norm = 1.9456e-01, time/batch = 18.0452s	
7297/29850 (epoch 12.223), train_loss = 1.20945931, grad/param norm = 1.8682e-01, time/batch = 18.8038s	
7298/29850 (epoch 12.224), train_loss = 1.13426853, grad/param norm = 1.8171e-01, time/batch = 17.5301s	
7299/29850 (epoch 12.226), train_loss = 1.13845001, grad/param norm = 1.5602e-01, time/batch = 17.7736s	
7300/29850 (epoch 12.228), train_loss = 1.19175627, grad/param norm = 1.6392e-01, time/batch = 17.1475s	
7301/29850 (epoch 12.229), train_loss = 1.09705900, grad/param norm = 1.6410e-01, time/batch = 18.5504s	
7302/29850 (epoch 12.231), train_loss = 1.19383320, grad/param norm = 1.6047e-01, time/batch = 16.0107s	
7303/29850 (epoch 12.233), train_loss = 1.21773393, grad/param norm = 1.8088e-01, time/batch = 19.8766s	
7304/29850 (epoch 12.235), train_loss = 1.13946274, grad/param norm = 1.5363e-01, time/batch = 15.6420s	
7305/29850 (epoch 12.236), train_loss = 1.37347897, grad/param norm = 2.0850e-01, time/batch = 16.2110s	
7306/29850 (epoch 12.238), train_loss = 1.10695492, grad/param norm = 1.8287e-01, time/batch = 17.2220s	
7307/29850 (epoch 12.240), train_loss = 1.15270115, grad/param norm = 1.7862e-01, time/batch = 17.6235s	
7308/29850 (epoch 12.241), train_loss = 1.37221315, grad/param norm = 2.0351e-01, time/batch = 18.4782s	
7309/29850 (epoch 12.243), train_loss = 1.23346212, grad/param norm = 1.7939e-01, time/batch = 16.9597s	
7310/29850 (epoch 12.245), train_loss = 1.16825387, grad/param norm = 1.8390e-01, time/batch = 17.9409s	
7311/29850 (epoch 12.246), train_loss = 1.14377528, grad/param norm = 1.7842e-01, time/batch = 19.2978s	
7312/29850 (epoch 12.248), train_loss = 1.14831275, grad/param norm = 1.7602e-01, time/batch = 15.6422s	
7313/29850 (epoch 12.250), train_loss = 1.21108054, grad/param norm = 1.6424e-01, time/batch = 16.8677s	
7314/29850 (epoch 12.251), train_loss = 1.12898017, grad/param norm = 1.7586e-01, time/batch = 17.6242s	
7315/29850 (epoch 12.253), train_loss = 1.08342810, grad/param norm = 1.9019e-01, time/batch = 17.7869s	
7316/29850 (epoch 12.255), train_loss = 1.12817473, grad/param norm = 1.6429e-01, time/batch = 17.1821s	
7317/29850 (epoch 12.256), train_loss = 1.26615823, grad/param norm = 1.9338e-01, time/batch = 18.5387s	
7318/29850 (epoch 12.258), train_loss = 1.22570448, grad/param norm = 1.7268e-01, time/batch = 17.2870s	
7319/29850 (epoch 12.260), train_loss = 1.18002450, grad/param norm = 1.6705e-01, time/batch = 16.1099s	
7320/29850 (epoch 12.261), train_loss = 1.18469446, grad/param norm = 1.7636e-01, time/batch = 18.5281s	
7321/29850 (epoch 12.263), train_loss = 1.08438196, grad/param norm = 1.5947e-01, time/batch = 17.8153s	
7322/29850 (epoch 12.265), train_loss = 1.17591655, grad/param norm = 1.8765e-01, time/batch = 16.9610s	
7323/29850 (epoch 12.266), train_loss = 1.18738960, grad/param norm = 1.7666e-01, time/batch = 18.7838s	
7324/29850 (epoch 12.268), train_loss = 1.16637446, grad/param norm = 1.5859e-01, time/batch = 17.8806s	
7325/29850 (epoch 12.270), train_loss = 1.13159238, grad/param norm = 1.6018e-01, time/batch = 18.3013s	
7326/29850 (epoch 12.271), train_loss = 1.30501592, grad/param norm = 1.7411e-01, time/batch = 18.6253s	
7327/29850 (epoch 12.273), train_loss = 1.08332493, grad/param norm = 1.6429e-01, time/batch = 18.1110s	
7328/29850 (epoch 12.275), train_loss = 1.08882515, grad/param norm = 1.6322e-01, time/batch = 15.6959s	
7329/29850 (epoch 12.276), train_loss = 1.10002537, grad/param norm = 1.6995e-01, time/batch = 16.7660s	
7330/29850 (epoch 12.278), train_loss = 1.17298498, grad/param norm = 1.6959e-01, time/batch = 19.5411s	
7331/29850 (epoch 12.280), train_loss = 1.35597897, grad/param norm = 2.0264e-01, time/batch = 18.4613s	
7332/29850 (epoch 12.281), train_loss = 1.22367086, grad/param norm = 1.8670e-01, time/batch = 18.2727s	
7333/29850 (epoch 12.283), train_loss = 1.32693473, grad/param norm = 2.0215e-01, time/batch = 18.3845s	
7334/29850 (epoch 12.285), train_loss = 1.19436285, grad/param norm = 1.8015e-01, time/batch = 18.0516s	
7335/29850 (epoch 12.286), train_loss = 1.27619376, grad/param norm = 1.8156e-01, time/batch = 16.5101s	
7336/29850 (epoch 12.288), train_loss = 1.40584342, grad/param norm = 2.1782e-01, time/batch = 16.4558s	
7337/29850 (epoch 12.290), train_loss = 1.16696047, grad/param norm = 1.7784e-01, time/batch = 17.1349s	
7338/29850 (epoch 12.291), train_loss = 1.47525605, grad/param norm = 1.8203e-01, time/batch = 17.9512s	
7339/29850 (epoch 12.293), train_loss = 1.30696014, grad/param norm = 1.8573e-01, time/batch = 17.8846s	
7340/29850 (epoch 12.295), train_loss = 1.40421290, grad/param norm = 1.9848e-01, time/batch = 16.8033s	
7341/29850 (epoch 12.296), train_loss = 1.16093162, grad/param norm = 1.7102e-01, time/batch = 18.3900s	
7342/29850 (epoch 12.298), train_loss = 1.01111005, grad/param norm = 1.7077e-01, time/batch = 17.9599s	
7343/29850 (epoch 12.300), train_loss = 1.08923799, grad/param norm = 1.5925e-01, time/batch = 17.0319s	
7344/29850 (epoch 12.302), train_loss = 1.08541820, grad/param norm = 1.5826e-01, time/batch = 18.8799s	
7345/29850 (epoch 12.303), train_loss = 1.15126537, grad/param norm = 1.7189e-01, time/batch = 19.0545s	
7346/29850 (epoch 12.305), train_loss = 1.22409672, grad/param norm = 1.7413e-01, time/batch = 16.3576s	
7347/29850 (epoch 12.307), train_loss = 1.31379876, grad/param norm = 1.7397e-01, time/batch = 17.9773s	
7348/29850 (epoch 12.308), train_loss = 1.21980550, grad/param norm = 1.8918e-01, time/batch = 18.6956s	
7349/29850 (epoch 12.310), train_loss = 1.24007588, grad/param norm = 1.8309e-01, time/batch = 15.2796s	
7350/29850 (epoch 12.312), train_loss = 1.30731784, grad/param norm = 1.8359e-01, time/batch = 18.2910s	
7351/29850 (epoch 12.313), train_loss = 1.27273589, grad/param norm = 1.9087e-01, time/batch = 16.7997s	
7352/29850 (epoch 12.315), train_loss = 1.25319129, grad/param norm = 1.7759e-01, time/batch = 17.7174s	
7353/29850 (epoch 12.317), train_loss = 1.25830242, grad/param norm = 1.9193e-01, time/batch = 16.1827s	
7354/29850 (epoch 12.318), train_loss = 1.20051072, grad/param norm = 1.6856e-01, time/batch = 17.5542s	
7355/29850 (epoch 12.320), train_loss = 1.11248308, grad/param norm = 1.5724e-01, time/batch = 17.9752s	
7356/29850 (epoch 12.322), train_loss = 1.39851435, grad/param norm = 1.9212e-01, time/batch = 17.0592s	
7357/29850 (epoch 12.323), train_loss = 1.27498805, grad/param norm = 2.0329e-01, time/batch = 17.4770s	
7358/29850 (epoch 12.325), train_loss = 1.24845870, grad/param norm = 1.7325e-01, time/batch = 18.7130s	
7359/29850 (epoch 12.327), train_loss = 1.39774288, grad/param norm = 1.9906e-01, time/batch = 18.2845s	
7360/29850 (epoch 12.328), train_loss = 1.37407347, grad/param norm = 1.8426e-01, time/batch = 19.1148s	
7361/29850 (epoch 12.330), train_loss = 1.23054494, grad/param norm = 1.7208e-01, time/batch = 18.9591s	
7362/29850 (epoch 12.332), train_loss = 1.15980770, grad/param norm = 1.6890e-01, time/batch = 17.6222s	
7363/29850 (epoch 12.333), train_loss = 1.37651701, grad/param norm = 1.8065e-01, time/batch = 18.6200s	
7364/29850 (epoch 12.335), train_loss = 1.29309046, grad/param norm = 1.8305e-01, time/batch = 17.7973s	
7365/29850 (epoch 12.337), train_loss = 1.25717110, grad/param norm = 1.8322e-01, time/batch = 19.5470s	
7366/29850 (epoch 12.338), train_loss = 1.22653203, grad/param norm = 1.6633e-01, time/batch = 16.0187s	
7367/29850 (epoch 12.340), train_loss = 1.11198141, grad/param norm = 1.7160e-01, time/batch = 17.9740s	
7368/29850 (epoch 12.342), train_loss = 1.25321434, grad/param norm = 1.7732e-01, time/batch = 15.1356s	
7369/29850 (epoch 12.343), train_loss = 1.26908294, grad/param norm = 1.8409e-01, time/batch = 14.9625s	
7370/29850 (epoch 12.345), train_loss = 1.32366318, grad/param norm = 1.9790e-01, time/batch = 15.3660s	
7371/29850 (epoch 12.347), train_loss = 1.32611565, grad/param norm = 1.8334e-01, time/batch = 16.9449s	
7372/29850 (epoch 12.348), train_loss = 1.18892674, grad/param norm = 1.6512e-01, time/batch = 18.0398s	
7373/29850 (epoch 12.350), train_loss = 1.32622259, grad/param norm = 1.8717e-01, time/batch = 16.0462s	
7374/29850 (epoch 12.352), train_loss = 1.23086320, grad/param norm = 1.6715e-01, time/batch = 17.0429s	
7375/29850 (epoch 12.353), train_loss = 1.29458528, grad/param norm = 1.8109e-01, time/batch = 17.3142s	
7376/29850 (epoch 12.355), train_loss = 1.12927821, grad/param norm = 1.7168e-01, time/batch = 15.5742s	
7377/29850 (epoch 12.357), train_loss = 1.38770851, grad/param norm = 1.7940e-01, time/batch = 17.8620s	
7378/29850 (epoch 12.358), train_loss = 1.11798307, grad/param norm = 1.7193e-01, time/batch = 17.2089s	
7379/29850 (epoch 12.360), train_loss = 1.22438987, grad/param norm = 1.7331e-01, time/batch = 17.0484s	
7380/29850 (epoch 12.362), train_loss = 1.22123641, grad/param norm = 1.8486e-01, time/batch = 15.3821s	
7381/29850 (epoch 12.363), train_loss = 1.25173825, grad/param norm = 1.7671e-01, time/batch = 18.0551s	
7382/29850 (epoch 12.365), train_loss = 1.40294844, grad/param norm = 2.0366e-01, time/batch = 17.3122s	
7383/29850 (epoch 12.367), train_loss = 1.20948747, grad/param norm = 1.7950e-01, time/batch = 17.2008s	
7384/29850 (epoch 12.369), train_loss = 1.12377942, grad/param norm = 1.6957e-01, time/batch = 16.5137s	
7385/29850 (epoch 12.370), train_loss = 1.05299569, grad/param norm = 1.6744e-01, time/batch = 18.8041s	
7386/29850 (epoch 12.372), train_loss = 1.41134148, grad/param norm = 2.1178e-01, time/batch = 17.5499s	
7387/29850 (epoch 12.374), train_loss = 1.22418227, grad/param norm = 1.9577e-01, time/batch = 17.0368s	
7388/29850 (epoch 12.375), train_loss = 1.23703626, grad/param norm = 1.8213e-01, time/batch = 19.5893s	
7389/29850 (epoch 12.377), train_loss = 1.24229023, grad/param norm = 1.7939e-01, time/batch = 17.7788s	
7390/29850 (epoch 12.379), train_loss = 1.31877149, grad/param norm = 1.8849e-01, time/batch = 17.6174s	
7391/29850 (epoch 12.380), train_loss = 1.30609947, grad/param norm = 1.9644e-01, time/batch = 18.7054s	
7392/29850 (epoch 12.382), train_loss = 1.28720612, grad/param norm = 1.8403e-01, time/batch = 16.8671s	
7393/29850 (epoch 12.384), train_loss = 1.26928894, grad/param norm = 1.9049e-01, time/batch = 16.6491s	
7394/29850 (epoch 12.385), train_loss = 1.22647647, grad/param norm = 1.7698e-01, time/batch = 16.8712s	
7395/29850 (epoch 12.387), train_loss = 1.26252582, grad/param norm = 1.9099e-01, time/batch = 17.8010s	
7396/29850 (epoch 12.389), train_loss = 1.39569329, grad/param norm = 1.7356e-01, time/batch = 17.6314s	
7397/29850 (epoch 12.390), train_loss = 1.28335958, grad/param norm = 1.6618e-01, time/batch = 18.3715s	
7398/29850 (epoch 12.392), train_loss = 1.21482271, grad/param norm = 1.8597e-01, time/batch = 16.9590s	
7399/29850 (epoch 12.394), train_loss = 1.33578778, grad/param norm = 1.8058e-01, time/batch = 19.0476s	
7400/29850 (epoch 12.395), train_loss = 1.25308643, grad/param norm = 1.7659e-01, time/batch = 16.3478s	
7401/29850 (epoch 12.397), train_loss = 1.17165370, grad/param norm = 1.7427e-01, time/batch = 17.2950s	
7402/29850 (epoch 12.399), train_loss = 1.14125441, grad/param norm = 1.8558e-01, time/batch = 18.3888s	
7403/29850 (epoch 12.400), train_loss = 1.52767042, grad/param norm = 2.2497e-01, time/batch = 17.1408s	
7404/29850 (epoch 12.402), train_loss = 1.40908180, grad/param norm = 1.8990e-01, time/batch = 16.2059s	
7405/29850 (epoch 12.404), train_loss = 1.29593913, grad/param norm = 1.8486e-01, time/batch = 17.8880s	
7406/29850 (epoch 12.405), train_loss = 1.25828302, grad/param norm = 1.9935e-01, time/batch = 15.7827s	
7407/29850 (epoch 12.407), train_loss = 1.19781454, grad/param norm = 1.8496e-01, time/batch = 17.6248s	
7408/29850 (epoch 12.409), train_loss = 1.39322580, grad/param norm = 2.0548e-01, time/batch = 16.8823s	
7409/29850 (epoch 12.410), train_loss = 1.41355988, grad/param norm = 1.8124e-01, time/batch = 16.2841s	
7410/29850 (epoch 12.412), train_loss = 1.31097824, grad/param norm = 1.8295e-01, time/batch = 18.5584s	
7411/29850 (epoch 12.414), train_loss = 1.28275261, grad/param norm = 2.0207e-01, time/batch = 17.8036s	
7412/29850 (epoch 12.415), train_loss = 1.26731372, grad/param norm = 1.7089e-01, time/batch = 18.7103s	
7413/29850 (epoch 12.417), train_loss = 1.41725872, grad/param norm = 1.9595e-01, time/batch = 18.0476s	
7414/29850 (epoch 12.419), train_loss = 1.29940995, grad/param norm = 1.8644e-01, time/batch = 17.5274s	
7415/29850 (epoch 12.420), train_loss = 1.24831679, grad/param norm = 1.6906e-01, time/batch = 18.1218s	
7416/29850 (epoch 12.422), train_loss = 1.22219692, grad/param norm = 1.7491e-01, time/batch = 18.8873s	
7417/29850 (epoch 12.424), train_loss = 1.25073360, grad/param norm = 1.8199e-01, time/batch = 17.5317s	
7418/29850 (epoch 12.425), train_loss = 1.45337436, grad/param norm = 1.7887e-01, time/batch = 17.2053s	
7419/29850 (epoch 12.427), train_loss = 1.07475143, grad/param norm = 1.6387e-01, time/batch = 16.6963s	
7420/29850 (epoch 12.429), train_loss = 1.13488374, grad/param norm = 1.6992e-01, time/batch = 17.8012s	
7421/29850 (epoch 12.430), train_loss = 1.07401487, grad/param norm = 1.7060e-01, time/batch = 16.5349s	
7422/29850 (epoch 12.432), train_loss = 1.23585266, grad/param norm = 1.8975e-01, time/batch = 17.8741s	
7423/29850 (epoch 12.434), train_loss = 1.12818566, grad/param norm = 1.6684e-01, time/batch = 17.7206s	
7424/29850 (epoch 12.436), train_loss = 1.29870964, grad/param norm = 1.8989e-01, time/batch = 17.2840s	
7425/29850 (epoch 12.437), train_loss = 1.30025461, grad/param norm = 1.6569e-01, time/batch = 19.6283s	
7426/29850 (epoch 12.439), train_loss = 1.26049436, grad/param norm = 1.6543e-01, time/batch = 16.7580s	
7427/29850 (epoch 12.441), train_loss = 1.24603725, grad/param norm = 1.7995e-01, time/batch = 18.3085s	
7428/29850 (epoch 12.442), train_loss = 1.29096085, grad/param norm = 1.7831e-01, time/batch = 16.6274s	
7429/29850 (epoch 12.444), train_loss = 1.24227440, grad/param norm = 1.6522e-01, time/batch = 19.1292s	
7430/29850 (epoch 12.446), train_loss = 1.27448735, grad/param norm = 1.7688e-01, time/batch = 19.3709s	
7431/29850 (epoch 12.447), train_loss = 1.33122880, grad/param norm = 1.8526e-01, time/batch = 17.2827s	
7432/29850 (epoch 12.449), train_loss = 1.32529420, grad/param norm = 1.9553e-01, time/batch = 18.7707s	
7433/29850 (epoch 12.451), train_loss = 1.12255687, grad/param norm = 1.7112e-01, time/batch = 16.8686s	
7434/29850 (epoch 12.452), train_loss = 0.96946439, grad/param norm = 1.4451e-01, time/batch = 18.0196s	
7435/29850 (epoch 12.454), train_loss = 1.10807395, grad/param norm = 1.5910e-01, time/batch = 18.0503s	
7436/29850 (epoch 12.456), train_loss = 1.31827620, grad/param norm = 1.9293e-01, time/batch = 17.0504s	
7437/29850 (epoch 12.457), train_loss = 1.33741759, grad/param norm = 2.0353e-01, time/batch = 17.4716s	
7438/29850 (epoch 12.459), train_loss = 1.41967542, grad/param norm = 1.8419e-01, time/batch = 15.8680s	
7439/29850 (epoch 12.461), train_loss = 1.40842963, grad/param norm = 1.7849e-01, time/batch = 17.5296s	
7440/29850 (epoch 12.462), train_loss = 1.36018846, grad/param norm = 1.8869e-01, time/batch = 15.5320s	
7441/29850 (epoch 12.464), train_loss = 1.28268387, grad/param norm = 1.7414e-01, time/batch = 18.3727s	
7442/29850 (epoch 12.466), train_loss = 1.15189472, grad/param norm = 1.7675e-01, time/batch = 18.8705s	
7443/29850 (epoch 12.467), train_loss = 1.24952495, grad/param norm = 1.8040e-01, time/batch = 18.4612s	
7444/29850 (epoch 12.469), train_loss = 1.23668938, grad/param norm = 1.7444e-01, time/batch = 18.2957s	
7445/29850 (epoch 12.471), train_loss = 1.25821447, grad/param norm = 1.7810e-01, time/batch = 17.7828s	
7446/29850 (epoch 12.472), train_loss = 1.15110365, grad/param norm = 1.7032e-01, time/batch = 17.4692s	
7447/29850 (epoch 12.474), train_loss = 1.37799903, grad/param norm = 1.8924e-01, time/batch = 17.8873s	
7448/29850 (epoch 12.476), train_loss = 1.28062430, grad/param norm = 1.7778e-01, time/batch = 17.6970s	
7449/29850 (epoch 12.477), train_loss = 1.28911751, grad/param norm = 1.9297e-01, time/batch = 18.8584s	
7450/29850 (epoch 12.479), train_loss = 1.36976592, grad/param norm = 1.8014e-01, time/batch = 19.0511s	
7451/29850 (epoch 12.481), train_loss = 1.31604749, grad/param norm = 2.0093e-01, time/batch = 22.6715s	
7452/29850 (epoch 12.482), train_loss = 1.17702678, grad/param norm = 1.5058e-01, time/batch = 25.3017s	
7453/29850 (epoch 12.484), train_loss = 1.19395395, grad/param norm = 1.7589e-01, time/batch = 18.8779s	
7454/29850 (epoch 12.486), train_loss = 1.25019597, grad/param norm = 1.7563e-01, time/batch = 16.3577s	
7455/29850 (epoch 12.487), train_loss = 1.21000459, grad/param norm = 1.7668e-01, time/batch = 18.9496s	
7456/29850 (epoch 12.489), train_loss = 1.25592024, grad/param norm = 1.8375e-01, time/batch = 19.2083s	
7457/29850 (epoch 12.491), train_loss = 1.10485810, grad/param norm = 1.5641e-01, time/batch = 17.9632s	
7458/29850 (epoch 12.492), train_loss = 1.29071345, grad/param norm = 1.8101e-01, time/batch = 17.8025s	
7459/29850 (epoch 12.494), train_loss = 1.38564913, grad/param norm = 1.7148e-01, time/batch = 18.5486s	
7460/29850 (epoch 12.496), train_loss = 1.41988865, grad/param norm = 1.8066e-01, time/batch = 18.4500s	
7461/29850 (epoch 12.497), train_loss = 1.30937394, grad/param norm = 1.7671e-01, time/batch = 19.0381s	
7462/29850 (epoch 12.499), train_loss = 1.27829134, grad/param norm = 1.7265e-01, time/batch = 18.2633s	
7463/29850 (epoch 12.501), train_loss = 1.21065579, grad/param norm = 1.7696e-01, time/batch = 17.4584s	
7464/29850 (epoch 12.503), train_loss = 1.22855527, grad/param norm = 1.6393e-01, time/batch = 14.6965s	
7465/29850 (epoch 12.504), train_loss = 1.44502397, grad/param norm = 1.7814e-01, time/batch = 18.9501s	
7466/29850 (epoch 12.506), train_loss = 1.46420492, grad/param norm = 2.0983e-01, time/batch = 18.1463s	
7467/29850 (epoch 12.508), train_loss = 1.21759827, grad/param norm = 1.6891e-01, time/batch = 16.2926s	
7468/29850 (epoch 12.509), train_loss = 1.05627093, grad/param norm = 1.6307e-01, time/batch = 17.8865s	
7469/29850 (epoch 12.511), train_loss = 1.24491651, grad/param norm = 1.6788e-01, time/batch = 18.0554s	
7470/29850 (epoch 12.513), train_loss = 1.29791966, grad/param norm = 1.9288e-01, time/batch = 17.8838s	
7471/29850 (epoch 12.514), train_loss = 1.12834448, grad/param norm = 1.7100e-01, time/batch = 17.1104s	
7472/29850 (epoch 12.516), train_loss = 1.13908084, grad/param norm = 1.6722e-01, time/batch = 18.0496s	
7473/29850 (epoch 12.518), train_loss = 1.09653009, grad/param norm = 1.6656e-01, time/batch = 18.2871s	
7474/29850 (epoch 12.519), train_loss = 1.09529449, grad/param norm = 1.6690e-01, time/batch = 18.0951s	
7475/29850 (epoch 12.521), train_loss = 1.08408947, grad/param norm = 1.5506e-01, time/batch = 19.7856s	
7476/29850 (epoch 12.523), train_loss = 1.08465421, grad/param norm = 1.4403e-01, time/batch = 19.2974s	
7477/29850 (epoch 12.524), train_loss = 1.22241043, grad/param norm = 1.9604e-01, time/batch = 16.3500s	
7478/29850 (epoch 12.526), train_loss = 1.31089328, grad/param norm = 1.9120e-01, time/batch = 18.3969s	
7479/29850 (epoch 12.528), train_loss = 1.41757810, grad/param norm = 1.9660e-01, time/batch = 19.3798s	
7480/29850 (epoch 12.529), train_loss = 1.31171364, grad/param norm = 1.8278e-01, time/batch = 17.8787s	
7481/29850 (epoch 12.531), train_loss = 1.28185700, grad/param norm = 2.2163e-01, time/batch = 15.2764s	
7482/29850 (epoch 12.533), train_loss = 1.20839853, grad/param norm = 1.7635e-01, time/batch = 17.3851s	
7483/29850 (epoch 12.534), train_loss = 1.21294339, grad/param norm = 1.7279e-01, time/batch = 18.6268s	
7484/29850 (epoch 12.536), train_loss = 1.25500540, grad/param norm = 1.9362e-01, time/batch = 17.1937s	
7485/29850 (epoch 12.538), train_loss = 1.34134467, grad/param norm = 1.8984e-01, time/batch = 16.4761s	
7486/29850 (epoch 12.539), train_loss = 1.40617436, grad/param norm = 1.7618e-01, time/batch = 15.0750s	
7487/29850 (epoch 12.541), train_loss = 1.06065272, grad/param norm = 1.5655e-01, time/batch = 17.0558s	
7488/29850 (epoch 12.543), train_loss = 1.24975159, grad/param norm = 1.6952e-01, time/batch = 17.2835s	
7489/29850 (epoch 12.544), train_loss = 1.26853810, grad/param norm = 1.8078e-01, time/batch = 18.8965s	
7490/29850 (epoch 12.546), train_loss = 1.33851221, grad/param norm = 1.7740e-01, time/batch = 18.3861s	
7491/29850 (epoch 12.548), train_loss = 1.11890943, grad/param norm = 1.7059e-01, time/batch = 18.6973s	
7492/29850 (epoch 12.549), train_loss = 1.18773242, grad/param norm = 1.7159e-01, time/batch = 16.5604s	
7493/29850 (epoch 12.551), train_loss = 1.15564186, grad/param norm = 1.7410e-01, time/batch = 15.5544s	
7494/29850 (epoch 12.553), train_loss = 1.25515566, grad/param norm = 1.6818e-01, time/batch = 16.5340s	
7495/29850 (epoch 12.554), train_loss = 1.03735431, grad/param norm = 1.4916e-01, time/batch = 18.7021s	
7496/29850 (epoch 12.556), train_loss = 1.20145144, grad/param norm = 2.0914e-01, time/batch = 17.1478s	
7497/29850 (epoch 12.558), train_loss = 1.15840907, grad/param norm = 1.6646e-01, time/batch = 17.6945s	
7498/29850 (epoch 12.559), train_loss = 1.25926273, grad/param norm = 1.8187e-01, time/batch = 17.3656s	
7499/29850 (epoch 12.561), train_loss = 1.31443986, grad/param norm = 1.8487e-01, time/batch = 19.2011s	
7500/29850 (epoch 12.563), train_loss = 1.21928235, grad/param norm = 1.7018e-01, time/batch = 18.8820s	
7501/29850 (epoch 12.564), train_loss = 1.22818530, grad/param norm = 1.8600e-01, time/batch = 16.6763s	
7502/29850 (epoch 12.566), train_loss = 1.19906227, grad/param norm = 1.7459e-01, time/batch = 16.5609s	
7503/29850 (epoch 12.568), train_loss = 1.33552867, grad/param norm = 1.7209e-01, time/batch = 18.2237s	
7504/29850 (epoch 12.570), train_loss = 1.24676995, grad/param norm = 1.6957e-01, time/batch = 15.6029s	
7505/29850 (epoch 12.571), train_loss = 1.26975965, grad/param norm = 1.8390e-01, time/batch = 18.1948s	
7506/29850 (epoch 12.573), train_loss = 1.37183867, grad/param norm = 2.0157e-01, time/batch = 17.7941s	
7507/29850 (epoch 12.575), train_loss = 1.34989633, grad/param norm = 1.7197e-01, time/batch = 18.3111s	
7508/29850 (epoch 12.576), train_loss = 1.38250117, grad/param norm = 1.8178e-01, time/batch = 17.1219s	
7509/29850 (epoch 12.578), train_loss = 1.27631129, grad/param norm = 1.7335e-01, time/batch = 18.5439s	
7510/29850 (epoch 12.580), train_loss = 1.37007603, grad/param norm = 1.7330e-01, time/batch = 18.8560s	
7511/29850 (epoch 12.581), train_loss = 1.16718671, grad/param norm = 1.8076e-01, time/batch = 17.6974s	
7512/29850 (epoch 12.583), train_loss = 1.22011999, grad/param norm = 1.7621e-01, time/batch = 17.4743s	
7513/29850 (epoch 12.585), train_loss = 1.29353204, grad/param norm = 1.7727e-01, time/batch = 18.5510s	
7514/29850 (epoch 12.586), train_loss = 1.29792638, grad/param norm = 1.8694e-01, time/batch = 16.7228s	
7515/29850 (epoch 12.588), train_loss = 1.19570392, grad/param norm = 1.7175e-01, time/batch = 18.4641s	
7516/29850 (epoch 12.590), train_loss = 1.23610987, grad/param norm = 1.7852e-01, time/batch = 18.3115s	
7517/29850 (epoch 12.591), train_loss = 1.17158348, grad/param norm = 1.6779e-01, time/batch = 17.7980s	
7518/29850 (epoch 12.593), train_loss = 1.14689855, grad/param norm = 1.5772e-01, time/batch = 15.4257s	
7519/29850 (epoch 12.595), train_loss = 1.12542261, grad/param norm = 1.5771e-01, time/batch = 18.2186s	
7520/29850 (epoch 12.596), train_loss = 1.09598607, grad/param norm = 1.6692e-01, time/batch = 17.9750s	
7521/29850 (epoch 12.598), train_loss = 1.12118603, grad/param norm = 1.5537e-01, time/batch = 17.2033s	
7522/29850 (epoch 12.600), train_loss = 1.34161400, grad/param norm = 1.9423e-01, time/batch = 18.7761s	
7523/29850 (epoch 12.601), train_loss = 1.10633193, grad/param norm = 1.6301e-01, time/batch = 16.2815s	
7524/29850 (epoch 12.603), train_loss = 1.22455811, grad/param norm = 1.7716e-01, time/batch = 17.6104s	
7525/29850 (epoch 12.605), train_loss = 1.23526331, grad/param norm = 1.8742e-01, time/batch = 18.5481s	
7526/29850 (epoch 12.606), train_loss = 1.00784982, grad/param norm = 1.7353e-01, time/batch = 18.2962s	
7527/29850 (epoch 12.608), train_loss = 1.23376882, grad/param norm = 1.7236e-01, time/batch = 18.3905s	
7528/29850 (epoch 12.610), train_loss = 1.23728149, grad/param norm = 1.6622e-01, time/batch = 15.0337s	
7529/29850 (epoch 12.611), train_loss = 1.08041994, grad/param norm = 1.5393e-01, time/batch = 18.9552s	
7530/29850 (epoch 12.613), train_loss = 0.98687120, grad/param norm = 1.4623e-01, time/batch = 16.7268s	
7531/29850 (epoch 12.615), train_loss = 1.08951512, grad/param norm = 1.6316e-01, time/batch = 16.7505s	
7532/29850 (epoch 12.616), train_loss = 1.13922496, grad/param norm = 1.7129e-01, time/batch = 16.4538s	
7533/29850 (epoch 12.618), train_loss = 1.19715838, grad/param norm = 1.6592e-01, time/batch = 18.1304s	
7534/29850 (epoch 12.620), train_loss = 1.24464327, grad/param norm = 1.8518e-01, time/batch = 17.9716s	
7535/29850 (epoch 12.621), train_loss = 1.32363763, grad/param norm = 1.8928e-01, time/batch = 16.1232s	
7536/29850 (epoch 12.623), train_loss = 1.32152585, grad/param norm = 1.8269e-01, time/batch = 19.0465s	
7537/29850 (epoch 12.625), train_loss = 1.26889777, grad/param norm = 1.8044e-01, time/batch = 17.6347s	
7538/29850 (epoch 12.626), train_loss = 1.25919861, grad/param norm = 1.7958e-01, time/batch = 16.4447s	
7539/29850 (epoch 12.628), train_loss = 1.10745610, grad/param norm = 1.6797e-01, time/batch = 18.3785s	
7540/29850 (epoch 12.630), train_loss = 1.22917267, grad/param norm = 1.8275e-01, time/batch = 18.7800s	
7541/29850 (epoch 12.631), train_loss = 1.16579371, grad/param norm = 1.8110e-01, time/batch = 17.7166s	
7542/29850 (epoch 12.633), train_loss = 1.31353066, grad/param norm = 1.9727e-01, time/batch = 16.9646s	
7543/29850 (epoch 12.635), train_loss = 1.21923125, grad/param norm = 1.7086e-01, time/batch = 17.3014s	
7544/29850 (epoch 12.637), train_loss = 1.21226034, grad/param norm = 1.8726e-01, time/batch = 17.4612s	
7545/29850 (epoch 12.638), train_loss = 1.19183590, grad/param norm = 1.7955e-01, time/batch = 17.9203s	
7546/29850 (epoch 12.640), train_loss = 1.37028133, grad/param norm = 1.9859e-01, time/batch = 17.0503s	
7547/29850 (epoch 12.642), train_loss = 1.16916744, grad/param norm = 1.6580e-01, time/batch = 18.2262s	
7548/29850 (epoch 12.643), train_loss = 1.12917446, grad/param norm = 1.6324e-01, time/batch = 16.3828s	
7549/29850 (epoch 12.645), train_loss = 1.24621814, grad/param norm = 1.7631e-01, time/batch = 18.4573s	
7550/29850 (epoch 12.647), train_loss = 1.36462071, grad/param norm = 1.7427e-01, time/batch = 18.8874s	
7551/29850 (epoch 12.648), train_loss = 1.11096120, grad/param norm = 1.6260e-01, time/batch = 18.1230s	
7552/29850 (epoch 12.650), train_loss = 1.20573286, grad/param norm = 1.8215e-01, time/batch = 16.9618s	
7553/29850 (epoch 12.652), train_loss = 1.23878391, grad/param norm = 1.8207e-01, time/batch = 18.1148s	
7554/29850 (epoch 12.653), train_loss = 1.35332510, grad/param norm = 1.8417e-01, time/batch = 18.3108s	
7555/29850 (epoch 12.655), train_loss = 1.21563827, grad/param norm = 1.6750e-01, time/batch = 16.2023s	
7556/29850 (epoch 12.657), train_loss = 1.19278052, grad/param norm = 1.6457e-01, time/batch = 15.6800s	
7557/29850 (epoch 12.658), train_loss = 1.32804380, grad/param norm = 1.7786e-01, time/batch = 17.1312s	
7558/29850 (epoch 12.660), train_loss = 1.19622814, grad/param norm = 1.8277e-01, time/batch = 17.3770s	
7559/29850 (epoch 12.662), train_loss = 1.27240719, grad/param norm = 1.9027e-01, time/batch = 18.1202s	
7560/29850 (epoch 12.663), train_loss = 1.37277369, grad/param norm = 1.9529e-01, time/batch = 17.6422s	
7561/29850 (epoch 12.665), train_loss = 1.30899260, grad/param norm = 1.7760e-01, time/batch = 18.0634s	
7562/29850 (epoch 12.667), train_loss = 1.32048315, grad/param norm = 2.1099e-01, time/batch = 18.2086s	
7563/29850 (epoch 12.668), train_loss = 1.24748860, grad/param norm = 1.7530e-01, time/batch = 17.3824s	
7564/29850 (epoch 12.670), train_loss = 1.43663872, grad/param norm = 2.0208e-01, time/batch = 19.6143s	
7565/29850 (epoch 12.672), train_loss = 1.33579700, grad/param norm = 1.9677e-01, time/batch = 16.2795s	
7566/29850 (epoch 12.673), train_loss = 1.34872652, grad/param norm = 1.9329e-01, time/batch = 18.8732s	
7567/29850 (epoch 12.675), train_loss = 1.18189370, grad/param norm = 1.6377e-01, time/batch = 18.2799s	
7568/29850 (epoch 12.677), train_loss = 1.22169845, grad/param norm = 1.8023e-01, time/batch = 17.9366s	
7569/29850 (epoch 12.678), train_loss = 1.20546020, grad/param norm = 1.8053e-01, time/batch = 17.6338s	
7570/29850 (epoch 12.680), train_loss = 1.26892813, grad/param norm = 1.8866e-01, time/batch = 15.5192s	
7571/29850 (epoch 12.682), train_loss = 1.22875915, grad/param norm = 1.8005e-01, time/batch = 19.9615s	
7572/29850 (epoch 12.683), train_loss = 1.39259750, grad/param norm = 1.9760e-01, time/batch = 16.4370s	
7573/29850 (epoch 12.685), train_loss = 1.39262589, grad/param norm = 1.8093e-01, time/batch = 17.9503s	
7574/29850 (epoch 12.687), train_loss = 1.30850122, grad/param norm = 1.8019e-01, time/batch = 17.4451s	
7575/29850 (epoch 12.688), train_loss = 1.13288909, grad/param norm = 1.5296e-01, time/batch = 18.0441s	
7576/29850 (epoch 12.690), train_loss = 1.15230986, grad/param norm = 1.8195e-01, time/batch = 18.5483s	
7577/29850 (epoch 12.692), train_loss = 1.35547999, grad/param norm = 1.8890e-01, time/batch = 18.4615s	
7578/29850 (epoch 12.693), train_loss = 1.22542572, grad/param norm = 1.6549e-01, time/batch = 18.8657s	
7579/29850 (epoch 12.695), train_loss = 1.06889690, grad/param norm = 1.5286e-01, time/batch = 18.0531s	
7580/29850 (epoch 12.697), train_loss = 1.28290107, grad/param norm = 1.7631e-01, time/batch = 18.4683s	
7581/29850 (epoch 12.698), train_loss = 1.32099079, grad/param norm = 1.8358e-01, time/batch = 18.2978s	
7582/29850 (epoch 12.700), train_loss = 1.27021185, grad/param norm = 1.8421e-01, time/batch = 17.0511s	
7583/29850 (epoch 12.702), train_loss = 1.20341162, grad/param norm = 1.7627e-01, time/batch = 17.9535s	
7584/29850 (epoch 12.704), train_loss = 1.15382205, grad/param norm = 1.7511e-01, time/batch = 17.1383s	
7585/29850 (epoch 12.705), train_loss = 1.25850193, grad/param norm = 1.7449e-01, time/batch = 15.8769s	
7586/29850 (epoch 12.707), train_loss = 1.18379107, grad/param norm = 1.7816e-01, time/batch = 17.5550s	
7587/29850 (epoch 12.709), train_loss = 1.32495798, grad/param norm = 1.9311e-01, time/batch = 16.8129s	
7588/29850 (epoch 12.710), train_loss = 1.20525255, grad/param norm = 1.7975e-01, time/batch = 17.4006s	
7589/29850 (epoch 12.712), train_loss = 1.22158216, grad/param norm = 1.6309e-01, time/batch = 15.4316s	
7590/29850 (epoch 12.714), train_loss = 1.29764532, grad/param norm = 1.8103e-01, time/batch = 14.2468s	
7591/29850 (epoch 12.715), train_loss = 1.31398354, grad/param norm = 1.9203e-01, time/batch = 16.9552s	
7592/29850 (epoch 12.717), train_loss = 1.05680316, grad/param norm = 1.6908e-01, time/batch = 18.6221s	
7593/29850 (epoch 12.719), train_loss = 1.19629660, grad/param norm = 1.7944e-01, time/batch = 17.4495s	
7594/29850 (epoch 12.720), train_loss = 1.24140968, grad/param norm = 1.6250e-01, time/batch = 19.1913s	
7595/29850 (epoch 12.722), train_loss = 1.15591449, grad/param norm = 1.6011e-01, time/batch = 15.1121s	
7596/29850 (epoch 12.724), train_loss = 1.32405112, grad/param norm = 1.8341e-01, time/batch = 17.6185s	
7597/29850 (epoch 12.725), train_loss = 1.12420972, grad/param norm = 1.7198e-01, time/batch = 18.7313s	
7598/29850 (epoch 12.727), train_loss = 1.19198399, grad/param norm = 1.9074e-01, time/batch = 17.2172s	
7599/29850 (epoch 12.729), train_loss = 1.07387960, grad/param norm = 1.6719e-01, time/batch = 17.7163s	
7600/29850 (epoch 12.730), train_loss = 1.08910110, grad/param norm = 1.7297e-01, time/batch = 17.5494s	
7601/29850 (epoch 12.732), train_loss = 1.31420043, grad/param norm = 1.7291e-01, time/batch = 17.8067s	
7602/29850 (epoch 12.734), train_loss = 1.45210788, grad/param norm = 2.1386e-01, time/batch = 18.4481s	
7603/29850 (epoch 12.735), train_loss = 1.22513727, grad/param norm = 1.8768e-01, time/batch = 3.9418s	
7604/29850 (epoch 12.737), train_loss = 1.15470152, grad/param norm = 1.7112e-01, time/batch = 0.6548s	
7605/29850 (epoch 12.739), train_loss = 1.06025056, grad/param norm = 1.6107e-01, time/batch = 0.6635s	
7606/29850 (epoch 12.740), train_loss = 1.08032316, grad/param norm = 1.6468e-01, time/batch = 0.6736s	
7607/29850 (epoch 12.742), train_loss = 1.08661394, grad/param norm = 1.6215e-01, time/batch = 0.6699s	
7608/29850 (epoch 12.744), train_loss = 1.19068377, grad/param norm = 1.9830e-01, time/batch = 0.6592s	
7609/29850 (epoch 12.745), train_loss = 1.18897817, grad/param norm = 2.1559e-01, time/batch = 0.6493s	
7610/29850 (epoch 12.747), train_loss = 1.19173626, grad/param norm = 1.8187e-01, time/batch = 0.7116s	
7611/29850 (epoch 12.749), train_loss = 1.11671597, grad/param norm = 1.8004e-01, time/batch = 0.9590s	
7612/29850 (epoch 12.750), train_loss = 1.13955560, grad/param norm = 1.8620e-01, time/batch = 0.9478s	
7613/29850 (epoch 12.752), train_loss = 1.06434918, grad/param norm = 1.6891e-01, time/batch = 0.9475s	
7614/29850 (epoch 12.754), train_loss = 1.10627792, grad/param norm = 1.6899e-01, time/batch = 0.9524s	
7615/29850 (epoch 12.755), train_loss = 1.17240063, grad/param norm = 1.7855e-01, time/batch = 1.0092s	
7616/29850 (epoch 12.757), train_loss = 1.18195562, grad/param norm = 1.7273e-01, time/batch = 1.7499s	
7617/29850 (epoch 12.759), train_loss = 1.20473799, grad/param norm = 1.7277e-01, time/batch = 1.7724s	
7618/29850 (epoch 12.760), train_loss = 1.09631418, grad/param norm = 1.6441e-01, time/batch = 4.8612s	
7619/29850 (epoch 12.762), train_loss = 1.11724424, grad/param norm = 1.9317e-01, time/batch = 15.2112s	
7620/29850 (epoch 12.764), train_loss = 1.09045026, grad/param norm = 1.7470e-01, time/batch = 17.8738s	
7621/29850 (epoch 12.765), train_loss = 1.17036960, grad/param norm = 1.7241e-01, time/batch = 16.3554s	
7622/29850 (epoch 12.767), train_loss = 1.20028821, grad/param norm = 1.7232e-01, time/batch = 18.2073s	
7623/29850 (epoch 12.769), train_loss = 1.16626397, grad/param norm = 1.7285e-01, time/batch = 19.6173s	
7624/29850 (epoch 12.771), train_loss = 1.24187903, grad/param norm = 1.7794e-01, time/batch = 18.2900s	
7625/29850 (epoch 12.772), train_loss = 1.29063697, grad/param norm = 1.8581e-01, time/batch = 17.7950s	
7626/29850 (epoch 12.774), train_loss = 1.12985695, grad/param norm = 1.7268e-01, time/batch = 19.1989s	
7627/29850 (epoch 12.776), train_loss = 1.18063699, grad/param norm = 1.8373e-01, time/batch = 18.5286s	
7628/29850 (epoch 12.777), train_loss = 1.26197077, grad/param norm = 1.7818e-01, time/batch = 16.9223s	
7629/29850 (epoch 12.779), train_loss = 1.07138037, grad/param norm = 1.5948e-01, time/batch = 16.8051s	
7630/29850 (epoch 12.781), train_loss = 1.17591137, grad/param norm = 1.6998e-01, time/batch = 18.8827s	
7631/29850 (epoch 12.782), train_loss = 1.22970238, grad/param norm = 1.6270e-01, time/batch = 17.5256s	
7632/29850 (epoch 12.784), train_loss = 1.11917146, grad/param norm = 1.8129e-01, time/batch = 17.7957s	
7633/29850 (epoch 12.786), train_loss = 1.17286097, grad/param norm = 1.6393e-01, time/batch = 15.5511s	
7634/29850 (epoch 12.787), train_loss = 1.10124444, grad/param norm = 1.7123e-01, time/batch = 16.1203s	
7635/29850 (epoch 12.789), train_loss = 1.03808920, grad/param norm = 1.5541e-01, time/batch = 18.8740s	
7636/29850 (epoch 12.791), train_loss = 1.18205545, grad/param norm = 1.9067e-01, time/batch = 16.5420s	
7637/29850 (epoch 12.792), train_loss = 1.30069296, grad/param norm = 1.8340e-01, time/batch = 17.4683s	
7638/29850 (epoch 12.794), train_loss = 1.21108781, grad/param norm = 1.6729e-01, time/batch = 17.0294s	
7639/29850 (epoch 12.796), train_loss = 1.14202580, grad/param norm = 1.8209e-01, time/batch = 19.2164s	
7640/29850 (epoch 12.797), train_loss = 1.05765772, grad/param norm = 1.7147e-01, time/batch = 17.3077s	
7641/29850 (epoch 12.799), train_loss = 1.07242967, grad/param norm = 1.6189e-01, time/batch = 17.4498s	
7642/29850 (epoch 12.801), train_loss = 1.25673775, grad/param norm = 1.8579e-01, time/batch = 18.8702s	
7643/29850 (epoch 12.802), train_loss = 1.05564413, grad/param norm = 1.6817e-01, time/batch = 17.6898s	
7644/29850 (epoch 12.804), train_loss = 1.08924223, grad/param norm = 1.6156e-01, time/batch = 17.7747s	
7645/29850 (epoch 12.806), train_loss = 1.09390864, grad/param norm = 1.6186e-01, time/batch = 17.8006s	
7646/29850 (epoch 12.807), train_loss = 1.00641582, grad/param norm = 1.5305e-01, time/batch = 19.1948s	
7647/29850 (epoch 12.809), train_loss = 1.15662502, grad/param norm = 1.8740e-01, time/batch = 18.0369s	
7648/29850 (epoch 12.811), train_loss = 1.25855526, grad/param norm = 2.0575e-01, time/batch = 17.3811s	
7649/29850 (epoch 12.812), train_loss = 1.23158801, grad/param norm = 1.9023e-01, time/batch = 16.7271s	
7650/29850 (epoch 12.814), train_loss = 1.30569490, grad/param norm = 1.8015e-01, time/batch = 19.5397s	
7651/29850 (epoch 12.816), train_loss = 1.27604624, grad/param norm = 1.7632e-01, time/batch = 15.4586s	
7652/29850 (epoch 12.817), train_loss = 1.20448997, grad/param norm = 1.7508e-01, time/batch = 17.7891s	
7653/29850 (epoch 12.819), train_loss = 1.10783755, grad/param norm = 1.7888e-01, time/batch = 17.6335s	
7654/29850 (epoch 12.821), train_loss = 1.35684451, grad/param norm = 1.9167e-01, time/batch = 15.9330s	
7655/29850 (epoch 12.822), train_loss = 1.27287125, grad/param norm = 1.7112e-01, time/batch = 17.2082s	
7656/29850 (epoch 12.824), train_loss = 1.17080856, grad/param norm = 1.7663e-01, time/batch = 19.1997s	
7657/29850 (epoch 12.826), train_loss = 1.14891884, grad/param norm = 1.6393e-01, time/batch = 19.1234s	
7658/29850 (epoch 12.827), train_loss = 1.10507666, grad/param norm = 1.7806e-01, time/batch = 17.8682s	
7659/29850 (epoch 12.829), train_loss = 1.21560789, grad/param norm = 1.8736e-01, time/batch = 17.7912s	
7660/29850 (epoch 12.831), train_loss = 1.26681820, grad/param norm = 1.8106e-01, time/batch = 18.9321s	
7661/29850 (epoch 12.832), train_loss = 1.16955611, grad/param norm = 1.6662e-01, time/batch = 16.8901s	
7662/29850 (epoch 12.834), train_loss = 1.06398099, grad/param norm = 1.7665e-01, time/batch = 17.7186s	
7663/29850 (epoch 12.836), train_loss = 1.05703463, grad/param norm = 1.5517e-01, time/batch = 18.8757s	
7664/29850 (epoch 12.838), train_loss = 1.18199807, grad/param norm = 1.7842e-01, time/batch = 18.4593s	
7665/29850 (epoch 12.839), train_loss = 1.12600435, grad/param norm = 1.7230e-01, time/batch = 17.8857s	
7666/29850 (epoch 12.841), train_loss = 1.14105846, grad/param norm = 1.7193e-01, time/batch = 18.1323s	
7667/29850 (epoch 12.843), train_loss = 1.10832963, grad/param norm = 1.6736e-01, time/batch = 19.0175s	
7668/29850 (epoch 12.844), train_loss = 1.15193504, grad/param norm = 1.7113e-01, time/batch = 31.2921s	
7669/29850 (epoch 12.846), train_loss = 1.20902320, grad/param norm = 1.7037e-01, time/batch = 18.0507s	
7670/29850 (epoch 12.848), train_loss = 1.25012852, grad/param norm = 1.8207e-01, time/batch = 16.8722s	
7671/29850 (epoch 12.849), train_loss = 1.10862847, grad/param norm = 1.9027e-01, time/batch = 15.3673s	
7672/29850 (epoch 12.851), train_loss = 1.29108718, grad/param norm = 1.9885e-01, time/batch = 17.9673s	
7673/29850 (epoch 12.853), train_loss = 1.15689101, grad/param norm = 2.0323e-01, time/batch = 16.5208s	
7674/29850 (epoch 12.854), train_loss = 1.31202727, grad/param norm = 2.0590e-01, time/batch = 17.7797s	
7675/29850 (epoch 12.856), train_loss = 1.27528899, grad/param norm = 2.2081e-01, time/batch = 18.7030s	
7676/29850 (epoch 12.858), train_loss = 1.16769956, grad/param norm = 1.7932e-01, time/batch = 17.3788s	
7677/29850 (epoch 12.859), train_loss = 1.13408064, grad/param norm = 1.7868e-01, time/batch = 17.2225s	
7678/29850 (epoch 12.861), train_loss = 1.27645558, grad/param norm = 1.8668e-01, time/batch = 18.4736s	
7679/29850 (epoch 12.863), train_loss = 1.35039584, grad/param norm = 1.7478e-01, time/batch = 19.2209s	
7680/29850 (epoch 12.864), train_loss = 1.28707929, grad/param norm = 1.9337e-01, time/batch = 18.2931s	
7681/29850 (epoch 12.866), train_loss = 1.23291653, grad/param norm = 1.9194e-01, time/batch = 17.5499s	
7682/29850 (epoch 12.868), train_loss = 1.34750918, grad/param norm = 1.9142e-01, time/batch = 18.5547s	
7683/29850 (epoch 12.869), train_loss = 1.17860002, grad/param norm = 1.8153e-01, time/batch = 15.7841s	
7684/29850 (epoch 12.871), train_loss = 1.22660065, grad/param norm = 1.8215e-01, time/batch = 17.2700s	
7685/29850 (epoch 12.873), train_loss = 1.28063656, grad/param norm = 1.8756e-01, time/batch = 17.7107s	
7686/29850 (epoch 12.874), train_loss = 1.25276918, grad/param norm = 1.8303e-01, time/batch = 18.7975s	
7687/29850 (epoch 12.876), train_loss = 1.20076526, grad/param norm = 2.0086e-01, time/batch = 16.4624s	
7688/29850 (epoch 12.878), train_loss = 1.20905089, grad/param norm = 1.6937e-01, time/batch = 18.0445s	
7689/29850 (epoch 12.879), train_loss = 1.23494818, grad/param norm = 1.8156e-01, time/batch = 17.5643s	
7690/29850 (epoch 12.881), train_loss = 1.28938896, grad/param norm = 1.9147e-01, time/batch = 15.4677s	
7691/29850 (epoch 12.883), train_loss = 1.31764844, grad/param norm = 2.1762e-01, time/batch = 18.3012s	
7692/29850 (epoch 12.884), train_loss = 1.10444381, grad/param norm = 1.7059e-01, time/batch = 17.8841s	
7693/29850 (epoch 12.886), train_loss = 1.34909342, grad/param norm = 1.7649e-01, time/batch = 19.3884s	
7694/29850 (epoch 12.888), train_loss = 1.19590449, grad/param norm = 1.6794e-01, time/batch = 15.4166s	
7695/29850 (epoch 12.889), train_loss = 1.14764397, grad/param norm = 1.7846e-01, time/batch = 19.0310s	
7696/29850 (epoch 12.891), train_loss = 1.16350696, grad/param norm = 1.7198e-01, time/batch = 19.6961s	
7697/29850 (epoch 12.893), train_loss = 1.09736463, grad/param norm = 1.6498e-01, time/batch = 17.1257s	
7698/29850 (epoch 12.894), train_loss = 1.16104009, grad/param norm = 1.6476e-01, time/batch = 18.2825s	
7699/29850 (epoch 12.896), train_loss = 1.18043791, grad/param norm = 1.7940e-01, time/batch = 17.3963s	
7700/29850 (epoch 12.898), train_loss = 1.32269882, grad/param norm = 1.9667e-01, time/batch = 18.3575s	
7701/29850 (epoch 12.899), train_loss = 1.04360949, grad/param norm = 1.6735e-01, time/batch = 18.3909s	
7702/29850 (epoch 12.901), train_loss = 1.52295305, grad/param norm = 2.4188e-01, time/batch = 17.6430s	
7703/29850 (epoch 12.903), train_loss = 1.24062663, grad/param norm = 2.3005e-01, time/batch = 16.4468s	
7704/29850 (epoch 12.905), train_loss = 1.42029469, grad/param norm = 1.9491e-01, time/batch = 16.4532s	
7705/29850 (epoch 12.906), train_loss = 1.16666620, grad/param norm = 1.9391e-01, time/batch = 19.7848s	
7706/29850 (epoch 12.908), train_loss = 1.29840900, grad/param norm = 1.9747e-01, time/batch = 17.7212s	
7707/29850 (epoch 12.910), train_loss = 1.26775947, grad/param norm = 1.7532e-01, time/batch = 14.6482s	
7708/29850 (epoch 12.911), train_loss = 1.39084733, grad/param norm = 1.8403e-01, time/batch = 16.4519s	
7709/29850 (epoch 12.913), train_loss = 1.29577999, grad/param norm = 1.7423e-01, time/batch = 18.4615s	
7710/29850 (epoch 12.915), train_loss = 1.32539888, grad/param norm = 1.9223e-01, time/batch = 16.2335s	
7711/29850 (epoch 12.916), train_loss = 1.29684618, grad/param norm = 1.8604e-01, time/batch = 18.1302s	
7712/29850 (epoch 12.918), train_loss = 1.15282634, grad/param norm = 1.5792e-01, time/batch = 18.5480s	
7713/29850 (epoch 12.920), train_loss = 1.29503357, grad/param norm = 1.6997e-01, time/batch = 17.4448s	
7714/29850 (epoch 12.921), train_loss = 1.26795523, grad/param norm = 1.9605e-01, time/batch = 17.1334s	
7715/29850 (epoch 12.923), train_loss = 1.29572408, grad/param norm = 1.8105e-01, time/batch = 19.5413s	
7716/29850 (epoch 12.925), train_loss = 1.34363188, grad/param norm = 1.9140e-01, time/batch = 17.5692s	
7717/29850 (epoch 12.926), train_loss = 1.39049548, grad/param norm = 2.0337e-01, time/batch = 17.2038s	
7718/29850 (epoch 12.928), train_loss = 1.23440103, grad/param norm = 1.8010e-01, time/batch = 15.6364s	
7719/29850 (epoch 12.930), train_loss = 1.30769337, grad/param norm = 1.9249e-01, time/batch = 17.0459s	
7720/29850 (epoch 12.931), train_loss = 1.27042360, grad/param norm = 1.8722e-01, time/batch = 16.3376s	
7721/29850 (epoch 12.933), train_loss = 1.38981655, grad/param norm = 1.8886e-01, time/batch = 17.1096s	
7722/29850 (epoch 12.935), train_loss = 1.34595168, grad/param norm = 1.8654e-01, time/batch = 16.8724s	
7723/29850 (epoch 12.936), train_loss = 1.34496614, grad/param norm = 1.8545e-01, time/batch = 15.1668s	
7724/29850 (epoch 12.938), train_loss = 1.10298505, grad/param norm = 1.8351e-01, time/batch = 18.7931s	
7725/29850 (epoch 12.940), train_loss = 1.10155804, grad/param norm = 1.8322e-01, time/batch = 18.9604s	
7726/29850 (epoch 12.941), train_loss = 1.16295558, grad/param norm = 1.8232e-01, time/batch = 19.0501s	
7727/29850 (epoch 12.943), train_loss = 1.13669366, grad/param norm = 1.6338e-01, time/batch = 18.3763s	
7728/29850 (epoch 12.945), train_loss = 1.23085513, grad/param norm = 1.9006e-01, time/batch = 16.2137s	
7729/29850 (epoch 12.946), train_loss = 1.12820185, grad/param norm = 1.8828e-01, time/batch = 20.2886s	
7730/29850 (epoch 12.948), train_loss = 1.20199557, grad/param norm = 1.6669e-01, time/batch = 18.4688s	
7731/29850 (epoch 12.950), train_loss = 1.13649458, grad/param norm = 1.6030e-01, time/batch = 16.4661s	
7732/29850 (epoch 12.951), train_loss = 1.09174112, grad/param norm = 1.5720e-01, time/batch = 17.5470s	
7733/29850 (epoch 12.953), train_loss = 1.20208488, grad/param norm = 1.9427e-01, time/batch = 18.4757s	
7734/29850 (epoch 12.955), train_loss = 1.06286521, grad/param norm = 1.6137e-01, time/batch = 17.2975s	
7735/29850 (epoch 12.956), train_loss = 1.07524878, grad/param norm = 1.6286e-01, time/batch = 16.9701s	
7736/29850 (epoch 12.958), train_loss = 0.95413579, grad/param norm = 1.6387e-01, time/batch = 16.8223s	
7737/29850 (epoch 12.960), train_loss = 1.27956862, grad/param norm = 1.9309e-01, time/batch = 18.0549s	
7738/29850 (epoch 12.961), train_loss = 1.13909102, grad/param norm = 1.6525e-01, time/batch = 15.6910s	
7739/29850 (epoch 12.963), train_loss = 1.08408714, grad/param norm = 1.6378e-01, time/batch = 17.2796s	
7740/29850 (epoch 12.965), train_loss = 1.15748719, grad/param norm = 1.7899e-01, time/batch = 19.8672s	
7741/29850 (epoch 12.966), train_loss = 1.04725254, grad/param norm = 1.5564e-01, time/batch = 18.0443s	
7742/29850 (epoch 12.968), train_loss = 1.17464401, grad/param norm = 1.8962e-01, time/batch = 18.7131s	
7743/29850 (epoch 12.970), train_loss = 1.10652518, grad/param norm = 1.7956e-01, time/batch = 18.1268s	
7744/29850 (epoch 12.972), train_loss = 1.10556244, grad/param norm = 1.6615e-01, time/batch = 18.5399s	
7745/29850 (epoch 12.973), train_loss = 1.12647012, grad/param norm = 1.8303e-01, time/batch = 18.1966s	
7746/29850 (epoch 12.975), train_loss = 0.96712280, grad/param norm = 1.5512e-01, time/batch = 18.9400s	
7747/29850 (epoch 12.977), train_loss = 1.13885974, grad/param norm = 1.6316e-01, time/batch = 19.5619s	
7748/29850 (epoch 12.978), train_loss = 1.08421195, grad/param norm = 1.5528e-01, time/batch = 17.1828s	
7749/29850 (epoch 12.980), train_loss = 1.11596698, grad/param norm = 1.6540e-01, time/batch = 19.1363s	
7750/29850 (epoch 12.982), train_loss = 1.13389583, grad/param norm = 1.6998e-01, time/batch = 17.6169s	
7751/29850 (epoch 12.983), train_loss = 1.17689698, grad/param norm = 1.6653e-01, time/batch = 15.9685s	
7752/29850 (epoch 12.985), train_loss = 1.24494668, grad/param norm = 1.8283e-01, time/batch = 17.0523s	
7753/29850 (epoch 12.987), train_loss = 1.15360036, grad/param norm = 1.5909e-01, time/batch = 17.6288s	
7754/29850 (epoch 12.988), train_loss = 1.09459296, grad/param norm = 1.5916e-01, time/batch = 17.9463s	
7755/29850 (epoch 12.990), train_loss = 1.19769051, grad/param norm = 1.7143e-01, time/batch = 15.9538s	
7756/29850 (epoch 12.992), train_loss = 1.20543186, grad/param norm = 1.7243e-01, time/batch = 18.4774s	
7757/29850 (epoch 12.993), train_loss = 1.18193611, grad/param norm = 1.7935e-01, time/batch = 19.4709s	
7758/29850 (epoch 12.995), train_loss = 1.21271231, grad/param norm = 1.7166e-01, time/batch = 15.1057s	
7759/29850 (epoch 12.997), train_loss = 1.18330665, grad/param norm = 1.6623e-01, time/batch = 18.3891s	
7760/29850 (epoch 12.998), train_loss = 1.27660607, grad/param norm = 1.8412e-01, time/batch = 18.2200s	
decayed learning rate by a factor 0.97 to 0.00177058562	
7761/29850 (epoch 13.000), train_loss = 1.12171767, grad/param norm = 1.6301e-01, time/batch = 16.5269s	
7762/29850 (epoch 13.002), train_loss = 1.41266094, grad/param norm = 1.8946e-01, time/batch = 18.8813s	
7763/29850 (epoch 13.003), train_loss = 1.12686471, grad/param norm = 1.7565e-01, time/batch = 17.8861s	
7764/29850 (epoch 13.005), train_loss = 1.20097796, grad/param norm = 1.7087e-01, time/batch = 17.8866s	
7765/29850 (epoch 13.007), train_loss = 1.22101087, grad/param norm = 2.0481e-01, time/batch = 17.1149s	
7766/29850 (epoch 13.008), train_loss = 1.46316353, grad/param norm = 1.9903e-01, time/batch = 18.8103s	
7767/29850 (epoch 13.010), train_loss = 1.09528994, grad/param norm = 1.8286e-01, time/batch = 18.2225s	
7768/29850 (epoch 13.012), train_loss = 1.24331543, grad/param norm = 1.7280e-01, time/batch = 16.3644s	
7769/29850 (epoch 13.013), train_loss = 1.26283285, grad/param norm = 1.8703e-01, time/batch = 19.7109s	
7770/29850 (epoch 13.015), train_loss = 1.26135707, grad/param norm = 1.7708e-01, time/batch = 16.4658s	
7771/29850 (epoch 13.017), train_loss = 1.31162351, grad/param norm = 1.9653e-01, time/batch = 18.3850s	
7772/29850 (epoch 13.018), train_loss = 1.34895539, grad/param norm = 2.0645e-01, time/batch = 17.7713s	
7773/29850 (epoch 13.020), train_loss = 1.15879377, grad/param norm = 1.7012e-01, time/batch = 18.6166s	
7774/29850 (epoch 13.022), train_loss = 1.30401505, grad/param norm = 1.8289e-01, time/batch = 19.1857s	
7775/29850 (epoch 13.023), train_loss = 1.22979833, grad/param norm = 1.6249e-01, time/batch = 16.4302s	
7776/29850 (epoch 13.025), train_loss = 1.16827771, grad/param norm = 1.6811e-01, time/batch = 16.1212s	
7777/29850 (epoch 13.027), train_loss = 1.05145139, grad/param norm = 1.5571e-01, time/batch = 18.4699s	
7778/29850 (epoch 13.028), train_loss = 1.17823621, grad/param norm = 1.7182e-01, time/batch = 16.4595s	
7779/29850 (epoch 13.030), train_loss = 1.24642157, grad/param norm = 1.7964e-01, time/batch = 18.3748s	
7780/29850 (epoch 13.032), train_loss = 1.21820687, grad/param norm = 1.7443e-01, time/batch = 18.9756s	
7781/29850 (epoch 13.034), train_loss = 1.14023877, grad/param norm = 1.6679e-01, time/batch = 18.3658s	
7782/29850 (epoch 13.035), train_loss = 1.03762390, grad/param norm = 1.5747e-01, time/batch = 18.4685s	
7783/29850 (epoch 13.037), train_loss = 1.22027500, grad/param norm = 1.8644e-01, time/batch = 19.6132s	
7784/29850 (epoch 13.039), train_loss = 1.03890620, grad/param norm = 1.5453e-01, time/batch = 16.5334s	
7785/29850 (epoch 13.040), train_loss = 1.09871906, grad/param norm = 1.6631e-01, time/batch = 16.9388s	
7786/29850 (epoch 13.042), train_loss = 1.12743162, grad/param norm = 1.6445e-01, time/batch = 18.4488s	
7787/29850 (epoch 13.044), train_loss = 1.14443883, grad/param norm = 1.6574e-01, time/batch = 18.8697s	
7788/29850 (epoch 13.045), train_loss = 1.25644214, grad/param norm = 1.8412e-01, time/batch = 16.1262s	
7789/29850 (epoch 13.047), train_loss = 1.02866227, grad/param norm = 1.7201e-01, time/batch = 15.7706s	
7790/29850 (epoch 13.049), train_loss = 1.23364262, grad/param norm = 1.6758e-01, time/batch = 17.8775s	
7791/29850 (epoch 13.050), train_loss = 1.10785488, grad/param norm = 1.7339e-01, time/batch = 18.0446s	
7792/29850 (epoch 13.052), train_loss = 1.39380750, grad/param norm = 2.0242e-01, time/batch = 18.5419s	
7793/29850 (epoch 13.054), train_loss = 1.26419684, grad/param norm = 1.7214e-01, time/batch = 16.7059s	
7794/29850 (epoch 13.055), train_loss = 1.17521087, grad/param norm = 1.7968e-01, time/batch = 19.4521s	
7795/29850 (epoch 13.057), train_loss = 1.23591025, grad/param norm = 1.7025e-01, time/batch = 16.7596s	
7796/29850 (epoch 13.059), train_loss = 1.26132019, grad/param norm = 1.9692e-01, time/batch = 19.3045s	
7797/29850 (epoch 13.060), train_loss = 1.23411073, grad/param norm = 1.8087e-01, time/batch = 19.5404s	
7798/29850 (epoch 13.062), train_loss = 1.32883823, grad/param norm = 1.9428e-01, time/batch = 16.9684s	
7799/29850 (epoch 13.064), train_loss = 1.27116204, grad/param norm = 1.8653e-01, time/batch = 17.6227s	
7800/29850 (epoch 13.065), train_loss = 1.09750614, grad/param norm = 1.6927e-01, time/batch = 18.3030s	
7801/29850 (epoch 13.067), train_loss = 1.23451807, grad/param norm = 1.7588e-01, time/batch = 16.8568s	
7802/29850 (epoch 13.069), train_loss = 1.19500706, grad/param norm = 1.7401e-01, time/batch = 15.3965s	
7803/29850 (epoch 13.070), train_loss = 1.23256945, grad/param norm = 1.6597e-01, time/batch = 15.7223s	
7804/29850 (epoch 13.072), train_loss = 1.28414152, grad/param norm = 1.9407e-01, time/batch = 17.3797s	
7805/29850 (epoch 13.074), train_loss = 1.27989859, grad/param norm = 1.6770e-01, time/batch = 17.0325s	
7806/29850 (epoch 13.075), train_loss = 1.13492234, grad/param norm = 1.6737e-01, time/batch = 19.2732s	
7807/29850 (epoch 13.077), train_loss = 1.23954866, grad/param norm = 1.8175e-01, time/batch = 19.1110s	
7808/29850 (epoch 13.079), train_loss = 1.46486298, grad/param norm = 2.0451e-01, time/batch = 17.6161s	
7809/29850 (epoch 13.080), train_loss = 1.37710945, grad/param norm = 1.9918e-01, time/batch = 19.5439s	
7810/29850 (epoch 13.082), train_loss = 1.26939339, grad/param norm = 1.7914e-01, time/batch = 18.3747s	
7811/29850 (epoch 13.084), train_loss = 1.31931612, grad/param norm = 1.9339e-01, time/batch = 14.9054s	
7812/29850 (epoch 13.085), train_loss = 1.27623179, grad/param norm = 1.9444e-01, time/batch = 17.9572s	
7813/29850 (epoch 13.087), train_loss = 1.33694025, grad/param norm = 1.7395e-01, time/batch = 15.8507s	
7814/29850 (epoch 13.089), train_loss = 1.26998091, grad/param norm = 1.7927e-01, time/batch = 16.7021s	
7815/29850 (epoch 13.090), train_loss = 1.29852621, grad/param norm = 1.9387e-01, time/batch = 16.5249s	
7816/29850 (epoch 13.092), train_loss = 1.17892292, grad/param norm = 1.7261e-01, time/batch = 18.2072s	
7817/29850 (epoch 13.094), train_loss = 1.30521733, grad/param norm = 1.8009e-01, time/batch = 19.1317s	
7818/29850 (epoch 13.095), train_loss = 1.26744643, grad/param norm = 1.9099e-01, time/batch = 19.0903s	
7819/29850 (epoch 13.097), train_loss = 1.01852510, grad/param norm = 1.5179e-01, time/batch = 15.2993s	
7820/29850 (epoch 13.099), train_loss = 1.05078021, grad/param norm = 1.6203e-01, time/batch = 18.2229s	
7821/29850 (epoch 13.101), train_loss = 1.34905070, grad/param norm = 1.8672e-01, time/batch = 18.6272s	
7822/29850 (epoch 13.102), train_loss = 1.27686798, grad/param norm = 1.9710e-01, time/batch = 16.1836s	
7823/29850 (epoch 13.104), train_loss = 1.18389330, grad/param norm = 1.6447e-01, time/batch = 18.8740s	
7824/29850 (epoch 13.106), train_loss = 1.28610817, grad/param norm = 1.8188e-01, time/batch = 19.2196s	
7825/29850 (epoch 13.107), train_loss = 1.05064040, grad/param norm = 1.4985e-01, time/batch = 16.7867s	
7826/29850 (epoch 13.109), train_loss = 1.17713661, grad/param norm = 1.9861e-01, time/batch = 16.9420s	
7827/29850 (epoch 13.111), train_loss = 1.30473983, grad/param norm = 1.7680e-01, time/batch = 19.0516s	
7828/29850 (epoch 13.112), train_loss = 1.11344540, grad/param norm = 1.6391e-01, time/batch = 18.8561s	
7829/29850 (epoch 13.114), train_loss = 1.26564107, grad/param norm = 2.0031e-01, time/batch = 16.6321s	
7830/29850 (epoch 13.116), train_loss = 1.13406845, grad/param norm = 1.6602e-01, time/batch = 19.2070s	
7831/29850 (epoch 13.117), train_loss = 1.21491605, grad/param norm = 1.8428e-01, time/batch = 16.7962s	
7832/29850 (epoch 13.119), train_loss = 1.19412936, grad/param norm = 1.6178e-01, time/batch = 17.0387s	
7833/29850 (epoch 13.121), train_loss = 1.00981659, grad/param norm = 1.7380e-01, time/batch = 17.8129s	
7834/29850 (epoch 13.122), train_loss = 1.07373450, grad/param norm = 1.6027e-01, time/batch = 17.6418s	
7835/29850 (epoch 13.124), train_loss = 1.13976359, grad/param norm = 1.6128e-01, time/batch = 16.8722s	
7836/29850 (epoch 13.126), train_loss = 1.19790804, grad/param norm = 1.8463e-01, time/batch = 18.0435s	
7837/29850 (epoch 13.127), train_loss = 1.33448350, grad/param norm = 1.9617e-01, time/batch = 16.6508s	
7838/29850 (epoch 13.129), train_loss = 1.18233647, grad/param norm = 1.7532e-01, time/batch = 18.7013s	
7839/29850 (epoch 13.131), train_loss = 1.18732344, grad/param norm = 1.7581e-01, time/batch = 15.7827s	
7840/29850 (epoch 13.132), train_loss = 1.11723987, grad/param norm = 1.7594e-01, time/batch = 17.0620s	
7841/29850 (epoch 13.134), train_loss = 1.24536346, grad/param norm = 1.7904e-01, time/batch = 15.5826s	
7842/29850 (epoch 13.136), train_loss = 1.23744697, grad/param norm = 1.8144e-01, time/batch = 18.1984s	
7843/29850 (epoch 13.137), train_loss = 1.07143180, grad/param norm = 1.7085e-01, time/batch = 16.1808s	
7844/29850 (epoch 13.139), train_loss = 1.09914579, grad/param norm = 1.6033e-01, time/batch = 18.5598s	
7845/29850 (epoch 13.141), train_loss = 1.17617359, grad/param norm = 1.7603e-01, time/batch = 18.5550s	
7846/29850 (epoch 13.142), train_loss = 1.30513090, grad/param norm = 1.9250e-01, time/batch = 18.9542s	
7847/29850 (epoch 13.144), train_loss = 1.45543653, grad/param norm = 1.9643e-01, time/batch = 18.6411s	
7848/29850 (epoch 13.146), train_loss = 1.43011351, grad/param norm = 2.0311e-01, time/batch = 18.1416s	
7849/29850 (epoch 13.147), train_loss = 1.32527890, grad/param norm = 1.9702e-01, time/batch = 17.9462s	
7850/29850 (epoch 13.149), train_loss = 1.30955565, grad/param norm = 1.9097e-01, time/batch = 16.0341s	
7851/29850 (epoch 13.151), train_loss = 1.24277142, grad/param norm = 1.8746e-01, time/batch = 19.7765s	
7852/29850 (epoch 13.152), train_loss = 1.13546581, grad/param norm = 1.6846e-01, time/batch = 16.3606s	
7853/29850 (epoch 13.154), train_loss = 1.16530376, grad/param norm = 1.7400e-01, time/batch = 17.8636s	
7854/29850 (epoch 13.156), train_loss = 1.13761474, grad/param norm = 1.6805e-01, time/batch = 18.1409s	
7855/29850 (epoch 13.157), train_loss = 1.20339631, grad/param norm = 1.6645e-01, time/batch = 17.0974s	
7856/29850 (epoch 13.159), train_loss = 1.22823690, grad/param norm = 1.6987e-01, time/batch = 16.6947s	
7857/29850 (epoch 13.161), train_loss = 1.26804051, grad/param norm = 1.8585e-01, time/batch = 18.3795s	
7858/29850 (epoch 13.162), train_loss = 1.37363031, grad/param norm = 1.9076e-01, time/batch = 16.6893s	
7859/29850 (epoch 13.164), train_loss = 1.21873918, grad/param norm = 1.8764e-01, time/batch = 16.7087s	
7860/29850 (epoch 13.166), train_loss = 1.11402071, grad/param norm = 1.6443e-01, time/batch = 19.6747s	
7861/29850 (epoch 13.168), train_loss = 1.02237518, grad/param norm = 1.6029e-01, time/batch = 19.2174s	
7862/29850 (epoch 13.169), train_loss = 1.39669069, grad/param norm = 1.9931e-01, time/batch = 17.2891s	
7863/29850 (epoch 13.171), train_loss = 1.31570511, grad/param norm = 1.8953e-01, time/batch = 16.6504s	
7864/29850 (epoch 13.173), train_loss = 1.18341863, grad/param norm = 1.9847e-01, time/batch = 19.0477s	
7865/29850 (epoch 13.174), train_loss = 1.30212504, grad/param norm = 1.9298e-01, time/batch = 18.3807s	
7866/29850 (epoch 13.176), train_loss = 1.26956249, grad/param norm = 1.8228e-01, time/batch = 17.0539s	
7867/29850 (epoch 13.178), train_loss = 1.28086851, grad/param norm = 1.8841e-01, time/batch = 18.1252s	
7868/29850 (epoch 13.179), train_loss = 1.04108830, grad/param norm = 1.6281e-01, time/batch = 19.5390s	
7869/29850 (epoch 13.181), train_loss = 1.20654991, grad/param norm = 1.7832e-01, time/batch = 27.4867s	
7870/29850 (epoch 13.183), train_loss = 1.16216846, grad/param norm = 1.7283e-01, time/batch = 20.4755s	
7871/29850 (epoch 13.184), train_loss = 1.18233318, grad/param norm = 1.8361e-01, time/batch = 18.1260s	
7872/29850 (epoch 13.186), train_loss = 1.19394088, grad/param norm = 1.7890e-01, time/batch = 16.0277s	
7873/29850 (epoch 13.188), train_loss = 1.29607856, grad/param norm = 2.0249e-01, time/batch = 17.7049s	
7874/29850 (epoch 13.189), train_loss = 1.40450726, grad/param norm = 2.0109e-01, time/batch = 19.8512s	
7875/29850 (epoch 13.191), train_loss = 1.25848557, grad/param norm = 1.7748e-01, time/batch = 16.1941s	
7876/29850 (epoch 13.193), train_loss = 1.12774062, grad/param norm = 1.6466e-01, time/batch = 18.6085s	
7877/29850 (epoch 13.194), train_loss = 1.25491328, grad/param norm = 1.8838e-01, time/batch = 17.2381s	
7878/29850 (epoch 13.196), train_loss = 1.17179171, grad/param norm = 1.7823e-01, time/batch = 18.0458s	
7879/29850 (epoch 13.198), train_loss = 1.20258720, grad/param norm = 1.7790e-01, time/batch = 17.9416s	
7880/29850 (epoch 13.199), train_loss = 1.48645585, grad/param norm = 1.9964e-01, time/batch = 16.4069s	
7881/29850 (epoch 13.201), train_loss = 1.15187943, grad/param norm = 1.7367e-01, time/batch = 18.1349s	
7882/29850 (epoch 13.203), train_loss = 1.05151884, grad/param norm = 1.7480e-01, time/batch = 18.1060s	
7883/29850 (epoch 13.204), train_loss = 1.28464037, grad/param norm = 2.0488e-01, time/batch = 19.2014s	
7884/29850 (epoch 13.206), train_loss = 1.10573717, grad/param norm = 1.8199e-01, time/batch = 16.5614s	
7885/29850 (epoch 13.208), train_loss = 1.39547113, grad/param norm = 1.9863e-01, time/batch = 16.5360s	
7886/29850 (epoch 13.209), train_loss = 1.11090603, grad/param norm = 1.6433e-01, time/batch = 16.2389s	
7887/29850 (epoch 13.211), train_loss = 1.17729975, grad/param norm = 1.5985e-01, time/batch = 18.5335s	
7888/29850 (epoch 13.213), train_loss = 1.34249790, grad/param norm = 2.0560e-01, time/batch = 18.1173s	
7889/29850 (epoch 13.214), train_loss = 1.12878320, grad/param norm = 1.6469e-01, time/batch = 15.6233s	
7890/29850 (epoch 13.216), train_loss = 1.16231339, grad/param norm = 1.8163e-01, time/batch = 16.7316s	
7891/29850 (epoch 13.218), train_loss = 1.27784384, grad/param norm = 1.8233e-01, time/batch = 19.1304s	
7892/29850 (epoch 13.219), train_loss = 1.35920049, grad/param norm = 1.9783e-01, time/batch = 17.8800s	
7893/29850 (epoch 13.221), train_loss = 1.20308558, grad/param norm = 1.9715e-01, time/batch = 18.1141s	
7894/29850 (epoch 13.223), train_loss = 1.18050454, grad/param norm = 1.9037e-01, time/batch = 18.7095s	
7895/29850 (epoch 13.224), train_loss = 1.10196025, grad/param norm = 1.8128e-01, time/batch = 17.0419s	
7896/29850 (epoch 13.226), train_loss = 1.10159861, grad/param norm = 1.5646e-01, time/batch = 18.1457s	
7897/29850 (epoch 13.228), train_loss = 1.16675976, grad/param norm = 1.6438e-01, time/batch = 18.1346s	
7898/29850 (epoch 13.229), train_loss = 1.06496513, grad/param norm = 1.6558e-01, time/batch = 18.5391s	
7899/29850 (epoch 13.231), train_loss = 1.17038199, grad/param norm = 1.6519e-01, time/batch = 16.4449s	
7900/29850 (epoch 13.233), train_loss = 1.18998047, grad/param norm = 1.8852e-01, time/batch = 16.4731s	
7901/29850 (epoch 13.235), train_loss = 1.10316938, grad/param norm = 1.5357e-01, time/batch = 18.6950s	
7902/29850 (epoch 13.236), train_loss = 1.33534184, grad/param norm = 2.0331e-01, time/batch = 15.3559s	
7903/29850 (epoch 13.238), train_loss = 1.08370016, grad/param norm = 1.8334e-01, time/batch = 15.4664s	
7904/29850 (epoch 13.240), train_loss = 1.10689958, grad/param norm = 1.6985e-01, time/batch = 17.1355s	
7905/29850 (epoch 13.241), train_loss = 1.32754782, grad/param norm = 2.0198e-01, time/batch = 18.1367s	
7906/29850 (epoch 13.243), train_loss = 1.20118958, grad/param norm = 1.7772e-01, time/batch = 16.5157s	
7907/29850 (epoch 13.245), train_loss = 1.13991806, grad/param norm = 1.8718e-01, time/batch = 19.0459s	
7908/29850 (epoch 13.246), train_loss = 1.11192838, grad/param norm = 1.7527e-01, time/batch = 17.8803s	
7909/29850 (epoch 13.248), train_loss = 1.10677676, grad/param norm = 1.8455e-01, time/batch = 17.1258s	
7910/29850 (epoch 13.250), train_loss = 1.17283754, grad/param norm = 1.6998e-01, time/batch = 17.1153s	
7911/29850 (epoch 13.251), train_loss = 1.09632513, grad/param norm = 1.8596e-01, time/batch = 19.2904s	
7912/29850 (epoch 13.253), train_loss = 1.04228751, grad/param norm = 1.8504e-01, time/batch = 16.8857s	
7913/29850 (epoch 13.255), train_loss = 1.09305128, grad/param norm = 1.6552e-01, time/batch = 18.5474s	
7914/29850 (epoch 13.256), train_loss = 1.22745433, grad/param norm = 1.9503e-01, time/batch = 15.4704s	
7915/29850 (epoch 13.258), train_loss = 1.20667887, grad/param norm = 1.7516e-01, time/batch = 17.0264s	
7916/29850 (epoch 13.260), train_loss = 1.14899802, grad/param norm = 1.6759e-01, time/batch = 16.5351s	
7917/29850 (epoch 13.261), train_loss = 1.14747037, grad/param norm = 1.7808e-01, time/batch = 18.9599s	
7918/29850 (epoch 13.263), train_loss = 1.06080245, grad/param norm = 1.6627e-01, time/batch = 19.3456s	
7919/29850 (epoch 13.265), train_loss = 1.14091796, grad/param norm = 1.8252e-01, time/batch = 17.4218s	
7920/29850 (epoch 13.266), train_loss = 1.15558673, grad/param norm = 1.8588e-01, time/batch = 17.8958s	
7921/29850 (epoch 13.268), train_loss = 1.14433003, grad/param norm = 1.6476e-01, time/batch = 16.4807s	
7922/29850 (epoch 13.270), train_loss = 1.11396428, grad/param norm = 1.7067e-01, time/batch = 18.7912s	
7923/29850 (epoch 13.271), train_loss = 1.27946729, grad/param norm = 1.7351e-01, time/batch = 16.0344s	
7924/29850 (epoch 13.273), train_loss = 1.05804862, grad/param norm = 1.7167e-01, time/batch = 18.7109s	
7925/29850 (epoch 13.275), train_loss = 1.05238861, grad/param norm = 1.6769e-01, time/batch = 17.3974s	
7926/29850 (epoch 13.276), train_loss = 1.06268551, grad/param norm = 1.6989e-01, time/batch = 17.2812s	
7927/29850 (epoch 13.278), train_loss = 1.13565220, grad/param norm = 1.6389e-01, time/batch = 18.4534s	
7928/29850 (epoch 13.280), train_loss = 1.33770077, grad/param norm = 2.0676e-01, time/batch = 15.7165s	
7929/29850 (epoch 13.281), train_loss = 1.20265521, grad/param norm = 1.9356e-01, time/batch = 17.7913s	
7930/29850 (epoch 13.283), train_loss = 1.30905482, grad/param norm = 2.0882e-01, time/batch = 16.9655s	
7931/29850 (epoch 13.285), train_loss = 1.16445092, grad/param norm = 1.7822e-01, time/batch = 18.4214s	
7932/29850 (epoch 13.286), train_loss = 1.25539231, grad/param norm = 1.8578e-01, time/batch = 18.9631s	
7933/29850 (epoch 13.288), train_loss = 1.38507220, grad/param norm = 2.3347e-01, time/batch = 17.2871s	
7934/29850 (epoch 13.290), train_loss = 1.14362601, grad/param norm = 1.7936e-01, time/batch = 17.3023s	
7935/29850 (epoch 13.291), train_loss = 1.44583843, grad/param norm = 1.7981e-01, time/batch = 19.3667s	
7936/29850 (epoch 13.293), train_loss = 1.28224690, grad/param norm = 1.8741e-01, time/batch = 16.8585s	
7937/29850 (epoch 13.295), train_loss = 1.36595444, grad/param norm = 1.7795e-01, time/batch = 17.8799s	
7938/29850 (epoch 13.296), train_loss = 1.13150407, grad/param norm = 1.6858e-01, time/batch = 16.3020s	
7939/29850 (epoch 13.298), train_loss = 0.97818256, grad/param norm = 1.6713e-01, time/batch = 18.4534s	
7940/29850 (epoch 13.300), train_loss = 1.05619631, grad/param norm = 1.6102e-01, time/batch = 15.9656s	
7941/29850 (epoch 13.302), train_loss = 1.05308756, grad/param norm = 1.6198e-01, time/batch = 19.5402s	
7942/29850 (epoch 13.303), train_loss = 1.10020624, grad/param norm = 1.6570e-01, time/batch = 18.1425s	
7943/29850 (epoch 13.305), train_loss = 1.20664244, grad/param norm = 1.8161e-01, time/batch = 17.1153s	
7944/29850 (epoch 13.307), train_loss = 1.29667873, grad/param norm = 1.8129e-01, time/batch = 19.8774s	
7945/29850 (epoch 13.308), train_loss = 1.18041787, grad/param norm = 1.9150e-01, time/batch = 17.5620s	
7946/29850 (epoch 13.310), train_loss = 1.21900241, grad/param norm = 1.8804e-01, time/batch = 16.6159s	
7947/29850 (epoch 13.312), train_loss = 1.27345725, grad/param norm = 1.7795e-01, time/batch = 17.4428s	
7948/29850 (epoch 13.313), train_loss = 1.23237310, grad/param norm = 1.8439e-01, time/batch = 15.6968s	
7949/29850 (epoch 13.315), train_loss = 1.21796515, grad/param norm = 1.7791e-01, time/batch = 17.9821s	
7950/29850 (epoch 13.317), train_loss = 1.22740285, grad/param norm = 2.0010e-01, time/batch = 16.6163s	
7951/29850 (epoch 13.318), train_loss = 1.17364701, grad/param norm = 1.7374e-01, time/batch = 20.1267s	
7952/29850 (epoch 13.320), train_loss = 1.08333134, grad/param norm = 1.5664e-01, time/batch = 18.1435s	
7953/29850 (epoch 13.322), train_loss = 1.36676304, grad/param norm = 1.9638e-01, time/batch = 15.4719s	
7954/29850 (epoch 13.323), train_loss = 1.25627277, grad/param norm = 2.1403e-01, time/batch = 17.8805s	
7955/29850 (epoch 13.325), train_loss = 1.23628613, grad/param norm = 1.7945e-01, time/batch = 18.0550s	
7956/29850 (epoch 13.327), train_loss = 1.37692831, grad/param norm = 1.9981e-01, time/batch = 17.2814s	
7957/29850 (epoch 13.328), train_loss = 1.35627222, grad/param norm = 1.9043e-01, time/batch = 16.7134s	
7958/29850 (epoch 13.330), train_loss = 1.19768038, grad/param norm = 1.7536e-01, time/batch = 18.2295s	
7959/29850 (epoch 13.332), train_loss = 1.13365377, grad/param norm = 1.6890e-01, time/batch = 18.0555s	
7960/29850 (epoch 13.333), train_loss = 1.34261321, grad/param norm = 1.8176e-01, time/batch = 16.7261s	
7961/29850 (epoch 13.335), train_loss = 1.25922408, grad/param norm = 1.7649e-01, time/batch = 17.9009s	
7962/29850 (epoch 13.337), train_loss = 1.22651800, grad/param norm = 1.7527e-01, time/batch = 17.5449s	
7963/29850 (epoch 13.338), train_loss = 1.21089649, grad/param norm = 1.7389e-01, time/batch = 16.8797s	
7964/29850 (epoch 13.340), train_loss = 1.08327120, grad/param norm = 1.6929e-01, time/batch = 18.2797s	
7965/29850 (epoch 13.342), train_loss = 1.21990864, grad/param norm = 1.8235e-01, time/batch = 16.9815s	
7966/29850 (epoch 13.343), train_loss = 1.24303215, grad/param norm = 1.9386e-01, time/batch = 16.0313s	
7967/29850 (epoch 13.345), train_loss = 1.28723498, grad/param norm = 1.9250e-01, time/batch = 17.0288s	
7968/29850 (epoch 13.347), train_loss = 1.31650208, grad/param norm = 2.3161e-01, time/batch = 18.7269s	
7969/29850 (epoch 13.348), train_loss = 1.15650383, grad/param norm = 1.6364e-01, time/batch = 19.3751s	
7970/29850 (epoch 13.350), train_loss = 1.30107054, grad/param norm = 1.9679e-01, time/batch = 15.7901s	
7971/29850 (epoch 13.352), train_loss = 1.20330435, grad/param norm = 1.7354e-01, time/batch = 18.6282s	
7972/29850 (epoch 13.353), train_loss = 1.27521656, grad/param norm = 1.8552e-01, time/batch = 17.9603s	
7973/29850 (epoch 13.355), train_loss = 1.09887530, grad/param norm = 1.7209e-01, time/batch = 17.2956s	
7974/29850 (epoch 13.357), train_loss = 1.36615069, grad/param norm = 1.8319e-01, time/batch = 16.3710s	
7975/29850 (epoch 13.358), train_loss = 1.09800876, grad/param norm = 1.7364e-01, time/batch = 19.0530s	
7976/29850 (epoch 13.360), train_loss = 1.19250304, grad/param norm = 1.7577e-01, time/batch = 17.9781s	
7977/29850 (epoch 13.362), train_loss = 1.19353854, grad/param norm = 1.7992e-01, time/batch = 17.1974s	
7978/29850 (epoch 13.363), train_loss = 1.21941260, grad/param norm = 1.7927e-01, time/batch = 19.1219s	
7979/29850 (epoch 13.365), train_loss = 1.37002264, grad/param norm = 1.9356e-01, time/batch = 16.9623s	
7980/29850 (epoch 13.367), train_loss = 1.19295158, grad/param norm = 1.7921e-01, time/batch = 16.0108s	
7981/29850 (epoch 13.369), train_loss = 1.09123886, grad/param norm = 1.6787e-01, time/batch = 19.7735s	
7982/29850 (epoch 13.370), train_loss = 1.02042975, grad/param norm = 1.6190e-01, time/batch = 17.1069s	
7983/29850 (epoch 13.372), train_loss = 1.37160934, grad/param norm = 2.0241e-01, time/batch = 18.3763s	
7984/29850 (epoch 13.374), train_loss = 1.18784744, grad/param norm = 1.8374e-01, time/batch = 17.9564s	
7985/29850 (epoch 13.375), train_loss = 1.21194979, grad/param norm = 1.8403e-01, time/batch = 18.0398s	
7986/29850 (epoch 13.377), train_loss = 1.20089050, grad/param norm = 1.8357e-01, time/batch = 19.2210s	
7987/29850 (epoch 13.379), train_loss = 1.29663373, grad/param norm = 1.9582e-01, time/batch = 16.2087s	
7988/29850 (epoch 13.380), train_loss = 1.26732355, grad/param norm = 1.9556e-01, time/batch = 17.5488s	
7989/29850 (epoch 13.382), train_loss = 1.25971127, grad/param norm = 1.8533e-01, time/batch = 17.9708s	
7990/29850 (epoch 13.384), train_loss = 1.25002947, grad/param norm = 1.8820e-01, time/batch = 18.0395s	
7991/29850 (epoch 13.385), train_loss = 1.19790538, grad/param norm = 1.7680e-01, time/batch = 18.3426s	
7992/29850 (epoch 13.387), train_loss = 1.23880663, grad/param norm = 1.9598e-01, time/batch = 17.7910s	
7993/29850 (epoch 13.389), train_loss = 1.36049642, grad/param norm = 1.7404e-01, time/batch = 18.8642s	
7994/29850 (epoch 13.390), train_loss = 1.25681354, grad/param norm = 1.7138e-01, time/batch = 17.3844s	
7995/29850 (epoch 13.392), train_loss = 1.18124695, grad/param norm = 1.8408e-01, time/batch = 18.9550s	
7996/29850 (epoch 13.394), train_loss = 1.30651519, grad/param norm = 1.7952e-01, time/batch = 18.8060s	
7997/29850 (epoch 13.395), train_loss = 1.21516722, grad/param norm = 1.7676e-01, time/batch = 16.4563s	
7998/29850 (epoch 13.397), train_loss = 1.13108232, grad/param norm = 1.7230e-01, time/batch = 16.4563s	
7999/29850 (epoch 13.399), train_loss = 1.11281643, grad/param norm = 1.8063e-01, time/batch = 18.0527s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch13.40_1.6407.t7	
8000/29850 (epoch 13.400), train_loss = 1.50163779, grad/param norm = 2.1715e-01, time/batch = 17.8013s	
8001/29850 (epoch 13.402), train_loss = 1.60544972, grad/param norm = 1.9904e-01, time/batch = 17.5428s	
8002/29850 (epoch 13.404), train_loss = 1.26501677, grad/param norm = 1.9525e-01, time/batch = 17.2883s	
8003/29850 (epoch 13.405), train_loss = 1.21554827, grad/param norm = 2.1477e-01, time/batch = 16.0327s	
8004/29850 (epoch 13.407), train_loss = 1.15935178, grad/param norm = 1.8593e-01, time/batch = 18.8802s	
8005/29850 (epoch 13.409), train_loss = 1.35141106, grad/param norm = 2.0453e-01, time/batch = 19.3496s	
8006/29850 (epoch 13.410), train_loss = 1.37637026, grad/param norm = 1.8104e-01, time/batch = 17.6168s	
8007/29850 (epoch 13.412), train_loss = 1.28656619, grad/param norm = 1.9033e-01, time/batch = 17.3808s	
8008/29850 (epoch 13.414), train_loss = 1.24670510, grad/param norm = 1.9571e-01, time/batch = 18.3851s	
8009/29850 (epoch 13.415), train_loss = 1.25391998, grad/param norm = 1.8098e-01, time/batch = 18.4714s	
8010/29850 (epoch 13.417), train_loss = 1.39445317, grad/param norm = 1.9429e-01, time/batch = 18.0166s	
8011/29850 (epoch 13.419), train_loss = 1.25984012, grad/param norm = 1.8981e-01, time/batch = 18.9620s	
8012/29850 (epoch 13.420), train_loss = 1.22274343, grad/param norm = 1.7180e-01, time/batch = 19.0332s	
8013/29850 (epoch 13.422), train_loss = 1.20051617, grad/param norm = 1.7344e-01, time/batch = 15.6041s	
8014/29850 (epoch 13.424), train_loss = 1.20851789, grad/param norm = 1.8737e-01, time/batch = 17.5310s	
8015/29850 (epoch 13.425), train_loss = 1.39656927, grad/param norm = 1.8576e-01, time/batch = 17.0579s	
8016/29850 (epoch 13.427), train_loss = 1.03985165, grad/param norm = 1.6276e-01, time/batch = 17.5429s	
8017/29850 (epoch 13.429), train_loss = 1.10589941, grad/param norm = 1.7304e-01, time/batch = 17.2812s	
8018/29850 (epoch 13.430), train_loss = 1.03402345, grad/param norm = 1.6276e-01, time/batch = 19.2123s	
8019/29850 (epoch 13.432), train_loss = 1.21155865, grad/param norm = 1.8864e-01, time/batch = 16.9778s	
8020/29850 (epoch 13.434), train_loss = 1.09598787, grad/param norm = 1.6601e-01, time/batch = 15.9519s	
8021/29850 (epoch 13.436), train_loss = 1.26267768, grad/param norm = 1.9923e-01, time/batch = 19.3721s	
8022/29850 (epoch 13.437), train_loss = 1.26620441, grad/param norm = 1.6664e-01, time/batch = 19.7904s	
8023/29850 (epoch 13.439), train_loss = 1.23898609, grad/param norm = 1.7145e-01, time/batch = 16.0437s	
8024/29850 (epoch 13.441), train_loss = 1.20752982, grad/param norm = 1.8069e-01, time/batch = 18.7124s	
8025/29850 (epoch 13.442), train_loss = 1.26775460, grad/param norm = 1.8562e-01, time/batch = 17.5262s	
8026/29850 (epoch 13.444), train_loss = 1.21754446, grad/param norm = 1.7104e-01, time/batch = 17.7935s	
8027/29850 (epoch 13.446), train_loss = 1.24571436, grad/param norm = 1.7404e-01, time/batch = 15.4419s	
8028/29850 (epoch 13.447), train_loss = 1.29488030, grad/param norm = 1.8659e-01, time/batch = 18.1357s	
8029/29850 (epoch 13.449), train_loss = 1.28436450, grad/param norm = 1.9819e-01, time/batch = 19.8752s	
8030/29850 (epoch 13.451), train_loss = 1.08610177, grad/param norm = 1.7173e-01, time/batch = 17.2736s	
8031/29850 (epoch 13.452), train_loss = 0.93773704, grad/param norm = 1.4436e-01, time/batch = 17.0628s	
8032/29850 (epoch 13.454), train_loss = 1.07896667, grad/param norm = 1.6061e-01, time/batch = 17.1187s	
8033/29850 (epoch 13.456), train_loss = 1.29211912, grad/param norm = 1.9680e-01, time/batch = 17.3046s	
8034/29850 (epoch 13.457), train_loss = 1.30841342, grad/param norm = 2.2769e-01, time/batch = 18.1006s	
8035/29850 (epoch 13.459), train_loss = 1.39915815, grad/param norm = 1.9003e-01, time/batch = 18.3936s	
8036/29850 (epoch 13.461), train_loss = 1.38705701, grad/param norm = 1.8194e-01, time/batch = 18.4623s	
8037/29850 (epoch 13.462), train_loss = 1.34016701, grad/param norm = 1.9051e-01, time/batch = 18.0429s	
8038/29850 (epoch 13.464), train_loss = 1.26138176, grad/param norm = 1.7922e-01, time/batch = 18.8755s	
8039/29850 (epoch 13.466), train_loss = 1.12320086, grad/param norm = 1.7788e-01, time/batch = 19.8820s	
8040/29850 (epoch 13.467), train_loss = 1.21465661, grad/param norm = 1.8708e-01, time/batch = 17.6080s	
8041/29850 (epoch 13.469), train_loss = 1.19889052, grad/param norm = 1.7399e-01, time/batch = 18.4388s	
8042/29850 (epoch 13.471), train_loss = 1.21662237, grad/param norm = 1.7528e-01, time/batch = 16.2175s	
8043/29850 (epoch 13.472), train_loss = 1.12343278, grad/param norm = 1.6593e-01, time/batch = 16.1050s	
8044/29850 (epoch 13.474), train_loss = 1.33626375, grad/param norm = 1.8725e-01, time/batch = 18.4642s	
8045/29850 (epoch 13.476), train_loss = 1.24091451, grad/param norm = 1.7195e-01, time/batch = 18.5392s	
8046/29850 (epoch 13.477), train_loss = 1.27108976, grad/param norm = 2.0640e-01, time/batch = 17.7909s	
8047/29850 (epoch 13.479), train_loss = 1.35296976, grad/param norm = 1.8808e-01, time/batch = 16.1413s	
8048/29850 (epoch 13.481), train_loss = 1.27659660, grad/param norm = 1.9713e-01, time/batch = 16.7764s	
8049/29850 (epoch 13.482), train_loss = 1.16370795, grad/param norm = 1.5517e-01, time/batch = 18.2148s	
8050/29850 (epoch 13.484), train_loss = 1.15971554, grad/param norm = 1.7965e-01, time/batch = 16.1183s	
8051/29850 (epoch 13.486), train_loss = 1.22299890, grad/param norm = 1.8131e-01, time/batch = 17.3642s	
8052/29850 (epoch 13.487), train_loss = 1.18499883, grad/param norm = 1.7279e-01, time/batch = 17.9522s	
8053/29850 (epoch 13.489), train_loss = 1.21934621, grad/param norm = 1.8457e-01, time/batch = 16.4488s	
8054/29850 (epoch 13.491), train_loss = 1.08327670, grad/param norm = 1.7074e-01, time/batch = 15.5726s	
8055/29850 (epoch 13.492), train_loss = 1.25016102, grad/param norm = 1.8335e-01, time/batch = 19.6137s	
8056/29850 (epoch 13.494), train_loss = 1.34260175, grad/param norm = 1.6603e-01, time/batch = 17.8015s	
8057/29850 (epoch 13.496), train_loss = 1.39027391, grad/param norm = 1.8732e-01, time/batch = 15.7241s	
8058/29850 (epoch 13.497), train_loss = 1.28745242, grad/param norm = 1.7811e-01, time/batch = 18.7202s	
8059/29850 (epoch 13.499), train_loss = 1.23745471, grad/param norm = 1.6976e-01, time/batch = 17.2041s	
8060/29850 (epoch 13.501), train_loss = 1.18233573, grad/param norm = 1.6998e-01, time/batch = 17.5369s	
8061/29850 (epoch 13.503), train_loss = 1.20817394, grad/param norm = 1.7078e-01, time/batch = 16.5079s	
8062/29850 (epoch 13.504), train_loss = 1.40962387, grad/param norm = 1.7846e-01, time/batch = 19.1151s	
8063/29850 (epoch 13.506), train_loss = 1.41188038, grad/param norm = 1.9183e-01, time/batch = 18.8899s	
8064/29850 (epoch 13.508), train_loss = 1.19486980, grad/param norm = 1.7233e-01, time/batch = 31.1754s	
8065/29850 (epoch 13.509), train_loss = 1.02312288, grad/param norm = 1.6403e-01, time/batch = 17.5457s	
8066/29850 (epoch 13.511), train_loss = 1.21823576, grad/param norm = 1.7501e-01, time/batch = 16.9634s	
8067/29850 (epoch 13.513), train_loss = 1.25438025, grad/param norm = 1.8745e-01, time/batch = 17.1864s	
8068/29850 (epoch 13.514), train_loss = 1.09038519, grad/param norm = 1.6919e-01, time/batch = 17.8579s	
8069/29850 (epoch 13.516), train_loss = 1.10774009, grad/param norm = 1.6357e-01, time/batch = 19.3680s	
8070/29850 (epoch 13.518), train_loss = 1.06571470, grad/param norm = 1.6207e-01, time/batch = 19.3505s	
8071/29850 (epoch 13.519), train_loss = 1.06610598, grad/param norm = 1.6765e-01, time/batch = 19.2134s	
8072/29850 (epoch 13.521), train_loss = 1.03723268, grad/param norm = 1.5480e-01, time/batch = 17.0499s	
8073/29850 (epoch 13.523), train_loss = 1.05170169, grad/param norm = 1.4733e-01, time/batch = 16.5522s	
8074/29850 (epoch 13.524), train_loss = 1.18293507, grad/param norm = 1.9263e-01, time/batch = 17.8014s	
8075/29850 (epoch 13.526), train_loss = 1.26661537, grad/param norm = 1.8310e-01, time/batch = 17.8875s	
8076/29850 (epoch 13.528), train_loss = 1.37095265, grad/param norm = 1.9314e-01, time/batch = 17.3696s	
8077/29850 (epoch 13.529), train_loss = 1.28704550, grad/param norm = 1.9406e-01, time/batch = 17.2987s	
8078/29850 (epoch 13.531), train_loss = 1.22954945, grad/param norm = 2.0871e-01, time/batch = 18.1374s	
8079/29850 (epoch 13.533), train_loss = 1.18268223, grad/param norm = 1.8480e-01, time/batch = 18.4665s	
8080/29850 (epoch 13.534), train_loss = 1.18368725, grad/param norm = 1.7312e-01, time/batch = 15.2524s	
8081/29850 (epoch 13.536), train_loss = 1.21719891, grad/param norm = 1.9035e-01, time/batch = 17.8152s	
8082/29850 (epoch 13.538), train_loss = 1.32007348, grad/param norm = 1.8605e-01, time/batch = 17.0763s	
8083/29850 (epoch 13.539), train_loss = 1.38549511, grad/param norm = 1.7887e-01, time/batch = 16.4673s	
8084/29850 (epoch 13.541), train_loss = 1.03327697, grad/param norm = 1.6171e-01, time/batch = 17.6928s	
8085/29850 (epoch 13.543), train_loss = 1.21792326, grad/param norm = 1.7026e-01, time/batch = 15.9520s	
8086/29850 (epoch 13.544), train_loss = 1.22826982, grad/param norm = 1.7601e-01, time/batch = 18.2060s	
8087/29850 (epoch 13.546), train_loss = 1.31167915, grad/param norm = 1.7830e-01, time/batch = 19.2859s	
8088/29850 (epoch 13.548), train_loss = 1.08329072, grad/param norm = 1.7179e-01, time/batch = 17.1331s	
8089/29850 (epoch 13.549), train_loss = 1.15045944, grad/param norm = 1.6995e-01, time/batch = 19.1392s	
8090/29850 (epoch 13.551), train_loss = 1.12172585, grad/param norm = 1.7616e-01, time/batch = 16.5259s	
8091/29850 (epoch 13.553), train_loss = 1.22018676, grad/param norm = 1.7258e-01, time/batch = 19.3688s	
8092/29850 (epoch 13.554), train_loss = 1.02416437, grad/param norm = 1.5450e-01, time/batch = 19.2165s	
8093/29850 (epoch 13.556), train_loss = 1.18017853, grad/param norm = 1.8245e-01, time/batch = 17.2960s	
8094/29850 (epoch 13.558), train_loss = 1.13402617, grad/param norm = 1.8740e-01, time/batch = 17.3154s	
8095/29850 (epoch 13.559), train_loss = 1.21512443, grad/param norm = 1.7473e-01, time/batch = 16.0281s	
8096/29850 (epoch 13.561), train_loss = 1.28303695, grad/param norm = 1.8722e-01, time/batch = 18.8649s	
8097/29850 (epoch 13.563), train_loss = 1.18790891, grad/param norm = 1.7363e-01, time/batch = 15.6203s	
8098/29850 (epoch 13.564), train_loss = 1.18453014, grad/param norm = 1.8484e-01, time/batch = 16.3066s	
8099/29850 (epoch 13.566), train_loss = 1.18286740, grad/param norm = 1.8266e-01, time/batch = 17.2122s	
8100/29850 (epoch 13.568), train_loss = 1.32977777, grad/param norm = 1.8677e-01, time/batch = 17.5531s	
8101/29850 (epoch 13.570), train_loss = 1.21872644, grad/param norm = 1.7014e-01, time/batch = 16.0261s	
8102/29850 (epoch 13.571), train_loss = 1.23862583, grad/param norm = 1.9161e-01, time/batch = 18.4473s	
8103/29850 (epoch 13.573), train_loss = 1.35563558, grad/param norm = 2.1359e-01, time/batch = 17.8084s	
8104/29850 (epoch 13.575), train_loss = 1.32821384, grad/param norm = 1.7599e-01, time/batch = 17.3611s	
8105/29850 (epoch 13.576), train_loss = 1.34934732, grad/param norm = 1.9131e-01, time/batch = 19.2260s	
8106/29850 (epoch 13.578), train_loss = 1.24124828, grad/param norm = 1.8452e-01, time/batch = 16.2249s	
8107/29850 (epoch 13.580), train_loss = 1.34798748, grad/param norm = 1.8348e-01, time/batch = 15.9430s	
8108/29850 (epoch 13.581), train_loss = 1.12859241, grad/param norm = 1.8204e-01, time/batch = 17.6291s	
8109/29850 (epoch 13.583), train_loss = 1.19757735, grad/param norm = 1.7448e-01, time/batch = 16.3031s	
8110/29850 (epoch 13.585), train_loss = 1.26913145, grad/param norm = 1.7064e-01, time/batch = 18.5453s	
8111/29850 (epoch 13.586), train_loss = 1.27438278, grad/param norm = 1.9117e-01, time/batch = 17.1331s	
8112/29850 (epoch 13.588), train_loss = 1.17101254, grad/param norm = 1.7594e-01, time/batch = 19.4630s	
8113/29850 (epoch 13.590), train_loss = 1.21065818, grad/param norm = 1.8564e-01, time/batch = 19.2936s	
8114/29850 (epoch 13.591), train_loss = 1.15102529, grad/param norm = 1.6756e-01, time/batch = 17.4486s	
8115/29850 (epoch 13.593), train_loss = 1.11881159, grad/param norm = 1.5758e-01, time/batch = 16.8930s	
8116/29850 (epoch 13.595), train_loss = 1.09003084, grad/param norm = 1.5622e-01, time/batch = 17.2375s	
8117/29850 (epoch 13.596), train_loss = 1.05794203, grad/param norm = 1.6604e-01, time/batch = 16.3012s	
8118/29850 (epoch 13.598), train_loss = 1.10013481, grad/param norm = 1.5786e-01, time/batch = 17.8573s	
8119/29850 (epoch 13.600), train_loss = 1.29860934, grad/param norm = 1.9446e-01, time/batch = 18.4658s	
8120/29850 (epoch 13.601), train_loss = 1.07615916, grad/param norm = 1.6466e-01, time/batch = 18.3791s	
8121/29850 (epoch 13.603), train_loss = 1.18811777, grad/param norm = 1.8207e-01, time/batch = 18.0496s	
8122/29850 (epoch 13.605), train_loss = 1.18550479, grad/param norm = 1.8591e-01, time/batch = 17.3749s	
8123/29850 (epoch 13.606), train_loss = 0.97013841, grad/param norm = 1.6462e-01, time/batch = 18.3100s	
8124/29850 (epoch 13.608), train_loss = 1.20316666, grad/param norm = 1.7193e-01, time/batch = 14.9459s	
8125/29850 (epoch 13.610), train_loss = 1.21239343, grad/param norm = 1.7056e-01, time/batch = 17.3660s	
8126/29850 (epoch 13.611), train_loss = 1.05030461, grad/param norm = 1.5435e-01, time/batch = 17.0341s	
8127/29850 (epoch 13.613), train_loss = 0.95883204, grad/param norm = 1.4799e-01, time/batch = 17.7945s	
8128/29850 (epoch 13.615), train_loss = 1.05890596, grad/param norm = 1.6078e-01, time/batch = 17.2977s	
8129/29850 (epoch 13.616), train_loss = 1.10019823, grad/param norm = 1.6916e-01, time/batch = 19.7145s	
8130/29850 (epoch 13.618), train_loss = 1.16217074, grad/param norm = 1.7026e-01, time/batch = 17.8214s	
8131/29850 (epoch 13.620), train_loss = 1.21127987, grad/param norm = 1.8402e-01, time/batch = 17.5244s	
8132/29850 (epoch 13.621), train_loss = 1.29870533, grad/param norm = 1.9212e-01, time/batch = 17.3039s	
8133/29850 (epoch 13.623), train_loss = 1.29823370, grad/param norm = 1.8664e-01, time/batch = 17.4076s	
8134/29850 (epoch 13.625), train_loss = 1.23254559, grad/param norm = 1.9096e-01, time/batch = 17.3603s	
8135/29850 (epoch 13.626), train_loss = 1.23952258, grad/param norm = 1.8843e-01, time/batch = 17.8686s	
8136/29850 (epoch 13.628), train_loss = 1.07638263, grad/param norm = 1.7137e-01, time/batch = 16.9561s	
8137/29850 (epoch 13.630), train_loss = 1.19872762, grad/param norm = 1.8659e-01, time/batch = 17.1132s	
8138/29850 (epoch 13.631), train_loss = 1.12685564, grad/param norm = 1.7987e-01, time/batch = 18.4320s	
8139/29850 (epoch 13.633), train_loss = 1.27198567, grad/param norm = 1.9142e-01, time/batch = 17.5404s	
8140/29850 (epoch 13.635), train_loss = 1.18413124, grad/param norm = 1.6794e-01, time/batch = 19.6289s	
8141/29850 (epoch 13.637), train_loss = 1.16623658, grad/param norm = 1.8549e-01, time/batch = 18.5297s	
8142/29850 (epoch 13.638), train_loss = 1.17619212, grad/param norm = 1.8283e-01, time/batch = 18.1146s	
8143/29850 (epoch 13.640), train_loss = 1.33598053, grad/param norm = 1.9832e-01, time/batch = 18.8867s	
8144/29850 (epoch 13.642), train_loss = 1.12632991, grad/param norm = 1.5599e-01, time/batch = 15.7045s	
8145/29850 (epoch 13.643), train_loss = 1.09562872, grad/param norm = 1.6058e-01, time/batch = 18.7012s	
8146/29850 (epoch 13.645), train_loss = 1.21766986, grad/param norm = 1.7716e-01, time/batch = 17.8071s	
8147/29850 (epoch 13.647), train_loss = 1.33198326, grad/param norm = 1.7749e-01, time/batch = 18.0953s	
8148/29850 (epoch 13.648), train_loss = 1.08180716, grad/param norm = 1.6622e-01, time/batch = 15.1162s	
8149/29850 (epoch 13.650), train_loss = 1.17669112, grad/param norm = 1.8433e-01, time/batch = 16.0306s	
8150/29850 (epoch 13.652), train_loss = 1.21391281, grad/param norm = 1.8658e-01, time/batch = 16.3895s	
8151/29850 (epoch 13.653), train_loss = 1.31182588, grad/param norm = 1.8401e-01, time/batch = 16.6198s	
8152/29850 (epoch 13.655), train_loss = 1.18317872, grad/param norm = 1.6692e-01, time/batch = 17.3579s	
8153/29850 (epoch 13.657), train_loss = 1.15910743, grad/param norm = 1.6993e-01, time/batch = 17.1585s	
8154/29850 (epoch 13.658), train_loss = 1.30448606, grad/param norm = 1.8171e-01, time/batch = 18.2965s	
8155/29850 (epoch 13.660), train_loss = 1.16943072, grad/param norm = 1.8325e-01, time/batch = 17.8624s	
8156/29850 (epoch 13.662), train_loss = 1.23749177, grad/param norm = 1.9348e-01, time/batch = 15.9504s	
8157/29850 (epoch 13.663), train_loss = 1.34205268, grad/param norm = 1.9533e-01, time/batch = 18.8693s	
8158/29850 (epoch 13.665), train_loss = 1.29826546, grad/param norm = 1.8529e-01, time/batch = 16.3828s	
8159/29850 (epoch 13.667), train_loss = 1.28639155, grad/param norm = 2.1664e-01, time/batch = 19.0352s	
8160/29850 (epoch 13.668), train_loss = 1.21045857, grad/param norm = 1.8673e-01, time/batch = 15.6116s	
8161/29850 (epoch 13.670), train_loss = 1.38430887, grad/param norm = 2.0841e-01, time/batch = 17.6148s	
8162/29850 (epoch 13.672), train_loss = 1.31144000, grad/param norm = 2.0266e-01, time/batch = 16.9846s	
8163/29850 (epoch 13.673), train_loss = 1.31541068, grad/param norm = 1.9383e-01, time/batch = 17.2922s	
8164/29850 (epoch 13.675), train_loss = 1.13813328, grad/param norm = 1.7059e-01, time/batch = 19.8556s	
8165/29850 (epoch 13.677), train_loss = 1.18983123, grad/param norm = 1.8207e-01, time/batch = 15.7967s	
8166/29850 (epoch 13.678), train_loss = 1.16884961, grad/param norm = 1.8136e-01, time/batch = 15.1049s	
8167/29850 (epoch 13.680), train_loss = 1.23467509, grad/param norm = 1.9117e-01, time/batch = 14.4227s	
8168/29850 (epoch 13.682), train_loss = 1.20738688, grad/param norm = 1.8861e-01, time/batch = 14.0202s	
8169/29850 (epoch 13.683), train_loss = 1.34789097, grad/param norm = 2.0198e-01, time/batch = 14.7014s	
8170/29850 (epoch 13.685), train_loss = 1.35764539, grad/param norm = 1.8919e-01, time/batch = 14.3243s	
8171/29850 (epoch 13.687), train_loss = 1.28327623, grad/param norm = 1.8762e-01, time/batch = 14.2486s	
8172/29850 (epoch 13.688), train_loss = 1.10294643, grad/param norm = 1.5364e-01, time/batch = 14.2487s	
8173/29850 (epoch 13.690), train_loss = 1.12551878, grad/param norm = 1.9215e-01, time/batch = 14.4131s	
8174/29850 (epoch 13.692), train_loss = 1.33241457, grad/param norm = 1.9770e-01, time/batch = 14.2478s	
8175/29850 (epoch 13.693), train_loss = 1.18640932, grad/param norm = 1.6015e-01, time/batch = 14.2544s	
8176/29850 (epoch 13.695), train_loss = 1.04171098, grad/param norm = 1.5079e-01, time/batch = 14.3177s	
8177/29850 (epoch 13.697), train_loss = 1.25144543, grad/param norm = 1.7327e-01, time/batch = 15.0915s	
8178/29850 (epoch 13.698), train_loss = 1.29250433, grad/param norm = 1.8417e-01, time/batch = 14.2523s	
8179/29850 (epoch 13.700), train_loss = 1.24652444, grad/param norm = 1.9384e-01, time/batch = 14.5902s	
8180/29850 (epoch 13.702), train_loss = 1.17869613, grad/param norm = 1.7895e-01, time/batch = 14.5656s	
8181/29850 (epoch 13.704), train_loss = 1.11313854, grad/param norm = 1.7554e-01, time/batch = 14.8137s	
8182/29850 (epoch 13.705), train_loss = 1.22201893, grad/param norm = 1.7340e-01, time/batch = 14.7312s	
8183/29850 (epoch 13.707), train_loss = 1.14841109, grad/param norm = 1.9178e-01, time/batch = 14.4017s	
8184/29850 (epoch 13.709), train_loss = 1.29343057, grad/param norm = 1.9233e-01, time/batch = 14.7967s	
8185/29850 (epoch 13.710), train_loss = 1.17948951, grad/param norm = 1.8337e-01, time/batch = 14.7303s	
8186/29850 (epoch 13.712), train_loss = 1.18960361, grad/param norm = 1.7823e-01, time/batch = 14.7285s	
8187/29850 (epoch 13.714), train_loss = 1.28072400, grad/param norm = 1.9102e-01, time/batch = 15.3992s	
8188/29850 (epoch 13.715), train_loss = 1.27285727, grad/param norm = 1.8655e-01, time/batch = 14.3840s	
8189/29850 (epoch 13.717), train_loss = 1.02117404, grad/param norm = 1.7171e-01, time/batch = 15.1030s	
8190/29850 (epoch 13.719), train_loss = 1.15346966, grad/param norm = 1.8026e-01, time/batch = 15.1137s	
8191/29850 (epoch 13.720), train_loss = 1.21387113, grad/param norm = 1.6137e-01, time/batch = 14.4195s	
8192/29850 (epoch 13.722), train_loss = 1.13163690, grad/param norm = 1.6600e-01, time/batch = 15.1878s	
8193/29850 (epoch 13.724), train_loss = 1.28995400, grad/param norm = 1.8388e-01, time/batch = 14.6443s	
8194/29850 (epoch 13.725), train_loss = 1.08653170, grad/param norm = 1.6939e-01, time/batch = 14.5831s	
8195/29850 (epoch 13.727), train_loss = 1.15118497, grad/param norm = 1.9310e-01, time/batch = 14.3366s	
8196/29850 (epoch 13.729), train_loss = 1.04683558, grad/param norm = 1.6615e-01, time/batch = 14.4952s	
8197/29850 (epoch 13.730), train_loss = 1.06196581, grad/param norm = 1.6957e-01, time/batch = 14.2412s	
8198/29850 (epoch 13.732), train_loss = 1.28708011, grad/param norm = 1.7254e-01, time/batch = 14.5654s	
8199/29850 (epoch 13.734), train_loss = 1.41737428, grad/param norm = 2.1970e-01, time/batch = 14.3451s	
8200/29850 (epoch 13.735), train_loss = 1.18671733, grad/param norm = 1.9209e-01, time/batch = 14.3341s	
8201/29850 (epoch 13.737), train_loss = 1.13109643, grad/param norm = 1.7293e-01, time/batch = 14.3335s	
8202/29850 (epoch 13.739), train_loss = 1.02299492, grad/param norm = 1.6954e-01, time/batch = 14.8879s	
8203/29850 (epoch 13.740), train_loss = 1.04626327, grad/param norm = 1.6715e-01, time/batch = 14.3297s	
8204/29850 (epoch 13.742), train_loss = 1.04779727, grad/param norm = 1.6310e-01, time/batch = 15.0490s	
8205/29850 (epoch 13.744), train_loss = 1.16083747, grad/param norm = 2.0193e-01, time/batch = 14.6578s	
8206/29850 (epoch 13.745), train_loss = 1.14871754, grad/param norm = 1.8803e-01, time/batch = 14.6365s	
8207/29850 (epoch 13.747), train_loss = 1.16959003, grad/param norm = 1.8019e-01, time/batch = 13.8516s	
8208/29850 (epoch 13.749), train_loss = 1.08722305, grad/param norm = 1.7985e-01, time/batch = 15.1151s	
8209/29850 (epoch 13.750), train_loss = 1.08789336, grad/param norm = 1.9054e-01, time/batch = 15.0291s	
8210/29850 (epoch 13.752), train_loss = 1.01876752, grad/param norm = 1.6494e-01, time/batch = 15.0897s	
8211/29850 (epoch 13.754), train_loss = 1.06477786, grad/param norm = 1.7613e-01, time/batch = 14.6690s	
8212/29850 (epoch 13.755), train_loss = 1.13510062, grad/param norm = 1.8470e-01, time/batch = 14.7323s	
8213/29850 (epoch 13.757), train_loss = 1.14437780, grad/param norm = 1.7417e-01, time/batch = 14.9560s	
8214/29850 (epoch 13.759), train_loss = 1.16537214, grad/param norm = 1.6911e-01, time/batch = 15.2602s	
8215/29850 (epoch 13.760), train_loss = 1.07206756, grad/param norm = 1.6634e-01, time/batch = 14.5756s	
8216/29850 (epoch 13.762), train_loss = 1.07755765, grad/param norm = 1.7113e-01, time/batch = 15.2245s	
8217/29850 (epoch 13.764), train_loss = 1.05099403, grad/param norm = 1.7330e-01, time/batch = 14.8328s	
8218/29850 (epoch 13.765), train_loss = 1.13762356, grad/param norm = 1.7825e-01, time/batch = 14.8686s	
8219/29850 (epoch 13.767), train_loss = 1.16950195, grad/param norm = 1.7719e-01, time/batch = 14.5677s	
8220/29850 (epoch 13.769), train_loss = 1.13546239, grad/param norm = 1.7296e-01, time/batch = 14.5820s	
8221/29850 (epoch 13.771), train_loss = 1.20403451, grad/param norm = 1.8212e-01, time/batch = 14.7226s	
8222/29850 (epoch 13.772), train_loss = 1.24492138, grad/param norm = 1.8441e-01, time/batch = 14.9604s	
8223/29850 (epoch 13.774), train_loss = 1.09029420, grad/param norm = 1.6627e-01, time/batch = 14.9929s	
8224/29850 (epoch 13.776), train_loss = 1.14263301, grad/param norm = 1.8277e-01, time/batch = 14.7511s	
8225/29850 (epoch 13.777), train_loss = 1.23829969, grad/param norm = 1.8600e-01, time/batch = 15.0674s	
8226/29850 (epoch 13.779), train_loss = 1.04146212, grad/param norm = 1.6159e-01, time/batch = 15.4415s	
8227/29850 (epoch 13.781), train_loss = 1.14112898, grad/param norm = 1.6759e-01, time/batch = 14.3302s	
8228/29850 (epoch 13.782), train_loss = 1.19700486, grad/param norm = 1.6764e-01, time/batch = 14.0875s	
8229/29850 (epoch 13.784), train_loss = 1.06875459, grad/param norm = 1.7092e-01, time/batch = 14.0888s	
8230/29850 (epoch 13.786), train_loss = 1.13806340, grad/param norm = 1.6643e-01, time/batch = 15.1736s	
8231/29850 (epoch 13.787), train_loss = 1.06771690, grad/param norm = 1.8151e-01, time/batch = 15.6474s	
8232/29850 (epoch 13.789), train_loss = 1.00491877, grad/param norm = 1.5482e-01, time/batch = 14.4939s	
8233/29850 (epoch 13.791), train_loss = 1.13568366, grad/param norm = 1.9022e-01, time/batch = 14.4893s	
8234/29850 (epoch 13.792), train_loss = 1.26125724, grad/param norm = 1.8950e-01, time/batch = 14.7325s	
8235/29850 (epoch 13.794), train_loss = 1.17451203, grad/param norm = 1.6923e-01, time/batch = 14.5103s	
8236/29850 (epoch 13.796), train_loss = 1.10931924, grad/param norm = 1.7779e-01, time/batch = 14.2436s	
8237/29850 (epoch 13.797), train_loss = 1.01995557, grad/param norm = 1.7153e-01, time/batch = 14.0875s	
8238/29850 (epoch 13.799), train_loss = 1.04406676, grad/param norm = 1.6618e-01, time/batch = 14.4675s	
8239/29850 (epoch 13.801), train_loss = 1.20942615, grad/param norm = 1.7761e-01, time/batch = 14.5019s	
8240/29850 (epoch 13.802), train_loss = 1.01246381, grad/param norm = 1.6993e-01, time/batch = 14.8008s	
8241/29850 (epoch 13.804), train_loss = 1.04561819, grad/param norm = 1.6512e-01, time/batch = 15.4344s	
8242/29850 (epoch 13.806), train_loss = 1.05801602, grad/param norm = 1.6582e-01, time/batch = 14.8105s	
8243/29850 (epoch 13.807), train_loss = 0.98337148, grad/param norm = 1.5191e-01, time/batch = 14.5780s	
8244/29850 (epoch 13.809), train_loss = 1.11640961, grad/param norm = 1.8818e-01, time/batch = 14.4143s	
8245/29850 (epoch 13.811), train_loss = 1.21710037, grad/param norm = 2.1582e-01, time/batch = 14.5843s	
8246/29850 (epoch 13.812), train_loss = 1.19609054, grad/param norm = 1.9309e-01, time/batch = 15.1041s	
8247/29850 (epoch 13.814), train_loss = 1.26891446, grad/param norm = 1.7760e-01, time/batch = 15.2405s	
8248/29850 (epoch 13.816), train_loss = 1.24309140, grad/param norm = 1.7592e-01, time/batch = 14.9152s	
8249/29850 (epoch 13.817), train_loss = 1.16903368, grad/param norm = 1.8285e-01, time/batch = 14.2526s	
8250/29850 (epoch 13.819), train_loss = 1.06892007, grad/param norm = 1.8312e-01, time/batch = 14.2278s	
8251/29850 (epoch 13.821), train_loss = 1.32275582, grad/param norm = 1.9474e-01, time/batch = 14.7087s	
8252/29850 (epoch 13.822), train_loss = 1.25618763, grad/param norm = 1.8261e-01, time/batch = 14.4164s	
8253/29850 (epoch 13.824), train_loss = 1.13923319, grad/param norm = 1.7080e-01, time/batch = 15.1162s	
8254/29850 (epoch 13.826), train_loss = 1.10436234, grad/param norm = 1.5622e-01, time/batch = 15.1077s	
8255/29850 (epoch 13.827), train_loss = 1.07332197, grad/param norm = 1.7801e-01, time/batch = 15.2796s	
8256/29850 (epoch 13.829), train_loss = 1.18783115, grad/param norm = 1.8807e-01, time/batch = 15.1903s	
8257/29850 (epoch 13.831), train_loss = 1.24694636, grad/param norm = 1.9438e-01, time/batch = 14.6572s	
8258/29850 (epoch 13.832), train_loss = 1.15445872, grad/param norm = 1.7169e-01, time/batch = 14.4866s	
8259/29850 (epoch 13.834), train_loss = 1.03321036, grad/param norm = 1.7802e-01, time/batch = 14.5698s	
8260/29850 (epoch 13.836), train_loss = 1.02529334, grad/param norm = 1.6321e-01, time/batch = 14.4152s	
8261/29850 (epoch 13.838), train_loss = 1.14564637, grad/param norm = 1.8547e-01, time/batch = 14.5842s	
8262/29850 (epoch 13.839), train_loss = 1.09029088, grad/param norm = 1.6843e-01, time/batch = 14.6299s	
8263/29850 (epoch 13.841), train_loss = 1.10157331, grad/param norm = 1.7740e-01, time/batch = 14.8128s	
8264/29850 (epoch 13.843), train_loss = 1.06984829, grad/param norm = 1.7146e-01, time/batch = 15.4116s	
8265/29850 (epoch 13.844), train_loss = 1.11271074, grad/param norm = 1.7957e-01, time/batch = 16.8099s	
8266/29850 (epoch 13.846), train_loss = 1.17857519, grad/param norm = 1.7920e-01, time/batch = 15.4878s	
8267/29850 (epoch 13.848), train_loss = 1.22289516, grad/param norm = 1.8228e-01, time/batch = 0.7060s	
8268/29850 (epoch 13.849), train_loss = 1.09066645, grad/param norm = 1.9337e-01, time/batch = 0.7030s	
8269/29850 (epoch 13.851), train_loss = 1.26233443, grad/param norm = 1.9795e-01, time/batch = 0.6881s	
8270/29850 (epoch 13.853), train_loss = 1.12531446, grad/param norm = 2.0205e-01, time/batch = 0.6768s	
8271/29850 (epoch 13.854), train_loss = 1.28229322, grad/param norm = 1.9517e-01, time/batch = 0.6954s	
8272/29850 (epoch 13.856), train_loss = 1.23934884, grad/param norm = 2.0403e-01, time/batch = 0.6883s	
8273/29850 (epoch 13.858), train_loss = 1.15908867, grad/param norm = 2.0059e-01, time/batch = 0.6812s	
8274/29850 (epoch 13.859), train_loss = 1.08754940, grad/param norm = 1.8277e-01, time/batch = 0.9305s	
8275/29850 (epoch 13.861), train_loss = 1.23366663, grad/param norm = 1.8809e-01, time/batch = 0.9761s	
8276/29850 (epoch 13.863), train_loss = 1.32253596, grad/param norm = 1.8045e-01, time/batch = 0.9732s	
8277/29850 (epoch 13.864), train_loss = 1.26181510, grad/param norm = 1.8829e-01, time/batch = 1.0226s	
8278/29850 (epoch 13.866), train_loss = 1.21162045, grad/param norm = 2.0718e-01, time/batch = 0.9753s	
8279/29850 (epoch 13.868), train_loss = 1.32433434, grad/param norm = 1.9281e-01, time/batch = 1.5953s	
8280/29850 (epoch 13.869), train_loss = 1.17503661, grad/param norm = 2.0558e-01, time/batch = 1.8080s	
8281/29850 (epoch 13.871), train_loss = 1.20522851, grad/param norm = 1.7888e-01, time/batch = 2.5453s	
8282/29850 (epoch 13.873), train_loss = 1.25685683, grad/param norm = 1.9529e-01, time/batch = 15.7780s	
8283/29850 (epoch 13.874), train_loss = 1.21294527, grad/param norm = 1.8250e-01, time/batch = 16.4672s	
8284/29850 (epoch 13.876), train_loss = 1.14977418, grad/param norm = 2.1346e-01, time/batch = 15.3672s	
8285/29850 (epoch 13.878), train_loss = 1.17429143, grad/param norm = 1.6839e-01, time/batch = 19.2748s	
8286/29850 (epoch 13.879), train_loss = 1.19694857, grad/param norm = 1.8174e-01, time/batch = 18.5503s	
8287/29850 (epoch 13.881), train_loss = 1.26751784, grad/param norm = 1.8902e-01, time/batch = 16.6303s	
8288/29850 (epoch 13.883), train_loss = 1.27707492, grad/param norm = 2.0692e-01, time/batch = 18.4530s	
8289/29850 (epoch 13.884), train_loss = 1.06443673, grad/param norm = 1.6856e-01, time/batch = 18.3911s	
8290/29850 (epoch 13.886), train_loss = 1.31635515, grad/param norm = 1.8088e-01, time/batch = 17.4535s	
8291/29850 (epoch 13.888), train_loss = 1.16514057, grad/param norm = 1.7371e-01, time/batch = 18.7776s	
8292/29850 (epoch 13.889), train_loss = 1.11953912, grad/param norm = 1.7878e-01, time/batch = 18.7972s	
8293/29850 (epoch 13.891), train_loss = 1.12763133, grad/param norm = 1.7275e-01, time/batch = 15.5710s	
8294/29850 (epoch 13.893), train_loss = 1.06497627, grad/param norm = 1.6800e-01, time/batch = 16.3491s	
8295/29850 (epoch 13.894), train_loss = 1.12624004, grad/param norm = 1.6896e-01, time/batch = 17.4568s	
8296/29850 (epoch 13.896), train_loss = 1.15038731, grad/param norm = 1.7982e-01, time/batch = 17.3977s	
8297/29850 (epoch 13.898), train_loss = 1.29420163, grad/param norm = 1.9950e-01, time/batch = 16.8429s	
8298/29850 (epoch 13.899), train_loss = 1.01611179, grad/param norm = 1.6673e-01, time/batch = 29.9758s	
8299/29850 (epoch 13.901), train_loss = 1.46172753, grad/param norm = 2.0571e-01, time/batch = 17.3013s	
8300/29850 (epoch 13.903), train_loss = 1.21112320, grad/param norm = 2.7979e-01, time/batch = 16.7957s	
8301/29850 (epoch 13.905), train_loss = 1.39053947, grad/param norm = 2.0847e-01, time/batch = 15.4186s	
8302/29850 (epoch 13.906), train_loss = 1.14841963, grad/param norm = 2.0242e-01, time/batch = 15.8003s	
8303/29850 (epoch 13.908), train_loss = 1.25934753, grad/param norm = 2.0066e-01, time/batch = 14.8898s	
8304/29850 (epoch 13.910), train_loss = 1.24814922, grad/param norm = 1.9976e-01, time/batch = 16.2974s	
8305/29850 (epoch 13.911), train_loss = 1.37399515, grad/param norm = 1.8832e-01, time/batch = 17.3091s	
8306/29850 (epoch 13.913), train_loss = 1.27726284, grad/param norm = 1.8175e-01, time/batch = 15.8443s	
8307/29850 (epoch 13.915), train_loss = 1.30489422, grad/param norm = 2.0111e-01, time/batch = 17.1032s	
8308/29850 (epoch 13.916), train_loss = 1.26473360, grad/param norm = 1.9598e-01, time/batch = 16.6584s	
8309/29850 (epoch 13.918), train_loss = 1.13095670, grad/param norm = 1.6094e-01, time/batch = 16.4400s	
8310/29850 (epoch 13.920), train_loss = 1.26297472, grad/param norm = 1.7076e-01, time/batch = 15.5020s	
8311/29850 (epoch 13.921), train_loss = 1.23138444, grad/param norm = 1.9543e-01, time/batch = 15.6053s	
8312/29850 (epoch 13.923), train_loss = 1.26606535, grad/param norm = 1.8349e-01, time/batch = 15.8802s	
8313/29850 (epoch 13.925), train_loss = 1.32004197, grad/param norm = 1.9052e-01, time/batch = 16.2216s	
8314/29850 (epoch 13.926), train_loss = 1.35931660, grad/param norm = 2.0792e-01, time/batch = 17.8710s	
8315/29850 (epoch 13.928), train_loss = 1.20208523, grad/param norm = 1.8175e-01, time/batch = 16.4476s	
8316/29850 (epoch 13.930), train_loss = 1.27912952, grad/param norm = 2.0176e-01, time/batch = 16.3042s	
8317/29850 (epoch 13.931), train_loss = 1.22346449, grad/param norm = 1.8624e-01, time/batch = 17.5474s	
8318/29850 (epoch 13.933), train_loss = 1.37232718, grad/param norm = 1.9139e-01, time/batch = 15.7238s	
8319/29850 (epoch 13.935), train_loss = 1.31916900, grad/param norm = 1.9417e-01, time/batch = 14.9604s	
8320/29850 (epoch 13.936), train_loss = 1.32276663, grad/param norm = 1.9462e-01, time/batch = 15.3636s	
8321/29850 (epoch 13.938), train_loss = 1.06962446, grad/param norm = 1.6777e-01, time/batch = 17.1257s	
8322/29850 (epoch 13.940), train_loss = 1.07993916, grad/param norm = 1.8097e-01, time/batch = 16.4570s	
8323/29850 (epoch 13.941), train_loss = 1.13043430, grad/param norm = 1.7827e-01, time/batch = 17.9715s	
8324/29850 (epoch 13.943), train_loss = 1.10888614, grad/param norm = 1.7443e-01, time/batch = 18.4424s	
8325/29850 (epoch 13.945), train_loss = 1.18205695, grad/param norm = 1.8861e-01, time/batch = 17.2777s	
8326/29850 (epoch 13.946), train_loss = 1.09844259, grad/param norm = 1.8709e-01, time/batch = 17.8676s	
8327/29850 (epoch 13.948), train_loss = 1.17978321, grad/param norm = 1.6777e-01, time/batch = 17.9357s	
8328/29850 (epoch 13.950), train_loss = 1.10660850, grad/param norm = 1.5518e-01, time/batch = 16.2768s	
8329/29850 (epoch 13.951), train_loss = 1.04924764, grad/param norm = 1.5659e-01, time/batch = 16.4693s	
8330/29850 (epoch 13.953), train_loss = 1.17643132, grad/param norm = 2.0197e-01, time/batch = 18.2120s	
8331/29850 (epoch 13.955), train_loss = 1.03096691, grad/param norm = 1.6138e-01, time/batch = 16.1450s	
8332/29850 (epoch 13.956), train_loss = 1.04339432, grad/param norm = 1.6469e-01, time/batch = 15.4922s	
8333/29850 (epoch 13.958), train_loss = 0.92006542, grad/param norm = 1.6077e-01, time/batch = 15.0396s	
8334/29850 (epoch 13.960), train_loss = 1.23911046, grad/param norm = 1.7953e-01, time/batch = 15.0520s	
8335/29850 (epoch 13.961), train_loss = 1.10433238, grad/param norm = 1.5956e-01, time/batch = 15.3500s	
8336/29850 (epoch 13.963), train_loss = 1.05844057, grad/param norm = 1.6546e-01, time/batch = 14.4901s	
8337/29850 (epoch 13.965), train_loss = 1.12020993, grad/param norm = 1.7828e-01, time/batch = 15.5800s	
8338/29850 (epoch 13.966), train_loss = 1.01788698, grad/param norm = 1.5728e-01, time/batch = 16.6497s	
8339/29850 (epoch 13.968), train_loss = 1.12782977, grad/param norm = 1.8606e-01, time/batch = 17.2791s	
8340/29850 (epoch 13.970), train_loss = 1.09078802, grad/param norm = 1.7838e-01, time/batch = 16.7928s	
8341/29850 (epoch 13.972), train_loss = 1.08165049, grad/param norm = 1.6602e-01, time/batch = 18.8872s	
8342/29850 (epoch 13.973), train_loss = 1.09197827, grad/param norm = 1.8434e-01, time/batch = 18.7851s	
8343/29850 (epoch 13.975), train_loss = 0.94503465, grad/param norm = 1.6466e-01, time/batch = 15.8892s	
8344/29850 (epoch 13.977), train_loss = 1.10704397, grad/param norm = 1.6328e-01, time/batch = 17.3854s	
8345/29850 (epoch 13.978), train_loss = 1.05339278, grad/param norm = 1.5399e-01, time/batch = 15.7307s	
8346/29850 (epoch 13.980), train_loss = 1.09126038, grad/param norm = 1.6700e-01, time/batch = 15.3671s	
8347/29850 (epoch 13.982), train_loss = 1.10869568, grad/param norm = 1.7322e-01, time/batch = 15.4901s	
8348/29850 (epoch 13.983), train_loss = 1.13429635, grad/param norm = 1.6588e-01, time/batch = 18.8718s	
8349/29850 (epoch 13.985), train_loss = 1.20646744, grad/param norm = 1.8115e-01, time/batch = 18.2129s	
8350/29850 (epoch 13.987), train_loss = 1.13238601, grad/param norm = 1.6542e-01, time/batch = 19.3635s	
8351/29850 (epoch 13.988), train_loss = 1.07678763, grad/param norm = 1.6407e-01, time/batch = 17.8710s	
8352/29850 (epoch 13.990), train_loss = 1.17520098, grad/param norm = 1.7542e-01, time/batch = 17.3745s	
8353/29850 (epoch 13.992), train_loss = 1.17576112, grad/param norm = 1.7367e-01, time/batch = 17.3680s	
8354/29850 (epoch 13.993), train_loss = 1.16007185, grad/param norm = 1.9683e-01, time/batch = 15.4459s	
8355/29850 (epoch 13.995), train_loss = 1.18766339, grad/param norm = 1.7664e-01, time/batch = 15.4843s	
8356/29850 (epoch 13.997), train_loss = 1.15943734, grad/param norm = 1.7423e-01, time/batch = 16.3661s	
8357/29850 (epoch 13.998), train_loss = 1.24301659, grad/param norm = 1.8118e-01, time/batch = 15.8848s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
8358/29850 (epoch 14.000), train_loss = 1.08479724, grad/param norm = 1.5858e-01, time/batch = 16.6973s	
8359/29850 (epoch 14.002), train_loss = 1.39053238, grad/param norm = 1.9872e-01, time/batch = 18.2837s	
8360/29850 (epoch 14.003), train_loss = 1.08881430, grad/param norm = 1.7082e-01, time/batch = 17.1978s	
8361/29850 (epoch 14.005), train_loss = 1.16848329, grad/param norm = 1.6792e-01, time/batch = 16.7946s	
8362/29850 (epoch 14.007), train_loss = 1.19729392, grad/param norm = 2.0823e-01, time/batch = 15.6182s	
8363/29850 (epoch 14.008), train_loss = 1.42504821, grad/param norm = 1.9327e-01, time/batch = 15.3979s	
8364/29850 (epoch 14.010), train_loss = 1.07399717, grad/param norm = 1.8536e-01, time/batch = 16.6884s	
8365/29850 (epoch 14.012), train_loss = 1.20811391, grad/param norm = 1.7218e-01, time/batch = 15.5525s	
8366/29850 (epoch 14.013), train_loss = 1.21085428, grad/param norm = 1.8705e-01, time/batch = 16.0595s	
8367/29850 (epoch 14.015), train_loss = 1.23061813, grad/param norm = 1.7632e-01, time/batch = 16.3127s	
8368/29850 (epoch 14.017), train_loss = 1.27617015, grad/param norm = 2.0030e-01, time/batch = 18.7639s	
8369/29850 (epoch 14.018), train_loss = 1.31177394, grad/param norm = 2.0701e-01, time/batch = 17.1233s	
8370/29850 (epoch 14.020), train_loss = 1.12704261, grad/param norm = 1.7084e-01, time/batch = 16.9789s	
8371/29850 (epoch 14.022), train_loss = 1.27000037, grad/param norm = 1.9030e-01, time/batch = 17.7757s	
8372/29850 (epoch 14.023), train_loss = 1.20074261, grad/param norm = 1.6906e-01, time/batch = 15.7975s	
8373/29850 (epoch 14.025), train_loss = 1.13812259, grad/param norm = 1.7141e-01, time/batch = 16.7942s	
8374/29850 (epoch 14.027), train_loss = 1.01939233, grad/param norm = 1.5835e-01, time/batch = 17.1140s	
8375/29850 (epoch 14.028), train_loss = 1.15446251, grad/param norm = 1.7567e-01, time/batch = 15.8680s	
8376/29850 (epoch 14.030), train_loss = 1.22319477, grad/param norm = 1.8777e-01, time/batch = 17.2335s	
8377/29850 (epoch 14.032), train_loss = 1.18914199, grad/param norm = 1.7367e-01, time/batch = 14.8615s	
8378/29850 (epoch 14.034), train_loss = 1.10454664, grad/param norm = 1.6513e-01, time/batch = 15.3926s	
8379/29850 (epoch 14.035), train_loss = 0.99209839, grad/param norm = 1.5287e-01, time/batch = 15.8012s	
8380/29850 (epoch 14.037), train_loss = 1.18450248, grad/param norm = 1.8823e-01, time/batch = 16.2031s	
8381/29850 (epoch 14.039), train_loss = 1.02196723, grad/param norm = 1.5702e-01, time/batch = 16.0247s	
8382/29850 (epoch 14.040), train_loss = 1.07397698, grad/param norm = 1.7385e-01, time/batch = 17.9555s	
8383/29850 (epoch 14.042), train_loss = 1.09566712, grad/param norm = 1.7708e-01, time/batch = 16.7035s	
8384/29850 (epoch 14.044), train_loss = 1.11895179, grad/param norm = 1.6949e-01, time/batch = 16.6479s	
8385/29850 (epoch 14.045), train_loss = 1.23278814, grad/param norm = 1.8411e-01, time/batch = 18.6300s	
8386/29850 (epoch 14.047), train_loss = 1.00008512, grad/param norm = 1.7137e-01, time/batch = 17.5328s	
8387/29850 (epoch 14.049), train_loss = 1.20577654, grad/param norm = 1.7329e-01, time/batch = 16.9677s	
8388/29850 (epoch 14.050), train_loss = 1.08275123, grad/param norm = 1.7736e-01, time/batch = 17.5636s	
8389/29850 (epoch 14.052), train_loss = 1.35582088, grad/param norm = 1.9725e-01, time/batch = 16.4054s	
8390/29850 (epoch 14.054), train_loss = 1.23284419, grad/param norm = 1.8263e-01, time/batch = 15.7914s	
8391/29850 (epoch 14.055), train_loss = 1.14722050, grad/param norm = 1.7772e-01, time/batch = 17.4670s	
8392/29850 (epoch 14.057), train_loss = 1.22408519, grad/param norm = 1.7888e-01, time/batch = 15.7906s	
8393/29850 (epoch 14.059), train_loss = 1.21303882, grad/param norm = 1.8344e-01, time/batch = 14.9951s	
8394/29850 (epoch 14.060), train_loss = 1.21252165, grad/param norm = 1.8343e-01, time/batch = 16.9538s	
8395/29850 (epoch 14.062), train_loss = 1.29751001, grad/param norm = 1.9134e-01, time/batch = 18.7044s	
8396/29850 (epoch 14.064), train_loss = 1.24325234, grad/param norm = 1.8874e-01, time/batch = 16.9409s	
8397/29850 (epoch 14.065), train_loss = 1.06635994, grad/param norm = 1.7234e-01, time/batch = 16.9691s	
8398/29850 (epoch 14.067), train_loss = 1.20618819, grad/param norm = 1.7819e-01, time/batch = 16.2892s	
8399/29850 (epoch 14.069), train_loss = 1.16276799, grad/param norm = 1.7632e-01, time/batch = 16.2749s	
8400/29850 (epoch 14.070), train_loss = 1.20426105, grad/param norm = 1.6963e-01, time/batch = 15.3463s	
8401/29850 (epoch 14.072), train_loss = 1.24293719, grad/param norm = 1.9488e-01, time/batch = 16.3572s	
8402/29850 (epoch 14.074), train_loss = 1.25295790, grad/param norm = 1.6531e-01, time/batch = 15.6145s	
8403/29850 (epoch 14.075), train_loss = 1.10654804, grad/param norm = 1.7381e-01, time/batch = 15.2344s	
8404/29850 (epoch 14.077), train_loss = 1.20811975, grad/param norm = 1.8188e-01, time/batch = 15.2926s	
8405/29850 (epoch 14.079), train_loss = 1.42908586, grad/param norm = 2.1718e-01, time/batch = 15.2865s	
8406/29850 (epoch 14.080), train_loss = 1.35777737, grad/param norm = 1.9857e-01, time/batch = 14.8218s	
8407/29850 (epoch 14.082), train_loss = 1.25352634, grad/param norm = 1.8172e-01, time/batch = 15.0348s	
8408/29850 (epoch 14.084), train_loss = 1.29280889, grad/param norm = 1.9517e-01, time/batch = 15.2177s	
8409/29850 (epoch 14.085), train_loss = 1.25123434, grad/param norm = 1.9351e-01, time/batch = 15.4551s	
8410/29850 (epoch 14.087), train_loss = 1.30745277, grad/param norm = 1.6854e-01, time/batch = 15.0579s	
8411/29850 (epoch 14.089), train_loss = 1.23654055, grad/param norm = 1.7735e-01, time/batch = 15.0593s	
8412/29850 (epoch 14.090), train_loss = 1.27210831, grad/param norm = 1.9884e-01, time/batch = 15.3045s	
8413/29850 (epoch 14.092), train_loss = 1.13694719, grad/param norm = 1.7200e-01, time/batch = 15.3768s	
8414/29850 (epoch 14.094), train_loss = 1.27697750, grad/param norm = 1.7554e-01, time/batch = 15.2306s	
8415/29850 (epoch 14.095), train_loss = 1.24025794, grad/param norm = 1.9167e-01, time/batch = 15.1501s	
8416/29850 (epoch 14.097), train_loss = 0.99890062, grad/param norm = 1.5772e-01, time/batch = 15.6676s	
8417/29850 (epoch 14.099), train_loss = 1.02214119, grad/param norm = 1.6798e-01, time/batch = 15.5836s	
8418/29850 (epoch 14.101), train_loss = 1.31522815, grad/param norm = 1.8310e-01, time/batch = 15.3599s	
8419/29850 (epoch 14.102), train_loss = 1.25694576, grad/param norm = 2.1764e-01, time/batch = 14.8025s	
8420/29850 (epoch 14.104), train_loss = 1.15698126, grad/param norm = 1.6553e-01, time/batch = 15.0453s	
8421/29850 (epoch 14.106), train_loss = 1.25183371, grad/param norm = 1.8177e-01, time/batch = 15.5791s	
8422/29850 (epoch 14.107), train_loss = 1.01616938, grad/param norm = 1.4987e-01, time/batch = 15.1816s	
8423/29850 (epoch 14.109), train_loss = 1.15452473, grad/param norm = 2.0884e-01, time/batch = 15.0634s	
8424/29850 (epoch 14.111), train_loss = 1.28720252, grad/param norm = 1.8463e-01, time/batch = 15.4389s	
8425/29850 (epoch 14.112), train_loss = 1.08363782, grad/param norm = 1.6645e-01, time/batch = 15.5130s	
8426/29850 (epoch 14.114), train_loss = 1.24162743, grad/param norm = 2.1537e-01, time/batch = 15.5834s	
8427/29850 (epoch 14.116), train_loss = 1.10370909, grad/param norm = 1.7316e-01, time/batch = 15.2796s	
8428/29850 (epoch 14.117), train_loss = 1.18358599, grad/param norm = 1.8196e-01, time/batch = 15.2096s	
8429/29850 (epoch 14.119), train_loss = 1.16521558, grad/param norm = 1.6821e-01, time/batch = 15.1239s	
8430/29850 (epoch 14.121), train_loss = 0.98691442, grad/param norm = 1.7420e-01, time/batch = 15.5316s	
8431/29850 (epoch 14.122), train_loss = 1.04009726, grad/param norm = 1.5725e-01, time/batch = 15.3835s	
8432/29850 (epoch 14.124), train_loss = 1.11646827, grad/param norm = 1.7035e-01, time/batch = 15.8676s	
8433/29850 (epoch 14.126), train_loss = 1.16569447, grad/param norm = 1.8242e-01, time/batch = 15.3868s	
8434/29850 (epoch 14.127), train_loss = 1.27554018, grad/param norm = 1.9226e-01, time/batch = 14.8207s	
8435/29850 (epoch 14.129), train_loss = 1.13987115, grad/param norm = 1.7239e-01, time/batch = 15.2217s	
8436/29850 (epoch 14.131), train_loss = 1.15691719, grad/param norm = 1.7507e-01, time/batch = 15.5381s	
8437/29850 (epoch 14.132), train_loss = 1.08387421, grad/param norm = 1.8938e-01, time/batch = 14.9010s	
8438/29850 (epoch 14.134), train_loss = 1.21431727, grad/param norm = 1.7877e-01, time/batch = 15.0748s	
8439/29850 (epoch 14.136), train_loss = 1.19729819, grad/param norm = 1.7831e-01, time/batch = 15.3862s	
8440/29850 (epoch 14.137), train_loss = 1.04771669, grad/param norm = 1.6964e-01, time/batch = 15.8846s	
8441/29850 (epoch 14.139), train_loss = 1.07218972, grad/param norm = 1.6413e-01, time/batch = 15.2841s	
8442/29850 (epoch 14.141), train_loss = 1.14069999, grad/param norm = 1.7177e-01, time/batch = 14.9017s	
8443/29850 (epoch 14.142), train_loss = 1.27383122, grad/param norm = 1.9294e-01, time/batch = 15.1319s	
8444/29850 (epoch 14.144), train_loss = 1.42340776, grad/param norm = 2.0565e-01, time/batch = 15.6824s	
8445/29850 (epoch 14.146), train_loss = 1.40267400, grad/param norm = 1.9879e-01, time/batch = 15.2941s	
8446/29850 (epoch 14.147), train_loss = 1.29171135, grad/param norm = 2.0589e-01, time/batch = 15.0649s	
8447/29850 (epoch 14.149), train_loss = 1.27336021, grad/param norm = 1.9275e-01, time/batch = 15.1461s	
8448/29850 (epoch 14.151), train_loss = 1.22303542, grad/param norm = 1.8954e-01, time/batch = 15.4529s	
8449/29850 (epoch 14.152), train_loss = 1.09989738, grad/param norm = 1.6726e-01, time/batch = 15.0681s	
8450/29850 (epoch 14.154), train_loss = 1.14403687, grad/param norm = 1.7801e-01, time/batch = 15.2844s	
8451/29850 (epoch 14.156), train_loss = 1.11159931, grad/param norm = 1.6553e-01, time/batch = 15.6702s	
8452/29850 (epoch 14.157), train_loss = 1.18385524, grad/param norm = 1.6867e-01, time/batch = 15.4027s	
8453/29850 (epoch 14.159), train_loss = 1.20030806, grad/param norm = 1.7561e-01, time/batch = 17.0560s	
8454/29850 (epoch 14.161), train_loss = 1.23019545, grad/param norm = 1.8699e-01, time/batch = 15.2172s	
8455/29850 (epoch 14.162), train_loss = 1.33740953, grad/param norm = 1.9186e-01, time/batch = 15.1298s	
8456/29850 (epoch 14.164), train_loss = 1.17984992, grad/param norm = 1.8244e-01, time/batch = 15.1522s	
8457/29850 (epoch 14.166), train_loss = 1.09050382, grad/param norm = 1.5689e-01, time/batch = 15.2144s	
8458/29850 (epoch 14.168), train_loss = 1.00014234, grad/param norm = 1.6119e-01, time/batch = 15.2891s	
8459/29850 (epoch 14.169), train_loss = 1.36711458, grad/param norm = 2.0618e-01, time/batch = 15.3510s	
8460/29850 (epoch 14.171), train_loss = 1.27381599, grad/param norm = 1.8182e-01, time/batch = 15.2642s	
8461/29850 (epoch 14.173), train_loss = 1.15362043, grad/param norm = 2.0094e-01, time/batch = 15.6441s	
8462/29850 (epoch 14.174), train_loss = 1.26241182, grad/param norm = 2.0062e-01, time/batch = 15.3480s	
8463/29850 (epoch 14.176), train_loss = 1.23143420, grad/param norm = 1.8275e-01, time/batch = 15.5963s	
8464/29850 (epoch 14.178), train_loss = 1.24355469, grad/param norm = 1.8760e-01, time/batch = 14.9743s	
8465/29850 (epoch 14.179), train_loss = 1.02215537, grad/param norm = 1.7003e-01, time/batch = 15.2893s	
8466/29850 (epoch 14.181), train_loss = 1.18737260, grad/param norm = 1.8386e-01, time/batch = 15.3689s	
8467/29850 (epoch 14.183), train_loss = 1.13714336, grad/param norm = 1.7557e-01, time/batch = 15.4602s	
8468/29850 (epoch 14.184), train_loss = 1.15277599, grad/param norm = 1.8321e-01, time/batch = 15.2069s	
8469/29850 (epoch 14.186), train_loss = 1.18293295, grad/param norm = 1.8763e-01, time/batch = 14.9750s	
8470/29850 (epoch 14.188), train_loss = 1.27955237, grad/param norm = 2.0902e-01, time/batch = 15.0497s	
8471/29850 (epoch 14.189), train_loss = 1.37045489, grad/param norm = 1.9960e-01, time/batch = 15.3035s	
8472/29850 (epoch 14.191), train_loss = 1.22250863, grad/param norm = 1.8133e-01, time/batch = 15.3070s	
8473/29850 (epoch 14.193), train_loss = 1.11601731, grad/param norm = 1.6998e-01, time/batch = 15.0431s	
8474/29850 (epoch 14.194), train_loss = 1.24511447, grad/param norm = 1.9775e-01, time/batch = 14.9611s	
8475/29850 (epoch 14.196), train_loss = 1.13557103, grad/param norm = 1.8047e-01, time/batch = 15.4604s	
8476/29850 (epoch 14.198), train_loss = 1.18684311, grad/param norm = 1.8451e-01, time/batch = 15.2888s	
8477/29850 (epoch 14.199), train_loss = 1.46180075, grad/param norm = 2.0254e-01, time/batch = 15.3158s	
8478/29850 (epoch 14.201), train_loss = 1.11538401, grad/param norm = 1.7917e-01, time/batch = 15.2192s	
8479/29850 (epoch 14.203), train_loss = 1.00373684, grad/param norm = 1.6968e-01, time/batch = 15.6644s	
8480/29850 (epoch 14.204), train_loss = 1.25908148, grad/param norm = 2.0831e-01, time/batch = 15.8062s	
8481/29850 (epoch 14.206), train_loss = 1.07210442, grad/param norm = 1.8586e-01, time/batch = 15.7716s	
8482/29850 (epoch 14.208), train_loss = 1.36505763, grad/param norm = 1.8975e-01, time/batch = 15.5173s	
8483/29850 (epoch 14.209), train_loss = 1.08134014, grad/param norm = 1.6553e-01, time/batch = 15.6046s	
8484/29850 (epoch 14.211), train_loss = 1.15806017, grad/param norm = 1.6630e-01, time/batch = 15.0712s	
8485/29850 (epoch 14.213), train_loss = 1.30134035, grad/param norm = 2.0845e-01, time/batch = 15.5050s	
8486/29850 (epoch 14.214), train_loss = 1.09463935, grad/param norm = 1.6043e-01, time/batch = 15.5261s	
8487/29850 (epoch 14.216), train_loss = 1.13029835, grad/param norm = 1.7506e-01, time/batch = 15.4591s	
8488/29850 (epoch 14.218), train_loss = 1.24911644, grad/param norm = 1.8461e-01, time/batch = 14.7502s	
8489/29850 (epoch 14.219), train_loss = 1.32278420, grad/param norm = 2.0253e-01, time/batch = 14.9920s	
8490/29850 (epoch 14.221), train_loss = 1.16362174, grad/param norm = 1.8749e-01, time/batch = 14.9751s	
8491/29850 (epoch 14.223), train_loss = 1.14158571, grad/param norm = 1.8921e-01, time/batch = 15.2194s	
8492/29850 (epoch 14.224), train_loss = 1.05852824, grad/param norm = 1.7990e-01, time/batch = 15.4519s	
8493/29850 (epoch 14.226), train_loss = 1.07373319, grad/param norm = 1.5124e-01, time/batch = 17.3650s	
8494/29850 (epoch 14.228), train_loss = 1.13525321, grad/param norm = 1.6354e-01, time/batch = 17.7047s	
8495/29850 (epoch 14.229), train_loss = 1.03559727, grad/param norm = 1.6845e-01, time/batch = 17.7910s	
8496/29850 (epoch 14.231), train_loss = 1.14994853, grad/param norm = 1.6745e-01, time/batch = 18.6924s	
8497/29850 (epoch 14.233), train_loss = 1.16827480, grad/param norm = 1.9457e-01, time/batch = 18.3770s	
8498/29850 (epoch 14.235), train_loss = 1.07237943, grad/param norm = 1.5370e-01, time/batch = 18.2232s	
8499/29850 (epoch 14.236), train_loss = 1.29553411, grad/param norm = 1.9846e-01, time/batch = 16.1839s	
8500/29850 (epoch 14.238), train_loss = 1.05406004, grad/param norm = 1.8421e-01, time/batch = 16.0270s	
8501/29850 (epoch 14.240), train_loss = 1.06756620, grad/param norm = 1.6408e-01, time/batch = 15.9412s	
8502/29850 (epoch 14.241), train_loss = 1.28851099, grad/param norm = 2.1930e-01, time/batch = 16.3787s	
8503/29850 (epoch 14.243), train_loss = 1.17889207, grad/param norm = 1.8404e-01, time/batch = 16.3008s	
8504/29850 (epoch 14.245), train_loss = 1.11621937, grad/param norm = 1.8965e-01, time/batch = 16.2183s	
8505/29850 (epoch 14.246), train_loss = 1.07836251, grad/param norm = 1.7879e-01, time/batch = 17.1910s	
8506/29850 (epoch 14.248), train_loss = 1.06517602, grad/param norm = 1.7340e-01, time/batch = 19.0295s	
8507/29850 (epoch 14.250), train_loss = 1.15143499, grad/param norm = 1.7317e-01, time/batch = 18.2114s	
8508/29850 (epoch 14.251), train_loss = 1.05562772, grad/param norm = 1.8327e-01, time/batch = 16.0179s	
8509/29850 (epoch 14.253), train_loss = 1.01312584, grad/param norm = 1.9470e-01, time/batch = 15.6608s	
8510/29850 (epoch 14.255), train_loss = 1.05744608, grad/param norm = 1.6744e-01, time/batch = 17.3006s	
8511/29850 (epoch 14.256), train_loss = 1.18309906, grad/param norm = 1.9543e-01, time/batch = 16.8421s	
8512/29850 (epoch 14.258), train_loss = 1.17916417, grad/param norm = 1.7948e-01, time/batch = 19.6196s	
8513/29850 (epoch 14.260), train_loss = 1.11886772, grad/param norm = 1.7078e-01, time/batch = 16.7835s	
8514/29850 (epoch 14.261), train_loss = 1.11840155, grad/param norm = 1.8362e-01, time/batch = 15.5137s	
8515/29850 (epoch 14.263), train_loss = 1.04371315, grad/param norm = 1.7747e-01, time/batch = 16.7876s	
8516/29850 (epoch 14.265), train_loss = 1.11483308, grad/param norm = 1.8687e-01, time/batch = 16.9725s	
8517/29850 (epoch 14.266), train_loss = 1.12709640, grad/param norm = 1.8508e-01, time/batch = 15.6108s	
8518/29850 (epoch 14.268), train_loss = 1.10828031, grad/param norm = 1.5836e-01, time/batch = 15.4869s	
8519/29850 (epoch 14.270), train_loss = 1.08471526, grad/param norm = 1.6726e-01, time/batch = 29.1190s	
8520/29850 (epoch 14.271), train_loss = 1.26299990, grad/param norm = 1.7723e-01, time/batch = 15.3293s	
8521/29850 (epoch 14.273), train_loss = 1.02330353, grad/param norm = 1.6999e-01, time/batch = 15.2796s	
8522/29850 (epoch 14.275), train_loss = 1.02146398, grad/param norm = 1.6832e-01, time/batch = 15.4392s	
8523/29850 (epoch 14.276), train_loss = 1.02800587, grad/param norm = 1.6776e-01, time/batch = 16.4839s	
8524/29850 (epoch 14.278), train_loss = 1.09988037, grad/param norm = 1.6666e-01, time/batch = 16.7346s	
8525/29850 (epoch 14.280), train_loss = 1.31073190, grad/param norm = 2.1239e-01, time/batch = 15.2210s	
8526/29850 (epoch 14.281), train_loss = 1.16873157, grad/param norm = 1.8760e-01, time/batch = 15.8894s	
8527/29850 (epoch 14.283), train_loss = 1.28682789, grad/param norm = 2.1256e-01, time/batch = 16.0262s	
8528/29850 (epoch 14.285), train_loss = 1.13002654, grad/param norm = 1.7865e-01, time/batch = 19.3718s	
8529/29850 (epoch 14.286), train_loss = 1.23429744, grad/param norm = 1.8745e-01, time/batch = 17.5279s	
8530/29850 (epoch 14.288), train_loss = 1.35451989, grad/param norm = 2.2348e-01, time/batch = 17.8047s	
8531/29850 (epoch 14.290), train_loss = 1.12750313, grad/param norm = 1.8035e-01, time/batch = 17.4769s	
8532/29850 (epoch 14.291), train_loss = 1.41106224, grad/param norm = 1.8724e-01, time/batch = 16.7922s	
8533/29850 (epoch 14.293), train_loss = 1.27189346, grad/param norm = 2.5524e-01, time/batch = 16.0670s	
8534/29850 (epoch 14.295), train_loss = 1.37896593, grad/param norm = 2.3751e-01, time/batch = 18.7893s	
8535/29850 (epoch 14.296), train_loss = 1.10528261, grad/param norm = 1.8068e-01, time/batch = 14.7845s	
8536/29850 (epoch 14.298), train_loss = 0.94233875, grad/param norm = 1.6097e-01, time/batch = 16.4321s	
8537/29850 (epoch 14.300), train_loss = 1.02940025, grad/param norm = 1.6552e-01, time/batch = 15.4200s	
8538/29850 (epoch 14.302), train_loss = 1.02290894, grad/param norm = 1.6159e-01, time/batch = 16.8045s	
8539/29850 (epoch 14.303), train_loss = 1.06626733, grad/param norm = 1.6551e-01, time/batch = 17.3706s	
8540/29850 (epoch 14.305), train_loss = 1.17898166, grad/param norm = 1.7327e-01, time/batch = 16.8617s	
8541/29850 (epoch 14.307), train_loss = 1.26380542, grad/param norm = 1.8472e-01, time/batch = 18.4656s	
8542/29850 (epoch 14.308), train_loss = 1.15377135, grad/param norm = 2.1435e-01, time/batch = 19.0327s	
8543/29850 (epoch 14.310), train_loss = 1.19658130, grad/param norm = 1.9247e-01, time/batch = 16.4488s	
8544/29850 (epoch 14.312), train_loss = 1.25822798, grad/param norm = 1.8713e-01, time/batch = 18.2104s	
8545/29850 (epoch 14.313), train_loss = 1.19948102, grad/param norm = 1.8376e-01, time/batch = 18.5365s	
8546/29850 (epoch 14.315), train_loss = 1.19502868, grad/param norm = 1.7222e-01, time/batch = 15.2954s	
8547/29850 (epoch 14.317), train_loss = 1.20261239, grad/param norm = 2.0656e-01, time/batch = 16.3554s	
8548/29850 (epoch 14.318), train_loss = 1.14851857, grad/param norm = 1.8020e-01, time/batch = 17.0483s	
8549/29850 (epoch 14.320), train_loss = 1.05660564, grad/param norm = 1.5446e-01, time/batch = 19.3701s	
8550/29850 (epoch 14.322), train_loss = 1.33315511, grad/param norm = 1.9562e-01, time/batch = 17.0115s	
8551/29850 (epoch 14.323), train_loss = 1.23344922, grad/param norm = 2.0976e-01, time/batch = 19.5938s	
8552/29850 (epoch 14.325), train_loss = 1.22474905, grad/param norm = 1.8253e-01, time/batch = 17.4528s	
8553/29850 (epoch 14.327), train_loss = 1.35328598, grad/param norm = 1.9877e-01, time/batch = 15.5958s	
8554/29850 (epoch 14.328), train_loss = 1.32906998, grad/param norm = 2.0158e-01, time/batch = 15.7097s	
8555/29850 (epoch 14.330), train_loss = 1.17278899, grad/param norm = 1.7709e-01, time/batch = 14.9406s	
8556/29850 (epoch 14.332), train_loss = 1.10483305, grad/param norm = 1.6781e-01, time/batch = 14.8590s	
8557/29850 (epoch 14.333), train_loss = 1.32084977, grad/param norm = 1.9064e-01, time/batch = 14.7196s	
8558/29850 (epoch 14.335), train_loss = 1.24406447, grad/param norm = 1.8704e-01, time/batch = 14.3282s	
8559/29850 (epoch 14.337), train_loss = 1.19850234, grad/param norm = 1.9314e-01, time/batch = 14.7009s	
8560/29850 (epoch 14.338), train_loss = 1.19000232, grad/param norm = 1.8026e-01, time/batch = 14.3944s	
8561/29850 (epoch 14.340), train_loss = 1.06412035, grad/param norm = 1.7149e-01, time/batch = 14.6330s	
8562/29850 (epoch 14.342), train_loss = 1.17965587, grad/param norm = 1.9010e-01, time/batch = 14.4011s	
8563/29850 (epoch 14.343), train_loss = 1.22204653, grad/param norm = 1.9729e-01, time/batch = 14.0819s	
8564/29850 (epoch 14.345), train_loss = 1.24668156, grad/param norm = 2.1124e-01, time/batch = 14.8057s	
8565/29850 (epoch 14.347), train_loss = 1.27984547, grad/param norm = 1.8915e-01, time/batch = 17.2169s	
8566/29850 (epoch 14.348), train_loss = 1.14037031, grad/param norm = 1.7123e-01, time/batch = 15.5663s	
8567/29850 (epoch 14.350), train_loss = 1.28568268, grad/param norm = 2.0743e-01, time/batch = 14.5493s	
8568/29850 (epoch 14.352), train_loss = 1.16547017, grad/param norm = 1.7293e-01, time/batch = 14.8505s	
8569/29850 (epoch 14.353), train_loss = 1.23578729, grad/param norm = 1.9032e-01, time/batch = 15.1888s	
8570/29850 (epoch 14.355), train_loss = 1.06336245, grad/param norm = 1.7480e-01, time/batch = 17.9446s	
8571/29850 (epoch 14.357), train_loss = 1.35077755, grad/param norm = 1.9128e-01, time/batch = 17.8532s	
8572/29850 (epoch 14.358), train_loss = 1.06280058, grad/param norm = 1.6554e-01, time/batch = 15.0941s	
8573/29850 (epoch 14.360), train_loss = 1.16169735, grad/param norm = 1.7473e-01, time/batch = 15.3812s	
8574/29850 (epoch 14.362), train_loss = 1.17333471, grad/param norm = 1.7775e-01, time/batch = 15.7756s	
8575/29850 (epoch 14.363), train_loss = 1.20374200, grad/param norm = 1.8647e-01, time/batch = 14.7714s	
8576/29850 (epoch 14.365), train_loss = 1.34794607, grad/param norm = 2.0044e-01, time/batch = 14.9234s	
8577/29850 (epoch 14.367), train_loss = 1.16501385, grad/param norm = 1.8655e-01, time/batch = 15.3129s	
8578/29850 (epoch 14.369), train_loss = 1.05715796, grad/param norm = 1.7363e-01, time/batch = 15.1813s	
8579/29850 (epoch 14.370), train_loss = 0.98955753, grad/param norm = 1.6692e-01, time/batch = 15.9100s	
8580/29850 (epoch 14.372), train_loss = 1.33239303, grad/param norm = 2.1228e-01, time/batch = 16.6332s	
8581/29850 (epoch 14.374), train_loss = 1.17024052, grad/param norm = 1.8726e-01, time/batch = 18.2822s	
8582/29850 (epoch 14.375), train_loss = 1.18138210, grad/param norm = 1.7983e-01, time/batch = 17.4348s	
8583/29850 (epoch 14.377), train_loss = 1.17444066, grad/param norm = 1.8244e-01, time/batch = 16.8541s	
8584/29850 (epoch 14.379), train_loss = 1.27288406, grad/param norm = 1.9833e-01, time/batch = 17.7825s	
8585/29850 (epoch 14.380), train_loss = 1.22977073, grad/param norm = 1.9017e-01, time/batch = 16.8821s	
8586/29850 (epoch 14.382), train_loss = 1.22370723, grad/param norm = 1.8522e-01, time/batch = 17.8494s	
8587/29850 (epoch 14.384), train_loss = 1.22684885, grad/param norm = 1.8600e-01, time/batch = 16.3655s	
8588/29850 (epoch 14.385), train_loss = 1.18037884, grad/param norm = 1.8188e-01, time/batch = 16.9660s	
8589/29850 (epoch 14.387), train_loss = 1.21876984, grad/param norm = 2.0012e-01, time/batch = 17.7028s	
8590/29850 (epoch 14.389), train_loss = 1.33624141, grad/param norm = 1.9080e-01, time/batch = 18.2566s	
8591/29850 (epoch 14.390), train_loss = 1.22366342, grad/param norm = 1.7146e-01, time/batch = 15.9651s	
8592/29850 (epoch 14.392), train_loss = 1.16810282, grad/param norm = 1.8923e-01, time/batch = 15.4769s	
8593/29850 (epoch 14.394), train_loss = 1.28560229, grad/param norm = 1.8231e-01, time/batch = 16.0699s	
8594/29850 (epoch 14.395), train_loss = 1.19046178, grad/param norm = 1.7991e-01, time/batch = 15.4973s	
8595/29850 (epoch 14.397), train_loss = 1.09307658, grad/param norm = 1.8036e-01, time/batch = 15.3357s	
8596/29850 (epoch 14.399), train_loss = 1.08606338, grad/param norm = 1.7306e-01, time/batch = 16.3055s	
8597/29850 (epoch 14.400), train_loss = 1.47012391, grad/param norm = 2.0728e-01, time/batch = 17.2166s	
8598/29850 (epoch 14.402), train_loss = 1.37715820, grad/param norm = 1.9727e-01, time/batch = 15.7203s	
8599/29850 (epoch 14.404), train_loss = 1.22177598, grad/param norm = 1.8900e-01, time/batch = 17.1810s	
8600/29850 (epoch 14.405), train_loss = 1.16663632, grad/param norm = 1.9258e-01, time/batch = 18.2727s	
8601/29850 (epoch 14.407), train_loss = 1.12227801, grad/param norm = 1.7759e-01, time/batch = 18.1048s	
8602/29850 (epoch 14.409), train_loss = 1.29987877, grad/param norm = 1.9635e-01, time/batch = 16.5594s	
8603/29850 (epoch 14.410), train_loss = 1.34820871, grad/param norm = 1.8323e-01, time/batch = 17.8339s	
8604/29850 (epoch 14.412), train_loss = 1.25955972, grad/param norm = 1.8309e-01, time/batch = 17.9394s	
8605/29850 (epoch 14.414), train_loss = 1.21606480, grad/param norm = 1.9990e-01, time/batch = 15.3356s	
8606/29850 (epoch 14.415), train_loss = 1.22151965, grad/param norm = 1.8059e-01, time/batch = 18.0368s	
8607/29850 (epoch 14.417), train_loss = 1.36748837, grad/param norm = 1.9245e-01, time/batch = 17.9636s	
8608/29850 (epoch 14.419), train_loss = 1.21947967, grad/param norm = 1.8794e-01, time/batch = 16.3435s	
8609/29850 (epoch 14.420), train_loss = 1.19492741, grad/param norm = 1.7641e-01, time/batch = 15.9358s	
8610/29850 (epoch 14.422), train_loss = 1.19335212, grad/param norm = 1.8470e-01, time/batch = 16.7617s	
8611/29850 (epoch 14.424), train_loss = 1.16784899, grad/param norm = 1.7848e-01, time/batch = 18.8370s	
8612/29850 (epoch 14.425), train_loss = 1.35702934, grad/param norm = 1.7540e-01, time/batch = 15.8600s	
8613/29850 (epoch 14.427), train_loss = 1.01302598, grad/param norm = 1.6704e-01, time/batch = 19.3545s	
8614/29850 (epoch 14.429), train_loss = 1.07620031, grad/param norm = 1.7463e-01, time/batch = 17.5538s	
8615/29850 (epoch 14.430), train_loss = 1.00154358, grad/param norm = 1.6033e-01, time/batch = 17.0180s	
8616/29850 (epoch 14.432), train_loss = 1.17524433, grad/param norm = 1.9945e-01, time/batch = 17.7062s	
8617/29850 (epoch 14.434), train_loss = 1.06634926, grad/param norm = 1.6896e-01, time/batch = 18.3576s	
8618/29850 (epoch 14.436), train_loss = 1.24116076, grad/param norm = 1.9714e-01, time/batch = 18.6040s	
8619/29850 (epoch 14.437), train_loss = 1.24455729, grad/param norm = 1.7806e-01, time/batch = 16.4591s	
8620/29850 (epoch 14.439), train_loss = 1.20596164, grad/param norm = 1.6901e-01, time/batch = 19.3512s	
8621/29850 (epoch 14.441), train_loss = 1.17052726, grad/param norm = 1.7072e-01, time/batch = 18.8720s	
8622/29850 (epoch 14.442), train_loss = 1.24931367, grad/param norm = 1.9807e-01, time/batch = 18.2591s	
8623/29850 (epoch 14.444), train_loss = 1.19689201, grad/param norm = 1.7726e-01, time/batch = 17.5214s	
8624/29850 (epoch 14.446), train_loss = 1.21322036, grad/param norm = 1.7629e-01, time/batch = 17.9439s	
8625/29850 (epoch 14.447), train_loss = 1.26019302, grad/param norm = 1.9250e-01, time/batch = 15.0993s	
8626/29850 (epoch 14.449), train_loss = 1.25349413, grad/param norm = 2.0454e-01, time/batch = 15.9074s	
8627/29850 (epoch 14.451), train_loss = 1.04963828, grad/param norm = 1.7155e-01, time/batch = 15.3707s	
8628/29850 (epoch 14.452), train_loss = 0.90573180, grad/param norm = 1.4540e-01, time/batch = 15.2748s	
8629/29850 (epoch 14.454), train_loss = 1.05377519, grad/param norm = 1.6864e-01, time/batch = 16.1286s	
8630/29850 (epoch 14.456), train_loss = 1.25949512, grad/param norm = 2.0417e-01, time/batch = 17.7786s	
8631/29850 (epoch 14.457), train_loss = 1.28611185, grad/param norm = 2.3786e-01, time/batch = 15.5171s	
8632/29850 (epoch 14.459), train_loss = 1.35942524, grad/param norm = 1.8794e-01, time/batch = 16.7036s	
8633/29850 (epoch 14.461), train_loss = 1.35691223, grad/param norm = 1.8430e-01, time/batch = 15.1978s	
8634/29850 (epoch 14.462), train_loss = 1.31191562, grad/param norm = 1.9400e-01, time/batch = 16.0582s	
8635/29850 (epoch 14.464), train_loss = 1.22863383, grad/param norm = 1.7551e-01, time/batch = 19.3761s	
8636/29850 (epoch 14.466), train_loss = 1.08806672, grad/param norm = 1.8127e-01, time/batch = 15.8747s	
8637/29850 (epoch 14.467), train_loss = 1.18566892, grad/param norm = 1.8873e-01, time/batch = 18.7119s	
8638/29850 (epoch 14.469), train_loss = 1.16056039, grad/param norm = 1.7433e-01, time/batch = 15.6860s	
8639/29850 (epoch 14.471), train_loss = 1.19127729, grad/param norm = 1.9140e-01, time/batch = 17.8828s	
8640/29850 (epoch 14.472), train_loss = 1.09917389, grad/param norm = 1.6580e-01, time/batch = 17.4587s	
8641/29850 (epoch 14.474), train_loss = 1.30702292, grad/param norm = 1.9885e-01, time/batch = 16.4769s	
8642/29850 (epoch 14.476), train_loss = 1.21429033, grad/param norm = 1.7503e-01, time/batch = 18.2223s	
8643/29850 (epoch 14.477), train_loss = 1.23670650, grad/param norm = 2.0996e-01, time/batch = 15.8732s	
8644/29850 (epoch 14.479), train_loss = 1.33487432, grad/param norm = 1.9984e-01, time/batch = 17.4719s	
8645/29850 (epoch 14.481), train_loss = 1.24009773, grad/param norm = 2.0023e-01, time/batch = 18.1356s	
8646/29850 (epoch 14.482), train_loss = 1.13259611, grad/param norm = 1.5561e-01, time/batch = 15.2652s	
8647/29850 (epoch 14.484), train_loss = 1.11562527, grad/param norm = 1.7952e-01, time/batch = 15.4159s	
8648/29850 (epoch 14.486), train_loss = 1.19675504, grad/param norm = 1.9928e-01, time/batch = 15.5199s	
8649/29850 (epoch 14.487), train_loss = 1.16972921, grad/param norm = 1.8672e-01, time/batch = 15.3943s	
8650/29850 (epoch 14.489), train_loss = 1.18643031, grad/param norm = 1.8734e-01, time/batch = 15.4257s	
8651/29850 (epoch 14.491), train_loss = 1.06699600, grad/param norm = 1.6306e-01, time/batch = 15.6777s	
8652/29850 (epoch 14.492), train_loss = 1.21711007, grad/param norm = 1.8756e-01, time/batch = 15.1433s	
8653/29850 (epoch 14.494), train_loss = 1.31244634, grad/param norm = 1.7269e-01, time/batch = 15.2085s	
8654/29850 (epoch 14.496), train_loss = 1.36203782, grad/param norm = 1.8794e-01, time/batch = 15.4425s	
8655/29850 (epoch 14.497), train_loss = 1.26020504, grad/param norm = 1.7100e-01, time/batch = 15.7108s	
8656/29850 (epoch 14.499), train_loss = 1.21038967, grad/param norm = 1.7727e-01, time/batch = 15.2922s	
8657/29850 (epoch 14.501), train_loss = 1.14535722, grad/param norm = 1.6699e-01, time/batch = 17.2002s	
8658/29850 (epoch 14.503), train_loss = 1.18423974, grad/param norm = 1.8203e-01, time/batch = 16.6152s	
8659/29850 (epoch 14.504), train_loss = 1.38166093, grad/param norm = 1.8150e-01, time/batch = 15.8047s	
8660/29850 (epoch 14.506), train_loss = 1.38422767, grad/param norm = 1.9891e-01, time/batch = 16.1034s	
8661/29850 (epoch 14.508), train_loss = 1.18267308, grad/param norm = 1.8923e-01, time/batch = 18.7770s	
8662/29850 (epoch 14.509), train_loss = 0.98881073, grad/param norm = 1.6710e-01, time/batch = 16.7691s	
8663/29850 (epoch 14.511), train_loss = 1.19871957, grad/param norm = 1.8665e-01, time/batch = 15.3136s	
8664/29850 (epoch 14.513), train_loss = 1.21978206, grad/param norm = 1.9727e-01, time/batch = 16.1817s	
8665/29850 (epoch 14.514), train_loss = 1.06018044, grad/param norm = 1.7099e-01, time/batch = 15.6332s	
8666/29850 (epoch 14.516), train_loss = 1.09644527, grad/param norm = 1.6873e-01, time/batch = 15.1823s	
8667/29850 (epoch 14.518), train_loss = 1.03223348, grad/param norm = 1.6473e-01, time/batch = 15.3699s	
8668/29850 (epoch 14.519), train_loss = 1.03431497, grad/param norm = 1.6743e-01, time/batch = 17.5187s	
8669/29850 (epoch 14.521), train_loss = 1.00883228, grad/param norm = 1.5693e-01, time/batch = 15.2719s	
8670/29850 (epoch 14.523), train_loss = 1.03330444, grad/param norm = 1.5162e-01, time/batch = 17.9493s	
8671/29850 (epoch 14.524), train_loss = 1.13470310, grad/param norm = 1.9192e-01, time/batch = 17.8377s	
8672/29850 (epoch 14.526), train_loss = 1.24106901, grad/param norm = 1.9136e-01, time/batch = 17.1860s	
8673/29850 (epoch 14.528), train_loss = 1.34110562, grad/param norm = 2.0029e-01, time/batch = 16.9448s	
8674/29850 (epoch 14.529), train_loss = 1.24947487, grad/param norm = 1.9569e-01, time/batch = 15.9581s	
8675/29850 (epoch 14.531), train_loss = 1.18401770, grad/param norm = 2.1177e-01, time/batch = 18.3590s	
8676/29850 (epoch 14.533), train_loss = 1.15243542, grad/param norm = 1.8695e-01, time/batch = 16.6911s	
8677/29850 (epoch 14.534), train_loss = 1.15678955, grad/param norm = 1.7501e-01, time/batch = 18.5144s	
8678/29850 (epoch 14.536), train_loss = 1.18054896, grad/param norm = 1.9010e-01, time/batch = 15.3253s	
8679/29850 (epoch 14.538), train_loss = 1.27885801, grad/param norm = 1.7893e-01, time/batch = 18.0865s	
8680/29850 (epoch 14.539), train_loss = 1.36186368, grad/param norm = 1.8178e-01, time/batch = 15.5204s	
8681/29850 (epoch 14.541), train_loss = 0.99656996, grad/param norm = 1.6192e-01, time/batch = 16.3009s	
8682/29850 (epoch 14.543), train_loss = 1.19817987, grad/param norm = 1.7281e-01, time/batch = 17.6218s	
8683/29850 (epoch 14.544), train_loss = 1.19265685, grad/param norm = 1.7480e-01, time/batch = 16.7779s	
8684/29850 (epoch 14.546), train_loss = 1.27956188, grad/param norm = 1.8156e-01, time/batch = 15.7873s	
8685/29850 (epoch 14.548), train_loss = 1.06235675, grad/param norm = 1.7652e-01, time/batch = 14.8597s	
8686/29850 (epoch 14.549), train_loss = 1.12260356, grad/param norm = 1.7193e-01, time/batch = 14.5655s	
8687/29850 (epoch 14.551), train_loss = 1.08628549, grad/param norm = 1.7312e-01, time/batch = 14.7944s	
8688/29850 (epoch 14.553), train_loss = 1.19453428, grad/param norm = 1.8227e-01, time/batch = 14.4902s	
8689/29850 (epoch 14.554), train_loss = 1.00590084, grad/param norm = 1.5901e-01, time/batch = 14.4868s	
8690/29850 (epoch 14.556), train_loss = 1.13278141, grad/param norm = 1.8266e-01, time/batch = 14.8952s	
8691/29850 (epoch 14.558), train_loss = 1.09087245, grad/param norm = 1.7188e-01, time/batch = 15.2116s	
8692/29850 (epoch 14.559), train_loss = 1.17854395, grad/param norm = 1.7610e-01, time/batch = 14.8971s	
8693/29850 (epoch 14.561), train_loss = 1.25120985, grad/param norm = 1.8543e-01, time/batch = 14.8170s	
8694/29850 (epoch 14.563), train_loss = 1.16463531, grad/param norm = 1.7603e-01, time/batch = 15.0261s	
8695/29850 (epoch 14.564), train_loss = 1.14751068, grad/param norm = 1.8252e-01, time/batch = 15.1912s	
8696/29850 (epoch 14.566), train_loss = 1.15958903, grad/param norm = 1.9025e-01, time/batch = 14.6476s	
8697/29850 (epoch 14.568), train_loss = 1.30176434, grad/param norm = 1.7790e-01, time/batch = 14.8148s	
8698/29850 (epoch 14.570), train_loss = 1.18698667, grad/param norm = 1.7232e-01, time/batch = 14.8143s	
8699/29850 (epoch 14.571), train_loss = 1.20916993, grad/param norm = 1.9300e-01, time/batch = 15.3435s	
8700/29850 (epoch 14.573), train_loss = 1.33471380, grad/param norm = 2.1632e-01, time/batch = 14.5593s	
8701/29850 (epoch 14.575), train_loss = 1.30360685, grad/param norm = 1.7287e-01, time/batch = 14.4087s	
8702/29850 (epoch 14.576), train_loss = 1.30250301, grad/param norm = 1.8381e-01, time/batch = 14.3332s	
8703/29850 (epoch 14.578), train_loss = 1.19566145, grad/param norm = 1.8511e-01, time/batch = 14.7251s	
8704/29850 (epoch 14.580), train_loss = 1.32108236, grad/param norm = 1.8622e-01, time/batch = 14.7871s	
8705/29850 (epoch 14.581), train_loss = 1.08841964, grad/param norm = 1.7349e-01, time/batch = 15.4836s	
8706/29850 (epoch 14.583), train_loss = 1.17562473, grad/param norm = 1.7792e-01, time/batch = 14.7222s	
8707/29850 (epoch 14.585), train_loss = 1.23805480, grad/param norm = 1.7538e-01, time/batch = 15.4681s	
8708/29850 (epoch 14.586), train_loss = 1.24042821, grad/param norm = 1.8880e-01, time/batch = 14.3246s	
8709/29850 (epoch 14.588), train_loss = 1.15024077, grad/param norm = 1.8562e-01, time/batch = 15.0608s	
8710/29850 (epoch 14.590), train_loss = 1.17300891, grad/param norm = 1.8219e-01, time/batch = 14.9496s	
8711/29850 (epoch 14.591), train_loss = 1.12849556, grad/param norm = 1.7676e-01, time/batch = 14.5649s	
8712/29850 (epoch 14.593), train_loss = 1.09689110, grad/param norm = 1.5874e-01, time/batch = 14.2525s	
8713/29850 (epoch 14.595), train_loss = 1.05529505, grad/param norm = 1.5360e-01, time/batch = 14.0881s	
8714/29850 (epoch 14.596), train_loss = 1.02708444, grad/param norm = 1.6440e-01, time/batch = 14.8194s	
8715/29850 (epoch 14.598), train_loss = 1.08282068, grad/param norm = 1.6233e-01, time/batch = 14.5668s	
8716/29850 (epoch 14.600), train_loss = 1.25830919, grad/param norm = 1.8872e-01, time/batch = 15.0416s	
8717/29850 (epoch 14.601), train_loss = 1.05131948, grad/param norm = 1.6420e-01, time/batch = 14.6608s	
8718/29850 (epoch 14.603), train_loss = 1.16441838, grad/param norm = 1.8628e-01, time/batch = 14.6613s	
8719/29850 (epoch 14.605), train_loss = 1.16249034, grad/param norm = 1.8490e-01, time/batch = 14.7452s	
8720/29850 (epoch 14.606), train_loss = 0.92802518, grad/param norm = 1.5961e-01, time/batch = 14.6427s	
8721/29850 (epoch 14.608), train_loss = 1.16587721, grad/param norm = 1.7524e-01, time/batch = 14.4132s	
8722/29850 (epoch 14.610), train_loss = 1.19149916, grad/param norm = 1.7716e-01, time/batch = 14.2555s	
8723/29850 (epoch 14.611), train_loss = 1.03040263, grad/param norm = 1.5890e-01, time/batch = 14.7393s	
8724/29850 (epoch 14.613), train_loss = 0.92849096, grad/param norm = 1.5215e-01, time/batch = 15.0372s	
8725/29850 (epoch 14.615), train_loss = 1.02886755, grad/param norm = 1.6510e-01, time/batch = 14.2644s	
8726/29850 (epoch 14.616), train_loss = 1.06539133, grad/param norm = 1.7713e-01, time/batch = 15.1830s	
8727/29850 (epoch 14.618), train_loss = 1.13845397, grad/param norm = 1.7440e-01, time/batch = 14.9524s	
8728/29850 (epoch 14.620), train_loss = 1.19568131, grad/param norm = 1.9453e-01, time/batch = 14.8804s	
8729/29850 (epoch 14.621), train_loss = 1.28028806, grad/param norm = 1.9343e-01, time/batch = 14.9588s	
8730/29850 (epoch 14.623), train_loss = 1.26945426, grad/param norm = 1.8834e-01, time/batch = 14.1840s	
8731/29850 (epoch 14.625), train_loss = 1.19805878, grad/param norm = 1.9644e-01, time/batch = 15.0551s	
8732/29850 (epoch 14.626), train_loss = 1.21439205, grad/param norm = 1.9523e-01, time/batch = 15.1305s	
8733/29850 (epoch 14.628), train_loss = 1.04024125, grad/param norm = 1.6751e-01, time/batch = 14.6711s	
8734/29850 (epoch 14.630), train_loss = 1.16638518, grad/param norm = 1.9051e-01, time/batch = 14.8628s	
8735/29850 (epoch 14.631), train_loss = 1.10178591, grad/param norm = 1.8363e-01, time/batch = 14.6564s	
8736/29850 (epoch 14.633), train_loss = 1.24410069, grad/param norm = 1.8540e-01, time/batch = 14.6485s	
8737/29850 (epoch 14.635), train_loss = 1.15566716, grad/param norm = 1.7567e-01, time/batch = 14.9756s	
8738/29850 (epoch 14.637), train_loss = 1.12097549, grad/param norm = 1.9349e-01, time/batch = 14.5622s	
8739/29850 (epoch 14.638), train_loss = 1.15731091, grad/param norm = 1.8369e-01, time/batch = 15.3824s	
8740/29850 (epoch 14.640), train_loss = 1.30344603, grad/param norm = 1.9842e-01, time/batch = 27.0814s	
8741/29850 (epoch 14.642), train_loss = 1.11005272, grad/param norm = 1.6202e-01, time/batch = 14.5059s	
8742/29850 (epoch 14.643), train_loss = 1.07163449, grad/param norm = 1.6423e-01, time/batch = 14.6452s	
8743/29850 (epoch 14.645), train_loss = 1.17646016, grad/param norm = 1.7199e-01, time/batch = 15.2627s	
8744/29850 (epoch 14.647), train_loss = 1.29156177, grad/param norm = 1.7761e-01, time/batch = 15.6256s	
8745/29850 (epoch 14.648), train_loss = 1.06320164, grad/param norm = 1.6974e-01, time/batch = 14.6345s	
8746/29850 (epoch 14.650), train_loss = 1.15868804, grad/param norm = 1.8566e-01, time/batch = 14.8676s	
8747/29850 (epoch 14.652), train_loss = 1.18479312, grad/param norm = 1.8944e-01, time/batch = 15.0388s	
8748/29850 (epoch 14.653), train_loss = 1.27754952, grad/param norm = 1.8628e-01, time/batch = 14.4151s	
8749/29850 (epoch 14.655), train_loss = 1.16151979, grad/param norm = 1.6835e-01, time/batch = 14.3364s	
8750/29850 (epoch 14.657), train_loss = 1.12744568, grad/param norm = 1.7692e-01, time/batch = 14.3421s	
8751/29850 (epoch 14.658), train_loss = 1.28252822, grad/param norm = 1.8224e-01, time/batch = 14.8784s	
8752/29850 (epoch 14.660), train_loss = 1.15382807, grad/param norm = 1.8267e-01, time/batch = 14.6525s	
8753/29850 (epoch 14.662), train_loss = 1.21709206, grad/param norm = 1.9361e-01, time/batch = 14.2618s	
8754/29850 (epoch 14.663), train_loss = 1.31902950, grad/param norm = 1.9462e-01, time/batch = 14.4171s	
8755/29850 (epoch 14.665), train_loss = 1.27948624, grad/param norm = 1.8935e-01, time/batch = 14.8786s	
8756/29850 (epoch 14.667), train_loss = 1.24597007, grad/param norm = 2.1603e-01, time/batch = 14.7162s	
8757/29850 (epoch 14.668), train_loss = 1.18520194, grad/param norm = 1.9575e-01, time/batch = 14.6592s	
8758/29850 (epoch 14.670), train_loss = 1.34679101, grad/param norm = 2.0515e-01, time/batch = 14.3408s	
8759/29850 (epoch 14.672), train_loss = 1.28273580, grad/param norm = 1.9583e-01, time/batch = 14.9681s	
8760/29850 (epoch 14.673), train_loss = 1.29210088, grad/param norm = 1.9573e-01, time/batch = 14.4913s	
8761/29850 (epoch 14.675), train_loss = 1.10097050, grad/param norm = 1.7424e-01, time/batch = 14.5013s	
8762/29850 (epoch 14.677), train_loss = 1.16829958, grad/param norm = 1.8235e-01, time/batch = 14.7279s	
8763/29850 (epoch 14.678), train_loss = 1.12833958, grad/param norm = 1.7777e-01, time/batch = 15.0489s	
8764/29850 (epoch 14.680), train_loss = 1.20406404, grad/param norm = 1.9578e-01, time/batch = 15.6467s	
8765/29850 (epoch 14.682), train_loss = 1.18445973, grad/param norm = 1.9033e-01, time/batch = 15.5128s	
8766/29850 (epoch 14.683), train_loss = 1.31780485, grad/param norm = 2.0248e-01, time/batch = 15.0627s	
8767/29850 (epoch 14.685), train_loss = 1.31927073, grad/param norm = 1.7773e-01, time/batch = 15.6375s	
8768/29850 (epoch 14.687), train_loss = 1.25566122, grad/param norm = 1.9043e-01, time/batch = 15.1310s	
8769/29850 (epoch 14.688), train_loss = 1.06180240, grad/param norm = 1.5896e-01, time/batch = 15.5851s	
8770/29850 (epoch 14.690), train_loss = 1.07629124, grad/param norm = 1.7878e-01, time/batch = 15.4383s	
8771/29850 (epoch 14.692), train_loss = 1.28595743, grad/param norm = 1.8271e-01, time/batch = 15.7579s	
8772/29850 (epoch 14.693), train_loss = 1.15339377, grad/param norm = 1.6232e-01, time/batch = 14.8230s	
8773/29850 (epoch 14.695), train_loss = 1.02351615, grad/param norm = 1.5301e-01, time/batch = 14.8191s	
8774/29850 (epoch 14.697), train_loss = 1.22744421, grad/param norm = 1.8009e-01, time/batch = 15.1217s	
8775/29850 (epoch 14.698), train_loss = 1.25952608, grad/param norm = 1.8464e-01, time/batch = 15.5223s	
8776/29850 (epoch 14.700), train_loss = 1.21424634, grad/param norm = 2.1459e-01, time/batch = 15.3667s	
8777/29850 (epoch 14.702), train_loss = 1.15137871, grad/param norm = 1.8187e-01, time/batch = 15.0506s	
8778/29850 (epoch 14.704), train_loss = 1.07921266, grad/param norm = 1.7664e-01, time/batch = 15.0499s	
8779/29850 (epoch 14.705), train_loss = 1.18102761, grad/param norm = 1.6968e-01, time/batch = 15.2697s	
8780/29850 (epoch 14.707), train_loss = 1.11624143, grad/param norm = 1.9357e-01, time/batch = 14.9809s	
8781/29850 (epoch 14.709), train_loss = 1.24879005, grad/param norm = 1.8940e-01, time/batch = 15.4491s	
8782/29850 (epoch 14.710), train_loss = 1.15519168, grad/param norm = 1.9623e-01, time/batch = 15.0577s	
8783/29850 (epoch 14.712), train_loss = 1.16733362, grad/param norm = 1.6885e-01, time/batch = 15.6047s	
8784/29850 (epoch 14.714), train_loss = 1.23781222, grad/param norm = 1.7806e-01, time/batch = 15.2086s	
8785/29850 (epoch 14.715), train_loss = 1.23518025, grad/param norm = 1.8211e-01, time/batch = 15.1297s	
8786/29850 (epoch 14.717), train_loss = 0.98787349, grad/param norm = 1.6866e-01, time/batch = 15.4261s	
8787/29850 (epoch 14.719), train_loss = 1.11902957, grad/param norm = 1.7828e-01, time/batch = 15.5490s	
8788/29850 (epoch 14.720), train_loss = 1.18517199, grad/param norm = 1.6549e-01, time/batch = 15.3863s	
8789/29850 (epoch 14.722), train_loss = 1.10360950, grad/param norm = 1.6631e-01, time/batch = 15.7491s	
8790/29850 (epoch 14.724), train_loss = 1.25656295, grad/param norm = 1.8770e-01, time/batch = 15.0334s	
8791/29850 (epoch 14.725), train_loss = 1.05269649, grad/param norm = 1.6942e-01, time/batch = 15.2162s	
8792/29850 (epoch 14.727), train_loss = 1.11707363, grad/param norm = 1.8728e-01, time/batch = 15.0589s	
8793/29850 (epoch 14.729), train_loss = 1.02248610, grad/param norm = 1.6659e-01, time/batch = 14.9735s	
8794/29850 (epoch 14.730), train_loss = 1.03512777, grad/param norm = 1.7196e-01, time/batch = 15.1401s	
8795/29850 (epoch 14.732), train_loss = 1.26093005, grad/param norm = 1.7368e-01, time/batch = 15.2903s	
8796/29850 (epoch 14.734), train_loss = 1.38286192, grad/param norm = 2.0189e-01, time/batch = 15.3861s	
8797/29850 (epoch 14.735), train_loss = 1.15775532, grad/param norm = 2.1484e-01, time/batch = 15.3067s	
8798/29850 (epoch 14.737), train_loss = 1.10471103, grad/param norm = 1.7795e-01, time/batch = 15.4608s	
8799/29850 (epoch 14.739), train_loss = 0.98625455, grad/param norm = 1.7112e-01, time/batch = 15.6214s	
8800/29850 (epoch 14.740), train_loss = 1.02183412, grad/param norm = 1.7107e-01, time/batch = 15.2176s	
8801/29850 (epoch 14.742), train_loss = 1.01972619, grad/param norm = 1.6516e-01, time/batch = 15.6311s	
8802/29850 (epoch 14.744), train_loss = 1.12219971, grad/param norm = 2.0158e-01, time/batch = 15.2978s	
8803/29850 (epoch 14.745), train_loss = 1.10452473, grad/param norm = 1.8610e-01, time/batch = 15.6870s	
8804/29850 (epoch 14.747), train_loss = 1.14178030, grad/param norm = 1.8802e-01, time/batch = 15.6773s	
8805/29850 (epoch 14.749), train_loss = 1.06468216, grad/param norm = 1.8781e-01, time/batch = 15.2294s	
8806/29850 (epoch 14.750), train_loss = 1.04274641, grad/param norm = 1.8463e-01, time/batch = 15.4606s	
8807/29850 (epoch 14.752), train_loss = 0.97924315, grad/param norm = 1.6424e-01, time/batch = 15.0578s	
8808/29850 (epoch 14.754), train_loss = 1.02588578, grad/param norm = 1.7509e-01, time/batch = 14.7325s	
8809/29850 (epoch 14.755), train_loss = 1.08841430, grad/param norm = 1.8475e-01, time/batch = 14.9727s	
8810/29850 (epoch 14.757), train_loss = 1.10812696, grad/param norm = 1.7891e-01, time/batch = 15.2986s	
8811/29850 (epoch 14.759), train_loss = 1.13390333, grad/param norm = 1.7096e-01, time/batch = 15.5902s	
8812/29850 (epoch 14.760), train_loss = 1.04502496, grad/param norm = 1.7107e-01, time/batch = 15.7501s	
8813/29850 (epoch 14.762), train_loss = 1.04817913, grad/param norm = 2.0495e-01, time/batch = 15.2879s	
8814/29850 (epoch 14.764), train_loss = 1.02048499, grad/param norm = 1.8289e-01, time/batch = 15.2014s	
8815/29850 (epoch 14.765), train_loss = 1.10375878, grad/param norm = 1.8362e-01, time/batch = 14.8142s	
8816/29850 (epoch 14.767), train_loss = 1.13161640, grad/param norm = 1.8063e-01, time/batch = 15.0396s	
8817/29850 (epoch 14.769), train_loss = 1.11647947, grad/param norm = 1.7641e-01, time/batch = 15.2063s	
8818/29850 (epoch 14.771), train_loss = 1.17659724, grad/param norm = 1.9196e-01, time/batch = 15.5334s	
8819/29850 (epoch 14.772), train_loss = 1.21398805, grad/param norm = 1.8494e-01, time/batch = 14.9059s	
8820/29850 (epoch 14.774), train_loss = 1.07260629, grad/param norm = 1.8282e-01, time/batch = 15.0593s	
8821/29850 (epoch 14.776), train_loss = 1.11390691, grad/param norm = 1.8158e-01, time/batch = 15.6870s	
8822/29850 (epoch 14.777), train_loss = 1.21438023, grad/param norm = 1.8556e-01, time/batch = 15.5979s	
8823/29850 (epoch 14.779), train_loss = 1.01355486, grad/param norm = 1.5902e-01, time/batch = 15.3209s	
8824/29850 (epoch 14.781), train_loss = 1.11377889, grad/param norm = 1.6207e-01, time/batch = 15.4681s	
8825/29850 (epoch 14.782), train_loss = 1.17491463, grad/param norm = 1.7324e-01, time/batch = 15.3829s	
8826/29850 (epoch 14.784), train_loss = 1.04358580, grad/param norm = 1.7970e-01, time/batch = 15.3954s	
8827/29850 (epoch 14.786), train_loss = 1.10291362, grad/param norm = 1.6706e-01, time/batch = 15.3591s	
8828/29850 (epoch 14.787), train_loss = 1.04109657, grad/param norm = 1.8369e-01, time/batch = 15.6953s	
8829/29850 (epoch 14.789), train_loss = 0.97228717, grad/param norm = 1.5437e-01, time/batch = 15.5075s	
8830/29850 (epoch 14.791), train_loss = 1.09202384, grad/param norm = 1.9790e-01, time/batch = 14.9787s	
8831/29850 (epoch 14.792), train_loss = 1.21666724, grad/param norm = 1.9419e-01, time/batch = 15.1451s	
8832/29850 (epoch 14.794), train_loss = 1.15389915, grad/param norm = 1.7282e-01, time/batch = 15.0582s	
8833/29850 (epoch 14.796), train_loss = 1.06822941, grad/param norm = 1.7254e-01, time/batch = 15.2887s	
8834/29850 (epoch 14.797), train_loss = 0.97145953, grad/param norm = 1.6749e-01, time/batch = 15.0647s	
8835/29850 (epoch 14.799), train_loss = 1.02284452, grad/param norm = 1.7632e-01, time/batch = 14.8973s	
8836/29850 (epoch 14.801), train_loss = 1.16647534, grad/param norm = 1.7862e-01, time/batch = 15.2668s	
8837/29850 (epoch 14.802), train_loss = 0.97599093, grad/param norm = 1.7384e-01, time/batch = 15.7639s	
8838/29850 (epoch 14.804), train_loss = 1.00747588, grad/param norm = 1.6653e-01, time/batch = 15.4548s	
8839/29850 (epoch 14.806), train_loss = 1.01881958, grad/param norm = 1.6654e-01, time/batch = 15.5383s	
8840/29850 (epoch 14.807), train_loss = 0.95204055, grad/param norm = 1.5068e-01, time/batch = 15.3830s	
8841/29850 (epoch 14.809), train_loss = 1.06496189, grad/param norm = 1.8602e-01, time/batch = 15.5373s	
8842/29850 (epoch 14.811), train_loss = 1.17903808, grad/param norm = 2.0787e-01, time/batch = 15.6344s	
8843/29850 (epoch 14.812), train_loss = 1.17742245, grad/param norm = 2.0163e-01, time/batch = 15.3095s	
8844/29850 (epoch 14.814), train_loss = 1.24790929, grad/param norm = 1.8660e-01, time/batch = 15.3954s	
8845/29850 (epoch 14.816), train_loss = 1.21479029, grad/param norm = 1.7512e-01, time/batch = 15.9679s	
8846/29850 (epoch 14.817), train_loss = 1.14757384, grad/param norm = 1.9132e-01, time/batch = 15.7622s	
8847/29850 (epoch 14.819), train_loss = 1.03887309, grad/param norm = 1.8242e-01, time/batch = 15.6084s	
8848/29850 (epoch 14.821), train_loss = 1.28176870, grad/param norm = 1.9711e-01, time/batch = 15.8887s	
8849/29850 (epoch 14.822), train_loss = 1.23237320, grad/param norm = 1.8656e-01, time/batch = 18.2017s	
8850/29850 (epoch 14.824), train_loss = 1.12131008, grad/param norm = 1.8055e-01, time/batch = 16.7268s	
8851/29850 (epoch 14.826), train_loss = 1.08459526, grad/param norm = 1.6793e-01, time/batch = 16.4529s	
8852/29850 (epoch 14.827), train_loss = 1.04258492, grad/param norm = 1.7475e-01, time/batch = 17.2174s	
8853/29850 (epoch 14.829), train_loss = 1.16727915, grad/param norm = 1.9702e-01, time/batch = 16.5187s	
8854/29850 (epoch 14.831), train_loss = 1.21678137, grad/param norm = 1.9141e-01, time/batch = 17.2656s	
8855/29850 (epoch 14.832), train_loss = 1.12642092, grad/param norm = 1.6972e-01, time/batch = 16.0164s	
8856/29850 (epoch 14.834), train_loss = 0.99754679, grad/param norm = 1.7523e-01, time/batch = 16.7025s	
8857/29850 (epoch 14.836), train_loss = 0.99495694, grad/param norm = 1.6484e-01, time/batch = 16.4667s	
8858/29850 (epoch 14.838), train_loss = 1.13409520, grad/param norm = 1.8742e-01, time/batch = 16.7059s	
8859/29850 (epoch 14.839), train_loss = 1.05520604, grad/param norm = 1.7118e-01, time/batch = 15.7386s	
8860/29850 (epoch 14.841), train_loss = 1.06369418, grad/param norm = 1.7396e-01, time/batch = 16.3766s	
8861/29850 (epoch 14.843), train_loss = 1.03659257, grad/param norm = 1.6507e-01, time/batch = 17.4680s	
8862/29850 (epoch 14.844), train_loss = 1.06469642, grad/param norm = 1.7955e-01, time/batch = 15.3975s	
8863/29850 (epoch 14.846), train_loss = 1.14896881, grad/param norm = 1.7206e-01, time/batch = 15.3432s	
8864/29850 (epoch 14.848), train_loss = 1.18676078, grad/param norm = 1.8493e-01, time/batch = 18.0566s	
8865/29850 (epoch 14.849), train_loss = 1.06214020, grad/param norm = 1.8770e-01, time/batch = 17.6354s	
8866/29850 (epoch 14.851), train_loss = 1.22976805, grad/param norm = 2.0071e-01, time/batch = 16.1099s	
8867/29850 (epoch 14.853), train_loss = 1.09500866, grad/param norm = 2.0560e-01, time/batch = 18.2195s	
8868/29850 (epoch 14.854), train_loss = 1.25429383, grad/param norm = 1.9893e-01, time/batch = 17.0432s	
8869/29850 (epoch 14.856), train_loss = 1.21173505, grad/param norm = 2.0815e-01, time/batch = 18.4734s	
8870/29850 (epoch 14.858), train_loss = 1.12830121, grad/param norm = 1.9803e-01, time/batch = 18.9363s	
8871/29850 (epoch 14.859), train_loss = 1.04887435, grad/param norm = 1.8168e-01, time/batch = 19.9427s	
8872/29850 (epoch 14.861), train_loss = 1.22041845, grad/param norm = 1.9016e-01, time/batch = 15.7063s	
8873/29850 (epoch 14.863), train_loss = 1.29510661, grad/param norm = 1.8140e-01, time/batch = 15.9983s	
8874/29850 (epoch 14.864), train_loss = 1.23226225, grad/param norm = 1.8535e-01, time/batch = 17.7703s	
8875/29850 (epoch 14.866), train_loss = 1.17341618, grad/param norm = 2.0190e-01, time/batch = 18.1238s	
8876/29850 (epoch 14.868), train_loss = 1.30404111, grad/param norm = 2.0034e-01, time/batch = 17.2756s	
8877/29850 (epoch 14.869), train_loss = 1.12938234, grad/param norm = 2.0226e-01, time/batch = 15.6773s	
8878/29850 (epoch 14.871), train_loss = 1.19083946, grad/param norm = 1.9356e-01, time/batch = 15.4184s	
8879/29850 (epoch 14.873), train_loss = 1.20733356, grad/param norm = 1.8901e-01, time/batch = 15.1241s	
8880/29850 (epoch 14.874), train_loss = 1.17121973, grad/param norm = 1.7497e-01, time/batch = 15.4473s	
8881/29850 (epoch 14.876), train_loss = 1.12041125, grad/param norm = 2.4265e-01, time/batch = 15.3873s	
8882/29850 (epoch 14.878), train_loss = 1.15461991, grad/param norm = 1.7318e-01, time/batch = 15.1328s	
8883/29850 (epoch 14.879), train_loss = 1.17225181, grad/param norm = 1.9524e-01, time/batch = 15.1281s	
8884/29850 (epoch 14.881), train_loss = 1.23019830, grad/param norm = 2.0116e-01, time/batch = 15.2652s	
8885/29850 (epoch 14.883), train_loss = 1.24547875, grad/param norm = 2.1105e-01, time/batch = 14.7382s	
8886/29850 (epoch 14.884), train_loss = 1.03516470, grad/param norm = 1.7827e-01, time/batch = 14.8321s	
8887/29850 (epoch 14.886), train_loss = 1.28373626, grad/param norm = 1.8628e-01, time/batch = 15.1366s	
8888/29850 (epoch 14.888), train_loss = 1.13216066, grad/param norm = 1.7452e-01, time/batch = 14.9702s	
8889/29850 (epoch 14.889), train_loss = 1.09848895, grad/param norm = 1.8404e-01, time/batch = 15.1347s	
8890/29850 (epoch 14.891), train_loss = 1.09418583, grad/param norm = 1.7339e-01, time/batch = 15.0405s	
8891/29850 (epoch 14.893), train_loss = 1.04640594, grad/param norm = 1.7567e-01, time/batch = 14.8166s	
8892/29850 (epoch 14.894), train_loss = 1.09115114, grad/param norm = 1.6655e-01, time/batch = 15.2192s	
8893/29850 (epoch 14.896), train_loss = 1.14487009, grad/param norm = 1.9094e-01, time/batch = 15.2975s	
8894/29850 (epoch 14.898), train_loss = 1.26504328, grad/param norm = 2.0751e-01, time/batch = 14.9799s	
8895/29850 (epoch 14.899), train_loss = 0.98605441, grad/param norm = 1.7233e-01, time/batch = 15.1378s	
8896/29850 (epoch 14.901), train_loss = 1.42723472, grad/param norm = 2.2044e-01, time/batch = 15.0614s	
8897/29850 (epoch 14.903), train_loss = 1.15905752, grad/param norm = 2.1076e-01, time/batch = 15.2923s	
8898/29850 (epoch 14.905), train_loss = 1.36683520, grad/param norm = 2.0168e-01, time/batch = 15.0508s	
8899/29850 (epoch 14.906), train_loss = 1.14608354, grad/param norm = 2.0994e-01, time/batch = 15.0630s	
8900/29850 (epoch 14.908), train_loss = 1.23382043, grad/param norm = 1.8795e-01, time/batch = 15.1038s	
8901/29850 (epoch 14.910), train_loss = 1.21600345, grad/param norm = 1.8246e-01, time/batch = 15.1453s	
8902/29850 (epoch 14.911), train_loss = 1.35054889, grad/param norm = 1.9577e-01, time/batch = 14.8223s	
8903/29850 (epoch 14.913), train_loss = 1.24315867, grad/param norm = 1.8096e-01, time/batch = 15.5253s	
8904/29850 (epoch 14.915), train_loss = 1.28862069, grad/param norm = 2.1174e-01, time/batch = 15.2052s	
8905/29850 (epoch 14.916), train_loss = 1.22497784, grad/param norm = 1.9288e-01, time/batch = 15.2217s	
8906/29850 (epoch 14.918), train_loss = 1.09578210, grad/param norm = 1.6832e-01, time/batch = 15.3718s	
8907/29850 (epoch 14.920), train_loss = 1.23102945, grad/param norm = 1.7633e-01, time/batch = 15.4864s	
8908/29850 (epoch 14.921), train_loss = 1.20727858, grad/param norm = 1.9932e-01, time/batch = 15.3625s	
8909/29850 (epoch 14.923), train_loss = 1.24555293, grad/param norm = 1.9038e-01, time/batch = 14.8914s	
8910/29850 (epoch 14.925), train_loss = 1.28419156, grad/param norm = 1.7889e-01, time/batch = 15.5677s	
8911/29850 (epoch 14.926), train_loss = 1.34111446, grad/param norm = 2.1733e-01, time/batch = 15.4381s	
8912/29850 (epoch 14.928), train_loss = 1.16794427, grad/param norm = 1.8021e-01, time/batch = 15.6816s	
8913/29850 (epoch 14.930), train_loss = 1.24199707, grad/param norm = 1.9864e-01, time/batch = 14.9728s	
8914/29850 (epoch 14.931), train_loss = 1.18405261, grad/param norm = 1.9440e-01, time/batch = 15.1453s	
8915/29850 (epoch 14.933), train_loss = 1.35238815, grad/param norm = 2.0006e-01, time/batch = 14.9033s	
8916/29850 (epoch 14.935), train_loss = 1.29738020, grad/param norm = 2.0563e-01, time/batch = 15.5132s	
8917/29850 (epoch 14.936), train_loss = 1.28799435, grad/param norm = 1.9904e-01, time/batch = 15.0615s	
8918/29850 (epoch 14.938), train_loss = 1.05318537, grad/param norm = 1.8119e-01, time/batch = 15.1828s	
8919/29850 (epoch 14.940), train_loss = 1.06355815, grad/param norm = 1.8852e-01, time/batch = 14.8907s	
8920/29850 (epoch 14.941), train_loss = 1.10667869, grad/param norm = 1.8525e-01, time/batch = 15.2724s	
8921/29850 (epoch 14.943), train_loss = 1.09259508, grad/param norm = 1.7961e-01, time/batch = 15.0586s	
8922/29850 (epoch 14.945), train_loss = 1.14230759, grad/param norm = 1.8567e-01, time/batch = 14.9820s	
8923/29850 (epoch 14.946), train_loss = 1.06617582, grad/param norm = 2.0171e-01, time/batch = 15.0607s	
8924/29850 (epoch 14.948), train_loss = 1.16222897, grad/param norm = 1.7016e-01, time/batch = 15.1935s	
8925/29850 (epoch 14.950), train_loss = 1.08270981, grad/param norm = 1.6715e-01, time/batch = 14.8898s	
8926/29850 (epoch 14.951), train_loss = 1.02783301, grad/param norm = 1.6387e-01, time/batch = 14.8245s	
8927/29850 (epoch 14.953), train_loss = 1.13938775, grad/param norm = 1.9543e-01, time/batch = 14.9732s	
8928/29850 (epoch 14.955), train_loss = 1.01631839, grad/param norm = 1.5766e-01, time/batch = 15.5341s	
8929/29850 (epoch 14.956), train_loss = 1.01780371, grad/param norm = 1.6554e-01, time/batch = 15.1449s	
8930/29850 (epoch 14.958), train_loss = 0.89550648, grad/param norm = 1.5990e-01, time/batch = 14.9814s	
8931/29850 (epoch 14.960), train_loss = 1.22566939, grad/param norm = 2.0503e-01, time/batch = 15.7227s	
8932/29850 (epoch 14.961), train_loss = 1.07820700, grad/param norm = 1.7619e-01, time/batch = 15.1350s	
8933/29850 (epoch 14.963), train_loss = 1.03433116, grad/param norm = 1.6396e-01, time/batch = 15.3611s	
8934/29850 (epoch 14.965), train_loss = 1.08125623, grad/param norm = 1.7910e-01, time/batch = 15.2972s	
8935/29850 (epoch 14.966), train_loss = 0.98654915, grad/param norm = 1.6574e-01, time/batch = 15.2932s	
8936/29850 (epoch 14.968), train_loss = 1.10248581, grad/param norm = 1.9779e-01, time/batch = 15.5287s	
8937/29850 (epoch 14.970), train_loss = 1.05384479, grad/param norm = 1.7240e-01, time/batch = 15.2150s	
8938/29850 (epoch 14.972), train_loss = 1.05565214, grad/param norm = 1.6777e-01, time/batch = 15.5344s	
8939/29850 (epoch 14.973), train_loss = 1.06222481, grad/param norm = 1.8352e-01, time/batch = 15.5946s	
8940/29850 (epoch 14.975), train_loss = 0.92049637, grad/param norm = 1.7319e-01, time/batch = 15.4280s	
8941/29850 (epoch 14.977), train_loss = 1.07862570, grad/param norm = 1.6169e-01, time/batch = 15.5416s	
8942/29850 (epoch 14.978), train_loss = 1.02549675, grad/param norm = 1.6028e-01, time/batch = 15.1425s	
8943/29850 (epoch 14.980), train_loss = 1.06631661, grad/param norm = 1.6519e-01, time/batch = 14.9636s	
8944/29850 (epoch 14.982), train_loss = 1.08329756, grad/param norm = 1.7381e-01, time/batch = 15.5378s	
8945/29850 (epoch 14.983), train_loss = 1.10183067, grad/param norm = 1.6526e-01, time/batch = 15.2305s	
8946/29850 (epoch 14.985), train_loss = 1.17377297, grad/param norm = 1.7865e-01, time/batch = 15.1466s	
8947/29850 (epoch 14.987), train_loss = 1.10739223, grad/param norm = 1.6228e-01, time/batch = 15.4649s	
8948/29850 (epoch 14.988), train_loss = 1.05812862, grad/param norm = 1.7097e-01, time/batch = 15.1417s	
8949/29850 (epoch 14.990), train_loss = 1.14556250, grad/param norm = 1.7082e-01, time/batch = 15.0424s	
8950/29850 (epoch 14.992), train_loss = 1.15096353, grad/param norm = 1.7616e-01, time/batch = 14.7422s	
8951/29850 (epoch 14.993), train_loss = 1.12651934, grad/param norm = 1.8060e-01, time/batch = 15.5200s	
8952/29850 (epoch 14.995), train_loss = 1.14999585, grad/param norm = 1.6936e-01, time/batch = 15.2108s	
8953/29850 (epoch 14.997), train_loss = 1.12226292, grad/param norm = 1.7785e-01, time/batch = 15.0570s	
8954/29850 (epoch 14.998), train_loss = 1.22151338, grad/param norm = 1.8682e-01, time/batch = 14.9758s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
8955/29850 (epoch 15.000), train_loss = 1.04709483, grad/param norm = 1.5971e-01, time/batch = 15.2749s	
8956/29850 (epoch 15.002), train_loss = 1.35600011, grad/param norm = 1.9879e-01, time/batch = 15.2916s	
8957/29850 (epoch 15.003), train_loss = 1.06199341, grad/param norm = 1.7076e-01, time/batch = 15.1401s	
8958/29850 (epoch 15.005), train_loss = 1.14865329, grad/param norm = 1.7028e-01, time/batch = 16.1370s	
8959/29850 (epoch 15.007), train_loss = 1.17361393, grad/param norm = 2.0123e-01, time/batch = 16.3573s	
8960/29850 (epoch 15.008), train_loss = 1.39358077, grad/param norm = 1.9321e-01, time/batch = 16.4393s	
8961/29850 (epoch 15.010), train_loss = 1.04835005, grad/param norm = 1.8438e-01, time/batch = 17.1834s	
8962/29850 (epoch 15.012), train_loss = 1.17295853, grad/param norm = 1.6952e-01, time/batch = 15.8476s	
8963/29850 (epoch 15.013), train_loss = 1.17732857, grad/param norm = 1.8770e-01, time/batch = 16.3705s	
8964/29850 (epoch 15.015), train_loss = 1.19927720, grad/param norm = 1.7544e-01, time/batch = 17.2985s	
8965/29850 (epoch 15.017), train_loss = 1.23920287, grad/param norm = 1.9745e-01, time/batch = 17.7305s	
8966/29850 (epoch 15.018), train_loss = 1.28158823, grad/param norm = 2.0890e-01, time/batch = 15.9669s	
8967/29850 (epoch 15.020), train_loss = 1.10506840, grad/param norm = 1.7697e-01, time/batch = 17.2906s	
8968/29850 (epoch 15.022), train_loss = 1.25572450, grad/param norm = 1.9649e-01, time/batch = 15.6473s	
8969/29850 (epoch 15.023), train_loss = 1.18020329, grad/param norm = 1.7040e-01, time/batch = 17.9447s	
8970/29850 (epoch 15.025), train_loss = 1.12139236, grad/param norm = 1.7425e-01, time/batch = 30.3788s	
8971/29850 (epoch 15.027), train_loss = 0.99411867, grad/param norm = 1.6722e-01, time/batch = 15.3845s	
8972/29850 (epoch 15.028), train_loss = 1.11796058, grad/param norm = 1.6943e-01, time/batch = 17.1371s	
8973/29850 (epoch 15.030), train_loss = 1.18821569, grad/param norm = 1.9032e-01, time/batch = 15.5501s	
8974/29850 (epoch 15.032), train_loss = 1.16051196, grad/param norm = 1.7338e-01, time/batch = 18.1382s	
8975/29850 (epoch 15.034), train_loss = 1.07400476, grad/param norm = 1.6565e-01, time/batch = 16.1162s	
8976/29850 (epoch 15.035), train_loss = 0.96985421, grad/param norm = 1.5394e-01, time/batch = 16.2109s	
8977/29850 (epoch 15.037), train_loss = 1.15461222, grad/param norm = 1.8519e-01, time/batch = 18.6324s	
8978/29850 (epoch 15.039), train_loss = 0.99528783, grad/param norm = 1.5336e-01, time/batch = 18.7981s	
8979/29850 (epoch 15.040), train_loss = 1.05596935, grad/param norm = 1.9193e-01, time/batch = 15.7635s	
8980/29850 (epoch 15.042), train_loss = 1.06508191, grad/param norm = 1.7593e-01, time/batch = 17.1390s	
8981/29850 (epoch 15.044), train_loss = 1.10336705, grad/param norm = 1.7101e-01, time/batch = 17.9555s	
8982/29850 (epoch 15.045), train_loss = 1.20718754, grad/param norm = 1.8701e-01, time/batch = 17.4696s	
8983/29850 (epoch 15.047), train_loss = 0.97200003, grad/param norm = 1.7044e-01, time/batch = 19.1913s	
8984/29850 (epoch 15.049), train_loss = 1.17687650, grad/param norm = 1.7769e-01, time/batch = 17.7250s	
8985/29850 (epoch 15.050), train_loss = 1.06099352, grad/param norm = 1.8456e-01, time/batch = 17.5452s	
8986/29850 (epoch 15.052), train_loss = 1.32482303, grad/param norm = 2.0325e-01, time/batch = 14.0708s	
8987/29850 (epoch 15.054), train_loss = 1.20444561, grad/param norm = 1.6977e-01, time/batch = 0.6654s	
8988/29850 (epoch 15.055), train_loss = 1.12933084, grad/param norm = 1.8583e-01, time/batch = 0.6659s	
8989/29850 (epoch 15.057), train_loss = 1.19463953, grad/param norm = 1.7807e-01, time/batch = 0.6738s	
8990/29850 (epoch 15.059), train_loss = 1.18131530, grad/param norm = 1.8546e-01, time/batch = 0.6823s	
8991/29850 (epoch 15.060), train_loss = 1.19261349, grad/param norm = 1.8911e-01, time/batch = 0.6787s	
8992/29850 (epoch 15.062), train_loss = 1.26891937, grad/param norm = 1.9935e-01, time/batch = 0.6697s	
8993/29850 (epoch 15.064), train_loss = 1.21259839, grad/param norm = 1.8532e-01, time/batch = 0.6626s	
8994/29850 (epoch 15.065), train_loss = 1.03613378, grad/param norm = 1.7273e-01, time/batch = 0.8763s	
8995/29850 (epoch 15.067), train_loss = 1.19042897, grad/param norm = 1.8164e-01, time/batch = 0.9681s	
8996/29850 (epoch 15.069), train_loss = 1.14209794, grad/param norm = 1.8053e-01, time/batch = 0.9701s	
8997/29850 (epoch 15.070), train_loss = 1.18613444, grad/param norm = 1.7853e-01, time/batch = 0.9574s	
8998/29850 (epoch 15.072), train_loss = 1.22097171, grad/param norm = 2.0656e-01, time/batch = 0.9698s	
8999/29850 (epoch 15.074), train_loss = 1.22416202, grad/param norm = 1.6404e-01, time/batch = 1.4057s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch15.08_1.6316.t7	
9000/29850 (epoch 15.075), train_loss = 1.08385309, grad/param norm = 1.7750e-01, time/batch = 1.7870s	
9001/29850 (epoch 15.077), train_loss = 1.47782884, grad/param norm = 2.1753e-01, time/batch = 17.0541s	
9002/29850 (epoch 15.079), train_loss = 1.41270529, grad/param norm = 2.7104e-01, time/batch = 19.9506s	
9003/29850 (epoch 15.080), train_loss = 1.35113991, grad/param norm = 2.0836e-01, time/batch = 17.5382s	
9004/29850 (epoch 15.082), train_loss = 1.22780205, grad/param norm = 1.8601e-01, time/batch = 19.3767s	
9005/29850 (epoch 15.084), train_loss = 1.26739852, grad/param norm = 1.9283e-01, time/batch = 18.0435s	
9006/29850 (epoch 15.085), train_loss = 1.23493522, grad/param norm = 2.1624e-01, time/batch = 16.8752s	
9007/29850 (epoch 15.087), train_loss = 1.29652286, grad/param norm = 1.7787e-01, time/batch = 18.7193s	
9008/29850 (epoch 15.089), train_loss = 1.20576045, grad/param norm = 1.8550e-01, time/batch = 16.1289s	
9009/29850 (epoch 15.090), train_loss = 1.24455405, grad/param norm = 2.0239e-01, time/batch = 16.7892s	
9010/29850 (epoch 15.092), train_loss = 1.11526521, grad/param norm = 1.7078e-01, time/batch = 15.1384s	
9011/29850 (epoch 15.094), train_loss = 1.25157307, grad/param norm = 1.8555e-01, time/batch = 17.7937s	
9012/29850 (epoch 15.095), train_loss = 1.21445626, grad/param norm = 1.9409e-01, time/batch = 15.3853s	
9013/29850 (epoch 15.097), train_loss = 0.96671841, grad/param norm = 1.6243e-01, time/batch = 17.3556s	
9014/29850 (epoch 15.099), train_loss = 1.00092143, grad/param norm = 1.7561e-01, time/batch = 15.8657s	
9015/29850 (epoch 15.101), train_loss = 1.28506320, grad/param norm = 1.9040e-01, time/batch = 18.1353s	
9016/29850 (epoch 15.102), train_loss = 1.23532198, grad/param norm = 2.0052e-01, time/batch = 16.0357s	
9017/29850 (epoch 15.104), train_loss = 1.13283803, grad/param norm = 1.6966e-01, time/batch = 15.2622s	
9018/29850 (epoch 15.106), train_loss = 1.23246204, grad/param norm = 1.7958e-01, time/batch = 17.2824s	
9019/29850 (epoch 15.107), train_loss = 0.98853463, grad/param norm = 1.6232e-01, time/batch = 18.7803s	
9020/29850 (epoch 15.109), train_loss = 1.12009184, grad/param norm = 2.0323e-01, time/batch = 16.3948s	
9021/29850 (epoch 15.111), train_loss = 1.25879914, grad/param norm = 1.8922e-01, time/batch = 17.0514s	
9022/29850 (epoch 15.112), train_loss = 1.05858634, grad/param norm = 1.6539e-01, time/batch = 17.7201s	
9023/29850 (epoch 15.114), train_loss = 1.18850008, grad/param norm = 2.0224e-01, time/batch = 16.6256s	
9024/29850 (epoch 15.116), train_loss = 1.07378766, grad/param norm = 1.6418e-01, time/batch = 16.5497s	
9025/29850 (epoch 15.117), train_loss = 1.16458275, grad/param norm = 1.8224e-01, time/batch = 15.7957s	
9026/29850 (epoch 15.119), train_loss = 1.13696605, grad/param norm = 1.7011e-01, time/batch = 19.0336s	
9027/29850 (epoch 15.121), train_loss = 0.97037368, grad/param norm = 1.8284e-01, time/batch = 17.3855s	
9028/29850 (epoch 15.122), train_loss = 1.01176022, grad/param norm = 1.6088e-01, time/batch = 17.0050s	
9029/29850 (epoch 15.124), train_loss = 1.09917932, grad/param norm = 1.8495e-01, time/batch = 17.5310s	
9030/29850 (epoch 15.126), train_loss = 1.13744028, grad/param norm = 1.8546e-01, time/batch = 17.0329s	
9031/29850 (epoch 15.127), train_loss = 1.24530285, grad/param norm = 1.8654e-01, time/batch = 17.2544s	
9032/29850 (epoch 15.129), train_loss = 1.11712745, grad/param norm = 1.7553e-01, time/batch = 17.9462s	
9033/29850 (epoch 15.131), train_loss = 1.12544256, grad/param norm = 1.7305e-01, time/batch = 18.0377s	
9034/29850 (epoch 15.132), train_loss = 1.06638612, grad/param norm = 1.9608e-01, time/batch = 16.8635s	
9035/29850 (epoch 15.134), train_loss = 1.19046141, grad/param norm = 1.8102e-01, time/batch = 17.7810s	
9036/29850 (epoch 15.136), train_loss = 1.16351313, grad/param norm = 1.7869e-01, time/batch = 17.3051s	
9037/29850 (epoch 15.137), train_loss = 1.00959461, grad/param norm = 1.6027e-01, time/batch = 18.2107s	
9038/29850 (epoch 15.139), train_loss = 1.06113424, grad/param norm = 1.7839e-01, time/batch = 16.1292s	
9039/29850 (epoch 15.141), train_loss = 1.12007039, grad/param norm = 1.7645e-01, time/batch = 15.4235s	
9040/29850 (epoch 15.142), train_loss = 1.24637340, grad/param norm = 2.0289e-01, time/batch = 18.3058s	
9041/29850 (epoch 15.144), train_loss = 1.40851769, grad/param norm = 2.3654e-01, time/batch = 15.7770s	
9042/29850 (epoch 15.146), train_loss = 1.38380879, grad/param norm = 1.9920e-01, time/batch = 16.5634s	
9043/29850 (epoch 15.147), train_loss = 1.26084457, grad/param norm = 2.0790e-01, time/batch = 16.6361s	
9044/29850 (epoch 15.149), train_loss = 1.24391752, grad/param norm = 1.9718e-01, time/batch = 17.2712s	
9045/29850 (epoch 15.151), train_loss = 1.18855720, grad/param norm = 1.8395e-01, time/batch = 15.3666s	
9046/29850 (epoch 15.152), train_loss = 1.07367939, grad/param norm = 1.6556e-01, time/batch = 15.6587s	
9047/29850 (epoch 15.154), train_loss = 1.12676474, grad/param norm = 1.8503e-01, time/batch = 17.9506s	
9048/29850 (epoch 15.156), train_loss = 1.08245025, grad/param norm = 1.6298e-01, time/batch = 17.9597s	
9049/29850 (epoch 15.157), train_loss = 1.16270721, grad/param norm = 1.6724e-01, time/batch = 15.4535s	
9050/29850 (epoch 15.159), train_loss = 1.15316776, grad/param norm = 1.7001e-01, time/batch = 17.6308s	
9051/29850 (epoch 15.161), train_loss = 1.19828595, grad/param norm = 1.8914e-01, time/batch = 18.7253s	
9052/29850 (epoch 15.162), train_loss = 1.30968560, grad/param norm = 1.9210e-01, time/batch = 15.4695s	
9053/29850 (epoch 15.164), train_loss = 1.14443460, grad/param norm = 1.7932e-01, time/batch = 18.6333s	
9054/29850 (epoch 15.166), train_loss = 1.06196952, grad/param norm = 1.5697e-01, time/batch = 15.3764s	
9055/29850 (epoch 15.168), train_loss = 0.96354030, grad/param norm = 1.6096e-01, time/batch = 18.8719s	
9056/29850 (epoch 15.169), train_loss = 1.34611496, grad/param norm = 2.1489e-01, time/batch = 17.7292s	
9057/29850 (epoch 15.171), train_loss = 1.23644795, grad/param norm = 1.8803e-01, time/batch = 18.2114s	
9058/29850 (epoch 15.173), train_loss = 1.11475664, grad/param norm = 2.0237e-01, time/batch = 17.0211s	
9059/29850 (epoch 15.174), train_loss = 1.23214609, grad/param norm = 2.0436e-01, time/batch = 16.7947s	
9060/29850 (epoch 15.176), train_loss = 1.19805906, grad/param norm = 1.8833e-01, time/batch = 19.5334s	
9061/29850 (epoch 15.178), train_loss = 1.21605220, grad/param norm = 1.8826e-01, time/batch = 16.8071s	
9062/29850 (epoch 15.179), train_loss = 0.99979065, grad/param norm = 1.6876e-01, time/batch = 16.7682s	
9063/29850 (epoch 15.181), train_loss = 1.17332921, grad/param norm = 2.0306e-01, time/batch = 16.5312s	
9064/29850 (epoch 15.183), train_loss = 1.12583215, grad/param norm = 1.7830e-01, time/batch = 17.3146s	
9065/29850 (epoch 15.184), train_loss = 1.13838872, grad/param norm = 1.8500e-01, time/batch = 18.3889s	
9066/29850 (epoch 15.186), train_loss = 1.15793393, grad/param norm = 1.8884e-01, time/batch = 16.1991s	
9067/29850 (epoch 15.188), train_loss = 1.26347509, grad/param norm = 2.0765e-01, time/batch = 18.6330s	
9068/29850 (epoch 15.189), train_loss = 1.35099015, grad/param norm = 2.0125e-01, time/batch = 18.5351s	
9069/29850 (epoch 15.191), train_loss = 1.18870975, grad/param norm = 1.7926e-01, time/batch = 16.7930s	
9070/29850 (epoch 15.193), train_loss = 1.09459258, grad/param norm = 1.7300e-01, time/batch = 18.1294s	
9071/29850 (epoch 15.194), train_loss = 1.20433026, grad/param norm = 1.9457e-01, time/batch = 18.2272s	
9072/29850 (epoch 15.196), train_loss = 1.11091787, grad/param norm = 1.7613e-01, time/batch = 17.5550s	
9073/29850 (epoch 15.198), train_loss = 1.16192659, grad/param norm = 1.8256e-01, time/batch = 15.2778s	
9074/29850 (epoch 15.199), train_loss = 1.43357779, grad/param norm = 2.0882e-01, time/batch = 15.7315s	
9075/29850 (epoch 15.201), train_loss = 1.07830785, grad/param norm = 1.8213e-01, time/batch = 15.8672s	
9076/29850 (epoch 15.203), train_loss = 0.97664545, grad/param norm = 1.8369e-01, time/batch = 16.0573s	
9077/29850 (epoch 15.204), train_loss = 1.23241238, grad/param norm = 2.0424e-01, time/batch = 17.5444s	
9078/29850 (epoch 15.206), train_loss = 1.04483769, grad/param norm = 2.1167e-01, time/batch = 16.4658s	
9079/29850 (epoch 15.208), train_loss = 1.33340919, grad/param norm = 1.9574e-01, time/batch = 17.7096s	
9080/29850 (epoch 15.209), train_loss = 1.05115012, grad/param norm = 1.7235e-01, time/batch = 16.0923s	
9081/29850 (epoch 15.211), train_loss = 1.12459561, grad/param norm = 1.7232e-01, time/batch = 18.9637s	
9082/29850 (epoch 15.213), train_loss = 1.25767977, grad/param norm = 1.9969e-01, time/batch = 16.8125s	
9083/29850 (epoch 15.214), train_loss = 1.06841771, grad/param norm = 1.6323e-01, time/batch = 15.9424s	
9084/29850 (epoch 15.216), train_loss = 1.11082291, grad/param norm = 1.7694e-01, time/batch = 15.1709s	
9085/29850 (epoch 15.218), train_loss = 1.22613061, grad/param norm = 1.8571e-01, time/batch = 17.8744s	
9086/29850 (epoch 15.219), train_loss = 1.30025486, grad/param norm = 2.0621e-01, time/batch = 17.5761s	
9087/29850 (epoch 15.221), train_loss = 1.13404279, grad/param norm = 1.8139e-01, time/batch = 15.8629s	
9088/29850 (epoch 15.223), train_loss = 1.10297320, grad/param norm = 1.9155e-01, time/batch = 17.9770s	
9089/29850 (epoch 15.224), train_loss = 1.02590727, grad/param norm = 1.9337e-01, time/batch = 15.8784s	
9090/29850 (epoch 15.226), train_loss = 1.05953033, grad/param norm = 1.5439e-01, time/batch = 17.0369s	
9091/29850 (epoch 15.228), train_loss = 1.10748894, grad/param norm = 1.6436e-01, time/batch = 17.3909s	
9092/29850 (epoch 15.229), train_loss = 1.01232194, grad/param norm = 1.6764e-01, time/batch = 16.0291s	
9093/29850 (epoch 15.231), train_loss = 1.12297831, grad/param norm = 1.7109e-01, time/batch = 17.1422s	
9094/29850 (epoch 15.233), train_loss = 1.13115986, grad/param norm = 1.9028e-01, time/batch = 15.6352s	
9095/29850 (epoch 15.235), train_loss = 1.03954084, grad/param norm = 1.5393e-01, time/batch = 17.3871s	
9096/29850 (epoch 15.236), train_loss = 1.26652879, grad/param norm = 1.9692e-01, time/batch = 17.8886s	
9097/29850 (epoch 15.238), train_loss = 1.01252463, grad/param norm = 1.7332e-01, time/batch = 16.8018s	
9098/29850 (epoch 15.240), train_loss = 1.03769989, grad/param norm = 1.5960e-01, time/batch = 15.9570s	
9099/29850 (epoch 15.241), train_loss = 1.25215342, grad/param norm = 2.0535e-01, time/batch = 17.4764s	
9100/29850 (epoch 15.243), train_loss = 1.15458965, grad/param norm = 1.8248e-01, time/batch = 16.8711s	
9101/29850 (epoch 15.245), train_loss = 1.09794263, grad/param norm = 1.9407e-01, time/batch = 15.8945s	
9102/29850 (epoch 15.246), train_loss = 1.04275270, grad/param norm = 1.7712e-01, time/batch = 16.8890s	
9103/29850 (epoch 15.248), train_loss = 1.04367369, grad/param norm = 1.7823e-01, time/batch = 17.3953s	
9104/29850 (epoch 15.250), train_loss = 1.12293953, grad/param norm = 1.7607e-01, time/batch = 17.6375s	
9105/29850 (epoch 15.251), train_loss = 1.02360034, grad/param norm = 1.8488e-01, time/batch = 16.7138s	
9106/29850 (epoch 15.253), train_loss = 0.97292415, grad/param norm = 1.9742e-01, time/batch = 16.4698s	
9107/29850 (epoch 15.255), train_loss = 1.03903227, grad/param norm = 1.7791e-01, time/batch = 17.5338s	
9108/29850 (epoch 15.256), train_loss = 1.15771179, grad/param norm = 1.8872e-01, time/batch = 16.9578s	
9109/29850 (epoch 15.258), train_loss = 1.16251938, grad/param norm = 1.8051e-01, time/batch = 19.1345s	
9110/29850 (epoch 15.260), train_loss = 1.09487866, grad/param norm = 1.6996e-01, time/batch = 18.3854s	
9111/29850 (epoch 15.261), train_loss = 1.08177807, grad/param norm = 1.8191e-01, time/batch = 16.4728s	
9112/29850 (epoch 15.263), train_loss = 1.03788351, grad/param norm = 1.8491e-01, time/batch = 18.6992s	
9113/29850 (epoch 15.265), train_loss = 1.08968236, grad/param norm = 1.8264e-01, time/batch = 18.0483s	
9114/29850 (epoch 15.266), train_loss = 1.10279468, grad/param norm = 1.8864e-01, time/batch = 18.4647s	
9115/29850 (epoch 15.268), train_loss = 1.07880678, grad/param norm = 1.5619e-01, time/batch = 17.9437s	
9116/29850 (epoch 15.270), train_loss = 1.05849894, grad/param norm = 1.6596e-01, time/batch = 16.7168s	
9117/29850 (epoch 15.271), train_loss = 1.22602976, grad/param norm = 1.7723e-01, time/batch = 18.9614s	
9118/29850 (epoch 15.273), train_loss = 0.97900819, grad/param norm = 1.6592e-01, time/batch = 16.5346s	
9119/29850 (epoch 15.275), train_loss = 0.99546924, grad/param norm = 1.7469e-01, time/batch = 17.8760s	
9120/29850 (epoch 15.276), train_loss = 0.99518802, grad/param norm = 1.6900e-01, time/batch = 17.9659s	
9121/29850 (epoch 15.278), train_loss = 1.06633073, grad/param norm = 1.6573e-01, time/batch = 16.7625s	
9122/29850 (epoch 15.280), train_loss = 1.28981197, grad/param norm = 2.1487e-01, time/batch = 17.5342s	
9123/29850 (epoch 15.281), train_loss = 1.15049293, grad/param norm = 1.9004e-01, time/batch = 16.6921s	
9124/29850 (epoch 15.283), train_loss = 1.26316001, grad/param norm = 1.9852e-01, time/batch = 16.7291s	
9125/29850 (epoch 15.285), train_loss = 1.11509837, grad/param norm = 1.8462e-01, time/batch = 17.2061s	
9126/29850 (epoch 15.286), train_loss = 1.21930555, grad/param norm = 1.8996e-01, time/batch = 18.7005s	
9127/29850 (epoch 15.288), train_loss = 1.31092895, grad/param norm = 2.3150e-01, time/batch = 19.3604s	
9128/29850 (epoch 15.290), train_loss = 1.10602066, grad/param norm = 1.8307e-01, time/batch = 17.5425s	
9129/29850 (epoch 15.291), train_loss = 1.38581240, grad/param norm = 1.9604e-01, time/batch = 18.0414s	
9130/29850 (epoch 15.293), train_loss = 1.24616020, grad/param norm = 2.0614e-01, time/batch = 16.9660s	
9131/29850 (epoch 15.295), train_loss = 1.33531790, grad/param norm = 1.8662e-01, time/batch = 15.8735s	
9132/29850 (epoch 15.296), train_loss = 1.06891871, grad/param norm = 1.7549e-01, time/batch = 17.4525s	
9133/29850 (epoch 15.298), train_loss = 0.92586419, grad/param norm = 1.7032e-01, time/batch = 18.3709s	
9134/29850 (epoch 15.300), train_loss = 1.00715881, grad/param norm = 1.6878e-01, time/batch = 17.1376s	
9135/29850 (epoch 15.302), train_loss = 1.00812023, grad/param norm = 1.7607e-01, time/batch = 16.1274s	
9136/29850 (epoch 15.303), train_loss = 1.03336813, grad/param norm = 1.6715e-01, time/batch = 14.6821s	
9137/29850 (epoch 15.305), train_loss = 1.16774166, grad/param norm = 1.7927e-01, time/batch = 15.2576s	
9138/29850 (epoch 15.307), train_loss = 1.24957280, grad/param norm = 1.9347e-01, time/batch = 19.2815s	
9139/29850 (epoch 15.308), train_loss = 1.12809101, grad/param norm = 1.9319e-01, time/batch = 17.3760s	
9140/29850 (epoch 15.310), train_loss = 1.17000656, grad/param norm = 1.9929e-01, time/batch = 16.4554s	
9141/29850 (epoch 15.312), train_loss = 1.22528762, grad/param norm = 1.8201e-01, time/batch = 17.1243s	
9142/29850 (epoch 15.313), train_loss = 1.16794138, grad/param norm = 1.8579e-01, time/batch = 16.5481s	
9143/29850 (epoch 15.315), train_loss = 1.16858705, grad/param norm = 1.8050e-01, time/batch = 18.8025s	
9144/29850 (epoch 15.317), train_loss = 1.16081912, grad/param norm = 1.7777e-01, time/batch = 16.8750s	
9145/29850 (epoch 15.318), train_loss = 1.13058436, grad/param norm = 1.8710e-01, time/batch = 16.4462s	
9146/29850 (epoch 15.320), train_loss = 1.03504270, grad/param norm = 1.5503e-01, time/batch = 17.5233s	
9147/29850 (epoch 15.322), train_loss = 1.31098086, grad/param norm = 2.0346e-01, time/batch = 17.2253s	
9148/29850 (epoch 15.323), train_loss = 1.21980382, grad/param norm = 2.1069e-01, time/batch = 15.9141s	
9149/29850 (epoch 15.325), train_loss = 1.20355833, grad/param norm = 1.8663e-01, time/batch = 16.9533s	
9150/29850 (epoch 15.327), train_loss = 1.33485381, grad/param norm = 2.0462e-01, time/batch = 18.1276s	
9151/29850 (epoch 15.328), train_loss = 1.30809856, grad/param norm = 2.0037e-01, time/batch = 17.2131s	
9152/29850 (epoch 15.330), train_loss = 1.16131952, grad/param norm = 1.7517e-01, time/batch = 15.3102s	
9153/29850 (epoch 15.332), train_loss = 1.07808488, grad/param norm = 1.7212e-01, time/batch = 16.0942s	
9154/29850 (epoch 15.333), train_loss = 1.29545666, grad/param norm = 1.9297e-01, time/batch = 17.3728s	
9155/29850 (epoch 15.335), train_loss = 1.21907559, grad/param norm = 1.8501e-01, time/batch = 17.2933s	
9156/29850 (epoch 15.337), train_loss = 1.17126472, grad/param norm = 1.8940e-01, time/batch = 16.8725s	
9157/29850 (epoch 15.338), train_loss = 1.16116745, grad/param norm = 1.7927e-01, time/batch = 17.3842s	
9158/29850 (epoch 15.340), train_loss = 1.04667593, grad/param norm = 1.7402e-01, time/batch = 17.9704s	
9159/29850 (epoch 15.342), train_loss = 1.15918390, grad/param norm = 1.8771e-01, time/batch = 18.7269s	
9160/29850 (epoch 15.343), train_loss = 1.20163694, grad/param norm = 1.9685e-01, time/batch = 17.2161s	
9161/29850 (epoch 15.345), train_loss = 1.21987870, grad/param norm = 1.9747e-01, time/batch = 17.0281s	
9162/29850 (epoch 15.347), train_loss = 1.25468342, grad/param norm = 2.0188e-01, time/batch = 18.6232s	
9163/29850 (epoch 15.348), train_loss = 1.11148308, grad/param norm = 1.7055e-01, time/batch = 16.4626s	
9164/29850 (epoch 15.350), train_loss = 1.26429576, grad/param norm = 2.1043e-01, time/batch = 18.8012s	
9165/29850 (epoch 15.352), train_loss = 1.13703801, grad/param norm = 1.7581e-01, time/batch = 17.7052s	
9166/29850 (epoch 15.353), train_loss = 1.20730305, grad/param norm = 1.8668e-01, time/batch = 17.1173s	
9167/29850 (epoch 15.355), train_loss = 1.03886769, grad/param norm = 1.7730e-01, time/batch = 18.4599s	
9168/29850 (epoch 15.357), train_loss = 1.32036596, grad/param norm = 1.9283e-01, time/batch = 16.3884s	
9169/29850 (epoch 15.358), train_loss = 1.05144187, grad/param norm = 1.7210e-01, time/batch = 17.2278s	
9170/29850 (epoch 15.360), train_loss = 1.12708988, grad/param norm = 1.7348e-01, time/batch = 15.5654s	
9171/29850 (epoch 15.362), train_loss = 1.13815492, grad/param norm = 1.7936e-01, time/batch = 15.1231s	
9172/29850 (epoch 15.363), train_loss = 1.18333487, grad/param norm = 1.8877e-01, time/batch = 16.4791s	
9173/29850 (epoch 15.365), train_loss = 1.32418975, grad/param norm = 2.0094e-01, time/batch = 15.7070s	
9174/29850 (epoch 15.367), train_loss = 1.13800853, grad/param norm = 1.9098e-01, time/batch = 17.7083s	
9175/29850 (epoch 15.369), train_loss = 1.02508511, grad/param norm = 1.6910e-01, time/batch = 15.5524s	
9176/29850 (epoch 15.370), train_loss = 0.96125148, grad/param norm = 1.7250e-01, time/batch = 19.1409s	
9177/29850 (epoch 15.372), train_loss = 1.29460541, grad/param norm = 2.0968e-01, time/batch = 16.4607s	
9178/29850 (epoch 15.374), train_loss = 1.15089510, grad/param norm = 1.9229e-01, time/batch = 17.1532s	
9179/29850 (epoch 15.375), train_loss = 1.15756931, grad/param norm = 1.7409e-01, time/batch = 17.3868s	
9180/29850 (epoch 15.377), train_loss = 1.14663409, grad/param norm = 1.8602e-01, time/batch = 18.0382s	
9181/29850 (epoch 15.379), train_loss = 1.23404615, grad/param norm = 1.9513e-01, time/batch = 19.2704s	
9182/29850 (epoch 15.380), train_loss = 1.21143268, grad/param norm = 1.9937e-01, time/batch = 16.3716s	
9183/29850 (epoch 15.382), train_loss = 1.21033894, grad/param norm = 2.0012e-01, time/batch = 17.5343s	
9184/29850 (epoch 15.384), train_loss = 1.20046179, grad/param norm = 1.8091e-01, time/batch = 26.2006s	
9185/29850 (epoch 15.385), train_loss = 1.16787462, grad/param norm = 1.9397e-01, time/batch = 18.6826s	
9186/29850 (epoch 15.387), train_loss = 1.19891245, grad/param norm = 1.9847e-01, time/batch = 18.3952s	
9187/29850 (epoch 15.389), train_loss = 1.31622667, grad/param norm = 1.9753e-01, time/batch = 16.2810s	
9188/29850 (epoch 15.390), train_loss = 1.20533638, grad/param norm = 1.7871e-01, time/batch = 18.2632s	
9189/29850 (epoch 15.392), train_loss = 1.15075232, grad/param norm = 2.0393e-01, time/batch = 18.5410s	
9190/29850 (epoch 15.394), train_loss = 1.26731208, grad/param norm = 1.9647e-01, time/batch = 16.1454s	
9191/29850 (epoch 15.395), train_loss = 1.15960361, grad/param norm = 1.8739e-01, time/batch = 19.6104s	
9192/29850 (epoch 15.397), train_loss = 1.05288836, grad/param norm = 1.8356e-01, time/batch = 18.2918s	
9193/29850 (epoch 15.399), train_loss = 1.06874745, grad/param norm = 1.7269e-01, time/batch = 17.6270s	
9194/29850 (epoch 15.400), train_loss = 1.44564919, grad/param norm = 2.0675e-01, time/batch = 17.3836s	
9195/29850 (epoch 15.402), train_loss = 1.35177620, grad/param norm = 1.9460e-01, time/batch = 15.8941s	
9196/29850 (epoch 15.404), train_loss = 1.19554059, grad/param norm = 1.9189e-01, time/batch = 18.8733s	
9197/29850 (epoch 15.405), train_loss = 1.12695810, grad/param norm = 1.9033e-01, time/batch = 15.8584s	
9198/29850 (epoch 15.407), train_loss = 1.08655835, grad/param norm = 1.7841e-01, time/batch = 18.8600s	
9199/29850 (epoch 15.409), train_loss = 1.26755593, grad/param norm = 2.0386e-01, time/batch = 16.3833s	
9200/29850 (epoch 15.410), train_loss = 1.32848182, grad/param norm = 1.8493e-01, time/batch = 17.6281s	
9201/29850 (epoch 15.412), train_loss = 1.23733715, grad/param norm = 1.8753e-01, time/batch = 16.9612s	
9202/29850 (epoch 15.414), train_loss = 1.18663627, grad/param norm = 2.1329e-01, time/batch = 16.7795s	
9203/29850 (epoch 15.415), train_loss = 1.18970379, grad/param norm = 1.7664e-01, time/batch = 17.6409s	
9204/29850 (epoch 15.417), train_loss = 1.35621719, grad/param norm = 2.0809e-01, time/batch = 16.0393s	
9205/29850 (epoch 15.419), train_loss = 1.20244699, grad/param norm = 1.9611e-01, time/batch = 17.6862s	
9206/29850 (epoch 15.420), train_loss = 1.17010006, grad/param norm = 1.7566e-01, time/batch = 17.3977s	
9207/29850 (epoch 15.422), train_loss = 1.16186249, grad/param norm = 1.8535e-01, time/batch = 17.2962s	
9208/29850 (epoch 15.424), train_loss = 1.14458305, grad/param norm = 2.0092e-01, time/batch = 18.7049s	
9209/29850 (epoch 15.425), train_loss = 1.32184805, grad/param norm = 1.8412e-01, time/batch = 17.6261s	
9210/29850 (epoch 15.427), train_loss = 0.98736802, grad/param norm = 1.7334e-01, time/batch = 18.3688s	
9211/29850 (epoch 15.429), train_loss = 1.04939861, grad/param norm = 1.7562e-01, time/batch = 18.2132s	
9212/29850 (epoch 15.430), train_loss = 0.97873979, grad/param norm = 1.6430e-01, time/batch = 16.6010s	
9213/29850 (epoch 15.432), train_loss = 1.14039504, grad/param norm = 1.8491e-01, time/batch = 18.8020s	
9214/29850 (epoch 15.434), train_loss = 1.02455201, grad/param norm = 1.6645e-01, time/batch = 16.9648s	
9215/29850 (epoch 15.436), train_loss = 1.20533913, grad/param norm = 1.9593e-01, time/batch = 16.8836s	
9216/29850 (epoch 15.437), train_loss = 1.22468184, grad/param norm = 1.8064e-01, time/batch = 18.7957s	
9217/29850 (epoch 15.439), train_loss = 1.18740731, grad/param norm = 1.7801e-01, time/batch = 17.0986s	
9218/29850 (epoch 15.441), train_loss = 1.14971010, grad/param norm = 1.6860e-01, time/batch = 16.9468s	
9219/29850 (epoch 15.442), train_loss = 1.21840829, grad/param norm = 1.9876e-01, time/batch = 16.8929s	
9220/29850 (epoch 15.444), train_loss = 1.17178181, grad/param norm = 1.7789e-01, time/batch = 17.8176s	
9221/29850 (epoch 15.446), train_loss = 1.19156839, grad/param norm = 1.8106e-01, time/batch = 16.7136s	
9222/29850 (epoch 15.447), train_loss = 1.22449263, grad/param norm = 1.8622e-01, time/batch = 17.9658s	
9223/29850 (epoch 15.449), train_loss = 1.20994978, grad/param norm = 1.9555e-01, time/batch = 17.8767s	
9224/29850 (epoch 15.451), train_loss = 1.01061038, grad/param norm = 1.6852e-01, time/batch = 15.4418s	
9225/29850 (epoch 15.452), train_loss = 0.88255998, grad/param norm = 1.4795e-01, time/batch = 17.8688s	
9226/29850 (epoch 15.454), train_loss = 1.03060717, grad/param norm = 1.6689e-01, time/batch = 18.1377s	
9227/29850 (epoch 15.456), train_loss = 1.23853130, grad/param norm = 2.0098e-01, time/batch = 15.9025s	
9228/29850 (epoch 15.457), train_loss = 1.23967284, grad/param norm = 2.4203e-01, time/batch = 16.9673s	
9229/29850 (epoch 15.459), train_loss = 1.36177815, grad/param norm = 2.2298e-01, time/batch = 17.5555s	
9230/29850 (epoch 15.461), train_loss = 1.32813972, grad/param norm = 1.9338e-01, time/batch = 17.2809s	
9231/29850 (epoch 15.462), train_loss = 1.29052343, grad/param norm = 2.1638e-01, time/batch = 17.2868s	
9232/29850 (epoch 15.464), train_loss = 1.21013894, grad/param norm = 1.7870e-01, time/batch = 19.2904s	
9233/29850 (epoch 15.466), train_loss = 1.05707814, grad/param norm = 1.7980e-01, time/batch = 16.7130s	
9234/29850 (epoch 15.467), train_loss = 1.15570597, grad/param norm = 1.9558e-01, time/batch = 15.2960s	
9235/29850 (epoch 15.469), train_loss = 1.13875649, grad/param norm = 1.7857e-01, time/batch = 16.5134s	
9236/29850 (epoch 15.471), train_loss = 1.16274511, grad/param norm = 1.8943e-01, time/batch = 17.9511s	
9237/29850 (epoch 15.472), train_loss = 1.08518805, grad/param norm = 1.7375e-01, time/batch = 17.7226s	
9238/29850 (epoch 15.474), train_loss = 1.27513020, grad/param norm = 1.9653e-01, time/batch = 16.2210s	
9239/29850 (epoch 15.476), train_loss = 1.19939965, grad/param norm = 2.4245e-01, time/batch = 15.1093s	
9240/29850 (epoch 15.477), train_loss = 1.23961637, grad/param norm = 2.3287e-01, time/batch = 17.6288s	
9241/29850 (epoch 15.479), train_loss = 1.31427307, grad/param norm = 2.1067e-01, time/batch = 18.1401s	
9242/29850 (epoch 15.481), train_loss = 1.20964634, grad/param norm = 1.8923e-01, time/batch = 15.9218s	
9243/29850 (epoch 15.482), train_loss = 1.10288199, grad/param norm = 1.6219e-01, time/batch = 19.3846s	
9244/29850 (epoch 15.484), train_loss = 1.09848133, grad/param norm = 1.7631e-01, time/batch = 18.3976s	
9245/29850 (epoch 15.486), train_loss = 1.17812083, grad/param norm = 1.9305e-01, time/batch = 16.9549s	
9246/29850 (epoch 15.487), train_loss = 1.14615708, grad/param norm = 1.9051e-01, time/batch = 17.8773s	
9247/29850 (epoch 15.489), train_loss = 1.15068209, grad/param norm = 1.8170e-01, time/batch = 16.8491s	
9248/29850 (epoch 15.491), train_loss = 1.04796808, grad/param norm = 1.6480e-01, time/batch = 17.7859s	
9249/29850 (epoch 15.492), train_loss = 1.18561238, grad/param norm = 1.9112e-01, time/batch = 18.4568s	
9250/29850 (epoch 15.494), train_loss = 1.29611391, grad/param norm = 1.7815e-01, time/batch = 16.8101s	
9251/29850 (epoch 15.496), train_loss = 1.32030743, grad/param norm = 1.8446e-01, time/batch = 18.4563s	
9252/29850 (epoch 15.497), train_loss = 1.24018658, grad/param norm = 1.7705e-01, time/batch = 16.4303s	
9253/29850 (epoch 15.499), train_loss = 1.17888349, grad/param norm = 1.7448e-01, time/batch = 17.7156s	
9254/29850 (epoch 15.501), train_loss = 1.12724776, grad/param norm = 1.7491e-01, time/batch = 17.8913s	
9255/29850 (epoch 15.503), train_loss = 1.17199894, grad/param norm = 1.8800e-01, time/batch = 17.5327s	
9256/29850 (epoch 15.504), train_loss = 1.36384576, grad/param norm = 1.8288e-01, time/batch = 15.9701s	
9257/29850 (epoch 15.506), train_loss = 1.36174315, grad/param norm = 2.0496e-01, time/batch = 16.2979s	
9258/29850 (epoch 15.508), train_loss = 1.15958865, grad/param norm = 1.9149e-01, time/batch = 17.7963s	
9259/29850 (epoch 15.509), train_loss = 0.96049614, grad/param norm = 1.7440e-01, time/batch = 15.3774s	
9260/29850 (epoch 15.511), train_loss = 1.18067367, grad/param norm = 1.9856e-01, time/batch = 18.3873s	
9261/29850 (epoch 15.513), train_loss = 1.19451731, grad/param norm = 2.0618e-01, time/batch = 18.1333s	
9262/29850 (epoch 15.514), train_loss = 1.03665743, grad/param norm = 1.7242e-01, time/batch = 17.7018s	
9263/29850 (epoch 15.516), train_loss = 1.07650138, grad/param norm = 1.7436e-01, time/batch = 18.8734s	
9264/29850 (epoch 15.518), train_loss = 1.00992929, grad/param norm = 1.7017e-01, time/batch = 16.7213s	
9265/29850 (epoch 15.519), train_loss = 1.01412379, grad/param norm = 1.7098e-01, time/batch = 18.4437s	
9266/29850 (epoch 15.521), train_loss = 0.97658353, grad/param norm = 1.5570e-01, time/batch = 18.0505s	
9267/29850 (epoch 15.523), train_loss = 1.01119224, grad/param norm = 1.5428e-01, time/batch = 18.1408s	
9268/29850 (epoch 15.524), train_loss = 1.10216584, grad/param norm = 1.8352e-01, time/batch = 17.9574s	
9269/29850 (epoch 15.526), train_loss = 1.20550673, grad/param norm = 1.8511e-01, time/batch = 16.6271s	
9270/29850 (epoch 15.528), train_loss = 1.31790129, grad/param norm = 2.0156e-01, time/batch = 16.0212s	
9271/29850 (epoch 15.529), train_loss = 1.21137320, grad/param norm = 1.9688e-01, time/batch = 15.5353s	
9272/29850 (epoch 15.531), train_loss = 1.15944451, grad/param norm = 2.1008e-01, time/batch = 16.8613s	
9273/29850 (epoch 15.533), train_loss = 1.12520152, grad/param norm = 1.8866e-01, time/batch = 15.0835s	
9274/29850 (epoch 15.534), train_loss = 1.14898714, grad/param norm = 1.7732e-01, time/batch = 16.8608s	
9275/29850 (epoch 15.536), train_loss = 1.16255637, grad/param norm = 2.0189e-01, time/batch = 17.0513s	
9276/29850 (epoch 15.538), train_loss = 1.26920689, grad/param norm = 1.8918e-01, time/batch = 16.0414s	
9277/29850 (epoch 15.539), train_loss = 1.33806252, grad/param norm = 1.9713e-01, time/batch = 17.1299s	
9278/29850 (epoch 15.541), train_loss = 0.96681238, grad/param norm = 1.6361e-01, time/batch = 18.3794s	
9279/29850 (epoch 15.543), train_loss = 1.16480200, grad/param norm = 1.7892e-01, time/batch = 18.1194s	
9280/29850 (epoch 15.544), train_loss = 1.17932331, grad/param norm = 1.7638e-01, time/batch = 17.9578s	
9281/29850 (epoch 15.546), train_loss = 1.25066819, grad/param norm = 1.8388e-01, time/batch = 17.1364s	
9282/29850 (epoch 15.548), train_loss = 1.02122269, grad/param norm = 1.7312e-01, time/batch = 18.0554s	
9283/29850 (epoch 15.549), train_loss = 1.10056445, grad/param norm = 1.7286e-01, time/batch = 16.5478s	
9284/29850 (epoch 15.551), train_loss = 1.04767812, grad/param norm = 1.7025e-01, time/batch = 16.6505s	
9285/29850 (epoch 15.553), train_loss = 1.16862779, grad/param norm = 1.8526e-01, time/batch = 18.3003s	
9286/29850 (epoch 15.554), train_loss = 0.98763123, grad/param norm = 1.6544e-01, time/batch = 15.8556s	
9287/29850 (epoch 15.556), train_loss = 1.09273139, grad/param norm = 1.7360e-01, time/batch = 17.1203s	
9288/29850 (epoch 15.558), train_loss = 1.06206770, grad/param norm = 1.7375e-01, time/batch = 17.6431s	
9289/29850 (epoch 15.559), train_loss = 1.14740917, grad/param norm = 1.7944e-01, time/batch = 15.8778s	
9290/29850 (epoch 15.561), train_loss = 1.23832293, grad/param norm = 2.0348e-01, time/batch = 15.6883s	
9291/29850 (epoch 15.563), train_loss = 1.13580647, grad/param norm = 1.7063e-01, time/batch = 15.5701s	
9292/29850 (epoch 15.564), train_loss = 1.13645622, grad/param norm = 1.8720e-01, time/batch = 15.4157s	
9293/29850 (epoch 15.566), train_loss = 1.14199453, grad/param norm = 1.9101e-01, time/batch = 15.4107s	
9294/29850 (epoch 15.568), train_loss = 1.27293377, grad/param norm = 1.7486e-01, time/batch = 17.2372s	
9295/29850 (epoch 15.570), train_loss = 1.16477921, grad/param norm = 1.7464e-01, time/batch = 16.8435s	
9296/29850 (epoch 15.571), train_loss = 1.18451842, grad/param norm = 1.9232e-01, time/batch = 17.1283s	
9297/29850 (epoch 15.573), train_loss = 1.31742031, grad/param norm = 2.5309e-01, time/batch = 17.3025s	
9298/29850 (epoch 15.575), train_loss = 1.28889851, grad/param norm = 1.8154e-01, time/batch = 17.7220s	
9299/29850 (epoch 15.576), train_loss = 1.28711636, grad/param norm = 2.0947e-01, time/batch = 16.6252s	
9300/29850 (epoch 15.578), train_loss = 1.15135150, grad/param norm = 1.8931e-01, time/batch = 15.9527s	
9301/29850 (epoch 15.580), train_loss = 1.28673598, grad/param norm = 2.0576e-01, time/batch = 15.3611s	
9302/29850 (epoch 15.581), train_loss = 1.05887258, grad/param norm = 1.7344e-01, time/batch = 17.6294s	
9303/29850 (epoch 15.583), train_loss = 1.14966421, grad/param norm = 1.8399e-01, time/batch = 18.5379s	
9304/29850 (epoch 15.585), train_loss = 1.20166727, grad/param norm = 1.6501e-01, time/batch = 14.7298s	
9305/29850 (epoch 15.586), train_loss = 1.21461392, grad/param norm = 1.8776e-01, time/batch = 16.7906s	
9306/29850 (epoch 15.588), train_loss = 1.12790849, grad/param norm = 1.9844e-01, time/batch = 17.2172s	
9307/29850 (epoch 15.590), train_loss = 1.15162718, grad/param norm = 2.0098e-01, time/batch = 18.2158s	
9308/29850 (epoch 15.591), train_loss = 1.11254859, grad/param norm = 1.8942e-01, time/batch = 15.5582s	
9309/29850 (epoch 15.593), train_loss = 1.07916192, grad/param norm = 1.6945e-01, time/batch = 16.7056s	
9310/29850 (epoch 15.595), train_loss = 1.03024922, grad/param norm = 1.5428e-01, time/batch = 16.5611s	
9311/29850 (epoch 15.596), train_loss = 1.00135390, grad/param norm = 1.6466e-01, time/batch = 18.6944s	
9312/29850 (epoch 15.598), train_loss = 1.06304721, grad/param norm = 1.7281e-01, time/batch = 15.8882s	
9313/29850 (epoch 15.600), train_loss = 1.24406552, grad/param norm = 1.9497e-01, time/batch = 18.1414s	
9314/29850 (epoch 15.601), train_loss = 1.02266844, grad/param norm = 1.6907e-01, time/batch = 19.7780s	
9315/29850 (epoch 15.603), train_loss = 1.12583876, grad/param norm = 1.8792e-01, time/batch = 16.8003s	
9316/29850 (epoch 15.605), train_loss = 1.13894419, grad/param norm = 1.8873e-01, time/batch = 19.5484s	
9317/29850 (epoch 15.606), train_loss = 0.89705679, grad/param norm = 1.5421e-01, time/batch = 16.6469s	
9318/29850 (epoch 15.608), train_loss = 1.13481373, grad/param norm = 1.8002e-01, time/batch = 16.7038s	
9319/29850 (epoch 15.610), train_loss = 1.15785130, grad/param norm = 1.7327e-01, time/batch = 16.0530s	
9320/29850 (epoch 15.611), train_loss = 1.02337694, grad/param norm = 1.6527e-01, time/batch = 18.6237s	
9321/29850 (epoch 15.613), train_loss = 0.90078121, grad/param norm = 1.5957e-01, time/batch = 18.0594s	
9322/29850 (epoch 15.615), train_loss = 1.00421560, grad/param norm = 1.6898e-01, time/batch = 15.7034s	
9323/29850 (epoch 15.616), train_loss = 1.03802927, grad/param norm = 1.7594e-01, time/batch = 18.0685s	
9324/29850 (epoch 15.618), train_loss = 1.09945085, grad/param norm = 1.7152e-01, time/batch = 17.2199s	
9325/29850 (epoch 15.620), train_loss = 1.16675108, grad/param norm = 1.9362e-01, time/batch = 16.1945s	
9326/29850 (epoch 15.621), train_loss = 1.26224564, grad/param norm = 1.9353e-01, time/batch = 15.9322s	
9327/29850 (epoch 15.623), train_loss = 1.23485841, grad/param norm = 1.8704e-01, time/batch = 19.0533s	
9328/29850 (epoch 15.625), train_loss = 1.16324225, grad/param norm = 1.8855e-01, time/batch = 18.5496s	
9329/29850 (epoch 15.626), train_loss = 1.19007648, grad/param norm = 1.9292e-01, time/batch = 18.0335s	
9330/29850 (epoch 15.628), train_loss = 1.01228684, grad/param norm = 1.6411e-01, time/batch = 17.0629s	
9331/29850 (epoch 15.630), train_loss = 1.13093060, grad/param norm = 1.9443e-01, time/batch = 16.9716s	
9332/29850 (epoch 15.631), train_loss = 1.07889220, grad/param norm = 1.7283e-01, time/batch = 16.6466s	
9333/29850 (epoch 15.633), train_loss = 1.21743146, grad/param norm = 2.0018e-01, time/batch = 17.9888s	
9334/29850 (epoch 15.635), train_loss = 1.13404224, grad/param norm = 1.8422e-01, time/batch = 17.3821s	
9335/29850 (epoch 15.637), train_loss = 1.06843258, grad/param norm = 1.8138e-01, time/batch = 16.1911s	
9336/29850 (epoch 15.638), train_loss = 1.13084110, grad/param norm = 1.8448e-01, time/batch = 15.7328s	
9337/29850 (epoch 15.640), train_loss = 1.28901582, grad/param norm = 2.0659e-01, time/batch = 19.3914s	
9338/29850 (epoch 15.642), train_loss = 1.08179008, grad/param norm = 1.6018e-01, time/batch = 16.4698s	
9339/29850 (epoch 15.643), train_loss = 1.05075166, grad/param norm = 1.7594e-01, time/batch = 15.4650s	
9340/29850 (epoch 15.645), train_loss = 1.15018973, grad/param norm = 1.7999e-01, time/batch = 15.7916s	
9341/29850 (epoch 15.647), train_loss = 1.26833684, grad/param norm = 1.7767e-01, time/batch = 18.3878s	
9342/29850 (epoch 15.648), train_loss = 1.02851390, grad/param norm = 1.7201e-01, time/batch = 17.3880s	
9343/29850 (epoch 15.650), train_loss = 1.13940941, grad/param norm = 1.8910e-01, time/batch = 15.9430s	
9344/29850 (epoch 15.652), train_loss = 1.17517755, grad/param norm = 1.9760e-01, time/batch = 17.9715s	
9345/29850 (epoch 15.653), train_loss = 1.25141661, grad/param norm = 1.9045e-01, time/batch = 15.5152s	
9346/29850 (epoch 15.655), train_loss = 1.13648482, grad/param norm = 1.6562e-01, time/batch = 16.5421s	
9347/29850 (epoch 15.657), train_loss = 1.09909287, grad/param norm = 1.8256e-01, time/batch = 18.4697s	
9348/29850 (epoch 15.658), train_loss = 1.25267210, grad/param norm = 1.8412e-01, time/batch = 18.4505s	
9349/29850 (epoch 15.660), train_loss = 1.13738307, grad/param norm = 1.8702e-01, time/batch = 16.9235s	
9350/29850 (epoch 15.662), train_loss = 1.20159194, grad/param norm = 2.0562e-01, time/batch = 18.3837s	
9351/29850 (epoch 15.663), train_loss = 1.29665254, grad/param norm = 1.9373e-01, time/batch = 16.9033s	
9352/29850 (epoch 15.665), train_loss = 1.24863644, grad/param norm = 1.8383e-01, time/batch = 18.4558s	
9353/29850 (epoch 15.667), train_loss = 1.22497360, grad/param norm = 2.2130e-01, time/batch = 16.8565s	
9354/29850 (epoch 15.668), train_loss = 1.14744679, grad/param norm = 1.8576e-01, time/batch = 16.4797s	
9355/29850 (epoch 15.670), train_loss = 1.32833129, grad/param norm = 2.5073e-01, time/batch = 17.2344s	
9356/29850 (epoch 15.672), train_loss = 1.26696507, grad/param norm = 2.0957e-01, time/batch = 17.2159s	
9357/29850 (epoch 15.673), train_loss = 1.26749891, grad/param norm = 2.0776e-01, time/batch = 16.3740s	
9358/29850 (epoch 15.675), train_loss = 1.06621060, grad/param norm = 1.7427e-01, time/batch = 17.2243s	
9359/29850 (epoch 15.677), train_loss = 1.14184448, grad/param norm = 1.8476e-01, time/batch = 16.9710s	
9360/29850 (epoch 15.678), train_loss = 1.10758667, grad/param norm = 1.7982e-01, time/batch = 15.8555s	
9361/29850 (epoch 15.680), train_loss = 1.17111884, grad/param norm = 1.9339e-01, time/batch = 17.6171s	
9362/29850 (epoch 15.682), train_loss = 1.15137523, grad/param norm = 1.8649e-01, time/batch = 17.8819s	
9363/29850 (epoch 15.683), train_loss = 1.28989456, grad/param norm = 2.0648e-01, time/batch = 16.8925s	
9364/29850 (epoch 15.685), train_loss = 1.28370397, grad/param norm = 1.7820e-01, time/batch = 18.0560s	
9365/29850 (epoch 15.687), train_loss = 1.23124338, grad/param norm = 1.9383e-01, time/batch = 17.2397s	
9366/29850 (epoch 15.688), train_loss = 1.03398669, grad/param norm = 1.6634e-01, time/batch = 17.5347s	
9367/29850 (epoch 15.690), train_loss = 1.05504153, grad/param norm = 1.7857e-01, time/batch = 17.3780s	
9368/29850 (epoch 15.692), train_loss = 1.27034033, grad/param norm = 1.8669e-01, time/batch = 15.8079s	
9369/29850 (epoch 15.693), train_loss = 1.11805251, grad/param norm = 1.6085e-01, time/batch = 15.9836s	
9370/29850 (epoch 15.695), train_loss = 1.00382266, grad/param norm = 1.5651e-01, time/batch = 17.2005s	
9371/29850 (epoch 15.697), train_loss = 1.19070530, grad/param norm = 1.8877e-01, time/batch = 18.1278s	
9372/29850 (epoch 15.698), train_loss = 1.23026649, grad/param norm = 1.7812e-01, time/batch = 17.8588s	
9373/29850 (epoch 15.700), train_loss = 1.17861784, grad/param norm = 2.0108e-01, time/batch = 19.4567s	
9374/29850 (epoch 15.702), train_loss = 1.11989229, grad/param norm = 1.8758e-01, time/batch = 16.4502s	
9375/29850 (epoch 15.704), train_loss = 1.04737920, grad/param norm = 1.6953e-01, time/batch = 17.8031s	
9376/29850 (epoch 15.705), train_loss = 1.15026036, grad/param norm = 1.6897e-01, time/batch = 17.3735s	
9377/29850 (epoch 15.707), train_loss = 1.07898053, grad/param norm = 1.7792e-01, time/batch = 15.5216s	
9378/29850 (epoch 15.709), train_loss = 1.21014280, grad/param norm = 1.8769e-01, time/batch = 14.8980s	
9379/29850 (epoch 15.710), train_loss = 1.11454653, grad/param norm = 1.8140e-01, time/batch = 18.2855s	
9380/29850 (epoch 15.712), train_loss = 1.14571253, grad/param norm = 1.6278e-01, time/batch = 18.4596s	
9381/29850 (epoch 15.714), train_loss = 1.21104228, grad/param norm = 1.7905e-01, time/batch = 17.6028s	
9382/29850 (epoch 15.715), train_loss = 1.19008204, grad/param norm = 1.7537e-01, time/batch = 17.9499s	
9383/29850 (epoch 15.717), train_loss = 0.96041887, grad/param norm = 1.7635e-01, time/batch = 17.2249s	
9384/29850 (epoch 15.719), train_loss = 1.08873544, grad/param norm = 1.7717e-01, time/batch = 17.8775s	
9385/29850 (epoch 15.720), train_loss = 1.15626120, grad/param norm = 1.7072e-01, time/batch = 16.8916s	
9386/29850 (epoch 15.722), train_loss = 1.08468564, grad/param norm = 1.7354e-01, time/batch = 17.7179s	
9387/29850 (epoch 15.724), train_loss = 1.23325757, grad/param norm = 2.0156e-01, time/batch = 17.8841s	
9388/29850 (epoch 15.725), train_loss = 1.02346249, grad/param norm = 1.7670e-01, time/batch = 17.2944s	
9389/29850 (epoch 15.727), train_loss = 1.08733483, grad/param norm = 1.8899e-01, time/batch = 17.7157s	
9390/29850 (epoch 15.729), train_loss = 0.99742978, grad/param norm = 1.6641e-01, time/batch = 18.4662s	
9391/29850 (epoch 15.730), train_loss = 1.01649375, grad/param norm = 1.7793e-01, time/batch = 28.9575s	
9392/29850 (epoch 15.732), train_loss = 1.24117042, grad/param norm = 1.7697e-01, time/batch = 19.6173s	
9393/29850 (epoch 15.734), train_loss = 1.35591822, grad/param norm = 2.1689e-01, time/batch = 17.5386s	
9394/29850 (epoch 15.735), train_loss = 1.12420094, grad/param norm = 1.8495e-01, time/batch = 17.1118s	
9395/29850 (epoch 15.737), train_loss = 1.07976484, grad/param norm = 1.9437e-01, time/batch = 18.1292s	
9396/29850 (epoch 15.739), train_loss = 0.96202690, grad/param norm = 1.7216e-01, time/batch = 18.5341s	
9397/29850 (epoch 15.740), train_loss = 1.01077588, grad/param norm = 1.7891e-01, time/batch = 16.5415s	
9398/29850 (epoch 15.742), train_loss = 0.98654654, grad/param norm = 1.6157e-01, time/batch = 18.2317s	
9399/29850 (epoch 15.744), train_loss = 1.08498949, grad/param norm = 2.0558e-01, time/batch = 17.0474s	
9400/29850 (epoch 15.745), train_loss = 1.07871481, grad/param norm = 1.8442e-01, time/batch = 16.4528s	
9401/29850 (epoch 15.747), train_loss = 1.12364118, grad/param norm = 1.8325e-01, time/batch = 17.2140s	
9402/29850 (epoch 15.749), train_loss = 1.04259298, grad/param norm = 1.9811e-01, time/batch = 16.9369s	
9403/29850 (epoch 15.750), train_loss = 1.01836927, grad/param norm = 1.8370e-01, time/batch = 17.4778s	
9404/29850 (epoch 15.752), train_loss = 0.95106695, grad/param norm = 1.6820e-01, time/batch = 16.8898s	
9405/29850 (epoch 15.754), train_loss = 1.00100010, grad/param norm = 1.7901e-01, time/batch = 17.2203s	
9406/29850 (epoch 15.755), train_loss = 1.05235785, grad/param norm = 1.8674e-01, time/batch = 18.6309s	
9407/29850 (epoch 15.757), train_loss = 1.08549090, grad/param norm = 1.7807e-01, time/batch = 16.6086s	
9408/29850 (epoch 15.759), train_loss = 1.10632916, grad/param norm = 1.7998e-01, time/batch = 17.3911s	
9409/29850 (epoch 15.760), train_loss = 1.03023788, grad/param norm = 1.8395e-01, time/batch = 17.2203s	
9410/29850 (epoch 15.762), train_loss = 1.00748431, grad/param norm = 1.6648e-01, time/batch = 17.8835s	
9411/29850 (epoch 15.764), train_loss = 0.97960597, grad/param norm = 1.9047e-01, time/batch = 16.6133s	
9412/29850 (epoch 15.765), train_loss = 1.08397532, grad/param norm = 1.7913e-01, time/batch = 17.8872s	
9413/29850 (epoch 15.767), train_loss = 1.10129071, grad/param norm = 1.7635e-01, time/batch = 16.9593s	
9414/29850 (epoch 15.769), train_loss = 1.09798789, grad/param norm = 1.8856e-01, time/batch = 16.3046s	
9415/29850 (epoch 15.771), train_loss = 1.15123419, grad/param norm = 1.9051e-01, time/batch = 16.9302s	
9416/29850 (epoch 15.772), train_loss = 1.17345495, grad/param norm = 1.9480e-01, time/batch = 18.4555s	
9417/29850 (epoch 15.774), train_loss = 1.05142674, grad/param norm = 1.7404e-01, time/batch = 18.7139s	
9418/29850 (epoch 15.776), train_loss = 1.08698344, grad/param norm = 1.8870e-01, time/batch = 17.0466s	
9419/29850 (epoch 15.777), train_loss = 1.19560072, grad/param norm = 1.9975e-01, time/batch = 17.9819s	
9420/29850 (epoch 15.779), train_loss = 0.99441133, grad/param norm = 1.5250e-01, time/batch = 16.6336s	
9421/29850 (epoch 15.781), train_loss = 1.09104511, grad/param norm = 1.6596e-01, time/batch = 15.5980s	
9422/29850 (epoch 15.782), train_loss = 1.13822175, grad/param norm = 1.7868e-01, time/batch = 17.9674s	
9423/29850 (epoch 15.784), train_loss = 1.01326190, grad/param norm = 1.8698e-01, time/batch = 15.8493s	
9424/29850 (epoch 15.786), train_loss = 1.07474936, grad/param norm = 1.6682e-01, time/batch = 16.5654s	
9425/29850 (epoch 15.787), train_loss = 1.00761291, grad/param norm = 1.9227e-01, time/batch = 17.1959s	
9426/29850 (epoch 15.789), train_loss = 0.94751993, grad/param norm = 1.5553e-01, time/batch = 17.6467s	
9427/29850 (epoch 15.791), train_loss = 1.05941708, grad/param norm = 1.9627e-01, time/batch = 17.0449s	
9428/29850 (epoch 15.792), train_loss = 1.18422728, grad/param norm = 1.9561e-01, time/batch = 16.6174s	
9429/29850 (epoch 15.794), train_loss = 1.13155029, grad/param norm = 1.7156e-01, time/batch = 17.0380s	
9430/29850 (epoch 15.796), train_loss = 1.03286498, grad/param norm = 1.6822e-01, time/batch = 17.2083s	
9431/29850 (epoch 15.797), train_loss = 0.95165964, grad/param norm = 1.7628e-01, time/batch = 18.3818s	
9432/29850 (epoch 15.799), train_loss = 0.99934212, grad/param norm = 1.6927e-01, time/batch = 16.4423s	
9433/29850 (epoch 15.801), train_loss = 1.12347051, grad/param norm = 1.8628e-01, time/batch = 18.6360s	
9434/29850 (epoch 15.802), train_loss = 0.93268775, grad/param norm = 1.7242e-01, time/batch = 16.3029s	
9435/29850 (epoch 15.804), train_loss = 0.97882238, grad/param norm = 1.6242e-01, time/batch = 16.5324s	
9436/29850 (epoch 15.806), train_loss = 0.98638431, grad/param norm = 1.6279e-01, time/batch = 16.9707s	
9437/29850 (epoch 15.807), train_loss = 0.92116221, grad/param norm = 1.4336e-01, time/batch = 16.8110s	
9438/29850 (epoch 15.809), train_loss = 1.02895659, grad/param norm = 1.8915e-01, time/batch = 16.5126s	
9439/29850 (epoch 15.811), train_loss = 1.14793342, grad/param norm = 1.9919e-01, time/batch = 17.7183s	
9440/29850 (epoch 15.812), train_loss = 1.14655333, grad/param norm = 2.0416e-01, time/batch = 17.7983s	
9441/29850 (epoch 15.814), train_loss = 1.22757378, grad/param norm = 1.8715e-01, time/batch = 18.7218s	
9442/29850 (epoch 15.816), train_loss = 1.18776345, grad/param norm = 1.7692e-01, time/batch = 15.6313s	
9443/29850 (epoch 15.817), train_loss = 1.11700341, grad/param norm = 1.8990e-01, time/batch = 17.9359s	
9444/29850 (epoch 15.819), train_loss = 0.99509894, grad/param norm = 1.8443e-01, time/batch = 17.3866s	
9445/29850 (epoch 15.821), train_loss = 1.24573885, grad/param norm = 2.0187e-01, time/batch = 17.9576s	
9446/29850 (epoch 15.822), train_loss = 1.20935034, grad/param norm = 1.8362e-01, time/batch = 16.1234s	
9447/29850 (epoch 15.824), train_loss = 1.10379343, grad/param norm = 1.8191e-01, time/batch = 18.9623s	
9448/29850 (epoch 15.826), train_loss = 1.06512234, grad/param norm = 1.6667e-01, time/batch = 17.3133s	
9449/29850 (epoch 15.827), train_loss = 1.01443442, grad/param norm = 1.7985e-01, time/batch = 15.7091s	
9450/29850 (epoch 15.829), train_loss = 1.13749936, grad/param norm = 1.9648e-01, time/batch = 18.8901s	
9451/29850 (epoch 15.831), train_loss = 1.19040734, grad/param norm = 2.0204e-01, time/batch = 15.2991s	
9452/29850 (epoch 15.832), train_loss = 1.10343467, grad/param norm = 1.7456e-01, time/batch = 17.1288s	
9453/29850 (epoch 15.834), train_loss = 0.96099705, grad/param norm = 1.7418e-01, time/batch = 18.0369s	
9454/29850 (epoch 15.836), train_loss = 0.97885381, grad/param norm = 1.6190e-01, time/batch = 17.7018s	
9455/29850 (epoch 15.838), train_loss = 1.09634114, grad/param norm = 1.8155e-01, time/batch = 17.2390s	
9456/29850 (epoch 15.839), train_loss = 1.03018968, grad/param norm = 1.6873e-01, time/batch = 18.3517s	
9457/29850 (epoch 15.841), train_loss = 1.02145853, grad/param norm = 1.6633e-01, time/batch = 17.0431s	
9458/29850 (epoch 15.843), train_loss = 1.01280655, grad/param norm = 1.6434e-01, time/batch = 18.9702s	
9459/29850 (epoch 15.844), train_loss = 1.03611586, grad/param norm = 1.9460e-01, time/batch = 15.9728s	
9460/29850 (epoch 15.846), train_loss = 1.11910340, grad/param norm = 1.7892e-01, time/batch = 17.1546s	
9461/29850 (epoch 15.848), train_loss = 1.15622705, grad/param norm = 1.8599e-01, time/batch = 18.2121s	
9462/29850 (epoch 15.849), train_loss = 1.04139495, grad/param norm = 2.1079e-01, time/batch = 17.4737s	
9463/29850 (epoch 15.851), train_loss = 1.20054873, grad/param norm = 2.0245e-01, time/batch = 15.5325s	
9464/29850 (epoch 15.853), train_loss = 1.07033640, grad/param norm = 1.9765e-01, time/batch = 18.5539s	
9465/29850 (epoch 15.854), train_loss = 1.24801517, grad/param norm = 2.0006e-01, time/batch = 19.0503s	
9466/29850 (epoch 15.856), train_loss = 1.18347014, grad/param norm = 2.0366e-01, time/batch = 16.3841s	
9467/29850 (epoch 15.858), train_loss = 1.09693668, grad/param norm = 1.9496e-01, time/batch = 17.7271s	
9468/29850 (epoch 15.859), train_loss = 1.02578432, grad/param norm = 2.0030e-01, time/batch = 17.4829s	
9469/29850 (epoch 15.861), train_loss = 1.18598307, grad/param norm = 1.8865e-01, time/batch = 17.3700s	
9470/29850 (epoch 15.863), train_loss = 1.25889747, grad/param norm = 1.9048e-01, time/batch = 18.2869s	
9471/29850 (epoch 15.864), train_loss = 1.21117393, grad/param norm = 1.8935e-01, time/batch = 17.4582s	
9472/29850 (epoch 15.866), train_loss = 1.15471750, grad/param norm = 1.9985e-01, time/batch = 18.2065s	
9473/29850 (epoch 15.868), train_loss = 1.27816308, grad/param norm = 2.0126e-01, time/batch = 17.7848s	
9474/29850 (epoch 15.869), train_loss = 1.11334305, grad/param norm = 2.1094e-01, time/batch = 17.0553s	
9475/29850 (epoch 15.871), train_loss = 1.17573133, grad/param norm = 2.0218e-01, time/batch = 15.3843s	
9476/29850 (epoch 15.873), train_loss = 1.17465665, grad/param norm = 1.9845e-01, time/batch = 17.5237s	
9477/29850 (epoch 15.874), train_loss = 1.14834267, grad/param norm = 1.8329e-01, time/batch = 18.3898s	
9478/29850 (epoch 15.876), train_loss = 1.09110087, grad/param norm = 2.4141e-01, time/batch = 16.6289s	
9479/29850 (epoch 15.878), train_loss = 1.13438201, grad/param norm = 1.8765e-01, time/batch = 18.1244s	
9480/29850 (epoch 15.879), train_loss = 1.14314970, grad/param norm = 1.9627e-01, time/batch = 16.3659s	
9481/29850 (epoch 15.881), train_loss = 1.22746290, grad/param norm = 2.1960e-01, time/batch = 18.7043s	
9482/29850 (epoch 15.883), train_loss = 1.21842710, grad/param norm = 2.0826e-01, time/batch = 17.5222s	
9483/29850 (epoch 15.884), train_loss = 1.00800317, grad/param norm = 1.7988e-01, time/batch = 17.3701s	
9484/29850 (epoch 15.886), train_loss = 1.26357765, grad/param norm = 1.9417e-01, time/batch = 18.5299s	
9485/29850 (epoch 15.888), train_loss = 1.11348820, grad/param norm = 1.8087e-01, time/batch = 18.3218s	
9486/29850 (epoch 15.889), train_loss = 1.07022137, grad/param norm = 1.7987e-01, time/batch = 16.8752s	
9487/29850 (epoch 15.891), train_loss = 1.05823662, grad/param norm = 1.7863e-01, time/batch = 16.7097s	
9488/29850 (epoch 15.893), train_loss = 1.01370732, grad/param norm = 1.6654e-01, time/batch = 16.0356s	
9489/29850 (epoch 15.894), train_loss = 1.07709406, grad/param norm = 1.7482e-01, time/batch = 17.8109s	
9490/29850 (epoch 15.896), train_loss = 1.11521475, grad/param norm = 1.7879e-01, time/batch = 17.0418s	
9491/29850 (epoch 15.898), train_loss = 1.22883403, grad/param norm = 2.0290e-01, time/batch = 18.7843s	
9492/29850 (epoch 15.899), train_loss = 0.96586563, grad/param norm = 1.8024e-01, time/batch = 18.2956s	
9493/29850 (epoch 15.901), train_loss = 1.40989009, grad/param norm = 2.4636e-01, time/batch = 16.7856s	
9494/29850 (epoch 15.903), train_loss = 1.13951130, grad/param norm = 2.3223e-01, time/batch = 16.2863s	
9495/29850 (epoch 15.905), train_loss = 1.35286351, grad/param norm = 2.0334e-01, time/batch = 17.3889s	
9496/29850 (epoch 15.906), train_loss = 1.13811911, grad/param norm = 2.2254e-01, time/batch = 18.6403s	
9497/29850 (epoch 15.908), train_loss = 1.20702531, grad/param norm = 1.8839e-01, time/batch = 17.3526s	
9498/29850 (epoch 15.910), train_loss = 1.19164631, grad/param norm = 1.9126e-01, time/batch = 17.5500s	
9499/29850 (epoch 15.911), train_loss = 1.33399090, grad/param norm = 1.9703e-01, time/batch = 16.3730s	
9500/29850 (epoch 15.913), train_loss = 1.20945662, grad/param norm = 1.6771e-01, time/batch = 17.5486s	
9501/29850 (epoch 15.915), train_loss = 1.24315119, grad/param norm = 2.0357e-01, time/batch = 18.5578s	
9502/29850 (epoch 15.916), train_loss = 1.21194116, grad/param norm = 1.9510e-01, time/batch = 17.7000s	
9503/29850 (epoch 15.918), train_loss = 1.07450788, grad/param norm = 1.7220e-01, time/batch = 17.2176s	
9504/29850 (epoch 15.920), train_loss = 1.20241757, grad/param norm = 1.7875e-01, time/batch = 15.7743s	
9505/29850 (epoch 15.921), train_loss = 1.19139402, grad/param norm = 2.0775e-01, time/batch = 16.6614s	
9506/29850 (epoch 15.923), train_loss = 1.20726356, grad/param norm = 1.8969e-01, time/batch = 17.6472s	
9507/29850 (epoch 15.925), train_loss = 1.25924588, grad/param norm = 1.8499e-01, time/batch = 17.1309s	
9508/29850 (epoch 15.926), train_loss = 1.33082686, grad/param norm = 2.2379e-01, time/batch = 17.3977s	
9509/29850 (epoch 15.928), train_loss = 1.14294139, grad/param norm = 1.8344e-01, time/batch = 17.4850s	
9510/29850 (epoch 15.930), train_loss = 1.20805222, grad/param norm = 1.9043e-01, time/batch = 15.5313s	
9511/29850 (epoch 15.931), train_loss = 1.13257847, grad/param norm = 1.8565e-01, time/batch = 18.0199s	
9512/29850 (epoch 15.933), train_loss = 1.32240800, grad/param norm = 1.9584e-01, time/batch = 15.3750s	
9513/29850 (epoch 15.935), train_loss = 1.26374083, grad/param norm = 2.0295e-01, time/batch = 18.2092s	
9514/29850 (epoch 15.936), train_loss = 1.25412576, grad/param norm = 2.0017e-01, time/batch = 16.7183s	
9515/29850 (epoch 15.938), train_loss = 1.02194312, grad/param norm = 1.6834e-01, time/batch = 16.3864s	
9516/29850 (epoch 15.940), train_loss = 1.03229448, grad/param norm = 1.8537e-01, time/batch = 17.8177s	
9517/29850 (epoch 15.941), train_loss = 1.08711341, grad/param norm = 1.9873e-01, time/batch = 18.1273s	
9518/29850 (epoch 15.943), train_loss = 1.06551016, grad/param norm = 1.8106e-01, time/batch = 18.4482s	
9519/29850 (epoch 15.945), train_loss = 1.11979021, grad/param norm = 2.0399e-01, time/batch = 19.1184s	
9520/29850 (epoch 15.946), train_loss = 1.03521021, grad/param norm = 1.7927e-01, time/batch = 18.7256s	
9521/29850 (epoch 15.948), train_loss = 1.15955787, grad/param norm = 1.8344e-01, time/batch = 17.4686s	
9522/29850 (epoch 15.950), train_loss = 1.06486311, grad/param norm = 1.6652e-01, time/batch = 19.0403s	
9523/29850 (epoch 15.951), train_loss = 1.00992202, grad/param norm = 1.6833e-01, time/batch = 16.0478s	
9524/29850 (epoch 15.953), train_loss = 1.12629065, grad/param norm = 2.0295e-01, time/batch = 16.4870s	
9525/29850 (epoch 15.955), train_loss = 0.99296252, grad/param norm = 1.6032e-01, time/batch = 18.8952s	
9526/29850 (epoch 15.956), train_loss = 0.99364130, grad/param norm = 1.6818e-01, time/batch = 16.1560s	
9527/29850 (epoch 15.958), train_loss = 0.85771092, grad/param norm = 1.5739e-01, time/batch = 17.0605s	
9528/29850 (epoch 15.960), train_loss = 1.18414578, grad/param norm = 1.8838e-01, time/batch = 15.5641s	
9529/29850 (epoch 15.961), train_loss = 1.04110889, grad/param norm = 1.6312e-01, time/batch = 16.1624s	
9530/29850 (epoch 15.963), train_loss = 1.00162947, grad/param norm = 1.6591e-01, time/batch = 17.8055s	
9531/29850 (epoch 15.965), train_loss = 1.04994878, grad/param norm = 1.8214e-01, time/batch = 16.9677s	
9532/29850 (epoch 15.966), train_loss = 0.96126363, grad/param norm = 1.7601e-01, time/batch = 15.7206s	
9533/29850 (epoch 15.968), train_loss = 1.07128880, grad/param norm = 1.8388e-01, time/batch = 16.7570s	
9534/29850 (epoch 15.970), train_loss = 1.02250754, grad/param norm = 1.7754e-01, time/batch = 15.2027s	
9535/29850 (epoch 15.972), train_loss = 1.02735267, grad/param norm = 1.7065e-01, time/batch = 16.5454s	
9536/29850 (epoch 15.973), train_loss = 1.03023729, grad/param norm = 1.7783e-01, time/batch = 18.8755s	
9537/29850 (epoch 15.975), train_loss = 0.88825061, grad/param norm = 1.7157e-01, time/batch = 14.7516s	
9538/29850 (epoch 15.977), train_loss = 1.04279292, grad/param norm = 1.6023e-01, time/batch = 16.1404s	
9539/29850 (epoch 15.978), train_loss = 0.99856158, grad/param norm = 1.5606e-01, time/batch = 17.2117s	
9540/29850 (epoch 15.980), train_loss = 1.04676488, grad/param norm = 1.6969e-01, time/batch = 17.3996s	
9541/29850 (epoch 15.982), train_loss = 1.07006934, grad/param norm = 1.8053e-01, time/batch = 19.5333s	
9542/29850 (epoch 15.983), train_loss = 1.07738938, grad/param norm = 1.6796e-01, time/batch = 16.9420s	
9543/29850 (epoch 15.985), train_loss = 1.13903943, grad/param norm = 1.7777e-01, time/batch = 19.0404s	
9544/29850 (epoch 15.987), train_loss = 1.09233791, grad/param norm = 1.7150e-01, time/batch = 17.8925s	
9545/29850 (epoch 15.988), train_loss = 1.04131137, grad/param norm = 1.7668e-01, time/batch = 16.5254s	
9546/29850 (epoch 15.990), train_loss = 1.12716820, grad/param norm = 1.7561e-01, time/batch = 16.6263s	
9547/29850 (epoch 15.992), train_loss = 1.12590985, grad/param norm = 1.7914e-01, time/batch = 17.4697s	
9548/29850 (epoch 15.993), train_loss = 1.11610766, grad/param norm = 1.7589e-01, time/batch = 18.5475s	
9549/29850 (epoch 15.995), train_loss = 1.11451048, grad/param norm = 1.6859e-01, time/batch = 16.2080s	
9550/29850 (epoch 15.997), train_loss = 1.10564800, grad/param norm = 1.8712e-01, time/batch = 18.2211s	
9551/29850 (epoch 15.998), train_loss = 1.19614862, grad/param norm = 1.8353e-01, time/batch = 17.6330s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
9552/29850 (epoch 16.000), train_loss = 1.01825135, grad/param norm = 1.6353e-01, time/batch = 16.7048s	
9553/29850 (epoch 16.002), train_loss = 1.32562730, grad/param norm = 1.9885e-01, time/batch = 15.9650s	
9554/29850 (epoch 16.003), train_loss = 1.02980107, grad/param norm = 1.6990e-01, time/batch = 17.9854s	
9555/29850 (epoch 16.005), train_loss = 1.12258896, grad/param norm = 1.6505e-01, time/batch = 17.8681s	
9556/29850 (epoch 16.007), train_loss = 1.14912818, grad/param norm = 1.9480e-01, time/batch = 16.8839s	
9557/29850 (epoch 16.008), train_loss = 1.36838792, grad/param norm = 1.9599e-01, time/batch = 17.3755s	
9558/29850 (epoch 16.010), train_loss = 1.02200814, grad/param norm = 1.9244e-01, time/batch = 16.1812s	
9559/29850 (epoch 16.012), train_loss = 1.14844881, grad/param norm = 1.7758e-01, time/batch = 16.4575s	
9560/29850 (epoch 16.013), train_loss = 1.15722476, grad/param norm = 2.0595e-01, time/batch = 18.9573s	
9561/29850 (epoch 16.015), train_loss = 1.17994477, grad/param norm = 1.7535e-01, time/batch = 17.3931s	
9562/29850 (epoch 16.017), train_loss = 1.19697261, grad/param norm = 1.9488e-01, time/batch = 17.6295s	
9563/29850 (epoch 16.018), train_loss = 1.26504230, grad/param norm = 2.1893e-01, time/batch = 17.1355s	
9564/29850 (epoch 16.020), train_loss = 1.09005208, grad/param norm = 1.8151e-01, time/batch = 18.2261s	
9565/29850 (epoch 16.022), train_loss = 1.23639969, grad/param norm = 1.8813e-01, time/batch = 16.5523s	
9566/29850 (epoch 16.023), train_loss = 1.16368387, grad/param norm = 1.7036e-01, time/batch = 15.6223s	
9567/29850 (epoch 16.025), train_loss = 1.09378871, grad/param norm = 1.7019e-01, time/batch = 17.1412s	
9568/29850 (epoch 16.027), train_loss = 0.95644830, grad/param norm = 1.6753e-01, time/batch = 16.9687s	
9569/29850 (epoch 16.028), train_loss = 1.08385346, grad/param norm = 1.6953e-01, time/batch = 17.2919s	
9570/29850 (epoch 16.030), train_loss = 1.15058986, grad/param norm = 1.8530e-01, time/batch = 17.2039s	
9571/29850 (epoch 16.032), train_loss = 1.14222155, grad/param norm = 1.7554e-01, time/batch = 17.5248s	
9572/29850 (epoch 16.034), train_loss = 1.04660103, grad/param norm = 1.7225e-01, time/batch = 18.2193s	
9573/29850 (epoch 16.035), train_loss = 0.95553901, grad/param norm = 1.6129e-01, time/batch = 17.8605s	
9574/29850 (epoch 16.037), train_loss = 1.12277439, grad/param norm = 1.8449e-01, time/batch = 17.3933s	
9575/29850 (epoch 16.039), train_loss = 0.96955955, grad/param norm = 1.5395e-01, time/batch = 16.1935s	
9576/29850 (epoch 16.040), train_loss = 1.03940948, grad/param norm = 1.9194e-01, time/batch = 17.3939s	
9577/29850 (epoch 16.042), train_loss = 1.02690709, grad/param norm = 1.7260e-01, time/batch = 17.8845s	
9578/29850 (epoch 16.044), train_loss = 1.07772178, grad/param norm = 1.7369e-01, time/batch = 18.9663s	
9579/29850 (epoch 16.045), train_loss = 1.18331902, grad/param norm = 1.7954e-01, time/batch = 17.9613s	
9580/29850 (epoch 16.047), train_loss = 0.95245933, grad/param norm = 1.6253e-01, time/batch = 17.5434s	
9581/29850 (epoch 16.049), train_loss = 1.16081922, grad/param norm = 1.8276e-01, time/batch = 17.4528s	
9582/29850 (epoch 16.050), train_loss = 1.03207693, grad/param norm = 1.7942e-01, time/batch = 18.0401s	
9583/29850 (epoch 16.052), train_loss = 1.27731662, grad/param norm = 2.0876e-01, time/batch = 17.1069s	
9584/29850 (epoch 16.054), train_loss = 1.18203026, grad/param norm = 1.8172e-01, time/batch = 16.2982s	
9585/29850 (epoch 16.055), train_loss = 1.11160305, grad/param norm = 1.7884e-01, time/batch = 17.6449s	
9586/29850 (epoch 16.057), train_loss = 1.15842824, grad/param norm = 1.7940e-01, time/batch = 15.2752s	
9587/29850 (epoch 16.059), train_loss = 1.14148255, grad/param norm = 1.8006e-01, time/batch = 18.4600s	
9588/29850 (epoch 16.060), train_loss = 1.17035549, grad/param norm = 1.8429e-01, time/batch = 18.0529s	
9589/29850 (epoch 16.062), train_loss = 1.25520742, grad/param norm = 2.0180e-01, time/batch = 19.3802s	
9590/29850 (epoch 16.064), train_loss = 1.18499609, grad/param norm = 1.9974e-01, time/batch = 16.8869s	
9591/29850 (epoch 16.065), train_loss = 1.01502569, grad/param norm = 1.8375e-01, time/batch = 17.4548s	
9592/29850 (epoch 16.067), train_loss = 1.16202820, grad/param norm = 1.8152e-01, time/batch = 17.8904s	
9593/29850 (epoch 16.069), train_loss = 1.12086324, grad/param norm = 1.8674e-01, time/batch = 16.5474s	
9594/29850 (epoch 16.070), train_loss = 1.16312666, grad/param norm = 1.7666e-01, time/batch = 18.3815s	
9595/29850 (epoch 16.072), train_loss = 1.18235943, grad/param norm = 2.0210e-01, time/batch = 17.2159s	
9596/29850 (epoch 16.074), train_loss = 1.19125616, grad/param norm = 1.6292e-01, time/batch = 18.6151s	
9597/29850 (epoch 16.075), train_loss = 1.05397870, grad/param norm = 1.8113e-01, time/batch = 28.4593s	
9598/29850 (epoch 16.077), train_loss = 1.17090098, grad/param norm = 1.9637e-01, time/batch = 17.1525s	
9599/29850 (epoch 16.079), train_loss = 1.36594594, grad/param norm = 2.2767e-01, time/batch = 17.2062s	
9600/29850 (epoch 16.080), train_loss = 1.32538644, grad/param norm = 2.1797e-01, time/batch = 16.1390s	
9601/29850 (epoch 16.082), train_loss = 1.19974507, grad/param norm = 1.8970e-01, time/batch = 17.9771s	
9602/29850 (epoch 16.084), train_loss = 1.25560683, grad/param norm = 1.9931e-01, time/batch = 15.8686s	
9603/29850 (epoch 16.085), train_loss = 1.22125093, grad/param norm = 1.9675e-01, time/batch = 16.4669s	
9604/29850 (epoch 16.087), train_loss = 1.27225135, grad/param norm = 1.8773e-01, time/batch = 19.8734s	
9605/29850 (epoch 16.089), train_loss = 1.16435895, grad/param norm = 1.8321e-01, time/batch = 16.5598s	
9606/29850 (epoch 16.090), train_loss = 1.22745485, grad/param norm = 1.9601e-01, time/batch = 17.2118s	
9607/29850 (epoch 16.092), train_loss = 1.08989719, grad/param norm = 1.7034e-01, time/batch = 17.5624s	
9608/29850 (epoch 16.094), train_loss = 1.22774904, grad/param norm = 2.4679e-01, time/batch = 15.9430s	
9609/29850 (epoch 16.095), train_loss = 1.18930792, grad/param norm = 2.2004e-01, time/batch = 18.7902s	
9610/29850 (epoch 16.097), train_loss = 0.93910128, grad/param norm = 1.6154e-01, time/batch = 16.5865s	
9611/29850 (epoch 16.099), train_loss = 0.97480093, grad/param norm = 1.7230e-01, time/batch = 17.7922s	
9612/29850 (epoch 16.101), train_loss = 1.25792784, grad/param norm = 1.9378e-01, time/batch = 16.7235s	
9613/29850 (epoch 16.102), train_loss = 1.20450683, grad/param norm = 1.9756e-01, time/batch = 17.0321s	
9614/29850 (epoch 16.104), train_loss = 1.10046165, grad/param norm = 1.7143e-01, time/batch = 16.6345s	
9615/29850 (epoch 16.106), train_loss = 1.21705337, grad/param norm = 1.8053e-01, time/batch = 18.8783s	
9616/29850 (epoch 16.107), train_loss = 0.97415448, grad/param norm = 1.6352e-01, time/batch = 17.8014s	
9617/29850 (epoch 16.109), train_loss = 1.10209992, grad/param norm = 1.9962e-01, time/batch = 16.7738s	
9618/29850 (epoch 16.111), train_loss = 1.23429482, grad/param norm = 1.8792e-01, time/batch = 18.0209s	
9619/29850 (epoch 16.112), train_loss = 1.03493838, grad/param norm = 1.6261e-01, time/batch = 15.8395s	
9620/29850 (epoch 16.114), train_loss = 1.18491364, grad/param norm = 2.4540e-01, time/batch = 16.2267s	
9621/29850 (epoch 16.116), train_loss = 1.06372428, grad/param norm = 1.7815e-01, time/batch = 19.2918s	
9622/29850 (epoch 16.117), train_loss = 1.14222939, grad/param norm = 1.7612e-01, time/batch = 17.7933s	
9623/29850 (epoch 16.119), train_loss = 1.10804651, grad/param norm = 1.6764e-01, time/batch = 16.1268s	
9624/29850 (epoch 16.121), train_loss = 0.95297565, grad/param norm = 1.8072e-01, time/batch = 18.3814s	
9625/29850 (epoch 16.122), train_loss = 0.99315356, grad/param norm = 1.6155e-01, time/batch = 17.3074s	
9626/29850 (epoch 16.124), train_loss = 1.05339993, grad/param norm = 1.7112e-01, time/batch = 18.4770s	
9627/29850 (epoch 16.126), train_loss = 1.10797196, grad/param norm = 1.8450e-01, time/batch = 16.6234s	
9628/29850 (epoch 16.127), train_loss = 1.24124481, grad/param norm = 2.1182e-01, time/batch = 17.3154s	
9629/29850 (epoch 16.129), train_loss = 1.09939579, grad/param norm = 1.8530e-01, time/batch = 17.2169s	
9630/29850 (epoch 16.131), train_loss = 1.09238935, grad/param norm = 1.8185e-01, time/batch = 17.4555s	
9631/29850 (epoch 16.132), train_loss = 1.03112353, grad/param norm = 1.9650e-01, time/batch = 17.0561s	
9632/29850 (epoch 16.134), train_loss = 1.16303602, grad/param norm = 1.8117e-01, time/batch = 16.8009s	
9633/29850 (epoch 16.136), train_loss = 1.12805763, grad/param norm = 1.7964e-01, time/batch = 17.6323s	
9634/29850 (epoch 16.137), train_loss = 0.97002124, grad/param norm = 1.6047e-01, time/batch = 17.2905s	
9635/29850 (epoch 16.139), train_loss = 1.04195375, grad/param norm = 1.7953e-01, time/batch = 17.8794s	
9636/29850 (epoch 16.141), train_loss = 1.09014717, grad/param norm = 1.7827e-01, time/batch = 17.0521s	
9637/29850 (epoch 16.142), train_loss = 1.21598746, grad/param norm = 2.0828e-01, time/batch = 15.9194s	
9638/29850 (epoch 16.144), train_loss = 1.36672150, grad/param norm = 2.1120e-01, time/batch = 16.7219s	
9639/29850 (epoch 16.146), train_loss = 1.36345175, grad/param norm = 2.0077e-01, time/batch = 18.4808s	
9640/29850 (epoch 16.147), train_loss = 1.22121934, grad/param norm = 2.0581e-01, time/batch = 15.8314s	
9641/29850 (epoch 16.149), train_loss = 1.20523225, grad/param norm = 1.9386e-01, time/batch = 15.4799s	
9642/29850 (epoch 16.151), train_loss = 1.17792586, grad/param norm = 1.8825e-01, time/batch = 17.3963s	
9643/29850 (epoch 16.152), train_loss = 1.06211795, grad/param norm = 1.6186e-01, time/batch = 18.0544s	
9644/29850 (epoch 16.154), train_loss = 1.09178642, grad/param norm = 1.8357e-01, time/batch = 16.7757s	
9645/29850 (epoch 16.156), train_loss = 1.05046512, grad/param norm = 1.6087e-01, time/batch = 18.1939s	
9646/29850 (epoch 16.157), train_loss = 1.14193666, grad/param norm = 1.7472e-01, time/batch = 16.2234s	
9647/29850 (epoch 16.159), train_loss = 1.12029491, grad/param norm = 1.8106e-01, time/batch = 18.2981s	
9648/29850 (epoch 16.161), train_loss = 1.17572803, grad/param norm = 1.9057e-01, time/batch = 12.6652s	
9649/29850 (epoch 16.162), train_loss = 1.28466138, grad/param norm = 2.0137e-01, time/batch = 0.6735s	
9650/29850 (epoch 16.164), train_loss = 1.12032189, grad/param norm = 1.8200e-01, time/batch = 0.6748s	
9651/29850 (epoch 16.166), train_loss = 1.02819273, grad/param norm = 1.5864e-01, time/batch = 0.6776s	
9652/29850 (epoch 16.168), train_loss = 0.93677841, grad/param norm = 1.5931e-01, time/batch = 0.6637s	
9653/29850 (epoch 16.169), train_loss = 1.31508519, grad/param norm = 2.1677e-01, time/batch = 0.6729s	
9654/29850 (epoch 16.171), train_loss = 1.20323022, grad/param norm = 1.8663e-01, time/batch = 0.6676s	
9655/29850 (epoch 16.173), train_loss = 1.07659528, grad/param norm = 2.0534e-01, time/batch = 0.6617s	
9656/29850 (epoch 16.174), train_loss = 1.19998745, grad/param norm = 2.0122e-01, time/batch = 0.8960s	
9657/29850 (epoch 16.176), train_loss = 1.17523014, grad/param norm = 1.9330e-01, time/batch = 0.9920s	
9658/29850 (epoch 16.178), train_loss = 1.19771572, grad/param norm = 1.9330e-01, time/batch = 0.9695s	
9659/29850 (epoch 16.179), train_loss = 0.98272118, grad/param norm = 1.7284e-01, time/batch = 0.9665s	
9660/29850 (epoch 16.181), train_loss = 1.14305277, grad/param norm = 1.9932e-01, time/batch = 0.9593s	
9661/29850 (epoch 16.183), train_loss = 1.11363347, grad/param norm = 1.9141e-01, time/batch = 1.5292s	
9662/29850 (epoch 16.184), train_loss = 1.12041658, grad/param norm = 1.8227e-01, time/batch = 1.7940s	
9663/29850 (epoch 16.186), train_loss = 1.16168320, grad/param norm = 2.0112e-01, time/batch = 1.7999s	
9664/29850 (epoch 16.188), train_loss = 1.25476535, grad/param norm = 2.1878e-01, time/batch = 14.8556s	
9665/29850 (epoch 16.189), train_loss = 1.32059324, grad/param norm = 2.0679e-01, time/batch = 18.1250s	
9666/29850 (epoch 16.191), train_loss = 1.18518610, grad/param norm = 1.9112e-01, time/batch = 16.7004s	
9667/29850 (epoch 16.193), train_loss = 1.07924818, grad/param norm = 1.7678e-01, time/batch = 17.6733s	
9668/29850 (epoch 16.194), train_loss = 1.18486730, grad/param norm = 2.0729e-01, time/batch = 17.4532s	
9669/29850 (epoch 16.196), train_loss = 1.08842233, grad/param norm = 1.8455e-01, time/batch = 17.3018s	
9670/29850 (epoch 16.198), train_loss = 1.13457673, grad/param norm = 1.8148e-01, time/batch = 16.8869s	
9671/29850 (epoch 16.199), train_loss = 1.38271324, grad/param norm = 2.0603e-01, time/batch = 16.0738s	
9672/29850 (epoch 16.201), train_loss = 1.05132576, grad/param norm = 1.7557e-01, time/batch = 18.8003s	
9673/29850 (epoch 16.203), train_loss = 0.95553855, grad/param norm = 1.9277e-01, time/batch = 16.1365s	
9674/29850 (epoch 16.204), train_loss = 1.21135790, grad/param norm = 2.0561e-01, time/batch = 18.7166s	
9675/29850 (epoch 16.206), train_loss = 1.03144628, grad/param norm = 2.0424e-01, time/batch = 15.3722s	
9676/29850 (epoch 16.208), train_loss = 1.31097688, grad/param norm = 2.0041e-01, time/batch = 17.3766s	
9677/29850 (epoch 16.209), train_loss = 1.01893921, grad/param norm = 1.6301e-01, time/batch = 19.6124s	
9678/29850 (epoch 16.211), train_loss = 1.09084464, grad/param norm = 1.7065e-01, time/batch = 17.2964s	
9679/29850 (epoch 16.213), train_loss = 1.22985332, grad/param norm = 1.9720e-01, time/batch = 17.6298s	
9680/29850 (epoch 16.214), train_loss = 1.03952073, grad/param norm = 1.6236e-01, time/batch = 17.1315s	
9681/29850 (epoch 16.216), train_loss = 1.08956012, grad/param norm = 1.8049e-01, time/batch = 17.2084s	
9682/29850 (epoch 16.218), train_loss = 1.20741444, grad/param norm = 1.9120e-01, time/batch = 16.3859s	
9683/29850 (epoch 16.219), train_loss = 1.26707902, grad/param norm = 2.0819e-01, time/batch = 15.3888s	
9684/29850 (epoch 16.221), train_loss = 1.11611721, grad/param norm = 1.8369e-01, time/batch = 16.9534s	
9685/29850 (epoch 16.223), train_loss = 1.07009052, grad/param norm = 1.9346e-01, time/batch = 16.9800s	
9686/29850 (epoch 16.224), train_loss = 0.99801673, grad/param norm = 1.8821e-01, time/batch = 17.9736s	
9687/29850 (epoch 16.226), train_loss = 1.03961233, grad/param norm = 1.5251e-01, time/batch = 17.0548s	
9688/29850 (epoch 16.228), train_loss = 1.09124507, grad/param norm = 1.7055e-01, time/batch = 18.3115s	
9689/29850 (epoch 16.229), train_loss = 0.98933239, grad/param norm = 1.6803e-01, time/batch = 16.7127s	
9690/29850 (epoch 16.231), train_loss = 1.09210490, grad/param norm = 1.7147e-01, time/batch = 17.1250s	
9691/29850 (epoch 16.233), train_loss = 1.08572169, grad/param norm = 1.8860e-01, time/batch = 18.9533s	
9692/29850 (epoch 16.235), train_loss = 1.01781555, grad/param norm = 1.6026e-01, time/batch = 18.4664s	
9693/29850 (epoch 16.236), train_loss = 1.24751555, grad/param norm = 2.0800e-01, time/batch = 18.6223s	
9694/29850 (epoch 16.238), train_loss = 0.98288787, grad/param norm = 1.7018e-01, time/batch = 18.2884s	
9695/29850 (epoch 16.240), train_loss = 1.01548403, grad/param norm = 1.6466e-01, time/batch = 18.4667s	
9696/29850 (epoch 16.241), train_loss = 1.21892053, grad/param norm = 2.1379e-01, time/batch = 18.8666s	
9697/29850 (epoch 16.243), train_loss = 1.12331888, grad/param norm = 1.9057e-01, time/batch = 17.3660s	
9698/29850 (epoch 16.245), train_loss = 1.07287909, grad/param norm = 1.9464e-01, time/batch = 15.9933s	
9699/29850 (epoch 16.246), train_loss = 1.02279060, grad/param norm = 1.7377e-01, time/batch = 17.1445s	
9700/29850 (epoch 16.248), train_loss = 1.01086516, grad/param norm = 1.6943e-01, time/batch = 16.1255s	
9701/29850 (epoch 16.250), train_loss = 1.09393858, grad/param norm = 1.7852e-01, time/batch = 16.4557s	
9702/29850 (epoch 16.251), train_loss = 0.99219433, grad/param norm = 1.8981e-01, time/batch = 17.2830s	
9703/29850 (epoch 16.253), train_loss = 0.92966576, grad/param norm = 1.6704e-01, time/batch = 18.5261s	
9704/29850 (epoch 16.255), train_loss = 1.00906573, grad/param norm = 1.7543e-01, time/batch = 17.0449s	
9705/29850 (epoch 16.256), train_loss = 1.13978578, grad/param norm = 1.9522e-01, time/batch = 18.7206s	
9706/29850 (epoch 16.258), train_loss = 1.12794133, grad/param norm = 1.8049e-01, time/batch = 18.6355s	
9707/29850 (epoch 16.260), train_loss = 1.08996441, grad/param norm = 1.7779e-01, time/batch = 15.6365s	
9708/29850 (epoch 16.261), train_loss = 1.04442281, grad/param norm = 1.8206e-01, time/batch = 17.8047s	
9709/29850 (epoch 16.263), train_loss = 1.02188517, grad/param norm = 1.7470e-01, time/batch = 18.2020s	
9710/29850 (epoch 16.265), train_loss = 1.06994464, grad/param norm = 1.8921e-01, time/batch = 17.3866s	
9711/29850 (epoch 16.266), train_loss = 1.07629545, grad/param norm = 2.0364e-01, time/batch = 16.8795s	
9712/29850 (epoch 16.268), train_loss = 1.05701247, grad/param norm = 1.6986e-01, time/batch = 17.8726s	
9713/29850 (epoch 16.270), train_loss = 1.02572508, grad/param norm = 1.6743e-01, time/batch = 18.2150s	
9714/29850 (epoch 16.271), train_loss = 1.21313991, grad/param norm = 1.8135e-01, time/batch = 16.3815s	
9715/29850 (epoch 16.273), train_loss = 0.95410228, grad/param norm = 1.8457e-01, time/batch = 16.9666s	
9716/29850 (epoch 16.275), train_loss = 0.96051213, grad/param norm = 1.7582e-01, time/batch = 16.4670s	
9717/29850 (epoch 16.276), train_loss = 0.97410010, grad/param norm = 1.6434e-01, time/batch = 17.7145s	
9718/29850 (epoch 16.278), train_loss = 1.04681780, grad/param norm = 1.7899e-01, time/batch = 16.6234s	
9719/29850 (epoch 16.280), train_loss = 1.25528280, grad/param norm = 2.0887e-01, time/batch = 17.5405s	
9720/29850 (epoch 16.281), train_loss = 1.13704124, grad/param norm = 1.9562e-01, time/batch = 18.7933s	
9721/29850 (epoch 16.283), train_loss = 1.25640915, grad/param norm = 2.1206e-01, time/batch = 17.6943s	
9722/29850 (epoch 16.285), train_loss = 1.08712042, grad/param norm = 1.7759e-01, time/batch = 15.9509s	
9723/29850 (epoch 16.286), train_loss = 1.20102085, grad/param norm = 1.9096e-01, time/batch = 18.1965s	
9724/29850 (epoch 16.288), train_loss = 1.27839347, grad/param norm = 2.2818e-01, time/batch = 16.6873s	
9725/29850 (epoch 16.290), train_loss = 1.08883873, grad/param norm = 1.9334e-01, time/batch = 18.1366s	
9726/29850 (epoch 16.291), train_loss = 1.34529181, grad/param norm = 1.9241e-01, time/batch = 18.0509s	
9727/29850 (epoch 16.293), train_loss = 1.23559019, grad/param norm = 2.7869e-01, time/batch = 17.3786s	
9728/29850 (epoch 16.295), train_loss = 1.33097122, grad/param norm = 2.4000e-01, time/batch = 17.7120s	
9729/29850 (epoch 16.296), train_loss = 1.04811037, grad/param norm = 1.9813e-01, time/batch = 17.7298s	
9730/29850 (epoch 16.298), train_loss = 0.89396086, grad/param norm = 1.6782e-01, time/batch = 14.9035s	
9731/29850 (epoch 16.300), train_loss = 0.99169019, grad/param norm = 1.6819e-01, time/batch = 15.9658s	
9732/29850 (epoch 16.302), train_loss = 0.97928293, grad/param norm = 1.7039e-01, time/batch = 17.3148s	
9733/29850 (epoch 16.303), train_loss = 1.00879343, grad/param norm = 1.6562e-01, time/batch = 18.6310s	
9734/29850 (epoch 16.305), train_loss = 1.14876799, grad/param norm = 1.8485e-01, time/batch = 18.2805s	
9735/29850 (epoch 16.307), train_loss = 1.20677025, grad/param norm = 1.9000e-01, time/batch = 15.6399s	
9736/29850 (epoch 16.308), train_loss = 1.09953161, grad/param norm = 1.9290e-01, time/batch = 17.5484s	
9737/29850 (epoch 16.310), train_loss = 1.14264248, grad/param norm = 2.0185e-01, time/batch = 17.7209s	
9738/29850 (epoch 16.312), train_loss = 1.19651924, grad/param norm = 1.9434e-01, time/batch = 16.4608s	
9739/29850 (epoch 16.313), train_loss = 1.13301161, grad/param norm = 1.9632e-01, time/batch = 18.6362s	
9740/29850 (epoch 16.315), train_loss = 1.14246061, grad/param norm = 1.7048e-01, time/batch = 18.5446s	
9741/29850 (epoch 16.317), train_loss = 1.13014772, grad/param norm = 1.8617e-01, time/batch = 17.5875s	
9742/29850 (epoch 16.318), train_loss = 1.11442709, grad/param norm = 1.8897e-01, time/batch = 15.5387s	
9743/29850 (epoch 16.320), train_loss = 1.01765159, grad/param norm = 1.5876e-01, time/batch = 18.7985s	
9744/29850 (epoch 16.322), train_loss = 1.28265390, grad/param norm = 2.0669e-01, time/batch = 18.6357s	
9745/29850 (epoch 16.323), train_loss = 1.19553587, grad/param norm = 2.1476e-01, time/batch = 16.4537s	
9746/29850 (epoch 16.325), train_loss = 1.18527146, grad/param norm = 1.9379e-01, time/batch = 19.2121s	
9747/29850 (epoch 16.327), train_loss = 1.30364228, grad/param norm = 2.0153e-01, time/batch = 17.3175s	
9748/29850 (epoch 16.328), train_loss = 1.28271768, grad/param norm = 1.9610e-01, time/batch = 16.6300s	
9749/29850 (epoch 16.330), train_loss = 1.14689722, grad/param norm = 1.9038e-01, time/batch = 18.1342s	
9750/29850 (epoch 16.332), train_loss = 1.06003570, grad/param norm = 1.7694e-01, time/batch = 16.8030s	
9751/29850 (epoch 16.333), train_loss = 1.26848257, grad/param norm = 2.0296e-01, time/batch = 18.2811s	
9752/29850 (epoch 16.335), train_loss = 1.20676336, grad/param norm = 1.9656e-01, time/batch = 15.6878s	
9753/29850 (epoch 16.337), train_loss = 1.14805025, grad/param norm = 1.8585e-01, time/batch = 18.7232s	
9754/29850 (epoch 16.338), train_loss = 1.13371097, grad/param norm = 1.7736e-01, time/batch = 18.0489s	
9755/29850 (epoch 16.340), train_loss = 1.02248074, grad/param norm = 1.7680e-01, time/batch = 15.9749s	
9756/29850 (epoch 16.342), train_loss = 1.12848342, grad/param norm = 1.9097e-01, time/batch = 19.5437s	
9757/29850 (epoch 16.343), train_loss = 1.18098213, grad/param norm = 2.0475e-01, time/batch = 18.2768s	
9758/29850 (epoch 16.345), train_loss = 1.18663800, grad/param norm = 2.0190e-01, time/batch = 16.0222s	
9759/29850 (epoch 16.347), train_loss = 1.22920053, grad/param norm = 2.0795e-01, time/batch = 17.1282s	
9760/29850 (epoch 16.348), train_loss = 1.08246578, grad/param norm = 1.7358e-01, time/batch = 17.3032s	
9761/29850 (epoch 16.350), train_loss = 1.22127426, grad/param norm = 1.9788e-01, time/batch = 16.9838s	
9762/29850 (epoch 16.352), train_loss = 1.10968033, grad/param norm = 1.7760e-01, time/batch = 18.4472s	
9763/29850 (epoch 16.353), train_loss = 1.18702272, grad/param norm = 1.7998e-01, time/batch = 18.2214s	
9764/29850 (epoch 16.355), train_loss = 1.01577223, grad/param norm = 1.7329e-01, time/batch = 17.6361s	
9765/29850 (epoch 16.357), train_loss = 1.29732144, grad/param norm = 1.9482e-01, time/batch = 17.1229s	
9766/29850 (epoch 16.358), train_loss = 1.02879477, grad/param norm = 1.7355e-01, time/batch = 17.3475s	
9767/29850 (epoch 16.360), train_loss = 1.10334689, grad/param norm = 1.7794e-01, time/batch = 15.2019s	
9768/29850 (epoch 16.362), train_loss = 1.12032545, grad/param norm = 1.8444e-01, time/batch = 17.5251s	
9769/29850 (epoch 16.363), train_loss = 1.16631405, grad/param norm = 1.9511e-01, time/batch = 16.6208s	
9770/29850 (epoch 16.365), train_loss = 1.31101314, grad/param norm = 2.0032e-01, time/batch = 17.9700s	
9771/29850 (epoch 16.367), train_loss = 1.10068483, grad/param norm = 1.9132e-01, time/batch = 18.5562s	
9772/29850 (epoch 16.369), train_loss = 1.00520810, grad/param norm = 1.9051e-01, time/batch = 16.3047s	
9773/29850 (epoch 16.370), train_loss = 0.93325333, grad/param norm = 1.8442e-01, time/batch = 19.0578s	
9774/29850 (epoch 16.372), train_loss = 1.25457767, grad/param norm = 2.0530e-01, time/batch = 17.0650s	
9775/29850 (epoch 16.374), train_loss = 1.13869656, grad/param norm = 1.9615e-01, time/batch = 15.9778s	
9776/29850 (epoch 16.375), train_loss = 1.14055275, grad/param norm = 1.9001e-01, time/batch = 18.6210s	
9777/29850 (epoch 16.377), train_loss = 1.12572011, grad/param norm = 1.9515e-01, time/batch = 17.3754s	
9778/29850 (epoch 16.379), train_loss = 1.21536284, grad/param norm = 2.0152e-01, time/batch = 17.7998s	
9779/29850 (epoch 16.380), train_loss = 1.17903792, grad/param norm = 1.8485e-01, time/batch = 16.6219s	
9780/29850 (epoch 16.382), train_loss = 1.17559540, grad/param norm = 1.9013e-01, time/batch = 18.3895s	
9781/29850 (epoch 16.384), train_loss = 1.17963251, grad/param norm = 1.8236e-01, time/batch = 16.7761s	
9782/29850 (epoch 16.385), train_loss = 1.14492230, grad/param norm = 1.9346e-01, time/batch = 16.5968s	
9783/29850 (epoch 16.387), train_loss = 1.17765100, grad/param norm = 2.0204e-01, time/batch = 16.8917s	
9784/29850 (epoch 16.389), train_loss = 1.29468777, grad/param norm = 1.9955e-01, time/batch = 17.8043s	
9785/29850 (epoch 16.390), train_loss = 1.16934527, grad/param norm = 1.7981e-01, time/batch = 18.0526s	
9786/29850 (epoch 16.392), train_loss = 1.12469267, grad/param norm = 2.0100e-01, time/batch = 15.1982s	
9787/29850 (epoch 16.394), train_loss = 1.24061151, grad/param norm = 1.9371e-01, time/batch = 17.6937s	
9788/29850 (epoch 16.395), train_loss = 1.11990655, grad/param norm = 1.8700e-01, time/batch = 17.2043s	
9789/29850 (epoch 16.397), train_loss = 1.02096588, grad/param norm = 1.7942e-01, time/batch = 17.1173s	
9790/29850 (epoch 16.399), train_loss = 1.03947650, grad/param norm = 1.6948e-01, time/batch = 18.7210s	
9791/29850 (epoch 16.400), train_loss = 1.41884950, grad/param norm = 1.9674e-01, time/batch = 16.5675s	
9792/29850 (epoch 16.402), train_loss = 1.31673768, grad/param norm = 1.8742e-01, time/batch = 17.7234s	
9793/29850 (epoch 16.404), train_loss = 1.16344404, grad/param norm = 1.8163e-01, time/batch = 17.1744s	
9794/29850 (epoch 16.405), train_loss = 1.07950840, grad/param norm = 1.9143e-01, time/batch = 19.1297s	
9795/29850 (epoch 16.407), train_loss = 1.05187226, grad/param norm = 1.6855e-01, time/batch = 17.8863s	
9796/29850 (epoch 16.409), train_loss = 1.22647160, grad/param norm = 1.9433e-01, time/batch = 17.3620s	
9797/29850 (epoch 16.410), train_loss = 1.31825438, grad/param norm = 1.8917e-01, time/batch = 17.0426s	
9798/29850 (epoch 16.412), train_loss = 1.21480652, grad/param norm = 1.9556e-01, time/batch = 18.3907s	
9799/29850 (epoch 16.414), train_loss = 1.15155619, grad/param norm = 2.0316e-01, time/batch = 17.4534s	
9800/29850 (epoch 16.415), train_loss = 1.16298685, grad/param norm = 1.8097e-01, time/batch = 17.7251s	
9801/29850 (epoch 16.417), train_loss = 1.31510004, grad/param norm = 2.1109e-01, time/batch = 16.5515s	
9802/29850 (epoch 16.419), train_loss = 1.17356574, grad/param norm = 2.1003e-01, time/batch = 16.8729s	
9803/29850 (epoch 16.420), train_loss = 1.14946974, grad/param norm = 1.8075e-01, time/batch = 16.6258s	
9804/29850 (epoch 16.422), train_loss = 1.13586083, grad/param norm = 1.9636e-01, time/batch = 18.5051s	
9805/29850 (epoch 16.424), train_loss = 1.10838170, grad/param norm = 1.8516e-01, time/batch = 17.7920s	
9806/29850 (epoch 16.425), train_loss = 1.28167598, grad/param norm = 1.9399e-01, time/batch = 17.3022s	
9807/29850 (epoch 16.427), train_loss = 0.96994874, grad/param norm = 1.8146e-01, time/batch = 17.2200s	
9808/29850 (epoch 16.429), train_loss = 1.02813460, grad/param norm = 1.7747e-01, time/batch = 18.8902s	
9809/29850 (epoch 16.430), train_loss = 0.95530304, grad/param norm = 1.6246e-01, time/batch = 18.1972s	
9810/29850 (epoch 16.432), train_loss = 1.12829771, grad/param norm = 1.9608e-01, time/batch = 17.2567s	
9811/29850 (epoch 16.434), train_loss = 0.99652452, grad/param norm = 1.6919e-01, time/batch = 17.7641s	
9812/29850 (epoch 16.436), train_loss = 1.16120670, grad/param norm = 1.8702e-01, time/batch = 16.9575s	
9813/29850 (epoch 16.437), train_loss = 1.19269312, grad/param norm = 1.7811e-01, time/batch = 16.4599s	
9814/29850 (epoch 16.439), train_loss = 1.15528722, grad/param norm = 1.7471e-01, time/batch = 17.7226s	
9815/29850 (epoch 16.441), train_loss = 1.13490454, grad/param norm = 1.8202e-01, time/batch = 17.2931s	
9816/29850 (epoch 16.442), train_loss = 1.18089913, grad/param norm = 1.9761e-01, time/batch = 20.1785s	
9817/29850 (epoch 16.444), train_loss = 1.15261693, grad/param norm = 1.8413e-01, time/batch = 30.5771s	
9818/29850 (epoch 16.446), train_loss = 1.17961359, grad/param norm = 1.8357e-01, time/batch = 16.1518s	
9819/29850 (epoch 16.447), train_loss = 1.19132317, grad/param norm = 1.8865e-01, time/batch = 17.1990s	
9820/29850 (epoch 16.449), train_loss = 1.18109899, grad/param norm = 2.0048e-01, time/batch = 16.2677s	
9821/29850 (epoch 16.451), train_loss = 0.97725412, grad/param norm = 1.7173e-01, time/batch = 19.1930s	
9822/29850 (epoch 16.452), train_loss = 0.86687741, grad/param norm = 1.5309e-01, time/batch = 17.6259s	
9823/29850 (epoch 16.454), train_loss = 0.99936245, grad/param norm = 1.6758e-01, time/batch = 18.1404s	
9824/29850 (epoch 16.456), train_loss = 1.20130370, grad/param norm = 2.0272e-01, time/batch = 18.4687s	
9825/29850 (epoch 16.457), train_loss = 1.20974960, grad/param norm = 2.2760e-01, time/batch = 18.2902s	
9826/29850 (epoch 16.459), train_loss = 1.33076677, grad/param norm = 2.0819e-01, time/batch = 17.9585s	
9827/29850 (epoch 16.461), train_loss = 1.29640403, grad/param norm = 1.8852e-01, time/batch = 17.7153s	
9828/29850 (epoch 16.462), train_loss = 1.26798113, grad/param norm = 2.0639e-01, time/batch = 18.6371s	
9829/29850 (epoch 16.464), train_loss = 1.20365788, grad/param norm = 1.9899e-01, time/batch = 16.6295s	
9830/29850 (epoch 16.466), train_loss = 1.02830529, grad/param norm = 1.9223e-01, time/batch = 18.2994s	
9831/29850 (epoch 16.467), train_loss = 1.12869565, grad/param norm = 2.0760e-01, time/batch = 15.7887s	
9832/29850 (epoch 16.469), train_loss = 1.11496987, grad/param norm = 1.7786e-01, time/batch = 17.9515s	
9833/29850 (epoch 16.471), train_loss = 1.14998411, grad/param norm = 2.5348e-01, time/batch = 17.6274s	
9834/29850 (epoch 16.472), train_loss = 1.05638337, grad/param norm = 1.7404e-01, time/batch = 18.4722s	
9835/29850 (epoch 16.474), train_loss = 1.26400342, grad/param norm = 2.0031e-01, time/batch = 16.3063s	
9836/29850 (epoch 16.476), train_loss = 1.17603089, grad/param norm = 1.8856e-01, time/batch = 16.3800s	
9837/29850 (epoch 16.477), train_loss = 1.16350787, grad/param norm = 1.9830e-01, time/batch = 16.5394s	
9838/29850 (epoch 16.479), train_loss = 1.30065551, grad/param norm = 2.0843e-01, time/batch = 18.7045s	
9839/29850 (epoch 16.481), train_loss = 1.18968343, grad/param norm = 1.9778e-01, time/batch = 17.2143s	
9840/29850 (epoch 16.482), train_loss = 1.06704493, grad/param norm = 1.6259e-01, time/batch = 19.4499s	
9841/29850 (epoch 16.484), train_loss = 1.06855918, grad/param norm = 1.7898e-01, time/batch = 17.5393s	
9842/29850 (epoch 16.486), train_loss = 1.16137697, grad/param norm = 1.8654e-01, time/batch = 18.2137s	
9843/29850 (epoch 16.487), train_loss = 1.12442147, grad/param norm = 1.9807e-01, time/batch = 17.7017s	
9844/29850 (epoch 16.489), train_loss = 1.13172037, grad/param norm = 1.8846e-01, time/batch = 15.3798s	
9845/29850 (epoch 16.491), train_loss = 1.03259901, grad/param norm = 1.6558e-01, time/batch = 16.4847s	
9846/29850 (epoch 16.492), train_loss = 1.16587572, grad/param norm = 1.9632e-01, time/batch = 16.7248s	
9847/29850 (epoch 16.494), train_loss = 1.28192361, grad/param norm = 1.8118e-01, time/batch = 17.5488s	
9848/29850 (epoch 16.496), train_loss = 1.28986888, grad/param norm = 1.8601e-01, time/batch = 17.2328s	
9849/29850 (epoch 16.497), train_loss = 1.20195581, grad/param norm = 1.6956e-01, time/batch = 19.2106s	
9850/29850 (epoch 16.499), train_loss = 1.15310283, grad/param norm = 1.7530e-01, time/batch = 16.7069s	
9851/29850 (epoch 16.501), train_loss = 1.09877527, grad/param norm = 1.7510e-01, time/batch = 18.6993s	
9852/29850 (epoch 16.503), train_loss = 1.14296262, grad/param norm = 1.8984e-01, time/batch = 17.2928s	
9853/29850 (epoch 16.504), train_loss = 1.34623157, grad/param norm = 1.8160e-01, time/batch = 16.0422s	
9854/29850 (epoch 16.506), train_loss = 1.32769283, grad/param norm = 2.0577e-01, time/batch = 15.5126s	
9855/29850 (epoch 16.508), train_loss = 1.14524806, grad/param norm = 1.9415e-01, time/batch = 15.8899s	
9856/29850 (epoch 16.509), train_loss = 0.93681043, grad/param norm = 1.7636e-01, time/batch = 18.5568s	
9857/29850 (epoch 16.511), train_loss = 1.14915528, grad/param norm = 1.9320e-01, time/batch = 17.0485s	
9858/29850 (epoch 16.513), train_loss = 1.15755509, grad/param norm = 1.9982e-01, time/batch = 18.1264s	
9859/29850 (epoch 16.514), train_loss = 1.01557045, grad/param norm = 1.7777e-01, time/batch = 17.3893s	
9860/29850 (epoch 16.516), train_loss = 1.05206142, grad/param norm = 1.6753e-01, time/batch = 16.0539s	
9861/29850 (epoch 16.518), train_loss = 0.98771658, grad/param norm = 1.7970e-01, time/batch = 18.3874s	
9862/29850 (epoch 16.519), train_loss = 0.98464617, grad/param norm = 1.7784e-01, time/batch = 17.2243s	
9863/29850 (epoch 16.521), train_loss = 0.95090608, grad/param norm = 1.6768e-01, time/batch = 16.8551s	
9864/29850 (epoch 16.523), train_loss = 1.00213531, grad/param norm = 1.6451e-01, time/batch = 16.8064s	
9865/29850 (epoch 16.524), train_loss = 1.09015360, grad/param norm = 1.9751e-01, time/batch = 17.4750s	
9866/29850 (epoch 16.526), train_loss = 1.18638575, grad/param norm = 1.9389e-01, time/batch = 19.1265s	
9867/29850 (epoch 16.528), train_loss = 1.28277286, grad/param norm = 2.0582e-01, time/batch = 15.9541s	
9868/29850 (epoch 16.529), train_loss = 1.17733721, grad/param norm = 1.9425e-01, time/batch = 18.6369s	
9869/29850 (epoch 16.531), train_loss = 1.11355672, grad/param norm = 1.8620e-01, time/batch = 16.4686s	
9870/29850 (epoch 16.533), train_loss = 1.09732129, grad/param norm = 1.8709e-01, time/batch = 17.0284s	
9871/29850 (epoch 16.534), train_loss = 1.13297354, grad/param norm = 1.8202e-01, time/batch = 15.6124s	
9872/29850 (epoch 16.536), train_loss = 1.12102862, grad/param norm = 1.9900e-01, time/batch = 17.8729s	
9873/29850 (epoch 16.538), train_loss = 1.25295717, grad/param norm = 1.9037e-01, time/batch = 15.2600s	
9874/29850 (epoch 16.539), train_loss = 1.31491232, grad/param norm = 2.0094e-01, time/batch = 15.0336s	
9875/29850 (epoch 16.541), train_loss = 0.94142221, grad/param norm = 1.6638e-01, time/batch = 16.3717s	
9876/29850 (epoch 16.543), train_loss = 1.13104468, grad/param norm = 1.7940e-01, time/batch = 15.0251s	
9877/29850 (epoch 16.544), train_loss = 1.16317656, grad/param norm = 1.9267e-01, time/batch = 14.6226s	
9878/29850 (epoch 16.546), train_loss = 1.21378890, grad/param norm = 1.8038e-01, time/batch = 15.0362s	
9879/29850 (epoch 16.548), train_loss = 0.99654970, grad/param norm = 1.6978e-01, time/batch = 15.3521s	
9880/29850 (epoch 16.549), train_loss = 1.08405922, grad/param norm = 1.7681e-01, time/batch = 18.9509s	
9881/29850 (epoch 16.551), train_loss = 1.02348200, grad/param norm = 1.7966e-01, time/batch = 17.9511s	
9882/29850 (epoch 16.553), train_loss = 1.14840536, grad/param norm = 1.8630e-01, time/batch = 19.0268s	
9883/29850 (epoch 16.554), train_loss = 0.96736325, grad/param norm = 1.6208e-01, time/batch = 15.1704s	
9884/29850 (epoch 16.556), train_loss = 1.07299150, grad/param norm = 1.9401e-01, time/batch = 15.2230s	
9885/29850 (epoch 16.558), train_loss = 1.04643401, grad/param norm = 1.8211e-01, time/batch = 16.6216s	
9886/29850 (epoch 16.559), train_loss = 1.12068300, grad/param norm = 1.9241e-01, time/batch = 17.1392s	
9887/29850 (epoch 16.561), train_loss = 1.20571884, grad/param norm = 1.9925e-01, time/batch = 18.0457s	
9888/29850 (epoch 16.563), train_loss = 1.12641314, grad/param norm = 1.7616e-01, time/batch = 17.2303s	
9889/29850 (epoch 16.564), train_loss = 1.10032435, grad/param norm = 1.7913e-01, time/batch = 15.5170s	
9890/29850 (epoch 16.566), train_loss = 1.11792357, grad/param norm = 1.8639e-01, time/batch = 14.9648s	
9891/29850 (epoch 16.568), train_loss = 1.25426508, grad/param norm = 1.9378e-01, time/batch = 17.2186s	
9892/29850 (epoch 16.570), train_loss = 1.14501266, grad/param norm = 1.7760e-01, time/batch = 16.4769s	
9893/29850 (epoch 16.571), train_loss = 1.17140646, grad/param norm = 1.9208e-01, time/batch = 19.5395s	
9894/29850 (epoch 16.573), train_loss = 1.28267206, grad/param norm = 2.2049e-01, time/batch = 18.1205s	
9895/29850 (epoch 16.575), train_loss = 1.26121084, grad/param norm = 1.7628e-01, time/batch = 17.7923s	
9896/29850 (epoch 16.576), train_loss = 1.23914936, grad/param norm = 1.9521e-01, time/batch = 17.1042s	
9897/29850 (epoch 16.578), train_loss = 1.11817259, grad/param norm = 1.8648e-01, time/batch = 18.3796s	
9898/29850 (epoch 16.580), train_loss = 1.26659754, grad/param norm = 1.8703e-01, time/batch = 18.4746s	
9899/29850 (epoch 16.581), train_loss = 1.04469363, grad/param norm = 1.7550e-01, time/batch = 15.5335s	
9900/29850 (epoch 16.583), train_loss = 1.11882146, grad/param norm = 1.8945e-01, time/batch = 18.3009s	
9901/29850 (epoch 16.585), train_loss = 1.17424376, grad/param norm = 1.7179e-01, time/batch = 18.2124s	
9902/29850 (epoch 16.586), train_loss = 1.18568668, grad/param norm = 1.9395e-01, time/batch = 19.0858s	
9903/29850 (epoch 16.588), train_loss = 1.10293449, grad/param norm = 1.9752e-01, time/batch = 20.6682s	
9904/29850 (epoch 16.590), train_loss = 1.13564479, grad/param norm = 1.9347e-01, time/batch = 21.4756s	
9905/29850 (epoch 16.591), train_loss = 1.07673845, grad/param norm = 1.8067e-01, time/batch = 22.9409s	
9906/29850 (epoch 16.593), train_loss = 1.04781703, grad/param norm = 1.7352e-01, time/batch = 19.9761s	
9907/29850 (epoch 16.595), train_loss = 1.00267960, grad/param norm = 1.6160e-01, time/batch = 21.1008s	
9908/29850 (epoch 16.596), train_loss = 0.99341955, grad/param norm = 1.8273e-01, time/batch = 22.6639s	
9909/29850 (epoch 16.598), train_loss = 1.05554471, grad/param norm = 1.7832e-01, time/batch = 22.2424s	
9910/29850 (epoch 16.600), train_loss = 1.21907950, grad/param norm = 1.9004e-01, time/batch = 22.7184s	
9911/29850 (epoch 16.601), train_loss = 1.00968937, grad/param norm = 1.7575e-01, time/batch = 22.3193s	
9912/29850 (epoch 16.603), train_loss = 1.10183665, grad/param norm = 1.9582e-01, time/batch = 23.5756s	
9913/29850 (epoch 16.605), train_loss = 1.10325770, grad/param norm = 1.8912e-01, time/batch = 22.7381s	
9914/29850 (epoch 16.606), train_loss = 0.87650568, grad/param norm = 1.5855e-01, time/batch = 22.1861s	
9915/29850 (epoch 16.608), train_loss = 1.11068600, grad/param norm = 1.8709e-01, time/batch = 20.5675s	
9916/29850 (epoch 16.610), train_loss = 1.14376015, grad/param norm = 1.8354e-01, time/batch = 20.8112s	
9917/29850 (epoch 16.611), train_loss = 0.99799621, grad/param norm = 1.6129e-01, time/batch = 22.6701s	
9918/29850 (epoch 16.613), train_loss = 0.87621106, grad/param norm = 1.5890e-01, time/batch = 23.2265s	
9919/29850 (epoch 16.615), train_loss = 0.98330615, grad/param norm = 1.6672e-01, time/batch = 18.7458s	
9920/29850 (epoch 16.616), train_loss = 1.01724114, grad/param norm = 1.7860e-01, time/batch = 24.4609s	
9921/29850 (epoch 16.618), train_loss = 1.06337898, grad/param norm = 1.7197e-01, time/batch = 24.8610s	
9922/29850 (epoch 16.620), train_loss = 1.15183606, grad/param norm = 1.9552e-01, time/batch = 19.4608s	
9923/29850 (epoch 16.621), train_loss = 1.24742215, grad/param norm = 1.9502e-01, time/batch = 17.3988s	
9924/29850 (epoch 16.623), train_loss = 1.20625583, grad/param norm = 1.8362e-01, time/batch = 16.8176s	
9925/29850 (epoch 16.625), train_loss = 1.14013489, grad/param norm = 1.9615e-01, time/batch = 17.6361s	
9926/29850 (epoch 16.626), train_loss = 1.16400076, grad/param norm = 1.9401e-01, time/batch = 19.3073s	
9927/29850 (epoch 16.628), train_loss = 0.99857639, grad/param norm = 1.6583e-01, time/batch = 17.0365s	
9928/29850 (epoch 16.630), train_loss = 1.11155152, grad/param norm = 2.1237e-01, time/batch = 18.1107s	
9929/29850 (epoch 16.631), train_loss = 1.06525202, grad/param norm = 1.8208e-01, time/batch = 18.4505s	
9930/29850 (epoch 16.633), train_loss = 1.19388278, grad/param norm = 1.9290e-01, time/batch = 16.8934s	
9931/29850 (epoch 16.635), train_loss = 1.10599781, grad/param norm = 1.8058e-01, time/batch = 16.3740s	
9932/29850 (epoch 16.637), train_loss = 1.04405323, grad/param norm = 1.9124e-01, time/batch = 15.4561s	
9933/29850 (epoch 16.638), train_loss = 1.10675986, grad/param norm = 1.8349e-01, time/batch = 17.7050s	
9934/29850 (epoch 16.640), train_loss = 1.27147049, grad/param norm = 2.0436e-01, time/batch = 18.3778s	
9935/29850 (epoch 16.642), train_loss = 1.06178435, grad/param norm = 1.6136e-01, time/batch = 16.1055s	
9936/29850 (epoch 16.643), train_loss = 1.03931403, grad/param norm = 1.8015e-01, time/batch = 18.8847s	
9937/29850 (epoch 16.645), train_loss = 1.12519614, grad/param norm = 1.8517e-01, time/batch = 17.8878s	
9938/29850 (epoch 16.647), train_loss = 1.25086564, grad/param norm = 1.8867e-01, time/batch = 16.5406s	
9939/29850 (epoch 16.648), train_loss = 1.00282399, grad/param norm = 1.7097e-01, time/batch = 18.3078s	
9940/29850 (epoch 16.650), train_loss = 1.12930143, grad/param norm = 1.9896e-01, time/batch = 17.5371s	
9941/29850 (epoch 16.652), train_loss = 1.13392843, grad/param norm = 1.8278e-01, time/batch = 18.0451s	
9942/29850 (epoch 16.653), train_loss = 1.22635541, grad/param norm = 2.0726e-01, time/batch = 18.4452s	
9943/29850 (epoch 16.655), train_loss = 1.10606280, grad/param norm = 1.7098e-01, time/batch = 18.1375s	
9944/29850 (epoch 16.657), train_loss = 1.06213021, grad/param norm = 1.7918e-01, time/batch = 17.5463s	
9945/29850 (epoch 16.658), train_loss = 1.22722769, grad/param norm = 1.9534e-01, time/batch = 18.6080s	
9946/29850 (epoch 16.660), train_loss = 1.11661324, grad/param norm = 1.9544e-01, time/batch = 17.2926s	
9947/29850 (epoch 16.662), train_loss = 1.16848453, grad/param norm = 1.9710e-01, time/batch = 18.3053s	
9948/29850 (epoch 16.663), train_loss = 1.28466729, grad/param norm = 1.9779e-01, time/batch = 17.0463s	
9949/29850 (epoch 16.665), train_loss = 1.23435984, grad/param norm = 1.8865e-01, time/batch = 17.2343s	
9950/29850 (epoch 16.667), train_loss = 1.19599594, grad/param norm = 2.4145e-01, time/batch = 16.1101s	
9951/29850 (epoch 16.668), train_loss = 1.10928781, grad/param norm = 1.8663e-01, time/batch = 17.4535s	
9952/29850 (epoch 16.670), train_loss = 1.30764034, grad/param norm = 2.3963e-01, time/batch = 16.6372s	
9953/29850 (epoch 16.672), train_loss = 1.22975283, grad/param norm = 1.9757e-01, time/batch = 18.3897s	
9954/29850 (epoch 16.673), train_loss = 1.23248224, grad/param norm = 1.9975e-01, time/batch = 17.5611s	
9955/29850 (epoch 16.675), train_loss = 1.04449764, grad/param norm = 1.8786e-01, time/batch = 16.5586s	
9956/29850 (epoch 16.677), train_loss = 1.12510383, grad/param norm = 1.9802e-01, time/batch = 18.3126s	
9957/29850 (epoch 16.678), train_loss = 1.09077027, grad/param norm = 1.8714e-01, time/batch = 16.9659s	
9958/29850 (epoch 16.680), train_loss = 1.14332028, grad/param norm = 2.0630e-01, time/batch = 15.6452s	
9959/29850 (epoch 16.682), train_loss = 1.13247974, grad/param norm = 1.9006e-01, time/batch = 16.8850s	
9960/29850 (epoch 16.683), train_loss = 1.28768429, grad/param norm = 2.1453e-01, time/batch = 15.1093s	
9961/29850 (epoch 16.685), train_loss = 1.26474205, grad/param norm = 1.6874e-01, time/batch = 17.2629s	
9962/29850 (epoch 16.687), train_loss = 1.19112314, grad/param norm = 1.8862e-01, time/batch = 16.5452s	
9963/29850 (epoch 16.688), train_loss = 1.00016619, grad/param norm = 1.6462e-01, time/batch = 16.1156s	
9964/29850 (epoch 16.690), train_loss = 1.02263322, grad/param norm = 1.8146e-01, time/batch = 17.6306s	
9965/29850 (epoch 16.692), train_loss = 1.23754821, grad/param norm = 1.8486e-01, time/batch = 15.9571s	
9966/29850 (epoch 16.693), train_loss = 1.09022601, grad/param norm = 1.6403e-01, time/batch = 16.1675s	
9967/29850 (epoch 16.695), train_loss = 0.99401318, grad/param norm = 1.6105e-01, time/batch = 17.9803s	
9968/29850 (epoch 16.697), train_loss = 1.15622505, grad/param norm = 1.8731e-01, time/batch = 17.9728s	
9969/29850 (epoch 16.698), train_loss = 1.20783323, grad/param norm = 1.8871e-01, time/batch = 16.3884s	
9970/29850 (epoch 16.700), train_loss = 1.14811015, grad/param norm = 1.8744e-01, time/batch = 15.5478s	
9971/29850 (epoch 16.702), train_loss = 1.09095117, grad/param norm = 1.8842e-01, time/batch = 18.6341s	
9972/29850 (epoch 16.704), train_loss = 1.01897126, grad/param norm = 1.6991e-01, time/batch = 18.3024s	
9973/29850 (epoch 16.705), train_loss = 1.11907828, grad/param norm = 1.6589e-01, time/batch = 17.4359s	
9974/29850 (epoch 16.707), train_loss = 1.05518342, grad/param norm = 1.7728e-01, time/batch = 17.8159s	
9975/29850 (epoch 16.709), train_loss = 1.16681530, grad/param norm = 1.8231e-01, time/batch = 19.6201s	
9976/29850 (epoch 16.710), train_loss = 1.07996543, grad/param norm = 1.9034e-01, time/batch = 15.8151s	
9977/29850 (epoch 16.712), train_loss = 1.12007279, grad/param norm = 1.6496e-01, time/batch = 18.9584s	
9978/29850 (epoch 16.714), train_loss = 1.19294027, grad/param norm = 1.8336e-01, time/batch = 17.5439s	
9979/29850 (epoch 16.715), train_loss = 1.15793763, grad/param norm = 1.7318e-01, time/batch = 16.6133s	
9980/29850 (epoch 16.717), train_loss = 0.93160049, grad/param norm = 1.7180e-01, time/batch = 17.2151s	
9981/29850 (epoch 16.719), train_loss = 1.05583108, grad/param norm = 1.8064e-01, time/batch = 18.5625s	
9982/29850 (epoch 16.720), train_loss = 1.12453323, grad/param norm = 1.7611e-01, time/batch = 18.2170s	
9983/29850 (epoch 16.722), train_loss = 1.05266472, grad/param norm = 1.6354e-01, time/batch = 16.3774s	
9984/29850 (epoch 16.724), train_loss = 1.19840236, grad/param norm = 1.9674e-01, time/batch = 18.2115s	
9985/29850 (epoch 16.725), train_loss = 0.98386478, grad/param norm = 1.7121e-01, time/batch = 16.3144s	
9986/29850 (epoch 16.727), train_loss = 1.05880135, grad/param norm = 1.8808e-01, time/batch = 15.9397s	
9987/29850 (epoch 16.729), train_loss = 0.96145517, grad/param norm = 1.6913e-01, time/batch = 16.6926s	
9988/29850 (epoch 16.730), train_loss = 0.99169874, grad/param norm = 1.8164e-01, time/batch = 17.9627s	
9989/29850 (epoch 16.732), train_loss = 1.21477977, grad/param norm = 1.8245e-01, time/batch = 18.4712s	
9990/29850 (epoch 16.734), train_loss = 1.32178245, grad/param norm = 2.1820e-01, time/batch = 18.4587s	
9991/29850 (epoch 16.735), train_loss = 1.10301031, grad/param norm = 2.0149e-01, time/batch = 16.6433s	
9992/29850 (epoch 16.737), train_loss = 1.03570837, grad/param norm = 1.7579e-01, time/batch = 14.7360s	
9993/29850 (epoch 16.739), train_loss = 0.93851767, grad/param norm = 1.7389e-01, time/batch = 17.1881s	
9994/29850 (epoch 16.740), train_loss = 0.97590199, grad/param norm = 1.7665e-01, time/batch = 17.7979s	
9995/29850 (epoch 16.742), train_loss = 0.96196364, grad/param norm = 1.6851e-01, time/batch = 18.9592s	
9996/29850 (epoch 16.744), train_loss = 1.04405563, grad/param norm = 1.9869e-01, time/batch = 16.9004s	
9997/29850 (epoch 16.745), train_loss = 1.03818071, grad/param norm = 1.8265e-01, time/batch = 19.1934s	
9998/29850 (epoch 16.747), train_loss = 1.08230653, grad/param norm = 1.7694e-01, time/batch = 19.1192s	
9999/29850 (epoch 16.749), train_loss = 1.02633369, grad/param norm = 1.9947e-01, time/batch = 16.7263s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch16.75_1.6701.t7	
10000/29850 (epoch 16.750), train_loss = 0.99112181, grad/param norm = 1.8586e-01, time/batch = 16.7121s	
10001/29850 (epoch 16.752), train_loss = 1.34409448, grad/param norm = 2.1447e-01, time/batch = 17.5553s	
10002/29850 (epoch 16.754), train_loss = 0.98566112, grad/param norm = 1.8905e-01, time/batch = 18.3820s	
10003/29850 (epoch 16.755), train_loss = 1.02964030, grad/param norm = 1.8949e-01, time/batch = 16.8595s	
10004/29850 (epoch 16.757), train_loss = 1.06547697, grad/param norm = 1.7985e-01, time/batch = 16.7212s	
10005/29850 (epoch 16.759), train_loss = 1.07464914, grad/param norm = 1.7140e-01, time/batch = 18.3497s	
10006/29850 (epoch 16.760), train_loss = 1.00554485, grad/param norm = 1.7962e-01, time/batch = 16.8018s	
10007/29850 (epoch 16.762), train_loss = 0.98726300, grad/param norm = 1.8964e-01, time/batch = 18.9593s	
10008/29850 (epoch 16.764), train_loss = 0.93687159, grad/param norm = 1.7891e-01, time/batch = 16.5480s	
10009/29850 (epoch 16.765), train_loss = 1.05442296, grad/param norm = 1.7801e-01, time/batch = 18.5192s	
10010/29850 (epoch 16.767), train_loss = 1.07511906, grad/param norm = 1.7194e-01, time/batch = 28.7365s	
10011/29850 (epoch 16.769), train_loss = 1.07012601, grad/param norm = 1.8507e-01, time/batch = 23.0656s	
10012/29850 (epoch 16.771), train_loss = 1.12413867, grad/param norm = 1.8980e-01, time/batch = 17.4434s	
10013/29850 (epoch 16.772), train_loss = 1.13893831, grad/param norm = 1.8686e-01, time/batch = 15.6430s	
10014/29850 (epoch 16.774), train_loss = 1.02260945, grad/param norm = 1.8607e-01, time/batch = 18.4342s	
10015/29850 (epoch 16.776), train_loss = 1.05286184, grad/param norm = 1.7918e-01, time/batch = 16.7996s	
10016/29850 (epoch 16.777), train_loss = 1.15772092, grad/param norm = 1.9406e-01, time/batch = 17.6220s	
10017/29850 (epoch 16.779), train_loss = 0.97904812, grad/param norm = 1.5998e-01, time/batch = 18.2289s	
10018/29850 (epoch 16.781), train_loss = 1.07459782, grad/param norm = 1.7077e-01, time/batch = 19.3748s	
10019/29850 (epoch 16.782), train_loss = 1.12198082, grad/param norm = 1.8583e-01, time/batch = 17.7886s	
10020/29850 (epoch 16.784), train_loss = 0.99899561, grad/param norm = 1.9044e-01, time/batch = 16.4823s	
10021/29850 (epoch 16.786), train_loss = 1.04997139, grad/param norm = 1.6964e-01, time/batch = 17.7257s	
10022/29850 (epoch 16.787), train_loss = 0.99240160, grad/param norm = 1.9841e-01, time/batch = 15.4327s	
10023/29850 (epoch 16.789), train_loss = 0.91980047, grad/param norm = 1.5566e-01, time/batch = 16.9718s	
10024/29850 (epoch 16.791), train_loss = 1.02286089, grad/param norm = 1.8862e-01, time/batch = 18.5424s	
10025/29850 (epoch 16.792), train_loss = 1.15411042, grad/param norm = 1.8960e-01, time/batch = 18.7795s	
10026/29850 (epoch 16.794), train_loss = 1.11434561, grad/param norm = 1.7406e-01, time/batch = 15.3070s	
10027/29850 (epoch 16.796), train_loss = 1.01688802, grad/param norm = 1.7220e-01, time/batch = 18.3728s	
10028/29850 (epoch 16.797), train_loss = 0.91731048, grad/param norm = 1.7583e-01, time/batch = 17.4762s	
10029/29850 (epoch 16.799), train_loss = 0.97748509, grad/param norm = 1.7001e-01, time/batch = 17.4460s	
10030/29850 (epoch 16.801), train_loss = 1.10884004, grad/param norm = 1.9448e-01, time/batch = 18.0191s	
10031/29850 (epoch 16.802), train_loss = 0.91418191, grad/param norm = 1.7370e-01, time/batch = 15.9650s	
10032/29850 (epoch 16.804), train_loss = 0.94972161, grad/param norm = 1.5895e-01, time/batch = 17.5358s	
10033/29850 (epoch 16.806), train_loss = 0.97027126, grad/param norm = 1.7343e-01, time/batch = 17.8713s	
10034/29850 (epoch 16.807), train_loss = 0.90250880, grad/param norm = 1.4600e-01, time/batch = 18.3859s	
10035/29850 (epoch 16.809), train_loss = 0.99213726, grad/param norm = 1.9293e-01, time/batch = 18.2292s	
10036/29850 (epoch 16.811), train_loss = 1.12492856, grad/param norm = 2.0194e-01, time/batch = 17.3750s	
10037/29850 (epoch 16.812), train_loss = 1.12574723, grad/param norm = 1.9662e-01, time/batch = 16.8738s	
10038/29850 (epoch 16.814), train_loss = 1.18824701, grad/param norm = 1.8603e-01, time/batch = 18.2904s	
10039/29850 (epoch 16.816), train_loss = 1.16331421, grad/param norm = 1.7802e-01, time/batch = 17.3814s	
10040/29850 (epoch 16.817), train_loss = 1.09267150, grad/param norm = 1.7872e-01, time/batch = 17.6378s	
10041/29850 (epoch 16.819), train_loss = 0.96809662, grad/param norm = 1.8490e-01, time/batch = 18.7859s	
10042/29850 (epoch 16.821), train_loss = 1.20303836, grad/param norm = 1.8743e-01, time/batch = 17.2059s	
10043/29850 (epoch 16.822), train_loss = 1.19668142, grad/param norm = 1.9632e-01, time/batch = 16.7178s	
10044/29850 (epoch 16.824), train_loss = 1.08651518, grad/param norm = 1.8600e-01, time/batch = 15.8092s	
10045/29850 (epoch 16.826), train_loss = 1.02494666, grad/param norm = 1.6304e-01, time/batch = 16.1421s	
10046/29850 (epoch 16.827), train_loss = 0.97901097, grad/param norm = 1.8767e-01, time/batch = 15.6363s	
10047/29850 (epoch 16.829), train_loss = 1.12448806, grad/param norm = 2.3168e-01, time/batch = 15.1679s	
10048/29850 (epoch 16.831), train_loss = 1.16669912, grad/param norm = 1.8876e-01, time/batch = 19.3003s	
10049/29850 (epoch 16.832), train_loss = 1.06816460, grad/param norm = 1.6775e-01, time/batch = 18.6391s	
10050/29850 (epoch 16.834), train_loss = 0.91665332, grad/param norm = 1.6465e-01, time/batch = 17.8732s	
10051/29850 (epoch 16.836), train_loss = 0.96297404, grad/param norm = 1.7030e-01, time/batch = 18.2254s	
10052/29850 (epoch 16.838), train_loss = 1.07657457, grad/param norm = 1.8645e-01, time/batch = 16.6342s	
10053/29850 (epoch 16.839), train_loss = 1.00187510, grad/param norm = 1.6796e-01, time/batch = 16.7827s	
10054/29850 (epoch 16.841), train_loss = 0.99916495, grad/param norm = 1.7301e-01, time/batch = 16.9024s	
10055/29850 (epoch 16.843), train_loss = 0.98690648, grad/param norm = 1.6906e-01, time/batch = 18.9641s	
10056/29850 (epoch 16.844), train_loss = 1.00001901, grad/param norm = 1.9044e-01, time/batch = 16.6528s	
10057/29850 (epoch 16.846), train_loss = 1.08883752, grad/param norm = 1.7834e-01, time/batch = 17.8536s	
10058/29850 (epoch 16.848), train_loss = 1.13618103, grad/param norm = 1.9269e-01, time/batch = 18.2990s	
10059/29850 (epoch 16.849), train_loss = 1.01685086, grad/param norm = 2.0114e-01, time/batch = 17.5482s	
10060/29850 (epoch 16.851), train_loss = 1.17295083, grad/param norm = 2.1094e-01, time/batch = 17.3745s	
10061/29850 (epoch 16.853), train_loss = 1.03207040, grad/param norm = 2.0871e-01, time/batch = 17.1395s	
10062/29850 (epoch 16.854), train_loss = 1.21932892, grad/param norm = 1.9564e-01, time/batch = 17.0611s	
10063/29850 (epoch 16.856), train_loss = 1.16692759, grad/param norm = 2.1145e-01, time/batch = 17.2198s	
10064/29850 (epoch 16.858), train_loss = 1.07127312, grad/param norm = 2.1314e-01, time/batch = 16.8748s	
10065/29850 (epoch 16.859), train_loss = 0.98793141, grad/param norm = 1.9519e-01, time/batch = 15.4818s	
10066/29850 (epoch 16.861), train_loss = 1.16510443, grad/param norm = 2.1427e-01, time/batch = 15.4877s	
10067/29850 (epoch 16.863), train_loss = 1.22912722, grad/param norm = 1.8631e-01, time/batch = 15.6843s	
10068/29850 (epoch 16.864), train_loss = 1.18543638, grad/param norm = 2.0621e-01, time/batch = 19.1318s	
10069/29850 (epoch 16.866), train_loss = 1.11998391, grad/param norm = 1.9662e-01, time/batch = 17.7173s	
10070/29850 (epoch 16.868), train_loss = 1.25451002, grad/param norm = 2.0238e-01, time/batch = 17.0351s	
10071/29850 (epoch 16.869), train_loss = 1.08893878, grad/param norm = 2.0718e-01, time/batch = 17.4655s	
10072/29850 (epoch 16.871), train_loss = 1.16263492, grad/param norm = 1.9913e-01, time/batch = 17.7300s	
10073/29850 (epoch 16.873), train_loss = 1.14161358, grad/param norm = 1.9431e-01, time/batch = 17.8730s	
10074/29850 (epoch 16.874), train_loss = 1.12110031, grad/param norm = 1.8115e-01, time/batch = 17.4349s	
10075/29850 (epoch 16.876), train_loss = 1.06979146, grad/param norm = 2.2244e-01, time/batch = 17.6293s	
10076/29850 (epoch 16.878), train_loss = 1.10055265, grad/param norm = 1.6883e-01, time/batch = 18.0617s	
10077/29850 (epoch 16.879), train_loss = 1.10424179, grad/param norm = 1.9010e-01, time/batch = 15.1915s	
10078/29850 (epoch 16.881), train_loss = 1.19419620, grad/param norm = 2.0188e-01, time/batch = 18.4557s	
10079/29850 (epoch 16.883), train_loss = 1.18962505, grad/param norm = 2.1178e-01, time/batch = 16.7044s	
10080/29850 (epoch 16.884), train_loss = 0.99040880, grad/param norm = 1.8925e-01, time/batch = 18.0492s	
10081/29850 (epoch 16.886), train_loss = 1.22585611, grad/param norm = 1.9493e-01, time/batch = 15.7736s	
10082/29850 (epoch 16.888), train_loss = 1.09595921, grad/param norm = 1.8388e-01, time/batch = 17.2823s	
10083/29850 (epoch 16.889), train_loss = 1.05429561, grad/param norm = 1.8554e-01, time/batch = 19.7153s	
10084/29850 (epoch 16.891), train_loss = 1.03636545, grad/param norm = 1.7979e-01, time/batch = 17.6249s	
10085/29850 (epoch 16.893), train_loss = 1.00635728, grad/param norm = 1.8207e-01, time/batch = 17.7146s	
10086/29850 (epoch 16.894), train_loss = 1.04294186, grad/param norm = 1.8079e-01, time/batch = 18.4715s	
10087/29850 (epoch 16.896), train_loss = 1.09835884, grad/param norm = 2.0180e-01, time/batch = 16.7993s	
10088/29850 (epoch 16.898), train_loss = 1.20021323, grad/param norm = 1.9661e-01, time/batch = 17.9737s	
10089/29850 (epoch 16.899), train_loss = 0.94694554, grad/param norm = 1.7238e-01, time/batch = 17.7147s	
10090/29850 (epoch 16.901), train_loss = 1.38627550, grad/param norm = 2.4745e-01, time/batch = 16.6466s	
10091/29850 (epoch 16.903), train_loss = 1.11572566, grad/param norm = 2.7333e-01, time/batch = 15.7195s	
10092/29850 (epoch 16.905), train_loss = 1.33259589, grad/param norm = 2.0409e-01, time/batch = 16.5365s	
10093/29850 (epoch 16.906), train_loss = 1.12039164, grad/param norm = 2.0798e-01, time/batch = 17.9831s	
10094/29850 (epoch 16.908), train_loss = 1.19362638, grad/param norm = 1.9789e-01, time/batch = 17.5437s	
10095/29850 (epoch 16.910), train_loss = 1.16509243, grad/param norm = 1.8701e-01, time/batch = 15.9006s	
10096/29850 (epoch 16.911), train_loss = 1.31279545, grad/param norm = 1.9707e-01, time/batch = 16.2046s	
10097/29850 (epoch 16.913), train_loss = 1.19920995, grad/param norm = 1.8088e-01, time/batch = 17.9457s	
10098/29850 (epoch 16.915), train_loss = 1.22470362, grad/param norm = 2.0899e-01, time/batch = 15.5307s	
10099/29850 (epoch 16.916), train_loss = 1.18436281, grad/param norm = 1.9856e-01, time/batch = 16.6932s	
10100/29850 (epoch 16.918), train_loss = 1.04596822, grad/param norm = 1.6652e-01, time/batch = 17.3005s	
10101/29850 (epoch 16.920), train_loss = 1.16853731, grad/param norm = 1.7603e-01, time/batch = 18.2926s	
10102/29850 (epoch 16.921), train_loss = 1.15858657, grad/param norm = 2.1226e-01, time/batch = 17.3673s	
10103/29850 (epoch 16.923), train_loss = 1.19146665, grad/param norm = 1.9162e-01, time/batch = 18.9654s	
10104/29850 (epoch 16.925), train_loss = 1.23755923, grad/param norm = 1.8786e-01, time/batch = 18.7875s	
10105/29850 (epoch 16.926), train_loss = 1.29011167, grad/param norm = 2.0989e-01, time/batch = 17.0978s	
10106/29850 (epoch 16.928), train_loss = 1.13239878, grad/param norm = 1.9023e-01, time/batch = 17.2997s	
10107/29850 (epoch 16.930), train_loss = 1.19691362, grad/param norm = 2.1220e-01, time/batch = 18.8833s	
10108/29850 (epoch 16.931), train_loss = 1.10819150, grad/param norm = 1.9336e-01, time/batch = 17.2079s	
10109/29850 (epoch 16.933), train_loss = 1.28525392, grad/param norm = 1.9105e-01, time/batch = 17.7981s	
10110/29850 (epoch 16.935), train_loss = 1.22940249, grad/param norm = 2.0455e-01, time/batch = 17.7356s	
10111/29850 (epoch 16.936), train_loss = 1.23426610, grad/param norm = 2.1220e-01, time/batch = 14.8000s	
10112/29850 (epoch 16.938), train_loss = 1.00780379, grad/param norm = 1.6878e-01, time/batch = 17.1085s	
10113/29850 (epoch 16.940), train_loss = 1.00624915, grad/param norm = 1.8569e-01, time/batch = 17.8046s	
10114/29850 (epoch 16.941), train_loss = 1.07307912, grad/param norm = 2.0603e-01, time/batch = 17.0378s	
10115/29850 (epoch 16.943), train_loss = 1.05810123, grad/param norm = 1.8787e-01, time/batch = 17.3078s	
10116/29850 (epoch 16.945), train_loss = 1.09200277, grad/param norm = 2.0041e-01, time/batch = 16.7194s	
10117/29850 (epoch 16.946), train_loss = 1.02103464, grad/param norm = 1.8786e-01, time/batch = 17.0522s	
10118/29850 (epoch 16.948), train_loss = 1.12464514, grad/param norm = 1.8243e-01, time/batch = 18.0442s	
10119/29850 (epoch 16.950), train_loss = 1.04011326, grad/param norm = 1.6994e-01, time/batch = 18.5387s	
10120/29850 (epoch 16.951), train_loss = 0.98863356, grad/param norm = 1.6773e-01, time/batch = 17.9760s	
10121/29850 (epoch 16.953), train_loss = 1.09880004, grad/param norm = 1.9225e-01, time/batch = 17.7909s	
10122/29850 (epoch 16.955), train_loss = 0.97894138, grad/param norm = 1.6595e-01, time/batch = 16.7887s	
10123/29850 (epoch 16.956), train_loss = 0.97401095, grad/param norm = 1.7506e-01, time/batch = 16.4608s	
10124/29850 (epoch 16.958), train_loss = 0.83476420, grad/param norm = 1.5793e-01, time/batch = 16.2126s	
10125/29850 (epoch 16.960), train_loss = 1.16857657, grad/param norm = 2.0942e-01, time/batch = 16.0563s	
10126/29850 (epoch 16.961), train_loss = 1.00941972, grad/param norm = 1.6738e-01, time/batch = 17.6889s	
10127/29850 (epoch 16.963), train_loss = 0.98549811, grad/param norm = 1.7119e-01, time/batch = 18.3670s	
10128/29850 (epoch 16.965), train_loss = 1.01910212, grad/param norm = 1.7800e-01, time/batch = 18.9493s	
10129/29850 (epoch 16.966), train_loss = 0.95273325, grad/param norm = 1.7869e-01, time/batch = 16.6798s	
10130/29850 (epoch 16.968), train_loss = 1.03561157, grad/param norm = 1.8690e-01, time/batch = 18.6224s	
10131/29850 (epoch 16.970), train_loss = 0.98376238, grad/param norm = 1.7702e-01, time/batch = 17.9740s	
10132/29850 (epoch 16.972), train_loss = 0.99549359, grad/param norm = 1.6899e-01, time/batch = 16.2050s	
10133/29850 (epoch 16.973), train_loss = 1.00738670, grad/param norm = 1.8033e-01, time/batch = 16.6121s	
10134/29850 (epoch 16.975), train_loss = 0.87102375, grad/param norm = 1.6841e-01, time/batch = 17.3185s	
10135/29850 (epoch 16.977), train_loss = 1.02025579, grad/param norm = 1.6249e-01, time/batch = 18.4597s	
10136/29850 (epoch 16.978), train_loss = 0.97381194, grad/param norm = 1.6087e-01, time/batch = 17.2876s	
10137/29850 (epoch 16.980), train_loss = 1.03572095, grad/param norm = 1.8071e-01, time/batch = 17.3108s	
10138/29850 (epoch 16.982), train_loss = 1.03705749, grad/param norm = 1.7724e-01, time/batch = 16.7931s	
10139/29850 (epoch 16.983), train_loss = 1.04194951, grad/param norm = 1.7170e-01, time/batch = 17.3059s	
10140/29850 (epoch 16.985), train_loss = 1.11368548, grad/param norm = 1.8425e-01, time/batch = 18.3073s	
10141/29850 (epoch 16.987), train_loss = 1.07113040, grad/param norm = 1.7404e-01, time/batch = 17.1406s	
10142/29850 (epoch 16.988), train_loss = 1.01409797, grad/param norm = 1.7683e-01, time/batch = 18.1258s	
10143/29850 (epoch 16.990), train_loss = 1.10851975, grad/param norm = 1.7848e-01, time/batch = 18.4674s	
10144/29850 (epoch 16.992), train_loss = 1.09600809, grad/param norm = 1.7742e-01, time/batch = 15.7815s	
10145/29850 (epoch 16.993), train_loss = 1.08337023, grad/param norm = 1.7805e-01, time/batch = 17.8879s	
10146/29850 (epoch 16.995), train_loss = 1.09669598, grad/param norm = 1.7235e-01, time/batch = 15.9724s	
10147/29850 (epoch 16.997), train_loss = 1.08732785, grad/param norm = 1.8599e-01, time/batch = 18.3866s	
10148/29850 (epoch 16.998), train_loss = 1.16280107, grad/param norm = 1.9121e-01, time/batch = 16.6137s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
10149/29850 (epoch 17.000), train_loss = 0.97247079, grad/param norm = 1.5985e-01, time/batch = 17.8794s	
10150/29850 (epoch 17.002), train_loss = 1.31079468, grad/param norm = 2.0444e-01, time/batch = 16.7713s	
10151/29850 (epoch 17.003), train_loss = 1.00444542, grad/param norm = 1.7104e-01, time/batch = 17.8898s	
10152/29850 (epoch 17.005), train_loss = 1.10621533, grad/param norm = 1.7187e-01, time/batch = 18.7264s	
10153/29850 (epoch 17.007), train_loss = 1.12955994, grad/param norm = 1.9702e-01, time/batch = 16.1320s	
10154/29850 (epoch 17.008), train_loss = 1.33993058, grad/param norm = 1.9771e-01, time/batch = 18.7915s	
10155/29850 (epoch 17.010), train_loss = 0.99668143, grad/param norm = 1.9187e-01, time/batch = 15.9746s	
10156/29850 (epoch 17.012), train_loss = 1.11519415, grad/param norm = 1.6694e-01, time/batch = 17.0407s	
10157/29850 (epoch 17.013), train_loss = 1.12179845, grad/param norm = 1.9987e-01, time/batch = 17.6902s	
10158/29850 (epoch 17.015), train_loss = 1.16360024, grad/param norm = 1.7707e-01, time/batch = 17.2980s	
10159/29850 (epoch 17.017), train_loss = 1.17253605, grad/param norm = 1.9892e-01, time/batch = 17.0428s	
10160/29850 (epoch 17.018), train_loss = 1.24643628, grad/param norm = 2.2206e-01, time/batch = 16.5281s	
10161/29850 (epoch 17.020), train_loss = 1.08628410, grad/param norm = 1.8890e-01, time/batch = 18.5652s	
10162/29850 (epoch 17.022), train_loss = 1.21789255, grad/param norm = 1.9016e-01, time/batch = 18.5581s	
10163/29850 (epoch 17.023), train_loss = 1.14785439, grad/param norm = 1.7185e-01, time/batch = 15.9551s	
10164/29850 (epoch 17.025), train_loss = 1.07321873, grad/param norm = 1.7125e-01, time/batch = 17.3812s	
10165/29850 (epoch 17.027), train_loss = 0.92977984, grad/param norm = 1.6678e-01, time/batch = 18.1321s	
10166/29850 (epoch 17.028), train_loss = 1.06492107, grad/param norm = 1.7620e-01, time/batch = 17.4662s	
10167/29850 (epoch 17.030), train_loss = 1.12168457, grad/param norm = 1.9138e-01, time/batch = 16.3828s	
10168/29850 (epoch 17.032), train_loss = 1.12098832, grad/param norm = 1.7575e-01, time/batch = 18.0478s	
10169/29850 (epoch 17.034), train_loss = 1.01437498, grad/param norm = 1.6693e-01, time/batch = 17.4555s	
10170/29850 (epoch 17.035), train_loss = 0.93509739, grad/param norm = 1.7002e-01, time/batch = 16.7567s	
10171/29850 (epoch 17.037), train_loss = 1.08931779, grad/param norm = 1.8020e-01, time/batch = 15.9422s	
10172/29850 (epoch 17.039), train_loss = 0.94745240, grad/param norm = 1.5601e-01, time/batch = 18.6426s	
10173/29850 (epoch 17.040), train_loss = 1.01587249, grad/param norm = 1.7788e-01, time/batch = 17.1228s	
10174/29850 (epoch 17.042), train_loss = 0.99788146, grad/param norm = 1.7082e-01, time/batch = 18.2223s	
10175/29850 (epoch 17.044), train_loss = 1.04344387, grad/param norm = 1.6350e-01, time/batch = 17.4794s	
10176/29850 (epoch 17.045), train_loss = 1.14376267, grad/param norm = 1.8039e-01, time/batch = 17.3943s	
10177/29850 (epoch 17.047), train_loss = 0.93218123, grad/param norm = 1.6412e-01, time/batch = 16.2950s	
10178/29850 (epoch 17.049), train_loss = 1.13065639, grad/param norm = 1.8323e-01, time/batch = 18.2985s	
10179/29850 (epoch 17.050), train_loss = 1.01256770, grad/param norm = 1.8151e-01, time/batch = 16.7162s	
10180/29850 (epoch 17.052), train_loss = 1.24668776, grad/param norm = 2.0940e-01, time/batch = 16.8000s	
10181/29850 (epoch 17.054), train_loss = 1.15020592, grad/param norm = 1.8964e-01, time/batch = 17.3876s	
10182/29850 (epoch 17.055), train_loss = 1.08061167, grad/param norm = 1.8059e-01, time/batch = 17.5654s	
10183/29850 (epoch 17.057), train_loss = 1.14902739, grad/param norm = 1.8024e-01, time/batch = 17.8067s	
10184/29850 (epoch 17.059), train_loss = 1.12137007, grad/param norm = 1.9250e-01, time/batch = 14.6186s	
10185/29850 (epoch 17.060), train_loss = 1.15438581, grad/param norm = 1.9148e-01, time/batch = 15.7085s	
10186/29850 (epoch 17.062), train_loss = 1.23491562, grad/param norm = 2.0476e-01, time/batch = 18.3069s	
10187/29850 (epoch 17.064), train_loss = 1.16274027, grad/param norm = 1.9004e-01, time/batch = 17.4721s	
10188/29850 (epoch 17.065), train_loss = 0.99796738, grad/param norm = 1.7447e-01, time/batch = 18.4471s	
10189/29850 (epoch 17.067), train_loss = 1.15158549, grad/param norm = 1.8872e-01, time/batch = 19.2042s	
10190/29850 (epoch 17.069), train_loss = 1.09890520, grad/param norm = 1.8573e-01, time/batch = 17.8812s	
10191/29850 (epoch 17.070), train_loss = 1.15031473, grad/param norm = 1.7714e-01, time/batch = 17.9490s	
10192/29850 (epoch 17.072), train_loss = 1.15218338, grad/param norm = 1.9861e-01, time/batch = 16.1097s	
10193/29850 (epoch 17.074), train_loss = 1.16798040, grad/param norm = 1.7830e-01, time/batch = 18.2676s	
10194/29850 (epoch 17.075), train_loss = 1.02895150, grad/param norm = 1.8049e-01, time/batch = 17.2876s	
10195/29850 (epoch 17.077), train_loss = 1.14898556, grad/param norm = 1.9977e-01, time/batch = 17.4727s	
10196/29850 (epoch 17.079), train_loss = 1.33730106, grad/param norm = 2.6569e-01, time/batch = 18.7954s	
10197/29850 (epoch 17.080), train_loss = 1.29815218, grad/param norm = 2.0866e-01, time/batch = 17.4620s	
10198/29850 (epoch 17.082), train_loss = 1.18834439, grad/param norm = 1.9873e-01, time/batch = 19.2828s	
10199/29850 (epoch 17.084), train_loss = 1.25050239, grad/param norm = 2.1441e-01, time/batch = 15.9730s	
10200/29850 (epoch 17.085), train_loss = 1.20517754, grad/param norm = 2.0955e-01, time/batch = 17.2291s	
10201/29850 (epoch 17.087), train_loss = 1.25658845, grad/param norm = 1.9923e-01, time/batch = 16.7067s	
10202/29850 (epoch 17.089), train_loss = 1.15190351, grad/param norm = 1.8647e-01, time/batch = 16.9514s	
10203/29850 (epoch 17.090), train_loss = 1.19397231, grad/param norm = 2.0307e-01, time/batch = 17.6487s	
10204/29850 (epoch 17.092), train_loss = 1.06942871, grad/param norm = 1.7773e-01, time/batch = 15.5751s	
10205/29850 (epoch 17.094), train_loss = 1.21167675, grad/param norm = 1.9656e-01, time/batch = 17.7008s	
10206/29850 (epoch 17.095), train_loss = 1.15989969, grad/param norm = 1.9123e-01, time/batch = 16.1517s	
10207/29850 (epoch 17.097), train_loss = 0.92560181, grad/param norm = 1.6747e-01, time/batch = 15.8073s	
10208/29850 (epoch 17.099), train_loss = 0.95631516, grad/param norm = 1.8064e-01, time/batch = 16.9832s	
10209/29850 (epoch 17.101), train_loss = 1.22549947, grad/param norm = 1.8507e-01, time/batch = 18.3867s	
10210/29850 (epoch 17.102), train_loss = 1.17660838, grad/param norm = 1.9903e-01, time/batch = 16.7242s	
10211/29850 (epoch 17.104), train_loss = 1.08047344, grad/param norm = 1.7951e-01, time/batch = 15.6128s	
10212/29850 (epoch 17.106), train_loss = 1.19104516, grad/param norm = 1.8188e-01, time/batch = 18.1266s	
10213/29850 (epoch 17.107), train_loss = 0.95360867, grad/param norm = 1.6853e-01, time/batch = 18.8783s	
10214/29850 (epoch 17.109), train_loss = 1.07383288, grad/param norm = 1.9103e-01, time/batch = 16.8126s	
10215/29850 (epoch 17.111), train_loss = 1.21816039, grad/param norm = 1.8869e-01, time/batch = 25.5919s	
10216/29850 (epoch 17.112), train_loss = 1.01354446, grad/param norm = 1.6977e-01, time/batch = 21.6781s	
10217/29850 (epoch 17.114), train_loss = 1.13437384, grad/param norm = 1.9832e-01, time/batch = 17.4660s	
10218/29850 (epoch 17.116), train_loss = 1.03153253, grad/param norm = 1.7452e-01, time/batch = 16.0514s	
10219/29850 (epoch 17.117), train_loss = 1.12145187, grad/param norm = 1.7706e-01, time/batch = 17.2305s	
10220/29850 (epoch 17.119), train_loss = 1.08871461, grad/param norm = 1.7597e-01, time/batch = 15.8747s	
10221/29850 (epoch 17.121), train_loss = 0.92619589, grad/param norm = 1.8102e-01, time/batch = 16.6489s	
10222/29850 (epoch 17.122), train_loss = 0.96099029, grad/param norm = 1.6465e-01, time/batch = 18.7081s	
10223/29850 (epoch 17.124), train_loss = 1.01700271, grad/param norm = 1.6996e-01, time/batch = 18.8057s	
10224/29850 (epoch 17.126), train_loss = 1.07645807, grad/param norm = 1.8821e-01, time/batch = 17.0212s	
10225/29850 (epoch 17.127), train_loss = 1.19497161, grad/param norm = 2.1328e-01, time/batch = 16.0365s	
10226/29850 (epoch 17.129), train_loss = 1.07153890, grad/param norm = 1.9143e-01, time/batch = 17.9709s	
10227/29850 (epoch 17.131), train_loss = 1.06683757, grad/param norm = 1.8147e-01, time/batch = 18.1272s	
10228/29850 (epoch 17.132), train_loss = 1.00228630, grad/param norm = 1.9532e-01, time/batch = 17.2908s	
10229/29850 (epoch 17.134), train_loss = 1.12688494, grad/param norm = 1.8001e-01, time/batch = 18.1341s	
10230/29850 (epoch 17.136), train_loss = 1.11366183, grad/param norm = 1.9122e-01, time/batch = 17.3025s	
10231/29850 (epoch 17.137), train_loss = 0.94197616, grad/param norm = 1.6009e-01, time/batch = 17.4599s	
10232/29850 (epoch 17.139), train_loss = 1.02027565, grad/param norm = 1.8435e-01, time/batch = 16.7294s	
10233/29850 (epoch 17.141), train_loss = 1.07226538, grad/param norm = 1.8628e-01, time/batch = 19.0426s	
10234/29850 (epoch 17.142), train_loss = 1.18717438, grad/param norm = 2.1316e-01, time/batch = 17.8082s	
10235/29850 (epoch 17.144), train_loss = 1.35282992, grad/param norm = 2.1579e-01, time/batch = 16.8671s	
10236/29850 (epoch 17.146), train_loss = 1.35194790, grad/param norm = 2.1648e-01, time/batch = 17.6254s	
10237/29850 (epoch 17.147), train_loss = 1.19654185, grad/param norm = 2.3337e-01, time/batch = 17.0391s	
10238/29850 (epoch 17.149), train_loss = 1.17330115, grad/param norm = 1.9830e-01, time/batch = 17.8768s	
10239/29850 (epoch 17.151), train_loss = 1.14911898, grad/param norm = 1.8696e-01, time/batch = 16.0367s	
10240/29850 (epoch 17.152), train_loss = 1.03799411, grad/param norm = 1.6473e-01, time/batch = 16.2769s	
10241/29850 (epoch 17.154), train_loss = 1.06706750, grad/param norm = 1.8830e-01, time/batch = 17.9608s	
10242/29850 (epoch 17.156), train_loss = 1.03593370, grad/param norm = 1.6545e-01, time/batch = 16.2206s	
10243/29850 (epoch 17.157), train_loss = 1.11505607, grad/param norm = 1.7743e-01, time/batch = 16.8074s	
10244/29850 (epoch 17.159), train_loss = 1.09242022, grad/param norm = 1.7710e-01, time/batch = 18.4708s	
10245/29850 (epoch 17.161), train_loss = 1.15160413, grad/param norm = 1.8299e-01, time/batch = 17.9559s	
10246/29850 (epoch 17.162), train_loss = 1.25620711, grad/param norm = 2.0249e-01, time/batch = 19.1244s	
10247/29850 (epoch 17.164), train_loss = 1.10442521, grad/param norm = 1.8405e-01, time/batch = 16.8739s	
10248/29850 (epoch 17.166), train_loss = 1.00935158, grad/param norm = 1.7134e-01, time/batch = 17.6299s	
10249/29850 (epoch 17.168), train_loss = 0.92527654, grad/param norm = 1.6440e-01, time/batch = 19.1241s	
10250/29850 (epoch 17.169), train_loss = 1.28326826, grad/param norm = 2.0380e-01, time/batch = 17.4636s	
10251/29850 (epoch 17.171), train_loss = 1.17981284, grad/param norm = 1.9630e-01, time/batch = 17.6846s	
10252/29850 (epoch 17.173), train_loss = 1.04371413, grad/param norm = 2.0469e-01, time/batch = 17.0275s	
10253/29850 (epoch 17.174), train_loss = 1.18450022, grad/param norm = 2.0276e-01, time/batch = 17.7981s	
10254/29850 (epoch 17.176), train_loss = 1.14707996, grad/param norm = 1.9493e-01, time/batch = 19.3639s	
10255/29850 (epoch 17.178), train_loss = 1.18220937, grad/param norm = 2.0466e-01, time/batch = 16.3902s	
10256/29850 (epoch 17.179), train_loss = 0.96482711, grad/param norm = 1.8508e-01, time/batch = 16.7149s	
10257/29850 (epoch 17.181), train_loss = 1.11065433, grad/param norm = 1.8174e-01, time/batch = 17.3855s	
10258/29850 (epoch 17.183), train_loss = 1.09189051, grad/param norm = 1.7963e-01, time/batch = 15.9926s	
10259/29850 (epoch 17.184), train_loss = 1.09419927, grad/param norm = 1.7800e-01, time/batch = 16.0467s	
10260/29850 (epoch 17.186), train_loss = 1.12700588, grad/param norm = 1.9050e-01, time/batch = 17.9587s	
10261/29850 (epoch 17.188), train_loss = 1.22711946, grad/param norm = 2.0812e-01, time/batch = 17.2153s	
10262/29850 (epoch 17.189), train_loss = 1.28235046, grad/param norm = 2.0973e-01, time/batch = 16.1382s	
10263/29850 (epoch 17.191), train_loss = 1.16897211, grad/param norm = 1.9578e-01, time/batch = 19.1294s	
10264/29850 (epoch 17.193), train_loss = 1.06967736, grad/param norm = 1.8777e-01, time/batch = 17.8515s	
10265/29850 (epoch 17.194), train_loss = 1.16312807, grad/param norm = 2.1632e-01, time/batch = 18.2096s	
10266/29850 (epoch 17.196), train_loss = 1.06223711, grad/param norm = 1.7563e-01, time/batch = 18.1173s	
10267/29850 (epoch 17.198), train_loss = 1.10930554, grad/param norm = 1.8557e-01, time/batch = 16.2204s	
10268/29850 (epoch 17.199), train_loss = 1.36594246, grad/param norm = 2.0656e-01, time/batch = 18.4555s	
10269/29850 (epoch 17.201), train_loss = 1.04249927, grad/param norm = 1.8807e-01, time/batch = 16.7150s	
10270/29850 (epoch 17.203), train_loss = 0.92237952, grad/param norm = 1.9301e-01, time/batch = 16.5196s	
10271/29850 (epoch 17.204), train_loss = 1.18321907, grad/param norm = 1.9688e-01, time/batch = 18.7080s	
10272/29850 (epoch 17.206), train_loss = 1.00652794, grad/param norm = 1.9084e-01, time/batch = 16.2237s	
10273/29850 (epoch 17.208), train_loss = 1.27118759, grad/param norm = 1.9339e-01, time/batch = 18.0413s	
10274/29850 (epoch 17.209), train_loss = 0.99680958, grad/param norm = 1.6451e-01, time/batch = 19.1300s	
10275/29850 (epoch 17.211), train_loss = 1.06392241, grad/param norm = 1.7235e-01, time/batch = 15.0491s	
10276/29850 (epoch 17.213), train_loss = 1.20538647, grad/param norm = 1.9007e-01, time/batch = 17.2951s	
10277/29850 (epoch 17.214), train_loss = 1.01329507, grad/param norm = 1.6547e-01, time/batch = 17.3687s	
10278/29850 (epoch 17.216), train_loss = 1.05242682, grad/param norm = 1.7402e-01, time/batch = 17.8927s	
10279/29850 (epoch 17.218), train_loss = 1.17967976, grad/param norm = 1.9219e-01, time/batch = 16.5309s	
10280/29850 (epoch 17.219), train_loss = 1.24904300, grad/param norm = 2.2095e-01, time/batch = 18.1297s	
10281/29850 (epoch 17.221), train_loss = 1.09216212, grad/param norm = 1.8007e-01, time/batch = 17.0569s	
10282/29850 (epoch 17.223), train_loss = 1.04724703, grad/param norm = 1.8716e-01, time/batch = 17.3894s	
10283/29850 (epoch 17.224), train_loss = 0.97088569, grad/param norm = 1.9220e-01, time/batch = 16.0141s	
10284/29850 (epoch 17.226), train_loss = 1.01183009, grad/param norm = 1.5383e-01, time/batch = 17.5316s	
10285/29850 (epoch 17.228), train_loss = 1.07414183, grad/param norm = 1.7312e-01, time/batch = 16.8079s	
10286/29850 (epoch 17.229), train_loss = 0.96385492, grad/param norm = 1.6667e-01, time/batch = 17.4607s	
10287/29850 (epoch 17.231), train_loss = 1.07737989, grad/param norm = 1.7986e-01, time/batch = 16.2699s	
10288/29850 (epoch 17.233), train_loss = 1.07582971, grad/param norm = 1.9607e-01, time/batch = 18.5501s	
10289/29850 (epoch 17.235), train_loss = 0.99780563, grad/param norm = 1.6492e-01, time/batch = 18.2056s	
10290/29850 (epoch 17.236), train_loss = 1.23342539, grad/param norm = 1.9261e-01, time/batch = 16.8061s	
10291/29850 (epoch 17.238), train_loss = 0.95523481, grad/param norm = 1.7087e-01, time/batch = 15.3568s	
10292/29850 (epoch 17.240), train_loss = 0.99196972, grad/param norm = 1.6738e-01, time/batch = 18.6332s	
10293/29850 (epoch 17.241), train_loss = 1.18803057, grad/param norm = 2.0681e-01, time/batch = 16.7126s	
10294/29850 (epoch 17.243), train_loss = 1.11330818, grad/param norm = 1.9119e-01, time/batch = 19.6207s	
10295/29850 (epoch 17.245), train_loss = 1.04240143, grad/param norm = 1.9848e-01, time/batch = 17.0538s	
10296/29850 (epoch 17.246), train_loss = 0.99500776, grad/param norm = 1.7838e-01, time/batch = 17.4748s	
10297/29850 (epoch 17.248), train_loss = 0.97927004, grad/param norm = 1.6506e-01, time/batch = 17.2065s	
10298/29850 (epoch 17.250), train_loss = 1.07279649, grad/param norm = 1.8036e-01, time/batch = 17.8972s	
10299/29850 (epoch 17.251), train_loss = 0.96495229, grad/param norm = 1.9598e-01, time/batch = 17.2991s	
10300/29850 (epoch 17.253), train_loss = 0.91667096, grad/param norm = 1.7694e-01, time/batch = 13.9679s	
10301/29850 (epoch 17.255), train_loss = 0.98917209, grad/param norm = 1.8762e-01, time/batch = 0.6533s	
10302/29850 (epoch 17.256), train_loss = 1.13150674, grad/param norm = 1.9749e-01, time/batch = 0.6451s	
10303/29850 (epoch 17.258), train_loss = 1.10627534, grad/param norm = 1.8348e-01, time/batch = 0.6534s	
10304/29850 (epoch 17.260), train_loss = 1.06693045, grad/param norm = 1.8051e-01, time/batch = 0.6710s	
10305/29850 (epoch 17.261), train_loss = 1.02667294, grad/param norm = 1.9551e-01, time/batch = 0.6565s	
10306/29850 (epoch 17.263), train_loss = 1.00188838, grad/param norm = 1.7448e-01, time/batch = 0.6462s	
10307/29850 (epoch 17.265), train_loss = 1.06191135, grad/param norm = 1.9506e-01, time/batch = 0.6518s	
10308/29850 (epoch 17.266), train_loss = 1.06124339, grad/param norm = 1.8989e-01, time/batch = 0.7871s	
10309/29850 (epoch 17.268), train_loss = 1.02905027, grad/param norm = 1.6727e-01, time/batch = 0.9399s	
10310/29850 (epoch 17.270), train_loss = 0.99418080, grad/param norm = 1.6129e-01, time/batch = 0.9554s	
10311/29850 (epoch 17.271), train_loss = 1.18605847, grad/param norm = 1.7928e-01, time/batch = 0.9510s	
10312/29850 (epoch 17.273), train_loss = 0.92801011, grad/param norm = 1.8052e-01, time/batch = 0.9655s	
10313/29850 (epoch 17.275), train_loss = 0.93096650, grad/param norm = 1.6811e-01, time/batch = 1.2421s	
10314/29850 (epoch 17.276), train_loss = 0.95577092, grad/param norm = 1.6888e-01, time/batch = 1.8378s	
10315/29850 (epoch 17.278), train_loss = 1.02585262, grad/param norm = 1.7584e-01, time/batch = 1.8112s	
10316/29850 (epoch 17.280), train_loss = 1.21733958, grad/param norm = 2.0637e-01, time/batch = 9.3353s	
10317/29850 (epoch 17.281), train_loss = 1.12531626, grad/param norm = 1.9832e-01, time/batch = 17.5529s	
10318/29850 (epoch 17.283), train_loss = 1.22787971, grad/param norm = 1.9941e-01, time/batch = 16.3794s	
10319/29850 (epoch 17.285), train_loss = 1.07345385, grad/param norm = 1.8694e-01, time/batch = 16.3888s	
10320/29850 (epoch 17.286), train_loss = 1.18971967, grad/param norm = 2.0537e-01, time/batch = 18.5339s	
10321/29850 (epoch 17.288), train_loss = 1.24983560, grad/param norm = 2.4511e-01, time/batch = 18.3798s	
10322/29850 (epoch 17.290), train_loss = 1.05672010, grad/param norm = 1.9310e-01, time/batch = 18.3758s	
10323/29850 (epoch 17.291), train_loss = 1.32731310, grad/param norm = 1.9532e-01, time/batch = 16.8981s	
10324/29850 (epoch 17.293), train_loss = 1.20663221, grad/param norm = 2.6619e-01, time/batch = 19.2055s	
10325/29850 (epoch 17.295), train_loss = 1.28819359, grad/param norm = 2.2422e-01, time/batch = 17.7916s	
10326/29850 (epoch 17.296), train_loss = 1.04008531, grad/param norm = 2.0779e-01, time/batch = 17.7168s	
10327/29850 (epoch 17.298), train_loss = 0.89516813, grad/param norm = 1.8058e-01, time/batch = 18.1211s	
10328/29850 (epoch 17.300), train_loss = 0.97452483, grad/param norm = 1.7350e-01, time/batch = 16.7198s	
10329/29850 (epoch 17.302), train_loss = 0.96574455, grad/param norm = 1.7744e-01, time/batch = 17.6284s	
10330/29850 (epoch 17.303), train_loss = 1.00581887, grad/param norm = 1.7979e-01, time/batch = 16.7263s	
10331/29850 (epoch 17.305), train_loss = 1.13370284, grad/param norm = 2.0031e-01, time/batch = 17.4525s	
10332/29850 (epoch 17.307), train_loss = 1.18141331, grad/param norm = 1.9420e-01, time/batch = 16.5339s	
10333/29850 (epoch 17.308), train_loss = 1.07337463, grad/param norm = 2.0024e-01, time/batch = 17.9604s	
10334/29850 (epoch 17.310), train_loss = 1.12393586, grad/param norm = 2.1014e-01, time/batch = 15.7150s	
10335/29850 (epoch 17.312), train_loss = 1.16915724, grad/param norm = 1.8951e-01, time/batch = 16.9797s	
10336/29850 (epoch 17.313), train_loss = 1.09432573, grad/param norm = 1.8341e-01, time/batch = 16.7006s	
10337/29850 (epoch 17.315), train_loss = 1.12961121, grad/param norm = 1.8905e-01, time/batch = 17.7163s	
10338/29850 (epoch 17.317), train_loss = 1.11515498, grad/param norm = 1.9118e-01, time/batch = 17.2259s	
10339/29850 (epoch 17.318), train_loss = 1.08836267, grad/param norm = 1.8997e-01, time/batch = 16.1062s	
10340/29850 (epoch 17.320), train_loss = 1.01080423, grad/param norm = 1.5662e-01, time/batch = 16.9780s	
10341/29850 (epoch 17.322), train_loss = 1.26465511, grad/param norm = 2.1286e-01, time/batch = 18.2245s	
10342/29850 (epoch 17.323), train_loss = 1.16192922, grad/param norm = 1.9855e-01, time/batch = 17.1878s	
10343/29850 (epoch 17.325), train_loss = 1.16755308, grad/param norm = 1.9905e-01, time/batch = 18.0251s	
10344/29850 (epoch 17.327), train_loss = 1.28754455, grad/param norm = 2.0993e-01, time/batch = 18.3078s	
10345/29850 (epoch 17.328), train_loss = 1.26222728, grad/param norm = 2.0147e-01, time/batch = 17.2240s	
10346/29850 (epoch 17.330), train_loss = 1.12940391, grad/param norm = 1.8200e-01, time/batch = 16.6139s	
10347/29850 (epoch 17.332), train_loss = 1.04562127, grad/param norm = 1.7829e-01, time/batch = 17.7983s	
10348/29850 (epoch 17.333), train_loss = 1.23520676, grad/param norm = 1.9415e-01, time/batch = 18.1486s	
10349/29850 (epoch 17.335), train_loss = 1.19189848, grad/param norm = 1.9641e-01, time/batch = 17.5213s	
10350/29850 (epoch 17.337), train_loss = 1.11563860, grad/param norm = 1.9070e-01, time/batch = 18.3816s	
10351/29850 (epoch 17.338), train_loss = 1.10932443, grad/param norm = 1.7155e-01, time/batch = 17.0520s	
10352/29850 (epoch 17.340), train_loss = 1.00048610, grad/param norm = 1.8334e-01, time/batch = 15.1828s	
10353/29850 (epoch 17.342), train_loss = 1.10436198, grad/param norm = 1.8539e-01, time/batch = 16.1074s	
10354/29850 (epoch 17.343), train_loss = 1.15116110, grad/param norm = 2.0557e-01, time/batch = 17.6403s	
10355/29850 (epoch 17.345), train_loss = 1.18722972, grad/param norm = 2.5000e-01, time/batch = 18.5561s	
10356/29850 (epoch 17.347), train_loss = 1.21981009, grad/param norm = 2.1313e-01, time/batch = 16.4627s	
10357/29850 (epoch 17.348), train_loss = 1.06833263, grad/param norm = 1.9157e-01, time/batch = 18.3874s	
10358/29850 (epoch 17.350), train_loss = 1.20490320, grad/param norm = 2.1731e-01, time/batch = 17.8712s	
10359/29850 (epoch 17.352), train_loss = 1.08122784, grad/param norm = 1.7258e-01, time/batch = 17.2018s	
10360/29850 (epoch 17.353), train_loss = 1.15587512, grad/param norm = 1.8843e-01, time/batch = 17.9789s	
10361/29850 (epoch 17.355), train_loss = 0.99901843, grad/param norm = 1.7606e-01, time/batch = 16.7930s	
10362/29850 (epoch 17.357), train_loss = 1.26622226, grad/param norm = 2.0002e-01, time/batch = 17.6501s	
10363/29850 (epoch 17.358), train_loss = 1.01765606, grad/param norm = 1.7588e-01, time/batch = 16.7036s	
10364/29850 (epoch 17.360), train_loss = 1.09428479, grad/param norm = 1.7726e-01, time/batch = 17.8987s	
10365/29850 (epoch 17.362), train_loss = 1.10142531, grad/param norm = 1.8764e-01, time/batch = 17.8044s	
10366/29850 (epoch 17.363), train_loss = 1.14333641, grad/param norm = 2.0146e-01, time/batch = 17.4539s	
10367/29850 (epoch 17.365), train_loss = 1.28144870, grad/param norm = 2.0582e-01, time/batch = 17.6358s	
10368/29850 (epoch 17.367), train_loss = 1.07940491, grad/param norm = 1.9582e-01, time/batch = 18.2119s	
10369/29850 (epoch 17.369), train_loss = 0.98077122, grad/param norm = 1.7482e-01, time/batch = 17.0372s	
10370/29850 (epoch 17.370), train_loss = 0.91515200, grad/param norm = 1.9064e-01, time/batch = 16.1256s	
10371/29850 (epoch 17.372), train_loss = 1.21659659, grad/param norm = 2.1346e-01, time/batch = 17.2146s	
10372/29850 (epoch 17.374), train_loss = 1.12047650, grad/param norm = 1.8892e-01, time/batch = 19.7119s	
10373/29850 (epoch 17.375), train_loss = 1.11490017, grad/param norm = 1.9078e-01, time/batch = 15.6046s	
10374/29850 (epoch 17.377), train_loss = 1.09521988, grad/param norm = 1.9959e-01, time/batch = 18.0478s	
10375/29850 (epoch 17.379), train_loss = 1.20551090, grad/param norm = 2.0761e-01, time/batch = 17.3868s	
10376/29850 (epoch 17.380), train_loss = 1.16434707, grad/param norm = 1.9444e-01, time/batch = 15.9632s	
10377/29850 (epoch 17.382), train_loss = 1.16095569, grad/param norm = 2.1518e-01, time/batch = 19.0885s	
10378/29850 (epoch 17.384), train_loss = 1.15751840, grad/param norm = 1.8827e-01, time/batch = 17.3742s	
10379/29850 (epoch 17.385), train_loss = 1.11579551, grad/param norm = 1.9539e-01, time/batch = 19.1292s	
10380/29850 (epoch 17.387), train_loss = 1.16904898, grad/param norm = 2.0672e-01, time/batch = 15.7935s	
10381/29850 (epoch 17.389), train_loss = 1.28916764, grad/param norm = 2.1214e-01, time/batch = 18.5493s	
10382/29850 (epoch 17.390), train_loss = 1.15629107, grad/param norm = 1.8467e-01, time/batch = 17.9707s	
10383/29850 (epoch 17.392), train_loss = 1.12327661, grad/param norm = 2.2071e-01, time/batch = 16.7210s	
10384/29850 (epoch 17.394), train_loss = 1.21799463, grad/param norm = 1.9175e-01, time/batch = 17.2667s	
10385/29850 (epoch 17.395), train_loss = 1.09870178, grad/param norm = 1.9285e-01, time/batch = 17.0410s	
10386/29850 (epoch 17.397), train_loss = 0.98397071, grad/param norm = 1.7288e-01, time/batch = 17.9009s	
10387/29850 (epoch 17.399), train_loss = 1.02163069, grad/param norm = 1.7593e-01, time/batch = 17.1176s	
10388/29850 (epoch 17.400), train_loss = 1.40710255, grad/param norm = 2.1255e-01, time/batch = 18.3002s	
10389/29850 (epoch 17.402), train_loss = 1.29772275, grad/param norm = 1.8474e-01, time/batch = 16.3751s	
10390/29850 (epoch 17.404), train_loss = 1.15465639, grad/param norm = 1.9425e-01, time/batch = 16.2055s	
10391/29850 (epoch 17.405), train_loss = 1.05251336, grad/param norm = 1.9558e-01, time/batch = 19.2232s	
10392/29850 (epoch 17.407), train_loss = 1.02641534, grad/param norm = 1.7940e-01, time/batch = 17.4580s	
10393/29850 (epoch 17.409), train_loss = 1.20861457, grad/param norm = 2.0471e-01, time/batch = 17.5285s	
10394/29850 (epoch 17.410), train_loss = 1.29366743, grad/param norm = 2.0081e-01, time/batch = 17.0182s	
10395/29850 (epoch 17.412), train_loss = 1.19737138, grad/param norm = 1.9226e-01, time/batch = 17.3131s	
10396/29850 (epoch 17.414), train_loss = 1.13129911, grad/param norm = 2.2401e-01, time/batch = 18.5512s	
10397/29850 (epoch 17.415), train_loss = 1.13954904, grad/param norm = 1.8360e-01, time/batch = 16.4478s	
10398/29850 (epoch 17.417), train_loss = 1.28226845, grad/param norm = 2.1779e-01, time/batch = 19.0511s	
10399/29850 (epoch 17.419), train_loss = 1.13517588, grad/param norm = 1.9741e-01, time/batch = 17.2192s	
10400/29850 (epoch 17.420), train_loss = 1.13350304, grad/param norm = 1.8748e-01, time/batch = 17.2939s	
10401/29850 (epoch 17.422), train_loss = 1.10736642, grad/param norm = 1.9655e-01, time/batch = 17.8818s	
10402/29850 (epoch 17.424), train_loss = 1.06505821, grad/param norm = 1.7847e-01, time/batch = 17.8855s	
10403/29850 (epoch 17.425), train_loss = 1.27198505, grad/param norm = 2.0373e-01, time/batch = 17.5504s	
10404/29850 (epoch 17.427), train_loss = 0.93738671, grad/param norm = 1.6987e-01, time/batch = 16.6182s	
10405/29850 (epoch 17.429), train_loss = 1.00892928, grad/param norm = 1.8265e-01, time/batch = 19.4411s	
10406/29850 (epoch 17.430), train_loss = 0.93068803, grad/param norm = 1.6086e-01, time/batch = 16.8820s	
10407/29850 (epoch 17.432), train_loss = 1.09311731, grad/param norm = 2.0349e-01, time/batch = 16.4710s	
10408/29850 (epoch 17.434), train_loss = 0.98291972, grad/param norm = 1.7114e-01, time/batch = 16.3200s	
10409/29850 (epoch 17.436), train_loss = 1.12922928, grad/param norm = 1.8793e-01, time/batch = 19.1248s	
10410/29850 (epoch 17.437), train_loss = 1.17135500, grad/param norm = 1.8475e-01, time/batch = 17.6325s	
10411/29850 (epoch 17.439), train_loss = 1.12589426, grad/param norm = 1.8429e-01, time/batch = 16.9329s	
10412/29850 (epoch 17.441), train_loss = 1.13384093, grad/param norm = 2.0805e-01, time/batch = 19.2153s	
10413/29850 (epoch 17.442), train_loss = 1.16518387, grad/param norm = 2.1190e-01, time/batch = 16.2192s	
10414/29850 (epoch 17.444), train_loss = 1.14138636, grad/param norm = 1.9472e-01, time/batch = 17.8517s	
10415/29850 (epoch 17.446), train_loss = 1.15975349, grad/param norm = 1.8311e-01, time/batch = 17.3760s	
10416/29850 (epoch 17.447), train_loss = 1.16176302, grad/param norm = 1.8801e-01, time/batch = 18.8052s	
10417/29850 (epoch 17.449), train_loss = 1.15310312, grad/param norm = 2.0204e-01, time/batch = 17.1914s	
10418/29850 (epoch 17.451), train_loss = 0.95338010, grad/param norm = 1.7351e-01, time/batch = 17.8067s	
10419/29850 (epoch 17.452), train_loss = 0.84480798, grad/param norm = 1.5342e-01, time/batch = 16.2882s	
10420/29850 (epoch 17.454), train_loss = 0.98036742, grad/param norm = 1.6571e-01, time/batch = 16.0512s	
10421/29850 (epoch 17.456), train_loss = 1.16133118, grad/param norm = 1.9654e-01, time/batch = 17.0209s	
10422/29850 (epoch 17.457), train_loss = 1.17259572, grad/param norm = 2.2497e-01, time/batch = 17.7125s	
10423/29850 (epoch 17.459), train_loss = 1.30386758, grad/param norm = 2.0404e-01, time/batch = 18.0327s	
10424/29850 (epoch 17.461), train_loss = 1.27987054, grad/param norm = 1.9730e-01, time/batch = 17.0604s	
10425/29850 (epoch 17.462), train_loss = 1.25790009, grad/param norm = 2.2133e-01, time/batch = 17.8817s	
10426/29850 (epoch 17.464), train_loss = 1.17833776, grad/param norm = 1.8137e-01, time/batch = 18.7169s	
10427/29850 (epoch 17.466), train_loss = 1.00228374, grad/param norm = 1.9020e-01, time/batch = 17.6433s	
10428/29850 (epoch 17.467), train_loss = 1.10313440, grad/param norm = 1.9115e-01, time/batch = 18.9508s	
10429/29850 (epoch 17.469), train_loss = 1.08448884, grad/param norm = 1.8694e-01, time/batch = 16.7978s	
10430/29850 (epoch 17.471), train_loss = 1.12995510, grad/param norm = 2.0757e-01, time/batch = 17.5567s	
10431/29850 (epoch 17.472), train_loss = 1.04440585, grad/param norm = 1.8007e-01, time/batch = 18.2921s	
10432/29850 (epoch 17.474), train_loss = 1.23222857, grad/param norm = 1.9160e-01, time/batch = 18.6314s	
10433/29850 (epoch 17.476), train_loss = 1.15480142, grad/param norm = 1.8582e-01, time/batch = 18.0406s	
10434/29850 (epoch 17.477), train_loss = 1.15784696, grad/param norm = 2.2460e-01, time/batch = 25.5938s	
10435/29850 (epoch 17.479), train_loss = 1.29152654, grad/param norm = 2.1774e-01, time/batch = 23.0542s	
10436/29850 (epoch 17.481), train_loss = 1.14359518, grad/param norm = 1.9721e-01, time/batch = 17.4852s	
10437/29850 (epoch 17.482), train_loss = 1.04112141, grad/param norm = 1.6741e-01, time/batch = 15.1938s	
10438/29850 (epoch 17.484), train_loss = 1.05521363, grad/param norm = 1.8180e-01, time/batch = 17.0346s	
10439/29850 (epoch 17.486), train_loss = 1.13210847, grad/param norm = 1.8073e-01, time/batch = 17.1092s	
10440/29850 (epoch 17.487), train_loss = 1.11013251, grad/param norm = 1.9977e-01, time/batch = 16.7158s	
10441/29850 (epoch 17.489), train_loss = 1.11595052, grad/param norm = 1.9577e-01, time/batch = 17.3660s	
10442/29850 (epoch 17.491), train_loss = 1.00615273, grad/param norm = 1.6667e-01, time/batch = 18.3877s	
10443/29850 (epoch 17.492), train_loss = 1.13714923, grad/param norm = 1.9890e-01, time/batch = 18.2830s	
10444/29850 (epoch 17.494), train_loss = 1.24591703, grad/param norm = 1.7996e-01, time/batch = 18.5993s	
10445/29850 (epoch 17.496), train_loss = 1.26385987, grad/param norm = 1.8872e-01, time/batch = 15.9148s	
10446/29850 (epoch 17.497), train_loss = 1.18650945, grad/param norm = 1.7278e-01, time/batch = 16.8833s	
10447/29850 (epoch 17.499), train_loss = 1.11945322, grad/param norm = 1.7940e-01, time/batch = 17.2044s	
10448/29850 (epoch 17.501), train_loss = 1.06562375, grad/param norm = 1.7538e-01, time/batch = 18.7956s	
10449/29850 (epoch 17.503), train_loss = 1.11931055, grad/param norm = 1.8661e-01, time/batch = 15.1200s	
10450/29850 (epoch 17.504), train_loss = 1.34874514, grad/param norm = 1.9408e-01, time/batch = 18.5454s	
10451/29850 (epoch 17.506), train_loss = 1.29463573, grad/param norm = 2.0624e-01, time/batch = 16.7130s	
10452/29850 (epoch 17.508), train_loss = 1.12466612, grad/param norm = 1.9435e-01, time/batch = 17.9592s	
10453/29850 (epoch 17.509), train_loss = 0.91382177, grad/param norm = 1.7710e-01, time/batch = 17.9527s	
10454/29850 (epoch 17.511), train_loss = 1.11855146, grad/param norm = 1.8728e-01, time/batch = 15.5652s	
10455/29850 (epoch 17.513), train_loss = 1.14417068, grad/param norm = 2.1124e-01, time/batch = 15.3795s	
10456/29850 (epoch 17.514), train_loss = 0.99806526, grad/param norm = 1.7954e-01, time/batch = 18.9591s	
10457/29850 (epoch 17.516), train_loss = 1.03821813, grad/param norm = 1.7121e-01, time/batch = 18.0442s	
10458/29850 (epoch 17.518), train_loss = 0.95257443, grad/param norm = 1.7444e-01, time/batch = 17.2093s	
10459/29850 (epoch 17.519), train_loss = 0.95134430, grad/param norm = 1.6725e-01, time/batch = 16.3768s	
10460/29850 (epoch 17.521), train_loss = 0.93100594, grad/param norm = 1.6697e-01, time/batch = 16.0571s	
10461/29850 (epoch 17.523), train_loss = 0.96814434, grad/param norm = 1.5519e-01, time/batch = 17.7934s	
10462/29850 (epoch 17.524), train_loss = 1.05918419, grad/param norm = 1.9014e-01, time/batch = 18.1279s	
10463/29850 (epoch 17.526), train_loss = 1.15404672, grad/param norm = 1.9460e-01, time/batch = 16.8043s	
10464/29850 (epoch 17.528), train_loss = 1.23315346, grad/param norm = 2.0629e-01, time/batch = 17.6252s	
10465/29850 (epoch 17.529), train_loss = 1.14635244, grad/param norm = 1.9004e-01, time/batch = 17.6366s	
10466/29850 (epoch 17.531), train_loss = 1.09884857, grad/param norm = 2.0907e-01, time/batch = 17.8974s	
10467/29850 (epoch 17.533), train_loss = 1.07462338, grad/param norm = 1.9004e-01, time/batch = 16.9700s	
10468/29850 (epoch 17.534), train_loss = 1.12417604, grad/param norm = 1.8810e-01, time/batch = 15.6337s	
10469/29850 (epoch 17.536), train_loss = 1.08901027, grad/param norm = 1.9719e-01, time/batch = 19.0389s	
10470/29850 (epoch 17.538), train_loss = 1.23453679, grad/param norm = 1.9537e-01, time/batch = 17.3049s	
10471/29850 (epoch 17.539), train_loss = 1.30324739, grad/param norm = 2.1465e-01, time/batch = 15.5408s	
10472/29850 (epoch 17.541), train_loss = 0.92323377, grad/param norm = 1.7155e-01, time/batch = 16.0438s	
10473/29850 (epoch 17.543), train_loss = 1.10719567, grad/param norm = 1.8189e-01, time/batch = 18.8825s	
10474/29850 (epoch 17.544), train_loss = 1.14767816, grad/param norm = 1.9902e-01, time/batch = 17.1430s	
10475/29850 (epoch 17.546), train_loss = 1.20657388, grad/param norm = 1.9173e-01, time/batch = 16.9598s	
10476/29850 (epoch 17.548), train_loss = 0.96810037, grad/param norm = 1.7167e-01, time/batch = 18.3909s	
10477/29850 (epoch 17.549), train_loss = 1.05731336, grad/param norm = 1.7622e-01, time/batch = 15.9760s	
10478/29850 (epoch 17.551), train_loss = 0.99247795, grad/param norm = 1.7227e-01, time/batch = 15.9448s	
10479/29850 (epoch 17.553), train_loss = 1.11065439, grad/param norm = 1.8512e-01, time/batch = 17.7232s	
10480/29850 (epoch 17.554), train_loss = 0.94581893, grad/param norm = 1.6529e-01, time/batch = 18.4667s	
10481/29850 (epoch 17.556), train_loss = 1.04546629, grad/param norm = 2.1303e-01, time/batch = 17.2192s	
10482/29850 (epoch 17.558), train_loss = 1.02597888, grad/param norm = 1.7618e-01, time/batch = 18.5322s	
10483/29850 (epoch 17.559), train_loss = 1.08492340, grad/param norm = 1.8109e-01, time/batch = 16.9612s	
10484/29850 (epoch 17.561), train_loss = 1.17899968, grad/param norm = 2.1020e-01, time/batch = 18.7980s	
10485/29850 (epoch 17.563), train_loss = 1.10437505, grad/param norm = 1.7975e-01, time/batch = 17.2008s	
10486/29850 (epoch 17.564), train_loss = 1.08772804, grad/param norm = 2.0593e-01, time/batch = 17.0591s	
10487/29850 (epoch 17.566), train_loss = 1.10140413, grad/param norm = 1.9152e-01, time/batch = 16.6952s	
10488/29850 (epoch 17.568), train_loss = 1.23168251, grad/param norm = 1.9721e-01, time/batch = 18.1286s	
10489/29850 (epoch 17.570), train_loss = 1.12505573, grad/param norm = 1.8265e-01, time/batch = 16.6272s	
10490/29850 (epoch 17.571), train_loss = 1.16808485, grad/param norm = 1.9941e-01, time/batch = 18.3788s	
10491/29850 (epoch 17.573), train_loss = 1.27322231, grad/param norm = 2.3832e-01, time/batch = 17.8621s	
10492/29850 (epoch 17.575), train_loss = 1.22611541, grad/param norm = 1.7752e-01, time/batch = 16.5577s	
10493/29850 (epoch 17.576), train_loss = 1.20114826, grad/param norm = 1.8153e-01, time/batch = 16.4864s	
10494/29850 (epoch 17.578), train_loss = 1.08865901, grad/param norm = 1.9231e-01, time/batch = 17.7850s	
10495/29850 (epoch 17.580), train_loss = 1.24595122, grad/param norm = 1.9937e-01, time/batch = 17.4512s	
10496/29850 (epoch 17.581), train_loss = 1.02623248, grad/param norm = 1.7533e-01, time/batch = 16.8071s	
10497/29850 (epoch 17.583), train_loss = 1.09632160, grad/param norm = 1.9202e-01, time/batch = 17.5668s	
10498/29850 (epoch 17.585), train_loss = 1.14374959, grad/param norm = 1.7387e-01, time/batch = 17.5673s	
10499/29850 (epoch 17.586), train_loss = 1.15208251, grad/param norm = 1.8828e-01, time/batch = 17.7922s	
10500/29850 (epoch 17.588), train_loss = 1.08900977, grad/param norm = 2.0442e-01, time/batch = 16.5590s	
10501/29850 (epoch 17.590), train_loss = 1.10463774, grad/param norm = 1.8650e-01, time/batch = 17.7102s	
10502/29850 (epoch 17.591), train_loss = 1.05165941, grad/param norm = 1.8625e-01, time/batch = 16.8693s	
10503/29850 (epoch 17.593), train_loss = 1.03566475, grad/param norm = 1.7546e-01, time/batch = 17.5234s	
10504/29850 (epoch 17.595), train_loss = 0.98405437, grad/param norm = 1.6086e-01, time/batch = 17.3791s	
10505/29850 (epoch 17.596), train_loss = 0.97004916, grad/param norm = 1.9511e-01, time/batch = 18.2990s	
10506/29850 (epoch 17.598), train_loss = 1.04020877, grad/param norm = 1.7654e-01, time/batch = 16.5393s	
10507/29850 (epoch 17.600), train_loss = 1.18445122, grad/param norm = 1.9533e-01, time/batch = 17.9567s	
10508/29850 (epoch 17.601), train_loss = 0.98367499, grad/param norm = 1.8030e-01, time/batch = 16.8930s	
10509/29850 (epoch 17.603), train_loss = 1.07938031, grad/param norm = 2.0494e-01, time/batch = 17.1171s	
10510/29850 (epoch 17.605), train_loss = 1.09235313, grad/param norm = 2.0081e-01, time/batch = 17.7870s	
10511/29850 (epoch 17.606), train_loss = 0.85399848, grad/param norm = 1.5952e-01, time/batch = 15.6922s	
10512/29850 (epoch 17.608), train_loss = 1.07308951, grad/param norm = 1.8094e-01, time/batch = 19.0488s	
10513/29850 (epoch 17.610), train_loss = 1.10601393, grad/param norm = 1.8604e-01, time/batch = 18.4540s	
10514/29850 (epoch 17.611), train_loss = 0.99418273, grad/param norm = 1.7045e-01, time/batch = 18.8079s	
10515/29850 (epoch 17.613), train_loss = 0.86005289, grad/param norm = 1.6073e-01, time/batch = 17.2976s	
10516/29850 (epoch 17.615), train_loss = 0.97535945, grad/param norm = 1.7069e-01, time/batch = 16.6198s	
10517/29850 (epoch 17.616), train_loss = 0.98249035, grad/param norm = 1.7856e-01, time/batch = 19.0460s	
10518/29850 (epoch 17.618), train_loss = 1.06031551, grad/param norm = 1.8201e-01, time/batch = 16.5370s	
10519/29850 (epoch 17.620), train_loss = 1.13306241, grad/param norm = 1.9804e-01, time/batch = 16.7848s	
10520/29850 (epoch 17.621), train_loss = 1.22696201, grad/param norm = 1.9448e-01, time/batch = 15.3834s	
10521/29850 (epoch 17.623), train_loss = 1.16762168, grad/param norm = 1.8267e-01, time/batch = 17.8942s	
10522/29850 (epoch 17.625), train_loss = 1.12199802, grad/param norm = 1.9160e-01, time/batch = 18.5438s	
10523/29850 (epoch 17.626), train_loss = 1.14327763, grad/param norm = 1.9033e-01, time/batch = 16.7104s	
10524/29850 (epoch 17.628), train_loss = 0.98735035, grad/param norm = 1.6437e-01, time/batch = 17.2150s	
10525/29850 (epoch 17.630), train_loss = 1.09068245, grad/param norm = 1.8907e-01, time/batch = 16.5675s	
10526/29850 (epoch 17.631), train_loss = 1.04766045, grad/param norm = 1.8665e-01, time/batch = 16.8899s	
10527/29850 (epoch 17.633), train_loss = 1.17840199, grad/param norm = 1.9616e-01, time/batch = 15.3392s	
10528/29850 (epoch 17.635), train_loss = 1.08060512, grad/param norm = 1.8553e-01, time/batch = 18.6312s	
10529/29850 (epoch 17.637), train_loss = 1.01574220, grad/param norm = 1.7888e-01, time/batch = 18.3906s	
10530/29850 (epoch 17.638), train_loss = 1.09721770, grad/param norm = 1.8262e-01, time/batch = 16.4788s	
10531/29850 (epoch 17.640), train_loss = 1.24592445, grad/param norm = 2.0895e-01, time/batch = 18.9599s	
10532/29850 (epoch 17.642), train_loss = 1.03319673, grad/param norm = 1.5785e-01, time/batch = 15.9885s	
10533/29850 (epoch 17.643), train_loss = 1.01712454, grad/param norm = 1.8436e-01, time/batch = 17.3866s	
10534/29850 (epoch 17.645), train_loss = 1.11154835, grad/param norm = 1.8377e-01, time/batch = 17.9636s	
10535/29850 (epoch 17.647), train_loss = 1.22309538, grad/param norm = 1.8116e-01, time/batch = 17.1348s	
10536/29850 (epoch 17.648), train_loss = 0.96875728, grad/param norm = 1.6626e-01, time/batch = 17.0615s	
10537/29850 (epoch 17.650), train_loss = 1.10155012, grad/param norm = 1.9746e-01, time/batch = 15.2085s	
10538/29850 (epoch 17.652), train_loss = 1.11578529, grad/param norm = 1.8307e-01, time/batch = 14.9752s	
10539/29850 (epoch 17.653), train_loss = 1.20323173, grad/param norm = 2.0820e-01, time/batch = 17.6378s	
10540/29850 (epoch 17.655), train_loss = 1.08390754, grad/param norm = 1.7353e-01, time/batch = 17.5528s	
10541/29850 (epoch 17.657), train_loss = 1.03028513, grad/param norm = 1.7465e-01, time/batch = 16.2925s	
10542/29850 (epoch 17.658), train_loss = 1.20988187, grad/param norm = 2.0406e-01, time/batch = 18.4600s	
10543/29850 (epoch 17.660), train_loss = 1.09647063, grad/param norm = 1.8798e-01, time/batch = 18.5466s	
10544/29850 (epoch 17.662), train_loss = 1.14897183, grad/param norm = 1.9702e-01, time/batch = 17.0952s	
10545/29850 (epoch 17.663), train_loss = 1.27185218, grad/param norm = 2.0993e-01, time/batch = 16.5444s	
10546/29850 (epoch 17.665), train_loss = 1.20712313, grad/param norm = 1.8867e-01, time/batch = 19.4542s	
10547/29850 (epoch 17.667), train_loss = 1.15617709, grad/param norm = 2.0338e-01, time/batch = 17.0458s	
10548/29850 (epoch 17.668), train_loss = 1.08638877, grad/param norm = 1.8419e-01, time/batch = 17.4649s	
10549/29850 (epoch 17.670), train_loss = 1.27762349, grad/param norm = 2.4089e-01, time/batch = 18.5485s	
10550/29850 (epoch 17.672), train_loss = 1.20257855, grad/param norm = 1.9919e-01, time/batch = 17.8750s	
10551/29850 (epoch 17.673), train_loss = 1.20194118, grad/param norm = 2.0610e-01, time/batch = 15.5329s	
10552/29850 (epoch 17.675), train_loss = 1.02490599, grad/param norm = 1.9114e-01, time/batch = 14.8060s	
10553/29850 (epoch 17.677), train_loss = 1.07693558, grad/param norm = 1.9098e-01, time/batch = 18.6954s	
10554/29850 (epoch 17.678), train_loss = 1.06817690, grad/param norm = 1.8645e-01, time/batch = 16.7915s	
10555/29850 (epoch 17.680), train_loss = 1.11384346, grad/param norm = 1.9886e-01, time/batch = 19.2880s	
10556/29850 (epoch 17.682), train_loss = 1.11237724, grad/param norm = 2.0090e-01, time/batch = 17.0449s	
10557/29850 (epoch 17.683), train_loss = 1.25311181, grad/param norm = 2.1703e-01, time/batch = 17.4536s	
10558/29850 (epoch 17.685), train_loss = 1.24798527, grad/param norm = 2.0460e-01, time/batch = 15.4535s	
10559/29850 (epoch 17.687), train_loss = 1.19515902, grad/param norm = 2.1296e-01, time/batch = 18.3891s	
10560/29850 (epoch 17.688), train_loss = 0.97464871, grad/param norm = 1.7033e-01, time/batch = 18.7115s	
10561/29850 (epoch 17.690), train_loss = 0.99554956, grad/param norm = 1.8627e-01, time/batch = 17.0414s	
10562/29850 (epoch 17.692), train_loss = 1.20987997, grad/param norm = 1.8746e-01, time/batch = 17.3953s	
10563/29850 (epoch 17.693), train_loss = 1.09270622, grad/param norm = 1.7066e-01, time/batch = 18.0398s	
10564/29850 (epoch 17.695), train_loss = 0.97475671, grad/param norm = 1.6640e-01, time/batch = 16.2794s	
10565/29850 (epoch 17.697), train_loss = 1.11819280, grad/param norm = 1.9459e-01, time/batch = 18.2105s	
10566/29850 (epoch 17.698), train_loss = 1.18001413, grad/param norm = 1.7716e-01, time/batch = 18.0566s	
10567/29850 (epoch 17.700), train_loss = 1.14313750, grad/param norm = 1.9500e-01, time/batch = 17.6467s	
10568/29850 (epoch 17.702), train_loss = 1.07673957, grad/param norm = 1.9266e-01, time/batch = 17.2038s	
10569/29850 (epoch 17.704), train_loss = 1.00813539, grad/param norm = 1.7828e-01, time/batch = 18.1426s	
10570/29850 (epoch 17.705), train_loss = 1.09709152, grad/param norm = 1.7424e-01, time/batch = 18.0387s	
10571/29850 (epoch 17.707), train_loss = 1.02995387, grad/param norm = 1.7640e-01, time/batch = 15.7841s	
10572/29850 (epoch 17.709), train_loss = 1.13672984, grad/param norm = 1.8351e-01, time/batch = 18.5441s	
10573/29850 (epoch 17.710), train_loss = 1.05143474, grad/param norm = 1.8840e-01, time/batch = 17.3939s	
10574/29850 (epoch 17.712), train_loss = 1.09672488, grad/param norm = 1.6230e-01, time/batch = 18.3812s	
10575/29850 (epoch 17.714), train_loss = 1.17535144, grad/param norm = 1.8477e-01, time/batch = 15.6499s	
10576/29850 (epoch 17.715), train_loss = 1.13686311, grad/param norm = 1.7821e-01, time/batch = 17.6108s	
10577/29850 (epoch 17.717), train_loss = 0.89294807, grad/param norm = 1.7208e-01, time/batch = 16.5345s	
10578/29850 (epoch 17.719), train_loss = 1.03244802, grad/param norm = 1.8152e-01, time/batch = 16.8004s	
10579/29850 (epoch 17.720), train_loss = 1.09775839, grad/param norm = 1.7569e-01, time/batch = 18.8816s	
10580/29850 (epoch 17.722), train_loss = 1.03444963, grad/param norm = 1.6069e-01, time/batch = 17.6325s	
10581/29850 (epoch 17.724), train_loss = 1.17431087, grad/param norm = 1.9907e-01, time/batch = 16.1268s	
10582/29850 (epoch 17.725), train_loss = 0.96341459, grad/param norm = 1.7511e-01, time/batch = 16.6530s	
10583/29850 (epoch 17.727), train_loss = 1.02943854, grad/param norm = 1.9216e-01, time/batch = 18.7240s	
10584/29850 (epoch 17.729), train_loss = 0.93733809, grad/param norm = 1.6934e-01, time/batch = 17.1350s	
10585/29850 (epoch 17.730), train_loss = 0.96623522, grad/param norm = 1.8513e-01, time/batch = 16.5572s	
10586/29850 (epoch 17.732), train_loss = 1.18824524, grad/param norm = 1.7779e-01, time/batch = 18.6352s	
10587/29850 (epoch 17.734), train_loss = 1.28697450, grad/param norm = 2.2039e-01, time/batch = 16.8920s	
10588/29850 (epoch 17.735), train_loss = 1.07733816, grad/param norm = 2.0535e-01, time/batch = 17.7038s	
10589/29850 (epoch 17.737), train_loss = 1.00662302, grad/param norm = 1.8969e-01, time/batch = 17.1334s	
10590/29850 (epoch 17.739), train_loss = 0.92025898, grad/param norm = 1.9316e-01, time/batch = 18.0563s	
10591/29850 (epoch 17.740), train_loss = 0.95524202, grad/param norm = 1.7605e-01, time/batch = 16.7151s	
10592/29850 (epoch 17.742), train_loss = 0.94236648, grad/param norm = 1.7243e-01, time/batch = 17.1969s	
10593/29850 (epoch 17.744), train_loss = 1.02566872, grad/param norm = 1.9541e-01, time/batch = 17.1174s	
10594/29850 (epoch 17.745), train_loss = 1.01108192, grad/param norm = 1.8656e-01, time/batch = 17.3947s	
10595/29850 (epoch 17.747), train_loss = 1.05781342, grad/param norm = 1.8478e-01, time/batch = 16.5506s	
10596/29850 (epoch 17.749), train_loss = 0.98834121, grad/param norm = 1.9391e-01, time/batch = 16.1192s	
10597/29850 (epoch 17.750), train_loss = 0.95416604, grad/param norm = 1.8500e-01, time/batch = 16.3722s	
10598/29850 (epoch 17.752), train_loss = 0.90068231, grad/param norm = 1.7832e-01, time/batch = 17.0475s	
10599/29850 (epoch 17.754), train_loss = 0.94908192, grad/param norm = 1.9012e-01, time/batch = 16.3008s	
10600/29850 (epoch 17.755), train_loss = 0.99046351, grad/param norm = 1.7946e-01, time/batch = 16.9453s	
10601/29850 (epoch 17.757), train_loss = 1.04156822, grad/param norm = 1.8499e-01, time/batch = 18.1238s	
10602/29850 (epoch 17.759), train_loss = 1.04911121, grad/param norm = 1.8302e-01, time/batch = 17.3729s	
10603/29850 (epoch 17.760), train_loss = 0.98167273, grad/param norm = 2.0088e-01, time/batch = 17.7884s	
10604/29850 (epoch 17.762), train_loss = 0.96546286, grad/param norm = 2.2554e-01, time/batch = 18.7895s	
10605/29850 (epoch 17.764), train_loss = 0.91711274, grad/param norm = 1.9591e-01, time/batch = 17.1463s	
10606/29850 (epoch 17.765), train_loss = 1.04555282, grad/param norm = 1.8203e-01, time/batch = 16.8559s	
10607/29850 (epoch 17.767), train_loss = 1.05763781, grad/param norm = 1.8554e-01, time/batch = 17.0514s	
10608/29850 (epoch 17.769), train_loss = 1.05868292, grad/param norm = 2.0005e-01, time/batch = 16.3695s	
10609/29850 (epoch 17.771), train_loss = 1.10094149, grad/param norm = 1.8438e-01, time/batch = 17.4642s	
10610/29850 (epoch 17.772), train_loss = 1.12652186, grad/param norm = 1.9861e-01, time/batch = 16.7884s	
10611/29850 (epoch 17.774), train_loss = 0.99880016, grad/param norm = 1.7913e-01, time/batch = 18.2036s	
10612/29850 (epoch 17.776), train_loss = 1.03303899, grad/param norm = 1.8988e-01, time/batch = 16.8906s	
10613/29850 (epoch 17.777), train_loss = 1.14282862, grad/param norm = 1.9857e-01, time/batch = 18.3730s	
10614/29850 (epoch 17.779), train_loss = 0.95727791, grad/param norm = 1.6582e-01, time/batch = 17.1332s	
10615/29850 (epoch 17.781), train_loss = 1.05646921, grad/param norm = 1.7955e-01, time/batch = 18.0367s	
10616/29850 (epoch 17.782), train_loss = 1.11130067, grad/param norm = 1.9253e-01, time/batch = 16.9601s	
10617/29850 (epoch 17.784), train_loss = 0.96753161, grad/param norm = 1.8557e-01, time/batch = 17.9623s	
10618/29850 (epoch 17.786), train_loss = 1.02126379, grad/param norm = 1.7214e-01, time/batch = 18.4690s	
10619/29850 (epoch 17.787), train_loss = 0.95561037, grad/param norm = 2.1002e-01, time/batch = 17.7106s	
10620/29850 (epoch 17.789), train_loss = 0.89092720, grad/param norm = 1.5644e-01, time/batch = 18.4669s	
10621/29850 (epoch 17.791), train_loss = 1.00164780, grad/param norm = 2.3145e-01, time/batch = 17.4598s	
10622/29850 (epoch 17.792), train_loss = 1.13368325, grad/param norm = 1.9893e-01, time/batch = 19.2830s	
10623/29850 (epoch 17.794), train_loss = 1.08219078, grad/param norm = 1.7417e-01, time/batch = 17.1121s	
10624/29850 (epoch 17.796), train_loss = 0.98725933, grad/param norm = 1.7366e-01, time/batch = 16.9077s	
10625/29850 (epoch 17.797), train_loss = 0.90030763, grad/param norm = 1.7929e-01, time/batch = 17.2155s	
10626/29850 (epoch 17.799), train_loss = 0.94706987, grad/param norm = 1.6464e-01, time/batch = 15.4431s	
10627/29850 (epoch 17.801), train_loss = 1.06133567, grad/param norm = 1.8448e-01, time/batch = 15.6017s	
10628/29850 (epoch 17.802), train_loss = 0.88526579, grad/param norm = 1.7558e-01, time/batch = 17.5475s	
10629/29850 (epoch 17.804), train_loss = 0.93216189, grad/param norm = 1.6354e-01, time/batch = 18.8802s	
10630/29850 (epoch 17.806), train_loss = 0.93556718, grad/param norm = 1.5935e-01, time/batch = 15.7117s	
10631/29850 (epoch 17.807), train_loss = 0.88385934, grad/param norm = 1.4784e-01, time/batch = 19.4622s	
10632/29850 (epoch 17.809), train_loss = 0.97172722, grad/param norm = 1.9600e-01, time/batch = 19.2077s	
10633/29850 (epoch 17.811), train_loss = 1.09202420, grad/param norm = 1.9873e-01, time/batch = 16.7168s	
10634/29850 (epoch 17.812), train_loss = 1.10258124, grad/param norm = 1.9697e-01, time/batch = 19.1238s	
10635/29850 (epoch 17.814), train_loss = 1.16306825, grad/param norm = 1.9056e-01, time/batch = 17.4628s	
10636/29850 (epoch 17.816), train_loss = 1.14249588, grad/param norm = 1.7480e-01, time/batch = 17.5422s	
10637/29850 (epoch 17.817), train_loss = 1.07753025, grad/param norm = 1.8604e-01, time/batch = 18.8731s	
10638/29850 (epoch 17.819), train_loss = 0.92502873, grad/param norm = 1.7606e-01, time/batch = 18.1291s	
10639/29850 (epoch 17.821), train_loss = 1.17465167, grad/param norm = 2.0875e-01, time/batch = 17.5485s	
10640/29850 (epoch 17.822), train_loss = 1.17320377, grad/param norm = 1.9283e-01, time/batch = 31.4607s	
10641/29850 (epoch 17.824), train_loss = 1.04839754, grad/param norm = 1.8018e-01, time/batch = 15.8902s	
10642/29850 (epoch 17.826), train_loss = 0.99927434, grad/param norm = 1.7089e-01, time/batch = 15.1845s	
10643/29850 (epoch 17.827), train_loss = 0.94722421, grad/param norm = 1.8959e-01, time/batch = 16.7702s	
10644/29850 (epoch 17.829), train_loss = 1.08996272, grad/param norm = 2.2190e-01, time/batch = 16.9686s	
10645/29850 (epoch 17.831), train_loss = 1.14672967, grad/param norm = 2.0111e-01, time/batch = 17.3891s	
10646/29850 (epoch 17.832), train_loss = 1.05020506, grad/param norm = 1.7660e-01, time/batch = 17.8608s	
10647/29850 (epoch 17.834), train_loss = 0.89309591, grad/param norm = 1.6847e-01, time/batch = 18.3560s	
10648/29850 (epoch 17.836), train_loss = 0.93956288, grad/param norm = 1.7629e-01, time/batch = 16.7152s	
10649/29850 (epoch 17.838), train_loss = 1.05654659, grad/param norm = 1.8548e-01, time/batch = 14.4173s	
10650/29850 (epoch 17.839), train_loss = 0.97644303, grad/param norm = 1.7235e-01, time/batch = 17.7150s	
10651/29850 (epoch 17.841), train_loss = 0.97711384, grad/param norm = 1.7079e-01, time/batch = 17.1198s	
10652/29850 (epoch 17.843), train_loss = 0.95336787, grad/param norm = 1.6932e-01, time/batch = 17.4600s	
10653/29850 (epoch 17.844), train_loss = 0.97236803, grad/param norm = 1.8778e-01, time/batch = 16.3714s	
10654/29850 (epoch 17.846), train_loss = 1.05721695, grad/param norm = 1.7941e-01, time/batch = 18.6244s	
10655/29850 (epoch 17.848), train_loss = 1.11828880, grad/param norm = 1.9830e-01, time/batch = 18.7951s	
10656/29850 (epoch 17.849), train_loss = 1.00106597, grad/param norm = 1.9999e-01, time/batch = 17.4614s	
10657/29850 (epoch 17.851), train_loss = 1.14447623, grad/param norm = 2.0902e-01, time/batch = 15.8848s	
10658/29850 (epoch 17.853), train_loss = 0.99871948, grad/param norm = 1.9793e-01, time/batch = 17.7203s	
10659/29850 (epoch 17.854), train_loss = 1.20411539, grad/param norm = 2.1140e-01, time/batch = 15.2858s	
10660/29850 (epoch 17.856), train_loss = 1.14365629, grad/param norm = 2.1473e-01, time/batch = 15.2899s	
10661/29850 (epoch 17.858), train_loss = 1.05006859, grad/param norm = 2.0279e-01, time/batch = 17.3674s	
10662/29850 (epoch 17.859), train_loss = 0.95831861, grad/param norm = 1.8942e-01, time/batch = 17.4626s	
10663/29850 (epoch 17.861), train_loss = 1.15641061, grad/param norm = 1.9803e-01, time/batch = 16.4752s	
10664/29850 (epoch 17.863), train_loss = 1.22540602, grad/param norm = 1.9932e-01, time/batch = 14.7327s	
10665/29850 (epoch 17.864), train_loss = 1.15542810, grad/param norm = 2.0951e-01, time/batch = 18.0549s	
10666/29850 (epoch 17.866), train_loss = 1.09598367, grad/param norm = 1.9467e-01, time/batch = 19.3788s	
10667/29850 (epoch 17.868), train_loss = 1.22286369, grad/param norm = 1.9406e-01, time/batch = 16.8851s	
10668/29850 (epoch 17.869), train_loss = 1.08522338, grad/param norm = 2.2154e-01, time/batch = 16.1395s	
10669/29850 (epoch 17.871), train_loss = 1.13971581, grad/param norm = 1.9431e-01, time/batch = 17.8793s	
10670/29850 (epoch 17.873), train_loss = 1.11546822, grad/param norm = 2.0835e-01, time/batch = 17.0515s	
10671/29850 (epoch 17.874), train_loss = 1.08914238, grad/param norm = 1.8109e-01, time/batch = 17.5472s	
10672/29850 (epoch 17.876), train_loss = 1.05814936, grad/param norm = 2.3745e-01, time/batch = 15.3800s	
10673/29850 (epoch 17.878), train_loss = 1.08557717, grad/param norm = 1.7965e-01, time/batch = 18.2089s	
10674/29850 (epoch 17.879), train_loss = 1.09302529, grad/param norm = 1.9982e-01, time/batch = 16.5295s	
10675/29850 (epoch 17.881), train_loss = 1.18818821, grad/param norm = 2.2965e-01, time/batch = 18.6344s	
10676/29850 (epoch 17.883), train_loss = 1.17468596, grad/param norm = 2.1521e-01, time/batch = 16.8806s	
10677/29850 (epoch 17.884), train_loss = 0.97079289, grad/param norm = 1.8407e-01, time/batch = 17.2191s	
10678/29850 (epoch 17.886), train_loss = 1.19985916, grad/param norm = 2.0815e-01, time/batch = 16.4592s	
10679/29850 (epoch 17.888), train_loss = 1.06874012, grad/param norm = 1.7833e-01, time/batch = 18.6381s	
10680/29850 (epoch 17.889), train_loss = 1.02782330, grad/param norm = 1.8655e-01, time/batch = 18.0567s	
10681/29850 (epoch 17.891), train_loss = 1.00677311, grad/param norm = 1.7450e-01, time/batch = 16.5375s	
10682/29850 (epoch 17.893), train_loss = 0.97836098, grad/param norm = 1.7411e-01, time/batch = 17.8079s	
10683/29850 (epoch 17.894), train_loss = 1.02240208, grad/param norm = 1.7672e-01, time/batch = 17.4792s	
10684/29850 (epoch 17.896), train_loss = 1.06756741, grad/param norm = 1.9806e-01, time/batch = 16.4412s	
10685/29850 (epoch 17.898), train_loss = 1.18704987, grad/param norm = 2.1157e-01, time/batch = 18.5334s	
10686/29850 (epoch 17.899), train_loss = 0.93158182, grad/param norm = 1.7341e-01, time/batch = 17.0568s	
10687/29850 (epoch 17.901), train_loss = 1.35133171, grad/param norm = 2.4700e-01, time/batch = 18.2165s	
10688/29850 (epoch 17.903), train_loss = 1.09896911, grad/param norm = 2.6475e-01, time/batch = 16.6229s	
10689/29850 (epoch 17.905), train_loss = 1.29799772, grad/param norm = 2.1540e-01, time/batch = 16.8848s	
10690/29850 (epoch 17.906), train_loss = 1.12243816, grad/param norm = 2.2932e-01, time/batch = 19.6032s	
10691/29850 (epoch 17.908), train_loss = 1.17773002, grad/param norm = 1.9363e-01, time/batch = 16.0156s	
10692/29850 (epoch 17.910), train_loss = 1.15147323, grad/param norm = 1.8675e-01, time/batch = 19.3807s	
10693/29850 (epoch 17.911), train_loss = 1.26922867, grad/param norm = 1.9245e-01, time/batch = 17.7969s	
10694/29850 (epoch 17.913), train_loss = 1.17370961, grad/param norm = 1.8155e-01, time/batch = 17.5289s	
10695/29850 (epoch 17.915), train_loss = 1.20734986, grad/param norm = 2.0794e-01, time/batch = 16.4555s	
10696/29850 (epoch 17.916), train_loss = 1.17662993, grad/param norm = 2.1666e-01, time/batch = 17.7806s	
10697/29850 (epoch 17.918), train_loss = 1.03334005, grad/param norm = 1.7655e-01, time/batch = 19.5346s	
10698/29850 (epoch 17.920), train_loss = 1.14749182, grad/param norm = 1.8819e-01, time/batch = 17.2073s	
10699/29850 (epoch 17.921), train_loss = 1.13947139, grad/param norm = 2.2050e-01, time/batch = 15.0482s	
10700/29850 (epoch 17.923), train_loss = 1.17808272, grad/param norm = 1.9592e-01, time/batch = 16.4489s	
10701/29850 (epoch 17.925), train_loss = 1.20566593, grad/param norm = 1.9281e-01, time/batch = 16.8527s	
10702/29850 (epoch 17.926), train_loss = 1.27581782, grad/param norm = 2.2265e-01, time/batch = 17.4576s	
10703/29850 (epoch 17.928), train_loss = 1.11525680, grad/param norm = 1.8969e-01, time/batch = 18.2010s	
10704/29850 (epoch 17.930), train_loss = 1.17474625, grad/param norm = 1.9828e-01, time/batch = 18.3096s	
10705/29850 (epoch 17.931), train_loss = 1.07351097, grad/param norm = 1.8503e-01, time/batch = 16.9748s	
10706/29850 (epoch 17.933), train_loss = 1.27264209, grad/param norm = 2.1331e-01, time/batch = 18.1373s	
10707/29850 (epoch 17.935), train_loss = 1.20975856, grad/param norm = 1.9946e-01, time/batch = 17.3052s	
10708/29850 (epoch 17.936), train_loss = 1.21887836, grad/param norm = 2.3573e-01, time/batch = 16.5401s	
10709/29850 (epoch 17.938), train_loss = 0.97705086, grad/param norm = 1.7434e-01, time/batch = 18.2190s	
10710/29850 (epoch 17.940), train_loss = 0.98539937, grad/param norm = 1.8072e-01, time/batch = 16.4850s	
10711/29850 (epoch 17.941), train_loss = 1.04879244, grad/param norm = 2.0965e-01, time/batch = 17.1776s	
10712/29850 (epoch 17.943), train_loss = 1.02664599, grad/param norm = 1.8010e-01, time/batch = 16.5482s	
10713/29850 (epoch 17.945), train_loss = 1.07109423, grad/param norm = 2.1770e-01, time/batch = 17.8793s	
10714/29850 (epoch 17.946), train_loss = 0.99081880, grad/param norm = 1.9303e-01, time/batch = 18.6376s	
10715/29850 (epoch 17.948), train_loss = 1.10386440, grad/param norm = 1.8587e-01, time/batch = 16.2256s	
10716/29850 (epoch 17.950), train_loss = 1.02119009, grad/param norm = 1.7132e-01, time/batch = 18.1985s	
10717/29850 (epoch 17.951), train_loss = 0.96355226, grad/param norm = 1.7299e-01, time/batch = 18.1228s	
10718/29850 (epoch 17.953), train_loss = 1.07945064, grad/param norm = 1.9987e-01, time/batch = 17.8852s	
10719/29850 (epoch 17.955), train_loss = 0.95616947, grad/param norm = 1.6538e-01, time/batch = 17.5337s	
10720/29850 (epoch 17.956), train_loss = 0.94526861, grad/param norm = 1.6679e-01, time/batch = 18.9578s	
10721/29850 (epoch 17.958), train_loss = 0.80919574, grad/param norm = 1.4909e-01, time/batch = 18.0490s	
10722/29850 (epoch 17.960), train_loss = 1.13568663, grad/param norm = 1.8809e-01, time/batch = 16.6218s	
10723/29850 (epoch 17.961), train_loss = 0.98709323, grad/param norm = 1.7019e-01, time/batch = 15.8743s	
10724/29850 (epoch 17.963), train_loss = 0.94806526, grad/param norm = 1.6692e-01, time/batch = 16.6425s	
10725/29850 (epoch 17.965), train_loss = 0.99251893, grad/param norm = 1.8643e-01, time/batch = 16.4689s	
10726/29850 (epoch 17.966), train_loss = 0.93128035, grad/param norm = 1.8505e-01, time/batch = 15.8103s	
10727/29850 (epoch 17.968), train_loss = 1.01666910, grad/param norm = 1.8946e-01, time/batch = 16.7854s	
10728/29850 (epoch 17.970), train_loss = 0.95302815, grad/param norm = 1.8686e-01, time/batch = 17.7295s	
10729/29850 (epoch 17.972), train_loss = 0.97537858, grad/param norm = 1.6652e-01, time/batch = 17.6974s	
10730/29850 (epoch 17.973), train_loss = 0.98757686, grad/param norm = 1.8347e-01, time/batch = 17.5383s	
10731/29850 (epoch 17.975), train_loss = 0.84451064, grad/param norm = 1.6716e-01, time/batch = 19.5527s	
10732/29850 (epoch 17.977), train_loss = 0.99336115, grad/param norm = 1.7248e-01, time/batch = 16.3005s	
10733/29850 (epoch 17.978), train_loss = 0.95098461, grad/param norm = 1.6520e-01, time/batch = 19.2895s	
10734/29850 (epoch 17.980), train_loss = 1.01526904, grad/param norm = 1.7172e-01, time/batch = 17.9628s	
10735/29850 (epoch 17.982), train_loss = 1.01659065, grad/param norm = 1.8475e-01, time/batch = 17.7906s	
10736/29850 (epoch 17.983), train_loss = 1.03957709, grad/param norm = 1.8669e-01, time/batch = 16.1976s	
10737/29850 (epoch 17.985), train_loss = 1.08253582, grad/param norm = 1.8494e-01, time/batch = 18.5469s	
10738/29850 (epoch 17.987), train_loss = 1.05043046, grad/param norm = 1.7202e-01, time/batch = 18.1440s	
10739/29850 (epoch 17.988), train_loss = 0.99271562, grad/param norm = 1.7678e-01, time/batch = 16.6995s	
10740/29850 (epoch 17.990), train_loss = 1.08479296, grad/param norm = 1.8259e-01, time/batch = 18.7181s	
10741/29850 (epoch 17.992), train_loss = 1.08222133, grad/param norm = 1.8968e-01, time/batch = 19.0591s	
10742/29850 (epoch 17.993), train_loss = 1.06894976, grad/param norm = 1.8219e-01, time/batch = 16.3317s	
10743/29850 (epoch 17.995), train_loss = 1.07588462, grad/param norm = 1.7000e-01, time/batch = 17.7974s	
10744/29850 (epoch 17.997), train_loss = 1.08152752, grad/param norm = 1.9811e-01, time/batch = 16.0466s	
10745/29850 (epoch 17.998), train_loss = 1.14741319, grad/param norm = 1.9268e-01, time/batch = 18.1990s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
10746/29850 (epoch 18.000), train_loss = 0.95302248, grad/param norm = 1.5765e-01, time/batch = 17.2772s	
10747/29850 (epoch 18.002), train_loss = 1.28809856, grad/param norm = 2.1068e-01, time/batch = 17.4618s	
10748/29850 (epoch 18.003), train_loss = 0.99131574, grad/param norm = 1.7631e-01, time/batch = 18.5545s	
10749/29850 (epoch 18.005), train_loss = 1.09325797, grad/param norm = 1.7929e-01, time/batch = 17.1292s	
10750/29850 (epoch 18.007), train_loss = 1.11208966, grad/param norm = 2.0203e-01, time/batch = 18.7101s	
10751/29850 (epoch 18.008), train_loss = 1.30566795, grad/param norm = 1.9412e-01, time/batch = 17.6993s	
10752/29850 (epoch 18.010), train_loss = 0.97639763, grad/param norm = 1.9910e-01, time/batch = 16.4716s	
10753/29850 (epoch 18.012), train_loss = 1.08589910, grad/param norm = 1.6531e-01, time/batch = 14.8817s	
10754/29850 (epoch 18.013), train_loss = 1.11296128, grad/param norm = 2.0307e-01, time/batch = 16.6109s	
10755/29850 (epoch 18.015), train_loss = 1.13247083, grad/param norm = 1.6917e-01, time/batch = 19.2280s	
10756/29850 (epoch 18.017), train_loss = 1.13094842, grad/param norm = 1.8725e-01, time/batch = 15.2225s	
10757/29850 (epoch 18.018), train_loss = 1.21447597, grad/param norm = 2.2970e-01, time/batch = 19.3768s	
10758/29850 (epoch 18.020), train_loss = 1.05622096, grad/param norm = 1.8404e-01, time/batch = 17.2177s	
10759/29850 (epoch 18.022), train_loss = 1.20642595, grad/param norm = 2.0501e-01, time/batch = 17.4444s	
10760/29850 (epoch 18.023), train_loss = 1.12272872, grad/param norm = 1.7183e-01, time/batch = 15.8187s	
10761/29850 (epoch 18.025), train_loss = 1.04705023, grad/param norm = 1.7938e-01, time/batch = 18.4544s	
10762/29850 (epoch 18.027), train_loss = 0.89806799, grad/param norm = 1.6123e-01, time/batch = 18.3850s	
10763/29850 (epoch 18.028), train_loss = 1.04814822, grad/param norm = 1.7733e-01, time/batch = 15.4574s	
10764/29850 (epoch 18.030), train_loss = 1.08873805, grad/param norm = 1.9721e-01, time/batch = 14.5639s	
10765/29850 (epoch 18.032), train_loss = 1.10962056, grad/param norm = 1.8038e-01, time/batch = 16.3036s	
10766/29850 (epoch 18.034), train_loss = 0.99299339, grad/param norm = 1.6804e-01, time/batch = 18.2178s	
10767/29850 (epoch 18.035), train_loss = 0.91057012, grad/param norm = 1.6548e-01, time/batch = 18.5330s	
10768/29850 (epoch 18.037), train_loss = 1.06557243, grad/param norm = 1.8725e-01, time/batch = 18.2998s	
10769/29850 (epoch 18.039), train_loss = 0.92669343, grad/param norm = 1.6631e-01, time/batch = 16.0981s	
10770/29850 (epoch 18.040), train_loss = 0.99583233, grad/param norm = 1.8066e-01, time/batch = 16.9559s	
10771/29850 (epoch 18.042), train_loss = 0.98257337, grad/param norm = 1.7791e-01, time/batch = 18.0446s	
10772/29850 (epoch 18.044), train_loss = 1.02429300, grad/param norm = 1.6892e-01, time/batch = 18.7178s	
10773/29850 (epoch 18.045), train_loss = 1.13067408, grad/param norm = 1.8302e-01, time/batch = 18.2952s	
10774/29850 (epoch 18.047), train_loss = 0.91502745, grad/param norm = 1.6961e-01, time/batch = 18.2259s	
10775/29850 (epoch 18.049), train_loss = 1.10217060, grad/param norm = 1.7988e-01, time/batch = 17.8894s	
10776/29850 (epoch 18.050), train_loss = 0.99247895, grad/param norm = 1.8247e-01, time/batch = 16.9672s	
10777/29850 (epoch 18.052), train_loss = 1.20414290, grad/param norm = 2.1052e-01, time/batch = 16.1100s	
10778/29850 (epoch 18.054), train_loss = 1.10537047, grad/param norm = 1.8616e-01, time/batch = 16.3904s	
10779/29850 (epoch 18.055), train_loss = 1.06827046, grad/param norm = 1.9509e-01, time/batch = 17.4760s	
10780/29850 (epoch 18.057), train_loss = 1.12589290, grad/param norm = 1.7905e-01, time/batch = 16.7141s	
10781/29850 (epoch 18.059), train_loss = 1.10248976, grad/param norm = 1.8866e-01, time/batch = 15.5488s	
10782/29850 (epoch 18.060), train_loss = 1.12727424, grad/param norm = 1.9833e-01, time/batch = 15.7148s	
10783/29850 (epoch 18.062), train_loss = 1.20457265, grad/param norm = 1.9791e-01, time/batch = 18.5528s	
10784/29850 (epoch 18.064), train_loss = 1.15355209, grad/param norm = 2.0884e-01, time/batch = 17.2903s	
10785/29850 (epoch 18.065), train_loss = 0.99338371, grad/param norm = 1.8834e-01, time/batch = 17.3005s	
10786/29850 (epoch 18.067), train_loss = 1.13175868, grad/param norm = 1.8643e-01, time/batch = 17.8919s	
10787/29850 (epoch 18.069), train_loss = 1.07042635, grad/param norm = 1.7632e-01, time/batch = 17.1956s	
10788/29850 (epoch 18.070), train_loss = 1.13079366, grad/param norm = 1.7184e-01, time/batch = 18.2879s	
10789/29850 (epoch 18.072), train_loss = 1.13190209, grad/param norm = 2.0590e-01, time/batch = 17.6236s	
10790/29850 (epoch 18.074), train_loss = 1.15637800, grad/param norm = 1.8247e-01, time/batch = 17.7840s	
10791/29850 (epoch 18.075), train_loss = 1.00895745, grad/param norm = 1.8938e-01, time/batch = 17.4393s	
10792/29850 (epoch 18.077), train_loss = 1.12131546, grad/param norm = 1.9383e-01, time/batch = 18.2261s	
10793/29850 (epoch 18.079), train_loss = 1.32814611, grad/param norm = 2.5033e-01, time/batch = 15.0441s	
10794/29850 (epoch 18.080), train_loss = 1.26885084, grad/param norm = 2.0942e-01, time/batch = 16.8678s	
10795/29850 (epoch 18.082), train_loss = 1.16430902, grad/param norm = 2.0467e-01, time/batch = 17.2371s	
10796/29850 (epoch 18.084), train_loss = 1.21926823, grad/param norm = 2.1521e-01, time/batch = 17.7112s	
10797/29850 (epoch 18.085), train_loss = 1.20536197, grad/param norm = 2.6075e-01, time/batch = 16.0313s	
10798/29850 (epoch 18.087), train_loss = 1.22589030, grad/param norm = 1.9995e-01, time/batch = 17.5230s	
10799/29850 (epoch 18.089), train_loss = 1.14003079, grad/param norm = 1.9538e-01, time/batch = 16.9681s	
10800/29850 (epoch 18.090), train_loss = 1.17063050, grad/param norm = 2.0962e-01, time/batch = 18.7221s	
10801/29850 (epoch 18.092), train_loss = 1.04898444, grad/param norm = 1.8878e-01, time/batch = 16.7890s	
10802/29850 (epoch 18.094), train_loss = 1.18732169, grad/param norm = 1.9521e-01, time/batch = 17.7082s	
10803/29850 (epoch 18.095), train_loss = 1.12391176, grad/param norm = 1.9487e-01, time/batch = 18.6274s	
10804/29850 (epoch 18.097), train_loss = 0.89808119, grad/param norm = 1.5902e-01, time/batch = 16.2834s	
10805/29850 (epoch 18.099), train_loss = 0.91944114, grad/param norm = 1.7024e-01, time/batch = 18.1275s	
10806/29850 (epoch 18.101), train_loss = 1.19707481, grad/param norm = 1.8728e-01, time/batch = 18.6333s	
10807/29850 (epoch 18.102), train_loss = 1.15572886, grad/param norm = 1.9569e-01, time/batch = 17.7931s	
10808/29850 (epoch 18.104), train_loss = 1.06983008, grad/param norm = 1.8443e-01, time/batch = 18.0943s	
10809/29850 (epoch 18.106), train_loss = 1.17994314, grad/param norm = 1.9021e-01, time/batch = 17.4713s	
10810/29850 (epoch 18.107), train_loss = 0.92770433, grad/param norm = 1.5676e-01, time/batch = 18.5409s	
10811/29850 (epoch 18.109), train_loss = 1.06599251, grad/param norm = 1.9669e-01, time/batch = 16.0458s	
10812/29850 (epoch 18.111), train_loss = 1.20588369, grad/param norm = 2.0714e-01, time/batch = 19.0572s	
10813/29850 (epoch 18.112), train_loss = 1.00490648, grad/param norm = 1.6726e-01, time/batch = 16.0639s	
10814/29850 (epoch 18.114), train_loss = 1.10599172, grad/param norm = 2.0715e-01, time/batch = 16.6479s	
10815/29850 (epoch 18.116), train_loss = 0.99733542, grad/param norm = 1.7110e-01, time/batch = 17.2767s	
10816/29850 (epoch 18.117), train_loss = 1.08892254, grad/param norm = 1.8178e-01, time/batch = 16.8648s	
10817/29850 (epoch 18.119), train_loss = 1.06070933, grad/param norm = 1.7780e-01, time/batch = 18.8858s	
10818/29850 (epoch 18.121), train_loss = 0.89523716, grad/param norm = 1.7926e-01, time/batch = 16.9560s	
10819/29850 (epoch 18.122), train_loss = 0.94182615, grad/param norm = 1.5840e-01, time/batch = 17.3655s	
10820/29850 (epoch 18.124), train_loss = 0.99924075, grad/param norm = 1.8319e-01, time/batch = 16.8791s	
10821/29850 (epoch 18.126), train_loss = 1.04794714, grad/param norm = 1.9373e-01, time/batch = 17.2974s	
10822/29850 (epoch 18.127), train_loss = 1.17485893, grad/param norm = 2.1254e-01, time/batch = 18.5383s	
10823/29850 (epoch 18.129), train_loss = 1.04347668, grad/param norm = 1.9461e-01, time/batch = 16.9742s	
10824/29850 (epoch 18.131), train_loss = 1.04531755, grad/param norm = 1.7929e-01, time/batch = 16.4701s	
10825/29850 (epoch 18.132), train_loss = 0.96366098, grad/param norm = 1.9372e-01, time/batch = 17.6987s	
10826/29850 (epoch 18.134), train_loss = 1.10010093, grad/param norm = 1.8896e-01, time/batch = 17.9719s	
10827/29850 (epoch 18.136), train_loss = 1.10289485, grad/param norm = 1.7907e-01, time/batch = 17.2254s	
10828/29850 (epoch 18.137), train_loss = 0.91517647, grad/param norm = 1.7624e-01, time/batch = 17.5359s	
10829/29850 (epoch 18.139), train_loss = 1.00742662, grad/param norm = 1.8189e-01, time/batch = 17.4518s	
10830/29850 (epoch 18.141), train_loss = 1.02960669, grad/param norm = 1.7420e-01, time/batch = 17.5525s	
10831/29850 (epoch 18.142), train_loss = 1.18692455, grad/param norm = 2.1713e-01, time/batch = 17.5461s	
10832/29850 (epoch 18.144), train_loss = 1.33514504, grad/param norm = 2.2728e-01, time/batch = 17.1266s	
10833/29850 (epoch 18.146), train_loss = 1.33122382, grad/param norm = 2.1227e-01, time/batch = 17.6988s	
10834/29850 (epoch 18.147), train_loss = 1.17043898, grad/param norm = 2.2338e-01, time/batch = 18.1902s	
10835/29850 (epoch 18.149), train_loss = 1.15150126, grad/param norm = 1.9300e-01, time/batch = 16.2994s	
10836/29850 (epoch 18.151), train_loss = 1.13762226, grad/param norm = 1.9069e-01, time/batch = 18.2041s	
10837/29850 (epoch 18.152), train_loss = 1.03430314, grad/param norm = 1.7995e-01, time/batch = 18.7976s	
10838/29850 (epoch 18.154), train_loss = 1.04548949, grad/param norm = 1.9388e-01, time/batch = 17.7077s	
10839/29850 (epoch 18.156), train_loss = 1.01688072, grad/param norm = 1.6990e-01, time/batch = 16.3166s	
10840/29850 (epoch 18.157), train_loss = 1.09347909, grad/param norm = 1.7753e-01, time/batch = 17.7228s	
10841/29850 (epoch 18.159), train_loss = 1.06971044, grad/param norm = 1.7623e-01, time/batch = 17.3895s	
10842/29850 (epoch 18.161), train_loss = 1.13977412, grad/param norm = 1.9868e-01, time/batch = 16.8614s	
10843/29850 (epoch 18.162), train_loss = 1.22985037, grad/param norm = 2.0579e-01, time/batch = 18.2107s	
10844/29850 (epoch 18.164), train_loss = 1.07540271, grad/param norm = 1.7703e-01, time/batch = 18.6992s	
10845/29850 (epoch 18.166), train_loss = 0.98853343, grad/param norm = 1.6118e-01, time/batch = 25.7396s	
10846/29850 (epoch 18.168), train_loss = 0.91073108, grad/param norm = 1.7324e-01, time/batch = 21.4804s	
10847/29850 (epoch 18.169), train_loss = 1.25155642, grad/param norm = 2.1233e-01, time/batch = 16.6948s	
10848/29850 (epoch 18.171), train_loss = 1.15541970, grad/param norm = 2.0324e-01, time/batch = 16.3856s	
10849/29850 (epoch 18.173), train_loss = 1.02370290, grad/param norm = 1.9660e-01, time/batch = 17.0474s	
10850/29850 (epoch 18.174), train_loss = 1.15983187, grad/param norm = 2.1246e-01, time/batch = 16.9761s	
10851/29850 (epoch 18.176), train_loss = 1.12695512, grad/param norm = 1.9687e-01, time/batch = 17.7939s	
10852/29850 (epoch 18.178), train_loss = 1.16987862, grad/param norm = 2.0969e-01, time/batch = 19.1841s	
10853/29850 (epoch 18.179), train_loss = 0.96042971, grad/param norm = 1.7707e-01, time/batch = 16.7266s	
10854/29850 (epoch 18.181), train_loss = 1.08646717, grad/param norm = 1.9272e-01, time/batch = 18.0424s	
10855/29850 (epoch 18.183), train_loss = 1.06702057, grad/param norm = 1.7719e-01, time/batch = 17.0285s	
10856/29850 (epoch 18.184), train_loss = 1.07134085, grad/param norm = 1.7662e-01, time/batch = 18.3844s	
10857/29850 (epoch 18.186), train_loss = 1.11199563, grad/param norm = 1.9298e-01, time/batch = 18.4754s	
10858/29850 (epoch 18.188), train_loss = 1.21279871, grad/param norm = 2.1447e-01, time/batch = 17.3744s	
10859/29850 (epoch 18.189), train_loss = 1.24902575, grad/param norm = 2.0172e-01, time/batch = 17.9620s	
10860/29850 (epoch 18.191), train_loss = 1.15157141, grad/param norm = 1.9544e-01, time/batch = 19.0455s	
10861/29850 (epoch 18.193), train_loss = 1.04722618, grad/param norm = 1.8729e-01, time/batch = 17.2000s	
10862/29850 (epoch 18.194), train_loss = 1.12940689, grad/param norm = 2.0398e-01, time/batch = 18.1282s	
10863/29850 (epoch 18.196), train_loss = 1.03075843, grad/param norm = 1.7571e-01, time/batch = 16.5695s	
10864/29850 (epoch 18.198), train_loss = 1.08420379, grad/param norm = 1.8286e-01, time/batch = 16.3784s	
10865/29850 (epoch 18.199), train_loss = 1.33214917, grad/param norm = 2.0933e-01, time/batch = 16.5371s	
10866/29850 (epoch 18.201), train_loss = 1.01682538, grad/param norm = 1.8566e-01, time/batch = 15.9560s	
10867/29850 (epoch 18.203), train_loss = 0.88679046, grad/param norm = 1.9920e-01, time/batch = 18.8659s	
10868/29850 (epoch 18.204), train_loss = 1.16123970, grad/param norm = 2.0613e-01, time/batch = 16.4411s	
10869/29850 (epoch 18.206), train_loss = 0.97642538, grad/param norm = 1.9236e-01, time/batch = 17.8708s	
10870/29850 (epoch 18.208), train_loss = 1.24630552, grad/param norm = 1.9936e-01, time/batch = 16.0732s	
10871/29850 (epoch 18.209), train_loss = 0.97293797, grad/param norm = 1.6769e-01, time/batch = 14.8778s	
10872/29850 (epoch 18.211), train_loss = 1.04839683, grad/param norm = 1.7873e-01, time/batch = 16.5489s	
10873/29850 (epoch 18.213), train_loss = 1.18041097, grad/param norm = 1.9264e-01, time/batch = 17.7195s	
10874/29850 (epoch 18.214), train_loss = 0.99797969, grad/param norm = 1.6860e-01, time/batch = 18.3679s	
10875/29850 (epoch 18.216), train_loss = 1.02940562, grad/param norm = 1.8055e-01, time/batch = 17.2087s	
10876/29850 (epoch 18.218), train_loss = 1.17505936, grad/param norm = 2.0367e-01, time/batch = 16.8776s	
10877/29850 (epoch 18.219), train_loss = 1.21799629, grad/param norm = 2.2524e-01, time/batch = 16.0395s	
10878/29850 (epoch 18.221), train_loss = 1.08821768, grad/param norm = 1.9342e-01, time/batch = 18.4644s	
10879/29850 (epoch 18.223), train_loss = 1.01510039, grad/param norm = 1.8871e-01, time/batch = 16.3765s	
10880/29850 (epoch 18.224), train_loss = 0.94613079, grad/param norm = 1.8208e-01, time/batch = 18.6212s	
10881/29850 (epoch 18.226), train_loss = 0.98875050, grad/param norm = 1.6397e-01, time/batch = 16.7151s	
10882/29850 (epoch 18.228), train_loss = 1.04999498, grad/param norm = 1.7549e-01, time/batch = 18.0436s	
10883/29850 (epoch 18.229), train_loss = 0.93510244, grad/param norm = 1.5595e-01, time/batch = 16.8694s	
10884/29850 (epoch 18.231), train_loss = 1.04968278, grad/param norm = 1.7278e-01, time/batch = 17.4563s	
10885/29850 (epoch 18.233), train_loss = 1.04946046, grad/param norm = 2.0623e-01, time/batch = 17.8898s	
10886/29850 (epoch 18.235), train_loss = 0.98467844, grad/param norm = 1.7752e-01, time/batch = 17.4628s	
10887/29850 (epoch 18.236), train_loss = 1.23017991, grad/param norm = 2.0718e-01, time/batch = 15.6109s	
10888/29850 (epoch 18.238), train_loss = 0.94057128, grad/param norm = 1.7411e-01, time/batch = 17.5475s	
10889/29850 (epoch 18.240), train_loss = 0.96319581, grad/param norm = 1.6286e-01, time/batch = 14.8931s	
10890/29850 (epoch 18.241), train_loss = 1.15393871, grad/param norm = 2.1471e-01, time/batch = 15.8848s	
10891/29850 (epoch 18.243), train_loss = 1.09840429, grad/param norm = 1.9130e-01, time/batch = 18.7233s	
10892/29850 (epoch 18.245), train_loss = 1.02682466, grad/param norm = 1.9525e-01, time/batch = 17.7236s	
10893/29850 (epoch 18.246), train_loss = 0.95632128, grad/param norm = 1.6935e-01, time/batch = 17.2852s	
10894/29850 (epoch 18.248), train_loss = 0.94427543, grad/param norm = 1.5955e-01, time/batch = 17.3873s	
10895/29850 (epoch 18.250), train_loss = 1.04533896, grad/param norm = 1.7822e-01, time/batch = 19.0493s	
10896/29850 (epoch 18.251), train_loss = 0.93812147, grad/param norm = 2.0096e-01, time/batch = 16.2826s	
10897/29850 (epoch 18.253), train_loss = 0.90229331, grad/param norm = 2.0620e-01, time/batch = 15.3177s	
10898/29850 (epoch 18.255), train_loss = 0.97790710, grad/param norm = 1.9189e-01, time/batch = 17.8745s	
10899/29850 (epoch 18.256), train_loss = 1.11313128, grad/param norm = 1.9579e-01, time/batch = 18.6256s	
10900/29850 (epoch 18.258), train_loss = 1.08201719, grad/param norm = 1.9154e-01, time/batch = 17.4517s	
10901/29850 (epoch 18.260), train_loss = 1.03551284, grad/param norm = 1.7438e-01, time/batch = 16.2881s	
10902/29850 (epoch 18.261), train_loss = 0.99359799, grad/param norm = 1.9762e-01, time/batch = 18.2252s	
10903/29850 (epoch 18.263), train_loss = 0.98082023, grad/param norm = 1.6972e-01, time/batch = 16.7240s	
10904/29850 (epoch 18.265), train_loss = 1.03710549, grad/param norm = 1.7995e-01, time/batch = 17.3042s	
10905/29850 (epoch 18.266), train_loss = 1.03290363, grad/param norm = 1.9080e-01, time/batch = 18.9771s	
10906/29850 (epoch 18.268), train_loss = 1.00926165, grad/param norm = 1.7204e-01, time/batch = 17.2194s	
10907/29850 (epoch 18.270), train_loss = 0.98359214, grad/param norm = 1.6775e-01, time/batch = 15.4570s	
10908/29850 (epoch 18.271), train_loss = 1.16192602, grad/param norm = 1.8718e-01, time/batch = 17.8908s	
10909/29850 (epoch 18.273), train_loss = 0.90361905, grad/param norm = 1.8738e-01, time/batch = 17.8107s	
10910/29850 (epoch 18.275), train_loss = 0.90472352, grad/param norm = 1.7506e-01, time/batch = 15.9751s	
10911/29850 (epoch 18.276), train_loss = 0.93112391, grad/param norm = 1.6475e-01, time/batch = 17.9507s	
10912/29850 (epoch 18.278), train_loss = 1.01108019, grad/param norm = 1.7779e-01, time/batch = 15.0367s	
10913/29850 (epoch 18.280), train_loss = 1.20666059, grad/param norm = 2.0820e-01, time/batch = 17.3774s	
10914/29850 (epoch 18.281), train_loss = 1.09806402, grad/param norm = 1.8925e-01, time/batch = 17.1095s	
10915/29850 (epoch 18.283), train_loss = 1.22621701, grad/param norm = 2.2244e-01, time/batch = 18.2986s	
10916/29850 (epoch 18.285), train_loss = 1.03816833, grad/param norm = 1.8089e-01, time/batch = 18.7058s	
10917/29850 (epoch 18.286), train_loss = 1.17608935, grad/param norm = 2.1454e-01, time/batch = 17.0424s	
10918/29850 (epoch 18.288), train_loss = 1.22449491, grad/param norm = 2.4468e-01, time/batch = 15.9565s	
10919/29850 (epoch 18.290), train_loss = 1.05903902, grad/param norm = 1.9423e-01, time/batch = 15.6945s	
10920/29850 (epoch 18.291), train_loss = 1.30465981, grad/param norm = 2.0154e-01, time/batch = 17.3080s	
10921/29850 (epoch 18.293), train_loss = 1.18408412, grad/param norm = 2.3397e-01, time/batch = 19.4510s	
10922/29850 (epoch 18.295), train_loss = 1.24726056, grad/param norm = 2.0975e-01, time/batch = 16.7136s	
10923/29850 (epoch 18.296), train_loss = 0.99272059, grad/param norm = 1.8360e-01, time/batch = 16.5362s	
10924/29850 (epoch 18.298), train_loss = 0.85973115, grad/param norm = 1.6941e-01, time/batch = 15.3475s	
10925/29850 (epoch 18.300), train_loss = 0.94570084, grad/param norm = 1.6808e-01, time/batch = 15.1108s	
10926/29850 (epoch 18.302), train_loss = 0.94334453, grad/param norm = 1.7907e-01, time/batch = 16.5338s	
10927/29850 (epoch 18.303), train_loss = 0.98940416, grad/param norm = 1.9062e-01, time/batch = 14.7916s	
10928/29850 (epoch 18.305), train_loss = 1.11672665, grad/param norm = 1.9120e-01, time/batch = 14.8689s	
10929/29850 (epoch 18.307), train_loss = 1.15205158, grad/param norm = 1.9435e-01, time/batch = 14.5634s	
10930/29850 (epoch 18.308), train_loss = 1.02190142, grad/param norm = 1.7906e-01, time/batch = 15.4727s	
10931/29850 (epoch 18.310), train_loss = 1.10847898, grad/param norm = 2.0904e-01, time/batch = 19.3508s	
10932/29850 (epoch 18.312), train_loss = 1.14222467, grad/param norm = 1.9236e-01, time/batch = 16.8000s	
10933/29850 (epoch 18.313), train_loss = 1.06967972, grad/param norm = 1.8586e-01, time/batch = 17.2265s	
10934/29850 (epoch 18.315), train_loss = 1.09608901, grad/param norm = 1.9593e-01, time/batch = 17.7848s	
10935/29850 (epoch 18.317), train_loss = 1.09133958, grad/param norm = 1.9573e-01, time/batch = 16.5412s	
10936/29850 (epoch 18.318), train_loss = 1.06758323, grad/param norm = 1.8160e-01, time/batch = 15.6250s	
10937/29850 (epoch 18.320), train_loss = 0.98383424, grad/param norm = 1.5896e-01, time/batch = 18.2236s	
10938/29850 (epoch 18.322), train_loss = 1.23759797, grad/param norm = 2.1377e-01, time/batch = 17.7978s	
10939/29850 (epoch 18.323), train_loss = 1.15751480, grad/param norm = 2.1251e-01, time/batch = 17.9575s	
10940/29850 (epoch 18.325), train_loss = 1.15456742, grad/param norm = 1.9488e-01, time/batch = 17.0537s	
10941/29850 (epoch 18.327), train_loss = 1.26650474, grad/param norm = 2.1584e-01, time/batch = 18.7891s	
10942/29850 (epoch 18.328), train_loss = 1.23962909, grad/param norm = 2.0084e-01, time/batch = 16.4701s	
10943/29850 (epoch 18.330), train_loss = 1.11290005, grad/param norm = 1.8168e-01, time/batch = 16.7984s	
10944/29850 (epoch 18.332), train_loss = 1.03234465, grad/param norm = 1.8342e-01, time/batch = 17.4620s	
10945/29850 (epoch 18.333), train_loss = 1.21154319, grad/param norm = 2.0617e-01, time/batch = 17.9605s	
10946/29850 (epoch 18.335), train_loss = 1.18178467, grad/param norm = 2.0998e-01, time/batch = 18.7069s	
10947/29850 (epoch 18.337), train_loss = 1.09147011, grad/param norm = 1.8690e-01, time/batch = 18.5434s	
10948/29850 (epoch 18.338), train_loss = 1.08710961, grad/param norm = 1.7657e-01, time/batch = 18.8451s	
10949/29850 (epoch 18.340), train_loss = 0.98472436, grad/param norm = 1.7977e-01, time/batch = 16.6991s	
10950/29850 (epoch 18.342), train_loss = 1.08764242, grad/param norm = 1.8913e-01, time/batch = 16.2932s	
10951/29850 (epoch 18.343), train_loss = 1.12762815, grad/param norm = 2.0558e-01, time/batch = 17.6212s	
10952/29850 (epoch 18.345), train_loss = 1.15243422, grad/param norm = 2.4311e-01, time/batch = 17.3829s	
10953/29850 (epoch 18.347), train_loss = 1.18029014, grad/param norm = 2.0351e-01, time/batch = 15.3649s	
10954/29850 (epoch 18.348), train_loss = 1.03155640, grad/param norm = 1.8332e-01, time/batch = 18.3811s	
10955/29850 (epoch 18.350), train_loss = 1.16405189, grad/param norm = 1.9625e-01, time/batch = 18.0470s	
10956/29850 (epoch 18.352), train_loss = 1.04368139, grad/param norm = 1.7112e-01, time/batch = 16.2178s	
10957/29850 (epoch 18.353), train_loss = 1.12909091, grad/param norm = 1.8758e-01, time/batch = 17.0555s	
10958/29850 (epoch 18.355), train_loss = 0.98787572, grad/param norm = 1.8422e-01, time/batch = 18.5409s	
10959/29850 (epoch 18.357), train_loss = 1.23851410, grad/param norm = 2.0751e-01, time/batch = 15.7092s	
10960/29850 (epoch 18.358), train_loss = 0.99293859, grad/param norm = 1.7566e-01, time/batch = 17.6211s	
10961/29850 (epoch 18.360), train_loss = 1.07866108, grad/param norm = 1.9321e-01, time/batch = 18.1412s	
10962/29850 (epoch 18.362), train_loss = 1.08231934, grad/param norm = 1.9760e-01, time/batch = 17.6294s	
10963/29850 (epoch 18.363), train_loss = 1.12890273, grad/param norm = 2.1562e-01, time/batch = 19.1971s	
10964/29850 (epoch 18.365), train_loss = 1.25453535, grad/param norm = 2.0627e-01, time/batch = 17.8742s	
10965/29850 (epoch 18.367), train_loss = 1.04140898, grad/param norm = 2.0221e-01, time/batch = 18.6149s	
10966/29850 (epoch 18.369), train_loss = 0.96079985, grad/param norm = 1.8824e-01, time/batch = 16.7093s	
10967/29850 (epoch 18.370), train_loss = 0.89690481, grad/param norm = 1.8383e-01, time/batch = 17.6337s	
10968/29850 (epoch 18.372), train_loss = 1.19781799, grad/param norm = 2.0656e-01, time/batch = 16.1398s	
10969/29850 (epoch 18.374), train_loss = 1.11661597, grad/param norm = 1.9949e-01, time/batch = 17.2160s	
10970/29850 (epoch 18.375), train_loss = 1.10157587, grad/param norm = 1.8811e-01, time/batch = 15.9447s	
10971/29850 (epoch 18.377), train_loss = 1.06299292, grad/param norm = 1.9249e-01, time/batch = 18.8053s	
10972/29850 (epoch 18.379), train_loss = 1.19062004, grad/param norm = 2.0103e-01, time/batch = 16.1344s	
10973/29850 (epoch 18.380), train_loss = 1.13523335, grad/param norm = 1.8771e-01, time/batch = 16.3787s	
10974/29850 (epoch 18.382), train_loss = 1.13799594, grad/param norm = 2.3126e-01, time/batch = 17.9407s	
10975/29850 (epoch 18.384), train_loss = 1.12529832, grad/param norm = 1.8043e-01, time/batch = 18.5504s	
10976/29850 (epoch 18.385), train_loss = 1.08865710, grad/param norm = 1.9290e-01, time/batch = 16.7819s	
10977/29850 (epoch 18.387), train_loss = 1.15674180, grad/param norm = 1.9988e-01, time/batch = 18.8039s	
10978/29850 (epoch 18.389), train_loss = 1.26301082, grad/param norm = 2.2009e-01, time/batch = 16.9475s	
10979/29850 (epoch 18.390), train_loss = 1.15046451, grad/param norm = 1.8787e-01, time/batch = 17.3026s	
10980/29850 (epoch 18.392), train_loss = 1.08816357, grad/param norm = 2.1094e-01, time/batch = 18.8729s	
10981/29850 (epoch 18.394), train_loss = 1.18208453, grad/param norm = 1.9188e-01, time/batch = 17.5520s	
10982/29850 (epoch 18.395), train_loss = 1.06011297, grad/param norm = 1.8992e-01, time/batch = 18.7953s	
10983/29850 (epoch 18.397), train_loss = 0.99008504, grad/param norm = 1.8585e-01, time/batch = 16.2859s	
10984/29850 (epoch 18.399), train_loss = 1.00195754, grad/param norm = 1.7654e-01, time/batch = 16.9724s	
10985/29850 (epoch 18.400), train_loss = 1.38688146, grad/param norm = 2.2776e-01, time/batch = 17.3136s	
10986/29850 (epoch 18.402), train_loss = 1.27180573, grad/param norm = 1.8678e-01, time/batch = 16.5540s	
10987/29850 (epoch 18.404), train_loss = 1.11448408, grad/param norm = 1.7827e-01, time/batch = 15.6244s	
10988/29850 (epoch 18.405), train_loss = 1.03344862, grad/param norm = 1.9744e-01, time/batch = 17.7294s	
10989/29850 (epoch 18.407), train_loss = 1.01804032, grad/param norm = 1.8968e-01, time/batch = 17.6994s	
10990/29850 (epoch 18.409), train_loss = 1.17003196, grad/param norm = 2.0251e-01, time/batch = 15.5323s	
10991/29850 (epoch 18.410), train_loss = 1.27409794, grad/param norm = 2.0856e-01, time/batch = 17.3772s	
10992/29850 (epoch 18.412), train_loss = 1.17620110, grad/param norm = 1.8860e-01, time/batch = 16.8036s	
10993/29850 (epoch 18.414), train_loss = 1.09521879, grad/param norm = 2.1338e-01, time/batch = 16.0316s	
10994/29850 (epoch 18.415), train_loss = 1.11454057, grad/param norm = 1.8927e-01, time/batch = 17.4635s	
10995/29850 (epoch 18.417), train_loss = 1.26406843, grad/param norm = 2.1746e-01, time/batch = 17.2280s	
10996/29850 (epoch 18.419), train_loss = 1.10992074, grad/param norm = 1.9908e-01, time/batch = 18.2944s	
10997/29850 (epoch 18.420), train_loss = 1.10090951, grad/param norm = 1.8162e-01, time/batch = 14.8256s	
10998/29850 (epoch 18.422), train_loss = 1.08817221, grad/param norm = 2.0431e-01, time/batch = 17.4518s	
10999/29850 (epoch 18.424), train_loss = 1.05219261, grad/param norm = 1.9205e-01, time/batch = 18.9574s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch18.43_1.6744.t7	
11000/29850 (epoch 18.425), train_loss = 1.21905805, grad/param norm = 1.8532e-01, time/batch = 15.9415s	
11001/29850 (epoch 18.427), train_loss = 1.31929228, grad/param norm = 2.2958e-01, time/batch = 16.0410s	
11002/29850 (epoch 18.429), train_loss = 0.98982193, grad/param norm = 1.7725e-01, time/batch = 16.9486s	
11003/29850 (epoch 18.430), train_loss = 0.91150435, grad/param norm = 1.5827e-01, time/batch = 17.9499s	
11004/29850 (epoch 18.432), train_loss = 1.07757547, grad/param norm = 2.2626e-01, time/batch = 16.8056s	
11005/29850 (epoch 18.434), train_loss = 0.96126703, grad/param norm = 1.6672e-01, time/batch = 16.6396s	
11006/29850 (epoch 18.436), train_loss = 1.11559257, grad/param norm = 2.0224e-01, time/batch = 17.3746s	
11007/29850 (epoch 18.437), train_loss = 1.15665086, grad/param norm = 1.8371e-01, time/batch = 16.2985s	
11008/29850 (epoch 18.439), train_loss = 1.11035438, grad/param norm = 1.8172e-01, time/batch = 18.6344s	
11009/29850 (epoch 18.441), train_loss = 1.11689731, grad/param norm = 1.9930e-01, time/batch = 17.8973s	
11010/29850 (epoch 18.442), train_loss = 1.13725104, grad/param norm = 2.0427e-01, time/batch = 16.0491s	
11011/29850 (epoch 18.444), train_loss = 1.12658618, grad/param norm = 1.9512e-01, time/batch = 15.6324s	
11012/29850 (epoch 18.446), train_loss = 1.14484960, grad/param norm = 1.8612e-01, time/batch = 17.8004s	
11013/29850 (epoch 18.447), train_loss = 1.16482491, grad/param norm = 2.0413e-01, time/batch = 17.6424s	
11014/29850 (epoch 18.449), train_loss = 1.11370119, grad/param norm = 1.9548e-01, time/batch = 16.3797s	
11015/29850 (epoch 18.451), train_loss = 0.92609984, grad/param norm = 1.7291e-01, time/batch = 16.4553s	
11016/29850 (epoch 18.452), train_loss = 0.83263050, grad/param norm = 1.5899e-01, time/batch = 16.9511s	
11017/29850 (epoch 18.454), train_loss = 0.96232736, grad/param norm = 1.6723e-01, time/batch = 18.2074s	
11018/29850 (epoch 18.456), train_loss = 1.13434035, grad/param norm = 2.0418e-01, time/batch = 17.2087s	
11019/29850 (epoch 18.457), train_loss = 1.14559088, grad/param norm = 3.1926e-01, time/batch = 15.1303s	
11020/29850 (epoch 18.459), train_loss = 1.28889821, grad/param norm = 2.3639e-01, time/batch = 18.2289s	
11021/29850 (epoch 18.461), train_loss = 1.25925928, grad/param norm = 1.8994e-01, time/batch = 17.0338s	
11022/29850 (epoch 18.462), train_loss = 1.23542535, grad/param norm = 2.1674e-01, time/batch = 17.2986s	
11023/29850 (epoch 18.464), train_loss = 1.16463838, grad/param norm = 1.9004e-01, time/batch = 18.3693s	
11024/29850 (epoch 18.466), train_loss = 0.97670539, grad/param norm = 1.9027e-01, time/batch = 17.2836s	
11025/29850 (epoch 18.467), train_loss = 1.08399246, grad/param norm = 1.9631e-01, time/batch = 17.8680s	
11026/29850 (epoch 18.469), train_loss = 1.06900518, grad/param norm = 1.9006e-01, time/batch = 18.0524s	
11027/29850 (epoch 18.471), train_loss = 1.09425052, grad/param norm = 2.0479e-01, time/batch = 17.4896s	
11028/29850 (epoch 18.472), train_loss = 1.01869553, grad/param norm = 1.8172e-01, time/batch = 17.0325s	
11029/29850 (epoch 18.474), train_loss = 1.20791719, grad/param norm = 1.8650e-01, time/batch = 18.2987s	
11030/29850 (epoch 18.476), train_loss = 1.12555668, grad/param norm = 1.9289e-01, time/batch = 17.7926s	
11031/29850 (epoch 18.477), train_loss = 1.13545986, grad/param norm = 2.2085e-01, time/batch = 17.4520s	
11032/29850 (epoch 18.479), train_loss = 1.26236006, grad/param norm = 2.1950e-01, time/batch = 15.7585s	
11033/29850 (epoch 18.481), train_loss = 1.11821870, grad/param norm = 1.9923e-01, time/batch = 17.3064s	
11034/29850 (epoch 18.482), train_loss = 1.02083354, grad/param norm = 1.6995e-01, time/batch = 16.7782s	
11035/29850 (epoch 18.484), train_loss = 1.02826144, grad/param norm = 1.7489e-01, time/batch = 18.9477s	
11036/29850 (epoch 18.486), train_loss = 1.11598609, grad/param norm = 1.8647e-01, time/batch = 17.6310s	
11037/29850 (epoch 18.487), train_loss = 1.09559292, grad/param norm = 2.1065e-01, time/batch = 19.2091s	
11038/29850 (epoch 18.489), train_loss = 1.09575646, grad/param norm = 2.0126e-01, time/batch = 17.0525s	
11039/29850 (epoch 18.491), train_loss = 0.98286203, grad/param norm = 1.6792e-01, time/batch = 18.3891s	
11040/29850 (epoch 18.492), train_loss = 1.09980335, grad/param norm = 1.8868e-01, time/batch = 17.2048s	
11041/29850 (epoch 18.494), train_loss = 1.21370820, grad/param norm = 1.8111e-01, time/batch = 16.9493s	
11042/29850 (epoch 18.496), train_loss = 1.23635817, grad/param norm = 1.8310e-01, time/batch = 18.4626s	
11043/29850 (epoch 18.497), train_loss = 1.15736030, grad/param norm = 1.7818e-01, time/batch = 18.1421s	
11044/29850 (epoch 18.499), train_loss = 1.09402550, grad/param norm = 1.9020e-01, time/batch = 17.5519s	
11045/29850 (epoch 18.501), train_loss = 1.04261044, grad/param norm = 1.9793e-01, time/batch = 33.4388s	
11046/29850 (epoch 18.503), train_loss = 1.09807363, grad/param norm = 1.8437e-01, time/batch = 16.6294s	
11047/29850 (epoch 18.504), train_loss = 1.31887387, grad/param norm = 1.9312e-01, time/batch = 16.4565s	
11048/29850 (epoch 18.506), train_loss = 1.27901945, grad/param norm = 2.1285e-01, time/batch = 16.2266s	
11049/29850 (epoch 18.508), train_loss = 1.09718902, grad/param norm = 1.8221e-01, time/batch = 18.2174s	
11050/29850 (epoch 18.509), train_loss = 0.89749903, grad/param norm = 1.7517e-01, time/batch = 18.9570s	
11051/29850 (epoch 18.511), train_loss = 1.09368334, grad/param norm = 1.8395e-01, time/batch = 17.3838s	
11052/29850 (epoch 18.513), train_loss = 1.13078440, grad/param norm = 2.0637e-01, time/batch = 17.5514s	
11053/29850 (epoch 18.514), train_loss = 0.97521781, grad/param norm = 1.7523e-01, time/batch = 15.7827s	
11054/29850 (epoch 18.516), train_loss = 1.02769049, grad/param norm = 1.7719e-01, time/batch = 17.0445s	
11055/29850 (epoch 18.518), train_loss = 0.94125750, grad/param norm = 1.8387e-01, time/batch = 16.5352s	
11056/29850 (epoch 18.519), train_loss = 0.93449125, grad/param norm = 1.7130e-01, time/batch = 16.7037s	
11057/29850 (epoch 18.521), train_loss = 0.91030591, grad/param norm = 1.6270e-01, time/batch = 18.8453s	
11058/29850 (epoch 18.523), train_loss = 0.94587193, grad/param norm = 1.6002e-01, time/batch = 18.5104s	
11059/29850 (epoch 18.524), train_loss = 1.03550093, grad/param norm = 1.8960e-01, time/batch = 18.9549s	
11060/29850 (epoch 18.526), train_loss = 1.12952633, grad/param norm = 2.0214e-01, time/batch = 20.1967s	
11061/29850 (epoch 18.528), train_loss = 1.20328334, grad/param norm = 1.9956e-01, time/batch = 16.7181s	
11062/29850 (epoch 18.529), train_loss = 1.13051577, grad/param norm = 1.9564e-01, time/batch = 17.2212s	
11063/29850 (epoch 18.531), train_loss = 1.07746274, grad/param norm = 2.0735e-01, time/batch = 18.1276s	
11064/29850 (epoch 18.533), train_loss = 1.05403201, grad/param norm = 1.7824e-01, time/batch = 16.4519s	
11065/29850 (epoch 18.534), train_loss = 1.10488210, grad/param norm = 1.8405e-01, time/batch = 16.5493s	
11066/29850 (epoch 18.536), train_loss = 1.05832750, grad/param norm = 2.0422e-01, time/batch = 16.9683s	
11067/29850 (epoch 18.538), train_loss = 1.21277176, grad/param norm = 1.9771e-01, time/batch = 17.8709s	
11068/29850 (epoch 18.539), train_loss = 1.27511160, grad/param norm = 2.0569e-01, time/batch = 18.4367s	
11069/29850 (epoch 18.541), train_loss = 0.89850598, grad/param norm = 1.7255e-01, time/batch = 18.2932s	
11070/29850 (epoch 18.543), train_loss = 1.08896135, grad/param norm = 1.8138e-01, time/batch = 15.4477s	
11071/29850 (epoch 18.544), train_loss = 1.13281259, grad/param norm = 1.9979e-01, time/batch = 16.4632s	
11072/29850 (epoch 18.546), train_loss = 1.19862858, grad/param norm = 1.9215e-01, time/batch = 17.8819s	
11073/29850 (epoch 18.548), train_loss = 0.93917961, grad/param norm = 1.6612e-01, time/batch = 18.8895s	
11074/29850 (epoch 18.549), train_loss = 1.03908132, grad/param norm = 1.8049e-01, time/batch = 18.5507s	
11075/29850 (epoch 18.551), train_loss = 0.96050472, grad/param norm = 1.6846e-01, time/batch = 16.7110s	
11076/29850 (epoch 18.553), train_loss = 1.07302191, grad/param norm = 1.7910e-01, time/batch = 19.2180s	
11077/29850 (epoch 18.554), train_loss = 0.94511352, grad/param norm = 1.8431e-01, time/batch = 18.0621s	
11078/29850 (epoch 18.556), train_loss = 1.03464639, grad/param norm = 2.1104e-01, time/batch = 16.2031s	
11079/29850 (epoch 18.558), train_loss = 1.01172707, grad/param norm = 1.8535e-01, time/batch = 16.9641s	
11080/29850 (epoch 18.559), train_loss = 1.06906170, grad/param norm = 1.8188e-01, time/batch = 16.3093s	
11081/29850 (epoch 18.561), train_loss = 1.15185717, grad/param norm = 1.8987e-01, time/batch = 16.5325s	
11082/29850 (epoch 18.563), train_loss = 1.09005652, grad/param norm = 2.0039e-01, time/batch = 16.6861s	
11083/29850 (epoch 18.564), train_loss = 1.05647970, grad/param norm = 1.8567e-01, time/batch = 18.6155s	
11084/29850 (epoch 18.566), train_loss = 1.10109349, grad/param norm = 1.9151e-01, time/batch = 18.3756s	
11085/29850 (epoch 18.568), train_loss = 1.20733151, grad/param norm = 2.0949e-01, time/batch = 16.7713s	
11086/29850 (epoch 18.570), train_loss = 1.11401128, grad/param norm = 1.8923e-01, time/batch = 17.6080s	
11087/29850 (epoch 18.571), train_loss = 1.15244863, grad/param norm = 1.9090e-01, time/batch = 17.1480s	
11088/29850 (epoch 18.573), train_loss = 1.25544534, grad/param norm = 2.2337e-01, time/batch = 16.7889s	
11089/29850 (epoch 18.575), train_loss = 1.20333967, grad/param norm = 1.8465e-01, time/batch = 14.8970s	
11090/29850 (epoch 18.576), train_loss = 1.17586683, grad/param norm = 1.9040e-01, time/batch = 19.0414s	
11091/29850 (epoch 18.578), train_loss = 1.05933167, grad/param norm = 1.8538e-01, time/batch = 18.3687s	
11092/29850 (epoch 18.580), train_loss = 1.21424948, grad/param norm = 1.7802e-01, time/batch = 17.9606s	
11093/29850 (epoch 18.581), train_loss = 0.99922728, grad/param norm = 1.7322e-01, time/batch = 17.6375s	
11094/29850 (epoch 18.583), train_loss = 1.06011997, grad/param norm = 1.9043e-01, time/batch = 19.1989s	
11095/29850 (epoch 18.585), train_loss = 1.13666554, grad/param norm = 1.9036e-01, time/batch = 15.2212s	
11096/29850 (epoch 18.586), train_loss = 1.14163046, grad/param norm = 1.9466e-01, time/batch = 16.2168s	
11097/29850 (epoch 18.588), train_loss = 1.06601306, grad/param norm = 2.0635e-01, time/batch = 18.3805s	
11098/29850 (epoch 18.590), train_loss = 1.09420878, grad/param norm = 1.9868e-01, time/batch = 15.6918s	
11099/29850 (epoch 18.591), train_loss = 1.03622984, grad/param norm = 1.9372e-01, time/batch = 16.6273s	
11100/29850 (epoch 18.593), train_loss = 1.00855149, grad/param norm = 1.7535e-01, time/batch = 17.2801s	
11101/29850 (epoch 18.595), train_loss = 0.96252252, grad/param norm = 1.6144e-01, time/batch = 18.5432s	
11102/29850 (epoch 18.596), train_loss = 0.95355026, grad/param norm = 1.7884e-01, time/batch = 17.5370s	
11103/29850 (epoch 18.598), train_loss = 1.02845097, grad/param norm = 1.7179e-01, time/batch = 17.1226s	
11104/29850 (epoch 18.600), train_loss = 1.15683621, grad/param norm = 1.9904e-01, time/batch = 19.1309s	
11105/29850 (epoch 18.601), train_loss = 0.96300513, grad/param norm = 1.8326e-01, time/batch = 17.9717s	
11106/29850 (epoch 18.603), train_loss = 1.05024886, grad/param norm = 2.0038e-01, time/batch = 17.7746s	
11107/29850 (epoch 18.605), train_loss = 1.05729654, grad/param norm = 1.8946e-01, time/batch = 16.5690s	
11108/29850 (epoch 18.606), train_loss = 0.83360291, grad/param norm = 1.5823e-01, time/batch = 18.6359s	
11109/29850 (epoch 18.608), train_loss = 1.05406054, grad/param norm = 1.9585e-01, time/batch = 18.2564s	
11110/29850 (epoch 18.610), train_loss = 1.08601989, grad/param norm = 1.8888e-01, time/batch = 17.2890s	
11111/29850 (epoch 18.611), train_loss = 0.96834693, grad/param norm = 1.6760e-01, time/batch = 20.1250s	
11112/29850 (epoch 18.613), train_loss = 0.82860910, grad/param norm = 1.6472e-01, time/batch = 16.6934s	
11113/29850 (epoch 18.615), train_loss = 0.95302469, grad/param norm = 1.7182e-01, time/batch = 16.7147s	
11114/29850 (epoch 18.616), train_loss = 0.95472739, grad/param norm = 1.8329e-01, time/batch = 17.9573s	
11115/29850 (epoch 18.618), train_loss = 1.03405455, grad/param norm = 1.8234e-01, time/batch = 17.3833s	
11116/29850 (epoch 18.620), train_loss = 1.12518650, grad/param norm = 1.9197e-01, time/batch = 16.8698s	
11117/29850 (epoch 18.621), train_loss = 1.19943213, grad/param norm = 1.9835e-01, time/batch = 18.0495s	
11118/29850 (epoch 18.623), train_loss = 1.14240982, grad/param norm = 1.9150e-01, time/batch = 17.5317s	
11119/29850 (epoch 18.625), train_loss = 1.11079705, grad/param norm = 1.9360e-01, time/batch = 16.2858s	
11120/29850 (epoch 18.626), train_loss = 1.13058400, grad/param norm = 1.9291e-01, time/batch = 17.2071s	
11121/29850 (epoch 18.628), train_loss = 0.98121441, grad/param norm = 1.7210e-01, time/batch = 19.2838s	
11122/29850 (epoch 18.630), train_loss = 1.06947039, grad/param norm = 1.8758e-01, time/batch = 17.3780s	
11123/29850 (epoch 18.631), train_loss = 1.03263755, grad/param norm = 1.7839e-01, time/batch = 17.6263s	
11124/29850 (epoch 18.633), train_loss = 1.14382384, grad/param norm = 2.0236e-01, time/batch = 18.5474s	
11125/29850 (epoch 18.635), train_loss = 1.06003442, grad/param norm = 1.8896e-01, time/batch = 18.1275s	
11126/29850 (epoch 18.637), train_loss = 0.98353409, grad/param norm = 1.7660e-01, time/batch = 17.8017s	
11127/29850 (epoch 18.638), train_loss = 1.08129256, grad/param norm = 1.9712e-01, time/batch = 19.7100s	
11128/29850 (epoch 18.640), train_loss = 1.22130727, grad/param norm = 2.1089e-01, time/batch = 18.1271s	
11129/29850 (epoch 18.642), train_loss = 1.01955397, grad/param norm = 1.6926e-01, time/batch = 16.4492s	
11130/29850 (epoch 18.643), train_loss = 1.01006515, grad/param norm = 1.9294e-01, time/batch = 18.2993s	
11131/29850 (epoch 18.645), train_loss = 1.08036678, grad/param norm = 1.9328e-01, time/batch = 17.9453s	
11132/29850 (epoch 18.647), train_loss = 1.19971030, grad/param norm = 1.8768e-01, time/batch = 16.8753s	
11133/29850 (epoch 18.648), train_loss = 0.95033676, grad/param norm = 1.6584e-01, time/batch = 15.5234s	
11134/29850 (epoch 18.650), train_loss = 1.07866155, grad/param norm = 1.8342e-01, time/batch = 18.2134s	
11135/29850 (epoch 18.652), train_loss = 1.10070647, grad/param norm = 1.8772e-01, time/batch = 18.8782s	
11136/29850 (epoch 18.653), train_loss = 1.17843969, grad/param norm = 2.0024e-01, time/batch = 17.8058s	
11137/29850 (epoch 18.655), train_loss = 1.06642098, grad/param norm = 1.8242e-01, time/batch = 18.9536s	
11138/29850 (epoch 18.657), train_loss = 1.00786799, grad/param norm = 1.7579e-01, time/batch = 18.1855s	
11139/29850 (epoch 18.658), train_loss = 1.18304453, grad/param norm = 2.0664e-01, time/batch = 17.1198s	
11140/29850 (epoch 18.660), train_loss = 1.08078949, grad/param norm = 2.0268e-01, time/batch = 18.0448s	
11141/29850 (epoch 18.662), train_loss = 1.11831534, grad/param norm = 1.9372e-01, time/batch = 16.2996s	
11142/29850 (epoch 18.663), train_loss = 1.26368270, grad/param norm = 2.0774e-01, time/batch = 17.2979s	
11143/29850 (epoch 18.665), train_loss = 1.22077610, grad/param norm = 2.1434e-01, time/batch = 15.9857s	
11144/29850 (epoch 18.667), train_loss = 1.15108538, grad/param norm = 2.2602e-01, time/batch = 18.5502s	
11145/29850 (epoch 18.668), train_loss = 1.06340212, grad/param norm = 1.9384e-01, time/batch = 18.7155s	
11146/29850 (epoch 18.670), train_loss = 1.26592173, grad/param norm = 2.4420e-01, time/batch = 15.7220s	
11147/29850 (epoch 18.672), train_loss = 1.19915962, grad/param norm = 2.0929e-01, time/batch = 17.4802s	
11148/29850 (epoch 18.673), train_loss = 1.16411033, grad/param norm = 2.0310e-01, time/batch = 17.3905s	
11149/29850 (epoch 18.675), train_loss = 0.99161953, grad/param norm = 1.8744e-01, time/batch = 18.1078s	
11150/29850 (epoch 18.677), train_loss = 1.04682641, grad/param norm = 1.8733e-01, time/batch = 16.7752s	
11151/29850 (epoch 18.678), train_loss = 1.04434170, grad/param norm = 1.8260e-01, time/batch = 17.7169s	
11152/29850 (epoch 18.680), train_loss = 1.10054329, grad/param norm = 2.0183e-01, time/batch = 17.5436s	
11153/29850 (epoch 18.682), train_loss = 1.08845323, grad/param norm = 2.0119e-01, time/batch = 15.0358s	
11154/29850 (epoch 18.683), train_loss = 1.24185280, grad/param norm = 2.2016e-01, time/batch = 16.7900s	
11155/29850 (epoch 18.685), train_loss = 1.22436997, grad/param norm = 1.8307e-01, time/batch = 17.7234s	
11156/29850 (epoch 18.687), train_loss = 1.13400260, grad/param norm = 1.8878e-01, time/batch = 18.2909s	
11157/29850 (epoch 18.688), train_loss = 0.95646452, grad/param norm = 1.7668e-01, time/batch = 17.7146s	
11158/29850 (epoch 18.690), train_loss = 0.97319900, grad/param norm = 1.8441e-01, time/batch = 17.2167s	
11159/29850 (epoch 18.692), train_loss = 1.19144344, grad/param norm = 2.0008e-01, time/batch = 17.9553s	
11160/29850 (epoch 18.693), train_loss = 1.05992740, grad/param norm = 1.7253e-01, time/batch = 17.8468s	
11161/29850 (epoch 18.695), train_loss = 0.96494200, grad/param norm = 1.7256e-01, time/batch = 18.2999s	
11162/29850 (epoch 18.697), train_loss = 1.08632600, grad/param norm = 1.9557e-01, time/batch = 18.0564s	
11163/29850 (epoch 18.698), train_loss = 1.18266009, grad/param norm = 1.8359e-01, time/batch = 16.0486s	
11164/29850 (epoch 18.700), train_loss = 1.13231620, grad/param norm = 1.9842e-01, time/batch = 16.9050s	
11165/29850 (epoch 18.702), train_loss = 1.06527865, grad/param norm = 2.0710e-01, time/batch = 16.2146s	
11166/29850 (epoch 18.704), train_loss = 0.97099971, grad/param norm = 1.7167e-01, time/batch = 16.9558s	
11167/29850 (epoch 18.705), train_loss = 1.08521523, grad/param norm = 1.8490e-01, time/batch = 17.1235s	
11168/29850 (epoch 18.707), train_loss = 1.00416918, grad/param norm = 1.7937e-01, time/batch = 19.5298s	
11169/29850 (epoch 18.709), train_loss = 1.09301080, grad/param norm = 1.6982e-01, time/batch = 17.9535s	
11170/29850 (epoch 18.710), train_loss = 1.01962937, grad/param norm = 1.8327e-01, time/batch = 17.0444s	
11171/29850 (epoch 18.712), train_loss = 1.08028702, grad/param norm = 1.6572e-01, time/batch = 16.8635s	
11172/29850 (epoch 18.714), train_loss = 1.15088326, grad/param norm = 1.9381e-01, time/batch = 18.9500s	
11173/29850 (epoch 18.715), train_loss = 1.11330891, grad/param norm = 1.7911e-01, time/batch = 17.2014s	
11174/29850 (epoch 18.717), train_loss = 0.87199829, grad/param norm = 1.7228e-01, time/batch = 18.8740s	
11175/29850 (epoch 18.719), train_loss = 1.00801905, grad/param norm = 1.8405e-01, time/batch = 18.2037s	
11176/29850 (epoch 18.720), train_loss = 1.07568560, grad/param norm = 1.7746e-01, time/batch = 17.2141s	
11177/29850 (epoch 18.722), train_loss = 1.00588306, grad/param norm = 1.5525e-01, time/batch = 17.7117s	
11178/29850 (epoch 18.724), train_loss = 1.13456534, grad/param norm = 1.9046e-01, time/batch = 19.2930s	
11179/29850 (epoch 18.725), train_loss = 0.94291457, grad/param norm = 1.7749e-01, time/batch = 19.2202s	
11180/29850 (epoch 18.727), train_loss = 1.01163707, grad/param norm = 1.9359e-01, time/batch = 6.0831s	
11181/29850 (epoch 18.729), train_loss = 0.91807158, grad/param norm = 1.5686e-01, time/batch = 0.6618s	
11182/29850 (epoch 18.730), train_loss = 0.93822114, grad/param norm = 1.8041e-01, time/batch = 0.6645s	
11183/29850 (epoch 18.732), train_loss = 1.16817189, grad/param norm = 1.8268e-01, time/batch = 0.6530s	
11184/29850 (epoch 18.734), train_loss = 1.25977854, grad/param norm = 2.1782e-01, time/batch = 0.6535s	
11185/29850 (epoch 18.735), train_loss = 1.06461685, grad/param norm = 2.1160e-01, time/batch = 0.6571s	
11186/29850 (epoch 18.737), train_loss = 0.99283944, grad/param norm = 1.9476e-01, time/batch = 0.6688s	
11187/29850 (epoch 18.739), train_loss = 0.88309965, grad/param norm = 1.7964e-01, time/batch = 0.6919s	
11188/29850 (epoch 18.740), train_loss = 0.92845405, grad/param norm = 1.7719e-01, time/batch = 0.9806s	
11189/29850 (epoch 18.742), train_loss = 0.92432304, grad/param norm = 1.6986e-01, time/batch = 0.9987s	
11190/29850 (epoch 18.744), train_loss = 1.00627149, grad/param norm = 2.0203e-01, time/batch = 0.9942s	
11191/29850 (epoch 18.745), train_loss = 1.00384332, grad/param norm = 2.0168e-01, time/batch = 0.9674s	
11192/29850 (epoch 18.747), train_loss = 1.03322308, grad/param norm = 1.7988e-01, time/batch = 1.0030s	
11193/29850 (epoch 18.749), train_loss = 0.96869657, grad/param norm = 1.9599e-01, time/batch = 1.8258s	
11194/29850 (epoch 18.750), train_loss = 0.92883284, grad/param norm = 1.7387e-01, time/batch = 1.8478s	
11195/29850 (epoch 18.752), train_loss = 0.86878334, grad/param norm = 1.7422e-01, time/batch = 8.1702s	
11196/29850 (epoch 18.754), train_loss = 0.91544161, grad/param norm = 1.8031e-01, time/batch = 16.6396s	
11197/29850 (epoch 18.755), train_loss = 0.94070185, grad/param norm = 1.7943e-01, time/batch = 17.9656s	
11198/29850 (epoch 18.757), train_loss = 1.01606140, grad/param norm = 1.9263e-01, time/batch = 18.3707s	
11199/29850 (epoch 18.759), train_loss = 1.01249429, grad/param norm = 1.6943e-01, time/batch = 16.6311s	
11200/29850 (epoch 18.760), train_loss = 0.96181926, grad/param norm = 1.8839e-01, time/batch = 18.8945s	
11201/29850 (epoch 18.762), train_loss = 0.93152491, grad/param norm = 2.2233e-01, time/batch = 17.2930s	
11202/29850 (epoch 18.764), train_loss = 0.88968359, grad/param norm = 1.8911e-01, time/batch = 18.6255s	
11203/29850 (epoch 18.765), train_loss = 1.02857610, grad/param norm = 1.9418e-01, time/batch = 16.6177s	
11204/29850 (epoch 18.767), train_loss = 1.02638465, grad/param norm = 1.7753e-01, time/batch = 16.5507s	
11205/29850 (epoch 18.769), train_loss = 1.03915707, grad/param norm = 1.9955e-01, time/batch = 16.9551s	
11206/29850 (epoch 18.771), train_loss = 1.07955624, grad/param norm = 1.9216e-01, time/batch = 18.3531s	
11207/29850 (epoch 18.772), train_loss = 1.10128527, grad/param norm = 2.0606e-01, time/batch = 14.9954s	
11208/29850 (epoch 18.774), train_loss = 0.98272830, grad/param norm = 1.8144e-01, time/batch = 16.5389s	
11209/29850 (epoch 18.776), train_loss = 1.00829319, grad/param norm = 1.9599e-01, time/batch = 19.3572s	
11210/29850 (epoch 18.777), train_loss = 1.11747568, grad/param norm = 1.9506e-01, time/batch = 18.3229s	
11211/29850 (epoch 18.779), train_loss = 0.93916745, grad/param norm = 1.7321e-01, time/batch = 16.8702s	
11212/29850 (epoch 18.781), train_loss = 1.03433303, grad/param norm = 1.8456e-01, time/batch = 18.3652s	
11213/29850 (epoch 18.782), train_loss = 1.09209126, grad/param norm = 1.9113e-01, time/batch = 16.6207s	
11214/29850 (epoch 18.784), train_loss = 0.95384006, grad/param norm = 2.0869e-01, time/batch = 18.4487s	
11215/29850 (epoch 18.786), train_loss = 1.00583998, grad/param norm = 1.7377e-01, time/batch = 15.0582s	
11216/29850 (epoch 18.787), train_loss = 0.93005315, grad/param norm = 1.9533e-01, time/batch = 17.7755s	
11217/29850 (epoch 18.789), train_loss = 0.86641952, grad/param norm = 1.5622e-01, time/batch = 17.4587s	
11218/29850 (epoch 18.791), train_loss = 0.96249703, grad/param norm = 1.9496e-01, time/batch = 17.8720s	
11219/29850 (epoch 18.792), train_loss = 1.10123137, grad/param norm = 2.0193e-01, time/batch = 19.1229s	
11220/29850 (epoch 18.794), train_loss = 1.07223330, grad/param norm = 1.7475e-01, time/batch = 17.9478s	
11221/29850 (epoch 18.796), train_loss = 0.95028292, grad/param norm = 1.7354e-01, time/batch = 17.5126s	
11222/29850 (epoch 18.797), train_loss = 0.87028589, grad/param norm = 1.8009e-01, time/batch = 18.9666s	
11223/29850 (epoch 18.799), train_loss = 0.92878160, grad/param norm = 1.6706e-01, time/batch = 17.7920s	
11224/29850 (epoch 18.801), train_loss = 1.02760096, grad/param norm = 1.8714e-01, time/batch = 17.8699s	
11225/29850 (epoch 18.802), train_loss = 0.85803957, grad/param norm = 1.7888e-01, time/batch = 16.6833s	
11226/29850 (epoch 18.804), train_loss = 0.90749729, grad/param norm = 1.6067e-01, time/batch = 19.8580s	
11227/29850 (epoch 18.806), train_loss = 0.92971787, grad/param norm = 1.9326e-01, time/batch = 16.5549s	
11228/29850 (epoch 18.807), train_loss = 0.85768450, grad/param norm = 1.4685e-01, time/batch = 16.3809s	
11229/29850 (epoch 18.809), train_loss = 0.94065737, grad/param norm = 1.9320e-01, time/batch = 17.3860s	
11230/29850 (epoch 18.811), train_loss = 1.07185143, grad/param norm = 2.0394e-01, time/batch = 16.5589s	
11231/29850 (epoch 18.812), train_loss = 1.06719378, grad/param norm = 1.8687e-01, time/batch = 18.2153s	
11232/29850 (epoch 18.814), train_loss = 1.15052370, grad/param norm = 1.9995e-01, time/batch = 17.1887s	
11233/29850 (epoch 18.816), train_loss = 1.11190716, grad/param norm = 1.7644e-01, time/batch = 19.5414s	
11234/29850 (epoch 18.817), train_loss = 1.04566258, grad/param norm = 1.9668e-01, time/batch = 18.1325s	
11235/29850 (epoch 18.819), train_loss = 0.91605979, grad/param norm = 1.9339e-01, time/batch = 16.7602s	
11236/29850 (epoch 18.821), train_loss = 1.15532942, grad/param norm = 1.9544e-01, time/batch = 17.8642s	
11237/29850 (epoch 18.822), train_loss = 1.15845944, grad/param norm = 1.9887e-01, time/batch = 19.5482s	
11238/29850 (epoch 18.824), train_loss = 1.03614104, grad/param norm = 1.8420e-01, time/batch = 17.7048s	
11239/29850 (epoch 18.826), train_loss = 0.97891926, grad/param norm = 1.7828e-01, time/batch = 17.6149s	
11240/29850 (epoch 18.827), train_loss = 0.92842013, grad/param norm = 1.8261e-01, time/batch = 18.8788s	
11241/29850 (epoch 18.829), train_loss = 1.04926626, grad/param norm = 1.9640e-01, time/batch = 18.4672s	
11242/29850 (epoch 18.831), train_loss = 1.10903425, grad/param norm = 2.0218e-01, time/batch = 17.4661s	
11243/29850 (epoch 18.832), train_loss = 1.02174685, grad/param norm = 1.7404e-01, time/batch = 19.0408s	
11244/29850 (epoch 18.834), train_loss = 0.86331934, grad/param norm = 1.6385e-01, time/batch = 16.7870s	
11245/29850 (epoch 18.836), train_loss = 0.90259098, grad/param norm = 1.7570e-01, time/batch = 16.8653s	
11246/29850 (epoch 18.838), train_loss = 1.04302487, grad/param norm = 1.9096e-01, time/batch = 16.9021s	
11247/29850 (epoch 18.839), train_loss = 0.95033957, grad/param norm = 1.6956e-01, time/batch = 17.9690s	
11248/29850 (epoch 18.841), train_loss = 0.94550729, grad/param norm = 1.7048e-01, time/batch = 17.0433s	
11249/29850 (epoch 18.843), train_loss = 0.93252856, grad/param norm = 1.7357e-01, time/batch = 16.7055s	
11250/29850 (epoch 18.844), train_loss = 0.93918257, grad/param norm = 1.8224e-01, time/batch = 16.7198s	
11251/29850 (epoch 18.846), train_loss = 1.04993189, grad/param norm = 1.7964e-01, time/batch = 18.3079s	
11252/29850 (epoch 18.848), train_loss = 1.09577709, grad/param norm = 1.9795e-01, time/batch = 17.8667s	
11253/29850 (epoch 18.849), train_loss = 0.97855677, grad/param norm = 2.1924e-01, time/batch = 17.3511s	
11254/29850 (epoch 18.851), train_loss = 1.13083087, grad/param norm = 2.0875e-01, time/batch = 16.3034s	
11255/29850 (epoch 18.853), train_loss = 0.96275979, grad/param norm = 2.1437e-01, time/batch = 17.9570s	
11256/29850 (epoch 18.854), train_loss = 1.17298387, grad/param norm = 2.0600e-01, time/batch = 18.1303s	
11257/29850 (epoch 18.856), train_loss = 1.13490389, grad/param norm = 2.3530e-01, time/batch = 18.3759s	
11258/29850 (epoch 18.858), train_loss = 1.03172159, grad/param norm = 2.0127e-01, time/batch = 17.2040s	
11259/29850 (epoch 18.859), train_loss = 0.93910824, grad/param norm = 2.0026e-01, time/batch = 19.4570s	
11260/29850 (epoch 18.861), train_loss = 1.12757761, grad/param norm = 1.9142e-01, time/batch = 16.3517s	
11261/29850 (epoch 18.863), train_loss = 1.19788887, grad/param norm = 1.8678e-01, time/batch = 18.1247s	
11262/29850 (epoch 18.864), train_loss = 1.13473455, grad/param norm = 2.0109e-01, time/batch = 30.9048s	
11263/29850 (epoch 18.866), train_loss = 1.06323253, grad/param norm = 1.9705e-01, time/batch = 17.0341s	
11264/29850 (epoch 18.868), train_loss = 1.20641289, grad/param norm = 2.1212e-01, time/batch = 15.9343s	
11265/29850 (epoch 18.869), train_loss = 1.04613881, grad/param norm = 1.9849e-01, time/batch = 18.0402s	
11266/29850 (epoch 18.871), train_loss = 1.11208622, grad/param norm = 1.9583e-01, time/batch = 17.1288s	
11267/29850 (epoch 18.873), train_loss = 1.09233256, grad/param norm = 2.1414e-01, time/batch = 17.9707s	
11268/29850 (epoch 18.874), train_loss = 1.06455712, grad/param norm = 1.8122e-01, time/batch = 15.8036s	
11269/29850 (epoch 18.876), train_loss = 1.02973135, grad/param norm = 2.3627e-01, time/batch = 18.9630s	
11270/29850 (epoch 18.878), train_loss = 1.06181096, grad/param norm = 1.8743e-01, time/batch = 18.8039s	
11271/29850 (epoch 18.879), train_loss = 1.08019345, grad/param norm = 1.9599e-01, time/batch = 18.1186s	
11272/29850 (epoch 18.881), train_loss = 1.18003708, grad/param norm = 2.2720e-01, time/batch = 19.9528s	
11273/29850 (epoch 18.883), train_loss = 1.13431223, grad/param norm = 1.9539e-01, time/batch = 17.6280s	
11274/29850 (epoch 18.884), train_loss = 0.94380047, grad/param norm = 1.9407e-01, time/batch = 15.8497s	
11275/29850 (epoch 18.886), train_loss = 1.18049107, grad/param norm = 2.0150e-01, time/batch = 18.6089s	
11276/29850 (epoch 18.888), train_loss = 1.06378591, grad/param norm = 1.9627e-01, time/batch = 19.3488s	
11277/29850 (epoch 18.889), train_loss = 0.99883218, grad/param norm = 1.7584e-01, time/batch = 18.5468s	
11278/29850 (epoch 18.891), train_loss = 0.98295681, grad/param norm = 1.8331e-01, time/batch = 17.1991s	
11279/29850 (epoch 18.893), train_loss = 0.95540644, grad/param norm = 1.7868e-01, time/batch = 18.1346s	
11280/29850 (epoch 18.894), train_loss = 0.98988751, grad/param norm = 1.7515e-01, time/batch = 15.7869s	
11281/29850 (epoch 18.896), train_loss = 1.03800009, grad/param norm = 1.9486e-01, time/batch = 16.7941s	
11282/29850 (epoch 18.898), train_loss = 1.16402576, grad/param norm = 2.0633e-01, time/batch = 16.5461s	
11283/29850 (epoch 18.899), train_loss = 0.91200958, grad/param norm = 2.1098e-01, time/batch = 17.2236s	
11284/29850 (epoch 18.901), train_loss = 1.34537309, grad/param norm = 2.9010e-01, time/batch = 18.1433s	
11285/29850 (epoch 18.903), train_loss = 1.05740521, grad/param norm = 2.3287e-01, time/batch = 17.4518s	
11286/29850 (epoch 18.905), train_loss = 1.28706413, grad/param norm = 2.1658e-01, time/batch = 17.8763s	
11287/29850 (epoch 18.906), train_loss = 1.07844208, grad/param norm = 2.0936e-01, time/batch = 19.2083s	
11288/29850 (epoch 18.908), train_loss = 1.18250232, grad/param norm = 2.0727e-01, time/batch = 16.3000s	
11289/29850 (epoch 18.910), train_loss = 1.14183626, grad/param norm = 1.8899e-01, time/batch = 19.3742s	
11290/29850 (epoch 18.911), train_loss = 1.25076681, grad/param norm = 1.9500e-01, time/batch = 17.6032s	
11291/29850 (epoch 18.913), train_loss = 1.15761701, grad/param norm = 1.8457e-01, time/batch = 17.3814s	
11292/29850 (epoch 18.915), train_loss = 1.18232257, grad/param norm = 2.1493e-01, time/batch = 18.0412s	
11293/29850 (epoch 18.916), train_loss = 1.15004410, grad/param norm = 2.1245e-01, time/batch = 17.9598s	
11294/29850 (epoch 18.918), train_loss = 1.00214790, grad/param norm = 1.7650e-01, time/batch = 18.7123s	
11295/29850 (epoch 18.920), train_loss = 1.11209291, grad/param norm = 1.8048e-01, time/batch = 16.0995s	
11296/29850 (epoch 18.921), train_loss = 1.10814947, grad/param norm = 2.2222e-01, time/batch = 17.1456s	
11297/29850 (epoch 18.923), train_loss = 1.15495105, grad/param norm = 1.9535e-01, time/batch = 15.6975s	
11298/29850 (epoch 18.925), train_loss = 1.19412094, grad/param norm = 2.1534e-01, time/batch = 17.6272s	
11299/29850 (epoch 18.926), train_loss = 1.26357304, grad/param norm = 2.2437e-01, time/batch = 16.5461s	
11300/29850 (epoch 18.928), train_loss = 1.10838643, grad/param norm = 2.0181e-01, time/batch = 18.0317s	
11301/29850 (epoch 18.930), train_loss = 1.15256664, grad/param norm = 2.0908e-01, time/batch = 18.2145s	
11302/29850 (epoch 18.931), train_loss = 1.07524551, grad/param norm = 2.1470e-01, time/batch = 18.8584s	
11303/29850 (epoch 18.933), train_loss = 1.24196492, grad/param norm = 2.0258e-01, time/batch = 17.8776s	
11304/29850 (epoch 18.935), train_loss = 1.18659962, grad/param norm = 2.0708e-01, time/batch = 17.5278s	
11305/29850 (epoch 18.936), train_loss = 1.18625380, grad/param norm = 2.1990e-01, time/batch = 17.5376s	
11306/29850 (epoch 18.938), train_loss = 0.94730106, grad/param norm = 1.6494e-01, time/batch = 17.6297s	
11307/29850 (epoch 18.940), train_loss = 0.95562551, grad/param norm = 1.7447e-01, time/batch = 19.1141s	
11308/29850 (epoch 18.941), train_loss = 1.02511747, grad/param norm = 2.0482e-01, time/batch = 18.5351s	
11309/29850 (epoch 18.943), train_loss = 0.99842661, grad/param norm = 1.8586e-01, time/batch = 18.3882s	
11310/29850 (epoch 18.945), train_loss = 1.04996881, grad/param norm = 2.1060e-01, time/batch = 18.6270s	
11311/29850 (epoch 18.946), train_loss = 0.96528865, grad/param norm = 2.0669e-01, time/batch = 17.9441s	
11312/29850 (epoch 18.948), train_loss = 1.08198421, grad/param norm = 1.8455e-01, time/batch = 17.0376s	
11313/29850 (epoch 18.950), train_loss = 0.99958985, grad/param norm = 1.7068e-01, time/batch = 17.7845s	
11314/29850 (epoch 18.951), train_loss = 0.95074859, grad/param norm = 1.6707e-01, time/batch = 17.4586s	
11315/29850 (epoch 18.953), train_loss = 1.04195015, grad/param norm = 1.9036e-01, time/batch = 15.2258s	
11316/29850 (epoch 18.955), train_loss = 0.93356829, grad/param norm = 1.6447e-01, time/batch = 15.1477s	
11317/29850 (epoch 18.956), train_loss = 0.92209347, grad/param norm = 1.7127e-01, time/batch = 18.0504s	
11318/29850 (epoch 18.958), train_loss = 0.79464002, grad/param norm = 1.4633e-01, time/batch = 17.8646s	
11319/29850 (epoch 18.960), train_loss = 1.12593248, grad/param norm = 2.0025e-01, time/batch = 17.3813s	
11320/29850 (epoch 18.961), train_loss = 0.95630030, grad/param norm = 1.7019e-01, time/batch = 17.1534s	
11321/29850 (epoch 18.963), train_loss = 0.92972575, grad/param norm = 1.6979e-01, time/batch = 16.7850s	
11322/29850 (epoch 18.965), train_loss = 0.96814375, grad/param norm = 1.8959e-01, time/batch = 17.2242s	
11323/29850 (epoch 18.966), train_loss = 0.91892191, grad/param norm = 1.7696e-01, time/batch = 16.8834s	
11324/29850 (epoch 18.968), train_loss = 0.97015917, grad/param norm = 1.7867e-01, time/batch = 19.4586s	
11325/29850 (epoch 18.970), train_loss = 0.93213643, grad/param norm = 1.9144e-01, time/batch = 15.7847s	
11326/29850 (epoch 18.972), train_loss = 0.96318478, grad/param norm = 1.6822e-01, time/batch = 17.8811s	
11327/29850 (epoch 18.973), train_loss = 0.96969714, grad/param norm = 1.9454e-01, time/batch = 15.5633s	
11328/29850 (epoch 18.975), train_loss = 0.83902807, grad/param norm = 1.7826e-01, time/batch = 19.4546s	
11329/29850 (epoch 18.977), train_loss = 0.98044188, grad/param norm = 1.6297e-01, time/batch = 17.7498s	
11330/29850 (epoch 18.978), train_loss = 0.93341530, grad/param norm = 1.6257e-01, time/batch = 18.0550s	
11331/29850 (epoch 18.980), train_loss = 0.99854749, grad/param norm = 1.7440e-01, time/batch = 16.4253s	
11332/29850 (epoch 18.982), train_loss = 0.99133436, grad/param norm = 1.8448e-01, time/batch = 16.0360s	
11333/29850 (epoch 18.983), train_loss = 1.00959259, grad/param norm = 1.7280e-01, time/batch = 17.0527s	
11334/29850 (epoch 18.985), train_loss = 1.05312444, grad/param norm = 1.7986e-01, time/batch = 18.0489s	
11335/29850 (epoch 18.987), train_loss = 1.04670776, grad/param norm = 1.9785e-01, time/batch = 18.4431s	
11336/29850 (epoch 18.988), train_loss = 0.97206219, grad/param norm = 1.7378e-01, time/batch = 17.8651s	
11337/29850 (epoch 18.990), train_loss = 1.06874127, grad/param norm = 1.8844e-01, time/batch = 18.4702s	
11338/29850 (epoch 18.992), train_loss = 1.06447245, grad/param norm = 1.7920e-01, time/batch = 18.2193s	
11339/29850 (epoch 18.993), train_loss = 1.06030414, grad/param norm = 1.8176e-01, time/batch = 16.6264s	
11340/29850 (epoch 18.995), train_loss = 1.05915921, grad/param norm = 1.8515e-01, time/batch = 18.2151s	
11341/29850 (epoch 18.997), train_loss = 1.06627912, grad/param norm = 2.0382e-01, time/batch = 17.5483s	
11342/29850 (epoch 18.998), train_loss = 1.13659252, grad/param norm = 1.9484e-01, time/batch = 17.1157s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
11343/29850 (epoch 19.000), train_loss = 0.94552600, grad/param norm = 1.7816e-01, time/batch = 17.5601s	
11344/29850 (epoch 19.002), train_loss = 1.25955208, grad/param norm = 2.0501e-01, time/batch = 19.3795s	
11345/29850 (epoch 19.003), train_loss = 0.96442520, grad/param norm = 1.8117e-01, time/batch = 18.0455s	
11346/29850 (epoch 19.005), train_loss = 1.07013294, grad/param norm = 1.8609e-01, time/batch = 17.6208s	
11347/29850 (epoch 19.007), train_loss = 1.10325315, grad/param norm = 2.0968e-01, time/batch = 17.3897s	
11348/29850 (epoch 19.008), train_loss = 1.28510597, grad/param norm = 2.1186e-01, time/batch = 18.0338s	
11349/29850 (epoch 19.010), train_loss = 0.95775052, grad/param norm = 2.0115e-01, time/batch = 17.3722s	
11350/29850 (epoch 19.012), train_loss = 1.05800907, grad/param norm = 1.6361e-01, time/batch = 16.8013s	
11351/29850 (epoch 19.013), train_loss = 1.09671562, grad/param norm = 2.1222e-01, time/batch = 17.0509s	
11352/29850 (epoch 19.015), train_loss = 1.10990070, grad/param norm = 1.7283e-01, time/batch = 17.7089s	
11353/29850 (epoch 19.017), train_loss = 1.09575144, grad/param norm = 1.8771e-01, time/batch = 17.8796s	
11354/29850 (epoch 19.018), train_loss = 1.17550347, grad/param norm = 2.0754e-01, time/batch = 16.4402s	
11355/29850 (epoch 19.020), train_loss = 1.03782241, grad/param norm = 1.8574e-01, time/batch = 16.7149s	
11356/29850 (epoch 19.022), train_loss = 1.18194791, grad/param norm = 1.9554e-01, time/batch = 15.4509s	
11357/29850 (epoch 19.023), train_loss = 1.11300314, grad/param norm = 1.8220e-01, time/batch = 16.9723s	
11358/29850 (epoch 19.025), train_loss = 1.02386716, grad/param norm = 1.6721e-01, time/batch = 18.7223s	
11359/29850 (epoch 19.027), train_loss = 0.86429311, grad/param norm = 1.6219e-01, time/batch = 18.4522s	
11360/29850 (epoch 19.028), train_loss = 1.02131605, grad/param norm = 1.6747e-01, time/batch = 17.5535s	
11361/29850 (epoch 19.030), train_loss = 1.06889895, grad/param norm = 2.0748e-01, time/batch = 18.1342s	
11362/29850 (epoch 19.032), train_loss = 1.10006339, grad/param norm = 1.8826e-01, time/batch = 19.5441s	
11363/29850 (epoch 19.034), train_loss = 0.97946665, grad/param norm = 1.7076e-01, time/batch = 16.1984s	
11364/29850 (epoch 19.035), train_loss = 0.89273616, grad/param norm = 1.6527e-01, time/batch = 17.6426s	
11365/29850 (epoch 19.037), train_loss = 1.03701494, grad/param norm = 1.8101e-01, time/batch = 17.3736s	
11366/29850 (epoch 19.039), train_loss = 0.92321629, grad/param norm = 1.6445e-01, time/batch = 17.3996s	
11367/29850 (epoch 19.040), train_loss = 0.97554732, grad/param norm = 1.8581e-01, time/batch = 15.5291s	
11368/29850 (epoch 19.042), train_loss = 0.97259503, grad/param norm = 1.9202e-01, time/batch = 18.5424s	
11369/29850 (epoch 19.044), train_loss = 1.00411571, grad/param norm = 1.7640e-01, time/batch = 16.6915s	
11370/29850 (epoch 19.045), train_loss = 1.10627298, grad/param norm = 1.7885e-01, time/batch = 18.5282s	
11371/29850 (epoch 19.047), train_loss = 0.88723203, grad/param norm = 1.7360e-01, time/batch = 18.1216s	
11372/29850 (epoch 19.049), train_loss = 1.07487994, grad/param norm = 1.7946e-01, time/batch = 18.7236s	
11373/29850 (epoch 19.050), train_loss = 0.97350133, grad/param norm = 1.8373e-01, time/batch = 17.6178s	
11374/29850 (epoch 19.052), train_loss = 1.16980027, grad/param norm = 2.0836e-01, time/batch = 18.9711s	
11375/29850 (epoch 19.054), train_loss = 1.09906414, grad/param norm = 2.0365e-01, time/batch = 17.0367s	
11376/29850 (epoch 19.055), train_loss = 1.03491473, grad/param norm = 1.9051e-01, time/batch = 16.7756s	
11377/29850 (epoch 19.057), train_loss = 1.11438953, grad/param norm = 1.7830e-01, time/batch = 19.8698s	
11378/29850 (epoch 19.059), train_loss = 1.08350631, grad/param norm = 1.9027e-01, time/batch = 18.7006s	
11379/29850 (epoch 19.060), train_loss = 1.08575016, grad/param norm = 1.9202e-01, time/batch = 18.5230s	
11380/29850 (epoch 19.062), train_loss = 1.18826342, grad/param norm = 2.1868e-01, time/batch = 3.2461s	
11381/29850 (epoch 19.064), train_loss = 1.13260176, grad/param norm = 2.1005e-01, time/batch = 0.6691s	
11382/29850 (epoch 19.065), train_loss = 0.96984706, grad/param norm = 1.9118e-01, time/batch = 0.6670s	
11383/29850 (epoch 19.067), train_loss = 1.10306944, grad/param norm = 1.8172e-01, time/batch = 0.6609s	
11384/29850 (epoch 19.069), train_loss = 1.05069166, grad/param norm = 1.7466e-01, time/batch = 0.6588s	
11385/29850 (epoch 19.070), train_loss = 1.11658220, grad/param norm = 1.7977e-01, time/batch = 0.6682s	
11386/29850 (epoch 19.072), train_loss = 1.10534832, grad/param norm = 2.1815e-01, time/batch = 0.6839s	
11387/29850 (epoch 19.074), train_loss = 1.13537929, grad/param norm = 1.9005e-01, time/batch = 0.7796s	
11388/29850 (epoch 19.075), train_loss = 0.98988135, grad/param norm = 1.7975e-01, time/batch = 0.9565s	
11389/29850 (epoch 19.077), train_loss = 1.10035219, grad/param norm = 1.9608e-01, time/batch = 0.9864s	
11390/29850 (epoch 19.079), train_loss = 1.30286658, grad/param norm = 2.7501e-01, time/batch = 0.9661s	
11391/29850 (epoch 19.080), train_loss = 1.29480476, grad/param norm = 2.3821e-01, time/batch = 0.9642s	
11392/29850 (epoch 19.082), train_loss = 1.14306285, grad/param norm = 2.0097e-01, time/batch = 1.1752s	
11393/29850 (epoch 19.084), train_loss = 1.21831398, grad/param norm = 2.0678e-01, time/batch = 1.8234s	
11394/29850 (epoch 19.085), train_loss = 1.18375202, grad/param norm = 2.1577e-01, time/batch = 1.8065s	
11395/29850 (epoch 19.087), train_loss = 1.21236822, grad/param norm = 2.0026e-01, time/batch = 10.0334s	
11396/29850 (epoch 19.089), train_loss = 1.11154849, grad/param norm = 1.8705e-01, time/batch = 17.2909s	
11397/29850 (epoch 19.090), train_loss = 1.14564044, grad/param norm = 1.9335e-01, time/batch = 17.0452s	
11398/29850 (epoch 19.092), train_loss = 1.02462167, grad/param norm = 1.8252e-01, time/batch = 15.9136s	
11399/29850 (epoch 19.094), train_loss = 1.18487564, grad/param norm = 2.0597e-01, time/batch = 17.6228s	
11400/29850 (epoch 19.095), train_loss = 1.10870652, grad/param norm = 2.1479e-01, time/batch = 18.2905s	
11401/29850 (epoch 19.097), train_loss = 0.88230542, grad/param norm = 1.6407e-01, time/batch = 18.0371s	
11402/29850 (epoch 19.099), train_loss = 0.90569583, grad/param norm = 1.7091e-01, time/batch = 16.8011s	
11403/29850 (epoch 19.101), train_loss = 1.17307514, grad/param norm = 1.9552e-01, time/batch = 19.4598s	
11404/29850 (epoch 19.102), train_loss = 1.13157817, grad/param norm = 1.9992e-01, time/batch = 16.7826s	
11405/29850 (epoch 19.104), train_loss = 1.05889404, grad/param norm = 1.8614e-01, time/batch = 19.5878s	
11406/29850 (epoch 19.106), train_loss = 1.15675683, grad/param norm = 1.9438e-01, time/batch = 18.8056s	
11407/29850 (epoch 19.107), train_loss = 0.91057528, grad/param norm = 1.5338e-01, time/batch = 17.7100s	
11408/29850 (epoch 19.109), train_loss = 1.04091471, grad/param norm = 1.9504e-01, time/batch = 19.1230s	
11409/29850 (epoch 19.111), train_loss = 1.17568573, grad/param norm = 1.8991e-01, time/batch = 18.7173s	
11410/29850 (epoch 19.112), train_loss = 0.98370182, grad/param norm = 1.7305e-01, time/batch = 18.0474s	
11411/29850 (epoch 19.114), train_loss = 1.08536836, grad/param norm = 2.2105e-01, time/batch = 17.0359s	
11412/29850 (epoch 19.116), train_loss = 0.98334309, grad/param norm = 1.6749e-01, time/batch = 16.2133s	
11413/29850 (epoch 19.117), train_loss = 1.09628581, grad/param norm = 1.9456e-01, time/batch = 16.1922s	
11414/29850 (epoch 19.119), train_loss = 1.05458349, grad/param norm = 1.8799e-01, time/batch = 17.0126s	
11415/29850 (epoch 19.121), train_loss = 0.86792273, grad/param norm = 1.7411e-01, time/batch = 15.7115s	
11416/29850 (epoch 19.122), train_loss = 0.92268400, grad/param norm = 1.6407e-01, time/batch = 17.7156s	
11417/29850 (epoch 19.124), train_loss = 0.98435163, grad/param norm = 1.8724e-01, time/batch = 19.4608s	
11418/29850 (epoch 19.126), train_loss = 1.02754567, grad/param norm = 1.8932e-01, time/batch = 18.8612s	
11419/29850 (epoch 19.127), train_loss = 1.14359216, grad/param norm = 1.9447e-01, time/batch = 18.2089s	
11420/29850 (epoch 19.129), train_loss = 1.02286748, grad/param norm = 1.9593e-01, time/batch = 17.6352s	
11421/29850 (epoch 19.131), train_loss = 1.02937161, grad/param norm = 1.8195e-01, time/batch = 16.6371s	
11422/29850 (epoch 19.132), train_loss = 0.94914306, grad/param norm = 2.0793e-01, time/batch = 18.3845s	
11423/29850 (epoch 19.134), train_loss = 1.07648858, grad/param norm = 1.9942e-01, time/batch = 18.6193s	
11424/29850 (epoch 19.136), train_loss = 1.08312792, grad/param norm = 1.8740e-01, time/batch = 16.1092s	
11425/29850 (epoch 19.137), train_loss = 0.89431936, grad/param norm = 1.7091e-01, time/batch = 19.3638s	
11426/29850 (epoch 19.139), train_loss = 0.99583186, grad/param norm = 1.9725e-01, time/batch = 17.1256s	
11427/29850 (epoch 19.141), train_loss = 1.00819488, grad/param norm = 1.8946e-01, time/batch = 18.4499s	
11428/29850 (epoch 19.142), train_loss = 1.16763982, grad/param norm = 1.9421e-01, time/batch = 18.0099s	
11429/29850 (epoch 19.144), train_loss = 1.32359682, grad/param norm = 2.2903e-01, time/batch = 16.9647s	
11430/29850 (epoch 19.146), train_loss = 1.32695708, grad/param norm = 2.3817e-01, time/batch = 17.5586s	
11431/29850 (epoch 19.147), train_loss = 1.14743555, grad/param norm = 2.0464e-01, time/batch = 17.1020s	
11432/29850 (epoch 19.149), train_loss = 1.14994964, grad/param norm = 2.0560e-01, time/batch = 16.2010s	
11433/29850 (epoch 19.151), train_loss = 1.12042877, grad/param norm = 1.9616e-01, time/batch = 17.7136s	
11434/29850 (epoch 19.152), train_loss = 1.01272278, grad/param norm = 1.8041e-01, time/batch = 18.0209s	
11435/29850 (epoch 19.154), train_loss = 1.00297661, grad/param norm = 1.8225e-01, time/batch = 19.1279s	
11436/29850 (epoch 19.156), train_loss = 0.99926696, grad/param norm = 1.7702e-01, time/batch = 16.3660s	
11437/29850 (epoch 19.157), train_loss = 1.08460608, grad/param norm = 1.8276e-01, time/batch = 17.6362s	
11438/29850 (epoch 19.159), train_loss = 1.03971497, grad/param norm = 1.6877e-01, time/batch = 17.3786s	
11439/29850 (epoch 19.161), train_loss = 1.10840576, grad/param norm = 1.9454e-01, time/batch = 18.7861s	
11440/29850 (epoch 19.162), train_loss = 1.21408526, grad/param norm = 2.0579e-01, time/batch = 18.7114s	
11441/29850 (epoch 19.164), train_loss = 1.05497620, grad/param norm = 1.8373e-01, time/batch = 16.8663s	
11442/29850 (epoch 19.166), train_loss = 0.96194566, grad/param norm = 1.6676e-01, time/batch = 18.1063s	
11443/29850 (epoch 19.168), train_loss = 0.89863054, grad/param norm = 1.7290e-01, time/batch = 18.7016s	
11444/29850 (epoch 19.169), train_loss = 1.22417710, grad/param norm = 2.0479e-01, time/batch = 17.8810s	
11445/29850 (epoch 19.171), train_loss = 1.13073537, grad/param norm = 1.9851e-01, time/batch = 15.6924s	
11446/29850 (epoch 19.173), train_loss = 1.00009147, grad/param norm = 1.9063e-01, time/batch = 17.1969s	
11447/29850 (epoch 19.174), train_loss = 1.14326088, grad/param norm = 2.2541e-01, time/batch = 18.2212s	
11448/29850 (epoch 19.176), train_loss = 1.10924666, grad/param norm = 1.9735e-01, time/batch = 15.0475s	
11449/29850 (epoch 19.178), train_loss = 1.14240889, grad/param norm = 2.0311e-01, time/batch = 15.3509s	
11450/29850 (epoch 19.179), train_loss = 0.92814545, grad/param norm = 1.7087e-01, time/batch = 17.8963s	
11451/29850 (epoch 19.181), train_loss = 1.07220286, grad/param norm = 2.0006e-01, time/batch = 17.8002s	
11452/29850 (epoch 19.183), train_loss = 1.05189104, grad/param norm = 1.8077e-01, time/batch = 18.7882s	
11453/29850 (epoch 19.184), train_loss = 1.07658513, grad/param norm = 1.8852e-01, time/batch = 16.7269s	
11454/29850 (epoch 19.186), train_loss = 1.08477925, grad/param norm = 1.9930e-01, time/batch = 18.8883s	
11455/29850 (epoch 19.188), train_loss = 1.17821685, grad/param norm = 2.1502e-01, time/batch = 17.1147s	
11456/29850 (epoch 19.189), train_loss = 1.21829188, grad/param norm = 2.0632e-01, time/batch = 18.4723s	
11457/29850 (epoch 19.191), train_loss = 1.14089063, grad/param norm = 2.0269e-01, time/batch = 19.1135s	
11458/29850 (epoch 19.193), train_loss = 1.02651018, grad/param norm = 1.8216e-01, time/batch = 16.3842s	
11459/29850 (epoch 19.194), train_loss = 1.11059365, grad/param norm = 1.9722e-01, time/batch = 18.2157s	
11460/29850 (epoch 19.196), train_loss = 1.01717363, grad/param norm = 1.8110e-01, time/batch = 16.3575s	
11461/29850 (epoch 19.198), train_loss = 1.07181864, grad/param norm = 1.9669e-01, time/batch = 17.8845s	
11462/29850 (epoch 19.199), train_loss = 1.31861689, grad/param norm = 2.2971e-01, time/batch = 16.7802s	
11463/29850 (epoch 19.201), train_loss = 0.99079572, grad/param norm = 2.0980e-01, time/batch = 18.1257s	
11464/29850 (epoch 19.203), train_loss = 0.86073350, grad/param norm = 1.8990e-01, time/batch = 19.0446s	
11465/29850 (epoch 19.204), train_loss = 1.12862588, grad/param norm = 2.1499e-01, time/batch = 16.1442s	
11466/29850 (epoch 19.206), train_loss = 0.95928244, grad/param norm = 1.9592e-01, time/batch = 16.1325s	
11467/29850 (epoch 19.208), train_loss = 1.22870982, grad/param norm = 1.9969e-01, time/batch = 17.0239s	
11468/29850 (epoch 19.209), train_loss = 0.96150667, grad/param norm = 1.8007e-01, time/batch = 18.7848s	
11469/29850 (epoch 19.211), train_loss = 1.03194655, grad/param norm = 1.8790e-01, time/batch = 16.8674s	
11470/29850 (epoch 19.213), train_loss = 1.15095118, grad/param norm = 1.9180e-01, time/batch = 16.6206s	
11471/29850 (epoch 19.214), train_loss = 0.96284904, grad/param norm = 1.7060e-01, time/batch = 18.9645s	
11472/29850 (epoch 19.216), train_loss = 1.00732390, grad/param norm = 1.9586e-01, time/batch = 16.2077s	
11473/29850 (epoch 19.218), train_loss = 1.14483301, grad/param norm = 1.9913e-01, time/batch = 18.4770s	
11474/29850 (epoch 19.219), train_loss = 1.19147776, grad/param norm = 2.1996e-01, time/batch = 16.2163s	
11475/29850 (epoch 19.221), train_loss = 1.06319994, grad/param norm = 1.9619e-01, time/batch = 18.3612s	
11476/29850 (epoch 19.223), train_loss = 0.99913591, grad/param norm = 1.8879e-01, time/batch = 17.8800s	
11477/29850 (epoch 19.224), train_loss = 0.92929997, grad/param norm = 1.8210e-01, time/batch = 17.7144s	
11478/29850 (epoch 19.226), train_loss = 0.97800202, grad/param norm = 1.7537e-01, time/batch = 17.3153s	
11479/29850 (epoch 19.228), train_loss = 1.04178481, grad/param norm = 1.8304e-01, time/batch = 28.2034s	
11480/29850 (epoch 19.229), train_loss = 0.90337703, grad/param norm = 1.5391e-01, time/batch = 15.6388s	
11481/29850 (epoch 19.231), train_loss = 1.04071425, grad/param norm = 1.7733e-01, time/batch = 17.7900s	
11482/29850 (epoch 19.233), train_loss = 1.02675874, grad/param norm = 1.9917e-01, time/batch = 17.7792s	
11483/29850 (epoch 19.235), train_loss = 0.96429671, grad/param norm = 1.6678e-01, time/batch = 16.9574s	
11484/29850 (epoch 19.236), train_loss = 1.21468626, grad/param norm = 2.0969e-01, time/batch = 19.0392s	
11485/29850 (epoch 19.238), train_loss = 0.92657127, grad/param norm = 1.7162e-01, time/batch = 17.3772s	
11486/29850 (epoch 19.240), train_loss = 0.95753141, grad/param norm = 1.7902e-01, time/batch = 18.1435s	
11487/29850 (epoch 19.241), train_loss = 1.12499397, grad/param norm = 1.9459e-01, time/batch = 16.7227s	
11488/29850 (epoch 19.243), train_loss = 1.10032630, grad/param norm = 2.0523e-01, time/batch = 17.8673s	
11489/29850 (epoch 19.245), train_loss = 1.02237449, grad/param norm = 2.0865e-01, time/batch = 17.0965s	
11490/29850 (epoch 19.246), train_loss = 0.94596192, grad/param norm = 1.7437e-01, time/batch = 19.8783s	
11491/29850 (epoch 19.248), train_loss = 0.92957644, grad/param norm = 1.7174e-01, time/batch = 19.1042s	
11492/29850 (epoch 19.250), train_loss = 1.02366977, grad/param norm = 1.7747e-01, time/batch = 16.9340s	
11493/29850 (epoch 19.251), train_loss = 0.90860005, grad/param norm = 1.9612e-01, time/batch = 19.4588s	
11494/29850 (epoch 19.253), train_loss = 0.86420279, grad/param norm = 1.8226e-01, time/batch = 15.7817s	
11495/29850 (epoch 19.255), train_loss = 0.94184028, grad/param norm = 1.7905e-01, time/batch = 16.0458s	
11496/29850 (epoch 19.256), train_loss = 1.09608546, grad/param norm = 2.0768e-01, time/batch = 17.9738s	
11497/29850 (epoch 19.258), train_loss = 1.05493627, grad/param norm = 1.8711e-01, time/batch = 17.2924s	
11498/29850 (epoch 19.260), train_loss = 1.03278982, grad/param norm = 1.7843e-01, time/batch = 17.6969s	
11499/29850 (epoch 19.261), train_loss = 0.96687842, grad/param norm = 1.9157e-01, time/batch = 16.6195s	
11500/29850 (epoch 19.263), train_loss = 0.95914970, grad/param norm = 1.9253e-01, time/batch = 16.9594s	
11501/29850 (epoch 19.265), train_loss = 1.01231548, grad/param norm = 1.7919e-01, time/batch = 19.3784s	
11502/29850 (epoch 19.266), train_loss = 1.03206639, grad/param norm = 1.9298e-01, time/batch = 17.2834s	
11503/29850 (epoch 19.268), train_loss = 0.98392137, grad/param norm = 1.6597e-01, time/batch = 18.0284s	
11504/29850 (epoch 19.270), train_loss = 0.95851843, grad/param norm = 1.6634e-01, time/batch = 18.7080s	
11505/29850 (epoch 19.271), train_loss = 1.12685542, grad/param norm = 1.8016e-01, time/batch = 17.5313s	
11506/29850 (epoch 19.273), train_loss = 0.90353373, grad/param norm = 1.8719e-01, time/batch = 18.1401s	
11507/29850 (epoch 19.275), train_loss = 0.88993925, grad/param norm = 1.7901e-01, time/batch = 19.6230s	
11508/29850 (epoch 19.276), train_loss = 0.92361638, grad/param norm = 1.7082e-01, time/batch = 17.6145s	
11509/29850 (epoch 19.278), train_loss = 0.98416062, grad/param norm = 1.7085e-01, time/batch = 17.9581s	
11510/29850 (epoch 19.280), train_loss = 1.20869193, grad/param norm = 2.4331e-01, time/batch = 15.7886s	
11511/29850 (epoch 19.281), train_loss = 1.08732329, grad/param norm = 1.9582e-01, time/batch = 19.4531s	
11512/29850 (epoch 19.283), train_loss = 1.21921943, grad/param norm = 2.2063e-01, time/batch = 15.6904s	
11513/29850 (epoch 19.285), train_loss = 1.04418212, grad/param norm = 2.0862e-01, time/batch = 17.0621s	
11514/29850 (epoch 19.286), train_loss = 1.14890937, grad/param norm = 2.1043e-01, time/batch = 16.6442s	
11515/29850 (epoch 19.288), train_loss = 1.19293635, grad/param norm = 2.4974e-01, time/batch = 14.4951s	
11516/29850 (epoch 19.290), train_loss = 1.04193373, grad/param norm = 2.0172e-01, time/batch = 16.2154s	
11517/29850 (epoch 19.291), train_loss = 1.28102201, grad/param norm = 2.0857e-01, time/batch = 16.6391s	
11518/29850 (epoch 19.293), train_loss = 1.13473439, grad/param norm = 2.0706e-01, time/batch = 17.8144s	
11519/29850 (epoch 19.295), train_loss = 1.21899534, grad/param norm = 2.0259e-01, time/batch = 17.7884s	
11520/29850 (epoch 19.296), train_loss = 0.96977569, grad/param norm = 2.1333e-01, time/batch = 19.2924s	
11521/29850 (epoch 19.298), train_loss = 0.85120933, grad/param norm = 1.7912e-01, time/batch = 17.6494s	
11522/29850 (epoch 19.300), train_loss = 0.93679593, grad/param norm = 1.7111e-01, time/batch = 16.2024s	
11523/29850 (epoch 19.302), train_loss = 0.90790239, grad/param norm = 1.7873e-01, time/batch = 19.5431s	
11524/29850 (epoch 19.303), train_loss = 0.96717945, grad/param norm = 1.9388e-01, time/batch = 17.1275s	
11525/29850 (epoch 19.305), train_loss = 1.09107127, grad/param norm = 1.8492e-01, time/batch = 19.1131s	
11526/29850 (epoch 19.307), train_loss = 1.13059901, grad/param norm = 1.8963e-01, time/batch = 18.0369s	
11527/29850 (epoch 19.308), train_loss = 1.00313010, grad/param norm = 1.8883e-01, time/batch = 19.0436s	
11528/29850 (epoch 19.310), train_loss = 1.08454513, grad/param norm = 1.9603e-01, time/batch = 18.4502s	
11529/29850 (epoch 19.312), train_loss = 1.13072637, grad/param norm = 1.9497e-01, time/batch = 16.1893s	
11530/29850 (epoch 19.313), train_loss = 1.03053497, grad/param norm = 1.8088e-01, time/batch = 16.8854s	
11531/29850 (epoch 19.315), train_loss = 1.06585666, grad/param norm = 1.8939e-01, time/batch = 17.1478s	
11532/29850 (epoch 19.317), train_loss = 1.07373828, grad/param norm = 2.0190e-01, time/batch = 17.3032s	
11533/29850 (epoch 19.318), train_loss = 1.06351429, grad/param norm = 1.9708e-01, time/batch = 16.7120s	
11534/29850 (epoch 19.320), train_loss = 0.97801286, grad/param norm = 1.6559e-01, time/batch = 17.4568s	
11535/29850 (epoch 19.322), train_loss = 1.20955314, grad/param norm = 2.0574e-01, time/batch = 18.2792s	
11536/29850 (epoch 19.323), train_loss = 1.13588237, grad/param norm = 2.1455e-01, time/batch = 16.7824s	
11537/29850 (epoch 19.325), train_loss = 1.14167024, grad/param norm = 1.9934e-01, time/batch = 19.8717s	
11538/29850 (epoch 19.327), train_loss = 1.25633323, grad/param norm = 2.1339e-01, time/batch = 19.2928s	
11539/29850 (epoch 19.328), train_loss = 1.22948872, grad/param norm = 2.2313e-01, time/batch = 16.0179s	
11540/29850 (epoch 19.330), train_loss = 1.10678799, grad/param norm = 1.9297e-01, time/batch = 19.0440s	
11541/29850 (epoch 19.332), train_loss = 1.02585706, grad/param norm = 1.7928e-01, time/batch = 19.2032s	
11542/29850 (epoch 19.333), train_loss = 1.20150699, grad/param norm = 2.1512e-01, time/batch = 18.0956s	
11543/29850 (epoch 19.335), train_loss = 1.17502130, grad/param norm = 2.0414e-01, time/batch = 16.2298s	
11544/29850 (epoch 19.337), train_loss = 1.08193189, grad/param norm = 1.8760e-01, time/batch = 20.1899s	
11545/29850 (epoch 19.338), train_loss = 1.07743896, grad/param norm = 1.8307e-01, time/batch = 18.5422s	
11546/29850 (epoch 19.340), train_loss = 0.96364377, grad/param norm = 1.8233e-01, time/batch = 16.1414s	
11547/29850 (epoch 19.342), train_loss = 1.07410557, grad/param norm = 2.0516e-01, time/batch = 17.8805s	
11548/29850 (epoch 19.343), train_loss = 1.11842841, grad/param norm = 2.3948e-01, time/batch = 18.1956s	
11549/29850 (epoch 19.345), train_loss = 1.14208611, grad/param norm = 2.5017e-01, time/batch = 16.8630s	
11550/29850 (epoch 19.347), train_loss = 1.16426633, grad/param norm = 2.0315e-01, time/batch = 15.6304s	
11551/29850 (epoch 19.348), train_loss = 1.03226481, grad/param norm = 1.8912e-01, time/batch = 18.5446s	
11552/29850 (epoch 19.350), train_loss = 1.14157507, grad/param norm = 2.1241e-01, time/batch = 18.2957s	
11553/29850 (epoch 19.352), train_loss = 1.02494026, grad/param norm = 1.8210e-01, time/batch = 15.5284s	
11554/29850 (epoch 19.353), train_loss = 1.12866671, grad/param norm = 1.9574e-01, time/batch = 18.1351s	
11555/29850 (epoch 19.355), train_loss = 0.97573048, grad/param norm = 1.8132e-01, time/batch = 19.3768s	
11556/29850 (epoch 19.357), train_loss = 1.20639629, grad/param norm = 1.9855e-01, time/batch = 15.1976s	
11557/29850 (epoch 19.358), train_loss = 0.98806610, grad/param norm = 1.7991e-01, time/batch = 16.1357s	
11558/29850 (epoch 19.360), train_loss = 1.05514129, grad/param norm = 1.9173e-01, time/batch = 18.0464s	
11559/29850 (epoch 19.362), train_loss = 1.06359180, grad/param norm = 1.9166e-01, time/batch = 17.9641s	
11560/29850 (epoch 19.363), train_loss = 1.09387976, grad/param norm = 1.9462e-01, time/batch = 17.3522s	
11561/29850 (epoch 19.365), train_loss = 1.22018933, grad/param norm = 2.0086e-01, time/batch = 19.0447s	
11562/29850 (epoch 19.367), train_loss = 1.01261239, grad/param norm = 1.8399e-01, time/batch = 18.5490s	
11563/29850 (epoch 19.369), train_loss = 0.93468501, grad/param norm = 1.7474e-01, time/batch = 17.1680s	
11564/29850 (epoch 19.370), train_loss = 0.87730136, grad/param norm = 1.9219e-01, time/batch = 17.1368s	
11565/29850 (epoch 19.372), train_loss = 1.16541629, grad/param norm = 2.1008e-01, time/batch = 15.3895s	
11566/29850 (epoch 19.374), train_loss = 1.10682692, grad/param norm = 1.9933e-01, time/batch = 17.0467s	
11567/29850 (epoch 19.375), train_loss = 1.07420708, grad/param norm = 1.8544e-01, time/batch = 17.2971s	
11568/29850 (epoch 19.377), train_loss = 1.04150636, grad/param norm = 2.0016e-01, time/batch = 17.3791s	
11569/29850 (epoch 19.379), train_loss = 1.17481974, grad/param norm = 2.1294e-01, time/batch = 17.4775s	
11570/29850 (epoch 19.380), train_loss = 1.11843849, grad/param norm = 1.8989e-01, time/batch = 17.2074s	
11571/29850 (epoch 19.382), train_loss = 1.10882303, grad/param norm = 2.0098e-01, time/batch = 16.3780s	
11572/29850 (epoch 19.384), train_loss = 1.13552823, grad/param norm = 2.0661e-01, time/batch = 18.8482s	
11573/29850 (epoch 19.385), train_loss = 1.07382939, grad/param norm = 1.9589e-01, time/batch = 17.2784s	
11574/29850 (epoch 19.387), train_loss = 1.11997068, grad/param norm = 1.9538e-01, time/batch = 17.5484s	
11575/29850 (epoch 19.389), train_loss = 1.23878148, grad/param norm = 2.3078e-01, time/batch = 17.9613s	
11576/29850 (epoch 19.390), train_loss = 1.12823460, grad/param norm = 1.9091e-01, time/batch = 17.9464s	
11577/29850 (epoch 19.392), train_loss = 1.08028529, grad/param norm = 2.2725e-01, time/batch = 16.5595s	
11578/29850 (epoch 19.394), train_loss = 1.16628726, grad/param norm = 1.9298e-01, time/batch = 17.9809s	
11579/29850 (epoch 19.395), train_loss = 1.04180896, grad/param norm = 2.0527e-01, time/batch = 17.1371s	
11580/29850 (epoch 19.397), train_loss = 0.96480340, grad/param norm = 1.9035e-01, time/batch = 15.9361s	
11581/29850 (epoch 19.399), train_loss = 0.97850824, grad/param norm = 1.7098e-01, time/batch = 18.8780s	
11582/29850 (epoch 19.400), train_loss = 1.36178578, grad/param norm = 2.1120e-01, time/batch = 17.1232s	
11583/29850 (epoch 19.402), train_loss = 1.24965599, grad/param norm = 1.8373e-01, time/batch = 17.7962s	
11584/29850 (epoch 19.404), train_loss = 1.10678498, grad/param norm = 1.8592e-01, time/batch = 15.7138s	
11585/29850 (epoch 19.405), train_loss = 1.01464997, grad/param norm = 1.9831e-01, time/batch = 17.6313s	
11586/29850 (epoch 19.407), train_loss = 0.99924914, grad/param norm = 1.8996e-01, time/batch = 18.0578s	
11587/29850 (epoch 19.409), train_loss = 1.14062799, grad/param norm = 1.9414e-01, time/batch = 16.2094s	
11588/29850 (epoch 19.410), train_loss = 1.23082659, grad/param norm = 2.0110e-01, time/batch = 17.4428s	
11589/29850 (epoch 19.412), train_loss = 1.17371970, grad/param norm = 1.9443e-01, time/batch = 18.7991s	
11590/29850 (epoch 19.414), train_loss = 1.08724830, grad/param norm = 2.1941e-01, time/batch = 16.8000s	
11591/29850 (epoch 19.415), train_loss = 1.09167526, grad/param norm = 1.9320e-01, time/batch = 17.1996s	
11592/29850 (epoch 19.417), train_loss = 1.24066092, grad/param norm = 2.1899e-01, time/batch = 18.7062s	
11593/29850 (epoch 19.419), train_loss = 1.08074918, grad/param norm = 2.1015e-01, time/batch = 18.1966s	
11594/29850 (epoch 19.420), train_loss = 1.08385399, grad/param norm = 1.8771e-01, time/batch = 15.5260s	
11595/29850 (epoch 19.422), train_loss = 1.06381176, grad/param norm = 2.0336e-01, time/batch = 16.0206s	
11596/29850 (epoch 19.424), train_loss = 1.02295621, grad/param norm = 1.7916e-01, time/batch = 19.1339s	
11597/29850 (epoch 19.425), train_loss = 1.19751834, grad/param norm = 1.9364e-01, time/batch = 17.0309s	
11598/29850 (epoch 19.427), train_loss = 0.88744760, grad/param norm = 1.6177e-01, time/batch = 18.6053s	
11599/29850 (epoch 19.429), train_loss = 0.97690396, grad/param norm = 1.9937e-01, time/batch = 17.1440s	
11600/29850 (epoch 19.430), train_loss = 0.88977590, grad/param norm = 1.6532e-01, time/batch = 18.2036s	
11601/29850 (epoch 19.432), train_loss = 1.03605832, grad/param norm = 2.0593e-01, time/batch = 16.8717s	
11602/29850 (epoch 19.434), train_loss = 0.93717617, grad/param norm = 1.7157e-01, time/batch = 18.6274s	
11603/29850 (epoch 19.436), train_loss = 1.07980063, grad/param norm = 1.9296e-01, time/batch = 18.3594s	
11604/29850 (epoch 19.437), train_loss = 1.13054503, grad/param norm = 1.8630e-01, time/batch = 17.6272s	
11605/29850 (epoch 19.439), train_loss = 1.10156225, grad/param norm = 1.9656e-01, time/batch = 18.3715s	
11606/29850 (epoch 19.441), train_loss = 1.09139621, grad/param norm = 2.0450e-01, time/batch = 16.4701s	
11607/29850 (epoch 19.442), train_loss = 1.10394913, grad/param norm = 1.9900e-01, time/batch = 17.3635s	
11608/29850 (epoch 19.444), train_loss = 1.09501882, grad/param norm = 1.9965e-01, time/batch = 16.4542s	
11609/29850 (epoch 19.446), train_loss = 1.13252591, grad/param norm = 1.8754e-01, time/batch = 17.9768s	
11610/29850 (epoch 19.447), train_loss = 1.13230673, grad/param norm = 1.9959e-01, time/batch = 17.8026s	
11611/29850 (epoch 19.449), train_loss = 1.10682483, grad/param norm = 2.0604e-01, time/batch = 16.0439s	
11612/29850 (epoch 19.451), train_loss = 0.90760975, grad/param norm = 1.7706e-01, time/batch = 18.5316s	
11613/29850 (epoch 19.452), train_loss = 0.81654594, grad/param norm = 1.5767e-01, time/batch = 19.3874s	
11614/29850 (epoch 19.454), train_loss = 0.94333384, grad/param norm = 1.7450e-01, time/batch = 16.2145s	
11615/29850 (epoch 19.456), train_loss = 1.12046787, grad/param norm = 2.0632e-01, time/batch = 16.9711s	
11616/29850 (epoch 19.457), train_loss = 1.12403003, grad/param norm = 2.3044e-01, time/batch = 18.2985s	
11617/29850 (epoch 19.459), train_loss = 1.25782167, grad/param norm = 2.3014e-01, time/batch = 17.6198s	
11618/29850 (epoch 19.461), train_loss = 1.23168310, grad/param norm = 1.8435e-01, time/batch = 16.7849s	
11619/29850 (epoch 19.462), train_loss = 1.19849563, grad/param norm = 2.0279e-01, time/batch = 15.7895s	
11620/29850 (epoch 19.464), train_loss = 1.14438553, grad/param norm = 1.9956e-01, time/batch = 19.0517s	
11621/29850 (epoch 19.466), train_loss = 0.96685103, grad/param norm = 1.9788e-01, time/batch = 17.0347s	
11622/29850 (epoch 19.467), train_loss = 1.06177098, grad/param norm = 1.9321e-01, time/batch = 17.3871s	
11623/29850 (epoch 19.469), train_loss = 1.04912759, grad/param norm = 1.9027e-01, time/batch = 19.0445s	
11624/29850 (epoch 19.471), train_loss = 1.07195462, grad/param norm = 2.0307e-01, time/batch = 17.2001s	
11625/29850 (epoch 19.472), train_loss = 1.01201300, grad/param norm = 1.7788e-01, time/batch = 16.8015s	
11626/29850 (epoch 19.474), train_loss = 1.19256924, grad/param norm = 1.8833e-01, time/batch = 20.1107s	
11627/29850 (epoch 19.476), train_loss = 1.10126923, grad/param norm = 1.8546e-01, time/batch = 16.3482s	
11628/29850 (epoch 19.477), train_loss = 1.10836077, grad/param norm = 2.2258e-01, time/batch = 17.4650s	
11629/29850 (epoch 19.479), train_loss = 1.24408068, grad/param norm = 2.1500e-01, time/batch = 19.0352s	
11630/29850 (epoch 19.481), train_loss = 1.08793657, grad/param norm = 1.9997e-01, time/batch = 17.8867s	
11631/29850 (epoch 19.482), train_loss = 0.99892608, grad/param norm = 1.6880e-01, time/batch = 16.7076s	
11632/29850 (epoch 19.484), train_loss = 1.00403607, grad/param norm = 1.8387e-01, time/batch = 17.2278s	
11633/29850 (epoch 19.486), train_loss = 1.11378523, grad/param norm = 2.0020e-01, time/batch = 16.8778s	
11634/29850 (epoch 19.487), train_loss = 1.05663375, grad/param norm = 1.9856e-01, time/batch = 16.4627s	
11635/29850 (epoch 19.489), train_loss = 1.06747489, grad/param norm = 2.0208e-01, time/batch = 17.3782s	
11636/29850 (epoch 19.491), train_loss = 0.96651374, grad/param norm = 1.6926e-01, time/batch = 16.2126s	
11637/29850 (epoch 19.492), train_loss = 1.07789178, grad/param norm = 1.9194e-01, time/batch = 18.8693s	
11638/29850 (epoch 19.494), train_loss = 1.19056196, grad/param norm = 1.8894e-01, time/batch = 16.0482s	
11639/29850 (epoch 19.496), train_loss = 1.22552319, grad/param norm = 1.8949e-01, time/batch = 19.3753s	
11640/29850 (epoch 19.497), train_loss = 1.12822734, grad/param norm = 1.7951e-01, time/batch = 18.3822s	
11641/29850 (epoch 19.499), train_loss = 1.07109754, grad/param norm = 1.7416e-01, time/batch = 16.8569s	
11642/29850 (epoch 19.501), train_loss = 1.01928520, grad/param norm = 1.9467e-01, time/batch = 18.0965s	
11643/29850 (epoch 19.503), train_loss = 1.08027702, grad/param norm = 1.8913e-01, time/batch = 18.0982s	
11644/29850 (epoch 19.504), train_loss = 1.31648439, grad/param norm = 2.0153e-01, time/batch = 18.4550s	
11645/29850 (epoch 19.506), train_loss = 1.24623026, grad/param norm = 2.1279e-01, time/batch = 17.5343s	
11646/29850 (epoch 19.508), train_loss = 1.08701719, grad/param norm = 1.8734e-01, time/batch = 17.3746s	
11647/29850 (epoch 19.509), train_loss = 0.88843690, grad/param norm = 1.8854e-01, time/batch = 18.5372s	
11648/29850 (epoch 19.511), train_loss = 1.08805186, grad/param norm = 1.9917e-01, time/batch = 15.3753s	
11649/29850 (epoch 19.513), train_loss = 1.11546722, grad/param norm = 2.1480e-01, time/batch = 16.9653s	
11650/29850 (epoch 19.514), train_loss = 0.96869723, grad/param norm = 1.9231e-01, time/batch = 16.7016s	
11651/29850 (epoch 19.516), train_loss = 1.00568519, grad/param norm = 1.7004e-01, time/batch = 16.7163s	
11652/29850 (epoch 19.518), train_loss = 0.92835260, grad/param norm = 1.8978e-01, time/batch = 18.2805s	
11653/29850 (epoch 19.519), train_loss = 0.90823958, grad/param norm = 1.6584e-01, time/batch = 16.6300s	
11654/29850 (epoch 19.521), train_loss = 0.89626803, grad/param norm = 1.7097e-01, time/batch = 17.0597s	
11655/29850 (epoch 19.523), train_loss = 0.92074535, grad/param norm = 1.6332e-01, time/batch = 17.0555s	
11656/29850 (epoch 19.524), train_loss = 1.01103736, grad/param norm = 1.9254e-01, time/batch = 18.6311s	
11657/29850 (epoch 19.526), train_loss = 1.09487721, grad/param norm = 2.3982e-01, time/batch = 17.9502s	
11658/29850 (epoch 19.528), train_loss = 1.18702441, grad/param norm = 2.0725e-01, time/batch = 17.1926s	
11659/29850 (epoch 19.529), train_loss = 1.10280401, grad/param norm = 1.9499e-01, time/batch = 18.0459s	
11660/29850 (epoch 19.531), train_loss = 1.04735409, grad/param norm = 1.9907e-01, time/batch = 16.6235s	
11661/29850 (epoch 19.533), train_loss = 1.03005754, grad/param norm = 1.8268e-01, time/batch = 19.1209s	
11662/29850 (epoch 19.534), train_loss = 1.08201115, grad/param norm = 1.8218e-01, time/batch = 18.1200s	
11663/29850 (epoch 19.536), train_loss = 1.02815304, grad/param norm = 2.0313e-01, time/batch = 17.6294s	
11664/29850 (epoch 19.538), train_loss = 1.19018434, grad/param norm = 2.2162e-01, time/batch = 19.4791s	
11665/29850 (epoch 19.539), train_loss = 1.24820050, grad/param norm = 2.1917e-01, time/batch = 15.6358s	
11666/29850 (epoch 19.541), train_loss = 0.87018530, grad/param norm = 1.7123e-01, time/batch = 17.0407s	
11667/29850 (epoch 19.543), train_loss = 1.06333165, grad/param norm = 1.8099e-01, time/batch = 18.6283s	
11668/29850 (epoch 19.544), train_loss = 1.11103298, grad/param norm = 1.8516e-01, time/batch = 16.9665s	
11669/29850 (epoch 19.546), train_loss = 1.17193568, grad/param norm = 1.9799e-01, time/batch = 16.7141s	
11670/29850 (epoch 19.548), train_loss = 0.92182081, grad/param norm = 1.6973e-01, time/batch = 18.3629s	
11671/29850 (epoch 19.549), train_loss = 1.02954371, grad/param norm = 1.9067e-01, time/batch = 19.1209s	
11672/29850 (epoch 19.551), train_loss = 0.94661821, grad/param norm = 1.6925e-01, time/batch = 15.5361s	
11673/29850 (epoch 19.553), train_loss = 1.05940562, grad/param norm = 1.8497e-01, time/batch = 16.9566s	
11674/29850 (epoch 19.554), train_loss = 0.92925880, grad/param norm = 1.8066e-01, time/batch = 17.3748s	
11675/29850 (epoch 19.556), train_loss = 0.99921119, grad/param norm = 1.8892e-01, time/batch = 18.2916s	
11676/29850 (epoch 19.558), train_loss = 0.98018204, grad/param norm = 1.7923e-01, time/batch = 17.7094s	
11677/29850 (epoch 19.559), train_loss = 1.03615732, grad/param norm = 1.7610e-01, time/batch = 16.1973s	
11678/29850 (epoch 19.561), train_loss = 1.12362201, grad/param norm = 1.9954e-01, time/batch = 18.4431s	
11679/29850 (epoch 19.563), train_loss = 1.07300902, grad/param norm = 1.8682e-01, time/batch = 16.6939s	
11680/29850 (epoch 19.564), train_loss = 1.04893594, grad/param norm = 1.9596e-01, time/batch = 19.4610s	
11681/29850 (epoch 19.566), train_loss = 1.08097847, grad/param norm = 2.0034e-01, time/batch = 19.2821s	
11682/29850 (epoch 19.568), train_loss = 1.17927786, grad/param norm = 1.9244e-01, time/batch = 29.3902s	
11683/29850 (epoch 19.570), train_loss = 1.09676583, grad/param norm = 1.9437e-01, time/batch = 18.3668s	
11684/29850 (epoch 19.571), train_loss = 1.15293723, grad/param norm = 2.0227e-01, time/batch = 17.1294s	
11685/29850 (epoch 19.573), train_loss = 1.23146426, grad/param norm = 2.3990e-01, time/batch = 17.4590s	
11686/29850 (epoch 19.575), train_loss = 1.19465121, grad/param norm = 1.8911e-01, time/batch = 16.4604s	
11687/29850 (epoch 19.576), train_loss = 1.17283677, grad/param norm = 1.9344e-01, time/batch = 18.9627s	
11688/29850 (epoch 19.578), train_loss = 1.03020026, grad/param norm = 1.8849e-01, time/batch = 15.4014s	
11689/29850 (epoch 19.580), train_loss = 1.20194291, grad/param norm = 1.8878e-01, time/batch = 16.5611s	
11690/29850 (epoch 19.581), train_loss = 0.99162964, grad/param norm = 1.8582e-01, time/batch = 17.3769s	
11691/29850 (epoch 19.583), train_loss = 1.05892864, grad/param norm = 1.9055e-01, time/batch = 17.0444s	
11692/29850 (epoch 19.585), train_loss = 1.11196122, grad/param norm = 1.9663e-01, time/batch = 18.3735s	
11693/29850 (epoch 19.586), train_loss = 1.11788890, grad/param norm = 2.0130e-01, time/batch = 16.2883s	
11694/29850 (epoch 19.588), train_loss = 1.04140765, grad/param norm = 2.1039e-01, time/batch = 18.8881s	
11695/29850 (epoch 19.590), train_loss = 1.05420360, grad/param norm = 1.9632e-01, time/batch = 17.4452s	
11696/29850 (epoch 19.591), train_loss = 1.00845608, grad/param norm = 1.8645e-01, time/batch = 17.7190s	
11697/29850 (epoch 19.593), train_loss = 0.99637895, grad/param norm = 1.7650e-01, time/batch = 16.9838s	
11698/29850 (epoch 19.595), train_loss = 0.93890671, grad/param norm = 1.5835e-01, time/batch = 17.5996s	
11699/29850 (epoch 19.596), train_loss = 0.93134898, grad/param norm = 1.7669e-01, time/batch = 16.7066s	
11700/29850 (epoch 19.598), train_loss = 1.01571391, grad/param norm = 1.6940e-01, time/batch = 17.5352s	
11701/29850 (epoch 19.600), train_loss = 1.12657438, grad/param norm = 1.9818e-01, time/batch = 17.8816s	
11702/29850 (epoch 19.601), train_loss = 0.94090820, grad/param norm = 1.7345e-01, time/batch = 16.2911s	
11703/29850 (epoch 19.603), train_loss = 1.01404911, grad/param norm = 1.8321e-01, time/batch = 16.3749s	
11704/29850 (epoch 19.605), train_loss = 1.04018933, grad/param norm = 1.9841e-01, time/batch = 19.3674s	
11705/29850 (epoch 19.606), train_loss = 0.81273001, grad/param norm = 1.5811e-01, time/batch = 16.4344s	
11706/29850 (epoch 19.608), train_loss = 1.01032482, grad/param norm = 1.8463e-01, time/batch = 19.7020s	
11707/29850 (epoch 19.610), train_loss = 1.05781051, grad/param norm = 1.8693e-01, time/batch = 18.6023s	
11708/29850 (epoch 19.611), train_loss = 0.95966857, grad/param norm = 1.7360e-01, time/batch = 18.3682s	
11709/29850 (epoch 19.613), train_loss = 0.81534650, grad/param norm = 1.6115e-01, time/batch = 17.3940s	
11710/29850 (epoch 19.615), train_loss = 0.93398439, grad/param norm = 1.6342e-01, time/batch = 17.3852s	
11711/29850 (epoch 19.616), train_loss = 0.92521086, grad/param norm = 1.8469e-01, time/batch = 18.9627s	
11712/29850 (epoch 19.618), train_loss = 1.00185323, grad/param norm = 1.7304e-01, time/batch = 18.0992s	
11713/29850 (epoch 19.620), train_loss = 1.09606531, grad/param norm = 1.9466e-01, time/batch = 17.7131s	
11714/29850 (epoch 19.621), train_loss = 1.19043942, grad/param norm = 2.0037e-01, time/batch = 19.4506s	
11715/29850 (epoch 19.623), train_loss = 1.11611380, grad/param norm = 1.8525e-01, time/batch = 15.3915s	
11716/29850 (epoch 19.625), train_loss = 1.08830522, grad/param norm = 2.1651e-01, time/batch = 17.6403s	
11717/29850 (epoch 19.626), train_loss = 1.09778577, grad/param norm = 1.9430e-01, time/batch = 17.0514s	
11718/29850 (epoch 19.628), train_loss = 0.95997452, grad/param norm = 1.6940e-01, time/batch = 18.2872s	
11719/29850 (epoch 19.630), train_loss = 1.05415406, grad/param norm = 1.8932e-01, time/batch = 19.0228s	
11720/29850 (epoch 19.631), train_loss = 1.01996740, grad/param norm = 1.8260e-01, time/batch = 16.4452s	
11721/29850 (epoch 19.633), train_loss = 1.13233935, grad/param norm = 2.1182e-01, time/batch = 17.5513s	
11722/29850 (epoch 19.635), train_loss = 1.02690839, grad/param norm = 1.9548e-01, time/batch = 15.3752s	
11723/29850 (epoch 19.637), train_loss = 0.96509719, grad/param norm = 1.8573e-01, time/batch = 16.7696s	
11724/29850 (epoch 19.638), train_loss = 1.06759870, grad/param norm = 2.0525e-01, time/batch = 19.0539s	
11725/29850 (epoch 19.640), train_loss = 1.19649893, grad/param norm = 2.0811e-01, time/batch = 17.0431s	
11726/29850 (epoch 19.642), train_loss = 1.00284611, grad/param norm = 1.7847e-01, time/batch = 19.3791s	
11727/29850 (epoch 19.643), train_loss = 0.96389127, grad/param norm = 1.8606e-01, time/batch = 17.5586s	
11728/29850 (epoch 19.645), train_loss = 1.04257208, grad/param norm = 1.8709e-01, time/batch = 17.3421s	
11729/29850 (epoch 19.647), train_loss = 1.17120998, grad/param norm = 1.8574e-01, time/batch = 16.9565s	
11730/29850 (epoch 19.648), train_loss = 0.93197229, grad/param norm = 1.6941e-01, time/batch = 18.1468s	
11731/29850 (epoch 19.650), train_loss = 1.07002003, grad/param norm = 1.8727e-01, time/batch = 17.8060s	
11732/29850 (epoch 19.652), train_loss = 1.08366567, grad/param norm = 1.8522e-01, time/batch = 15.9489s	
11733/29850 (epoch 19.653), train_loss = 1.15832359, grad/param norm = 2.0576e-01, time/batch = 18.6987s	
11734/29850 (epoch 19.655), train_loss = 1.03858750, grad/param norm = 1.7370e-01, time/batch = 18.1313s	
11735/29850 (epoch 19.657), train_loss = 0.99306885, grad/param norm = 1.8312e-01, time/batch = 18.5244s	
11736/29850 (epoch 19.658), train_loss = 1.15442097, grad/param norm = 1.9150e-01, time/batch = 17.6172s	
11737/29850 (epoch 19.660), train_loss = 1.05417574, grad/param norm = 1.9065e-01, time/batch = 18.2897s	
11738/29850 (epoch 19.662), train_loss = 1.11930026, grad/param norm = 2.0506e-01, time/batch = 17.9608s	
11739/29850 (epoch 19.663), train_loss = 1.24462107, grad/param norm = 2.0047e-01, time/batch = 16.4534s	
11740/29850 (epoch 19.665), train_loss = 1.16625741, grad/param norm = 1.9515e-01, time/batch = 18.1149s	
11741/29850 (epoch 19.667), train_loss = 1.11640187, grad/param norm = 2.3083e-01, time/batch = 19.4633s	
11742/29850 (epoch 19.668), train_loss = 1.05549794, grad/param norm = 2.1396e-01, time/batch = 16.3116s	
11743/29850 (epoch 19.670), train_loss = 1.23937138, grad/param norm = 2.6304e-01, time/batch = 17.7928s	
11744/29850 (epoch 19.672), train_loss = 1.17992554, grad/param norm = 2.0145e-01, time/batch = 19.7804s	
11745/29850 (epoch 19.673), train_loss = 1.14706619, grad/param norm = 2.0644e-01, time/batch = 17.6878s	
11746/29850 (epoch 19.675), train_loss = 0.97107887, grad/param norm = 2.0210e-01, time/batch = 17.1210s	
11747/29850 (epoch 19.677), train_loss = 1.04231029, grad/param norm = 2.1799e-01, time/batch = 17.1344s	
11748/29850 (epoch 19.678), train_loss = 1.03117439, grad/param norm = 1.9164e-01, time/batch = 17.3837s	
11749/29850 (epoch 19.680), train_loss = 1.07897959, grad/param norm = 2.0760e-01, time/batch = 15.7742s	
11750/29850 (epoch 19.682), train_loss = 1.07553418, grad/param norm = 2.2123e-01, time/batch = 18.3729s	
11751/29850 (epoch 19.683), train_loss = 1.19919212, grad/param norm = 2.0816e-01, time/batch = 17.8013s	
11752/29850 (epoch 19.685), train_loss = 1.20651512, grad/param norm = 1.9175e-01, time/batch = 18.0426s	
11753/29850 (epoch 19.687), train_loss = 1.12529046, grad/param norm = 2.0363e-01, time/batch = 17.2774s	
11754/29850 (epoch 19.688), train_loss = 0.94599285, grad/param norm = 1.9124e-01, time/batch = 17.9654s	
11755/29850 (epoch 19.690), train_loss = 0.94446130, grad/param norm = 1.9106e-01, time/batch = 18.3907s	
11756/29850 (epoch 19.692), train_loss = 1.16205251, grad/param norm = 2.0057e-01, time/batch = 18.6314s	
11757/29850 (epoch 19.693), train_loss = 1.04486551, grad/param norm = 1.6954e-01, time/batch = 16.8836s	
11758/29850 (epoch 19.695), train_loss = 0.94535579, grad/param norm = 1.7434e-01, time/batch = 18.1274s	
11759/29850 (epoch 19.697), train_loss = 1.04921492, grad/param norm = 1.8823e-01, time/batch = 17.8791s	
11760/29850 (epoch 19.698), train_loss = 1.16901622, grad/param norm = 1.8829e-01, time/batch = 18.6275s	
11761/29850 (epoch 19.700), train_loss = 1.13142026, grad/param norm = 2.0833e-01, time/batch = 18.1208s	
11762/29850 (epoch 19.702), train_loss = 1.03205658, grad/param norm = 1.8512e-01, time/batch = 17.0338s	
11763/29850 (epoch 19.704), train_loss = 0.94819776, grad/param norm = 1.7047e-01, time/batch = 18.1233s	
11764/29850 (epoch 19.705), train_loss = 1.06275142, grad/param norm = 1.8810e-01, time/batch = 18.9656s	
11765/29850 (epoch 19.707), train_loss = 0.98681774, grad/param norm = 1.8180e-01, time/batch = 17.9719s	
11766/29850 (epoch 19.709), train_loss = 1.07345811, grad/param norm = 1.7729e-01, time/batch = 18.3686s	
11767/29850 (epoch 19.710), train_loss = 0.99543828, grad/param norm = 1.8851e-01, time/batch = 15.1251s	
11768/29850 (epoch 19.712), train_loss = 1.05920045, grad/param norm = 1.6753e-01, time/batch = 17.2195s	
11769/29850 (epoch 19.714), train_loss = 1.15260624, grad/param norm = 1.9590e-01, time/batch = 16.1369s	
11770/29850 (epoch 19.715), train_loss = 1.09512825, grad/param norm = 1.8920e-01, time/batch = 17.0408s	
11771/29850 (epoch 19.717), train_loss = 0.84679806, grad/param norm = 1.7853e-01, time/batch = 17.1306s	
11772/29850 (epoch 19.719), train_loss = 0.98791472, grad/param norm = 1.8327e-01, time/batch = 17.6313s	
11773/29850 (epoch 19.720), train_loss = 1.04499430, grad/param norm = 1.6816e-01, time/batch = 18.5449s	
11774/29850 (epoch 19.722), train_loss = 0.98217569, grad/param norm = 1.5777e-01, time/batch = 18.6311s	
11775/29850 (epoch 19.724), train_loss = 1.11665519, grad/param norm = 2.0374e-01, time/batch = 17.1048s	
11776/29850 (epoch 19.725), train_loss = 0.93333669, grad/param norm = 1.8006e-01, time/batch = 16.6313s	
11777/29850 (epoch 19.727), train_loss = 0.99001840, grad/param norm = 1.8887e-01, time/batch = 18.7998s	
11778/29850 (epoch 19.729), train_loss = 0.90411442, grad/param norm = 1.5559e-01, time/batch = 18.0243s	
11779/29850 (epoch 19.730), train_loss = 0.90913705, grad/param norm = 1.7803e-01, time/batch = 17.5469s	
11780/29850 (epoch 19.732), train_loss = 1.14896540, grad/param norm = 1.7800e-01, time/batch = 18.2935s	
11781/29850 (epoch 19.734), train_loss = 1.22668524, grad/param norm = 2.1247e-01, time/batch = 18.8939s	
11782/29850 (epoch 19.735), train_loss = 1.03026039, grad/param norm = 2.0083e-01, time/batch = 18.0380s	
11783/29850 (epoch 19.737), train_loss = 0.96761695, grad/param norm = 1.9899e-01, time/batch = 16.2653s	
11784/29850 (epoch 19.739), train_loss = 0.86759137, grad/param norm = 1.9649e-01, time/batch = 15.4545s	
11785/29850 (epoch 19.740), train_loss = 0.92418015, grad/param norm = 1.7901e-01, time/batch = 17.3096s	
11786/29850 (epoch 19.742), train_loss = 0.90344976, grad/param norm = 1.7486e-01, time/batch = 15.8144s	
11787/29850 (epoch 19.744), train_loss = 0.99971508, grad/param norm = 2.0838e-01, time/batch = 16.6243s	
11788/29850 (epoch 19.745), train_loss = 0.97752884, grad/param norm = 2.0335e-01, time/batch = 17.5421s	
11789/29850 (epoch 19.747), train_loss = 1.01781986, grad/param norm = 1.8906e-01, time/batch = 18.7170s	
11790/29850 (epoch 19.749), train_loss = 0.94562699, grad/param norm = 2.0172e-01, time/batch = 17.5351s	
11791/29850 (epoch 19.750), train_loss = 0.90711597, grad/param norm = 1.7704e-01, time/batch = 17.7252s	
11792/29850 (epoch 19.752), train_loss = 0.83997078, grad/param norm = 1.7369e-01, time/batch = 18.2944s	
11793/29850 (epoch 19.754), train_loss = 0.90248982, grad/param norm = 1.8274e-01, time/batch = 17.1281s	
11794/29850 (epoch 19.755), train_loss = 0.91679168, grad/param norm = 1.8446e-01, time/batch = 18.7821s	
11795/29850 (epoch 19.757), train_loss = 0.99419735, grad/param norm = 1.9999e-01, time/batch = 14.3165s	
11796/29850 (epoch 19.759), train_loss = 0.99802154, grad/param norm = 1.7977e-01, time/batch = 17.8729s	
11797/29850 (epoch 19.760), train_loss = 0.94609366, grad/param norm = 2.0916e-01, time/batch = 19.3666s	
11798/29850 (epoch 19.762), train_loss = 0.91244604, grad/param norm = 1.9995e-01, time/batch = 18.6953s	
11799/29850 (epoch 19.764), train_loss = 0.87467248, grad/param norm = 1.9422e-01, time/batch = 16.0448s	
11800/29850 (epoch 19.765), train_loss = 0.98864780, grad/param norm = 1.7898e-01, time/batch = 15.3001s	
11801/29850 (epoch 19.767), train_loss = 1.01849355, grad/param norm = 1.7504e-01, time/batch = 17.7141s	
11802/29850 (epoch 19.769), train_loss = 1.00222467, grad/param norm = 1.9217e-01, time/batch = 16.8792s	
11803/29850 (epoch 19.771), train_loss = 1.05107762, grad/param norm = 1.8449e-01, time/batch = 15.1174s	
11804/29850 (epoch 19.772), train_loss = 1.08465896, grad/param norm = 2.1282e-01, time/batch = 15.9399s	
11805/29850 (epoch 19.774), train_loss = 0.97386339, grad/param norm = 1.8559e-01, time/batch = 17.0385s	
11806/29850 (epoch 19.776), train_loss = 0.97528725, grad/param norm = 2.0428e-01, time/batch = 17.6234s	
11807/29850 (epoch 19.777), train_loss = 1.09827872, grad/param norm = 2.0127e-01, time/batch = 17.9663s	
11808/29850 (epoch 19.779), train_loss = 0.91901283, grad/param norm = 1.7243e-01, time/batch = 18.9648s	
11809/29850 (epoch 19.781), train_loss = 1.03625151, grad/param norm = 1.9075e-01, time/batch = 17.3713s	
11810/29850 (epoch 19.782), train_loss = 1.08185865, grad/param norm = 2.0869e-01, time/batch = 18.4573s	
11811/29850 (epoch 19.784), train_loss = 0.92345237, grad/param norm = 1.9465e-01, time/batch = 17.5437s	
11812/29850 (epoch 19.786), train_loss = 0.98596619, grad/param norm = 1.9145e-01, time/batch = 18.3078s	
11813/29850 (epoch 19.787), train_loss = 0.89948758, grad/param norm = 2.0754e-01, time/batch = 17.3926s	
11814/29850 (epoch 19.789), train_loss = 0.85003707, grad/param norm = 1.6362e-01, time/batch = 17.3660s	
11815/29850 (epoch 19.791), train_loss = 0.96173797, grad/param norm = 2.2809e-01, time/batch = 18.4694s	
11816/29850 (epoch 19.792), train_loss = 1.08928449, grad/param norm = 2.0114e-01, time/batch = 15.3801s	
11817/29850 (epoch 19.794), train_loss = 1.05359764, grad/param norm = 1.9126e-01, time/batch = 16.4463s	
11818/29850 (epoch 19.796), train_loss = 0.92200410, grad/param norm = 1.6427e-01, time/batch = 17.5381s	
11819/29850 (epoch 19.797), train_loss = 0.84787339, grad/param norm = 1.7499e-01, time/batch = 16.7238s	
11820/29850 (epoch 19.799), train_loss = 0.89943033, grad/param norm = 1.6324e-01, time/batch = 17.2241s	
11821/29850 (epoch 19.801), train_loss = 1.00171960, grad/param norm = 1.9164e-01, time/batch = 17.3625s	
11822/29850 (epoch 19.802), train_loss = 0.83635782, grad/param norm = 1.8099e-01, time/batch = 16.8882s	
11823/29850 (epoch 19.804), train_loss = 0.88725866, grad/param norm = 1.6233e-01, time/batch = 17.4661s	
11824/29850 (epoch 19.806), train_loss = 0.90048566, grad/param norm = 1.7948e-01, time/batch = 17.1268s	
11825/29850 (epoch 19.807), train_loss = 0.84682826, grad/param norm = 1.5419e-01, time/batch = 18.2234s	
11826/29850 (epoch 19.809), train_loss = 0.92212432, grad/param norm = 1.9558e-01, time/batch = 19.6210s	
11827/29850 (epoch 19.811), train_loss = 1.04378648, grad/param norm = 1.9466e-01, time/batch = 16.3082s	
11828/29850 (epoch 19.812), train_loss = 1.05339197, grad/param norm = 2.1261e-01, time/batch = 19.0430s	
11829/29850 (epoch 19.814), train_loss = 1.12871067, grad/param norm = 1.8915e-01, time/batch = 16.9354s	
11830/29850 (epoch 19.816), train_loss = 1.08841328, grad/param norm = 1.7011e-01, time/batch = 18.5280s	
11831/29850 (epoch 19.817), train_loss = 1.03424022, grad/param norm = 1.9012e-01, time/batch = 16.6079s	
11832/29850 (epoch 19.819), train_loss = 0.87993707, grad/param norm = 1.9302e-01, time/batch = 19.3761s	
11833/29850 (epoch 19.821), train_loss = 1.13636974, grad/param norm = 2.1379e-01, time/batch = 19.1831s	
11834/29850 (epoch 19.822), train_loss = 1.12939200, grad/param norm = 1.9299e-01, time/batch = 15.9677s	
11835/29850 (epoch 19.824), train_loss = 1.00281076, grad/param norm = 1.7270e-01, time/batch = 17.2888s	
11836/29850 (epoch 19.826), train_loss = 0.95933133, grad/param norm = 1.8501e-01, time/batch = 17.7224s	
11837/29850 (epoch 19.827), train_loss = 0.90936393, grad/param norm = 1.9232e-01, time/batch = 16.9619s	
11838/29850 (epoch 19.829), train_loss = 1.03112155, grad/param norm = 2.2027e-01, time/batch = 16.6462s	
11839/29850 (epoch 19.831), train_loss = 1.10936091, grad/param norm = 2.0853e-01, time/batch = 16.2061s	
11840/29850 (epoch 19.832), train_loss = 1.00250747, grad/param norm = 1.7082e-01, time/batch = 19.2227s	
11841/29850 (epoch 19.834), train_loss = 0.84038104, grad/param norm = 1.6113e-01, time/batch = 17.9589s	
11842/29850 (epoch 19.836), train_loss = 0.87818592, grad/param norm = 1.7503e-01, time/batch = 18.7074s	
11843/29850 (epoch 19.838), train_loss = 1.01383845, grad/param norm = 1.9932e-01, time/batch = 19.5092s	
11844/29850 (epoch 19.839), train_loss = 0.91608761, grad/param norm = 1.6662e-01, time/batch = 17.6033s	
11845/29850 (epoch 19.841), train_loss = 0.91638035, grad/param norm = 1.6951e-01, time/batch = 19.8631s	
11846/29850 (epoch 19.843), train_loss = 0.90241311, grad/param norm = 1.8458e-01, time/batch = 17.3631s	
11847/29850 (epoch 19.844), train_loss = 0.90753196, grad/param norm = 1.7713e-01, time/batch = 17.6068s	
11848/29850 (epoch 19.846), train_loss = 1.03088387, grad/param norm = 1.9355e-01, time/batch = 17.7931s	
11849/29850 (epoch 19.848), train_loss = 1.07062685, grad/param norm = 1.9677e-01, time/batch = 18.1918s	
11850/29850 (epoch 19.849), train_loss = 0.96176480, grad/param norm = 1.9762e-01, time/batch = 19.7852s	
11851/29850 (epoch 19.851), train_loss = 1.11030638, grad/param norm = 2.0875e-01, time/batch = 15.6591s	
11852/29850 (epoch 19.853), train_loss = 0.95411490, grad/param norm = 2.1128e-01, time/batch = 18.7952s	
11853/29850 (epoch 19.854), train_loss = 1.16689621, grad/param norm = 2.1186e-01, time/batch = 17.5488s	
11854/29850 (epoch 19.856), train_loss = 1.11813888, grad/param norm = 2.4752e-01, time/batch = 16.0567s	
11855/29850 (epoch 19.858), train_loss = 1.02144828, grad/param norm = 2.0039e-01, time/batch = 17.1150s	
11856/29850 (epoch 19.859), train_loss = 0.92038009, grad/param norm = 2.1690e-01, time/batch = 18.4735s	
11857/29850 (epoch 19.861), train_loss = 1.12453643, grad/param norm = 2.0345e-01, time/batch = 16.6169s	
11858/29850 (epoch 19.863), train_loss = 1.18243246, grad/param norm = 2.0436e-01, time/batch = 18.3779s	
11859/29850 (epoch 19.864), train_loss = 1.12151649, grad/param norm = 2.1275e-01, time/batch = 17.8912s	
11860/29850 (epoch 19.866), train_loss = 1.04895417, grad/param norm = 2.1368e-01, time/batch = 18.5523s	
11861/29850 (epoch 19.868), train_loss = 1.18472336, grad/param norm = 2.0874e-01, time/batch = 17.1063s	
11862/29850 (epoch 19.869), train_loss = 1.03033859, grad/param norm = 2.1740e-01, time/batch = 18.7123s	
11863/29850 (epoch 19.871), train_loss = 1.09835698, grad/param norm = 1.9366e-01, time/batch = 18.8100s	
11864/29850 (epoch 19.873), train_loss = 1.08424409, grad/param norm = 2.4304e-01, time/batch = 17.1907s	
11865/29850 (epoch 19.874), train_loss = 1.04216719, grad/param norm = 1.8806e-01, time/batch = 19.5473s	
11866/29850 (epoch 19.876), train_loss = 1.01330520, grad/param norm = 2.4760e-01, time/batch = 15.7758s	
11867/29850 (epoch 19.878), train_loss = 1.05220713, grad/param norm = 2.0951e-01, time/batch = 18.7897s	
11868/29850 (epoch 19.879), train_loss = 1.05366984, grad/param norm = 1.9947e-01, time/batch = 17.5440s	
11869/29850 (epoch 19.881), train_loss = 1.15816947, grad/param norm = 2.3856e-01, time/batch = 16.1409s	
11870/29850 (epoch 19.883), train_loss = 1.12929985, grad/param norm = 2.1468e-01, time/batch = 18.2936s	
11871/29850 (epoch 19.884), train_loss = 0.92846720, grad/param norm = 1.8737e-01, time/batch = 17.4647s	
11872/29850 (epoch 19.886), train_loss = 1.16752924, grad/param norm = 2.2297e-01, time/batch = 16.6960s	
11873/29850 (epoch 19.888), train_loss = 1.04300765, grad/param norm = 1.9975e-01, time/batch = 16.6151s	
11874/29850 (epoch 19.889), train_loss = 0.98707493, grad/param norm = 1.8602e-01, time/batch = 18.3722s	
11875/29850 (epoch 19.891), train_loss = 0.96451960, grad/param norm = 1.8136e-01, time/batch = 17.5468s	
11876/29850 (epoch 19.893), train_loss = 0.94678703, grad/param norm = 1.7672e-01, time/batch = 19.3822s	
11877/29850 (epoch 19.894), train_loss = 0.97530667, grad/param norm = 1.8375e-01, time/batch = 17.7208s	
11878/29850 (epoch 19.896), train_loss = 1.01922730, grad/param norm = 1.9035e-01, time/batch = 17.1993s	
11879/29850 (epoch 19.898), train_loss = 1.13666392, grad/param norm = 1.9046e-01, time/batch = 17.6438s	
11880/29850 (epoch 19.899), train_loss = 0.88594336, grad/param norm = 1.7457e-01, time/batch = 17.9793s	
11881/29850 (epoch 19.901), train_loss = 1.30901794, grad/param norm = 2.5837e-01, time/batch = 17.5398s	
11882/29850 (epoch 19.903), train_loss = 1.07001527, grad/param norm = 3.3776e-01, time/batch = 17.5479s	
11883/29850 (epoch 19.905), train_loss = 1.25674460, grad/param norm = 2.1544e-01, time/batch = 19.0292s	
11884/29850 (epoch 19.906), train_loss = 1.07145406, grad/param norm = 2.1438e-01, time/batch = 22.1323s	
11885/29850 (epoch 19.908), train_loss = 1.17627722, grad/param norm = 2.1998e-01, time/batch = 27.2666s	
11886/29850 (epoch 19.910), train_loss = 1.10465364, grad/param norm = 1.9697e-01, time/batch = 17.0566s	
11887/29850 (epoch 19.911), train_loss = 1.23742156, grad/param norm = 2.0260e-01, time/batch = 16.6918s	
11888/29850 (epoch 19.913), train_loss = 1.15409838, grad/param norm = 1.9050e-01, time/batch = 15.1874s	
11889/29850 (epoch 19.915), train_loss = 1.17168708, grad/param norm = 2.1808e-01, time/batch = 17.9504s	
11890/29850 (epoch 19.916), train_loss = 1.13533386, grad/param norm = 2.1894e-01, time/batch = 17.4548s	
11891/29850 (epoch 19.918), train_loss = 0.98918008, grad/param norm = 1.8926e-01, time/batch = 19.1918s	
11892/29850 (epoch 19.920), train_loss = 1.09971156, grad/param norm = 1.8376e-01, time/batch = 15.5667s	
11893/29850 (epoch 19.921), train_loss = 1.08605023, grad/param norm = 2.2852e-01, time/batch = 17.8954s	
11894/29850 (epoch 19.923), train_loss = 1.13844460, grad/param norm = 2.0639e-01, time/batch = 16.9556s	
11895/29850 (epoch 19.925), train_loss = 1.16935659, grad/param norm = 1.9464e-01, time/batch = 17.2676s	
11896/29850 (epoch 19.926), train_loss = 1.24217919, grad/param norm = 2.4056e-01, time/batch = 18.6235s	
11897/29850 (epoch 19.928), train_loss = 1.09147582, grad/param norm = 2.0152e-01, time/batch = 15.5264s	
11898/29850 (epoch 19.930), train_loss = 1.13259837, grad/param norm = 2.1124e-01, time/batch = 17.7912s	
11899/29850 (epoch 19.931), train_loss = 1.03052502, grad/param norm = 1.8722e-01, time/batch = 18.3036s	
11900/29850 (epoch 19.933), train_loss = 1.23354125, grad/param norm = 2.1091e-01, time/batch = 18.0423s	
11901/29850 (epoch 19.935), train_loss = 1.15631230, grad/param norm = 2.0852e-01, time/batch = 16.3428s	
11902/29850 (epoch 19.936), train_loss = 1.14952331, grad/param norm = 2.1378e-01, time/batch = 16.0411s	
11903/29850 (epoch 19.938), train_loss = 0.93469944, grad/param norm = 1.7296e-01, time/batch = 18.6172s	
11904/29850 (epoch 19.940), train_loss = 0.94508607, grad/param norm = 1.8751e-01, time/batch = 16.1852s	
11905/29850 (epoch 19.941), train_loss = 0.99945405, grad/param norm = 2.1167e-01, time/batch = 17.7122s	
11906/29850 (epoch 19.943), train_loss = 0.99718955, grad/param norm = 1.8765e-01, time/batch = 15.6366s	
11907/29850 (epoch 19.945), train_loss = 1.02797649, grad/param norm = 2.0247e-01, time/batch = 18.3906s	
11908/29850 (epoch 19.946), train_loss = 0.93669050, grad/param norm = 1.9886e-01, time/batch = 17.5441s	
11909/29850 (epoch 19.948), train_loss = 1.05872548, grad/param norm = 1.9341e-01, time/batch = 19.6246s	
11910/29850 (epoch 19.950), train_loss = 0.96895609, grad/param norm = 1.6828e-01, time/batch = 17.9509s	
11911/29850 (epoch 19.951), train_loss = 0.92815335, grad/param norm = 1.7025e-01, time/batch = 16.9657s	
11912/29850 (epoch 19.953), train_loss = 1.04054890, grad/param norm = 2.2675e-01, time/batch = 19.3720s	
11913/29850 (epoch 19.955), train_loss = 0.92045113, grad/param norm = 1.7275e-01, time/batch = 16.5509s	
11914/29850 (epoch 19.956), train_loss = 0.90628347, grad/param norm = 1.7308e-01, time/batch = 18.3748s	
11915/29850 (epoch 19.958), train_loss = 0.78023873, grad/param norm = 1.6105e-01, time/batch = 17.7124s	
11916/29850 (epoch 19.960), train_loss = 1.10890503, grad/param norm = 1.9872e-01, time/batch = 19.2768s	
11917/29850 (epoch 19.961), train_loss = 0.93158235, grad/param norm = 1.8790e-01, time/batch = 18.5495s	
11918/29850 (epoch 19.963), train_loss = 0.91313823, grad/param norm = 1.7052e-01, time/batch = 17.9419s	
11919/29850 (epoch 19.965), train_loss = 0.94242115, grad/param norm = 1.9415e-01, time/batch = 16.6575s	
11920/29850 (epoch 19.966), train_loss = 0.89040714, grad/param norm = 1.7874e-01, time/batch = 17.1399s	
11921/29850 (epoch 19.968), train_loss = 0.95448576, grad/param norm = 1.9700e-01, time/batch = 16.5444s	
11922/29850 (epoch 19.970), train_loss = 0.90158699, grad/param norm = 1.9865e-01, time/batch = 16.3670s	
11923/29850 (epoch 19.972), train_loss = 0.94026532, grad/param norm = 1.7361e-01, time/batch = 17.8680s	
11924/29850 (epoch 19.973), train_loss = 0.93737375, grad/param norm = 1.8044e-01, time/batch = 18.1376s	
11925/29850 (epoch 19.975), train_loss = 0.83745404, grad/param norm = 1.6976e-01, time/batch = 18.4251s	
11926/29850 (epoch 19.977), train_loss = 0.96289821, grad/param norm = 1.6829e-01, time/batch = 17.9750s	
11927/29850 (epoch 19.978), train_loss = 0.90890185, grad/param norm = 1.6222e-01, time/batch = 16.2279s	
11928/29850 (epoch 19.980), train_loss = 0.98098676, grad/param norm = 1.8021e-01, time/batch = 16.2087s	
11929/29850 (epoch 19.982), train_loss = 0.97166327, grad/param norm = 1.8722e-01, time/batch = 18.5431s	
11930/29850 (epoch 19.983), train_loss = 0.99420173, grad/param norm = 1.7809e-01, time/batch = 18.6267s	
11931/29850 (epoch 19.985), train_loss = 1.03855625, grad/param norm = 1.8796e-01, time/batch = 17.7898s	
11932/29850 (epoch 19.987), train_loss = 1.02632719, grad/param norm = 1.8000e-01, time/batch = 19.7026s	
11933/29850 (epoch 19.988), train_loss = 0.96266647, grad/param norm = 1.7436e-01, time/batch = 17.7204s	
11934/29850 (epoch 19.990), train_loss = 1.03726689, grad/param norm = 1.9278e-01, time/batch = 16.2802s	
11935/29850 (epoch 19.992), train_loss = 1.04760914, grad/param norm = 1.8417e-01, time/batch = 16.9455s	
11936/29850 (epoch 19.993), train_loss = 1.03401314, grad/param norm = 1.8838e-01, time/batch = 18.1338s	
11937/29850 (epoch 19.995), train_loss = 1.04788429, grad/param norm = 1.8416e-01, time/batch = 15.9813s	
11938/29850 (epoch 19.997), train_loss = 1.04584140, grad/param norm = 2.0550e-01, time/batch = 16.6259s	
11939/29850 (epoch 19.998), train_loss = 1.10052737, grad/param norm = 1.8803e-01, time/batch = 16.7995s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
11940/29850 (epoch 20.000), train_loss = 0.92447723, grad/param norm = 1.7614e-01, time/batch = 18.4669s	
11941/29850 (epoch 20.002), train_loss = 1.24506762, grad/param norm = 2.1605e-01, time/batch = 17.6254s	
11942/29850 (epoch 20.003), train_loss = 0.95532520, grad/param norm = 1.7920e-01, time/batch = 16.5525s	
11943/29850 (epoch 20.005), train_loss = 1.05027187, grad/param norm = 1.8830e-01, time/batch = 18.8842s	
11944/29850 (epoch 20.007), train_loss = 1.08315434, grad/param norm = 1.9989e-01, time/batch = 18.3053s	
11945/29850 (epoch 20.008), train_loss = 1.25090970, grad/param norm = 2.0050e-01, time/batch = 16.5694s	
11946/29850 (epoch 20.010), train_loss = 0.93775965, grad/param norm = 2.0016e-01, time/batch = 17.2877s	
11947/29850 (epoch 20.012), train_loss = 1.03484395, grad/param norm = 1.6884e-01, time/batch = 19.0467s	
11948/29850 (epoch 20.013), train_loss = 1.07629195, grad/param norm = 2.1096e-01, time/batch = 17.4574s	
11949/29850 (epoch 20.015), train_loss = 1.08792927, grad/param norm = 1.7344e-01, time/batch = 18.1319s	
11950/29850 (epoch 20.017), train_loss = 1.06883241, grad/param norm = 1.9453e-01, time/batch = 18.1240s	
11951/29850 (epoch 20.018), train_loss = 1.17936647, grad/param norm = 2.2086e-01, time/batch = 15.4562s	
11952/29850 (epoch 20.020), train_loss = 1.01921649, grad/param norm = 1.8533e-01, time/batch = 15.2747s	
11953/29850 (epoch 20.022), train_loss = 1.15280313, grad/param norm = 1.9414e-01, time/batch = 17.8787s	
11954/29850 (epoch 20.023), train_loss = 1.10997239, grad/param norm = 2.0165e-01, time/batch = 17.9877s	
11955/29850 (epoch 20.025), train_loss = 1.02283580, grad/param norm = 1.7550e-01, time/batch = 16.8003s	
11956/29850 (epoch 20.027), train_loss = 0.84953723, grad/param norm = 1.7515e-01, time/batch = 17.1300s	
11957/29850 (epoch 20.028), train_loss = 1.00912395, grad/param norm = 1.7465e-01, time/batch = 17.3844s	
11958/29850 (epoch 20.030), train_loss = 1.05103246, grad/param norm = 2.1466e-01, time/batch = 17.0514s	
11959/29850 (epoch 20.032), train_loss = 1.08957727, grad/param norm = 1.9306e-01, time/batch = 17.7837s	
11960/29850 (epoch 20.034), train_loss = 0.95928801, grad/param norm = 1.7914e-01, time/batch = 16.4642s	
11961/29850 (epoch 20.035), train_loss = 0.87751792, grad/param norm = 1.7657e-01, time/batch = 19.6296s	
11962/29850 (epoch 20.037), train_loss = 1.01873199, grad/param norm = 1.8368e-01, time/batch = 17.8025s	
11963/29850 (epoch 20.039), train_loss = 0.90822502, grad/param norm = 1.7126e-01, time/batch = 17.4006s	
11964/29850 (epoch 20.040), train_loss = 0.95077431, grad/param norm = 1.8231e-01, time/batch = 19.4685s	
11965/29850 (epoch 20.042), train_loss = 0.94993474, grad/param norm = 1.8012e-01, time/batch = 16.9363s	
11966/29850 (epoch 20.044), train_loss = 0.99066036, grad/param norm = 1.7136e-01, time/batch = 17.0462s	
11967/29850 (epoch 20.045), train_loss = 1.09114446, grad/param norm = 1.8652e-01, time/batch = 19.1228s	
11968/29850 (epoch 20.047), train_loss = 0.88728068, grad/param norm = 1.7968e-01, time/batch = 18.4683s	
11969/29850 (epoch 20.049), train_loss = 1.05471218, grad/param norm = 1.8022e-01, time/batch = 17.2186s	
11970/29850 (epoch 20.050), train_loss = 0.95038979, grad/param norm = 1.8996e-01, time/batch = 16.8960s	
11971/29850 (epoch 20.052), train_loss = 1.15216292, grad/param norm = 2.1405e-01, time/batch = 16.0718s	
11972/29850 (epoch 20.054), train_loss = 1.07634416, grad/param norm = 1.9662e-01, time/batch = 15.9550s	
11973/29850 (epoch 20.055), train_loss = 1.00215721, grad/param norm = 1.7944e-01, time/batch = 17.1902s	
11974/29850 (epoch 20.057), train_loss = 1.09984343, grad/param norm = 1.8564e-01, time/batch = 17.5453s	
11975/29850 (epoch 20.059), train_loss = 1.06848586, grad/param norm = 1.9723e-01, time/batch = 17.8915s	
11976/29850 (epoch 20.060), train_loss = 1.04999064, grad/param norm = 1.9415e-01, time/batch = 17.7041s	
11977/29850 (epoch 20.062), train_loss = 1.15692968, grad/param norm = 2.0222e-01, time/batch = 18.0405s	
11978/29850 (epoch 20.064), train_loss = 1.10287278, grad/param norm = 1.9171e-01, time/batch = 18.4691s	
11979/29850 (epoch 20.065), train_loss = 0.95887023, grad/param norm = 1.9435e-01, time/batch = 17.6993s	
11980/29850 (epoch 20.067), train_loss = 1.09695008, grad/param norm = 1.8953e-01, time/batch = 18.4585s	
11981/29850 (epoch 20.069), train_loss = 1.03637334, grad/param norm = 1.7377e-01, time/batch = 17.9339s	
11982/29850 (epoch 20.070), train_loss = 1.11235324, grad/param norm = 1.7899e-01, time/batch = 16.3808s	
11983/29850 (epoch 20.072), train_loss = 1.07383918, grad/param norm = 2.0245e-01, time/batch = 16.8044s	
11984/29850 (epoch 20.074), train_loss = 1.10458090, grad/param norm = 1.7943e-01, time/batch = 18.6300s	
11985/29850 (epoch 20.075), train_loss = 0.96539647, grad/param norm = 2.0013e-01, time/batch = 18.6278s	
11986/29850 (epoch 20.077), train_loss = 1.08999035, grad/param norm = 2.0135e-01, time/batch = 16.8521s	
11987/29850 (epoch 20.079), train_loss = 1.28127686, grad/param norm = 3.2770e-01, time/batch = 17.1299s	
11988/29850 (epoch 20.080), train_loss = 1.26411883, grad/param norm = 2.4140e-01, time/batch = 17.4723s	
11989/29850 (epoch 20.082), train_loss = 1.12967509, grad/param norm = 2.1816e-01, time/batch = 15.6105s	
11990/29850 (epoch 20.084), train_loss = 1.18265719, grad/param norm = 2.0257e-01, time/batch = 16.0687s	
11991/29850 (epoch 20.085), train_loss = 1.17632689, grad/param norm = 2.4665e-01, time/batch = 17.1293s	
11992/29850 (epoch 20.087), train_loss = 1.19498151, grad/param norm = 2.1367e-01, time/batch = 18.2297s	
11993/29850 (epoch 20.089), train_loss = 1.10110579, grad/param norm = 2.0734e-01, time/batch = 16.2960s	
11994/29850 (epoch 20.090), train_loss = 1.13104540, grad/param norm = 2.0454e-01, time/batch = 15.7437s	
11995/29850 (epoch 20.092), train_loss = 1.02192288, grad/param norm = 2.0068e-01, time/batch = 17.7198s	
11996/29850 (epoch 20.094), train_loss = 1.17392301, grad/param norm = 2.1294e-01, time/batch = 17.0528s	
11997/29850 (epoch 20.095), train_loss = 1.08143704, grad/param norm = 1.9807e-01, time/batch = 16.2710s	
11998/29850 (epoch 20.097), train_loss = 0.86308008, grad/param norm = 1.6009e-01, time/batch = 18.2189s	
11999/29850 (epoch 20.099), train_loss = 0.89769197, grad/param norm = 1.7864e-01, time/batch = 18.1346s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch20.10_1.6735.t7	
12000/29850 (epoch 20.101), train_loss = 1.15018282, grad/param norm = 1.9122e-01, time/batch = 17.2906s	
12001/29850 (epoch 20.102), train_loss = 1.43784341, grad/param norm = 2.7587e-01, time/batch = 18.7036s	
12002/29850 (epoch 20.104), train_loss = 1.05255270, grad/param norm = 1.8545e-01, time/batch = 15.2458s	
12003/29850 (epoch 20.106), train_loss = 1.14064685, grad/param norm = 1.9040e-01, time/batch = 17.5468s	
12004/29850 (epoch 20.107), train_loss = 0.90077489, grad/param norm = 1.5867e-01, time/batch = 17.5445s	
12005/29850 (epoch 20.109), train_loss = 1.02117156, grad/param norm = 1.9518e-01, time/batch = 19.4683s	
12006/29850 (epoch 20.111), train_loss = 1.15257718, grad/param norm = 1.9574e-01, time/batch = 17.7945s	
12007/29850 (epoch 20.112), train_loss = 0.98288913, grad/param norm = 1.7927e-01, time/batch = 17.3057s	
12008/29850 (epoch 20.114), train_loss = 1.05076499, grad/param norm = 2.0450e-01, time/batch = 18.4655s	
12009/29850 (epoch 20.116), train_loss = 0.95738644, grad/param norm = 1.6923e-01, time/batch = 17.2968s	
12010/29850 (epoch 20.117), train_loss = 1.06121915, grad/param norm = 1.9544e-01, time/batch = 16.8099s	
12011/29850 (epoch 20.119), train_loss = 1.02153304, grad/param norm = 1.7774e-01, time/batch = 18.4759s	
12012/29850 (epoch 20.121), train_loss = 0.84225143, grad/param norm = 1.8496e-01, time/batch = 17.9023s	
12013/29850 (epoch 20.122), train_loss = 0.90315005, grad/param norm = 1.6090e-01, time/batch = 17.6791s	
12014/29850 (epoch 20.124), train_loss = 0.97531136, grad/param norm = 1.8809e-01, time/batch = 17.1242s	
12015/29850 (epoch 20.126), train_loss = 1.00984808, grad/param norm = 1.9134e-01, time/batch = 17.6311s	
12016/29850 (epoch 20.127), train_loss = 1.13019112, grad/param norm = 2.2348e-01, time/batch = 17.5473s	
12017/29850 (epoch 20.129), train_loss = 0.99158144, grad/param norm = 1.9099e-01, time/batch = 16.2920s	
12018/29850 (epoch 20.131), train_loss = 1.01749964, grad/param norm = 1.8184e-01, time/batch = 18.7080s	
12019/29850 (epoch 20.132), train_loss = 0.92902427, grad/param norm = 1.9283e-01, time/batch = 17.2254s	
12020/29850 (epoch 20.134), train_loss = 1.06079296, grad/param norm = 1.9511e-01, time/batch = 17.5449s	
12021/29850 (epoch 20.136), train_loss = 1.06035483, grad/param norm = 1.8538e-01, time/batch = 15.3012s	
12022/29850 (epoch 20.137), train_loss = 0.87019859, grad/param norm = 1.6884e-01, time/batch = 17.8601s	
12023/29850 (epoch 20.139), train_loss = 0.99597105, grad/param norm = 1.9602e-01, time/batch = 16.3796s	
12024/29850 (epoch 20.141), train_loss = 0.98709416, grad/param norm = 1.9009e-01, time/batch = 18.1264s	
12025/29850 (epoch 20.142), train_loss = 1.14707568, grad/param norm = 2.0016e-01, time/batch = 17.9437s	
12026/29850 (epoch 20.144), train_loss = 1.29685195, grad/param norm = 2.1129e-01, time/batch = 16.9738s	
12027/29850 (epoch 20.146), train_loss = 1.28874060, grad/param norm = 2.0531e-01, time/batch = 16.7090s	
12028/29850 (epoch 20.147), train_loss = 1.10432119, grad/param norm = 1.9830e-01, time/batch = 18.1459s	
12029/29850 (epoch 20.149), train_loss = 1.12578123, grad/param norm = 2.0430e-01, time/batch = 18.6290s	
12030/29850 (epoch 20.151), train_loss = 1.11058403, grad/param norm = 2.0963e-01, time/batch = 15.5437s	
12031/29850 (epoch 20.152), train_loss = 0.99933330, grad/param norm = 1.8698e-01, time/batch = 18.2174s	
12032/29850 (epoch 20.154), train_loss = 0.98413356, grad/param norm = 2.0116e-01, time/batch = 18.5489s	
12033/29850 (epoch 20.156), train_loss = 0.97902425, grad/param norm = 1.8321e-01, time/batch = 16.6414s	
12034/29850 (epoch 20.157), train_loss = 1.06795413, grad/param norm = 1.8302e-01, time/batch = 18.5243s	
12035/29850 (epoch 20.159), train_loss = 1.02366448, grad/param norm = 1.7640e-01, time/batch = 19.2658s	
12036/29850 (epoch 20.161), train_loss = 1.10870963, grad/param norm = 2.1619e-01, time/batch = 18.2912s	
12037/29850 (epoch 20.162), train_loss = 1.19062266, grad/param norm = 1.9553e-01, time/batch = 17.1140s	
12038/29850 (epoch 20.164), train_loss = 1.04927764, grad/param norm = 1.8223e-01, time/batch = 17.8974s	
12039/29850 (epoch 20.166), train_loss = 0.95296473, grad/param norm = 1.7363e-01, time/batch = 19.4662s	
12040/29850 (epoch 20.168), train_loss = 0.89454468, grad/param norm = 1.7054e-01, time/batch = 16.7799s	
12041/29850 (epoch 20.169), train_loss = 1.19041304, grad/param norm = 2.0164e-01, time/batch = 17.1166s	
12042/29850 (epoch 20.171), train_loss = 1.11708099, grad/param norm = 2.0277e-01, time/batch = 19.5409s	
12043/29850 (epoch 20.173), train_loss = 0.98731004, grad/param norm = 2.0097e-01, time/batch = 16.8036s	
12044/29850 (epoch 20.174), train_loss = 1.11219248, grad/param norm = 2.1489e-01, time/batch = 19.5382s	
12045/29850 (epoch 20.176), train_loss = 1.09015821, grad/param norm = 2.0815e-01, time/batch = 16.4778s	
12046/29850 (epoch 20.178), train_loss = 1.13520448, grad/param norm = 2.1889e-01, time/batch = 18.6936s	
12047/29850 (epoch 20.179), train_loss = 0.93000526, grad/param norm = 1.9251e-01, time/batch = 16.9384s	
12048/29850 (epoch 20.181), train_loss = 1.05726816, grad/param norm = 1.9538e-01, time/batch = 15.2025s	
12049/29850 (epoch 20.183), train_loss = 1.04659353, grad/param norm = 1.8628e-01, time/batch = 17.5623s	
12050/29850 (epoch 20.184), train_loss = 1.06956208, grad/param norm = 1.9866e-01, time/batch = 17.1296s	
12051/29850 (epoch 20.186), train_loss = 1.09117289, grad/param norm = 2.1188e-01, time/batch = 16.6377s	
12052/29850 (epoch 20.188), train_loss = 1.16969249, grad/param norm = 2.1042e-01, time/batch = 17.3840s	
12053/29850 (epoch 20.189), train_loss = 1.19377184, grad/param norm = 2.0910e-01, time/batch = 18.0474s	
12054/29850 (epoch 20.191), train_loss = 1.11433814, grad/param norm = 2.1491e-01, time/batch = 17.7292s	
12055/29850 (epoch 20.193), train_loss = 1.01217529, grad/param norm = 1.8410e-01, time/batch = 17.1402s	
12056/29850 (epoch 20.194), train_loss = 1.09179247, grad/param norm = 2.0414e-01, time/batch = 17.9762s	
12057/29850 (epoch 20.196), train_loss = 1.00129377, grad/param norm = 1.9597e-01, time/batch = 16.8816s	
12058/29850 (epoch 20.198), train_loss = 1.05677300, grad/param norm = 1.9866e-01, time/batch = 15.5457s	
12059/29850 (epoch 20.199), train_loss = 1.28610358, grad/param norm = 2.3736e-01, time/batch = 17.2866s	
12060/29850 (epoch 20.201), train_loss = 0.98138900, grad/param norm = 2.7155e-01, time/batch = 17.3815s	
12061/29850 (epoch 20.203), train_loss = 0.86394300, grad/param norm = 2.0717e-01, time/batch = 19.7630s	
12062/29850 (epoch 20.204), train_loss = 1.11706234, grad/param norm = 2.1459e-01, time/batch = 19.0566s	
12063/29850 (epoch 20.206), train_loss = 0.94504335, grad/param norm = 2.0726e-01, time/batch = 18.5178s	
12064/29850 (epoch 20.208), train_loss = 1.19638510, grad/param norm = 1.9104e-01, time/batch = 16.8002s	
12065/29850 (epoch 20.209), train_loss = 0.94342364, grad/param norm = 1.8802e-01, time/batch = 16.8216s	
12066/29850 (epoch 20.211), train_loss = 1.01823098, grad/param norm = 1.9391e-01, time/batch = 17.0501s	
12067/29850 (epoch 20.213), train_loss = 1.11916299, grad/param norm = 1.9285e-01, time/batch = 16.5321s	
12068/29850 (epoch 20.214), train_loss = 0.94427544, grad/param norm = 1.6692e-01, time/batch = 17.2908s	
12069/29850 (epoch 20.216), train_loss = 0.98284274, grad/param norm = 1.9264e-01, time/batch = 15.8854s	
12070/29850 (epoch 20.218), train_loss = 1.13861949, grad/param norm = 2.0461e-01, time/batch = 15.3069s	
12071/29850 (epoch 20.219), train_loss = 1.15909528, grad/param norm = 2.1326e-01, time/batch = 15.5369s	
12072/29850 (epoch 20.221), train_loss = 1.04626938, grad/param norm = 1.8593e-01, time/batch = 17.7874s	
12073/29850 (epoch 20.223), train_loss = 0.96968338, grad/param norm = 1.9647e-01, time/batch = 16.0363s	
12074/29850 (epoch 20.224), train_loss = 0.92656326, grad/param norm = 1.8756e-01, time/batch = 17.7897s	
12075/29850 (epoch 20.226), train_loss = 0.96048943, grad/param norm = 1.6709e-01, time/batch = 18.0864s	
12076/29850 (epoch 20.228), train_loss = 1.01172207, grad/param norm = 1.8101e-01, time/batch = 17.4501s	
12077/29850 (epoch 20.229), train_loss = 0.88212169, grad/param norm = 1.5532e-01, time/batch = 17.9029s	
12078/29850 (epoch 20.231), train_loss = 1.03443363, grad/param norm = 1.8806e-01, time/batch = 18.9433s	
12079/29850 (epoch 20.233), train_loss = 1.00656466, grad/param norm = 2.0412e-01, time/batch = 17.5468s	
12080/29850 (epoch 20.235), train_loss = 0.95107731, grad/param norm = 1.9333e-01, time/batch = 19.8733s	
12081/29850 (epoch 20.236), train_loss = 1.19681361, grad/param norm = 2.1716e-01, time/batch = 29.9525s	
12082/29850 (epoch 20.238), train_loss = 0.92544954, grad/param norm = 1.7756e-01, time/batch = 18.0961s	
12083/29850 (epoch 20.240), train_loss = 0.93205756, grad/param norm = 1.7517e-01, time/batch = 16.3939s	
12084/29850 (epoch 20.241), train_loss = 1.13219782, grad/param norm = 2.4720e-01, time/batch = 18.2801s	
12085/29850 (epoch 20.243), train_loss = 1.06920297, grad/param norm = 1.9506e-01, time/batch = 15.8147s	
12086/29850 (epoch 20.245), train_loss = 0.98157735, grad/param norm = 1.9336e-01, time/batch = 18.2918s	
12087/29850 (epoch 20.246), train_loss = 0.91804129, grad/param norm = 1.6580e-01, time/batch = 16.2791s	
12088/29850 (epoch 20.248), train_loss = 0.91955473, grad/param norm = 1.8389e-01, time/batch = 19.6133s	
12089/29850 (epoch 20.250), train_loss = 0.98626558, grad/param norm = 1.7419e-01, time/batch = 17.2273s	
12090/29850 (epoch 20.251), train_loss = 0.90482858, grad/param norm = 1.9134e-01, time/batch = 16.5421s	
12091/29850 (epoch 20.253), train_loss = 0.86210002, grad/param norm = 2.1633e-01, time/batch = 18.0365s	
12092/29850 (epoch 20.255), train_loss = 0.92998114, grad/param norm = 1.7731e-01, time/batch = 17.1998s	
12093/29850 (epoch 20.256), train_loss = 1.07244290, grad/param norm = 1.9770e-01, time/batch = 19.1351s	
12094/29850 (epoch 20.258), train_loss = 1.04355747, grad/param norm = 1.9651e-01, time/batch = 18.1949s	
12095/29850 (epoch 20.260), train_loss = 1.00164811, grad/param norm = 1.7534e-01, time/batch = 16.2939s	
12096/29850 (epoch 20.261), train_loss = 0.94072909, grad/param norm = 1.8910e-01, time/batch = 17.2187s	
12097/29850 (epoch 20.263), train_loss = 0.93607266, grad/param norm = 1.7837e-01, time/batch = 17.0362s	
12098/29850 (epoch 20.265), train_loss = 0.99331620, grad/param norm = 1.7512e-01, time/batch = 18.0550s	
12099/29850 (epoch 20.266), train_loss = 1.00109321, grad/param norm = 1.9522e-01, time/batch = 16.7067s	
12100/29850 (epoch 20.268), train_loss = 0.95959668, grad/param norm = 1.7388e-01, time/batch = 15.4079s	
12101/29850 (epoch 20.270), train_loss = 0.95764288, grad/param norm = 1.8405e-01, time/batch = 17.1139s	
12102/29850 (epoch 20.271), train_loss = 1.10311432, grad/param norm = 1.8844e-01, time/batch = 16.6162s	
12103/29850 (epoch 20.273), train_loss = 0.88787322, grad/param norm = 2.0437e-01, time/batch = 17.6023s	
12104/29850 (epoch 20.275), train_loss = 0.87806980, grad/param norm = 1.9148e-01, time/batch = 17.3024s	
12105/29850 (epoch 20.276), train_loss = 0.90775441, grad/param norm = 1.7631e-01, time/batch = 20.0021s	
12106/29850 (epoch 20.278), train_loss = 0.97497466, grad/param norm = 1.7672e-01, time/batch = 15.5652s	
12107/29850 (epoch 20.280), train_loss = 1.17799749, grad/param norm = 2.1521e-01, time/batch = 16.4794s	
12108/29850 (epoch 20.281), train_loss = 1.08033118, grad/param norm = 2.0926e-01, time/batch = 16.4657s	
12109/29850 (epoch 20.283), train_loss = 1.18370928, grad/param norm = 2.1147e-01, time/batch = 18.2948s	
12110/29850 (epoch 20.285), train_loss = 1.00376218, grad/param norm = 1.9121e-01, time/batch = 18.3803s	
12111/29850 (epoch 20.286), train_loss = 1.13667564, grad/param norm = 2.1241e-01, time/batch = 16.3433s	
12112/29850 (epoch 20.288), train_loss = 1.16149117, grad/param norm = 2.3021e-01, time/batch = 19.3017s	
12113/29850 (epoch 20.290), train_loss = 1.04056714, grad/param norm = 1.8617e-01, time/batch = 17.4682s	
12114/29850 (epoch 20.291), train_loss = 1.24680532, grad/param norm = 2.0444e-01, time/batch = 18.4400s	
12115/29850 (epoch 20.293), train_loss = 1.12675297, grad/param norm = 2.2676e-01, time/batch = 15.5496s	
12116/29850 (epoch 20.295), train_loss = 1.21136677, grad/param norm = 2.2219e-01, time/batch = 18.0601s	
12117/29850 (epoch 20.296), train_loss = 0.95627649, grad/param norm = 2.0348e-01, time/batch = 18.3050s	
12118/29850 (epoch 20.298), train_loss = 0.83113634, grad/param norm = 1.7155e-01, time/batch = 15.4675s	
12119/29850 (epoch 20.300), train_loss = 0.91032268, grad/param norm = 1.7071e-01, time/batch = 16.1402s	
12120/29850 (epoch 20.302), train_loss = 0.88166542, grad/param norm = 1.6955e-01, time/batch = 17.6038s	
12121/29850 (epoch 20.303), train_loss = 0.95387544, grad/param norm = 1.9194e-01, time/batch = 18.0471s	
12122/29850 (epoch 20.305), train_loss = 1.07619085, grad/param norm = 1.8715e-01, time/batch = 17.7172s	
12123/29850 (epoch 20.307), train_loss = 1.11779370, grad/param norm = 1.9415e-01, time/batch = 16.4734s	
12124/29850 (epoch 20.308), train_loss = 0.97551162, grad/param norm = 1.9866e-01, time/batch = 16.9793s	
12125/29850 (epoch 20.310), train_loss = 1.06777094, grad/param norm = 2.0393e-01, time/batch = 16.9640s	
12126/29850 (epoch 20.312), train_loss = 1.10258008, grad/param norm = 1.8993e-01, time/batch = 17.1272s	
12127/29850 (epoch 20.313), train_loss = 1.02702029, grad/param norm = 1.8899e-01, time/batch = 18.6773s	
12128/29850 (epoch 20.315), train_loss = 1.04718106, grad/param norm = 1.9407e-01, time/batch = 17.9654s	
12129/29850 (epoch 20.317), train_loss = 1.04348065, grad/param norm = 2.0181e-01, time/batch = 18.1162s	
12130/29850 (epoch 20.318), train_loss = 1.04300945, grad/param norm = 1.9640e-01, time/batch = 16.9849s	
12131/29850 (epoch 20.320), train_loss = 0.95676017, grad/param norm = 1.6849e-01, time/batch = 17.8798s	
12132/29850 (epoch 20.322), train_loss = 1.19303797, grad/param norm = 2.1567e-01, time/batch = 17.6079s	
12133/29850 (epoch 20.323), train_loss = 1.10564701, grad/param norm = 2.1383e-01, time/batch = 17.6298s	
12134/29850 (epoch 20.325), train_loss = 1.12525794, grad/param norm = 1.9716e-01, time/batch = 17.7129s	
12135/29850 (epoch 20.327), train_loss = 1.23855399, grad/param norm = 2.2522e-01, time/batch = 17.5172s	
12136/29850 (epoch 20.328), train_loss = 1.19724675, grad/param norm = 2.2596e-01, time/batch = 17.7046s	
12137/29850 (epoch 20.330), train_loss = 1.08292967, grad/param norm = 1.9259e-01, time/batch = 16.2857s	
12138/29850 (epoch 20.332), train_loss = 0.99908215, grad/param norm = 1.8357e-01, time/batch = 18.2821s	
12139/29850 (epoch 20.333), train_loss = 1.16612708, grad/param norm = 2.1383e-01, time/batch = 18.2903s	
12140/29850 (epoch 20.335), train_loss = 1.15196488, grad/param norm = 2.0381e-01, time/batch = 17.1367s	
12141/29850 (epoch 20.337), train_loss = 1.07063573, grad/param norm = 1.9676e-01, time/batch = 17.8966s	
12142/29850 (epoch 20.338), train_loss = 1.06485206, grad/param norm = 1.8046e-01, time/batch = 15.9377s	
12143/29850 (epoch 20.340), train_loss = 0.95666082, grad/param norm = 1.8982e-01, time/batch = 19.1199s	
12144/29850 (epoch 20.342), train_loss = 1.06017150, grad/param norm = 2.0633e-01, time/batch = 17.4561s	
12145/29850 (epoch 20.343), train_loss = 1.09386424, grad/param norm = 2.2653e-01, time/batch = 15.7192s	
12146/29850 (epoch 20.345), train_loss = 1.11447901, grad/param norm = 2.5285e-01, time/batch = 19.7074s	
12147/29850 (epoch 20.347), train_loss = 1.13872384, grad/param norm = 2.0312e-01, time/batch = 17.3787s	
12148/29850 (epoch 20.348), train_loss = 0.98578564, grad/param norm = 1.8020e-01, time/batch = 18.6815s	
12149/29850 (epoch 20.350), train_loss = 1.11664553, grad/param norm = 2.1316e-01, time/batch = 16.0393s	
12150/29850 (epoch 20.352), train_loss = 0.98441822, grad/param norm = 1.7266e-01, time/batch = 17.3950s	
12151/29850 (epoch 20.353), train_loss = 1.10263197, grad/param norm = 1.8821e-01, time/batch = 15.6226s	
12152/29850 (epoch 20.355), train_loss = 0.96605061, grad/param norm = 1.9160e-01, time/batch = 16.2146s	
12153/29850 (epoch 20.357), train_loss = 1.19345892, grad/param norm = 2.1365e-01, time/batch = 17.7046s	
12154/29850 (epoch 20.358), train_loss = 0.96889956, grad/param norm = 1.9791e-01, time/batch = 18.3627s	
12155/29850 (epoch 20.360), train_loss = 1.04359378, grad/param norm = 1.9848e-01, time/batch = 18.3666s	
12156/29850 (epoch 20.362), train_loss = 1.05103106, grad/param norm = 2.0657e-01, time/batch = 18.1332s	
12157/29850 (epoch 20.363), train_loss = 1.08477324, grad/param norm = 2.1172e-01, time/batch = 18.8848s	
12158/29850 (epoch 20.365), train_loss = 1.20852878, grad/param norm = 2.1780e-01, time/batch = 17.8805s	
12159/29850 (epoch 20.367), train_loss = 0.99830923, grad/param norm = 2.0806e-01, time/batch = 16.7637s	
12160/29850 (epoch 20.369), train_loss = 0.91656915, grad/param norm = 1.8552e-01, time/batch = 17.7032s	
12161/29850 (epoch 20.370), train_loss = 0.86443140, grad/param norm = 2.0161e-01, time/batch = 19.5413s	
12162/29850 (epoch 20.372), train_loss = 1.16402829, grad/param norm = 2.1947e-01, time/batch = 17.3028s	
12163/29850 (epoch 20.374), train_loss = 1.09729775, grad/param norm = 2.0090e-01, time/batch = 17.5321s	
12164/29850 (epoch 20.375), train_loss = 1.04809710, grad/param norm = 1.9125e-01, time/batch = 18.4636s	
12165/29850 (epoch 20.377), train_loss = 1.01956126, grad/param norm = 2.0919e-01, time/batch = 17.6128s	
12166/29850 (epoch 20.379), train_loss = 1.15372527, grad/param norm = 2.2126e-01, time/batch = 17.7741s	
12167/29850 (epoch 20.380), train_loss = 1.09706928, grad/param norm = 1.9144e-01, time/batch = 17.4768s	
12168/29850 (epoch 20.382), train_loss = 1.09723674, grad/param norm = 2.0651e-01, time/batch = 16.6303s	
12169/29850 (epoch 20.384), train_loss = 1.09550848, grad/param norm = 1.9711e-01, time/batch = 16.2794s	
12170/29850 (epoch 20.385), train_loss = 1.04888382, grad/param norm = 2.0345e-01, time/batch = 16.3839s	
12171/29850 (epoch 20.387), train_loss = 1.11501292, grad/param norm = 2.0911e-01, time/batch = 18.0545s	
12172/29850 (epoch 20.389), train_loss = 1.21192137, grad/param norm = 2.1369e-01, time/batch = 18.0381s	
12173/29850 (epoch 20.390), train_loss = 1.11184036, grad/param norm = 1.8508e-01, time/batch = 18.4640s	
12174/29850 (epoch 20.392), train_loss = 1.03546863, grad/param norm = 2.1190e-01, time/batch = 18.7115s	
12175/29850 (epoch 20.394), train_loss = 1.14692229, grad/param norm = 1.8751e-01, time/batch = 19.2912s	
12176/29850 (epoch 20.395), train_loss = 1.03176775, grad/param norm = 1.9461e-01, time/batch = 17.3829s	
12177/29850 (epoch 20.397), train_loss = 0.93876330, grad/param norm = 1.9109e-01, time/batch = 18.3894s	
12178/29850 (epoch 20.399), train_loss = 0.96470054, grad/param norm = 1.8288e-01, time/batch = 19.0471s	
12179/29850 (epoch 20.400), train_loss = 1.35232353, grad/param norm = 2.2268e-01, time/batch = 15.8074s	
12180/29850 (epoch 20.402), train_loss = 1.22658498, grad/param norm = 1.9302e-01, time/batch = 18.7865s	
12181/29850 (epoch 20.404), train_loss = 1.10237873, grad/param norm = 2.1517e-01, time/batch = 19.2886s	
12182/29850 (epoch 20.405), train_loss = 0.99654438, grad/param norm = 2.0332e-01, time/batch = 17.1081s	
12183/29850 (epoch 20.407), train_loss = 0.97945461, grad/param norm = 1.8738e-01, time/batch = 16.1112s	
12184/29850 (epoch 20.409), train_loss = 1.12549335, grad/param norm = 2.0107e-01, time/batch = 16.1354s	
12185/29850 (epoch 20.410), train_loss = 1.22920886, grad/param norm = 2.3085e-01, time/batch = 18.2182s	
12186/29850 (epoch 20.412), train_loss = 1.16668352, grad/param norm = 2.0284e-01, time/batch = 16.9571s	
12187/29850 (epoch 20.414), train_loss = 1.06515367, grad/param norm = 2.1488e-01, time/batch = 16.3721s	
12188/29850 (epoch 20.415), train_loss = 1.05813250, grad/param norm = 1.9314e-01, time/batch = 18.9620s	
12189/29850 (epoch 20.417), train_loss = 1.22004296, grad/param norm = 2.0399e-01, time/batch = 16.7011s	
12190/29850 (epoch 20.419), train_loss = 1.06956683, grad/param norm = 2.0387e-01, time/batch = 17.5483s	
12191/29850 (epoch 20.420), train_loss = 1.06022586, grad/param norm = 1.8560e-01, time/batch = 17.2757s	
12192/29850 (epoch 20.422), train_loss = 1.03899904, grad/param norm = 1.8827e-01, time/batch = 18.4637s	
12193/29850 (epoch 20.424), train_loss = 1.00862298, grad/param norm = 1.9658e-01, time/batch = 18.7710s	
12194/29850 (epoch 20.425), train_loss = 1.17003614, grad/param norm = 2.0300e-01, time/batch = 18.6450s	
12195/29850 (epoch 20.427), train_loss = 0.87916677, grad/param norm = 1.7786e-01, time/batch = 17.4701s	
12196/29850 (epoch 20.429), train_loss = 0.96254015, grad/param norm = 1.8412e-01, time/batch = 16.6151s	
12197/29850 (epoch 20.430), train_loss = 0.89314942, grad/param norm = 1.8205e-01, time/batch = 19.0388s	
12198/29850 (epoch 20.432), train_loss = 1.02493215, grad/param norm = 2.2417e-01, time/batch = 15.5466s	
12199/29850 (epoch 20.434), train_loss = 0.92529701, grad/param norm = 1.6765e-01, time/batch = 17.2684s	
12200/29850 (epoch 20.436), train_loss = 1.05317734, grad/param norm = 1.9490e-01, time/batch = 18.8689s	
12201/29850 (epoch 20.437), train_loss = 1.11627365, grad/param norm = 1.9191e-01, time/batch = 17.9718s	
12202/29850 (epoch 20.439), train_loss = 1.08346520, grad/param norm = 2.0124e-01, time/batch = 16.8713s	
12203/29850 (epoch 20.441), train_loss = 1.07752145, grad/param norm = 1.9478e-01, time/batch = 18.4375s	
12204/29850 (epoch 20.442), train_loss = 1.06603169, grad/param norm = 1.9419e-01, time/batch = 14.6451s	
12205/29850 (epoch 20.444), train_loss = 1.07862994, grad/param norm = 2.0134e-01, time/batch = 17.3854s	
12206/29850 (epoch 20.446), train_loss = 1.11784022, grad/param norm = 1.8599e-01, time/batch = 17.2156s	
12207/29850 (epoch 20.447), train_loss = 1.12715433, grad/param norm = 2.0785e-01, time/batch = 18.1206s	
12208/29850 (epoch 20.449), train_loss = 1.07194845, grad/param norm = 2.0358e-01, time/batch = 17.0917s	
12209/29850 (epoch 20.451), train_loss = 0.88862709, grad/param norm = 1.7955e-01, time/batch = 17.7197s	
12210/29850 (epoch 20.452), train_loss = 0.79195302, grad/param norm = 1.5822e-01, time/batch = 16.7994s	
12211/29850 (epoch 20.454), train_loss = 0.91031005, grad/param norm = 1.7769e-01, time/batch = 18.1422s	
12212/29850 (epoch 20.456), train_loss = 1.10299731, grad/param norm = 2.0250e-01, time/batch = 19.0526s	
12213/29850 (epoch 20.457), train_loss = 1.10772172, grad/param norm = 2.4504e-01, time/batch = 16.9361s	
12214/29850 (epoch 20.459), train_loss = 1.22969927, grad/param norm = 2.2132e-01, time/batch = 17.7112s	
12215/29850 (epoch 20.461), train_loss = 1.20243050, grad/param norm = 1.8583e-01, time/batch = 18.7940s	
12216/29850 (epoch 20.462), train_loss = 1.18190036, grad/param norm = 2.0501e-01, time/batch = 17.6966s	
12217/29850 (epoch 20.464), train_loss = 1.12432220, grad/param norm = 2.1031e-01, time/batch = 17.0593s	
12218/29850 (epoch 20.466), train_loss = 0.93788960, grad/param norm = 2.0391e-01, time/batch = 16.4625s	
12219/29850 (epoch 20.467), train_loss = 1.04974241, grad/param norm = 2.1274e-01, time/batch = 16.6269s	
12220/29850 (epoch 20.469), train_loss = 1.03186357, grad/param norm = 1.9829e-01, time/batch = 14.4931s	
12221/29850 (epoch 20.471), train_loss = 1.03644819, grad/param norm = 1.9080e-01, time/batch = 16.9653s	
12222/29850 (epoch 20.472), train_loss = 1.00029630, grad/param norm = 1.8163e-01, time/batch = 16.1880s	
12223/29850 (epoch 20.474), train_loss = 1.15324073, grad/param norm = 1.8230e-01, time/batch = 18.1843s	
12224/29850 (epoch 20.476), train_loss = 1.07189299, grad/param norm = 1.7941e-01, time/batch = 19.2124s	
12225/29850 (epoch 20.477), train_loss = 1.08201790, grad/param norm = 2.2676e-01, time/batch = 19.7081s	
12226/29850 (epoch 20.479), train_loss = 1.21502536, grad/param norm = 2.1313e-01, time/batch = 16.5322s	
12227/29850 (epoch 20.481), train_loss = 1.03951888, grad/param norm = 1.8381e-01, time/batch = 16.1060s	
12228/29850 (epoch 20.482), train_loss = 0.98202964, grad/param norm = 1.7326e-01, time/batch = 17.8001s	
12229/29850 (epoch 20.484), train_loss = 0.99127032, grad/param norm = 1.8117e-01, time/batch = 18.5531s	
12230/29850 (epoch 20.486), train_loss = 1.10279659, grad/param norm = 2.0506e-01, time/batch = 17.5384s	
12231/29850 (epoch 20.487), train_loss = 1.05815261, grad/param norm = 2.0905e-01, time/batch = 17.7110s	
12232/29850 (epoch 20.489), train_loss = 1.04726407, grad/param norm = 1.9616e-01, time/batch = 18.7043s	
12233/29850 (epoch 20.491), train_loss = 0.93952448, grad/param norm = 1.7471e-01, time/batch = 17.7806s	
12234/29850 (epoch 20.492), train_loss = 1.05892133, grad/param norm = 1.9412e-01, time/batch = 16.7181s	
12235/29850 (epoch 20.494), train_loss = 1.16259166, grad/param norm = 1.8590e-01, time/batch = 17.7136s	
12236/29850 (epoch 20.496), train_loss = 1.21742361, grad/param norm = 1.9639e-01, time/batch = 17.5639s	
12237/29850 (epoch 20.497), train_loss = 1.11444137, grad/param norm = 1.7781e-01, time/batch = 15.6761s	
12238/29850 (epoch 20.499), train_loss = 1.06187733, grad/param norm = 1.9060e-01, time/batch = 15.5366s	
12239/29850 (epoch 20.501), train_loss = 0.99453318, grad/param norm = 1.9563e-01, time/batch = 18.4574s	
12240/29850 (epoch 20.503), train_loss = 1.05024054, grad/param norm = 1.8158e-01, time/batch = 17.3901s	
12241/29850 (epoch 20.504), train_loss = 1.29937134, grad/param norm = 2.0730e-01, time/batch = 16.6375s	
12242/29850 (epoch 20.506), train_loss = 1.22262018, grad/param norm = 2.1913e-01, time/batch = 18.5482s	
12243/29850 (epoch 20.508), train_loss = 1.08032192, grad/param norm = 2.0542e-01, time/batch = 18.7099s	
12244/29850 (epoch 20.509), train_loss = 0.86512364, grad/param norm = 1.8204e-01, time/batch = 16.0918s	
12245/29850 (epoch 20.511), train_loss = 1.07261311, grad/param norm = 1.8879e-01, time/batch = 17.4759s	
12246/29850 (epoch 20.513), train_loss = 1.08961304, grad/param norm = 2.1494e-01, time/batch = 17.7211s	
12247/29850 (epoch 20.514), train_loss = 0.94807049, grad/param norm = 1.9634e-01, time/batch = 16.6345s	
12248/29850 (epoch 20.516), train_loss = 0.99893514, grad/param norm = 1.8824e-01, time/batch = 17.3932s	
12249/29850 (epoch 20.518), train_loss = 0.89729540, grad/param norm = 2.0790e-01, time/batch = 19.0376s	
12250/29850 (epoch 20.519), train_loss = 0.89339145, grad/param norm = 1.8524e-01, time/batch = 18.6163s	
12251/29850 (epoch 20.521), train_loss = 0.86571962, grad/param norm = 1.6899e-01, time/batch = 15.7178s	
12252/29850 (epoch 20.523), train_loss = 0.90875571, grad/param norm = 1.6334e-01, time/batch = 17.1460s	
12253/29850 (epoch 20.524), train_loss = 1.00442289, grad/param norm = 2.1082e-01, time/batch = 17.3129s	
12254/29850 (epoch 20.526), train_loss = 1.06761371, grad/param norm = 2.0346e-01, time/batch = 16.6299s	
12255/29850 (epoch 20.528), train_loss = 1.14097175, grad/param norm = 2.0824e-01, time/batch = 17.4555s	
12256/29850 (epoch 20.529), train_loss = 1.07690239, grad/param norm = 1.8527e-01, time/batch = 16.2893s	
12257/29850 (epoch 20.531), train_loss = 1.03085658, grad/param norm = 2.0185e-01, time/batch = 17.2867s	
12258/29850 (epoch 20.533), train_loss = 1.00034269, grad/param norm = 1.8355e-01, time/batch = 18.4256s	
12259/29850 (epoch 20.534), train_loss = 1.05851689, grad/param norm = 1.8771e-01, time/batch = 17.3847s	
12260/29850 (epoch 20.536), train_loss = 1.00899387, grad/param norm = 2.1488e-01, time/batch = 19.7007s	
12261/29850 (epoch 20.538), train_loss = 1.17154886, grad/param norm = 2.1504e-01, time/batch = 18.4574s	
12262/29850 (epoch 20.539), train_loss = 1.22856653, grad/param norm = 2.1555e-01, time/batch = 19.0999s	
12263/29850 (epoch 20.541), train_loss = 0.83833580, grad/param norm = 1.6727e-01, time/batch = 18.6121s	
12264/29850 (epoch 20.543), train_loss = 1.05211508, grad/param norm = 1.8316e-01, time/batch = 17.0254s	
12265/29850 (epoch 20.544), train_loss = 1.09679340, grad/param norm = 2.0915e-01, time/batch = 17.9497s	
12266/29850 (epoch 20.546), train_loss = 1.15004221, grad/param norm = 2.0207e-01, time/batch = 18.7150s	
12267/29850 (epoch 20.548), train_loss = 0.91269482, grad/param norm = 1.7127e-01, time/batch = 17.4492s	
12268/29850 (epoch 20.549), train_loss = 1.00901843, grad/param norm = 1.8846e-01, time/batch = 18.4467s	
12269/29850 (epoch 20.551), train_loss = 0.92102593, grad/param norm = 1.7081e-01, time/batch = 17.2930s	
12270/29850 (epoch 20.553), train_loss = 1.04521186, grad/param norm = 1.8782e-01, time/batch = 17.9466s	
12271/29850 (epoch 20.554), train_loss = 0.89749638, grad/param norm = 1.7830e-01, time/batch = 17.3800s	
12272/29850 (epoch 20.556), train_loss = 0.97595248, grad/param norm = 1.9718e-01, time/batch = 16.7819s	
12273/29850 (epoch 20.558), train_loss = 0.96082564, grad/param norm = 1.8172e-01, time/batch = 16.7852s	
12274/29850 (epoch 20.559), train_loss = 1.00780650, grad/param norm = 1.7784e-01, time/batch = 18.2865s	
12275/29850 (epoch 20.561), train_loss = 1.10027607, grad/param norm = 2.0179e-01, time/batch = 19.6182s	
12276/29850 (epoch 20.563), train_loss = 1.05840842, grad/param norm = 1.9703e-01, time/batch = 17.9745s	
12277/29850 (epoch 20.564), train_loss = 1.02405769, grad/param norm = 1.9654e-01, time/batch = 17.9522s	
12278/29850 (epoch 20.566), train_loss = 1.06622828, grad/param norm = 2.0885e-01, time/batch = 17.1301s	
12279/29850 (epoch 20.568), train_loss = 1.15782372, grad/param norm = 2.0478e-01, time/batch = 18.0562s	
12280/29850 (epoch 20.570), train_loss = 1.08051877, grad/param norm = 1.9763e-01, time/batch = 18.8017s	
12281/29850 (epoch 20.571), train_loss = 1.12942872, grad/param norm = 2.0027e-01, time/batch = 15.0328s	
12282/29850 (epoch 20.573), train_loss = 1.22490355, grad/param norm = 2.3391e-01, time/batch = 19.6227s	
12283/29850 (epoch 20.575), train_loss = 1.17596567, grad/param norm = 1.8857e-01, time/batch = 17.3807s	
12284/29850 (epoch 20.576), train_loss = 1.14433030, grad/param norm = 2.0412e-01, time/batch = 24.2776s	
12285/29850 (epoch 20.578), train_loss = 0.99473207, grad/param norm = 1.8352e-01, time/batch = 24.5351s	
12286/29850 (epoch 20.580), train_loss = 1.17630308, grad/param norm = 1.9421e-01, time/batch = 16.8951s	
12287/29850 (epoch 20.581), train_loss = 0.99216636, grad/param norm = 1.9433e-01, time/batch = 15.7878s	
12288/29850 (epoch 20.583), train_loss = 1.05266134, grad/param norm = 2.0525e-01, time/batch = 16.9832s	
12289/29850 (epoch 20.585), train_loss = 1.09227635, grad/param norm = 2.0498e-01, time/batch = 17.1382s	
12290/29850 (epoch 20.586), train_loss = 1.08615599, grad/param norm = 1.9324e-01, time/batch = 17.8015s	
12291/29850 (epoch 20.588), train_loss = 1.01962988, grad/param norm = 1.9792e-01, time/batch = 16.8557s	
12292/29850 (epoch 20.590), train_loss = 1.03039664, grad/param norm = 1.8975e-01, time/batch = 15.2043s	
12293/29850 (epoch 20.591), train_loss = 1.01025771, grad/param norm = 2.0929e-01, time/batch = 18.8750s	
12294/29850 (epoch 20.593), train_loss = 0.97350664, grad/param norm = 1.8428e-01, time/batch = 17.0418s	
12295/29850 (epoch 20.595), train_loss = 0.91541555, grad/param norm = 1.5581e-01, time/batch = 19.0502s	
12296/29850 (epoch 20.596), train_loss = 0.90350084, grad/param norm = 1.9092e-01, time/batch = 18.9575s	
12297/29850 (epoch 20.598), train_loss = 1.00799382, grad/param norm = 1.7103e-01, time/batch = 17.5231s	
12298/29850 (epoch 20.600), train_loss = 1.11139106, grad/param norm = 2.0784e-01, time/batch = 18.3069s	
12299/29850 (epoch 20.601), train_loss = 0.92218170, grad/param norm = 1.7251e-01, time/batch = 17.2208s	
12300/29850 (epoch 20.603), train_loss = 1.00025170, grad/param norm = 1.9260e-01, time/batch = 18.1326s	
12301/29850 (epoch 20.605), train_loss = 1.01173235, grad/param norm = 1.8695e-01, time/batch = 18.1210s	
12302/29850 (epoch 20.606), train_loss = 0.79418170, grad/param norm = 1.5882e-01, time/batch = 17.6381s	
12303/29850 (epoch 20.608), train_loss = 0.97651575, grad/param norm = 1.8252e-01, time/batch = 17.2034s	
12304/29850 (epoch 20.610), train_loss = 1.02932822, grad/param norm = 2.0635e-01, time/batch = 15.9443s	
12305/29850 (epoch 20.611), train_loss = 0.96249454, grad/param norm = 1.8802e-01, time/batch = 17.4535s	
12306/29850 (epoch 20.613), train_loss = 0.80994905, grad/param norm = 1.6402e-01, time/batch = 18.4553s	
12307/29850 (epoch 20.615), train_loss = 0.92504582, grad/param norm = 1.7467e-01, time/batch = 17.3536s	
12308/29850 (epoch 20.616), train_loss = 0.91243968, grad/param norm = 1.9312e-01, time/batch = 17.0319s	
12309/29850 (epoch 20.618), train_loss = 1.01043518, grad/param norm = 1.9145e-01, time/batch = 17.1360s	
12310/29850 (epoch 20.620), train_loss = 1.07444089, grad/param norm = 1.9187e-01, time/batch = 18.7094s	
12311/29850 (epoch 20.621), train_loss = 1.18011445, grad/param norm = 2.2230e-01, time/batch = 16.6122s	
12312/29850 (epoch 20.623), train_loss = 1.09844139, grad/param norm = 1.8737e-01, time/batch = 18.3023s	
12313/29850 (epoch 20.625), train_loss = 1.07344668, grad/param norm = 2.3796e-01, time/batch = 18.5407s	
12314/29850 (epoch 20.626), train_loss = 1.08728279, grad/param norm = 1.8845e-01, time/batch = 15.8470s	
12315/29850 (epoch 20.628), train_loss = 0.93498187, grad/param norm = 1.6807e-01, time/batch = 19.2574s	
12316/29850 (epoch 20.630), train_loss = 1.02559977, grad/param norm = 1.7352e-01, time/batch = 18.3905s	
12317/29850 (epoch 20.631), train_loss = 1.01181103, grad/param norm = 1.8714e-01, time/batch = 17.6130s	
12318/29850 (epoch 20.633), train_loss = 1.11595243, grad/param norm = 2.1298e-01, time/batch = 3.5726s	
12319/29850 (epoch 20.635), train_loss = 1.00036993, grad/param norm = 2.0115e-01, time/batch = 0.6769s	
12320/29850 (epoch 20.637), train_loss = 0.95242816, grad/param norm = 1.8454e-01, time/batch = 0.6674s	
12321/29850 (epoch 20.638), train_loss = 1.06584950, grad/param norm = 2.2223e-01, time/batch = 0.6727s	
12322/29850 (epoch 20.640), train_loss = 1.18160636, grad/param norm = 2.0510e-01, time/batch = 0.6681s	
12323/29850 (epoch 20.642), train_loss = 0.96942429, grad/param norm = 1.6703e-01, time/batch = 0.6575s	
12324/29850 (epoch 20.643), train_loss = 0.95848612, grad/param norm = 2.0532e-01, time/batch = 0.6560s	
12325/29850 (epoch 20.645), train_loss = 1.02610212, grad/param norm = 1.9459e-01, time/batch = 0.7841s	
12326/29850 (epoch 20.647), train_loss = 1.15337168, grad/param norm = 1.8782e-01, time/batch = 0.9915s	
12327/29850 (epoch 20.648), train_loss = 0.91521978, grad/param norm = 1.7058e-01, time/batch = 0.9681s	
12328/29850 (epoch 20.650), train_loss = 1.05718303, grad/param norm = 1.8827e-01, time/batch = 0.9612s	
12329/29850 (epoch 20.652), train_loss = 1.06373597, grad/param norm = 1.9579e-01, time/batch = 0.9681s	
12330/29850 (epoch 20.653), train_loss = 1.14661435, grad/param norm = 2.0829e-01, time/batch = 1.1973s	
12331/29850 (epoch 20.655), train_loss = 1.02207278, grad/param norm = 1.8289e-01, time/batch = 1.8046s	
12332/29850 (epoch 20.657), train_loss = 0.96400347, grad/param norm = 1.7803e-01, time/batch = 1.8023s	
12333/29850 (epoch 20.658), train_loss = 1.13403171, grad/param norm = 1.9219e-01, time/batch = 9.9742s	
12334/29850 (epoch 20.660), train_loss = 1.04152585, grad/param norm = 2.1089e-01, time/batch = 17.7082s	
12335/29850 (epoch 20.662), train_loss = 1.10385422, grad/param norm = 2.1216e-01, time/batch = 17.8699s	
12336/29850 (epoch 20.663), train_loss = 1.22123976, grad/param norm = 2.0875e-01, time/batch = 17.7846s	
12337/29850 (epoch 20.665), train_loss = 1.16391226, grad/param norm = 2.1013e-01, time/batch = 16.4657s	
12338/29850 (epoch 20.667), train_loss = 1.11168781, grad/param norm = 2.4041e-01, time/batch = 19.6266s	
12339/29850 (epoch 20.668), train_loss = 1.03301723, grad/param norm = 2.0444e-01, time/batch = 18.6989s	
12340/29850 (epoch 20.670), train_loss = 1.19376346, grad/param norm = 2.3424e-01, time/batch = 17.5491s	
12341/29850 (epoch 20.672), train_loss = 1.15738880, grad/param norm = 2.0855e-01, time/batch = 17.7415s	
12342/29850 (epoch 20.673), train_loss = 1.11599577, grad/param norm = 2.0725e-01, time/batch = 16.2196s	
12343/29850 (epoch 20.675), train_loss = 0.95435471, grad/param norm = 1.9437e-01, time/batch = 19.2050s	
12344/29850 (epoch 20.677), train_loss = 1.01484819, grad/param norm = 2.0066e-01, time/batch = 18.6148s	
12345/29850 (epoch 20.678), train_loss = 1.01698911, grad/param norm = 1.9766e-01, time/batch = 17.2816s	
12346/29850 (epoch 20.680), train_loss = 1.05868863, grad/param norm = 2.0133e-01, time/batch = 17.7073s	
12347/29850 (epoch 20.682), train_loss = 1.06773705, grad/param norm = 2.3719e-01, time/batch = 15.3200s	
12348/29850 (epoch 20.683), train_loss = 1.17160720, grad/param norm = 2.0104e-01, time/batch = 19.1255s	
12349/29850 (epoch 20.685), train_loss = 1.20666223, grad/param norm = 1.8502e-01, time/batch = 15.5974s	
12350/29850 (epoch 20.687), train_loss = 1.11738490, grad/param norm = 2.0515e-01, time/batch = 17.9550s	
12351/29850 (epoch 20.688), train_loss = 0.91352152, grad/param norm = 1.7980e-01, time/batch = 17.0624s	
12352/29850 (epoch 20.690), train_loss = 0.93745593, grad/param norm = 2.0301e-01, time/batch = 17.3114s	
12353/29850 (epoch 20.692), train_loss = 1.14476072, grad/param norm = 1.9404e-01, time/batch = 17.7937s	
12354/29850 (epoch 20.693), train_loss = 1.01903547, grad/param norm = 1.7372e-01, time/batch = 16.1388s	
12355/29850 (epoch 20.695), train_loss = 0.91767086, grad/param norm = 1.7073e-01, time/batch = 18.0529s	
12356/29850 (epoch 20.697), train_loss = 1.03743076, grad/param norm = 1.9736e-01, time/batch = 18.8541s	
12357/29850 (epoch 20.698), train_loss = 1.16582377, grad/param norm = 1.9487e-01, time/batch = 17.3760s	
12358/29850 (epoch 20.700), train_loss = 1.10226789, grad/param norm = 2.2508e-01, time/batch = 18.3703s	
12359/29850 (epoch 20.702), train_loss = 1.01376612, grad/param norm = 1.9737e-01, time/batch = 16.0397s	
12360/29850 (epoch 20.704), train_loss = 0.93658776, grad/param norm = 1.7169e-01, time/batch = 18.7168s	
12361/29850 (epoch 20.705), train_loss = 1.05800516, grad/param norm = 2.0002e-01, time/batch = 17.3020s	
12362/29850 (epoch 20.707), train_loss = 0.96728968, grad/param norm = 1.8514e-01, time/batch = 16.7684s	
12363/29850 (epoch 20.709), train_loss = 1.05217651, grad/param norm = 2.1374e-01, time/batch = 18.1333s	
12364/29850 (epoch 20.710), train_loss = 0.98113599, grad/param norm = 2.0319e-01, time/batch = 17.7906s	
12365/29850 (epoch 20.712), train_loss = 1.03364596, grad/param norm = 1.5964e-01, time/batch = 17.2931s	
12366/29850 (epoch 20.714), train_loss = 1.14125204, grad/param norm = 2.1629e-01, time/batch = 16.2822s	
12367/29850 (epoch 20.715), train_loss = 1.07428944, grad/param norm = 1.9191e-01, time/batch = 18.1334s	
12368/29850 (epoch 20.717), train_loss = 0.82732964, grad/param norm = 1.7697e-01, time/batch = 17.9629s	
12369/29850 (epoch 20.719), train_loss = 0.98213148, grad/param norm = 1.7916e-01, time/batch = 16.3920s	
12370/29850 (epoch 20.720), train_loss = 1.03770840, grad/param norm = 1.7537e-01, time/batch = 18.7709s	
12371/29850 (epoch 20.722), train_loss = 0.98854350, grad/param norm = 1.6447e-01, time/batch = 15.7896s	
12372/29850 (epoch 20.724), train_loss = 1.09013553, grad/param norm = 2.3381e-01, time/batch = 15.7888s	
12373/29850 (epoch 20.725), train_loss = 0.90958561, grad/param norm = 1.7909e-01, time/batch = 15.9622s	
12374/29850 (epoch 20.727), train_loss = 0.97628137, grad/param norm = 2.0546e-01, time/batch = 18.4657s	
12375/29850 (epoch 20.729), train_loss = 0.90046281, grad/param norm = 1.6153e-01, time/batch = 17.8841s	
12376/29850 (epoch 20.730), train_loss = 0.88464512, grad/param norm = 1.7141e-01, time/batch = 15.9437s	
12377/29850 (epoch 20.732), train_loss = 1.12951632, grad/param norm = 1.7635e-01, time/batch = 18.2994s	
12378/29850 (epoch 20.734), train_loss = 1.23396789, grad/param norm = 2.6371e-01, time/batch = 17.8790s	
12379/29850 (epoch 20.735), train_loss = 1.00999216, grad/param norm = 2.1810e-01, time/batch = 18.1259s	
12380/29850 (epoch 20.737), train_loss = 0.95648932, grad/param norm = 2.0273e-01, time/batch = 18.1285s	
12381/29850 (epoch 20.739), train_loss = 0.82884344, grad/param norm = 1.8162e-01, time/batch = 18.9546s	
12382/29850 (epoch 20.740), train_loss = 0.90154464, grad/param norm = 1.7758e-01, time/batch = 17.3883s	
12383/29850 (epoch 20.742), train_loss = 0.87958386, grad/param norm = 1.7690e-01, time/batch = 15.4560s	
12384/29850 (epoch 20.744), train_loss = 0.97726573, grad/param norm = 2.0451e-01, time/batch = 17.0580s	
12385/29850 (epoch 20.745), train_loss = 0.94971014, grad/param norm = 1.9505e-01, time/batch = 15.3933s	
12386/29850 (epoch 20.747), train_loss = 1.01548528, grad/param norm = 1.9544e-01, time/batch = 17.2954s	
12387/29850 (epoch 20.749), train_loss = 0.93011891, grad/param norm = 2.5736e-01, time/batch = 18.0357s	
12388/29850 (epoch 20.750), train_loss = 0.88981167, grad/param norm = 1.9653e-01, time/batch = 16.5268s	
12389/29850 (epoch 20.752), train_loss = 0.81346843, grad/param norm = 1.7185e-01, time/batch = 19.1976s	
12390/29850 (epoch 20.754), train_loss = 0.88856245, grad/param norm = 1.7994e-01, time/batch = 17.1123s	
12391/29850 (epoch 20.755), train_loss = 0.89473596, grad/param norm = 1.8636e-01, time/batch = 18.1240s	
12392/29850 (epoch 20.757), train_loss = 0.95990535, grad/param norm = 1.8961e-01, time/batch = 18.9608s	
12393/29850 (epoch 20.759), train_loss = 0.97476913, grad/param norm = 1.8449e-01, time/batch = 17.4413s	
12394/29850 (epoch 20.760), train_loss = 0.92981884, grad/param norm = 2.1069e-01, time/batch = 19.0475s	
12395/29850 (epoch 20.762), train_loss = 0.88891016, grad/param norm = 1.8195e-01, time/batch = 18.2983s	
12396/29850 (epoch 20.764), train_loss = 0.85859600, grad/param norm = 2.0115e-01, time/batch = 18.6846s	
12397/29850 (epoch 20.765), train_loss = 0.99975006, grad/param norm = 1.9820e-01, time/batch = 17.7016s	
12398/29850 (epoch 20.767), train_loss = 0.98693627, grad/param norm = 1.7383e-01, time/batch = 19.8688s	
12399/29850 (epoch 20.769), train_loss = 0.97876130, grad/param norm = 1.8653e-01, time/batch = 16.6163s	
12400/29850 (epoch 20.771), train_loss = 1.03254895, grad/param norm = 1.9148e-01, time/batch = 15.9555s	
12401/29850 (epoch 20.772), train_loss = 1.05283212, grad/param norm = 2.0540e-01, time/batch = 18.4584s	
12402/29850 (epoch 20.774), train_loss = 0.95123863, grad/param norm = 1.8766e-01, time/batch = 16.6097s	
12403/29850 (epoch 20.776), train_loss = 0.97055731, grad/param norm = 2.1202e-01, time/batch = 18.3707s	
12404/29850 (epoch 20.777), train_loss = 1.09373741, grad/param norm = 2.2347e-01, time/batch = 17.1325s	
12405/29850 (epoch 20.779), train_loss = 0.89712822, grad/param norm = 1.7365e-01, time/batch = 16.3695s	
12406/29850 (epoch 20.781), train_loss = 1.00773551, grad/param norm = 1.9043e-01, time/batch = 17.7983s	
12407/29850 (epoch 20.782), train_loss = 1.07344359, grad/param norm = 2.0346e-01, time/batch = 18.5201s	
12408/29850 (epoch 20.784), train_loss = 0.89517368, grad/param norm = 1.9639e-01, time/batch = 18.3896s	
12409/29850 (epoch 20.786), train_loss = 0.96799274, grad/param norm = 1.7996e-01, time/batch = 15.8706s	
12410/29850 (epoch 20.787), train_loss = 0.86752268, grad/param norm = 1.9279e-01, time/batch = 16.3890s	
12411/29850 (epoch 20.789), train_loss = 0.82339013, grad/param norm = 1.5584e-01, time/batch = 17.8799s	
12412/29850 (epoch 20.791), train_loss = 0.95310362, grad/param norm = 2.0945e-01, time/batch = 18.7230s	
12413/29850 (epoch 20.792), train_loss = 1.07295906, grad/param norm = 2.0058e-01, time/batch = 17.6121s	
12414/29850 (epoch 20.794), train_loss = 1.03867625, grad/param norm = 1.8937e-01, time/batch = 17.7975s	
12415/29850 (epoch 20.796), train_loss = 0.89172067, grad/param norm = 1.7465e-01, time/batch = 18.2173s	
12416/29850 (epoch 20.797), train_loss = 0.81828245, grad/param norm = 1.6695e-01, time/batch = 19.0329s	
12417/29850 (epoch 20.799), train_loss = 0.89048942, grad/param norm = 1.6858e-01, time/batch = 16.1890s	
12418/29850 (epoch 20.801), train_loss = 0.97359398, grad/param norm = 1.9217e-01, time/batch = 17.4765s	
12419/29850 (epoch 20.802), train_loss = 0.82258710, grad/param norm = 1.9075e-01, time/batch = 16.7187s	
12420/29850 (epoch 20.804), train_loss = 0.87076133, grad/param norm = 1.6640e-01, time/batch = 16.2010s	
12421/29850 (epoch 20.806), train_loss = 0.87208863, grad/param norm = 1.6406e-01, time/batch = 17.4473s	
12422/29850 (epoch 20.807), train_loss = 0.82820703, grad/param norm = 1.5511e-01, time/batch = 15.2645s	
12423/29850 (epoch 20.809), train_loss = 0.90150246, grad/param norm = 2.0142e-01, time/batch = 16.2902s	
12424/29850 (epoch 20.811), train_loss = 1.03041215, grad/param norm = 2.0541e-01, time/batch = 17.1437s	
12425/29850 (epoch 20.812), train_loss = 1.02185337, grad/param norm = 2.0687e-01, time/batch = 17.0607s	
12426/29850 (epoch 20.814), train_loss = 1.10372693, grad/param norm = 1.9213e-01, time/batch = 18.5337s	
12427/29850 (epoch 20.816), train_loss = 1.07785622, grad/param norm = 1.6938e-01, time/batch = 16.6367s	
12428/29850 (epoch 20.817), train_loss = 1.00745834, grad/param norm = 1.8898e-01, time/batch = 19.1021s	
12429/29850 (epoch 20.819), train_loss = 0.85038014, grad/param norm = 1.7524e-01, time/batch = 18.7080s	
12430/29850 (epoch 20.821), train_loss = 1.11102173, grad/param norm = 2.3042e-01, time/batch = 18.6050s	
12431/29850 (epoch 20.822), train_loss = 1.11417363, grad/param norm = 2.0180e-01, time/batch = 17.6372s	
12432/29850 (epoch 20.824), train_loss = 0.98525363, grad/param norm = 1.7372e-01, time/batch = 17.8006s	
12433/29850 (epoch 20.826), train_loss = 0.94346391, grad/param norm = 1.8498e-01, time/batch = 18.8646s	
12434/29850 (epoch 20.827), train_loss = 0.88128850, grad/param norm = 1.8765e-01, time/batch = 15.3513s	
12435/29850 (epoch 20.829), train_loss = 1.00735990, grad/param norm = 2.1563e-01, time/batch = 17.7077s	
12436/29850 (epoch 20.831), train_loss = 1.09925608, grad/param norm = 2.0990e-01, time/batch = 16.0517s	
12437/29850 (epoch 20.832), train_loss = 0.99167513, grad/param norm = 1.7798e-01, time/batch = 17.9445s	
12438/29850 (epoch 20.834), train_loss = 0.81775814, grad/param norm = 1.6232e-01, time/batch = 15.9625s	
12439/29850 (epoch 20.836), train_loss = 0.85716023, grad/param norm = 1.6442e-01, time/batch = 16.2970s	
12440/29850 (epoch 20.838), train_loss = 0.98905523, grad/param norm = 1.9708e-01, time/batch = 16.7892s	
12441/29850 (epoch 20.839), train_loss = 0.89110876, grad/param norm = 1.7674e-01, time/batch = 16.3824s	
12442/29850 (epoch 20.841), train_loss = 0.89095204, grad/param norm = 1.7236e-01, time/batch = 18.3888s	
12443/29850 (epoch 20.843), train_loss = 0.86483221, grad/param norm = 1.8462e-01, time/batch = 15.8293s	
12444/29850 (epoch 20.844), train_loss = 0.89034825, grad/param norm = 1.8129e-01, time/batch = 14.7498s	
12445/29850 (epoch 20.846), train_loss = 1.00507082, grad/param norm = 1.8253e-01, time/batch = 17.4578s	
12446/29850 (epoch 20.848), train_loss = 1.05513842, grad/param norm = 2.0257e-01, time/batch = 18.8844s	
12447/29850 (epoch 20.849), train_loss = 0.93161119, grad/param norm = 2.0075e-01, time/batch = 16.8794s	
12448/29850 (epoch 20.851), train_loss = 1.10962891, grad/param norm = 2.3218e-01, time/batch = 17.1321s	
12449/29850 (epoch 20.853), train_loss = 0.94048638, grad/param norm = 2.2665e-01, time/batch = 17.7918s	
12450/29850 (epoch 20.854), train_loss = 1.14569651, grad/param norm = 2.1479e-01, time/batch = 17.3837s	
12451/29850 (epoch 20.856), train_loss = 1.07894353, grad/param norm = 2.4541e-01, time/batch = 17.4564s	
12452/29850 (epoch 20.858), train_loss = 1.01639457, grad/param norm = 2.1265e-01, time/batch = 15.8739s	
12453/29850 (epoch 20.859), train_loss = 0.90320448, grad/param norm = 2.2203e-01, time/batch = 18.2934s	
12454/29850 (epoch 20.861), train_loss = 1.13270527, grad/param norm = 2.2115e-01, time/batch = 18.7089s	
12455/29850 (epoch 20.863), train_loss = 1.15773712, grad/param norm = 2.0098e-01, time/batch = 17.3730s	
12456/29850 (epoch 20.864), train_loss = 1.12022614, grad/param norm = 2.2144e-01, time/batch = 18.4589s	
12457/29850 (epoch 20.866), train_loss = 1.01278701, grad/param norm = 2.0579e-01, time/batch = 17.4450s	
12458/29850 (epoch 20.868), train_loss = 1.17580083, grad/param norm = 2.1784e-01, time/batch = 16.7911s	
12459/29850 (epoch 20.869), train_loss = 1.01371210, grad/param norm = 2.3728e-01, time/batch = 18.2023s	
12460/29850 (epoch 20.871), train_loss = 1.09812318, grad/param norm = 2.0417e-01, time/batch = 16.8705s	
12461/29850 (epoch 20.873), train_loss = 1.05225517, grad/param norm = 2.1151e-01, time/batch = 19.6170s	
12462/29850 (epoch 20.874), train_loss = 1.03336901, grad/param norm = 1.8788e-01, time/batch = 14.1660s	
12463/29850 (epoch 20.876), train_loss = 1.01215553, grad/param norm = 2.2609e-01, time/batch = 18.5442s	
12464/29850 (epoch 20.878), train_loss = 1.02395609, grad/param norm = 1.7981e-01, time/batch = 17.0174s	
12465/29850 (epoch 20.879), train_loss = 1.03693587, grad/param norm = 1.9629e-01, time/batch = 17.8448s	
12466/29850 (epoch 20.881), train_loss = 1.13366006, grad/param norm = 2.3634e-01, time/batch = 16.9555s	
12467/29850 (epoch 20.883), train_loss = 1.10708224, grad/param norm = 2.1854e-01, time/batch = 19.9463s	
12468/29850 (epoch 20.884), train_loss = 0.89750434, grad/param norm = 1.9645e-01, time/batch = 17.6187s	
12469/29850 (epoch 20.886), train_loss = 1.14477685, grad/param norm = 2.4229e-01, time/batch = 17.4439s	
12470/29850 (epoch 20.888), train_loss = 1.02675580, grad/param norm = 2.0095e-01, time/batch = 17.2874s	
12471/29850 (epoch 20.889), train_loss = 0.96267810, grad/param norm = 1.7662e-01, time/batch = 18.3031s	
12472/29850 (epoch 20.891), train_loss = 0.93572500, grad/param norm = 1.7403e-01, time/batch = 16.5338s	
12473/29850 (epoch 20.893), train_loss = 0.93911139, grad/param norm = 1.9811e-01, time/batch = 16.0594s	
12474/29850 (epoch 20.894), train_loss = 0.97322446, grad/param norm = 2.0029e-01, time/batch = 18.1956s	
12475/29850 (epoch 20.896), train_loss = 1.00157555, grad/param norm = 1.9403e-01, time/batch = 17.4617s	
12476/29850 (epoch 20.898), train_loss = 1.13520857, grad/param norm = 2.2553e-01, time/batch = 17.4472s	
12477/29850 (epoch 20.899), train_loss = 0.86865013, grad/param norm = 1.8470e-01, time/batch = 17.9793s	
12478/29850 (epoch 20.901), train_loss = 1.27919979, grad/param norm = 2.5057e-01, time/batch = 19.3525s	
12479/29850 (epoch 20.903), train_loss = 1.03104979, grad/param norm = 2.5128e-01, time/batch = 18.4655s	
12480/29850 (epoch 20.905), train_loss = 1.26015580, grad/param norm = 2.1568e-01, time/batch = 16.9789s	
12481/29850 (epoch 20.906), train_loss = 1.07450273, grad/param norm = 2.0765e-01, time/batch = 19.1978s	
12482/29850 (epoch 20.908), train_loss = 1.15341582, grad/param norm = 2.0729e-01, time/batch = 16.1020s	
12483/29850 (epoch 20.910), train_loss = 1.09131615, grad/param norm = 1.8061e-01, time/batch = 17.5283s	
12484/29850 (epoch 20.911), train_loss = 1.21599225, grad/param norm = 1.9943e-01, time/batch = 18.7979s	
12485/29850 (epoch 20.913), train_loss = 1.14623511, grad/param norm = 2.2391e-01, time/batch = 17.1238s	
12486/29850 (epoch 20.915), train_loss = 1.16134313, grad/param norm = 2.3654e-01, time/batch = 16.8919s	
12487/29850 (epoch 20.916), train_loss = 1.11968340, grad/param norm = 2.2623e-01, time/batch = 16.8166s	
12488/29850 (epoch 20.918), train_loss = 0.97527828, grad/param norm = 1.9990e-01, time/batch = 17.8824s	
12489/29850 (epoch 20.920), train_loss = 1.09310103, grad/param norm = 1.9242e-01, time/batch = 16.7166s	
12490/29850 (epoch 20.921), train_loss = 1.06718621, grad/param norm = 2.2259e-01, time/batch = 16.2959s	
12491/29850 (epoch 20.923), train_loss = 1.11448451, grad/param norm = 2.1306e-01, time/batch = 18.2065s	
12492/29850 (epoch 20.925), train_loss = 1.15588347, grad/param norm = 2.2183e-01, time/batch = 17.1378s	
12493/29850 (epoch 20.926), train_loss = 1.20489180, grad/param norm = 2.3359e-01, time/batch = 18.6218s	
12494/29850 (epoch 20.928), train_loss = 1.07026044, grad/param norm = 1.9594e-01, time/batch = 15.9808s	
12495/29850 (epoch 20.930), train_loss = 1.12980859, grad/param norm = 2.1272e-01, time/batch = 18.1409s	
12496/29850 (epoch 20.931), train_loss = 1.03652506, grad/param norm = 1.9614e-01, time/batch = 18.6835s	
12497/29850 (epoch 20.933), train_loss = 1.23494042, grad/param norm = 2.2550e-01, time/batch = 17.1143s	
12498/29850 (epoch 20.935), train_loss = 1.13600055, grad/param norm = 2.0912e-01, time/batch = 17.1100s	
12499/29850 (epoch 20.936), train_loss = 1.12479057, grad/param norm = 2.2029e-01, time/batch = 17.3764s	
12500/29850 (epoch 20.938), train_loss = 0.93225918, grad/param norm = 1.8110e-01, time/batch = 19.2923s	
12501/29850 (epoch 20.940), train_loss = 0.92178761, grad/param norm = 1.8145e-01, time/batch = 17.2060s	
12502/29850 (epoch 20.941), train_loss = 0.97881226, grad/param norm = 2.1561e-01, time/batch = 21.0815s	
12503/29850 (epoch 20.943), train_loss = 0.97694942, grad/param norm = 1.8875e-01, time/batch = 27.9094s	
12504/29850 (epoch 20.945), train_loss = 0.98289570, grad/param norm = 1.9710e-01, time/batch = 16.7746s	
12505/29850 (epoch 20.946), train_loss = 0.92888889, grad/param norm = 2.2360e-01, time/batch = 15.7585s	
12506/29850 (epoch 20.948), train_loss = 1.03949793, grad/param norm = 1.8945e-01, time/batch = 18.6274s	
12507/29850 (epoch 20.950), train_loss = 0.93559679, grad/param norm = 1.6379e-01, time/batch = 17.3633s	
12508/29850 (epoch 20.951), train_loss = 0.91158450, grad/param norm = 1.7416e-01, time/batch = 18.2883s	
12509/29850 (epoch 20.953), train_loss = 1.01994625, grad/param norm = 2.2179e-01, time/batch = 17.7225s	
12510/29850 (epoch 20.955), train_loss = 0.89822137, grad/param norm = 1.7028e-01, time/batch = 16.7307s	
12511/29850 (epoch 20.956), train_loss = 0.90009047, grad/param norm = 1.8507e-01, time/batch = 19.0444s	
12512/29850 (epoch 20.958), train_loss = 0.77735046, grad/param norm = 1.6273e-01, time/batch = 18.4394s	
12513/29850 (epoch 20.960), train_loss = 1.10122425, grad/param norm = 2.0931e-01, time/batch = 17.7952s	
12514/29850 (epoch 20.961), train_loss = 0.91597353, grad/param norm = 1.8129e-01, time/batch = 19.8637s	
12515/29850 (epoch 20.963), train_loss = 0.88920368, grad/param norm = 1.8134e-01, time/batch = 17.6991s	
12516/29850 (epoch 20.965), train_loss = 0.93739925, grad/param norm = 1.9636e-01, time/batch = 19.7862s	
12517/29850 (epoch 20.966), train_loss = 0.88451257, grad/param norm = 1.8365e-01, time/batch = 18.0458s	
12518/29850 (epoch 20.968), train_loss = 0.94253638, grad/param norm = 1.9927e-01, time/batch = 16.9549s	
12519/29850 (epoch 20.970), train_loss = 0.90016726, grad/param norm = 2.0323e-01, time/batch = 17.8886s	
12520/29850 (epoch 20.972), train_loss = 0.92895777, grad/param norm = 1.7071e-01, time/batch = 15.4395s	
12521/29850 (epoch 20.973), train_loss = 0.91789273, grad/param norm = 1.8166e-01, time/batch = 18.5378s	
12522/29850 (epoch 20.975), train_loss = 0.83249339, grad/param norm = 1.7759e-01, time/batch = 16.8570s	
12523/29850 (epoch 20.977), train_loss = 0.93397879, grad/param norm = 1.6611e-01, time/batch = 16.7850s	
12524/29850 (epoch 20.978), train_loss = 0.88567773, grad/param norm = 1.6968e-01, time/batch = 17.9554s	
12525/29850 (epoch 20.980), train_loss = 0.95888660, grad/param norm = 1.8533e-01, time/batch = 17.8739s	
12526/29850 (epoch 20.982), train_loss = 0.94417326, grad/param norm = 1.9920e-01, time/batch = 19.2818s	
12527/29850 (epoch 20.983), train_loss = 0.97319219, grad/param norm = 1.7345e-01, time/batch = 17.2805s	
12528/29850 (epoch 20.985), train_loss = 1.02326496, grad/param norm = 1.9198e-01, time/batch = 18.4581s	
12529/29850 (epoch 20.987), train_loss = 1.02098347, grad/param norm = 2.0385e-01, time/batch = 17.2992s	
12530/29850 (epoch 20.988), train_loss = 0.94757372, grad/param norm = 1.6917e-01, time/batch = 17.2946s	
12531/29850 (epoch 20.990), train_loss = 1.03063403, grad/param norm = 1.9367e-01, time/batch = 19.1153s	
12532/29850 (epoch 20.992), train_loss = 1.03403866, grad/param norm = 1.8019e-01, time/batch = 16.8754s	
12533/29850 (epoch 20.993), train_loss = 1.03169471, grad/param norm = 2.2000e-01, time/batch = 19.1269s	
12534/29850 (epoch 20.995), train_loss = 1.04770674, grad/param norm = 1.9913e-01, time/batch = 18.3953s	
12535/29850 (epoch 20.997), train_loss = 1.02381062, grad/param norm = 2.0190e-01, time/batch = 15.9732s	
12536/29850 (epoch 20.998), train_loss = 1.07976697, grad/param norm = 1.9418e-01, time/batch = 16.8015s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
12537/29850 (epoch 21.000), train_loss = 0.91225598, grad/param norm = 1.7599e-01, time/batch = 15.9720s	
12538/29850 (epoch 21.002), train_loss = 1.21796696, grad/param norm = 2.2520e-01, time/batch = 17.6473s	
12539/29850 (epoch 21.003), train_loss = 0.93362142, grad/param norm = 1.9201e-01, time/batch = 17.3705s	
12540/29850 (epoch 21.005), train_loss = 1.04495738, grad/param norm = 1.9557e-01, time/batch = 16.1344s	
12541/29850 (epoch 21.007), train_loss = 1.08067390, grad/param norm = 2.1360e-01, time/batch = 18.2998s	
12542/29850 (epoch 21.008), train_loss = 1.23252924, grad/param norm = 2.0782e-01, time/batch = 17.2208s	
12543/29850 (epoch 21.010), train_loss = 0.93264906, grad/param norm = 2.0980e-01, time/batch = 16.4691s	
12544/29850 (epoch 21.012), train_loss = 1.01312816, grad/param norm = 1.7309e-01, time/batch = 16.7009s	
12545/29850 (epoch 21.013), train_loss = 1.07275764, grad/param norm = 2.1987e-01, time/batch = 16.5509s	
12546/29850 (epoch 21.015), train_loss = 1.07873166, grad/param norm = 1.8142e-01, time/batch = 18.3736s	
12547/29850 (epoch 21.017), train_loss = 1.06348999, grad/param norm = 2.0521e-01, time/batch = 17.5414s	
12548/29850 (epoch 21.018), train_loss = 1.15848609, grad/param norm = 2.2951e-01, time/batch = 18.9520s	
12549/29850 (epoch 21.020), train_loss = 1.00987463, grad/param norm = 2.0862e-01, time/batch = 16.2406s	
12550/29850 (epoch 21.022), train_loss = 1.13630627, grad/param norm = 2.3316e-01, time/batch = 17.7256s	
12551/29850 (epoch 21.023), train_loss = 1.09088912, grad/param norm = 1.9754e-01, time/batch = 18.2051s	
12552/29850 (epoch 21.025), train_loss = 0.99659302, grad/param norm = 1.6838e-01, time/batch = 17.8037s	
12553/29850 (epoch 21.027), train_loss = 0.83085605, grad/param norm = 1.7792e-01, time/batch = 17.3007s	
12554/29850 (epoch 21.028), train_loss = 0.98422067, grad/param norm = 1.7780e-01, time/batch = 16.8938s	
12555/29850 (epoch 21.030), train_loss = 1.03209502, grad/param norm = 2.1757e-01, time/batch = 16.9619s	
12556/29850 (epoch 21.032), train_loss = 1.06116493, grad/param norm = 1.8388e-01, time/batch = 15.5239s	
12557/29850 (epoch 21.034), train_loss = 0.94448585, grad/param norm = 1.7337e-01, time/batch = 18.1384s	
12558/29850 (epoch 21.035), train_loss = 0.85506413, grad/param norm = 1.7733e-01, time/batch = 18.0321s	
12559/29850 (epoch 21.037), train_loss = 1.00552060, grad/param norm = 1.9440e-01, time/batch = 17.4570s	
12560/29850 (epoch 21.039), train_loss = 0.90267153, grad/param norm = 1.7140e-01, time/batch = 14.7996s	
12561/29850 (epoch 21.040), train_loss = 0.92576771, grad/param norm = 1.7886e-01, time/batch = 19.1950s	
12562/29850 (epoch 21.042), train_loss = 0.93981971, grad/param norm = 2.0240e-01, time/batch = 16.8008s	
12563/29850 (epoch 21.044), train_loss = 0.96858836, grad/param norm = 1.6673e-01, time/batch = 17.2007s	
12564/29850 (epoch 21.045), train_loss = 1.07024750, grad/param norm = 1.8280e-01, time/batch = 18.8694s	
12565/29850 (epoch 21.047), train_loss = 0.87089550, grad/param norm = 1.7400e-01, time/batch = 18.0627s	
12566/29850 (epoch 21.049), train_loss = 1.03253126, grad/param norm = 1.8157e-01, time/batch = 16.8716s	
12567/29850 (epoch 21.050), train_loss = 0.92625772, grad/param norm = 1.8429e-01, time/batch = 18.8763s	
12568/29850 (epoch 21.052), train_loss = 1.13445998, grad/param norm = 2.0783e-01, time/batch = 16.6128s	
12569/29850 (epoch 21.054), train_loss = 1.05169777, grad/param norm = 2.3470e-01, time/batch = 18.3738s	
12570/29850 (epoch 21.055), train_loss = 0.99010520, grad/param norm = 1.7709e-01, time/batch = 16.1830s	
12571/29850 (epoch 21.057), train_loss = 1.08433327, grad/param norm = 1.8459e-01, time/batch = 18.6141s	
12572/29850 (epoch 21.059), train_loss = 1.04225269, grad/param norm = 2.0043e-01, time/batch = 16.8054s	
12573/29850 (epoch 21.060), train_loss = 1.03594421, grad/param norm = 1.9039e-01, time/batch = 17.1996s	
12574/29850 (epoch 21.062), train_loss = 1.13544427, grad/param norm = 2.0478e-01, time/batch = 18.3810s	
12575/29850 (epoch 21.064), train_loss = 1.09139885, grad/param norm = 1.8893e-01, time/batch = 16.3486s	
12576/29850 (epoch 21.065), train_loss = 0.93953968, grad/param norm = 1.8874e-01, time/batch = 17.5413s	
12577/29850 (epoch 21.067), train_loss = 1.06586708, grad/param norm = 1.8778e-01, time/batch = 17.6931s	
12578/29850 (epoch 21.069), train_loss = 1.02930103, grad/param norm = 1.8278e-01, time/batch = 16.5386s	
12579/29850 (epoch 21.070), train_loss = 1.09043880, grad/param norm = 1.8305e-01, time/batch = 15.3808s	
12580/29850 (epoch 21.072), train_loss = 1.06380031, grad/param norm = 2.1608e-01, time/batch = 17.0282s	
12581/29850 (epoch 21.074), train_loss = 1.09406387, grad/param norm = 1.7966e-01, time/batch = 19.4572s	
12582/29850 (epoch 21.075), train_loss = 0.95803934, grad/param norm = 1.9518e-01, time/batch = 17.3091s	
12583/29850 (epoch 21.077), train_loss = 1.07442825, grad/param norm = 2.0921e-01, time/batch = 18.0433s	
12584/29850 (epoch 21.079), train_loss = 1.27497667, grad/param norm = 2.4966e-01, time/batch = 19.2004s	
12585/29850 (epoch 21.080), train_loss = 1.24523456, grad/param norm = 2.2551e-01, time/batch = 17.5451s	
12586/29850 (epoch 21.082), train_loss = 1.09979682, grad/param norm = 2.0099e-01, time/batch = 19.2818s	
12587/29850 (epoch 21.084), train_loss = 1.18423441, grad/param norm = 2.1881e-01, time/batch = 16.2967s	
12588/29850 (epoch 21.085), train_loss = 1.15415954, grad/param norm = 2.0358e-01, time/batch = 16.7440s	
12589/29850 (epoch 21.087), train_loss = 1.16706725, grad/param norm = 2.1050e-01, time/batch = 17.3836s	
12590/29850 (epoch 21.089), train_loss = 1.08252562, grad/param norm = 2.0479e-01, time/batch = 17.7014s	
12591/29850 (epoch 21.090), train_loss = 1.10250599, grad/param norm = 1.9926e-01, time/batch = 19.2161s	
12592/29850 (epoch 21.092), train_loss = 0.99761500, grad/param norm = 1.7973e-01, time/batch = 16.3745s	
12593/29850 (epoch 21.094), train_loss = 1.16200178, grad/param norm = 2.1290e-01, time/batch = 16.3545s	
12594/29850 (epoch 21.095), train_loss = 1.05889440, grad/param norm = 2.0439e-01, time/batch = 17.3040s	
12595/29850 (epoch 21.097), train_loss = 0.85204563, grad/param norm = 1.5521e-01, time/batch = 19.1275s	
12596/29850 (epoch 21.099), train_loss = 0.88974484, grad/param norm = 1.8483e-01, time/batch = 20.2742s	
12597/29850 (epoch 21.101), train_loss = 1.13818233, grad/param norm = 1.9832e-01, time/batch = 18.3619s	
12598/29850 (epoch 21.102), train_loss = 1.11528295, grad/param norm = 2.1199e-01, time/batch = 17.7022s	
12599/29850 (epoch 21.104), train_loss = 1.02645981, grad/param norm = 1.8622e-01, time/batch = 18.7231s	
12600/29850 (epoch 21.106), train_loss = 1.11508718, grad/param norm = 1.8760e-01, time/batch = 16.0993s	
12601/29850 (epoch 21.107), train_loss = 0.90025954, grad/param norm = 1.6653e-01, time/batch = 19.1113s	
12602/29850 (epoch 21.109), train_loss = 1.01427509, grad/param norm = 2.0881e-01, time/batch = 17.0406s	
12603/29850 (epoch 21.111), train_loss = 1.12859643, grad/param norm = 2.2276e-01, time/batch = 17.5326s	
12604/29850 (epoch 21.112), train_loss = 0.96357945, grad/param norm = 1.8469e-01, time/batch = 17.2988s	
12605/29850 (epoch 21.114), train_loss = 1.02649643, grad/param norm = 2.1539e-01, time/batch = 17.7272s	
12606/29850 (epoch 21.116), train_loss = 0.92879220, grad/param norm = 1.6570e-01, time/batch = 18.2224s	
12607/29850 (epoch 21.117), train_loss = 1.04629375, grad/param norm = 1.9859e-01, time/batch = 16.7753s	
12608/29850 (epoch 21.119), train_loss = 1.01227401, grad/param norm = 1.8437e-01, time/batch = 17.7919s	
12609/29850 (epoch 21.121), train_loss = 0.82831950, grad/param norm = 1.9297e-01, time/batch = 17.7078s	
12610/29850 (epoch 21.122), train_loss = 0.89389894, grad/param norm = 1.6160e-01, time/batch = 17.5417s	
12611/29850 (epoch 21.124), train_loss = 0.95361198, grad/param norm = 1.7810e-01, time/batch = 17.0556s	
12612/29850 (epoch 21.126), train_loss = 0.98482574, grad/param norm = 1.9426e-01, time/batch = 19.1443s	
12613/29850 (epoch 21.127), train_loss = 1.11532329, grad/param norm = 2.1476e-01, time/batch = 18.2100s	
12614/29850 (epoch 21.129), train_loss = 0.98814309, grad/param norm = 2.1685e-01, time/batch = 15.1838s	
12615/29850 (epoch 21.131), train_loss = 1.00496301, grad/param norm = 1.9117e-01, time/batch = 17.2815s	
12616/29850 (epoch 21.132), train_loss = 0.91255284, grad/param norm = 2.0707e-01, time/batch = 17.2255s	
12617/29850 (epoch 21.134), train_loss = 1.04870067, grad/param norm = 1.9799e-01, time/batch = 17.2158s	
12618/29850 (epoch 21.136), train_loss = 1.05693021, grad/param norm = 1.8634e-01, time/batch = 17.7076s	
12619/29850 (epoch 21.137), train_loss = 0.83591014, grad/param norm = 1.6882e-01, time/batch = 15.0053s	
12620/29850 (epoch 21.139), train_loss = 0.97917267, grad/param norm = 2.0465e-01, time/batch = 16.7013s	
12621/29850 (epoch 21.141), train_loss = 0.96238450, grad/param norm = 2.0188e-01, time/batch = 15.7413s	
12622/29850 (epoch 21.142), train_loss = 1.14537162, grad/param norm = 2.1876e-01, time/batch = 17.8851s	
12623/29850 (epoch 21.144), train_loss = 1.29767675, grad/param norm = 2.1007e-01, time/batch = 16.8936s	
12624/29850 (epoch 21.146), train_loss = 1.25980559, grad/param norm = 2.2116e-01, time/batch = 15.6709s	
12625/29850 (epoch 21.147), train_loss = 1.08849603, grad/param norm = 1.9729e-01, time/batch = 15.7902s	
12626/29850 (epoch 21.149), train_loss = 1.10280366, grad/param norm = 1.9968e-01, time/batch = 16.6986s	
12627/29850 (epoch 21.151), train_loss = 1.08042185, grad/param norm = 2.0279e-01, time/batch = 17.7137s	
12628/29850 (epoch 21.152), train_loss = 0.98517308, grad/param norm = 1.8603e-01, time/batch = 17.1347s	
12629/29850 (epoch 21.154), train_loss = 0.95161049, grad/param norm = 1.9685e-01, time/batch = 18.8588s	
12630/29850 (epoch 21.156), train_loss = 0.96460656, grad/param norm = 1.8144e-01, time/batch = 16.2102s	
12631/29850 (epoch 21.157), train_loss = 1.04406140, grad/param norm = 1.7974e-01, time/batch = 15.8830s	
12632/29850 (epoch 21.159), train_loss = 1.00093434, grad/param norm = 1.8177e-01, time/batch = 17.1169s	
12633/29850 (epoch 21.161), train_loss = 1.08180198, grad/param norm = 2.0644e-01, time/batch = 19.0550s	
12634/29850 (epoch 21.162), train_loss = 1.19250468, grad/param norm = 2.2528e-01, time/batch = 18.7095s	
12635/29850 (epoch 21.164), train_loss = 1.02687964, grad/param norm = 1.9180e-01, time/batch = 18.0222s	
12636/29850 (epoch 21.166), train_loss = 0.94491320, grad/param norm = 1.8787e-01, time/batch = 15.2793s	
12637/29850 (epoch 21.168), train_loss = 0.87652388, grad/param norm = 1.8204e-01, time/batch = 17.4380s	
12638/29850 (epoch 21.169), train_loss = 1.17415484, grad/param norm = 2.0299e-01, time/batch = 17.6062s	
12639/29850 (epoch 21.171), train_loss = 1.09294032, grad/param norm = 2.1256e-01, time/batch = 16.2226s	
12640/29850 (epoch 21.173), train_loss = 0.97409727, grad/param norm = 2.0103e-01, time/batch = 16.8970s	
12641/29850 (epoch 21.174), train_loss = 1.08775196, grad/param norm = 2.2407e-01, time/batch = 18.4338s	
12642/29850 (epoch 21.176), train_loss = 1.08482222, grad/param norm = 2.0898e-01, time/batch = 17.3750s	
12643/29850 (epoch 21.178), train_loss = 1.10929984, grad/param norm = 2.0955e-01, time/batch = 16.5433s	
12644/29850 (epoch 21.179), train_loss = 0.89594311, grad/param norm = 1.8218e-01, time/batch = 17.3750s	
12645/29850 (epoch 21.181), train_loss = 1.04431831, grad/param norm = 2.0254e-01, time/batch = 16.0415s	
12646/29850 (epoch 21.183), train_loss = 1.03722010, grad/param norm = 1.9474e-01, time/batch = 16.0481s	
12647/29850 (epoch 21.184), train_loss = 1.05753332, grad/param norm = 1.9790e-01, time/batch = 18.5350s	
12648/29850 (epoch 21.186), train_loss = 1.05703232, grad/param norm = 2.0931e-01, time/batch = 16.6348s	
12649/29850 (epoch 21.188), train_loss = 1.15283089, grad/param norm = 2.2656e-01, time/batch = 19.4492s	
12650/29850 (epoch 21.189), train_loss = 1.17608651, grad/param norm = 2.2758e-01, time/batch = 19.0480s	
12651/29850 (epoch 21.191), train_loss = 1.11723261, grad/param norm = 2.1529e-01, time/batch = 17.3611s	
12652/29850 (epoch 21.193), train_loss = 1.00845446, grad/param norm = 1.8806e-01, time/batch = 17.8661s	
12653/29850 (epoch 21.194), train_loss = 1.08760169, grad/param norm = 2.0938e-01, time/batch = 18.5432s	
12654/29850 (epoch 21.196), train_loss = 0.99554014, grad/param norm = 2.0568e-01, time/batch = 17.2105s	
12655/29850 (epoch 21.198), train_loss = 1.03126769, grad/param norm = 1.9068e-01, time/batch = 17.0418s	
12656/29850 (epoch 21.199), train_loss = 1.28071279, grad/param norm = 2.3984e-01, time/batch = 17.6988s	
12657/29850 (epoch 21.201), train_loss = 0.98200060, grad/param norm = 2.1755e-01, time/batch = 17.4723s	
12658/29850 (epoch 21.203), train_loss = 0.82551656, grad/param norm = 1.9721e-01, time/batch = 18.5407s	
12659/29850 (epoch 21.204), train_loss = 1.07054035, grad/param norm = 2.0744e-01, time/batch = 16.6323s	
12660/29850 (epoch 21.206), train_loss = 0.91872447, grad/param norm = 1.8663e-01, time/batch = 17.1317s	
12661/29850 (epoch 21.208), train_loss = 1.18567227, grad/param norm = 2.0352e-01, time/batch = 18.2607s	
12662/29850 (epoch 21.209), train_loss = 0.92408331, grad/param norm = 1.8037e-01, time/batch = 16.8685s	
12663/29850 (epoch 21.211), train_loss = 1.00200761, grad/param norm = 1.9254e-01, time/batch = 18.4625s	
12664/29850 (epoch 21.213), train_loss = 1.11815440, grad/param norm = 2.1851e-01, time/batch = 17.4451s	
12665/29850 (epoch 21.214), train_loss = 0.91562381, grad/param norm = 1.6665e-01, time/batch = 18.1233s	
12666/29850 (epoch 21.216), train_loss = 0.96998923, grad/param norm = 2.0853e-01, time/batch = 15.8822s	
12667/29850 (epoch 21.218), train_loss = 1.12542329, grad/param norm = 1.9769e-01, time/batch = 17.5247s	
12668/29850 (epoch 21.219), train_loss = 1.14399466, grad/param norm = 2.0965e-01, time/batch = 16.7950s	
12669/29850 (epoch 21.221), train_loss = 1.01749360, grad/param norm = 1.8029e-01, time/batch = 15.1955s	
12670/29850 (epoch 21.223), train_loss = 0.96319664, grad/param norm = 2.1950e-01, time/batch = 18.3704s	
12671/29850 (epoch 21.224), train_loss = 0.90672947, grad/param norm = 1.9804e-01, time/batch = 17.3000s	
12672/29850 (epoch 21.226), train_loss = 0.94216705, grad/param norm = 1.8118e-01, time/batch = 17.5244s	
12673/29850 (epoch 21.228), train_loss = 0.99484484, grad/param norm = 1.6496e-01, time/batch = 15.6293s	
12674/29850 (epoch 21.229), train_loss = 0.86308220, grad/param norm = 1.5535e-01, time/batch = 17.0539s	
12675/29850 (epoch 21.231), train_loss = 1.02176243, grad/param norm = 1.7921e-01, time/batch = 17.3067s	
12676/29850 (epoch 21.233), train_loss = 0.98309880, grad/param norm = 2.0597e-01, time/batch = 16.7030s	
12677/29850 (epoch 21.235), train_loss = 0.91502561, grad/param norm = 1.6418e-01, time/batch = 17.9790s	
12678/29850 (epoch 21.236), train_loss = 1.17557460, grad/param norm = 2.2040e-01, time/batch = 16.8594s	
12679/29850 (epoch 21.238), train_loss = 0.89949820, grad/param norm = 1.7478e-01, time/batch = 17.6361s	
12680/29850 (epoch 21.240), train_loss = 0.90687498, grad/param norm = 1.8272e-01, time/batch = 18.8572s	
12681/29850 (epoch 21.241), train_loss = 1.08741425, grad/param norm = 2.1715e-01, time/batch = 18.6302s	
12682/29850 (epoch 21.243), train_loss = 1.04165863, grad/param norm = 1.7820e-01, time/batch = 18.7129s	
12683/29850 (epoch 21.245), train_loss = 0.96157919, grad/param norm = 1.9163e-01, time/batch = 17.4375s	
12684/29850 (epoch 21.246), train_loss = 0.91058666, grad/param norm = 1.7814e-01, time/batch = 14.8234s	
12685/29850 (epoch 21.248), train_loss = 0.89895011, grad/param norm = 1.7962e-01, time/batch = 17.5447s	
12686/29850 (epoch 21.250), train_loss = 0.98236559, grad/param norm = 1.7774e-01, time/batch = 17.1292s	
12687/29850 (epoch 21.251), train_loss = 0.88446966, grad/param norm = 1.9240e-01, time/batch = 18.6407s	
12688/29850 (epoch 21.253), train_loss = 0.82154199, grad/param norm = 1.8575e-01, time/batch = 16.4462s	
12689/29850 (epoch 21.255), train_loss = 0.91604278, grad/param norm = 1.8285e-01, time/batch = 18.3504s	
12690/29850 (epoch 21.256), train_loss = 1.06196647, grad/param norm = 1.9851e-01, time/batch = 16.7178s	
12691/29850 (epoch 21.258), train_loss = 1.02897251, grad/param norm = 1.9781e-01, time/batch = 16.4641s	
12692/29850 (epoch 21.260), train_loss = 1.00914206, grad/param norm = 1.8992e-01, time/batch = 16.4666s	
12693/29850 (epoch 21.261), train_loss = 0.92588172, grad/param norm = 1.9199e-01, time/batch = 16.7971s	
12694/29850 (epoch 21.263), train_loss = 0.92069837, grad/param norm = 1.9103e-01, time/batch = 17.1385s	
12695/29850 (epoch 21.265), train_loss = 0.98138303, grad/param norm = 1.8385e-01, time/batch = 17.8689s	
12696/29850 (epoch 21.266), train_loss = 0.99184721, grad/param norm = 2.0421e-01, time/batch = 17.9628s	
12697/29850 (epoch 21.268), train_loss = 0.94310919, grad/param norm = 1.5853e-01, time/batch = 18.2776s	
12698/29850 (epoch 21.270), train_loss = 0.93473848, grad/param norm = 1.9635e-01, time/batch = 19.2849s	
12699/29850 (epoch 21.271), train_loss = 1.08552428, grad/param norm = 1.8368e-01, time/batch = 18.8721s	
12700/29850 (epoch 21.273), train_loss = 0.86111661, grad/param norm = 1.9500e-01, time/batch = 18.1149s	
12701/29850 (epoch 21.275), train_loss = 0.87454491, grad/param norm = 2.1811e-01, time/batch = 16.7991s	
12702/29850 (epoch 21.276), train_loss = 0.89161309, grad/param norm = 1.8336e-01, time/batch = 19.1277s	
12703/29850 (epoch 21.278), train_loss = 0.95047623, grad/param norm = 1.8019e-01, time/batch = 17.0437s	
12704/29850 (epoch 21.280), train_loss = 1.14953936, grad/param norm = 2.1374e-01, time/batch = 20.0326s	
12705/29850 (epoch 21.281), train_loss = 1.06310503, grad/param norm = 2.1911e-01, time/batch = 16.5725s	
12706/29850 (epoch 21.283), train_loss = 1.16600422, grad/param norm = 2.3801e-01, time/batch = 22.3220s	
12707/29850 (epoch 21.285), train_loss = 1.00267797, grad/param norm = 1.8719e-01, time/batch = 26.2708s	
12708/29850 (epoch 21.286), train_loss = 1.10801722, grad/param norm = 1.9501e-01, time/batch = 16.3587s	
12709/29850 (epoch 21.288), train_loss = 1.15221641, grad/param norm = 2.5761e-01, time/batch = 16.0982s	
12710/29850 (epoch 21.290), train_loss = 1.02875018, grad/param norm = 2.0035e-01, time/batch = 19.3576s	
12711/29850 (epoch 21.291), train_loss = 1.23144429, grad/param norm = 2.1102e-01, time/batch = 15.2745s	
12712/29850 (epoch 21.293), train_loss = 1.10643424, grad/param norm = 2.0256e-01, time/batch = 18.5353s	
12713/29850 (epoch 21.295), train_loss = 1.18701043, grad/param norm = 2.1597e-01, time/batch = 18.6909s	
12714/29850 (epoch 21.296), train_loss = 0.92466798, grad/param norm = 1.8403e-01, time/batch = 19.9473s	
12715/29850 (epoch 21.298), train_loss = 0.81932894, grad/param norm = 1.8230e-01, time/batch = 18.0383s	
12716/29850 (epoch 21.300), train_loss = 0.88478467, grad/param norm = 1.7045e-01, time/batch = 16.6158s	
12717/29850 (epoch 21.302), train_loss = 0.86453685, grad/param norm = 1.7629e-01, time/batch = 19.1796s	
12718/29850 (epoch 21.303), train_loss = 0.93668739, grad/param norm = 1.8747e-01, time/batch = 18.3864s	
12719/29850 (epoch 21.305), train_loss = 1.05507724, grad/param norm = 1.8260e-01, time/batch = 17.2071s	
12720/29850 (epoch 21.307), train_loss = 1.10735975, grad/param norm = 1.9076e-01, time/batch = 18.1067s	
12721/29850 (epoch 21.308), train_loss = 0.95211849, grad/param norm = 1.8537e-01, time/batch = 18.6204s	
12722/29850 (epoch 21.310), train_loss = 1.06132555, grad/param norm = 2.0810e-01, time/batch = 15.9450s	
12723/29850 (epoch 21.312), train_loss = 1.08904064, grad/param norm = 1.9369e-01, time/batch = 15.7142s	
12724/29850 (epoch 21.313), train_loss = 1.01173855, grad/param norm = 1.8899e-01, time/batch = 16.2355s	
12725/29850 (epoch 21.315), train_loss = 1.03915703, grad/param norm = 2.0717e-01, time/batch = 18.4552s	
12726/29850 (epoch 21.317), train_loss = 1.01887911, grad/param norm = 2.1029e-01, time/batch = 16.5473s	
12727/29850 (epoch 21.318), train_loss = 1.02044493, grad/param norm = 2.0086e-01, time/batch = 16.9382s	
12728/29850 (epoch 21.320), train_loss = 0.95082422, grad/param norm = 1.7153e-01, time/batch = 17.7782s	
12729/29850 (epoch 21.322), train_loss = 1.16261057, grad/param norm = 2.1115e-01, time/batch = 18.3653s	
12730/29850 (epoch 21.323), train_loss = 1.08502033, grad/param norm = 2.0819e-01, time/batch = 16.9452s	
12731/29850 (epoch 21.325), train_loss = 1.12121424, grad/param norm = 1.9912e-01, time/batch = 19.1214s	
12732/29850 (epoch 21.327), train_loss = 1.22766697, grad/param norm = 2.3169e-01, time/batch = 18.7876s	
12733/29850 (epoch 21.328), train_loss = 1.17431093, grad/param norm = 2.2687e-01, time/batch = 19.3645s	
12734/29850 (epoch 21.330), train_loss = 1.07584251, grad/param norm = 1.9676e-01, time/batch = 18.7083s	
12735/29850 (epoch 21.332), train_loss = 0.99163633, grad/param norm = 1.8988e-01, time/batch = 17.7907s	
12736/29850 (epoch 21.333), train_loss = 1.13336759, grad/param norm = 2.0485e-01, time/batch = 18.1084s	
12737/29850 (epoch 21.335), train_loss = 1.13445832, grad/param norm = 2.0145e-01, time/batch = 19.2072s	
12738/29850 (epoch 21.337), train_loss = 1.05203750, grad/param norm = 2.0705e-01, time/batch = 16.1425s	
12739/29850 (epoch 21.338), train_loss = 1.03981468, grad/param norm = 1.8066e-01, time/batch = 16.6230s	
12740/29850 (epoch 21.340), train_loss = 0.93999617, grad/param norm = 1.9362e-01, time/batch = 17.2990s	
12741/29850 (epoch 21.342), train_loss = 1.04536860, grad/param norm = 2.1537e-01, time/batch = 17.5507s	
12742/29850 (epoch 21.343), train_loss = 1.06561153, grad/param norm = 2.2713e-01, time/batch = 16.6218s	
12743/29850 (epoch 21.345), train_loss = 1.10620343, grad/param norm = 2.4564e-01, time/batch = 17.8704s	
12744/29850 (epoch 21.347), train_loss = 1.13398094, grad/param norm = 2.1622e-01, time/batch = 16.7189s	
12745/29850 (epoch 21.348), train_loss = 0.97713833, grad/param norm = 1.8283e-01, time/batch = 15.7214s	
12746/29850 (epoch 21.350), train_loss = 1.10830309, grad/param norm = 2.2034e-01, time/batch = 15.9423s	
12747/29850 (epoch 21.352), train_loss = 0.96584401, grad/param norm = 1.8022e-01, time/batch = 18.6099s	
12748/29850 (epoch 21.353), train_loss = 1.09221539, grad/param norm = 1.9000e-01, time/batch = 18.7889s	
12749/29850 (epoch 21.355), train_loss = 0.94632196, grad/param norm = 1.8997e-01, time/batch = 16.4618s	
12750/29850 (epoch 21.357), train_loss = 1.16461898, grad/param norm = 2.1566e-01, time/batch = 19.7527s	
12751/29850 (epoch 21.358), train_loss = 0.95954358, grad/param norm = 1.9406e-01, time/batch = 17.6266s	
12752/29850 (epoch 21.360), train_loss = 1.02237366, grad/param norm = 2.0702e-01, time/batch = 19.5389s	
12753/29850 (epoch 21.362), train_loss = 1.03364734, grad/param norm = 2.2343e-01, time/batch = 16.2039s	
12754/29850 (epoch 21.363), train_loss = 1.05628049, grad/param norm = 2.1259e-01, time/batch = 18.3681s	
12755/29850 (epoch 21.365), train_loss = 1.18658483, grad/param norm = 2.0544e-01, time/batch = 18.3583s	
12756/29850 (epoch 21.367), train_loss = 0.97661611, grad/param norm = 1.9666e-01, time/batch = 17.1158s	
12757/29850 (epoch 21.369), train_loss = 0.90095030, grad/param norm = 1.8374e-01, time/batch = 16.8045s	
12758/29850 (epoch 21.370), train_loss = 0.85185898, grad/param norm = 1.9342e-01, time/batch = 17.9742s	
12759/29850 (epoch 21.372), train_loss = 1.14932927, grad/param norm = 2.2199e-01, time/batch = 18.7877s	
12760/29850 (epoch 21.374), train_loss = 1.08925154, grad/param norm = 2.1355e-01, time/batch = 17.5324s	
12761/29850 (epoch 21.375), train_loss = 1.02712635, grad/param norm = 1.9064e-01, time/batch = 16.8873s	
12762/29850 (epoch 21.377), train_loss = 1.00335230, grad/param norm = 2.0799e-01, time/batch = 18.7966s	
12763/29850 (epoch 21.379), train_loss = 1.14190559, grad/param norm = 2.1758e-01, time/batch = 17.0322s	
12764/29850 (epoch 21.380), train_loss = 1.09688856, grad/param norm = 2.0424e-01, time/batch = 16.7021s	
12765/29850 (epoch 21.382), train_loss = 1.08389347, grad/param norm = 2.1038e-01, time/batch = 15.1963s	
12766/29850 (epoch 21.384), train_loss = 1.08834003, grad/param norm = 2.0534e-01, time/batch = 15.1641s	
12767/29850 (epoch 21.385), train_loss = 1.03685946, grad/param norm = 2.0759e-01, time/batch = 15.7650s	
12768/29850 (epoch 21.387), train_loss = 1.07507679, grad/param norm = 1.8806e-01, time/batch = 14.9538s	
12769/29850 (epoch 21.389), train_loss = 1.19031878, grad/param norm = 2.4652e-01, time/batch = 14.9205s	
12770/29850 (epoch 21.390), train_loss = 1.09899708, grad/param norm = 1.8758e-01, time/batch = 14.1607s	
12771/29850 (epoch 21.392), train_loss = 1.01248852, grad/param norm = 2.0601e-01, time/batch = 15.2589s	
12772/29850 (epoch 21.394), train_loss = 1.14011584, grad/param norm = 1.9989e-01, time/batch = 17.0267s	
12773/29850 (epoch 21.395), train_loss = 0.99830081, grad/param norm = 1.9427e-01, time/batch = 14.4895s	
12774/29850 (epoch 21.397), train_loss = 0.93652235, grad/param norm = 2.2465e-01, time/batch = 17.1128s	
12775/29850 (epoch 21.399), train_loss = 0.95147872, grad/param norm = 1.8526e-01, time/batch = 16.3871s	
12776/29850 (epoch 21.400), train_loss = 1.33705676, grad/param norm = 2.2011e-01, time/batch = 16.8607s	
12777/29850 (epoch 21.402), train_loss = 1.21622255, grad/param norm = 1.9018e-01, time/batch = 16.6312s	
12778/29850 (epoch 21.404), train_loss = 1.05988167, grad/param norm = 1.8232e-01, time/batch = 15.9649s	
12779/29850 (epoch 21.405), train_loss = 0.98285254, grad/param norm = 2.0818e-01, time/batch = 17.1500s	
12780/29850 (epoch 21.407), train_loss = 0.95367829, grad/param norm = 1.8258e-01, time/batch = 17.1132s	
12781/29850 (epoch 21.409), train_loss = 1.11214524, grad/param norm = 2.1233e-01, time/batch = 18.1308s	
12782/29850 (epoch 21.410), train_loss = 1.18439787, grad/param norm = 2.0355e-01, time/batch = 19.0286s	
12783/29850 (epoch 21.412), train_loss = 1.14555816, grad/param norm = 2.0034e-01, time/batch = 17.8872s	
12784/29850 (epoch 21.414), train_loss = 1.03985533, grad/param norm = 2.0515e-01, time/batch = 18.7000s	
12785/29850 (epoch 21.415), train_loss = 1.06112180, grad/param norm = 1.9913e-01, time/batch = 16.7931s	
12786/29850 (epoch 21.417), train_loss = 1.17872815, grad/param norm = 2.3019e-01, time/batch = 17.1244s	
12787/29850 (epoch 21.419), train_loss = 1.05107610, grad/param norm = 2.1767e-01, time/batch = 18.5316s	
12788/29850 (epoch 21.420), train_loss = 1.03894289, grad/param norm = 1.8260e-01, time/batch = 17.1148s	
12789/29850 (epoch 21.422), train_loss = 1.01773029, grad/param norm = 1.9514e-01, time/batch = 18.7930s	
12790/29850 (epoch 21.424), train_loss = 0.97692413, grad/param norm = 1.8654e-01, time/batch = 18.5549s	
12791/29850 (epoch 21.425), train_loss = 1.16412186, grad/param norm = 1.9972e-01, time/batch = 17.3808s	
12792/29850 (epoch 21.427), train_loss = 0.85840806, grad/param norm = 1.7132e-01, time/batch = 18.2099s	
12793/29850 (epoch 21.429), train_loss = 0.94460346, grad/param norm = 1.9289e-01, time/batch = 16.4834s	
12794/29850 (epoch 21.430), train_loss = 0.87230108, grad/param norm = 1.7561e-01, time/batch = 17.5521s	
12795/29850 (epoch 21.432), train_loss = 1.01021017, grad/param norm = 2.4219e-01, time/batch = 16.4581s	
12796/29850 (epoch 21.434), train_loss = 0.89619017, grad/param norm = 1.6418e-01, time/batch = 18.3026s	
12797/29850 (epoch 21.436), train_loss = 1.05663183, grad/param norm = 2.1485e-01, time/batch = 18.8641s	
12798/29850 (epoch 21.437), train_loss = 1.08601140, grad/param norm = 1.8583e-01, time/batch = 16.9676s	
12799/29850 (epoch 21.439), train_loss = 1.06993030, grad/param norm = 2.2655e-01, time/batch = 16.1344s	
12800/29850 (epoch 21.441), train_loss = 1.04813825, grad/param norm = 2.0821e-01, time/batch = 17.1251s	
12801/29850 (epoch 21.442), train_loss = 1.04949202, grad/param norm = 1.9940e-01, time/batch = 17.1123s	
12802/29850 (epoch 21.444), train_loss = 1.07082647, grad/param norm = 2.1463e-01, time/batch = 14.9760s	
12803/29850 (epoch 21.446), train_loss = 1.10209460, grad/param norm = 1.9443e-01, time/batch = 16.2222s	
12804/29850 (epoch 21.447), train_loss = 1.10781478, grad/param norm = 1.9997e-01, time/batch = 18.5602s	
12805/29850 (epoch 21.449), train_loss = 1.06792071, grad/param norm = 2.2602e-01, time/batch = 17.2041s	
12806/29850 (epoch 21.451), train_loss = 0.86274591, grad/param norm = 1.8234e-01, time/batch = 17.6233s	
12807/29850 (epoch 21.452), train_loss = 0.77688546, grad/param norm = 1.5373e-01, time/batch = 19.8798s	
12808/29850 (epoch 21.454), train_loss = 0.89310572, grad/param norm = 1.7166e-01, time/batch = 18.1907s	
12809/29850 (epoch 21.456), train_loss = 1.08338678, grad/param norm = 2.0394e-01, time/batch = 16.6755s	
12810/29850 (epoch 21.457), train_loss = 1.08203969, grad/param norm = 2.4992e-01, time/batch = 16.4901s	
12811/29850 (epoch 21.459), train_loss = 1.22535577, grad/param norm = 2.1798e-01, time/batch = 17.7027s	
12812/29850 (epoch 21.461), train_loss = 1.18997354, grad/param norm = 1.8967e-01, time/batch = 16.7989s	
12813/29850 (epoch 21.462), train_loss = 1.17788791, grad/param norm = 2.1898e-01, time/batch = 18.7110s	
12814/29850 (epoch 21.464), train_loss = 1.11096298, grad/param norm = 2.1415e-01, time/batch = 16.3733s	
12815/29850 (epoch 21.466), train_loss = 0.92260538, grad/param norm = 2.1183e-01, time/batch = 17.2849s	
12816/29850 (epoch 21.467), train_loss = 1.03307058, grad/param norm = 2.0337e-01, time/batch = 17.7909s	
12817/29850 (epoch 21.469), train_loss = 1.01651561, grad/param norm = 1.8464e-01, time/batch = 16.3796s	
12818/29850 (epoch 21.471), train_loss = 1.02918443, grad/param norm = 1.9981e-01, time/batch = 17.9621s	
12819/29850 (epoch 21.472), train_loss = 0.98223185, grad/param norm = 1.8394e-01, time/batch = 16.6977s	
12820/29850 (epoch 21.474), train_loss = 1.13934198, grad/param norm = 1.8794e-01, time/batch = 19.3658s	
12821/29850 (epoch 21.476), train_loss = 1.06007085, grad/param norm = 1.8240e-01, time/batch = 18.5948s	
12822/29850 (epoch 21.477), train_loss = 1.05405405, grad/param norm = 2.1862e-01, time/batch = 17.1168s	
12823/29850 (epoch 21.479), train_loss = 1.20079301, grad/param norm = 2.1604e-01, time/batch = 18.7876s	
12824/29850 (epoch 21.481), train_loss = 1.01967125, grad/param norm = 1.9688e-01, time/batch = 19.1923s	
12825/29850 (epoch 21.482), train_loss = 0.97132930, grad/param norm = 1.7794e-01, time/batch = 17.3717s	
12826/29850 (epoch 21.484), train_loss = 0.98064822, grad/param norm = 1.8102e-01, time/batch = 18.5288s	
12827/29850 (epoch 21.486), train_loss = 1.06789026, grad/param norm = 2.0067e-01, time/batch = 16.2176s	
12828/29850 (epoch 21.487), train_loss = 1.03360267, grad/param norm = 1.9664e-01, time/batch = 17.9562s	
12829/29850 (epoch 21.489), train_loss = 1.01728570, grad/param norm = 1.8713e-01, time/batch = 15.6203s	
12830/29850 (epoch 21.491), train_loss = 0.93498232, grad/param norm = 1.8371e-01, time/batch = 16.5981s	
12831/29850 (epoch 21.492), train_loss = 1.02978485, grad/param norm = 1.8882e-01, time/batch = 18.6809s	
12832/29850 (epoch 21.494), train_loss = 1.14627547, grad/param norm = 1.8955e-01, time/batch = 17.1992s	
12833/29850 (epoch 21.496), train_loss = 1.20260437, grad/param norm = 1.9022e-01, time/batch = 17.3795s	
12834/29850 (epoch 21.497), train_loss = 1.09681862, grad/param norm = 1.8776e-01, time/batch = 18.3831s	
12835/29850 (epoch 21.499), train_loss = 1.03374810, grad/param norm = 1.9136e-01, time/batch = 18.6324s	
12836/29850 (epoch 21.501), train_loss = 0.98500069, grad/param norm = 2.1027e-01, time/batch = 18.1048s	
12837/29850 (epoch 21.503), train_loss = 1.04570752, grad/param norm = 1.9279e-01, time/batch = 18.2950s	
12838/29850 (epoch 21.504), train_loss = 1.27705134, grad/param norm = 2.1274e-01, time/batch = 19.2982s	
12839/29850 (epoch 21.506), train_loss = 1.20059110, grad/param norm = 2.0929e-01, time/batch = 17.1958s	
12840/29850 (epoch 21.508), train_loss = 1.06712811, grad/param norm = 1.9179e-01, time/batch = 18.6257s	
12841/29850 (epoch 21.509), train_loss = 0.84716908, grad/param norm = 1.7573e-01, time/batch = 18.8870s	
12842/29850 (epoch 21.511), train_loss = 1.06412299, grad/param norm = 1.9055e-01, time/batch = 16.9690s	
12843/29850 (epoch 21.513), train_loss = 1.08708064, grad/param norm = 2.2067e-01, time/batch = 17.6275s	
12844/29850 (epoch 21.514), train_loss = 0.93057636, grad/param norm = 1.8728e-01, time/batch = 17.2072s	
12845/29850 (epoch 21.516), train_loss = 0.97384148, grad/param norm = 1.6402e-01, time/batch = 18.5279s	
12846/29850 (epoch 21.518), train_loss = 0.88040577, grad/param norm = 1.8694e-01, time/batch = 17.0448s	
12847/29850 (epoch 21.519), train_loss = 0.87657726, grad/param norm = 1.8509e-01, time/batch = 16.4563s	
12848/29850 (epoch 21.521), train_loss = 0.83435092, grad/param norm = 1.6295e-01, time/batch = 18.2994s	
12849/29850 (epoch 21.523), train_loss = 0.88764411, grad/param norm = 1.6892e-01, time/batch = 17.5526s	
12850/29850 (epoch 21.524), train_loss = 0.97854418, grad/param norm = 2.1070e-01, time/batch = 19.2000s	
12851/29850 (epoch 21.526), train_loss = 1.05226775, grad/param norm = 2.1429e-01, time/batch = 16.9561s	
12852/29850 (epoch 21.528), train_loss = 1.13440155, grad/param norm = 2.1074e-01, time/batch = 15.4545s	
12853/29850 (epoch 21.529), train_loss = 1.07069827, grad/param norm = 2.0739e-01, time/batch = 17.1285s	
12854/29850 (epoch 21.531), train_loss = 1.00944671, grad/param norm = 2.0735e-01, time/batch = 18.9566s	
12855/29850 (epoch 21.533), train_loss = 0.98926440, grad/param norm = 1.8994e-01, time/batch = 16.1149s	
12856/29850 (epoch 21.534), train_loss = 1.03777692, grad/param norm = 1.9297e-01, time/batch = 16.7128s	
12857/29850 (epoch 21.536), train_loss = 0.97863191, grad/param norm = 2.1197e-01, time/batch = 16.5698s	
12858/29850 (epoch 21.538), train_loss = 1.15206540, grad/param norm = 2.1595e-01, time/batch = 18.6307s	
12859/29850 (epoch 21.539), train_loss = 1.20219042, grad/param norm = 2.3783e-01, time/batch = 17.5227s	
12860/29850 (epoch 21.541), train_loss = 0.81303932, grad/param norm = 1.7033e-01, time/batch = 19.1039s	
12861/29850 (epoch 21.543), train_loss = 1.04216945, grad/param norm = 1.9235e-01, time/batch = 15.6485s	
12862/29850 (epoch 21.544), train_loss = 1.09395218, grad/param norm = 1.9860e-01, time/batch = 17.6316s	
12863/29850 (epoch 21.546), train_loss = 1.14838405, grad/param norm = 2.0647e-01, time/batch = 17.0373s	
12864/29850 (epoch 21.548), train_loss = 0.87809668, grad/param norm = 1.7256e-01, time/batch = 17.4617s	
12865/29850 (epoch 21.549), train_loss = 1.00372581, grad/param norm = 1.9257e-01, time/batch = 16.9487s	
12866/29850 (epoch 21.551), train_loss = 0.90432314, grad/param norm = 1.6722e-01, time/batch = 16.5560s	
12867/29850 (epoch 21.553), train_loss = 1.01143283, grad/param norm = 1.8509e-01, time/batch = 19.1241s	
12868/29850 (epoch 21.554), train_loss = 0.88771624, grad/param norm = 1.8501e-01, time/batch = 17.6360s	
12869/29850 (epoch 21.556), train_loss = 0.93872017, grad/param norm = 1.9252e-01, time/batch = 17.6342s	
12870/29850 (epoch 21.558), train_loss = 0.94399594, grad/param norm = 1.7510e-01, time/batch = 17.5184s	
12871/29850 (epoch 21.559), train_loss = 0.99614170, grad/param norm = 1.8342e-01, time/batch = 18.7814s	
12872/29850 (epoch 21.561), train_loss = 1.07912259, grad/param norm = 2.0298e-01, time/batch = 17.3187s	
12873/29850 (epoch 21.563), train_loss = 1.03558576, grad/param norm = 1.9606e-01, time/batch = 17.7082s	
12874/29850 (epoch 21.564), train_loss = 1.00088474, grad/param norm = 2.0925e-01, time/batch = 19.0396s	
12875/29850 (epoch 21.566), train_loss = 1.04735367, grad/param norm = 1.9640e-01, time/batch = 17.8747s	
12876/29850 (epoch 21.568), train_loss = 1.14269393, grad/param norm = 2.0935e-01, time/batch = 16.7895s	
12877/29850 (epoch 21.570), train_loss = 1.06188436, grad/param norm = 2.0653e-01, time/batch = 17.0392s	
12878/29850 (epoch 21.571), train_loss = 1.11751376, grad/param norm = 1.9855e-01, time/batch = 15.6357s	
12879/29850 (epoch 21.573), train_loss = 1.18977063, grad/param norm = 2.3023e-01, time/batch = 18.8028s	
12880/29850 (epoch 21.575), train_loss = 1.16061383, grad/param norm = 1.9720e-01, time/batch = 15.6221s	
12881/29850 (epoch 21.576), train_loss = 1.13368885, grad/param norm = 2.0937e-01, time/batch = 18.3573s	
12882/29850 (epoch 21.578), train_loss = 0.98464024, grad/param norm = 2.0079e-01, time/batch = 17.1025s	
12883/29850 (epoch 21.580), train_loss = 1.17179810, grad/param norm = 2.2085e-01, time/batch = 17.4538s	
12884/29850 (epoch 21.581), train_loss = 0.94439237, grad/param norm = 1.7922e-01, time/batch = 18.8788s	
12885/29850 (epoch 21.583), train_loss = 1.04237445, grad/param norm = 1.9943e-01, time/batch = 16.1886s	
12886/29850 (epoch 21.585), train_loss = 1.07232259, grad/param norm = 1.9149e-01, time/batch = 18.7032s	
12887/29850 (epoch 21.586), train_loss = 1.05075034, grad/param norm = 1.8976e-01, time/batch = 17.4367s	
12888/29850 (epoch 21.588), train_loss = 1.00410790, grad/param norm = 2.1865e-01, time/batch = 18.8132s	
12889/29850 (epoch 21.590), train_loss = 1.00686699, grad/param norm = 1.9245e-01, time/batch = 18.3771s	
12890/29850 (epoch 21.591), train_loss = 1.00626436, grad/param norm = 2.3966e-01, time/batch = 15.7064s	
12891/29850 (epoch 21.593), train_loss = 0.95734601, grad/param norm = 1.8872e-01, time/batch = 19.2799s	
12892/29850 (epoch 21.595), train_loss = 0.90068612, grad/param norm = 1.5462e-01, time/batch = 15.2362s	
12893/29850 (epoch 21.596), train_loss = 0.89035011, grad/param norm = 1.7433e-01, time/batch = 17.9334s	
12894/29850 (epoch 21.598), train_loss = 1.00259433, grad/param norm = 1.7921e-01, time/batch = 17.4627s	
12895/29850 (epoch 21.600), train_loss = 1.07955282, grad/param norm = 2.1193e-01, time/batch = 17.1517s	
12896/29850 (epoch 21.601), train_loss = 0.90498062, grad/param norm = 1.6518e-01, time/batch = 17.7984s	
12897/29850 (epoch 21.603), train_loss = 0.97798226, grad/param norm = 1.9333e-01, time/batch = 16.6300s	
12898/29850 (epoch 21.605), train_loss = 1.00310600, grad/param norm = 1.9979e-01, time/batch = 18.1260s	
12899/29850 (epoch 21.606), train_loss = 0.77161999, grad/param norm = 1.6670e-01, time/batch = 17.7888s	
12900/29850 (epoch 21.608), train_loss = 0.95840417, grad/param norm = 1.7786e-01, time/batch = 16.8004s	
12901/29850 (epoch 21.610), train_loss = 1.02637760, grad/param norm = 2.0649e-01, time/batch = 18.8731s	
12902/29850 (epoch 21.611), train_loss = 0.94701172, grad/param norm = 1.9534e-01, time/batch = 16.1165s	
12903/29850 (epoch 21.613), train_loss = 0.78492627, grad/param norm = 1.6648e-01, time/batch = 18.1013s	
12904/29850 (epoch 21.615), train_loss = 0.91914430, grad/param norm = 1.7644e-01, time/batch = 17.7065s	
12905/29850 (epoch 21.616), train_loss = 0.89652808, grad/param norm = 1.8951e-01, time/batch = 18.0423s	
12906/29850 (epoch 21.618), train_loss = 0.99062641, grad/param norm = 1.8859e-01, time/batch = 18.5390s	
12907/29850 (epoch 21.620), train_loss = 1.05031209, grad/param norm = 1.9110e-01, time/batch = 16.9633s	
12908/29850 (epoch 21.621), train_loss = 1.15566910, grad/param norm = 2.0414e-01, time/batch = 19.2942s	
12909/29850 (epoch 21.623), train_loss = 1.08849448, grad/param norm = 2.0348e-01, time/batch = 17.2857s	
12910/29850 (epoch 21.625), train_loss = 1.03946621, grad/param norm = 1.9912e-01, time/batch = 21.1274s	
12911/29850 (epoch 21.626), train_loss = 1.06536588, grad/param norm = 1.9886e-01, time/batch = 25.3495s	
12912/29850 (epoch 21.628), train_loss = 0.92242275, grad/param norm = 1.8027e-01, time/batch = 16.0282s	
12913/29850 (epoch 21.630), train_loss = 1.01398202, grad/param norm = 1.8624e-01, time/batch = 15.5114s	
12914/29850 (epoch 21.631), train_loss = 0.99523421, grad/param norm = 1.8828e-01, time/batch = 16.9226s	
12915/29850 (epoch 21.633), train_loss = 1.08570959, grad/param norm = 2.0586e-01, time/batch = 15.1547s	
12916/29850 (epoch 21.635), train_loss = 0.99232099, grad/param norm = 2.0387e-01, time/batch = 17.6443s	
12917/29850 (epoch 21.637), train_loss = 0.94731326, grad/param norm = 2.1523e-01, time/batch = 17.1299s	
12918/29850 (epoch 21.638), train_loss = 1.03725429, grad/param norm = 2.0119e-01, time/batch = 18.7170s	
12919/29850 (epoch 21.640), train_loss = 1.18238222, grad/param norm = 2.3860e-01, time/batch = 17.3009s	
12920/29850 (epoch 21.642), train_loss = 0.94062121, grad/param norm = 1.8522e-01, time/batch = 16.6328s	
12921/29850 (epoch 21.643), train_loss = 0.94106130, grad/param norm = 1.9173e-01, time/batch = 17.5562s	
12922/29850 (epoch 21.645), train_loss = 0.99423823, grad/param norm = 1.8022e-01, time/batch = 18.4442s	
12923/29850 (epoch 21.647), train_loss = 1.14292140, grad/param norm = 2.1247e-01, time/batch = 17.1310s	
12924/29850 (epoch 21.648), train_loss = 0.89727987, grad/param norm = 1.8184e-01, time/batch = 17.6433s	
12925/29850 (epoch 21.650), train_loss = 1.04932019, grad/param norm = 2.0051e-01, time/batch = 16.8788s	
12926/29850 (epoch 21.652), train_loss = 1.05256608, grad/param norm = 2.3398e-01, time/batch = 18.6245s	
12927/29850 (epoch 21.653), train_loss = 1.13662372, grad/param norm = 2.1526e-01, time/batch = 15.5304s	
12928/29850 (epoch 21.655), train_loss = 1.01882735, grad/param norm = 1.8696e-01, time/batch = 17.0954s	
12929/29850 (epoch 21.657), train_loss = 0.96217623, grad/param norm = 1.8664e-01, time/batch = 16.4739s	
12930/29850 (epoch 21.658), train_loss = 1.12993521, grad/param norm = 2.1593e-01, time/batch = 15.1253s	
12931/29850 (epoch 21.660), train_loss = 1.02362726, grad/param norm = 1.8999e-01, time/batch = 17.8656s	
12932/29850 (epoch 21.662), train_loss = 1.09399039, grad/param norm = 2.1046e-01, time/batch = 16.0425s	
12933/29850 (epoch 21.663), train_loss = 1.21175941, grad/param norm = 2.1055e-01, time/batch = 17.5520s	
12934/29850 (epoch 21.665), train_loss = 1.14018828, grad/param norm = 2.0322e-01, time/batch = 17.5457s	
12935/29850 (epoch 21.667), train_loss = 1.08619528, grad/param norm = 2.2100e-01, time/batch = 18.4558s	
12936/29850 (epoch 21.668), train_loss = 1.02243646, grad/param norm = 2.2281e-01, time/batch = 18.8806s	
12937/29850 (epoch 21.670), train_loss = 1.17100396, grad/param norm = 2.3794e-01, time/batch = 17.1272s	
12938/29850 (epoch 21.672), train_loss = 1.16518916, grad/param norm = 2.2587e-01, time/batch = 17.5469s	
12939/29850 (epoch 21.673), train_loss = 1.11021850, grad/param norm = 2.0886e-01, time/batch = 18.9469s	
12940/29850 (epoch 21.675), train_loss = 0.91542954, grad/param norm = 1.9384e-01, time/batch = 15.4572s	
12941/29850 (epoch 21.677), train_loss = 0.99685891, grad/param norm = 2.0450e-01, time/batch = 17.8725s	
12942/29850 (epoch 21.678), train_loss = 1.00423214, grad/param norm = 1.9153e-01, time/batch = 17.6342s	
12943/29850 (epoch 21.680), train_loss = 1.04226634, grad/param norm = 2.2450e-01, time/batch = 18.8796s	
12944/29850 (epoch 21.682), train_loss = 1.04499749, grad/param norm = 2.1282e-01, time/batch = 17.0414s	
12945/29850 (epoch 21.683), train_loss = 1.17295539, grad/param norm = 2.3660e-01, time/batch = 17.4740s	
12946/29850 (epoch 21.685), train_loss = 1.18783747, grad/param norm = 2.1282e-01, time/batch = 16.7127s	
12947/29850 (epoch 21.687), train_loss = 1.10817746, grad/param norm = 2.2633e-01, time/batch = 17.3684s	
12948/29850 (epoch 21.688), train_loss = 0.90763329, grad/param norm = 1.9337e-01, time/batch = 17.7839s	
12949/29850 (epoch 21.690), train_loss = 0.90403405, grad/param norm = 1.9445e-01, time/batch = 16.6240s	
12950/29850 (epoch 21.692), train_loss = 1.12495372, grad/param norm = 1.9785e-01, time/batch = 19.0417s	
12951/29850 (epoch 21.693), train_loss = 1.00884622, grad/param norm = 1.7344e-01, time/batch = 16.3631s	
12952/29850 (epoch 21.695), train_loss = 0.89892881, grad/param norm = 1.7109e-01, time/batch = 20.0245s	
12953/29850 (epoch 21.697), train_loss = 1.02036775, grad/param norm = 1.9772e-01, time/batch = 17.3560s	
12954/29850 (epoch 21.698), train_loss = 1.15404103, grad/param norm = 2.0650e-01, time/batch = 16.5442s	
12955/29850 (epoch 21.700), train_loss = 1.08428431, grad/param norm = 2.1374e-01, time/batch = 18.2110s	
12956/29850 (epoch 21.702), train_loss = 1.01129303, grad/param norm = 1.9317e-01, time/batch = 18.9539s	
12957/29850 (epoch 21.704), train_loss = 0.90871672, grad/param norm = 1.7059e-01, time/batch = 18.3743s	
12958/29850 (epoch 21.705), train_loss = 1.03744031, grad/param norm = 1.9193e-01, time/batch = 17.1941s	
12959/29850 (epoch 21.707), train_loss = 0.95556699, grad/param norm = 2.0957e-01, time/batch = 19.8598s	
12960/29850 (epoch 21.709), train_loss = 1.03538082, grad/param norm = 2.0099e-01, time/batch = 19.1198s	
12961/29850 (epoch 21.710), train_loss = 0.95851016, grad/param norm = 2.1079e-01, time/batch = 16.2464s	
12962/29850 (epoch 21.712), train_loss = 1.02898386, grad/param norm = 1.7048e-01, time/batch = 17.6787s	
12963/29850 (epoch 21.714), train_loss = 1.11945351, grad/param norm = 2.1079e-01, time/batch = 17.2987s	
12964/29850 (epoch 21.715), train_loss = 1.06592806, grad/param norm = 1.9539e-01, time/batch = 16.7995s	
12965/29850 (epoch 21.717), train_loss = 0.81731086, grad/param norm = 1.8384e-01, time/batch = 16.6323s	
12966/29850 (epoch 21.719), train_loss = 0.97051991, grad/param norm = 1.9880e-01, time/batch = 17.0469s	
12967/29850 (epoch 21.720), train_loss = 1.01727780, grad/param norm = 1.7070e-01, time/batch = 18.6387s	
12968/29850 (epoch 21.722), train_loss = 0.95264697, grad/param norm = 1.5987e-01, time/batch = 18.0301s	
12969/29850 (epoch 21.724), train_loss = 1.08036243, grad/param norm = 1.9573e-01, time/batch = 19.3747s	
12970/29850 (epoch 21.725), train_loss = 0.88430385, grad/param norm = 1.7217e-01, time/batch = 17.7071s	
12971/29850 (epoch 21.727), train_loss = 0.95862615, grad/param norm = 2.0461e-01, time/batch = 16.3658s	
12972/29850 (epoch 21.729), train_loss = 0.87914038, grad/param norm = 1.6761e-01, time/batch = 17.2029s	
12973/29850 (epoch 21.730), train_loss = 0.86143468, grad/param norm = 1.7580e-01, time/batch = 18.1974s	
12974/29850 (epoch 21.732), train_loss = 1.10231378, grad/param norm = 1.7979e-01, time/batch = 17.3836s	
12975/29850 (epoch 21.734), train_loss = 1.17836795, grad/param norm = 2.1126e-01, time/batch = 17.0475s	
12976/29850 (epoch 21.735), train_loss = 0.97276062, grad/param norm = 2.1063e-01, time/batch = 17.9684s	
12977/29850 (epoch 21.737), train_loss = 0.92570539, grad/param norm = 2.0249e-01, time/batch = 18.8666s	
12978/29850 (epoch 21.739), train_loss = 0.81217327, grad/param norm = 1.9223e-01, time/batch = 9.3482s	
12979/29850 (epoch 21.740), train_loss = 0.88895649, grad/param norm = 1.8232e-01, time/batch = 0.6549s	
12980/29850 (epoch 21.742), train_loss = 0.84310529, grad/param norm = 1.6883e-01, time/batch = 0.6571s	
12981/29850 (epoch 21.744), train_loss = 0.95967776, grad/param norm = 1.9616e-01, time/batch = 0.6645s	
12982/29850 (epoch 21.745), train_loss = 0.93506562, grad/param norm = 1.8683e-01, time/batch = 0.6737s	
12983/29850 (epoch 21.747), train_loss = 1.00599445, grad/param norm = 1.9964e-01, time/batch = 0.6521s	
12984/29850 (epoch 21.749), train_loss = 0.88909609, grad/param norm = 1.9959e-01, time/batch = 0.6586s	
12985/29850 (epoch 21.750), train_loss = 0.86407083, grad/param norm = 1.7666e-01, time/batch = 0.6558s	
12986/29850 (epoch 21.752), train_loss = 0.79334596, grad/param norm = 1.7496e-01, time/batch = 0.9394s	
12987/29850 (epoch 21.754), train_loss = 0.86545639, grad/param norm = 1.9013e-01, time/batch = 0.9645s	
12988/29850 (epoch 21.755), train_loss = 0.87644021, grad/param norm = 1.8661e-01, time/batch = 0.9642s	
12989/29850 (epoch 21.757), train_loss = 0.93886700, grad/param norm = 1.9080e-01, time/batch = 0.9551s	
12990/29850 (epoch 21.759), train_loss = 0.95634668, grad/param norm = 1.9522e-01, time/batch = 0.9748s	
12991/29850 (epoch 21.760), train_loss = 0.91125061, grad/param norm = 1.9363e-01, time/batch = 1.6201s	
12992/29850 (epoch 21.762), train_loss = 0.86783612, grad/param norm = 2.1161e-01, time/batch = 1.8076s	
12993/29850 (epoch 21.764), train_loss = 0.83852860, grad/param norm = 2.1122e-01, time/batch = 1.7766s	
12994/29850 (epoch 21.765), train_loss = 0.97690801, grad/param norm = 1.9835e-01, time/batch = 16.5530s	
12995/29850 (epoch 21.767), train_loss = 0.96868415, grad/param norm = 1.8465e-01, time/batch = 16.7226s	
12996/29850 (epoch 21.769), train_loss = 0.97222770, grad/param norm = 1.9564e-01, time/batch = 15.9347s	
12997/29850 (epoch 21.771), train_loss = 1.01742147, grad/param norm = 2.0284e-01, time/batch = 18.4467s	
12998/29850 (epoch 21.772), train_loss = 1.03023515, grad/param norm = 2.1151e-01, time/batch = 17.1833s	
12999/29850 (epoch 21.774), train_loss = 0.94336712, grad/param norm = 1.9952e-01, time/batch = 17.6380s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch21.78_1.7077.t7	
13000/29850 (epoch 21.776), train_loss = 0.94114673, grad/param norm = 2.0656e-01, time/batch = 18.4653s	
13001/29850 (epoch 21.777), train_loss = 1.50682762, grad/param norm = 2.5956e-01, time/batch = 19.6957s	
13002/29850 (epoch 21.779), train_loss = 0.89936725, grad/param norm = 1.9362e-01, time/batch = 16.6381s	
13003/29850 (epoch 21.781), train_loss = 1.01074348, grad/param norm = 1.8950e-01, time/batch = 16.4705s	
13004/29850 (epoch 21.782), train_loss = 1.04671118, grad/param norm = 2.0121e-01, time/batch = 17.7923s	
13005/29850 (epoch 21.784), train_loss = 0.89015097, grad/param norm = 2.0962e-01, time/batch = 18.0349s	
13006/29850 (epoch 21.786), train_loss = 0.94865816, grad/param norm = 1.8196e-01, time/batch = 16.5472s	
13007/29850 (epoch 21.787), train_loss = 0.84686945, grad/param norm = 1.8973e-01, time/batch = 16.8066s	
13008/29850 (epoch 21.789), train_loss = 0.80438208, grad/param norm = 1.5636e-01, time/batch = 18.3474s	
13009/29850 (epoch 21.791), train_loss = 0.91102490, grad/param norm = 2.0225e-01, time/batch = 15.6437s	
13010/29850 (epoch 21.792), train_loss = 1.03664894, grad/param norm = 2.0258e-01, time/batch = 17.7215s	
13011/29850 (epoch 21.794), train_loss = 1.02622709, grad/param norm = 1.9618e-01, time/batch = 16.2702s	
13012/29850 (epoch 21.796), train_loss = 0.87024426, grad/param norm = 1.6410e-01, time/batch = 18.3755s	
13013/29850 (epoch 21.797), train_loss = 0.80667057, grad/param norm = 1.7803e-01, time/batch = 18.3082s	
13014/29850 (epoch 21.799), train_loss = 0.86325711, grad/param norm = 1.6762e-01, time/batch = 17.4656s	
13015/29850 (epoch 21.801), train_loss = 0.95497668, grad/param norm = 2.0468e-01, time/batch = 18.0624s	
13016/29850 (epoch 21.802), train_loss = 0.81154930, grad/param norm = 1.8948e-01, time/batch = 17.1272s	
13017/29850 (epoch 21.804), train_loss = 0.85923247, grad/param norm = 1.7125e-01, time/batch = 18.2199s	
13018/29850 (epoch 21.806), train_loss = 0.86045466, grad/param norm = 1.8330e-01, time/batch = 17.3951s	
13019/29850 (epoch 21.807), train_loss = 0.81397461, grad/param norm = 1.5541e-01, time/batch = 16.9607s	
13020/29850 (epoch 21.809), train_loss = 0.88037753, grad/param norm = 1.9948e-01, time/batch = 15.7827s	
13021/29850 (epoch 21.811), train_loss = 1.01914441, grad/param norm = 2.0582e-01, time/batch = 16.2925s	
13022/29850 (epoch 21.812), train_loss = 1.02214676, grad/param norm = 2.1686e-01, time/batch = 16.5395s	
13023/29850 (epoch 21.814), train_loss = 1.08504796, grad/param norm = 1.9970e-01, time/batch = 16.7182s	
13024/29850 (epoch 21.816), train_loss = 1.05199423, grad/param norm = 1.7637e-01, time/batch = 16.7164s	
13025/29850 (epoch 21.817), train_loss = 0.99631260, grad/param norm = 1.9339e-01, time/batch = 17.7912s	
13026/29850 (epoch 21.819), train_loss = 0.86172055, grad/param norm = 2.1196e-01, time/batch = 18.3707s	
13027/29850 (epoch 21.821), train_loss = 1.11027859, grad/param norm = 2.2502e-01, time/batch = 19.0353s	
13028/29850 (epoch 21.822), train_loss = 1.10159815, grad/param norm = 1.9610e-01, time/batch = 17.3893s	
13029/29850 (epoch 21.824), train_loss = 0.98184698, grad/param norm = 1.8592e-01, time/batch = 19.2105s	
13030/29850 (epoch 21.826), train_loss = 0.92622366, grad/param norm = 1.9034e-01, time/batch = 15.8955s	
13031/29850 (epoch 21.827), train_loss = 0.86075750, grad/param norm = 1.8740e-01, time/batch = 19.2878s	
13032/29850 (epoch 21.829), train_loss = 1.00327131, grad/param norm = 2.2338e-01, time/batch = 18.3770s	
13033/29850 (epoch 21.831), train_loss = 1.07593239, grad/param norm = 2.1385e-01, time/batch = 16.6352s	
13034/29850 (epoch 21.832), train_loss = 0.95000463, grad/param norm = 1.6720e-01, time/batch = 18.5574s	
13035/29850 (epoch 21.834), train_loss = 0.79589591, grad/param norm = 1.6852e-01, time/batch = 16.2140s	
13036/29850 (epoch 21.836), train_loss = 0.83928485, grad/param norm = 1.6966e-01, time/batch = 17.8397s	
13037/29850 (epoch 21.838), train_loss = 0.96775452, grad/param norm = 2.0269e-01, time/batch = 17.8839s	
13038/29850 (epoch 21.839), train_loss = 0.85971411, grad/param norm = 1.6633e-01, time/batch = 17.7138s	
13039/29850 (epoch 21.841), train_loss = 0.87280170, grad/param norm = 1.7276e-01, time/batch = 15.4999s	
13040/29850 (epoch 21.843), train_loss = 0.83975817, grad/param norm = 1.7766e-01, time/batch = 15.8666s	
13041/29850 (epoch 21.844), train_loss = 0.87702517, grad/param norm = 1.8810e-01, time/batch = 16.6930s	
13042/29850 (epoch 21.846), train_loss = 0.98936185, grad/param norm = 1.9484e-01, time/batch = 17.7109s	
13043/29850 (epoch 21.848), train_loss = 1.04452923, grad/param norm = 2.1774e-01, time/batch = 16.8002s	
13044/29850 (epoch 21.849), train_loss = 0.91914006, grad/param norm = 1.8840e-01, time/batch = 17.7960s	
13045/29850 (epoch 21.851), train_loss = 1.08324604, grad/param norm = 2.1424e-01, time/batch = 16.6879s	
13046/29850 (epoch 21.853), train_loss = 0.91480394, grad/param norm = 2.0287e-01, time/batch = 18.5502s	
13047/29850 (epoch 21.854), train_loss = 1.12508347, grad/param norm = 2.0497e-01, time/batch = 16.8895s	
13048/29850 (epoch 21.856), train_loss = 1.06567349, grad/param norm = 2.4821e-01, time/batch = 17.2983s	
13049/29850 (epoch 21.858), train_loss = 1.00095981, grad/param norm = 1.9476e-01, time/batch = 17.7287s	
13050/29850 (epoch 21.859), train_loss = 0.87520794, grad/param norm = 2.2118e-01, time/batch = 16.8697s	
13051/29850 (epoch 21.861), train_loss = 1.09218615, grad/param norm = 1.9886e-01, time/batch = 17.5464s	
13052/29850 (epoch 21.863), train_loss = 1.16249031, grad/param norm = 2.0508e-01, time/batch = 17.8786s	
13053/29850 (epoch 21.864), train_loss = 1.08663591, grad/param norm = 2.2903e-01, time/batch = 18.5483s	
13054/29850 (epoch 21.866), train_loss = 1.00570699, grad/param norm = 2.1921e-01, time/batch = 15.9540s	
13055/29850 (epoch 21.868), train_loss = 1.15082180, grad/param norm = 2.0937e-01, time/batch = 15.0020s	
13056/29850 (epoch 21.869), train_loss = 0.99562312, grad/param norm = 2.3509e-01, time/batch = 15.7853s	
13057/29850 (epoch 21.871), train_loss = 1.08518039, grad/param norm = 1.9907e-01, time/batch = 17.2157s	
13058/29850 (epoch 21.873), train_loss = 1.03801677, grad/param norm = 1.9957e-01, time/batch = 17.4441s	
13059/29850 (epoch 21.874), train_loss = 1.00762876, grad/param norm = 1.8074e-01, time/batch = 16.7991s	
13060/29850 (epoch 21.876), train_loss = 0.97102339, grad/param norm = 3.7403e-01, time/batch = 17.8959s	
13061/29850 (epoch 21.878), train_loss = 1.03129431, grad/param norm = 2.0198e-01, time/batch = 17.4588s	
13062/29850 (epoch 21.879), train_loss = 1.02912979, grad/param norm = 2.0820e-01, time/batch = 18.6250s	
13063/29850 (epoch 21.881), train_loss = 1.11022558, grad/param norm = 2.2357e-01, time/batch = 18.8706s	
13064/29850 (epoch 21.883), train_loss = 1.08875426, grad/param norm = 2.2631e-01, time/batch = 16.0532s	
13065/29850 (epoch 21.884), train_loss = 0.88462780, grad/param norm = 1.8707e-01, time/batch = 17.8795s	
13066/29850 (epoch 21.886), train_loss = 1.11353276, grad/param norm = 2.0940e-01, time/batch = 19.7795s	
13067/29850 (epoch 21.888), train_loss = 1.01536510, grad/param norm = 2.0466e-01, time/batch = 17.6206s	
13068/29850 (epoch 21.889), train_loss = 0.95103189, grad/param norm = 1.8479e-01, time/batch = 19.3760s	
13069/29850 (epoch 21.891), train_loss = 0.91870307, grad/param norm = 1.8750e-01, time/batch = 18.2899s	
13070/29850 (epoch 21.893), train_loss = 0.92687823, grad/param norm = 1.8896e-01, time/batch = 15.1169s	
13071/29850 (epoch 21.894), train_loss = 0.96355052, grad/param norm = 2.0791e-01, time/batch = 16.3610s	
13072/29850 (epoch 21.896), train_loss = 0.98628273, grad/param norm = 1.9741e-01, time/batch = 16.9714s	
13073/29850 (epoch 21.898), train_loss = 1.10691914, grad/param norm = 2.1128e-01, time/batch = 18.1243s	
13074/29850 (epoch 21.899), train_loss = 0.85387326, grad/param norm = 1.7948e-01, time/batch = 17.7099s	
13075/29850 (epoch 21.901), train_loss = 1.27449784, grad/param norm = 3.0242e-01, time/batch = 18.3763s	
13076/29850 (epoch 21.903), train_loss = 1.03852066, grad/param norm = 2.5119e-01, time/batch = 16.2176s	
13077/29850 (epoch 21.905), train_loss = 1.22054488, grad/param norm = 2.0715e-01, time/batch = 18.6177s	
13078/29850 (epoch 21.906), train_loss = 1.05144440, grad/param norm = 2.0980e-01, time/batch = 18.4620s	
13079/29850 (epoch 21.908), train_loss = 1.14345338, grad/param norm = 2.0754e-01, time/batch = 17.1053s	
13080/29850 (epoch 21.910), train_loss = 1.06386356, grad/param norm = 1.9641e-01, time/batch = 16.7048s	
13081/29850 (epoch 21.911), train_loss = 1.20817127, grad/param norm = 1.9863e-01, time/batch = 16.7925s	
13082/29850 (epoch 21.913), train_loss = 1.12800925, grad/param norm = 1.9755e-01, time/batch = 18.3861s	
13083/29850 (epoch 21.915), train_loss = 1.13192211, grad/param norm = 2.1811e-01, time/batch = 17.9720s	
13084/29850 (epoch 21.916), train_loss = 1.11521202, grad/param norm = 2.1729e-01, time/batch = 16.9643s	
13085/29850 (epoch 21.918), train_loss = 0.94628064, grad/param norm = 1.8333e-01, time/batch = 17.9733s	
13086/29850 (epoch 21.920), train_loss = 1.08117197, grad/param norm = 1.8623e-01, time/batch = 15.2802s	
13087/29850 (epoch 21.921), train_loss = 1.03609758, grad/param norm = 2.2569e-01, time/batch = 19.3818s	
13088/29850 (epoch 21.923), train_loss = 1.09363976, grad/param norm = 2.0826e-01, time/batch = 16.3759s	
13089/29850 (epoch 21.925), train_loss = 1.14705751, grad/param norm = 2.1154e-01, time/batch = 16.6263s	
13090/29850 (epoch 21.926), train_loss = 1.18512907, grad/param norm = 2.2072e-01, time/batch = 17.7946s	
13091/29850 (epoch 21.928), train_loss = 1.05408544, grad/param norm = 2.0330e-01, time/batch = 16.4540s	
13092/29850 (epoch 21.930), train_loss = 1.09671653, grad/param norm = 2.0413e-01, time/batch = 17.6051s	
13093/29850 (epoch 21.931), train_loss = 1.01053636, grad/param norm = 1.8526e-01, time/batch = 15.4698s	
13094/29850 (epoch 21.933), train_loss = 1.20357382, grad/param norm = 2.0980e-01, time/batch = 19.2048s	
13095/29850 (epoch 21.935), train_loss = 1.11269584, grad/param norm = 2.1300e-01, time/batch = 16.9663s	
13096/29850 (epoch 21.936), train_loss = 1.09347614, grad/param norm = 2.1830e-01, time/batch = 17.6270s	
13097/29850 (epoch 21.938), train_loss = 0.91434279, grad/param norm = 1.7294e-01, time/batch = 18.3983s	
13098/29850 (epoch 21.940), train_loss = 0.91205715, grad/param norm = 1.8060e-01, time/batch = 16.3558s	
13099/29850 (epoch 21.941), train_loss = 0.95966927, grad/param norm = 2.0901e-01, time/batch = 18.4568s	
13100/29850 (epoch 21.943), train_loss = 0.96104143, grad/param norm = 1.8768e-01, time/batch = 17.0476s	
13101/29850 (epoch 21.945), train_loss = 0.96318610, grad/param norm = 2.0568e-01, time/batch = 15.6328s	
13102/29850 (epoch 21.946), train_loss = 0.92620090, grad/param norm = 2.1327e-01, time/batch = 17.2801s	
13103/29850 (epoch 21.948), train_loss = 1.02167484, grad/param norm = 1.8325e-01, time/batch = 19.0478s	
13104/29850 (epoch 21.950), train_loss = 0.93075880, grad/param norm = 1.7506e-01, time/batch = 18.2757s	
13105/29850 (epoch 21.951), train_loss = 0.87626344, grad/param norm = 1.7053e-01, time/batch = 16.8505s	
13106/29850 (epoch 21.953), train_loss = 0.99003033, grad/param norm = 2.1854e-01, time/batch = 17.5540s	
13107/29850 (epoch 21.955), train_loss = 0.88291027, grad/param norm = 1.6846e-01, time/batch = 17.3123s	
13108/29850 (epoch 21.956), train_loss = 0.86755498, grad/param norm = 1.8389e-01, time/batch = 18.4357s	
13109/29850 (epoch 21.958), train_loss = 0.75973611, grad/param norm = 1.5542e-01, time/batch = 17.2264s	
13110/29850 (epoch 21.960), train_loss = 1.08956565, grad/param norm = 2.1159e-01, time/batch = 15.7530s	
13111/29850 (epoch 21.961), train_loss = 0.92040515, grad/param norm = 2.2067e-01, time/batch = 16.7945s	
13112/29850 (epoch 21.963), train_loss = 0.86586565, grad/param norm = 1.7977e-01, time/batch = 17.4555s	
13113/29850 (epoch 21.965), train_loss = 0.92664966, grad/param norm = 2.0287e-01, time/batch = 16.7162s	
13114/29850 (epoch 21.966), train_loss = 0.86612868, grad/param norm = 1.7225e-01, time/batch = 18.5588s	
13115/29850 (epoch 21.968), train_loss = 0.90101253, grad/param norm = 1.8293e-01, time/batch = 17.5523s	
13116/29850 (epoch 21.970), train_loss = 0.87051711, grad/param norm = 1.9061e-01, time/batch = 17.2815s	
13117/29850 (epoch 21.972), train_loss = 0.90991036, grad/param norm = 1.7225e-01, time/batch = 19.1226s	
13118/29850 (epoch 21.973), train_loss = 0.91292144, grad/param norm = 1.8977e-01, time/batch = 18.1274s	
13119/29850 (epoch 21.975), train_loss = 0.82501633, grad/param norm = 1.8537e-01, time/batch = 18.6954s	
13120/29850 (epoch 21.977), train_loss = 0.92456815, grad/param norm = 1.7261e-01, time/batch = 17.9663s	
13121/29850 (epoch 21.978), train_loss = 0.86373080, grad/param norm = 1.6753e-01, time/batch = 18.5457s	
13122/29850 (epoch 21.980), train_loss = 0.93514253, grad/param norm = 1.7926e-01, time/batch = 30.5468s	
13123/29850 (epoch 21.982), train_loss = 0.92469300, grad/param norm = 2.1279e-01, time/batch = 18.6937s	
13124/29850 (epoch 21.983), train_loss = 0.95393208, grad/param norm = 1.7396e-01, time/batch = 17.2259s	
13125/29850 (epoch 21.985), train_loss = 1.01819028, grad/param norm = 1.9835e-01, time/batch = 16.6310s	
13126/29850 (epoch 21.987), train_loss = 0.99638879, grad/param norm = 1.7829e-01, time/batch = 15.0636s	
13127/29850 (epoch 21.988), train_loss = 0.94737983, grad/param norm = 1.8444e-01, time/batch = 19.4609s	
13128/29850 (epoch 21.990), train_loss = 0.99915079, grad/param norm = 1.9797e-01, time/batch = 16.4521s	
13129/29850 (epoch 21.992), train_loss = 1.01812048, grad/param norm = 1.8123e-01, time/batch = 18.5411s	
13130/29850 (epoch 21.993), train_loss = 1.02240516, grad/param norm = 2.2238e-01, time/batch = 17.4286s	
13131/29850 (epoch 21.995), train_loss = 1.03038926, grad/param norm = 2.0846e-01, time/batch = 17.8786s	
13132/29850 (epoch 21.997), train_loss = 1.03140123, grad/param norm = 2.0155e-01, time/batch = 17.2018s	
13133/29850 (epoch 21.998), train_loss = 1.07839963, grad/param norm = 2.0149e-01, time/batch = 19.2904s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
13134/29850 (epoch 22.000), train_loss = 0.89732614, grad/param norm = 1.9275e-01, time/batch = 18.4406s	
13135/29850 (epoch 22.002), train_loss = 1.20652202, grad/param norm = 2.3878e-01, time/batch = 17.2088s	
13136/29850 (epoch 22.003), train_loss = 0.91078188, grad/param norm = 1.8401e-01, time/batch = 18.3032s	
13137/29850 (epoch 22.005), train_loss = 1.02122369, grad/param norm = 1.9310e-01, time/batch = 19.2818s	
13138/29850 (epoch 22.007), train_loss = 1.06464607, grad/param norm = 2.0683e-01, time/batch = 16.7898s	
13139/29850 (epoch 22.008), train_loss = 1.21668022, grad/param norm = 2.1647e-01, time/batch = 17.2048s	
13140/29850 (epoch 22.010), train_loss = 0.92181888, grad/param norm = 2.0461e-01, time/batch = 17.4554s	
13141/29850 (epoch 22.012), train_loss = 1.00408614, grad/param norm = 1.7712e-01, time/batch = 18.0405s	
13142/29850 (epoch 22.013), train_loss = 1.04005084, grad/param norm = 2.1561e-01, time/batch = 17.2880s	
13143/29850 (epoch 22.015), train_loss = 1.05693315, grad/param norm = 1.8630e-01, time/batch = 16.2849s	
13144/29850 (epoch 22.017), train_loss = 1.03052936, grad/param norm = 2.0432e-01, time/batch = 18.3597s	
13145/29850 (epoch 22.018), train_loss = 1.16311818, grad/param norm = 2.5766e-01, time/batch = 16.9535s	
13146/29850 (epoch 22.020), train_loss = 1.00223809, grad/param norm = 2.1223e-01, time/batch = 17.5544s	
13147/29850 (epoch 22.022), train_loss = 1.12147085, grad/param norm = 2.2314e-01, time/batch = 16.5651s	
13148/29850 (epoch 22.023), train_loss = 1.07402463, grad/param norm = 1.9814e-01, time/batch = 18.3720s	
13149/29850 (epoch 22.025), train_loss = 0.98315583, grad/param norm = 1.7382e-01, time/batch = 17.8826s	
13150/29850 (epoch 22.027), train_loss = 0.80420041, grad/param norm = 1.7777e-01, time/batch = 16.3971s	
13151/29850 (epoch 22.028), train_loss = 0.96424912, grad/param norm = 1.7586e-01, time/batch = 18.8880s	
13152/29850 (epoch 22.030), train_loss = 1.01440990, grad/param norm = 2.0674e-01, time/batch = 17.1045s	
13153/29850 (epoch 22.032), train_loss = 1.06235357, grad/param norm = 1.8994e-01, time/batch = 18.4268s	
13154/29850 (epoch 22.034), train_loss = 0.92524326, grad/param norm = 1.7592e-01, time/batch = 17.9685s	
13155/29850 (epoch 22.035), train_loss = 0.83980710, grad/param norm = 1.7616e-01, time/batch = 14.8870s	
13156/29850 (epoch 22.037), train_loss = 1.00378354, grad/param norm = 1.9185e-01, time/batch = 17.2795s	
13157/29850 (epoch 22.039), train_loss = 0.87908059, grad/param norm = 1.6905e-01, time/batch = 17.0469s	
13158/29850 (epoch 22.040), train_loss = 0.91916303, grad/param norm = 1.8385e-01, time/batch = 17.7280s	
13159/29850 (epoch 22.042), train_loss = 0.92295572, grad/param norm = 2.0567e-01, time/batch = 17.7841s	
13160/29850 (epoch 22.044), train_loss = 0.95285309, grad/param norm = 1.7194e-01, time/batch = 16.1236s	
13161/29850 (epoch 22.045), train_loss = 1.04140145, grad/param norm = 1.8292e-01, time/batch = 18.1407s	
13162/29850 (epoch 22.047), train_loss = 0.87540248, grad/param norm = 1.8447e-01, time/batch = 17.8726s	
13163/29850 (epoch 22.049), train_loss = 1.02408444, grad/param norm = 1.8853e-01, time/batch = 18.4619s	
13164/29850 (epoch 22.050), train_loss = 0.91159956, grad/param norm = 1.8345e-01, time/batch = 17.5137s	
13165/29850 (epoch 22.052), train_loss = 1.10920833, grad/param norm = 2.1585e-01, time/batch = 15.4007s	
13166/29850 (epoch 22.054), train_loss = 1.01725562, grad/param norm = 1.9569e-01, time/batch = 17.8959s	
13167/29850 (epoch 22.055), train_loss = 0.97124912, grad/param norm = 1.8490e-01, time/batch = 17.8874s	
13168/29850 (epoch 22.057), train_loss = 1.07281910, grad/param norm = 1.9007e-01, time/batch = 17.0202s	
13169/29850 (epoch 22.059), train_loss = 1.03926060, grad/param norm = 2.1093e-01, time/batch = 15.8590s	
13170/29850 (epoch 22.060), train_loss = 1.00972990, grad/param norm = 1.8958e-01, time/batch = 16.8805s	
13171/29850 (epoch 22.062), train_loss = 1.11633163, grad/param norm = 2.0405e-01, time/batch = 19.2106s	
13172/29850 (epoch 22.064), train_loss = 1.07826721, grad/param norm = 1.9424e-01, time/batch = 17.9348s	
13173/29850 (epoch 22.065), train_loss = 0.92268689, grad/param norm = 1.9459e-01, time/batch = 16.8030s	
13174/29850 (epoch 22.067), train_loss = 1.04947483, grad/param norm = 1.7388e-01, time/batch = 18.2151s	
13175/29850 (epoch 22.069), train_loss = 1.00533526, grad/param norm = 1.7581e-01, time/batch = 18.6400s	
13176/29850 (epoch 22.070), train_loss = 1.06210476, grad/param norm = 1.8141e-01, time/batch = 16.3759s	
13177/29850 (epoch 22.072), train_loss = 1.06846547, grad/param norm = 2.3973e-01, time/batch = 16.3972s	
13178/29850 (epoch 22.074), train_loss = 1.09002354, grad/param norm = 1.9378e-01, time/batch = 18.3894s	
13179/29850 (epoch 22.075), train_loss = 0.93764364, grad/param norm = 1.8948e-01, time/batch = 18.1223s	
13180/29850 (epoch 22.077), train_loss = 1.06507017, grad/param norm = 2.0966e-01, time/batch = 16.9768s	
13181/29850 (epoch 22.079), train_loss = 1.24633290, grad/param norm = 2.7155e-01, time/batch = 17.3570s	
13182/29850 (epoch 22.080), train_loss = 1.23372171, grad/param norm = 2.4781e-01, time/batch = 17.9615s	
13183/29850 (epoch 22.082), train_loss = 1.08277534, grad/param norm = 1.9970e-01, time/batch = 17.2201s	
13184/29850 (epoch 22.084), train_loss = 1.16059880, grad/param norm = 2.4181e-01, time/batch = 18.3810s	
13185/29850 (epoch 22.085), train_loss = 1.14272245, grad/param norm = 2.1192e-01, time/batch = 18.6369s	
13186/29850 (epoch 22.087), train_loss = 1.14859748, grad/param norm = 2.0049e-01, time/batch = 17.3006s	
13187/29850 (epoch 22.089), train_loss = 1.06718351, grad/param norm = 2.2158e-01, time/batch = 18.2967s	
13188/29850 (epoch 22.090), train_loss = 1.06992580, grad/param norm = 1.9609e-01, time/batch = 17.2148s	
13189/29850 (epoch 22.092), train_loss = 0.98768228, grad/param norm = 2.0530e-01, time/batch = 17.3685s	
13190/29850 (epoch 22.094), train_loss = 1.16437992, grad/param norm = 2.1124e-01, time/batch = 15.9344s	
13191/29850 (epoch 22.095), train_loss = 1.05157195, grad/param norm = 2.2365e-01, time/batch = 18.1120s	
13192/29850 (epoch 22.097), train_loss = 0.84302971, grad/param norm = 1.6727e-01, time/batch = 15.9260s	
13193/29850 (epoch 22.099), train_loss = 0.86034385, grad/param norm = 1.7770e-01, time/batch = 17.1054s	
13194/29850 (epoch 22.101), train_loss = 1.10818517, grad/param norm = 2.0384e-01, time/batch = 17.8910s	
13195/29850 (epoch 22.102), train_loss = 1.07079457, grad/param norm = 2.1247e-01, time/batch = 17.8035s	
13196/29850 (epoch 22.104), train_loss = 0.99320432, grad/param norm = 1.8872e-01, time/batch = 16.8048s	
13197/29850 (epoch 22.106), train_loss = 1.10452099, grad/param norm = 1.9514e-01, time/batch = 18.7981s	
13198/29850 (epoch 22.107), train_loss = 0.88954130, grad/param norm = 1.6200e-01, time/batch = 17.1405s	
13199/29850 (epoch 22.109), train_loss = 0.99039599, grad/param norm = 2.0189e-01, time/batch = 18.5481s	
13200/29850 (epoch 22.111), train_loss = 1.10146491, grad/param norm = 1.8946e-01, time/batch = 18.5190s	
13201/29850 (epoch 22.112), train_loss = 0.94677017, grad/param norm = 1.8349e-01, time/batch = 18.4815s	
13202/29850 (epoch 22.114), train_loss = 0.98334022, grad/param norm = 2.1684e-01, time/batch = 18.3847s	
13203/29850 (epoch 22.116), train_loss = 0.91964236, grad/param norm = 1.8447e-01, time/batch = 16.8699s	
13204/29850 (epoch 22.117), train_loss = 1.02440067, grad/param norm = 2.0338e-01, time/batch = 18.3115s	
13205/29850 (epoch 22.119), train_loss = 0.97880528, grad/param norm = 1.8838e-01, time/batch = 18.7213s	
13206/29850 (epoch 22.121), train_loss = 0.80921982, grad/param norm = 1.8204e-01, time/batch = 17.8715s	
13207/29850 (epoch 22.122), train_loss = 0.86394844, grad/param norm = 1.5477e-01, time/batch = 18.5466s	
13208/29850 (epoch 22.124), train_loss = 0.92638082, grad/param norm = 1.8469e-01, time/batch = 16.3978s	
13209/29850 (epoch 22.126), train_loss = 0.97434016, grad/param norm = 1.9436e-01, time/batch = 17.2034s	
13210/29850 (epoch 22.127), train_loss = 1.11342439, grad/param norm = 2.3465e-01, time/batch = 17.5488s	
13211/29850 (epoch 22.129), train_loss = 0.95120165, grad/param norm = 1.8997e-01, time/batch = 16.0660s	
13212/29850 (epoch 22.131), train_loss = 0.99009520, grad/param norm = 1.8483e-01, time/batch = 17.3058s	
13213/29850 (epoch 22.132), train_loss = 0.88462730, grad/param norm = 1.8226e-01, time/batch = 15.3424s	
13214/29850 (epoch 22.134), train_loss = 1.02632148, grad/param norm = 1.9685e-01, time/batch = 19.0466s	
13215/29850 (epoch 22.136), train_loss = 1.02355017, grad/param norm = 1.7767e-01, time/batch = 17.0463s	
13216/29850 (epoch 22.137), train_loss = 0.81996990, grad/param norm = 1.7186e-01, time/batch = 18.5525s	
13217/29850 (epoch 22.139), train_loss = 0.98260675, grad/param norm = 2.0711e-01, time/batch = 18.4568s	
13218/29850 (epoch 22.141), train_loss = 0.93094945, grad/param norm = 1.8029e-01, time/batch = 17.5505s	
13219/29850 (epoch 22.142), train_loss = 1.10379365, grad/param norm = 2.1391e-01, time/batch = 17.9705s	
13220/29850 (epoch 22.144), train_loss = 1.29310230, grad/param norm = 2.2903e-01, time/batch = 16.4567s	
13221/29850 (epoch 22.146), train_loss = 1.24427111, grad/param norm = 2.2039e-01, time/batch = 17.4896s	
13222/29850 (epoch 22.147), train_loss = 1.07258270, grad/param norm = 2.0152e-01, time/batch = 18.6397s	
13223/29850 (epoch 22.149), train_loss = 1.07876656, grad/param norm = 2.0681e-01, time/batch = 16.9593s	
13224/29850 (epoch 22.151), train_loss = 1.05697635, grad/param norm = 1.9208e-01, time/batch = 16.4652s	
13225/29850 (epoch 22.152), train_loss = 0.95782608, grad/param norm = 1.8156e-01, time/batch = 16.7912s	
13226/29850 (epoch 22.154), train_loss = 0.92530365, grad/param norm = 1.9165e-01, time/batch = 18.3882s	
13227/29850 (epoch 22.156), train_loss = 0.96241664, grad/param norm = 1.9051e-01, time/batch = 17.2782s	
13228/29850 (epoch 22.157), train_loss = 1.03749088, grad/param norm = 1.9161e-01, time/batch = 16.7246s	
13229/29850 (epoch 22.159), train_loss = 0.97848148, grad/param norm = 1.8616e-01, time/batch = 18.3887s	
13230/29850 (epoch 22.161), train_loss = 1.06577219, grad/param norm = 2.2470e-01, time/batch = 16.8671s	
13231/29850 (epoch 22.162), train_loss = 1.15950086, grad/param norm = 2.0934e-01, time/batch = 16.6152s	
13232/29850 (epoch 22.164), train_loss = 1.01470940, grad/param norm = 1.8908e-01, time/batch = 18.7061s	
13233/29850 (epoch 22.166), train_loss = 0.92409624, grad/param norm = 1.7309e-01, time/batch = 17.7961s	
13234/29850 (epoch 22.168), train_loss = 0.86291498, grad/param norm = 1.7668e-01, time/batch = 18.6280s	
13235/29850 (epoch 22.169), train_loss = 1.15231468, grad/param norm = 2.1652e-01, time/batch = 14.7325s	
13236/29850 (epoch 22.171), train_loss = 1.08270218, grad/param norm = 2.0561e-01, time/batch = 17.6387s	
13237/29850 (epoch 22.173), train_loss = 0.94518553, grad/param norm = 1.9884e-01, time/batch = 15.9693s	
13238/29850 (epoch 22.174), train_loss = 1.05735264, grad/param norm = 2.1603e-01, time/batch = 18.3868s	
13239/29850 (epoch 22.176), train_loss = 1.02956494, grad/param norm = 1.9835e-01, time/batch = 17.0622s	
13240/29850 (epoch 22.178), train_loss = 1.09228099, grad/param norm = 2.1329e-01, time/batch = 18.1031s	
13241/29850 (epoch 22.179), train_loss = 0.87706348, grad/param norm = 1.7576e-01, time/batch = 16.6433s	
13242/29850 (epoch 22.181), train_loss = 1.01969555, grad/param norm = 1.9903e-01, time/batch = 17.7278s	
13243/29850 (epoch 22.183), train_loss = 1.01928442, grad/param norm = 1.9732e-01, time/batch = 16.7022s	
13244/29850 (epoch 22.184), train_loss = 1.04198934, grad/param norm = 1.9940e-01, time/batch = 16.8734s	
13245/29850 (epoch 22.186), train_loss = 1.02989342, grad/param norm = 2.0545e-01, time/batch = 17.0546s	
13246/29850 (epoch 22.188), train_loss = 1.13156077, grad/param norm = 2.2232e-01, time/batch = 16.5381s	
13247/29850 (epoch 22.189), train_loss = 1.14372180, grad/param norm = 2.0857e-01, time/batch = 16.3477s	
13248/29850 (epoch 22.191), train_loss = 1.09764324, grad/param norm = 2.2048e-01, time/batch = 19.4403s	
13249/29850 (epoch 22.193), train_loss = 0.99195374, grad/param norm = 1.9534e-01, time/batch = 16.2005s	
13250/29850 (epoch 22.194), train_loss = 1.05092814, grad/param norm = 1.9145e-01, time/batch = 17.7967s	
13251/29850 (epoch 22.196), train_loss = 0.98747013, grad/param norm = 1.9924e-01, time/batch = 17.0490s	
13252/29850 (epoch 22.198), train_loss = 1.01903999, grad/param norm = 2.1876e-01, time/batch = 18.6189s	
13253/29850 (epoch 22.199), train_loss = 1.24047336, grad/param norm = 2.1759e-01, time/batch = 19.4589s	
13254/29850 (epoch 22.201), train_loss = 0.95379973, grad/param norm = 1.8285e-01, time/batch = 15.8000s	
13255/29850 (epoch 22.203), train_loss = 0.80238500, grad/param norm = 1.8421e-01, time/batch = 18.9440s	
13256/29850 (epoch 22.204), train_loss = 1.05770252, grad/param norm = 2.4026e-01, time/batch = 18.6372s	
13257/29850 (epoch 22.206), train_loss = 0.91550440, grad/param norm = 2.2888e-01, time/batch = 17.6242s	
13258/29850 (epoch 22.208), train_loss = 1.15338752, grad/param norm = 1.9840e-01, time/batch = 17.7179s	
13259/29850 (epoch 22.209), train_loss = 0.89286791, grad/param norm = 1.7291e-01, time/batch = 17.3953s	
13260/29850 (epoch 22.211), train_loss = 0.97619405, grad/param norm = 1.9161e-01, time/batch = 14.9531s	
13261/29850 (epoch 22.213), train_loss = 1.09796049, grad/param norm = 2.0572e-01, time/batch = 16.5393s	
13262/29850 (epoch 22.214), train_loss = 0.91288024, grad/param norm = 1.7089e-01, time/batch = 18.3953s	
13263/29850 (epoch 22.216), train_loss = 0.96552550, grad/param norm = 2.0294e-01, time/batch = 17.0138s	
13264/29850 (epoch 22.218), train_loss = 1.10132530, grad/param norm = 2.0490e-01, time/batch = 17.5464s	
13265/29850 (epoch 22.219), train_loss = 1.10332652, grad/param norm = 2.4263e-01, time/batch = 17.7927s	
13266/29850 (epoch 22.221), train_loss = 1.02569410, grad/param norm = 1.9543e-01, time/batch = 15.6266s	
13267/29850 (epoch 22.223), train_loss = 0.93670134, grad/param norm = 2.0799e-01, time/batch = 16.7026s	
13268/29850 (epoch 22.224), train_loss = 0.90614634, grad/param norm = 2.0518e-01, time/batch = 16.3831s	
13269/29850 (epoch 22.226), train_loss = 0.92432683, grad/param norm = 1.7697e-01, time/batch = 14.4801s	
13270/29850 (epoch 22.228), train_loss = 0.98901835, grad/param norm = 1.8217e-01, time/batch = 19.2942s	
13271/29850 (epoch 22.229), train_loss = 0.84306605, grad/param norm = 1.5601e-01, time/batch = 17.9558s	
13272/29850 (epoch 22.231), train_loss = 1.00582388, grad/param norm = 1.8306e-01, time/batch = 16.1251s	
13273/29850 (epoch 22.233), train_loss = 0.97369818, grad/param norm = 2.0594e-01, time/batch = 16.8745s	
13274/29850 (epoch 22.235), train_loss = 0.90586004, grad/param norm = 1.8083e-01, time/batch = 18.9636s	
13275/29850 (epoch 22.236), train_loss = 1.13874662, grad/param norm = 2.0861e-01, time/batch = 16.4573s	
13276/29850 (epoch 22.238), train_loss = 0.91473202, grad/param norm = 1.8636e-01, time/batch = 18.4644s	
13277/29850 (epoch 22.240), train_loss = 0.89138705, grad/param norm = 1.8024e-01, time/batch = 17.4814s	
13278/29850 (epoch 22.241), train_loss = 1.06351380, grad/param norm = 2.1094e-01, time/batch = 18.0321s	
13279/29850 (epoch 22.243), train_loss = 1.03282439, grad/param norm = 1.9550e-01, time/batch = 16.6103s	
13280/29850 (epoch 22.245), train_loss = 0.94240980, grad/param norm = 1.9162e-01, time/batch = 16.1336s	
13281/29850 (epoch 22.246), train_loss = 0.88819035, grad/param norm = 1.6875e-01, time/batch = 17.9658s	
13282/29850 (epoch 22.248), train_loss = 0.87844611, grad/param norm = 1.7973e-01, time/batch = 16.5434s	
13283/29850 (epoch 22.250), train_loss = 0.97057435, grad/param norm = 1.7506e-01, time/batch = 18.8219s	
13284/29850 (epoch 22.251), train_loss = 0.85809063, grad/param norm = 1.9746e-01, time/batch = 17.1344s	
13285/29850 (epoch 22.253), train_loss = 0.80082644, grad/param norm = 1.7995e-01, time/batch = 17.4527s	
13286/29850 (epoch 22.255), train_loss = 0.89646686, grad/param norm = 1.8102e-01, time/batch = 17.8661s	
13287/29850 (epoch 22.256), train_loss = 1.03766749, grad/param norm = 1.9366e-01, time/batch = 18.3843s	
13288/29850 (epoch 22.258), train_loss = 1.00708528, grad/param norm = 1.9803e-01, time/batch = 17.8731s	
13289/29850 (epoch 22.260), train_loss = 0.98269092, grad/param norm = 1.8785e-01, time/batch = 16.6347s	
13290/29850 (epoch 22.261), train_loss = 0.91320312, grad/param norm = 1.9823e-01, time/batch = 18.3937s	
13291/29850 (epoch 22.263), train_loss = 0.89011533, grad/param norm = 1.7931e-01, time/batch = 18.7997s	
13292/29850 (epoch 22.265), train_loss = 0.97651551, grad/param norm = 1.8763e-01, time/batch = 15.2786s	
13293/29850 (epoch 22.266), train_loss = 0.98284103, grad/param norm = 1.9907e-01, time/batch = 18.1361s	
13294/29850 (epoch 22.268), train_loss = 0.94553831, grad/param norm = 1.6981e-01, time/batch = 17.2940s	
13295/29850 (epoch 22.270), train_loss = 0.92096061, grad/param norm = 1.8667e-01, time/batch = 16.8000s	
13296/29850 (epoch 22.271), train_loss = 1.05994153, grad/param norm = 1.9441e-01, time/batch = 16.6350s	
13297/29850 (epoch 22.273), train_loss = 0.85098951, grad/param norm = 1.8657e-01, time/batch = 15.0851s	
13298/29850 (epoch 22.275), train_loss = 0.86974916, grad/param norm = 2.1579e-01, time/batch = 18.3738s	
13299/29850 (epoch 22.276), train_loss = 0.89512758, grad/param norm = 1.8977e-01, time/batch = 18.0395s	
13300/29850 (epoch 22.278), train_loss = 0.94202678, grad/param norm = 1.8299e-01, time/batch = 19.1306s	
13301/29850 (epoch 22.280), train_loss = 1.12049382, grad/param norm = 2.2814e-01, time/batch = 17.5393s	
13302/29850 (epoch 22.281), train_loss = 1.04160211, grad/param norm = 2.0647e-01, time/batch = 17.8806s	
13303/29850 (epoch 22.283), train_loss = 1.13885270, grad/param norm = 2.4128e-01, time/batch = 17.0338s	
13304/29850 (epoch 22.285), train_loss = 1.00301497, grad/param norm = 2.2021e-01, time/batch = 18.1211s	
13305/29850 (epoch 22.286), train_loss = 1.09147369, grad/param norm = 2.0889e-01, time/batch = 16.0361s	
13306/29850 (epoch 22.288), train_loss = 1.10915112, grad/param norm = 2.4285e-01, time/batch = 17.8782s	
13307/29850 (epoch 22.290), train_loss = 1.03188434, grad/param norm = 2.2609e-01, time/batch = 17.3071s	
13308/29850 (epoch 22.291), train_loss = 1.20431351, grad/param norm = 2.1157e-01, time/batch = 19.0430s	
13309/29850 (epoch 22.293), train_loss = 1.10444364, grad/param norm = 2.7238e-01, time/batch = 15.5221s	
13310/29850 (epoch 22.295), train_loss = 1.16197652, grad/param norm = 2.1582e-01, time/batch = 17.9586s	
13311/29850 (epoch 22.296), train_loss = 0.91383718, grad/param norm = 1.8425e-01, time/batch = 17.7878s	
13312/29850 (epoch 22.298), train_loss = 0.80230763, grad/param norm = 1.8144e-01, time/batch = 16.4262s	
13313/29850 (epoch 22.300), train_loss = 0.86405957, grad/param norm = 1.7636e-01, time/batch = 18.3832s	
13314/29850 (epoch 22.302), train_loss = 0.86429918, grad/param norm = 1.8345e-01, time/batch = 16.8773s	
13315/29850 (epoch 22.303), train_loss = 0.92256688, grad/param norm = 1.9135e-01, time/batch = 17.5482s	
13316/29850 (epoch 22.305), train_loss = 1.03702550, grad/param norm = 1.8421e-01, time/batch = 17.1330s	
13317/29850 (epoch 22.307), train_loss = 1.07892924, grad/param norm = 1.7727e-01, time/batch = 16.5586s	
13318/29850 (epoch 22.308), train_loss = 0.92425167, grad/param norm = 1.8033e-01, time/batch = 19.0561s	
13319/29850 (epoch 22.310), train_loss = 1.03176242, grad/param norm = 2.1149e-01, time/batch = 17.8782s	
13320/29850 (epoch 22.312), train_loss = 1.06775028, grad/param norm = 1.8798e-01, time/batch = 19.0386s	
13321/29850 (epoch 22.313), train_loss = 1.01249339, grad/param norm = 1.9419e-01, time/batch = 15.3717s	
13322/29850 (epoch 22.315), train_loss = 1.01841122, grad/param norm = 1.9039e-01, time/batch = 17.8800s	
13323/29850 (epoch 22.317), train_loss = 1.00058211, grad/param norm = 2.0691e-01, time/batch = 18.3720s	
13324/29850 (epoch 22.318), train_loss = 0.99846564, grad/param norm = 2.0327e-01, time/batch = 18.1395s	
13325/29850 (epoch 22.320), train_loss = 0.93119378, grad/param norm = 1.6767e-01, time/batch = 17.9746s	
13326/29850 (epoch 22.322), train_loss = 1.13959100, grad/param norm = 1.9297e-01, time/batch = 25.3552s	
13327/29850 (epoch 22.323), train_loss = 1.08156412, grad/param norm = 2.3231e-01, time/batch = 21.2556s	
13328/29850 (epoch 22.325), train_loss = 1.11945877, grad/param norm = 2.1784e-01, time/batch = 15.6324s	
13329/29850 (epoch 22.327), train_loss = 1.21241531, grad/param norm = 2.2154e-01, time/batch = 16.0481s	
13330/29850 (epoch 22.328), train_loss = 1.13958022, grad/param norm = 2.2051e-01, time/batch = 19.0471s	
13331/29850 (epoch 22.330), train_loss = 1.05782845, grad/param norm = 1.8720e-01, time/batch = 16.2167s	
13332/29850 (epoch 22.332), train_loss = 0.98370477, grad/param norm = 1.9335e-01, time/batch = 18.2163s	
13333/29850 (epoch 22.333), train_loss = 1.10075489, grad/param norm = 2.0365e-01, time/batch = 18.7984s	
13334/29850 (epoch 22.335), train_loss = 1.14291721, grad/param norm = 2.2435e-01, time/batch = 16.9113s	
13335/29850 (epoch 22.337), train_loss = 1.02320033, grad/param norm = 1.9745e-01, time/batch = 18.3847s	
13336/29850 (epoch 22.338), train_loss = 1.03136146, grad/param norm = 1.9142e-01, time/batch = 19.2701s	
13337/29850 (epoch 22.340), train_loss = 0.92977013, grad/param norm = 1.8524e-01, time/batch = 16.8940s	
13338/29850 (epoch 22.342), train_loss = 1.04087685, grad/param norm = 2.1998e-01, time/batch = 17.9603s	
13339/29850 (epoch 22.343), train_loss = 1.04253130, grad/param norm = 2.1902e-01, time/batch = 15.7785s	
13340/29850 (epoch 22.345), train_loss = 1.10011953, grad/param norm = 2.4559e-01, time/batch = 16.7854s	
13341/29850 (epoch 22.347), train_loss = 1.11815949, grad/param norm = 2.0901e-01, time/batch = 17.0563s	
13342/29850 (epoch 22.348), train_loss = 0.98113759, grad/param norm = 1.9472e-01, time/batch = 17.6218s	
13343/29850 (epoch 22.350), train_loss = 1.10927208, grad/param norm = 2.4587e-01, time/batch = 18.2810s	
13344/29850 (epoch 22.352), train_loss = 0.95346533, grad/param norm = 1.9326e-01, time/batch = 18.0534s	
13345/29850 (epoch 22.353), train_loss = 1.07731036, grad/param norm = 1.9801e-01, time/batch = 16.1491s	
13346/29850 (epoch 22.355), train_loss = 0.94440082, grad/param norm = 2.1736e-01, time/batch = 15.3829s	
13347/29850 (epoch 22.357), train_loss = 1.13991919, grad/param norm = 2.0616e-01, time/batch = 19.2734s	
13348/29850 (epoch 22.358), train_loss = 0.94266117, grad/param norm = 1.9485e-01, time/batch = 17.3232s	
13349/29850 (epoch 22.360), train_loss = 1.00108402, grad/param norm = 2.0762e-01, time/batch = 17.2089s	
13350/29850 (epoch 22.362), train_loss = 1.00988747, grad/param norm = 2.0070e-01, time/batch = 15.7703s	
13351/29850 (epoch 22.363), train_loss = 1.06487067, grad/param norm = 2.2846e-01, time/batch = 18.2048s	
13352/29850 (epoch 22.365), train_loss = 1.17847991, grad/param norm = 2.1825e-01, time/batch = 18.6073s	
13353/29850 (epoch 22.367), train_loss = 0.95089857, grad/param norm = 2.0653e-01, time/batch = 17.4429s	
13354/29850 (epoch 22.369), train_loss = 0.88078161, grad/param norm = 1.9510e-01, time/batch = 16.3964s	
13355/29850 (epoch 22.370), train_loss = 0.84288798, grad/param norm = 2.2207e-01, time/batch = 18.1326s	
13356/29850 (epoch 22.372), train_loss = 1.11312775, grad/param norm = 2.2031e-01, time/batch = 17.3390s	
13357/29850 (epoch 22.374), train_loss = 1.07054551, grad/param norm = 2.1285e-01, time/batch = 17.8100s	
13358/29850 (epoch 22.375), train_loss = 1.00448495, grad/param norm = 1.8819e-01, time/batch = 16.9570s	
13359/29850 (epoch 22.377), train_loss = 0.97693876, grad/param norm = 2.0193e-01, time/batch = 18.6954s	
13360/29850 (epoch 22.379), train_loss = 1.11081476, grad/param norm = 2.0115e-01, time/batch = 16.2129s	
13361/29850 (epoch 22.380), train_loss = 1.07540410, grad/param norm = 2.0086e-01, time/batch = 15.8774s	
13362/29850 (epoch 22.382), train_loss = 1.07046516, grad/param norm = 2.3874e-01, time/batch = 17.5505s	
13363/29850 (epoch 22.384), train_loss = 1.06745653, grad/param norm = 2.0515e-01, time/batch = 16.7132s	
13364/29850 (epoch 22.385), train_loss = 1.02416132, grad/param norm = 2.1240e-01, time/batch = 18.3817s	
13365/29850 (epoch 22.387), train_loss = 1.06506502, grad/param norm = 2.0175e-01, time/batch = 16.2106s	
13366/29850 (epoch 22.389), train_loss = 1.17459670, grad/param norm = 2.1563e-01, time/batch = 18.2824s	
13367/29850 (epoch 22.390), train_loss = 1.08332449, grad/param norm = 1.9005e-01, time/batch = 19.5242s	
13368/29850 (epoch 22.392), train_loss = 0.99894720, grad/param norm = 2.0630e-01, time/batch = 17.6334s	
13369/29850 (epoch 22.394), train_loss = 1.12302475, grad/param norm = 1.9771e-01, time/batch = 15.8766s	
13370/29850 (epoch 22.395), train_loss = 0.99198123, grad/param norm = 2.2816e-01, time/batch = 16.6222s	
13371/29850 (epoch 22.397), train_loss = 0.91027883, grad/param norm = 2.2989e-01, time/batch = 17.5353s	
13372/29850 (epoch 22.399), train_loss = 0.92820096, grad/param norm = 1.7699e-01, time/batch = 18.3719s	
13373/29850 (epoch 22.400), train_loss = 1.31239693, grad/param norm = 2.2215e-01, time/batch = 16.9658s	
13374/29850 (epoch 22.402), train_loss = 1.21084210, grad/param norm = 2.0408e-01, time/batch = 18.3691s	
13375/29850 (epoch 22.404), train_loss = 1.05972376, grad/param norm = 2.0017e-01, time/batch = 18.2898s	
13376/29850 (epoch 22.405), train_loss = 0.95674361, grad/param norm = 2.0301e-01, time/batch = 18.5465s	
13377/29850 (epoch 22.407), train_loss = 0.94176988, grad/param norm = 2.0723e-01, time/batch = 17.2863s	
13378/29850 (epoch 22.409), train_loss = 1.07673328, grad/param norm = 2.0038e-01, time/batch = 16.7964s	
13379/29850 (epoch 22.410), train_loss = 1.18589220, grad/param norm = 2.2431e-01, time/batch = 18.2239s	
13380/29850 (epoch 22.412), train_loss = 1.13550802, grad/param norm = 1.9953e-01, time/batch = 17.5456s	
13381/29850 (epoch 22.414), train_loss = 1.02192651, grad/param norm = 2.1250e-01, time/batch = 18.7841s	
13382/29850 (epoch 22.415), train_loss = 1.02797512, grad/param norm = 2.0396e-01, time/batch = 15.7912s	
13383/29850 (epoch 22.417), train_loss = 1.17427597, grad/param norm = 2.1634e-01, time/batch = 15.6181s	
13384/29850 (epoch 22.419), train_loss = 1.01842692, grad/param norm = 2.1865e-01, time/batch = 16.6205s	
13385/29850 (epoch 22.420), train_loss = 1.03200140, grad/param norm = 1.9890e-01, time/batch = 18.1384s	
13386/29850 (epoch 22.422), train_loss = 1.02265826, grad/param norm = 1.9537e-01, time/batch = 18.7188s	
13387/29850 (epoch 22.424), train_loss = 0.96315280, grad/param norm = 1.9364e-01, time/batch = 16.1564s	
13388/29850 (epoch 22.425), train_loss = 1.13658729, grad/param norm = 2.0766e-01, time/batch = 17.8862s	
13389/29850 (epoch 22.427), train_loss = 0.84093922, grad/param norm = 1.6667e-01, time/batch = 17.0501s	
13390/29850 (epoch 22.429), train_loss = 0.92040976, grad/param norm = 1.9075e-01, time/batch = 17.5411s	
13391/29850 (epoch 22.430), train_loss = 0.84571688, grad/param norm = 1.6800e-01, time/batch = 18.3734s	
13392/29850 (epoch 22.432), train_loss = 0.98039296, grad/param norm = 2.5767e-01, time/batch = 17.7183s	
13393/29850 (epoch 22.434), train_loss = 0.89079575, grad/param norm = 1.7275e-01, time/batch = 16.4788s	
13394/29850 (epoch 22.436), train_loss = 1.00792162, grad/param norm = 2.0462e-01, time/batch = 16.1192s	
13395/29850 (epoch 22.437), train_loss = 1.07771198, grad/param norm = 1.9097e-01, time/batch = 17.2246s	
13396/29850 (epoch 22.439), train_loss = 1.06110335, grad/param norm = 2.0171e-01, time/batch = 16.9640s	
13397/29850 (epoch 22.441), train_loss = 1.05047237, grad/param norm = 2.1092e-01, time/batch = 17.8827s	
13398/29850 (epoch 22.442), train_loss = 1.01716628, grad/param norm = 1.9312e-01, time/batch = 16.3668s	
13399/29850 (epoch 22.444), train_loss = 1.05724923, grad/param norm = 2.0525e-01, time/batch = 16.7803s	
13400/29850 (epoch 22.446), train_loss = 1.08105447, grad/param norm = 1.9840e-01, time/batch = 17.5426s	
13401/29850 (epoch 22.447), train_loss = 1.10142753, grad/param norm = 2.2572e-01, time/batch = 17.8007s	
13402/29850 (epoch 22.449), train_loss = 1.03250916, grad/param norm = 2.1929e-01, time/batch = 16.7293s	
13403/29850 (epoch 22.451), train_loss = 0.86440804, grad/param norm = 1.8723e-01, time/batch = 18.3955s	
13404/29850 (epoch 22.452), train_loss = 0.76334507, grad/param norm = 1.6298e-01, time/batch = 17.1236s	
13405/29850 (epoch 22.454), train_loss = 0.87535581, grad/param norm = 1.7668e-01, time/batch = 18.8071s	
13406/29850 (epoch 22.456), train_loss = 1.06324928, grad/param norm = 2.0218e-01, time/batch = 17.7135s	
13407/29850 (epoch 22.457), train_loss = 1.07274574, grad/param norm = 3.0202e-01, time/batch = 18.1463s	
13408/29850 (epoch 22.459), train_loss = 1.20725846, grad/param norm = 2.3230e-01, time/batch = 16.3471s	
13409/29850 (epoch 22.461), train_loss = 1.17401346, grad/param norm = 2.0621e-01, time/batch = 18.6447s	
13410/29850 (epoch 22.462), train_loss = 1.15582401, grad/param norm = 2.1787e-01, time/batch = 18.2245s	
13411/29850 (epoch 22.464), train_loss = 1.07006999, grad/param norm = 2.0728e-01, time/batch = 17.1990s	
13412/29850 (epoch 22.466), train_loss = 0.89724256, grad/param norm = 2.0200e-01, time/batch = 16.5592s	
13413/29850 (epoch 22.467), train_loss = 1.00149423, grad/param norm = 2.0147e-01, time/batch = 16.9772s	
13414/29850 (epoch 22.469), train_loss = 1.00287682, grad/param norm = 2.1559e-01, time/batch = 17.7158s	
13415/29850 (epoch 22.471), train_loss = 0.99905745, grad/param norm = 1.9977e-01, time/batch = 17.9722s	
13416/29850 (epoch 22.472), train_loss = 0.97467822, grad/param norm = 1.8313e-01, time/batch = 16.4712s	
13417/29850 (epoch 22.474), train_loss = 1.12168331, grad/param norm = 2.0008e-01, time/batch = 17.2192s	
13418/29850 (epoch 22.476), train_loss = 1.03162870, grad/param norm = 1.7240e-01, time/batch = 16.1524s	
13419/29850 (epoch 22.477), train_loss = 1.03987508, grad/param norm = 2.1353e-01, time/batch = 15.8677s	
13420/29850 (epoch 22.479), train_loss = 1.18266490, grad/param norm = 2.1472e-01, time/batch = 17.6418s	
13421/29850 (epoch 22.481), train_loss = 0.98734045, grad/param norm = 2.0108e-01, time/batch = 17.7919s	
13422/29850 (epoch 22.482), train_loss = 0.94324254, grad/param norm = 1.7390e-01, time/batch = 17.3196s	
13423/29850 (epoch 22.484), train_loss = 0.98307970, grad/param norm = 1.9865e-01, time/batch = 17.0407s	
13424/29850 (epoch 22.486), train_loss = 1.04380970, grad/param norm = 2.0251e-01, time/batch = 18.0624s	
13425/29850 (epoch 22.487), train_loss = 1.02108195, grad/param norm = 2.0650e-01, time/batch = 16.3873s	
13426/29850 (epoch 22.489), train_loss = 1.02439082, grad/param norm = 2.1316e-01, time/batch = 17.0688s	
13427/29850 (epoch 22.491), train_loss = 0.91327734, grad/param norm = 1.8230e-01, time/batch = 18.1508s	
13428/29850 (epoch 22.492), train_loss = 1.02040709, grad/param norm = 2.2164e-01, time/batch = 17.1120s	
13429/29850 (epoch 22.494), train_loss = 1.13442118, grad/param norm = 1.9731e-01, time/batch = 17.7756s	
13430/29850 (epoch 22.496), train_loss = 1.18653754, grad/param norm = 1.8711e-01, time/batch = 16.2143s	
13431/29850 (epoch 22.497), train_loss = 1.09091109, grad/param norm = 2.0325e-01, time/batch = 17.9720s	
13432/29850 (epoch 22.499), train_loss = 1.02979091, grad/param norm = 1.9867e-01, time/batch = 16.0485s	
13433/29850 (epoch 22.501), train_loss = 0.95966563, grad/param norm = 2.2573e-01, time/batch = 18.2290s	
13434/29850 (epoch 22.503), train_loss = 1.01654091, grad/param norm = 1.7792e-01, time/batch = 17.7012s	
13435/29850 (epoch 22.504), train_loss = 1.27230901, grad/param norm = 2.1900e-01, time/batch = 17.1870s	
13436/29850 (epoch 22.506), train_loss = 1.18579165, grad/param norm = 2.0848e-01, time/batch = 18.6297s	
13437/29850 (epoch 22.508), train_loss = 1.04793444, grad/param norm = 2.0998e-01, time/batch = 18.3066s	
13438/29850 (epoch 22.509), train_loss = 0.83047342, grad/param norm = 1.7408e-01, time/batch = 18.4606s	
13439/29850 (epoch 22.511), train_loss = 1.04930997, grad/param norm = 1.9765e-01, time/batch = 16.1870s	
13440/29850 (epoch 22.513), train_loss = 1.06731569, grad/param norm = 2.3880e-01, time/batch = 15.8771s	
13441/29850 (epoch 22.514), train_loss = 0.93793911, grad/param norm = 2.3364e-01, time/batch = 18.4488s	
13442/29850 (epoch 22.516), train_loss = 0.95625237, grad/param norm = 1.6264e-01, time/batch = 18.1976s	
13443/29850 (epoch 22.518), train_loss = 0.85114780, grad/param norm = 2.0185e-01, time/batch = 17.6203s	
13444/29850 (epoch 22.519), train_loss = 0.86050448, grad/param norm = 1.7300e-01, time/batch = 18.7111s	
13445/29850 (epoch 22.521), train_loss = 0.81929840, grad/param norm = 1.6625e-01, time/batch = 15.2910s	
13446/29850 (epoch 22.523), train_loss = 0.86510409, grad/param norm = 1.6723e-01, time/batch = 15.2712s	
13447/29850 (epoch 22.524), train_loss = 0.94727496, grad/param norm = 2.0449e-01, time/batch = 15.6196s	
13448/29850 (epoch 22.526), train_loss = 1.04117274, grad/param norm = 2.1727e-01, time/batch = 17.3914s	
13449/29850 (epoch 22.528), train_loss = 1.08941633, grad/param norm = 2.1007e-01, time/batch = 17.9593s	
13450/29850 (epoch 22.529), train_loss = 1.05157797, grad/param norm = 1.9687e-01, time/batch = 17.0353s	
13451/29850 (epoch 22.531), train_loss = 0.98172971, grad/param norm = 1.9507e-01, time/batch = 16.0521s	
13452/29850 (epoch 22.533), train_loss = 0.97556079, grad/param norm = 1.8784e-01, time/batch = 16.9477s	
13453/29850 (epoch 22.534), train_loss = 1.03774368, grad/param norm = 1.9716e-01, time/batch = 17.7094s	
13454/29850 (epoch 22.536), train_loss = 0.96157671, grad/param norm = 2.0415e-01, time/batch = 15.3320s	
13455/29850 (epoch 22.538), train_loss = 1.10920879, grad/param norm = 2.1568e-01, time/batch = 17.4724s	
13456/29850 (epoch 22.539), train_loss = 1.19572751, grad/param norm = 2.3599e-01, time/batch = 16.1363s	
13457/29850 (epoch 22.541), train_loss = 0.80978322, grad/param norm = 1.7594e-01, time/batch = 17.5506s	
13458/29850 (epoch 22.543), train_loss = 1.02452284, grad/param norm = 1.9093e-01, time/batch = 18.6443s	
13459/29850 (epoch 22.544), train_loss = 1.06768822, grad/param norm = 2.0001e-01, time/batch = 16.9645s	
13460/29850 (epoch 22.546), train_loss = 1.10644618, grad/param norm = 1.9824e-01, time/batch = 16.7794s	
13461/29850 (epoch 22.548), train_loss = 0.87610819, grad/param norm = 1.7366e-01, time/batch = 18.4781s	
13462/29850 (epoch 22.549), train_loss = 0.98803519, grad/param norm = 1.8883e-01, time/batch = 18.7092s	
13463/29850 (epoch 22.551), train_loss = 0.87113347, grad/param norm = 1.6301e-01, time/batch = 16.2982s	
13464/29850 (epoch 22.553), train_loss = 1.00615525, grad/param norm = 1.8704e-01, time/batch = 15.1231s	
13465/29850 (epoch 22.554), train_loss = 0.86348314, grad/param norm = 1.7399e-01, time/batch = 17.4548s	
13466/29850 (epoch 22.556), train_loss = 0.91966106, grad/param norm = 1.9686e-01, time/batch = 17.7064s	
13467/29850 (epoch 22.558), train_loss = 0.92111799, grad/param norm = 1.7266e-01, time/batch = 17.8028s	
13468/29850 (epoch 22.559), train_loss = 0.98056304, grad/param norm = 1.8688e-01, time/batch = 16.7183s	
13469/29850 (epoch 22.561), train_loss = 1.07006593, grad/param norm = 2.0165e-01, time/batch = 17.6304s	
13470/29850 (epoch 22.563), train_loss = 1.04510168, grad/param norm = 2.0638e-01, time/batch = 16.8808s	
13471/29850 (epoch 22.564), train_loss = 0.98931784, grad/param norm = 2.0039e-01, time/batch = 18.7028s	
13472/29850 (epoch 22.566), train_loss = 1.06234757, grad/param norm = 2.2320e-01, time/batch = 18.7939s	
13473/29850 (epoch 22.568), train_loss = 1.11671560, grad/param norm = 2.1980e-01, time/batch = 15.4704s	
13474/29850 (epoch 22.570), train_loss = 1.04294532, grad/param norm = 2.0440e-01, time/batch = 18.8928s	
13475/29850 (epoch 22.571), train_loss = 1.09982687, grad/param norm = 2.0124e-01, time/batch = 16.6006s	
13476/29850 (epoch 22.573), train_loss = 1.18766905, grad/param norm = 2.2951e-01, time/batch = 17.8049s	
13477/29850 (epoch 22.575), train_loss = 1.12502383, grad/param norm = 1.8953e-01, time/batch = 17.4498s	
13478/29850 (epoch 22.576), train_loss = 1.10283950, grad/param norm = 1.9880e-01, time/batch = 17.0683s	
13479/29850 (epoch 22.578), train_loss = 0.98103966, grad/param norm = 2.1880e-01, time/batch = 16.3768s	
13480/29850 (epoch 22.580), train_loss = 1.14719444, grad/param norm = 2.0452e-01, time/batch = 17.1352s	
13481/29850 (epoch 22.581), train_loss = 0.93402746, grad/param norm = 1.8655e-01, time/batch = 16.8770s	
13482/29850 (epoch 22.583), train_loss = 1.02783640, grad/param norm = 1.9807e-01, time/batch = 17.7260s	
13483/29850 (epoch 22.585), train_loss = 1.04546979, grad/param norm = 1.8968e-01, time/batch = 17.5633s	
13484/29850 (epoch 22.586), train_loss = 1.03646583, grad/param norm = 1.9180e-01, time/batch = 16.2873s	
13485/29850 (epoch 22.588), train_loss = 0.98931482, grad/param norm = 2.0554e-01, time/batch = 17.1300s	
13486/29850 (epoch 22.590), train_loss = 0.97174939, grad/param norm = 1.9413e-01, time/batch = 17.6215s	
13487/29850 (epoch 22.591), train_loss = 0.99310113, grad/param norm = 2.1028e-01, time/batch = 16.4312s	
13488/29850 (epoch 22.593), train_loss = 0.94852777, grad/param norm = 1.9500e-01, time/batch = 19.3756s	
13489/29850 (epoch 22.595), train_loss = 0.88562735, grad/param norm = 1.6632e-01, time/batch = 16.4867s	
13490/29850 (epoch 22.596), train_loss = 0.89269401, grad/param norm = 2.0162e-01, time/batch = 16.8653s	
13491/29850 (epoch 22.598), train_loss = 0.98152283, grad/param norm = 1.7900e-01, time/batch = 17.7076s	
13492/29850 (epoch 22.600), train_loss = 1.03959138, grad/param norm = 1.9552e-01, time/batch = 17.8702s	
13493/29850 (epoch 22.601), train_loss = 0.89082236, grad/param norm = 1.7261e-01, time/batch = 18.4637s	
13494/29850 (epoch 22.603), train_loss = 0.95574829, grad/param norm = 1.8973e-01, time/batch = 17.6974s	
13495/29850 (epoch 22.605), train_loss = 0.98105414, grad/param norm = 2.0372e-01, time/batch = 19.5314s	
13496/29850 (epoch 22.606), train_loss = 0.75038315, grad/param norm = 1.6291e-01, time/batch = 17.3010s	
13497/29850 (epoch 22.608), train_loss = 0.93182677, grad/param norm = 1.7728e-01, time/batch = 16.6285s	
13498/29850 (epoch 22.610), train_loss = 0.99509502, grad/param norm = 1.9594e-01, time/batch = 18.2976s	
13499/29850 (epoch 22.611), train_loss = 0.91763975, grad/param norm = 1.8679e-01, time/batch = 16.9624s	
13500/29850 (epoch 22.613), train_loss = 0.76992203, grad/param norm = 1.6882e-01, time/batch = 18.0561s	
13501/29850 (epoch 22.615), train_loss = 0.89551676, grad/param norm = 1.7526e-01, time/batch = 16.4578s	
13502/29850 (epoch 22.616), train_loss = 0.87926589, grad/param norm = 1.9232e-01, time/batch = 16.0350s	
13503/29850 (epoch 22.618), train_loss = 0.97068594, grad/param norm = 2.0315e-01, time/batch = 16.8722s	
13504/29850 (epoch 22.620), train_loss = 1.03462834, grad/param norm = 2.0325e-01, time/batch = 17.0359s	
13505/29850 (epoch 22.621), train_loss = 1.15623745, grad/param norm = 2.2871e-01, time/batch = 18.8009s	
13506/29850 (epoch 22.623), train_loss = 1.06212732, grad/param norm = 2.0678e-01, time/batch = 17.3662s	
13507/29850 (epoch 22.625), train_loss = 1.03157343, grad/param norm = 2.0604e-01, time/batch = 17.8036s	
13508/29850 (epoch 22.626), train_loss = 1.05133957, grad/param norm = 2.0885e-01, time/batch = 16.7741s	
13509/29850 (epoch 22.628), train_loss = 0.91500373, grad/param norm = 1.7476e-01, time/batch = 17.6419s	
13510/29850 (epoch 22.630), train_loss = 1.01171415, grad/param norm = 2.0728e-01, time/batch = 18.4768s	
13511/29850 (epoch 22.631), train_loss = 0.98841838, grad/param norm = 1.9504e-01, time/batch = 17.3833s	
13512/29850 (epoch 22.633), train_loss = 1.07620223, grad/param norm = 2.2678e-01, time/batch = 18.3911s	
13513/29850 (epoch 22.635), train_loss = 0.95837173, grad/param norm = 2.2306e-01, time/batch = 17.3874s	
13514/29850 (epoch 22.637), train_loss = 0.92462505, grad/param norm = 1.9431e-01, time/batch = 17.4563s	
13515/29850 (epoch 22.638), train_loss = 1.02769461, grad/param norm = 2.1454e-01, time/batch = 17.7111s	
13516/29850 (epoch 22.640), train_loss = 1.15167445, grad/param norm = 2.1141e-01, time/batch = 17.8127s	
13517/29850 (epoch 22.642), train_loss = 0.93488439, grad/param norm = 1.7489e-01, time/batch = 18.1383s	
13518/29850 (epoch 22.643), train_loss = 0.92800711, grad/param norm = 1.9230e-01, time/batch = 17.7771s	
13519/29850 (epoch 22.645), train_loss = 0.97975824, grad/param norm = 1.9554e-01, time/batch = 16.9602s	
13520/29850 (epoch 22.647), train_loss = 1.12106415, grad/param norm = 1.9552e-01, time/batch = 18.0411s	
13521/29850 (epoch 22.648), train_loss = 0.87980719, grad/param norm = 1.8024e-01, time/batch = 16.4615s	
13522/29850 (epoch 22.650), train_loss = 1.01896455, grad/param norm = 1.9235e-01, time/batch = 17.1931s	
13523/29850 (epoch 22.652), train_loss = 1.01380215, grad/param norm = 2.0312e-01, time/batch = 16.1301s	
13524/29850 (epoch 22.653), train_loss = 1.12340185, grad/param norm = 2.3150e-01, time/batch = 17.3106s	
13525/29850 (epoch 22.655), train_loss = 0.98886031, grad/param norm = 1.8793e-01, time/batch = 18.5383s	
13526/29850 (epoch 22.657), train_loss = 0.94099423, grad/param norm = 1.7960e-01, time/batch = 17.3041s	
13527/29850 (epoch 22.658), train_loss = 1.10045852, grad/param norm = 2.0223e-01, time/batch = 17.5494s	
13528/29850 (epoch 22.660), train_loss = 1.01826934, grad/param norm = 2.2294e-01, time/batch = 17.7140s	
13529/29850 (epoch 22.662), train_loss = 1.08539929, grad/param norm = 2.1543e-01, time/batch = 16.9698s	
13530/29850 (epoch 22.663), train_loss = 1.20476685, grad/param norm = 2.1317e-01, time/batch = 18.1392s	
13531/29850 (epoch 22.665), train_loss = 1.12784735, grad/param norm = 2.2193e-01, time/batch = 18.9119s	
13532/29850 (epoch 22.667), train_loss = 1.07063366, grad/param norm = 2.2497e-01, time/batch = 29.7119s	
13533/29850 (epoch 22.668), train_loss = 0.98584441, grad/param norm = 1.9838e-01, time/batch = 16.8241s	
13534/29850 (epoch 22.670), train_loss = 1.16295112, grad/param norm = 2.8554e-01, time/batch = 17.0245s	
13535/29850 (epoch 22.672), train_loss = 1.15007632, grad/param norm = 2.2493e-01, time/batch = 18.7967s	
13536/29850 (epoch 22.673), train_loss = 1.09937072, grad/param norm = 2.3093e-01, time/batch = 16.0508s	
13537/29850 (epoch 22.675), train_loss = 0.91019043, grad/param norm = 2.1228e-01, time/batch = 17.4585s	
13538/29850 (epoch 22.677), train_loss = 0.97620072, grad/param norm = 2.0970e-01, time/batch = 18.3010s	
13539/29850 (epoch 22.678), train_loss = 0.98274665, grad/param norm = 1.9079e-01, time/batch = 17.8646s	
13540/29850 (epoch 22.680), train_loss = 1.00712308, grad/param norm = 1.8928e-01, time/batch = 17.8093s	
13541/29850 (epoch 22.682), train_loss = 1.02387982, grad/param norm = 2.2008e-01, time/batch = 17.7637s	
13542/29850 (epoch 22.683), train_loss = 1.14428044, grad/param norm = 2.2345e-01, time/batch = 18.5390s	
13543/29850 (epoch 22.685), train_loss = 1.17374659, grad/param norm = 1.9832e-01, time/batch = 19.0476s	
13544/29850 (epoch 22.687), train_loss = 1.07515259, grad/param norm = 2.0486e-01, time/batch = 16.3859s	
13545/29850 (epoch 22.688), train_loss = 0.89734821, grad/param norm = 1.8858e-01, time/batch = 18.1182s	
13546/29850 (epoch 22.690), train_loss = 0.89322138, grad/param norm = 1.9012e-01, time/batch = 15.6136s	
13547/29850 (epoch 22.692), train_loss = 1.12328444, grad/param norm = 2.0487e-01, time/batch = 18.3797s	
13548/29850 (epoch 22.693), train_loss = 0.99991517, grad/param norm = 1.7434e-01, time/batch = 18.0943s	
13549/29850 (epoch 22.695), train_loss = 0.88228974, grad/param norm = 1.6761e-01, time/batch = 17.5558s	
13550/29850 (epoch 22.697), train_loss = 1.00119311, grad/param norm = 2.0278e-01, time/batch = 18.9708s	
13551/29850 (epoch 22.698), train_loss = 1.14116246, grad/param norm = 2.0418e-01, time/batch = 15.9480s	
13552/29850 (epoch 22.700), train_loss = 1.09129306, grad/param norm = 2.3531e-01, time/batch = 17.9498s	
13553/29850 (epoch 22.702), train_loss = 0.98784855, grad/param norm = 1.9331e-01, time/batch = 17.4508s	
13554/29850 (epoch 22.704), train_loss = 0.89776123, grad/param norm = 1.8587e-01, time/batch = 15.7957s	
13555/29850 (epoch 22.705), train_loss = 1.02393786, grad/param norm = 2.0725e-01, time/batch = 17.4645s	
13556/29850 (epoch 22.707), train_loss = 0.93701185, grad/param norm = 2.0069e-01, time/batch = 17.1404s	
13557/29850 (epoch 22.709), train_loss = 1.01151409, grad/param norm = 1.9674e-01, time/batch = 19.5388s	
13558/29850 (epoch 22.710), train_loss = 0.93486523, grad/param norm = 2.1046e-01, time/batch = 17.6126s	
13559/29850 (epoch 22.712), train_loss = 1.02527740, grad/param norm = 1.7874e-01, time/batch = 15.9551s	
13560/29850 (epoch 22.714), train_loss = 1.09778920, grad/param norm = 2.0998e-01, time/batch = 18.2981s	
13561/29850 (epoch 22.715), train_loss = 1.05546993, grad/param norm = 2.0180e-01, time/batch = 17.3846s	
13562/29850 (epoch 22.717), train_loss = 0.80267139, grad/param norm = 1.9610e-01, time/batch = 17.7864s	
13563/29850 (epoch 22.719), train_loss = 0.96554276, grad/param norm = 2.0864e-01, time/batch = 17.6110s	
13564/29850 (epoch 22.720), train_loss = 0.99878108, grad/param norm = 1.7241e-01, time/batch = 18.2102s	
13565/29850 (epoch 22.722), train_loss = 0.93770513, grad/param norm = 1.6317e-01, time/batch = 16.8845s	
13566/29850 (epoch 22.724), train_loss = 1.06382571, grad/param norm = 2.0541e-01, time/batch = 17.3637s	
13567/29850 (epoch 22.725), train_loss = 0.86340299, grad/param norm = 1.8026e-01, time/batch = 17.9394s	
13568/29850 (epoch 22.727), train_loss = 0.93201394, grad/param norm = 2.0244e-01, time/batch = 17.3735s	
13569/29850 (epoch 22.729), train_loss = 0.85940415, grad/param norm = 1.6173e-01, time/batch = 18.5501s	
13570/29850 (epoch 22.730), train_loss = 0.84176995, grad/param norm = 1.8183e-01, time/batch = 17.2108s	
13571/29850 (epoch 22.732), train_loss = 1.08324281, grad/param norm = 1.8111e-01, time/batch = 15.5639s	
13572/29850 (epoch 22.734), train_loss = 1.16964542, grad/param norm = 2.6226e-01, time/batch = 17.0637s	
13573/29850 (epoch 22.735), train_loss = 0.94977693, grad/param norm = 1.9892e-01, time/batch = 16.5625s	
13574/29850 (epoch 22.737), train_loss = 0.89116445, grad/param norm = 1.9227e-01, time/batch = 17.5604s	
13575/29850 (epoch 22.739), train_loss = 0.79008502, grad/param norm = 1.8237e-01, time/batch = 15.6233s	
13576/29850 (epoch 22.740), train_loss = 0.87199531, grad/param norm = 1.9181e-01, time/batch = 18.7137s	
13577/29850 (epoch 22.742), train_loss = 0.81076266, grad/param norm = 1.6401e-01, time/batch = 18.1389s	
13578/29850 (epoch 22.744), train_loss = 0.96111695, grad/param norm = 2.1494e-01, time/batch = 17.8807s	
13579/29850 (epoch 22.745), train_loss = 0.90255841, grad/param norm = 1.9937e-01, time/batch = 17.2311s	
13580/29850 (epoch 22.747), train_loss = 0.98318320, grad/param norm = 1.9405e-01, time/batch = 19.7866s	
13581/29850 (epoch 22.749), train_loss = 0.87381415, grad/param norm = 2.0619e-01, time/batch = 17.9510s	
13582/29850 (epoch 22.750), train_loss = 0.83359518, grad/param norm = 1.9838e-01, time/batch = 17.3783s	
13583/29850 (epoch 22.752), train_loss = 0.76434877, grad/param norm = 1.7417e-01, time/batch = 16.6985s	
13584/29850 (epoch 22.754), train_loss = 0.84643552, grad/param norm = 1.8984e-01, time/batch = 16.6508s	
13585/29850 (epoch 22.755), train_loss = 0.86030026, grad/param norm = 1.9205e-01, time/batch = 16.8063s	
13586/29850 (epoch 22.757), train_loss = 0.92059557, grad/param norm = 2.0023e-01, time/batch = 15.8695s	
13587/29850 (epoch 22.759), train_loss = 0.91769168, grad/param norm = 1.8974e-01, time/batch = 16.2249s	
13588/29850 (epoch 22.760), train_loss = 0.87742786, grad/param norm = 1.8135e-01, time/batch = 17.5724s	
13589/29850 (epoch 22.762), train_loss = 0.85729505, grad/param norm = 2.2025e-01, time/batch = 17.6361s	
13590/29850 (epoch 22.764), train_loss = 0.81583564, grad/param norm = 1.8979e-01, time/batch = 16.6491s	
13591/29850 (epoch 22.765), train_loss = 0.95533013, grad/param norm = 2.0090e-01, time/batch = 18.9653s	
13592/29850 (epoch 22.767), train_loss = 0.95461882, grad/param norm = 1.8424e-01, time/batch = 17.3829s	
13593/29850 (epoch 22.769), train_loss = 0.96070517, grad/param norm = 1.9652e-01, time/batch = 17.5541s	
13594/29850 (epoch 22.771), train_loss = 1.00514397, grad/param norm = 2.0521e-01, time/batch = 18.7237s	
13595/29850 (epoch 22.772), train_loss = 1.01119664, grad/param norm = 2.0154e-01, time/batch = 17.4635s	
13596/29850 (epoch 22.774), train_loss = 0.93788919, grad/param norm = 2.0059e-01, time/batch = 18.1269s	
13597/29850 (epoch 22.776), train_loss = 0.92738856, grad/param norm = 1.9167e-01, time/batch = 17.9657s	
13598/29850 (epoch 22.777), train_loss = 1.07348771, grad/param norm = 2.1851e-01, time/batch = 18.7178s	
13599/29850 (epoch 22.779), train_loss = 0.86737873, grad/param norm = 1.8725e-01, time/batch = 16.5310s	
13600/29850 (epoch 22.781), train_loss = 0.99062898, grad/param norm = 1.8195e-01, time/batch = 18.0415s	
13601/29850 (epoch 22.782), train_loss = 1.04397666, grad/param norm = 2.0689e-01, time/batch = 16.6304s	
13602/29850 (epoch 22.784), train_loss = 0.85812760, grad/param norm = 2.0539e-01, time/batch = 15.9773s	
13603/29850 (epoch 22.786), train_loss = 0.94564362, grad/param norm = 1.9054e-01, time/batch = 17.5406s	
13604/29850 (epoch 22.787), train_loss = 0.81700778, grad/param norm = 1.9157e-01, time/batch = 17.2802s	
13605/29850 (epoch 22.789), train_loss = 0.78824972, grad/param norm = 1.5894e-01, time/batch = 17.8097s	
13606/29850 (epoch 22.791), train_loss = 0.90316228, grad/param norm = 2.0621e-01, time/batch = 16.4368s	
13607/29850 (epoch 22.792), train_loss = 1.02724792, grad/param norm = 1.9836e-01, time/batch = 16.3887s	
13608/29850 (epoch 22.794), train_loss = 1.00991571, grad/param norm = 2.0231e-01, time/batch = 17.4229s	
13609/29850 (epoch 22.796), train_loss = 0.86244188, grad/param norm = 1.7639e-01, time/batch = 16.0603s	
13610/29850 (epoch 22.797), train_loss = 0.78930371, grad/param norm = 1.7341e-01, time/batch = 18.1293s	
13611/29850 (epoch 22.799), train_loss = 0.83161394, grad/param norm = 1.5585e-01, time/batch = 18.7864s	
13612/29850 (epoch 22.801), train_loss = 0.92448131, grad/param norm = 1.9534e-01, time/batch = 18.1286s	
13613/29850 (epoch 22.802), train_loss = 0.79940890, grad/param norm = 1.8634e-01, time/batch = 17.1368s	
13614/29850 (epoch 22.804), train_loss = 0.84227884, grad/param norm = 1.6389e-01, time/batch = 17.6214s	
13615/29850 (epoch 22.806), train_loss = 0.82654986, grad/param norm = 1.7384e-01, time/batch = 19.3757s	
13616/29850 (epoch 22.807), train_loss = 0.80553808, grad/param norm = 1.5690e-01, time/batch = 15.3883s	
13617/29850 (epoch 22.809), train_loss = 0.85775337, grad/param norm = 2.1350e-01, time/batch = 17.7687s	
13618/29850 (epoch 22.811), train_loss = 0.98727007, grad/param norm = 2.1412e-01, time/batch = 16.7424s	
13619/29850 (epoch 22.812), train_loss = 1.01276685, grad/param norm = 2.3089e-01, time/batch = 17.6953s	
13620/29850 (epoch 22.814), train_loss = 1.08074495, grad/param norm = 2.1390e-01, time/batch = 16.8256s	
13621/29850 (epoch 22.816), train_loss = 1.04913655, grad/param norm = 1.7639e-01, time/batch = 16.6428s	
13622/29850 (epoch 22.817), train_loss = 0.96627713, grad/param norm = 1.7734e-01, time/batch = 18.0466s	
13623/29850 (epoch 22.819), train_loss = 0.83819893, grad/param norm = 2.1054e-01, time/batch = 17.2147s	
13624/29850 (epoch 22.821), train_loss = 1.08217240, grad/param norm = 2.1447e-01, time/batch = 18.3053s	
13625/29850 (epoch 22.822), train_loss = 1.07292124, grad/param norm = 1.9944e-01, time/batch = 17.6953s	
13626/29850 (epoch 22.824), train_loss = 0.96506324, grad/param norm = 1.8795e-01, time/batch = 17.9443s	
13627/29850 (epoch 22.826), train_loss = 0.89156534, grad/param norm = 1.7946e-01, time/batch = 17.4475s	
13628/29850 (epoch 22.827), train_loss = 0.84098918, grad/param norm = 2.0539e-01, time/batch = 14.7224s	
13629/29850 (epoch 22.829), train_loss = 0.98041405, grad/param norm = 2.2399e-01, time/batch = 17.7146s	
13630/29850 (epoch 22.831), train_loss = 1.06366065, grad/param norm = 2.2055e-01, time/batch = 16.2113s	
13631/29850 (epoch 22.832), train_loss = 0.94725502, grad/param norm = 1.7858e-01, time/batch = 18.6257s	
13632/29850 (epoch 22.834), train_loss = 0.76835776, grad/param norm = 1.6361e-01, time/batch = 18.8030s	
13633/29850 (epoch 22.836), train_loss = 0.81038567, grad/param norm = 1.7612e-01, time/batch = 16.0766s	
13634/29850 (epoch 22.838), train_loss = 0.94998369, grad/param norm = 2.0045e-01, time/batch = 0.6676s	
13635/29850 (epoch 22.839), train_loss = 0.83134188, grad/param norm = 1.6824e-01, time/batch = 0.6648s	
13636/29850 (epoch 22.841), train_loss = 0.85051713, grad/param norm = 1.8123e-01, time/batch = 0.6875s	
13637/29850 (epoch 22.843), train_loss = 0.81672188, grad/param norm = 1.8010e-01, time/batch = 0.6775s	
13638/29850 (epoch 22.844), train_loss = 0.86168141, grad/param norm = 1.8992e-01, time/batch = 0.6734s	
13639/29850 (epoch 22.846), train_loss = 0.96046772, grad/param norm = 1.8129e-01, time/batch = 0.6902s	
13640/29850 (epoch 22.848), train_loss = 1.02497404, grad/param norm = 2.1654e-01, time/batch = 0.6686s	
13641/29850 (epoch 22.849), train_loss = 0.88682897, grad/param norm = 1.8352e-01, time/batch = 0.8887s	
13642/29850 (epoch 22.851), train_loss = 1.07172418, grad/param norm = 2.2320e-01, time/batch = 0.9689s	
13643/29850 (epoch 22.853), train_loss = 0.90149273, grad/param norm = 2.1488e-01, time/batch = 0.9679s	
13644/29850 (epoch 22.854), train_loss = 1.11493168, grad/param norm = 2.0939e-01, time/batch = 0.9930s	
13645/29850 (epoch 22.856), train_loss = 1.05197393, grad/param norm = 2.9217e-01, time/batch = 0.9914s	
13646/29850 (epoch 22.858), train_loss = 0.99004180, grad/param norm = 1.9945e-01, time/batch = 1.5424s	
13647/29850 (epoch 22.859), train_loss = 0.83839610, grad/param norm = 2.0758e-01, time/batch = 1.8891s	
13648/29850 (epoch 22.861), train_loss = 1.09497332, grad/param norm = 2.3153e-01, time/batch = 1.8949s	
13649/29850 (epoch 22.863), train_loss = 1.14012261, grad/param norm = 2.1409e-01, time/batch = 15.4106s	
13650/29850 (epoch 22.864), train_loss = 1.07885162, grad/param norm = 2.2019e-01, time/batch = 17.0379s	
13651/29850 (epoch 22.866), train_loss = 0.98177080, grad/param norm = 2.2644e-01, time/batch = 16.0168s	
13652/29850 (epoch 22.868), train_loss = 1.14153282, grad/param norm = 2.1346e-01, time/batch = 19.1287s	
13653/29850 (epoch 22.869), train_loss = 1.01110149, grad/param norm = 2.3473e-01, time/batch = 17.3464s	
13654/29850 (epoch 22.871), train_loss = 1.06264351, grad/param norm = 2.1093e-01, time/batch = 16.1258s	
13655/29850 (epoch 22.873), train_loss = 1.02046784, grad/param norm = 2.1156e-01, time/batch = 18.4630s	
13656/29850 (epoch 22.874), train_loss = 1.00617455, grad/param norm = 2.0098e-01, time/batch = 18.6232s	
13657/29850 (epoch 22.876), train_loss = 0.98441815, grad/param norm = 2.4738e-01, time/batch = 18.2074s	
13658/29850 (epoch 22.878), train_loss = 0.98634212, grad/param norm = 1.7896e-01, time/batch = 16.7839s	
13659/29850 (epoch 22.879), train_loss = 1.01489552, grad/param norm = 2.0110e-01, time/batch = 18.8873s	
13660/29850 (epoch 22.881), train_loss = 1.09054039, grad/param norm = 2.5083e-01, time/batch = 19.3600s	
13661/29850 (epoch 22.883), train_loss = 1.07019615, grad/param norm = 2.0779e-01, time/batch = 16.8630s	
13662/29850 (epoch 22.884), train_loss = 0.87286605, grad/param norm = 1.9145e-01, time/batch = 18.4705s	
13663/29850 (epoch 22.886), train_loss = 1.09165257, grad/param norm = 2.2679e-01, time/batch = 17.8940s	
13664/29850 (epoch 22.888), train_loss = 0.98470567, grad/param norm = 1.8335e-01, time/batch = 17.1122s	
13665/29850 (epoch 22.889), train_loss = 0.93214321, grad/param norm = 1.7443e-01, time/batch = 15.4605s	
13666/29850 (epoch 22.891), train_loss = 0.89759196, grad/param norm = 1.8348e-01, time/batch = 16.7218s	
13667/29850 (epoch 22.893), train_loss = 0.89993913, grad/param norm = 1.8046e-01, time/batch = 16.9830s	
13668/29850 (epoch 22.894), train_loss = 0.93298399, grad/param norm = 1.9790e-01, time/batch = 16.2243s	
13669/29850 (epoch 22.896), train_loss = 0.95888915, grad/param norm = 1.8858e-01, time/batch = 17.5525s	
13670/29850 (epoch 22.898), train_loss = 1.09910440, grad/param norm = 2.2167e-01, time/batch = 17.2839s	
13671/29850 (epoch 22.899), train_loss = 0.85036737, grad/param norm = 1.8523e-01, time/batch = 16.1214s	
13672/29850 (epoch 22.901), train_loss = 1.25430869, grad/param norm = 2.6151e-01, time/batch = 17.0650s	
13673/29850 (epoch 22.903), train_loss = 1.01930631, grad/param norm = 3.2448e-01, time/batch = 15.8964s	
13674/29850 (epoch 22.905), train_loss = 1.20985981, grad/param norm = 2.4004e-01, time/batch = 18.3073s	
13675/29850 (epoch 22.906), train_loss = 1.05360750, grad/param norm = 2.1316e-01, time/batch = 15.7007s	
13676/29850 (epoch 22.908), train_loss = 1.12916259, grad/param norm = 2.1485e-01, time/batch = 18.2816s	
13677/29850 (epoch 22.910), train_loss = 1.04473770, grad/param norm = 2.0833e-01, time/batch = 17.1396s	
13678/29850 (epoch 22.911), train_loss = 1.17435939, grad/param norm = 1.8314e-01, time/batch = 17.3036s	
13679/29850 (epoch 22.913), train_loss = 1.14986168, grad/param norm = 2.2535e-01, time/batch = 19.1180s	
13680/29850 (epoch 22.915), train_loss = 1.11074900, grad/param norm = 2.1843e-01, time/batch = 18.1326s	
13681/29850 (epoch 22.916), train_loss = 1.09453946, grad/param norm = 2.2641e-01, time/batch = 18.3910s	
13682/29850 (epoch 22.918), train_loss = 0.93304133, grad/param norm = 1.9167e-01, time/batch = 16.2172s	
13683/29850 (epoch 22.920), train_loss = 1.05572489, grad/param norm = 1.8971e-01, time/batch = 17.8848s	
13684/29850 (epoch 22.921), train_loss = 1.01455252, grad/param norm = 2.1476e-01, time/batch = 16.2114s	
13685/29850 (epoch 22.923), train_loss = 1.09954430, grad/param norm = 2.1202e-01, time/batch = 17.2176s	
13686/29850 (epoch 22.925), train_loss = 1.13020234, grad/param norm = 2.0907e-01, time/batch = 18.2011s	
13687/29850 (epoch 22.926), train_loss = 1.16513727, grad/param norm = 2.4290e-01, time/batch = 16.5504s	
13688/29850 (epoch 22.928), train_loss = 1.05264460, grad/param norm = 2.1519e-01, time/batch = 17.7950s	
13689/29850 (epoch 22.930), train_loss = 1.06290880, grad/param norm = 2.0299e-01, time/batch = 16.6948s	
13690/29850 (epoch 22.931), train_loss = 0.99643375, grad/param norm = 1.9275e-01, time/batch = 16.9571s	
13691/29850 (epoch 22.933), train_loss = 1.19207928, grad/param norm = 2.1947e-01, time/batch = 18.9432s	
13692/29850 (epoch 22.935), train_loss = 1.08969889, grad/param norm = 2.1146e-01, time/batch = 15.1428s	
13693/29850 (epoch 22.936), train_loss = 1.07399497, grad/param norm = 2.2246e-01, time/batch = 15.7449s	
13694/29850 (epoch 22.938), train_loss = 0.89942571, grad/param norm = 1.8403e-01, time/batch = 18.0538s	
13695/29850 (epoch 22.940), train_loss = 0.90006678, grad/param norm = 1.9738e-01, time/batch = 18.3850s	
13696/29850 (epoch 22.941), train_loss = 0.92863644, grad/param norm = 2.2093e-01, time/batch = 17.7804s	
13697/29850 (epoch 22.943), train_loss = 0.93444803, grad/param norm = 1.8627e-01, time/batch = 18.4640s	
13698/29850 (epoch 22.945), train_loss = 0.94320632, grad/param norm = 2.1979e-01, time/batch = 19.0531s	
13699/29850 (epoch 22.946), train_loss = 0.87382300, grad/param norm = 2.0297e-01, time/batch = 16.1322s	
13700/29850 (epoch 22.948), train_loss = 1.00986069, grad/param norm = 1.8888e-01, time/batch = 18.2925s	
13701/29850 (epoch 22.950), train_loss = 0.89741269, grad/param norm = 1.7416e-01, time/batch = 15.8894s	
13702/29850 (epoch 22.951), train_loss = 0.86099421, grad/param norm = 1.6971e-01, time/batch = 15.5279s	
13703/29850 (epoch 22.953), train_loss = 0.98423238, grad/param norm = 2.2140e-01, time/batch = 17.5628s	
13704/29850 (epoch 22.955), train_loss = 0.87325008, grad/param norm = 1.7555e-01, time/batch = 16.9591s	
13705/29850 (epoch 22.956), train_loss = 0.84312996, grad/param norm = 1.7706e-01, time/batch = 16.4417s	
13706/29850 (epoch 22.958), train_loss = 0.74470973, grad/param norm = 1.5068e-01, time/batch = 17.3757s	
13707/29850 (epoch 22.960), train_loss = 1.06441450, grad/param norm = 2.0658e-01, time/batch = 16.8012s	
13708/29850 (epoch 22.961), train_loss = 0.88018515, grad/param norm = 1.8978e-01, time/batch = 18.7081s	
13709/29850 (epoch 22.963), train_loss = 0.85142044, grad/param norm = 1.9390e-01, time/batch = 18.3860s	
13710/29850 (epoch 22.965), train_loss = 0.92074804, grad/param norm = 1.9956e-01, time/batch = 17.3942s	
13711/29850 (epoch 22.966), train_loss = 0.86001346, grad/param norm = 1.8978e-01, time/batch = 16.8966s	
13712/29850 (epoch 22.968), train_loss = 0.91312158, grad/param norm = 2.0362e-01, time/batch = 18.6280s	
13713/29850 (epoch 22.970), train_loss = 0.84671536, grad/param norm = 1.8898e-01, time/batch = 18.4485s	
13714/29850 (epoch 22.972), train_loss = 0.89013500, grad/param norm = 1.7053e-01, time/batch = 18.1249s	
13715/29850 (epoch 22.973), train_loss = 0.89196575, grad/param norm = 1.8345e-01, time/batch = 16.8148s	
13716/29850 (epoch 22.975), train_loss = 0.80938039, grad/param norm = 1.7732e-01, time/batch = 16.2141s	
13717/29850 (epoch 22.977), train_loss = 0.91719248, grad/param norm = 1.6989e-01, time/batch = 17.0228s	
13718/29850 (epoch 22.978), train_loss = 0.84398374, grad/param norm = 1.7750e-01, time/batch = 16.2203s	
13719/29850 (epoch 22.980), train_loss = 0.91848737, grad/param norm = 1.8560e-01, time/batch = 18.2957s	
13720/29850 (epoch 22.982), train_loss = 0.91216684, grad/param norm = 2.0501e-01, time/batch = 17.5393s	
13721/29850 (epoch 22.983), train_loss = 0.92487280, grad/param norm = 1.6937e-01, time/batch = 16.3713s	
13722/29850 (epoch 22.985), train_loss = 1.00029957, grad/param norm = 1.9614e-01, time/batch = 16.5459s	
13723/29850 (epoch 22.987), train_loss = 0.98527015, grad/param norm = 1.8867e-01, time/batch = 17.4598s	
13724/29850 (epoch 22.988), train_loss = 0.91729877, grad/param norm = 1.7140e-01, time/batch = 16.6419s	
13725/29850 (epoch 22.990), train_loss = 0.97469819, grad/param norm = 1.9188e-01, time/batch = 19.4511s	
13726/29850 (epoch 22.992), train_loss = 1.00975936, grad/param norm = 1.9388e-01, time/batch = 16.8838s	
13727/29850 (epoch 22.993), train_loss = 0.98333161, grad/param norm = 1.8383e-01, time/batch = 16.3174s	
13728/29850 (epoch 22.995), train_loss = 1.00327669, grad/param norm = 1.8561e-01, time/batch = 19.2989s	
13729/29850 (epoch 22.997), train_loss = 1.02198848, grad/param norm = 2.2381e-01, time/batch = 18.1436s	
13730/29850 (epoch 22.998), train_loss = 1.05747248, grad/param norm = 1.9912e-01, time/batch = 17.2054s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
13731/29850 (epoch 23.000), train_loss = 0.87520985, grad/param norm = 1.7736e-01, time/batch = 17.9584s	
13732/29850 (epoch 23.002), train_loss = 1.16807247, grad/param norm = 2.2688e-01, time/batch = 19.2916s	
13733/29850 (epoch 23.003), train_loss = 0.89234698, grad/param norm = 1.9846e-01, time/batch = 17.5997s	
13734/29850 (epoch 23.005), train_loss = 1.00125928, grad/param norm = 2.0677e-01, time/batch = 17.8831s	
13735/29850 (epoch 23.007), train_loss = 1.04886527, grad/param norm = 2.1715e-01, time/batch = 15.8975s	
13736/29850 (epoch 23.008), train_loss = 1.20413794, grad/param norm = 2.1214e-01, time/batch = 17.0613s	
13737/29850 (epoch 23.010), train_loss = 0.90222425, grad/param norm = 2.0201e-01, time/batch = 18.7915s	
13738/29850 (epoch 23.012), train_loss = 0.98503416, grad/param norm = 1.7985e-01, time/batch = 16.3060s	
13739/29850 (epoch 23.013), train_loss = 1.03791182, grad/param norm = 2.1809e-01, time/batch = 15.4093s	
13740/29850 (epoch 23.015), train_loss = 1.04599138, grad/param norm = 1.9225e-01, time/batch = 16.0677s	
13741/29850 (epoch 23.017), train_loss = 1.00909279, grad/param norm = 2.0995e-01, time/batch = 18.7048s	
13742/29850 (epoch 23.018), train_loss = 1.13694638, grad/param norm = 2.3688e-01, time/batch = 18.8715s	
13743/29850 (epoch 23.020), train_loss = 0.99235085, grad/param norm = 2.0663e-01, time/batch = 17.5624s	
13744/29850 (epoch 23.022), train_loss = 1.09295613, grad/param norm = 2.3022e-01, time/batch = 16.2024s	
13745/29850 (epoch 23.023), train_loss = 1.07321449, grad/param norm = 2.3248e-01, time/batch = 16.7280s	
13746/29850 (epoch 23.025), train_loss = 0.97942507, grad/param norm = 1.8611e-01, time/batch = 18.9642s	
13747/29850 (epoch 23.027), train_loss = 0.80440685, grad/param norm = 1.8030e-01, time/batch = 16.5498s	
13748/29850 (epoch 23.028), train_loss = 0.94707405, grad/param norm = 1.7527e-01, time/batch = 17.8676s	
13749/29850 (epoch 23.030), train_loss = 0.99698952, grad/param norm = 2.1462e-01, time/batch = 18.9655s	
13750/29850 (epoch 23.032), train_loss = 1.03534451, grad/param norm = 1.9699e-01, time/batch = 21.0607s	
13751/29850 (epoch 23.034), train_loss = 0.91575667, grad/param norm = 1.7469e-01, time/batch = 25.9609s	
13752/29850 (epoch 23.035), train_loss = 0.83272670, grad/param norm = 1.8616e-01, time/batch = 16.1294s	
13753/29850 (epoch 23.037), train_loss = 0.97307106, grad/param norm = 1.8969e-01, time/batch = 17.0597s	
13754/29850 (epoch 23.039), train_loss = 0.87562368, grad/param norm = 1.7311e-01, time/batch = 16.4578s	
13755/29850 (epoch 23.040), train_loss = 0.90232601, grad/param norm = 1.9236e-01, time/batch = 16.7941s	
13756/29850 (epoch 23.042), train_loss = 0.89540970, grad/param norm = 1.7460e-01, time/batch = 17.9635s	
13757/29850 (epoch 23.044), train_loss = 0.93597021, grad/param norm = 1.7268e-01, time/batch = 17.7210s	
13758/29850 (epoch 23.045), train_loss = 1.03553126, grad/param norm = 1.8753e-01, time/batch = 17.3855s	
13759/29850 (epoch 23.047), train_loss = 0.87431792, grad/param norm = 1.9495e-01, time/batch = 15.2141s	
13760/29850 (epoch 23.049), train_loss = 1.01127080, grad/param norm = 1.8297e-01, time/batch = 17.4644s	
13761/29850 (epoch 23.050), train_loss = 0.90501049, grad/param norm = 2.0881e-01, time/batch = 17.8631s	
13762/29850 (epoch 23.052), train_loss = 1.09527706, grad/param norm = 2.1381e-01, time/batch = 17.5509s	
13763/29850 (epoch 23.054), train_loss = 0.99093369, grad/param norm = 1.8812e-01, time/batch = 17.0337s	
13764/29850 (epoch 23.055), train_loss = 0.95296542, grad/param norm = 1.8437e-01, time/batch = 17.9587s	
13765/29850 (epoch 23.057), train_loss = 1.04009069, grad/param norm = 1.8293e-01, time/batch = 18.2962s	
13766/29850 (epoch 23.059), train_loss = 1.02165170, grad/param norm = 2.0107e-01, time/batch = 18.9810s	
13767/29850 (epoch 23.060), train_loss = 1.00035761, grad/param norm = 1.9041e-01, time/batch = 16.6740s	
13768/29850 (epoch 23.062), train_loss = 1.11052293, grad/param norm = 2.4161e-01, time/batch = 19.0506s	
13769/29850 (epoch 23.064), train_loss = 1.06093109, grad/param norm = 1.9047e-01, time/batch = 18.0536s	
13770/29850 (epoch 23.065), train_loss = 0.90095595, grad/param norm = 1.8998e-01, time/batch = 16.2802s	
13771/29850 (epoch 23.067), train_loss = 1.04172427, grad/param norm = 1.8705e-01, time/batch = 19.0455s	
13772/29850 (epoch 23.069), train_loss = 0.99965520, grad/param norm = 1.8608e-01, time/batch = 16.9629s	
13773/29850 (epoch 23.070), train_loss = 1.05158664, grad/param norm = 1.8438e-01, time/batch = 17.2059s	
13774/29850 (epoch 23.072), train_loss = 1.02124232, grad/param norm = 2.1423e-01, time/batch = 15.8694s	
13775/29850 (epoch 23.074), train_loss = 1.05771617, grad/param norm = 1.8549e-01, time/batch = 17.3778s	
13776/29850 (epoch 23.075), train_loss = 0.92131436, grad/param norm = 1.9470e-01, time/batch = 17.7886s	
13777/29850 (epoch 23.077), train_loss = 1.06061831, grad/param norm = 2.1272e-01, time/batch = 16.0454s	
13778/29850 (epoch 23.079), train_loss = 1.23277470, grad/param norm = 2.5983e-01, time/batch = 15.6191s	
13779/29850 (epoch 23.080), train_loss = 1.19459186, grad/param norm = 2.3440e-01, time/batch = 19.2990s	
13780/29850 (epoch 23.082), train_loss = 1.06519962, grad/param norm = 2.0408e-01, time/batch = 17.7864s	
13781/29850 (epoch 23.084), train_loss = 1.14627219, grad/param norm = 2.3025e-01, time/batch = 18.4644s	
13782/29850 (epoch 23.085), train_loss = 1.12710948, grad/param norm = 1.9954e-01, time/batch = 18.6266s	
13783/29850 (epoch 23.087), train_loss = 1.14240293, grad/param norm = 2.0657e-01, time/batch = 18.2884s	
13784/29850 (epoch 23.089), train_loss = 1.03192923, grad/param norm = 2.0318e-01, time/batch = 16.7941s	
13785/29850 (epoch 23.090), train_loss = 1.05762860, grad/param norm = 1.9155e-01, time/batch = 16.8883s	
13786/29850 (epoch 23.092), train_loss = 0.93912661, grad/param norm = 1.7957e-01, time/batch = 16.7721s	
13787/29850 (epoch 23.094), train_loss = 1.14499666, grad/param norm = 2.1654e-01, time/batch = 17.4459s	
13788/29850 (epoch 23.095), train_loss = 1.02909173, grad/param norm = 2.3034e-01, time/batch = 16.9756s	
13789/29850 (epoch 23.097), train_loss = 0.82783867, grad/param norm = 1.6801e-01, time/batch = 16.9506s	
13790/29850 (epoch 23.099), train_loss = 0.83551855, grad/param norm = 1.7419e-01, time/batch = 19.0414s	
13791/29850 (epoch 23.101), train_loss = 1.09726137, grad/param norm = 2.0192e-01, time/batch = 17.0592s	
13792/29850 (epoch 23.102), train_loss = 1.04433422, grad/param norm = 2.0683e-01, time/batch = 17.3130s	
13793/29850 (epoch 23.104), train_loss = 0.97591227, grad/param norm = 2.0473e-01, time/batch = 18.3008s	
13794/29850 (epoch 23.106), train_loss = 1.08956884, grad/param norm = 1.9683e-01, time/batch = 16.5543s	
13795/29850 (epoch 23.107), train_loss = 0.88780381, grad/param norm = 1.6665e-01, time/batch = 16.7326s	
13796/29850 (epoch 23.109), train_loss = 0.97031731, grad/param norm = 2.1663e-01, time/batch = 18.2991s	
13797/29850 (epoch 23.111), train_loss = 1.07855031, grad/param norm = 2.1196e-01, time/batch = 15.7022s	
13798/29850 (epoch 23.112), train_loss = 0.93388049, grad/param norm = 1.8638e-01, time/batch = 17.0254s	
13799/29850 (epoch 23.114), train_loss = 0.96548437, grad/param norm = 2.0424e-01, time/batch = 17.8807s	
13800/29850 (epoch 23.116), train_loss = 0.90041098, grad/param norm = 1.7486e-01, time/batch = 18.8813s	
13801/29850 (epoch 23.117), train_loss = 0.99746906, grad/param norm = 1.9186e-01, time/batch = 15.9529s	
13802/29850 (epoch 23.119), train_loss = 0.96917299, grad/param norm = 1.8797e-01, time/batch = 17.8081s	
13803/29850 (epoch 23.121), train_loss = 0.79022699, grad/param norm = 1.7349e-01, time/batch = 17.5627s	
13804/29850 (epoch 23.122), train_loss = 0.84993911, grad/param norm = 1.5378e-01, time/batch = 16.9607s	
13805/29850 (epoch 23.124), train_loss = 0.90951894, grad/param norm = 1.9354e-01, time/batch = 16.6922s	
13806/29850 (epoch 23.126), train_loss = 0.95029522, grad/param norm = 2.0194e-01, time/batch = 15.8804s	
13807/29850 (epoch 23.127), train_loss = 1.07209907, grad/param norm = 2.4498e-01, time/batch = 19.2225s	
13808/29850 (epoch 23.129), train_loss = 0.93639584, grad/param norm = 1.9544e-01, time/batch = 16.8515s	
13809/29850 (epoch 23.131), train_loss = 0.96716539, grad/param norm = 1.8539e-01, time/batch = 14.6597s	
13810/29850 (epoch 23.132), train_loss = 0.89704911, grad/param norm = 2.2462e-01, time/batch = 14.8030s	
13811/29850 (epoch 23.134), train_loss = 0.98882339, grad/param norm = 1.8859e-01, time/batch = 14.8059s	
13812/29850 (epoch 23.136), train_loss = 1.02454619, grad/param norm = 1.8632e-01, time/batch = 16.4892s	
13813/29850 (epoch 23.137), train_loss = 0.80080083, grad/param norm = 1.6449e-01, time/batch = 15.3907s	
13814/29850 (epoch 23.139), train_loss = 0.94801310, grad/param norm = 1.9705e-01, time/batch = 16.7035s	
13815/29850 (epoch 23.141), train_loss = 0.91958740, grad/param norm = 1.8521e-01, time/batch = 17.5418s	
13816/29850 (epoch 23.142), train_loss = 1.12187724, grad/param norm = 2.3298e-01, time/batch = 18.0179s	
13817/29850 (epoch 23.144), train_loss = 1.25856775, grad/param norm = 2.2826e-01, time/batch = 18.7204s	
13818/29850 (epoch 23.146), train_loss = 1.23969371, grad/param norm = 2.4609e-01, time/batch = 19.8807s	
13819/29850 (epoch 23.147), train_loss = 1.04387224, grad/param norm = 2.0909e-01, time/batch = 17.9516s	
13820/29850 (epoch 23.149), train_loss = 1.05606011, grad/param norm = 1.9990e-01, time/batch = 18.1218s	
13821/29850 (epoch 23.151), train_loss = 1.05312221, grad/param norm = 2.0968e-01, time/batch = 17.9670s	
13822/29850 (epoch 23.152), train_loss = 0.94910252, grad/param norm = 1.8359e-01, time/batch = 15.8873s	
13823/29850 (epoch 23.154), train_loss = 0.92199678, grad/param norm = 1.9353e-01, time/batch = 18.3834s	
13824/29850 (epoch 23.156), train_loss = 0.94594520, grad/param norm = 1.9515e-01, time/batch = 16.7886s	
13825/29850 (epoch 23.157), train_loss = 1.01450950, grad/param norm = 1.8464e-01, time/batch = 17.1995s	
13826/29850 (epoch 23.159), train_loss = 0.96444880, grad/param norm = 2.0067e-01, time/batch = 17.5439s	
13827/29850 (epoch 23.161), train_loss = 1.05030417, grad/param norm = 2.3283e-01, time/batch = 15.6246s	
13828/29850 (epoch 23.162), train_loss = 1.16106501, grad/param norm = 2.2142e-01, time/batch = 18.5517s	
13829/29850 (epoch 23.164), train_loss = 0.99390185, grad/param norm = 2.0774e-01, time/batch = 16.2250s	
13830/29850 (epoch 23.166), train_loss = 0.90318638, grad/param norm = 1.6941e-01, time/batch = 17.8057s	
13831/29850 (epoch 23.168), train_loss = 0.86080624, grad/param norm = 1.8355e-01, time/batch = 18.3017s	
13832/29850 (epoch 23.169), train_loss = 1.15758323, grad/param norm = 2.2142e-01, time/batch = 16.7040s	
13833/29850 (epoch 23.171), train_loss = 1.06237294, grad/param norm = 2.0163e-01, time/batch = 18.1941s	
13834/29850 (epoch 23.173), train_loss = 0.90602852, grad/param norm = 1.8952e-01, time/batch = 17.1318s	
13835/29850 (epoch 23.174), train_loss = 1.03241478, grad/param norm = 2.1770e-01, time/batch = 19.6088s	
13836/29850 (epoch 23.176), train_loss = 0.99943403, grad/param norm = 1.8642e-01, time/batch = 17.2038s	
13837/29850 (epoch 23.178), train_loss = 1.07246647, grad/param norm = 2.1847e-01, time/batch = 17.0392s	
13838/29850 (epoch 23.179), train_loss = 0.85828620, grad/param norm = 1.8187e-01, time/batch = 16.6245s	
13839/29850 (epoch 23.181), train_loss = 0.99664505, grad/param norm = 2.0567e-01, time/batch = 16.8759s	
13840/29850 (epoch 23.183), train_loss = 1.01772877, grad/param norm = 2.0543e-01, time/batch = 18.2185s	
13841/29850 (epoch 23.184), train_loss = 1.04694172, grad/param norm = 2.0385e-01, time/batch = 15.9619s	
13842/29850 (epoch 23.186), train_loss = 1.02510395, grad/param norm = 2.1385e-01, time/batch = 18.4512s	
13843/29850 (epoch 23.188), train_loss = 1.12675380, grad/param norm = 2.4396e-01, time/batch = 17.2926s	
13844/29850 (epoch 23.189), train_loss = 1.14206224, grad/param norm = 2.4413e-01, time/batch = 17.5550s	
13845/29850 (epoch 23.191), train_loss = 1.07832531, grad/param norm = 2.1596e-01, time/batch = 17.7326s	
13846/29850 (epoch 23.193), train_loss = 0.99656833, grad/param norm = 2.0258e-01, time/batch = 15.9564s	
13847/29850 (epoch 23.194), train_loss = 1.05793499, grad/param norm = 2.1879e-01, time/batch = 18.2173s	
13848/29850 (epoch 23.196), train_loss = 0.97499232, grad/param norm = 2.0065e-01, time/batch = 17.3158s	
13849/29850 (epoch 23.198), train_loss = 0.99209220, grad/param norm = 2.0449e-01, time/batch = 15.8144s	
13850/29850 (epoch 23.199), train_loss = 1.22111497, grad/param norm = 2.0906e-01, time/batch = 16.5515s	
13851/29850 (epoch 23.201), train_loss = 0.93870070, grad/param norm = 1.9846e-01, time/batch = 17.4752s	
13852/29850 (epoch 23.203), train_loss = 0.78478283, grad/param norm = 1.9688e-01, time/batch = 16.9864s	
13853/29850 (epoch 23.204), train_loss = 1.04342138, grad/param norm = 2.2104e-01, time/batch = 17.6231s	
13854/29850 (epoch 23.206), train_loss = 0.89056511, grad/param norm = 1.9442e-01, time/batch = 17.7914s	
13855/29850 (epoch 23.208), train_loss = 1.13685778, grad/param norm = 2.0395e-01, time/batch = 16.1318s	
13856/29850 (epoch 23.209), train_loss = 0.87413310, grad/param norm = 1.9055e-01, time/batch = 17.6935s	
13857/29850 (epoch 23.211), train_loss = 0.96611590, grad/param norm = 2.0303e-01, time/batch = 16.1730s	
13858/29850 (epoch 23.213), train_loss = 1.07101015, grad/param norm = 2.0036e-01, time/batch = 15.6311s	
13859/29850 (epoch 23.214), train_loss = 0.88498365, grad/param norm = 1.6472e-01, time/batch = 18.4618s	
13860/29850 (epoch 23.216), train_loss = 0.94221870, grad/param norm = 2.0911e-01, time/batch = 16.2028s	
13861/29850 (epoch 23.218), train_loss = 1.07881815, grad/param norm = 2.0066e-01, time/batch = 18.8805s	
13862/29850 (epoch 23.219), train_loss = 1.09496636, grad/param norm = 2.1722e-01, time/batch = 17.8924s	
13863/29850 (epoch 23.221), train_loss = 0.98689933, grad/param norm = 1.8526e-01, time/batch = 17.4509s	
13864/29850 (epoch 23.223), train_loss = 0.91851205, grad/param norm = 2.1191e-01, time/batch = 17.7957s	
13865/29850 (epoch 23.224), train_loss = 0.87214883, grad/param norm = 2.0083e-01, time/batch = 18.3897s	
13866/29850 (epoch 23.226), train_loss = 0.91156463, grad/param norm = 1.7932e-01, time/batch = 19.1217s	
13867/29850 (epoch 23.228), train_loss = 0.97519000, grad/param norm = 1.7443e-01, time/batch = 16.1657s	
13868/29850 (epoch 23.229), train_loss = 0.83305558, grad/param norm = 1.6033e-01, time/batch = 15.7620s	
13869/29850 (epoch 23.231), train_loss = 0.99784408, grad/param norm = 1.8633e-01, time/batch = 15.4606s	
13870/29850 (epoch 23.233), train_loss = 0.96406852, grad/param norm = 1.9869e-01, time/batch = 14.9701s	
13871/29850 (epoch 23.235), train_loss = 0.87906148, grad/param norm = 1.7606e-01, time/batch = 15.3768s	
13872/29850 (epoch 23.236), train_loss = 1.10057436, grad/param norm = 2.1037e-01, time/batch = 15.0684s	
13873/29850 (epoch 23.238), train_loss = 0.88271219, grad/param norm = 1.8364e-01, time/batch = 15.4272s	
13874/29850 (epoch 23.240), train_loss = 0.86523437, grad/param norm = 1.8296e-01, time/batch = 15.5023s	
13875/29850 (epoch 23.241), train_loss = 1.03605434, grad/param norm = 2.1001e-01, time/batch = 15.4544s	
13876/29850 (epoch 23.243), train_loss = 1.01511951, grad/param norm = 1.9374e-01, time/batch = 15.3717s	
13877/29850 (epoch 23.245), train_loss = 0.92761107, grad/param norm = 2.0193e-01, time/batch = 18.2943s	
13878/29850 (epoch 23.246), train_loss = 0.87178851, grad/param norm = 1.6306e-01, time/batch = 16.7049s	
13879/29850 (epoch 23.248), train_loss = 0.85519603, grad/param norm = 1.7104e-01, time/batch = 15.0589s	
13880/29850 (epoch 23.250), train_loss = 0.95410097, grad/param norm = 1.7878e-01, time/batch = 15.4540s	
13881/29850 (epoch 23.251), train_loss = 0.84570166, grad/param norm = 1.9346e-01, time/batch = 18.0457s	
13882/29850 (epoch 23.253), train_loss = 0.77072886, grad/param norm = 1.8547e-01, time/batch = 18.0221s	
13883/29850 (epoch 23.255), train_loss = 0.89848672, grad/param norm = 1.9042e-01, time/batch = 17.5507s	
13884/29850 (epoch 23.256), train_loss = 1.02692978, grad/param norm = 2.1830e-01, time/batch = 17.9509s	
13885/29850 (epoch 23.258), train_loss = 0.99737449, grad/param norm = 2.1408e-01, time/batch = 17.9678s	
13886/29850 (epoch 23.260), train_loss = 0.96464939, grad/param norm = 1.9136e-01, time/batch = 18.1135s	
13887/29850 (epoch 23.261), train_loss = 0.88999921, grad/param norm = 1.9070e-01, time/batch = 18.2094s	
13888/29850 (epoch 23.263), train_loss = 0.89189754, grad/param norm = 1.9095e-01, time/batch = 17.1144s	
13889/29850 (epoch 23.265), train_loss = 0.96241704, grad/param norm = 1.8929e-01, time/batch = 19.0223s	
13890/29850 (epoch 23.266), train_loss = 0.96458831, grad/param norm = 2.0119e-01, time/batch = 16.2118s	
13891/29850 (epoch 23.268), train_loss = 0.90856109, grad/param norm = 1.6090e-01, time/batch = 17.5522s	
13892/29850 (epoch 23.270), train_loss = 0.89476769, grad/param norm = 1.8255e-01, time/batch = 18.1957s	
13893/29850 (epoch 23.271), train_loss = 1.03477519, grad/param norm = 1.9369e-01, time/batch = 17.8586s	
13894/29850 (epoch 23.273), train_loss = 0.84575891, grad/param norm = 2.0785e-01, time/batch = 19.0110s	
13895/29850 (epoch 23.275), train_loss = 0.84266954, grad/param norm = 1.9660e-01, time/batch = 16.9515s	
13896/29850 (epoch 23.276), train_loss = 0.86446580, grad/param norm = 1.7422e-01, time/batch = 18.9560s	
13897/29850 (epoch 23.278), train_loss = 0.91678187, grad/param norm = 1.7644e-01, time/batch = 15.1145s	
13898/29850 (epoch 23.280), train_loss = 1.11056868, grad/param norm = 2.3701e-01, time/batch = 16.0298s	
13899/29850 (epoch 23.281), train_loss = 1.01269944, grad/param norm = 2.0259e-01, time/batch = 18.8484s	
13900/29850 (epoch 23.283), train_loss = 1.12156056, grad/param norm = 2.7415e-01, time/batch = 17.1125s	
13901/29850 (epoch 23.285), train_loss = 0.99057846, grad/param norm = 2.1767e-01, time/batch = 17.6014s	
13902/29850 (epoch 23.286), train_loss = 1.08839547, grad/param norm = 2.1265e-01, time/batch = 17.4517s	
13903/29850 (epoch 23.288), train_loss = 1.10521494, grad/param norm = 3.0262e-01, time/batch = 18.2075s	
13904/29850 (epoch 23.290), train_loss = 1.03786380, grad/param norm = 2.3315e-01, time/batch = 17.2192s	
13905/29850 (epoch 23.291), train_loss = 1.19780283, grad/param norm = 1.9982e-01, time/batch = 17.3618s	
13906/29850 (epoch 23.293), train_loss = 1.08521521, grad/param norm = 2.3441e-01, time/batch = 17.4472s	
13907/29850 (epoch 23.295), train_loss = 1.17042600, grad/param norm = 2.2593e-01, time/batch = 15.8164s	
13908/29850 (epoch 23.296), train_loss = 0.89255660, grad/param norm = 1.9668e-01, time/batch = 18.7150s	
13909/29850 (epoch 23.298), train_loss = 0.76975807, grad/param norm = 1.6725e-01, time/batch = 17.6058s	
13910/29850 (epoch 23.300), train_loss = 0.85517272, grad/param norm = 1.6888e-01, time/batch = 17.7818s	
13911/29850 (epoch 23.302), train_loss = 0.86059127, grad/param norm = 1.9296e-01, time/batch = 18.8594s	
13912/29850 (epoch 23.303), train_loss = 0.91152211, grad/param norm = 1.8184e-01, time/batch = 16.3755s	
13913/29850 (epoch 23.305), train_loss = 1.02595932, grad/param norm = 1.9499e-01, time/batch = 17.6334s	
13914/29850 (epoch 23.307), train_loss = 1.07355705, grad/param norm = 1.9591e-01, time/batch = 15.9636s	
13915/29850 (epoch 23.308), train_loss = 0.91999851, grad/param norm = 1.8233e-01, time/batch = 16.4318s	
13916/29850 (epoch 23.310), train_loss = 1.01935813, grad/param norm = 2.1444e-01, time/batch = 17.5200s	
13917/29850 (epoch 23.312), train_loss = 1.06197436, grad/param norm = 2.1528e-01, time/batch = 17.8858s	
13918/29850 (epoch 23.313), train_loss = 1.00554494, grad/param norm = 2.1435e-01, time/batch = 14.9759s	
13919/29850 (epoch 23.315), train_loss = 0.99462798, grad/param norm = 1.9395e-01, time/batch = 17.3527s	
13920/29850 (epoch 23.317), train_loss = 0.99839949, grad/param norm = 2.1458e-01, time/batch = 16.8912s	
13921/29850 (epoch 23.318), train_loss = 0.96412264, grad/param norm = 1.8502e-01, time/batch = 17.1264s	
13922/29850 (epoch 23.320), train_loss = 0.92945515, grad/param norm = 1.7453e-01, time/batch = 18.7811s	
13923/29850 (epoch 23.322), train_loss = 1.13206963, grad/param norm = 2.0487e-01, time/batch = 17.4526s	
13924/29850 (epoch 23.323), train_loss = 1.05726362, grad/param norm = 2.2422e-01, time/batch = 16.6036s	
13925/29850 (epoch 23.325), train_loss = 1.10440136, grad/param norm = 2.0999e-01, time/batch = 15.4207s	
13926/29850 (epoch 23.327), train_loss = 1.20180931, grad/param norm = 2.2359e-01, time/batch = 15.7054s	
13927/29850 (epoch 23.328), train_loss = 1.14471253, grad/param norm = 2.3940e-01, time/batch = 15.3733s	
13928/29850 (epoch 23.330), train_loss = 1.05148761, grad/param norm = 1.9639e-01, time/batch = 16.5247s	
13929/29850 (epoch 23.332), train_loss = 0.98377318, grad/param norm = 2.0207e-01, time/batch = 18.0263s	
13930/29850 (epoch 23.333), train_loss = 1.08301647, grad/param norm = 2.3075e-01, time/batch = 16.7079s	
13931/29850 (epoch 23.335), train_loss = 1.12514494, grad/param norm = 2.0823e-01, time/batch = 17.9475s	
13932/29850 (epoch 23.337), train_loss = 1.02875941, grad/param norm = 2.1544e-01, time/batch = 16.1068s	
13933/29850 (epoch 23.338), train_loss = 1.02117981, grad/param norm = 1.8957e-01, time/batch = 15.3495s	
13934/29850 (epoch 23.340), train_loss = 0.88956585, grad/param norm = 1.8702e-01, time/batch = 18.0264s	
13935/29850 (epoch 23.342), train_loss = 1.02675574, grad/param norm = 2.5245e-01, time/batch = 16.9629s	
13936/29850 (epoch 23.343), train_loss = 1.02518143, grad/param norm = 2.1805e-01, time/batch = 17.3159s	
13937/29850 (epoch 23.345), train_loss = 1.06942946, grad/param norm = 2.1128e-01, time/batch = 16.3673s	
13938/29850 (epoch 23.347), train_loss = 1.12307934, grad/param norm = 2.3011e-01, time/batch = 15.1844s	
13939/29850 (epoch 23.348), train_loss = 0.96787534, grad/param norm = 1.9791e-01, time/batch = 16.8831s	
13940/29850 (epoch 23.350), train_loss = 1.07857678, grad/param norm = 2.1652e-01, time/batch = 16.5012s	
13941/29850 (epoch 23.352), train_loss = 0.93901289, grad/param norm = 1.9346e-01, time/batch = 18.6237s	
13942/29850 (epoch 23.353), train_loss = 1.07416052, grad/param norm = 2.2347e-01, time/batch = 16.2148s	
13943/29850 (epoch 23.355), train_loss = 0.92565968, grad/param norm = 1.9716e-01, time/batch = 18.4653s	
13944/29850 (epoch 23.357), train_loss = 1.11525865, grad/param norm = 1.9141e-01, time/batch = 15.4300s	
13945/29850 (epoch 23.358), train_loss = 0.91815766, grad/param norm = 1.9138e-01, time/batch = 15.3747s	
13946/29850 (epoch 23.360), train_loss = 0.97407563, grad/param norm = 1.9160e-01, time/batch = 15.7158s	
13947/29850 (epoch 23.362), train_loss = 0.99082644, grad/param norm = 1.9972e-01, time/batch = 17.1352s	
13948/29850 (epoch 23.363), train_loss = 1.03242836, grad/param norm = 2.1869e-01, time/batch = 15.5229s	
13949/29850 (epoch 23.365), train_loss = 1.14760791, grad/param norm = 2.1064e-01, time/batch = 17.8759s	
13950/29850 (epoch 23.367), train_loss = 0.93616383, grad/param norm = 2.0540e-01, time/batch = 19.2810s	
13951/29850 (epoch 23.369), train_loss = 0.86480618, grad/param norm = 1.7545e-01, time/batch = 18.1230s	
13952/29850 (epoch 23.370), train_loss = 0.82190358, grad/param norm = 1.8720e-01, time/batch = 16.0361s	
13953/29850 (epoch 23.372), train_loss = 1.08947658, grad/param norm = 2.2452e-01, time/batch = 17.5860s	
13954/29850 (epoch 23.374), train_loss = 1.05414542, grad/param norm = 1.9622e-01, time/batch = 18.7021s	
13955/29850 (epoch 23.375), train_loss = 0.99818025, grad/param norm = 1.9191e-01, time/batch = 18.7791s	
13956/29850 (epoch 23.377), train_loss = 0.96172063, grad/param norm = 2.0100e-01, time/batch = 17.1260s	
13957/29850 (epoch 23.379), train_loss = 1.12313562, grad/param norm = 2.3361e-01, time/batch = 18.5555s	
13958/29850 (epoch 23.380), train_loss = 1.07109976, grad/param norm = 2.0288e-01, time/batch = 28.8991s	
13959/29850 (epoch 23.382), train_loss = 1.05835553, grad/param norm = 2.3191e-01, time/batch = 16.2554s	
13960/29850 (epoch 23.384), train_loss = 1.07952398, grad/param norm = 2.1276e-01, time/batch = 15.7250s	
13961/29850 (epoch 23.385), train_loss = 1.01913380, grad/param norm = 2.1690e-01, time/batch = 16.6778s	
13962/29850 (epoch 23.387), train_loss = 1.03646959, grad/param norm = 2.0622e-01, time/batch = 15.0941s	
13963/29850 (epoch 23.389), train_loss = 1.16246970, grad/param norm = 2.4632e-01, time/batch = 14.9421s	
13964/29850 (epoch 23.390), train_loss = 1.07226367, grad/param norm = 1.8002e-01, time/batch = 14.4924s	
13965/29850 (epoch 23.392), train_loss = 0.98461809, grad/param norm = 2.1920e-01, time/batch = 14.8836s	
13966/29850 (epoch 23.394), train_loss = 1.09626697, grad/param norm = 1.9858e-01, time/batch = 14.1627s	
13967/29850 (epoch 23.395), train_loss = 0.98304241, grad/param norm = 2.2897e-01, time/batch = 14.3240s	
13968/29850 (epoch 23.397), train_loss = 0.89849356, grad/param norm = 2.0508e-01, time/batch = 14.3404s	
13969/29850 (epoch 23.399), train_loss = 0.90975458, grad/param norm = 1.7703e-01, time/batch = 14.3053s	
13970/29850 (epoch 23.400), train_loss = 1.30518689, grad/param norm = 2.2813e-01, time/batch = 14.5738s	
13971/29850 (epoch 23.402), train_loss = 1.18545942, grad/param norm = 2.0001e-01, time/batch = 14.4109s	
13972/29850 (epoch 23.404), train_loss = 1.04225491, grad/param norm = 1.8459e-01, time/batch = 14.3407s	
13973/29850 (epoch 23.405), train_loss = 0.94721719, grad/param norm = 2.1451e-01, time/batch = 14.7269s	
13974/29850 (epoch 23.407), train_loss = 0.91316478, grad/param norm = 1.9278e-01, time/batch = 14.4166s	
13975/29850 (epoch 23.409), train_loss = 1.07082668, grad/param norm = 2.2681e-01, time/batch = 14.5839s	
13976/29850 (epoch 23.410), train_loss = 1.15382564, grad/param norm = 2.2870e-01, time/batch = 13.9979s	
13977/29850 (epoch 23.412), train_loss = 1.12758721, grad/param norm = 2.0903e-01, time/batch = 14.6500s	
13978/29850 (epoch 23.414), train_loss = 1.01425880, grad/param norm = 2.1327e-01, time/batch = 14.7424s	
13979/29850 (epoch 23.415), train_loss = 1.01876630, grad/param norm = 1.9732e-01, time/batch = 14.5005s	
13980/29850 (epoch 23.417), train_loss = 1.16420096, grad/param norm = 2.5109e-01, time/batch = 15.1973s	
13981/29850 (epoch 23.419), train_loss = 0.99866898, grad/param norm = 2.0333e-01, time/batch = 15.1637s	
13982/29850 (epoch 23.420), train_loss = 1.01109570, grad/param norm = 1.9521e-01, time/batch = 15.1124s	
13983/29850 (epoch 23.422), train_loss = 1.00043724, grad/param norm = 1.8254e-01, time/batch = 14.5640s	
13984/29850 (epoch 23.424), train_loss = 0.94236725, grad/param norm = 1.9923e-01, time/batch = 15.1651s	
13985/29850 (epoch 23.425), train_loss = 1.11380784, grad/param norm = 2.0120e-01, time/batch = 14.7140s	
13986/29850 (epoch 23.427), train_loss = 0.83037000, grad/param norm = 1.7052e-01, time/batch = 14.8704s	
13987/29850 (epoch 23.429), train_loss = 0.89684263, grad/param norm = 1.8158e-01, time/batch = 14.3418s	
13988/29850 (epoch 23.430), train_loss = 0.85214991, grad/param norm = 1.8094e-01, time/batch = 14.2590s	
13989/29850 (epoch 23.432), train_loss = 0.97060741, grad/param norm = 2.2570e-01, time/batch = 14.6432s	
13990/29850 (epoch 23.434), train_loss = 0.90082484, grad/param norm = 1.8499e-01, time/batch = 14.7911s	
13991/29850 (epoch 23.436), train_loss = 1.00678766, grad/param norm = 2.1574e-01, time/batch = 14.4850s	
13992/29850 (epoch 23.437), train_loss = 1.06440474, grad/param norm = 1.8315e-01, time/batch = 14.3435s	
13993/29850 (epoch 23.439), train_loss = 1.04755297, grad/param norm = 2.0471e-01, time/batch = 14.4815s	
13994/29850 (epoch 23.441), train_loss = 1.01518591, grad/param norm = 2.0004e-01, time/batch = 14.3335s	
13995/29850 (epoch 23.442), train_loss = 1.01531492, grad/param norm = 1.9637e-01, time/batch = 14.3384s	
13996/29850 (epoch 23.444), train_loss = 1.04850751, grad/param norm = 2.2649e-01, time/batch = 14.0861s	
13997/29850 (epoch 23.446), train_loss = 1.07126397, grad/param norm = 2.0292e-01, time/batch = 14.4749s	
13998/29850 (epoch 23.447), train_loss = 1.06906038, grad/param norm = 1.9764e-01, time/batch = 14.4921s	
13999/29850 (epoch 23.449), train_loss = 1.02169540, grad/param norm = 2.1476e-01, time/batch = 14.2550s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch23.45_1.7218.t7	
14000/29850 (epoch 23.451), train_loss = 0.82027000, grad/param norm = 1.6283e-01, time/batch = 14.7942s	
14001/29850 (epoch 23.452), train_loss = 1.21046872, grad/param norm = 2.1745e-01, time/batch = 15.3241s	
14002/29850 (epoch 23.454), train_loss = 0.85384263, grad/param norm = 1.6781e-01, time/batch = 15.0132s	
14003/29850 (epoch 23.456), train_loss = 1.06440606, grad/param norm = 2.0550e-01, time/batch = 14.8932s	
14004/29850 (epoch 23.457), train_loss = 1.08360092, grad/param norm = 3.0270e-01, time/batch = 14.8197s	
14005/29850 (epoch 23.459), train_loss = 1.17725897, grad/param norm = 2.3718e-01, time/batch = 15.0624s	
14006/29850 (epoch 23.461), train_loss = 1.15616368, grad/param norm = 1.9893e-01, time/batch = 14.8972s	
14007/29850 (epoch 23.462), train_loss = 1.13370744, grad/param norm = 2.2174e-01, time/batch = 14.7251s	
14008/29850 (epoch 23.464), train_loss = 1.06911894, grad/param norm = 2.2317e-01, time/batch = 15.0664s	
14009/29850 (epoch 23.466), train_loss = 0.87648357, grad/param norm = 2.0748e-01, time/batch = 14.9799s	
14010/29850 (epoch 23.467), train_loss = 0.98722991, grad/param norm = 2.1256e-01, time/batch = 14.9037s	
14011/29850 (epoch 23.469), train_loss = 0.97680096, grad/param norm = 2.1060e-01, time/batch = 14.9422s	
14012/29850 (epoch 23.471), train_loss = 1.00472808, grad/param norm = 2.2496e-01, time/batch = 14.7532s	
14013/29850 (epoch 23.472), train_loss = 0.95841462, grad/param norm = 2.0034e-01, time/batch = 14.8118s	
14014/29850 (epoch 23.474), train_loss = 1.10410399, grad/param norm = 2.0036e-01, time/batch = 14.6727s	
14015/29850 (epoch 23.476), train_loss = 1.01096577, grad/param norm = 1.7834e-01, time/batch = 15.0374s	
14016/29850 (epoch 23.477), train_loss = 1.04197993, grad/param norm = 2.5060e-01, time/batch = 14.4811s	
14017/29850 (epoch 23.479), train_loss = 1.17555927, grad/param norm = 2.2808e-01, time/batch = 14.5664s	
14018/29850 (epoch 23.481), train_loss = 0.97274526, grad/param norm = 1.8155e-01, time/batch = 14.8255s	
14019/29850 (epoch 23.482), train_loss = 0.93117475, grad/param norm = 1.7277e-01, time/batch = 14.3978s	
14020/29850 (epoch 23.484), train_loss = 0.94655649, grad/param norm = 1.9868e-01, time/batch = 15.0479s	
14021/29850 (epoch 23.486), train_loss = 1.03827072, grad/param norm = 2.0580e-01, time/batch = 15.0403s	
14022/29850 (epoch 23.487), train_loss = 0.99645264, grad/param norm = 2.0810e-01, time/batch = 14.5711s	
14023/29850 (epoch 23.489), train_loss = 0.98764051, grad/param norm = 1.9613e-01, time/batch = 14.0860s	
14024/29850 (epoch 23.491), train_loss = 0.91474168, grad/param norm = 1.9492e-01, time/batch = 14.3457s	
14025/29850 (epoch 23.492), train_loss = 1.00448154, grad/param norm = 2.1541e-01, time/batch = 14.5645s	
14026/29850 (epoch 23.494), train_loss = 1.10808888, grad/param norm = 1.9494e-01, time/batch = 15.0258s	
14027/29850 (epoch 23.496), train_loss = 1.18204203, grad/param norm = 2.0190e-01, time/batch = 14.5540s	
14028/29850 (epoch 23.497), train_loss = 1.07376365, grad/param norm = 1.9262e-01, time/batch = 14.5688s	
14029/29850 (epoch 23.499), train_loss = 1.00640203, grad/param norm = 1.8682e-01, time/batch = 14.8610s	
14030/29850 (epoch 23.501), train_loss = 0.95124388, grad/param norm = 2.0914e-01, time/batch = 14.8596s	
14031/29850 (epoch 23.503), train_loss = 1.02299071, grad/param norm = 2.0813e-01, time/batch = 14.3407s	
14032/29850 (epoch 23.504), train_loss = 1.22898277, grad/param norm = 2.1824e-01, time/batch = 14.6405s	
14033/29850 (epoch 23.506), train_loss = 1.18806537, grad/param norm = 2.3069e-01, time/batch = 14.4096s	
14034/29850 (epoch 23.508), train_loss = 1.04116275, grad/param norm = 2.2044e-01, time/batch = 14.7178s	
14035/29850 (epoch 23.509), train_loss = 0.82666899, grad/param norm = 1.8297e-01, time/batch = 14.7137s	
14036/29850 (epoch 23.511), train_loss = 1.03417898, grad/param norm = 1.9445e-01, time/batch = 16.2196s	
14037/29850 (epoch 23.513), train_loss = 1.07609344, grad/param norm = 2.5269e-01, time/batch = 17.2976s	
14038/29850 (epoch 23.514), train_loss = 0.91585836, grad/param norm = 2.0514e-01, time/batch = 17.7113s	
14039/29850 (epoch 23.516), train_loss = 0.94724709, grad/param norm = 1.6423e-01, time/batch = 14.9011s	
14040/29850 (epoch 23.518), train_loss = 0.83883747, grad/param norm = 1.9498e-01, time/batch = 15.7864s	
14041/29850 (epoch 23.519), train_loss = 0.84390655, grad/param norm = 1.7186e-01, time/batch = 16.3797s	
14042/29850 (epoch 23.521), train_loss = 0.78853480, grad/param norm = 1.9180e-01, time/batch = 16.6398s	
14043/29850 (epoch 23.523), train_loss = 0.84739394, grad/param norm = 1.7754e-01, time/batch = 18.1332s	
14044/29850 (epoch 23.524), train_loss = 0.92193991, grad/param norm = 2.0659e-01, time/batch = 16.2550s	
14045/29850 (epoch 23.526), train_loss = 1.00062022, grad/param norm = 2.0105e-01, time/batch = 16.0882s	
14046/29850 (epoch 23.528), train_loss = 1.08547823, grad/param norm = 2.1619e-01, time/batch = 15.7510s	
14047/29850 (epoch 23.529), train_loss = 1.04569807, grad/param norm = 2.0916e-01, time/batch = 15.6644s	
14048/29850 (epoch 23.531), train_loss = 0.97694527, grad/param norm = 2.0629e-01, time/batch = 15.4438s	
14049/29850 (epoch 23.533), train_loss = 0.97608807, grad/param norm = 1.9757e-01, time/batch = 15.1309s	
14050/29850 (epoch 23.534), train_loss = 1.03287466, grad/param norm = 2.3162e-01, time/batch = 15.4467s	
14051/29850 (epoch 23.536), train_loss = 0.96163981, grad/param norm = 2.2611e-01, time/batch = 14.9643s	
14052/29850 (epoch 23.538), train_loss = 1.09517970, grad/param norm = 1.9963e-01, time/batch = 15.4099s	
14053/29850 (epoch 23.539), train_loss = 1.16156721, grad/param norm = 2.3707e-01, time/batch = 15.6463s	
14054/29850 (epoch 23.541), train_loss = 0.77321793, grad/param norm = 1.8866e-01, time/batch = 15.2264s	
14055/29850 (epoch 23.543), train_loss = 1.01128196, grad/param norm = 2.1071e-01, time/batch = 16.0402s	
14056/29850 (epoch 23.544), train_loss = 1.06330839, grad/param norm = 1.9338e-01, time/batch = 16.7914s	
14057/29850 (epoch 23.546), train_loss = 1.09678726, grad/param norm = 2.0406e-01, time/batch = 15.7846s	
14058/29850 (epoch 23.548), train_loss = 0.86180658, grad/param norm = 1.7945e-01, time/batch = 15.2834s	
14059/29850 (epoch 23.549), train_loss = 0.98558778, grad/param norm = 2.0821e-01, time/batch = 18.5464s	
14060/29850 (epoch 23.551), train_loss = 0.85527888, grad/param norm = 1.6387e-01, time/batch = 18.1996s	
14061/29850 (epoch 23.553), train_loss = 1.00237285, grad/param norm = 1.9612e-01, time/batch = 18.3802s	
14062/29850 (epoch 23.554), train_loss = 0.84950319, grad/param norm = 1.7242e-01, time/batch = 16.1899s	
14063/29850 (epoch 23.556), train_loss = 0.90162926, grad/param norm = 2.1032e-01, time/batch = 15.7096s	
14064/29850 (epoch 23.558), train_loss = 0.91618312, grad/param norm = 1.9873e-01, time/batch = 16.7136s	
14065/29850 (epoch 23.559), train_loss = 0.96271118, grad/param norm = 1.7625e-01, time/batch = 18.2940s	
14066/29850 (epoch 23.561), train_loss = 1.06305250, grad/param norm = 2.1922e-01, time/batch = 17.1120s	
14067/29850 (epoch 23.563), train_loss = 1.01153650, grad/param norm = 2.0632e-01, time/batch = 15.4789s	
14068/29850 (epoch 23.564), train_loss = 0.97871485, grad/param norm = 2.0665e-01, time/batch = 15.6312s	
14069/29850 (epoch 23.566), train_loss = 1.03737712, grad/param norm = 2.0779e-01, time/batch = 15.0963s	
14070/29850 (epoch 23.568), train_loss = 1.07735905, grad/param norm = 2.0677e-01, time/batch = 14.5712s	
14071/29850 (epoch 23.570), train_loss = 1.04109009, grad/param norm = 2.1249e-01, time/batch = 14.8101s	
14072/29850 (epoch 23.571), train_loss = 1.09935171, grad/param norm = 2.1410e-01, time/batch = 14.8159s	
14073/29850 (epoch 23.573), train_loss = 1.17982549, grad/param norm = 2.5753e-01, time/batch = 14.9516s	
14074/29850 (epoch 23.575), train_loss = 1.13529146, grad/param norm = 2.1495e-01, time/batch = 15.5621s	
14075/29850 (epoch 23.576), train_loss = 1.08895447, grad/param norm = 2.0232e-01, time/batch = 15.1332s	
14076/29850 (epoch 23.578), train_loss = 0.96827272, grad/param norm = 2.1739e-01, time/batch = 15.5026s	
14077/29850 (epoch 23.580), train_loss = 1.11698573, grad/param norm = 1.9764e-01, time/batch = 14.4751s	
14078/29850 (epoch 23.581), train_loss = 0.93174463, grad/param norm = 2.0604e-01, time/batch = 14.3925s	
14079/29850 (epoch 23.583), train_loss = 1.01801083, grad/param norm = 2.0634e-01, time/batch = 14.4783s	
14080/29850 (epoch 23.585), train_loss = 1.03959989, grad/param norm = 2.0407e-01, time/batch = 14.5392s	
14081/29850 (epoch 23.586), train_loss = 1.02041010, grad/param norm = 2.1113e-01, time/batch = 14.5742s	
14082/29850 (epoch 23.588), train_loss = 0.96966289, grad/param norm = 2.0453e-01, time/batch = 14.5698s	
14083/29850 (epoch 23.590), train_loss = 0.98476744, grad/param norm = 1.9066e-01, time/batch = 14.7112s	
14084/29850 (epoch 23.591), train_loss = 0.96850338, grad/param norm = 2.3367e-01, time/batch = 14.5640s	
14085/29850 (epoch 23.593), train_loss = 0.92203199, grad/param norm = 1.7701e-01, time/batch = 15.5700s	
14086/29850 (epoch 23.595), train_loss = 0.86830791, grad/param norm = 1.6031e-01, time/batch = 15.0257s	
14087/29850 (epoch 23.596), train_loss = 0.86625103, grad/param norm = 1.7209e-01, time/batch = 15.4284s	
14088/29850 (epoch 23.598), train_loss = 0.97146375, grad/param norm = 1.8495e-01, time/batch = 15.2487s	
14089/29850 (epoch 23.600), train_loss = 1.03232926, grad/param norm = 2.0915e-01, time/batch = 14.4852s	
14090/29850 (epoch 23.601), train_loss = 0.87854685, grad/param norm = 1.8363e-01, time/batch = 14.1721s	
14091/29850 (epoch 23.603), train_loss = 0.94122471, grad/param norm = 1.9047e-01, time/batch = 14.6314s	
14092/29850 (epoch 23.605), train_loss = 0.97556007, grad/param norm = 2.0676e-01, time/batch = 14.4848s	
14093/29850 (epoch 23.606), train_loss = 0.73770973, grad/param norm = 1.7745e-01, time/batch = 14.7775s	
14094/29850 (epoch 23.608), train_loss = 0.91035393, grad/param norm = 1.9271e-01, time/batch = 14.0809s	
14095/29850 (epoch 23.610), train_loss = 0.98432112, grad/param norm = 2.1021e-01, time/batch = 14.8818s	
14096/29850 (epoch 23.611), train_loss = 0.91836769, grad/param norm = 2.0064e-01, time/batch = 14.3400s	
14097/29850 (epoch 23.613), train_loss = 0.74895581, grad/param norm = 1.6745e-01, time/batch = 14.7046s	
14098/29850 (epoch 23.615), train_loss = 0.87429177, grad/param norm = 1.8085e-01, time/batch = 14.4193s	
14099/29850 (epoch 23.616), train_loss = 0.88239901, grad/param norm = 2.0849e-01, time/batch = 14.9452s	
14100/29850 (epoch 23.618), train_loss = 0.96096118, grad/param norm = 2.1138e-01, time/batch = 14.3233s	
14101/29850 (epoch 23.620), train_loss = 1.00684592, grad/param norm = 2.0895e-01, time/batch = 14.4955s	
14102/29850 (epoch 23.621), train_loss = 1.14806552, grad/param norm = 2.2608e-01, time/batch = 14.2472s	
14103/29850 (epoch 23.623), train_loss = 1.04333658, grad/param norm = 1.9826e-01, time/batch = 14.6440s	
14104/29850 (epoch 23.625), train_loss = 1.01583425, grad/param norm = 2.4121e-01, time/batch = 14.4133s	
14105/29850 (epoch 23.626), train_loss = 1.02913525, grad/param norm = 2.0044e-01, time/batch = 14.8922s	
14106/29850 (epoch 23.628), train_loss = 0.91623488, grad/param norm = 1.9592e-01, time/batch = 14.4053s	
14107/29850 (epoch 23.630), train_loss = 0.99002712, grad/param norm = 2.0301e-01, time/batch = 15.4061s	
14108/29850 (epoch 23.631), train_loss = 0.97659171, grad/param norm = 1.8919e-01, time/batch = 15.1783s	
14109/29850 (epoch 23.633), train_loss = 1.04475167, grad/param norm = 2.2788e-01, time/batch = 14.6433s	
14110/29850 (epoch 23.635), train_loss = 0.95399265, grad/param norm = 2.0442e-01, time/batch = 14.6541s	
14111/29850 (epoch 23.637), train_loss = 0.91310078, grad/param norm = 2.1239e-01, time/batch = 15.6251s	
14112/29850 (epoch 23.638), train_loss = 1.00067528, grad/param norm = 2.0468e-01, time/batch = 15.2656s	
14113/29850 (epoch 23.640), train_loss = 1.14589975, grad/param norm = 2.4170e-01, time/batch = 14.8800s	
14114/29850 (epoch 23.642), train_loss = 0.93260307, grad/param norm = 1.9759e-01, time/batch = 14.5618s	
14115/29850 (epoch 23.643), train_loss = 0.91485277, grad/param norm = 2.1157e-01, time/batch = 14.9651s	
14116/29850 (epoch 23.645), train_loss = 0.96230575, grad/param norm = 1.9729e-01, time/batch = 14.6442s	
14117/29850 (epoch 23.647), train_loss = 1.12207946, grad/param norm = 2.2669e-01, time/batch = 15.2256s	
14118/29850 (epoch 23.648), train_loss = 0.87343298, grad/param norm = 1.8681e-01, time/batch = 14.7778s	
14119/29850 (epoch 23.650), train_loss = 1.00895728, grad/param norm = 2.1097e-01, time/batch = 15.1053s	
14120/29850 (epoch 23.652), train_loss = 1.00040997, grad/param norm = 2.0789e-01, time/batch = 14.7328s	
14121/29850 (epoch 23.653), train_loss = 1.11423167, grad/param norm = 2.5107e-01, time/batch = 14.7386s	
14122/29850 (epoch 23.655), train_loss = 0.99056721, grad/param norm = 1.8843e-01, time/batch = 14.5041s	
14123/29850 (epoch 23.657), train_loss = 0.94928704, grad/param norm = 1.9740e-01, time/batch = 14.9516s	
14124/29850 (epoch 23.658), train_loss = 1.08394092, grad/param norm = 1.9733e-01, time/batch = 14.4293s	
14125/29850 (epoch 23.660), train_loss = 0.98427193, grad/param norm = 2.0972e-01, time/batch = 15.0332s	
14126/29850 (epoch 23.662), train_loss = 1.06707573, grad/param norm = 2.1849e-01, time/batch = 15.0296s	
14127/29850 (epoch 23.663), train_loss = 1.18392235, grad/param norm = 2.1772e-01, time/batch = 14.7066s	
14128/29850 (epoch 23.665), train_loss = 1.11943003, grad/param norm = 2.1902e-01, time/batch = 14.7999s	
14129/29850 (epoch 23.667), train_loss = 1.06840049, grad/param norm = 2.5919e-01, time/batch = 14.8021s	
14130/29850 (epoch 23.668), train_loss = 0.97116868, grad/param norm = 2.0833e-01, time/batch = 14.4928s	
14131/29850 (epoch 23.670), train_loss = 1.10429072, grad/param norm = 2.4185e-01, time/batch = 14.8087s	
14132/29850 (epoch 23.672), train_loss = 1.14761876, grad/param norm = 2.6106e-01, time/batch = 14.7190s	
14133/29850 (epoch 23.673), train_loss = 1.05705221, grad/param norm = 2.1326e-01, time/batch = 15.0918s	
14134/29850 (epoch 23.675), train_loss = 0.89258669, grad/param norm = 2.1088e-01, time/batch = 14.4707s	
14135/29850 (epoch 23.677), train_loss = 0.95758862, grad/param norm = 1.9764e-01, time/batch = 14.7139s	
14136/29850 (epoch 23.678), train_loss = 0.96861427, grad/param norm = 1.9960e-01, time/batch = 14.2554s	
14137/29850 (epoch 23.680), train_loss = 1.00891754, grad/param norm = 2.1122e-01, time/batch = 14.2430s	
14138/29850 (epoch 23.682), train_loss = 0.99827899, grad/param norm = 2.1441e-01, time/batch = 14.5669s	
14139/29850 (epoch 23.683), train_loss = 1.13444655, grad/param norm = 2.3682e-01, time/batch = 15.1000s	
14140/29850 (epoch 23.685), train_loss = 1.16639212, grad/param norm = 1.8977e-01, time/batch = 14.5696s	
14141/29850 (epoch 23.687), train_loss = 1.06978472, grad/param norm = 2.2509e-01, time/batch = 15.0398s	
14142/29850 (epoch 23.688), train_loss = 0.87459019, grad/param norm = 1.8893e-01, time/batch = 14.9785s	
14143/29850 (epoch 23.690), train_loss = 0.87608374, grad/param norm = 1.9970e-01, time/batch = 14.8811s	
14144/29850 (epoch 23.692), train_loss = 1.08245098, grad/param norm = 1.9731e-01, time/batch = 15.0615s	
14145/29850 (epoch 23.693), train_loss = 0.97909071, grad/param norm = 1.8327e-01, time/batch = 14.7400s	
14146/29850 (epoch 23.695), train_loss = 0.86250344, grad/param norm = 1.7263e-01, time/batch = 14.3392s	
14147/29850 (epoch 23.697), train_loss = 0.98443810, grad/param norm = 2.0863e-01, time/batch = 15.0847s	
14148/29850 (epoch 23.698), train_loss = 1.12707221, grad/param norm = 2.0344e-01, time/batch = 14.9752s	
14149/29850 (epoch 23.700), train_loss = 1.06712822, grad/param norm = 2.2415e-01, time/batch = 14.4942s	
14150/29850 (epoch 23.702), train_loss = 0.97941130, grad/param norm = 1.9265e-01, time/batch = 15.0440s	
14151/29850 (epoch 23.704), train_loss = 0.87618006, grad/param norm = 1.7674e-01, time/batch = 15.4808s	
14152/29850 (epoch 23.705), train_loss = 1.00390697, grad/param norm = 1.9101e-01, time/batch = 15.4783s	
14153/29850 (epoch 23.707), train_loss = 0.91870859, grad/param norm = 1.9761e-01, time/batch = 15.2386s	
14154/29850 (epoch 23.709), train_loss = 1.00025321, grad/param norm = 1.9283e-01, time/batch = 14.8160s	
14155/29850 (epoch 23.710), train_loss = 0.94452517, grad/param norm = 2.1559e-01, time/batch = 14.7412s	
14156/29850 (epoch 23.712), train_loss = 1.00110012, grad/param norm = 1.7048e-01, time/batch = 15.0591s	
14157/29850 (epoch 23.714), train_loss = 1.07250748, grad/param norm = 2.0839e-01, time/batch = 14.8986s	
14158/29850 (epoch 23.715), train_loss = 1.03367725, grad/param norm = 2.0787e-01, time/batch = 14.7424s	
14159/29850 (epoch 23.717), train_loss = 0.78327203, grad/param norm = 1.7555e-01, time/batch = 14.4088s	
14160/29850 (epoch 23.719), train_loss = 0.94256229, grad/param norm = 2.0248e-01, time/batch = 14.5727s	
14161/29850 (epoch 23.720), train_loss = 0.99347280, grad/param norm = 1.9795e-01, time/batch = 14.5008s	
14162/29850 (epoch 23.722), train_loss = 0.91497495, grad/param norm = 1.6291e-01, time/batch = 14.4182s	
14163/29850 (epoch 23.724), train_loss = 1.04653802, grad/param norm = 2.0178e-01, time/batch = 14.5688s	
14164/29850 (epoch 23.725), train_loss = 0.85057597, grad/param norm = 1.8337e-01, time/batch = 15.0224s	
14165/29850 (epoch 23.727), train_loss = 0.91618762, grad/param norm = 2.0099e-01, time/batch = 14.6360s	
14166/29850 (epoch 23.729), train_loss = 0.83855183, grad/param norm = 1.6515e-01, time/batch = 14.9384s	
14167/29850 (epoch 23.730), train_loss = 0.82005625, grad/param norm = 1.8002e-01, time/batch = 14.6925s	
14168/29850 (epoch 23.732), train_loss = 1.06840157, grad/param norm = 1.8345e-01, time/batch = 14.7047s	
14169/29850 (epoch 23.734), train_loss = 1.15883616, grad/param norm = 2.2469e-01, time/batch = 14.6442s	
14170/29850 (epoch 23.735), train_loss = 0.97302923, grad/param norm = 3.0045e-01, time/batch = 14.6389s	
14171/29850 (epoch 23.737), train_loss = 0.89449845, grad/param norm = 1.9592e-01, time/batch = 14.5695s	
14172/29850 (epoch 23.739), train_loss = 0.77448315, grad/param norm = 1.8530e-01, time/batch = 14.5826s	
14173/29850 (epoch 23.740), train_loss = 0.85889563, grad/param norm = 1.7974e-01, time/batch = 14.5766s	
14174/29850 (epoch 23.742), train_loss = 0.79437972, grad/param norm = 1.8273e-01, time/batch = 14.5702s	
14175/29850 (epoch 23.744), train_loss = 0.93940186, grad/param norm = 2.1863e-01, time/batch = 14.9651s	
14176/29850 (epoch 23.745), train_loss = 0.89558353, grad/param norm = 2.0043e-01, time/batch = 14.5576s	
14177/29850 (epoch 23.747), train_loss = 0.95836242, grad/param norm = 2.0161e-01, time/batch = 14.4176s	
14178/29850 (epoch 23.749), train_loss = 0.86399987, grad/param norm = 2.1272e-01, time/batch = 14.4229s	
14179/29850 (epoch 23.750), train_loss = 0.80824286, grad/param norm = 1.7386e-01, time/batch = 14.5079s	
14180/29850 (epoch 23.752), train_loss = 0.75224792, grad/param norm = 1.8669e-01, time/batch = 14.9020s	
14181/29850 (epoch 23.754), train_loss = 0.83554668, grad/param norm = 1.8985e-01, time/batch = 14.5035s	
14182/29850 (epoch 23.755), train_loss = 0.83433694, grad/param norm = 1.7831e-01, time/batch = 15.1948s	
14183/29850 (epoch 23.757), train_loss = 0.89225249, grad/param norm = 1.7352e-01, time/batch = 14.3846s	
14184/29850 (epoch 23.759), train_loss = 0.90555823, grad/param norm = 1.9679e-01, time/batch = 14.3070s	
14185/29850 (epoch 23.760), train_loss = 0.87619797, grad/param norm = 2.1000e-01, time/batch = 14.7384s	
14186/29850 (epoch 23.762), train_loss = 0.84301496, grad/param norm = 2.5890e-01, time/batch = 14.7206s	
14187/29850 (epoch 23.764), train_loss = 0.82149644, grad/param norm = 2.3509e-01, time/batch = 14.7949s	
14188/29850 (epoch 23.765), train_loss = 0.94473214, grad/param norm = 2.2768e-01, time/batch = 28.1519s	
14189/29850 (epoch 23.767), train_loss = 0.93436815, grad/param norm = 1.8221e-01, time/batch = 14.8223s	
14190/29850 (epoch 23.769), train_loss = 0.93991957, grad/param norm = 1.8751e-01, time/batch = 15.8041s	
14191/29850 (epoch 23.771), train_loss = 0.99391011, grad/param norm = 2.0540e-01, time/batch = 15.4291s	
14192/29850 (epoch 23.772), train_loss = 1.00442950, grad/param norm = 2.1621e-01, time/batch = 15.2367s	
14193/29850 (epoch 23.774), train_loss = 0.91540759, grad/param norm = 2.0727e-01, time/batch = 15.5953s	
14194/29850 (epoch 23.776), train_loss = 0.90801364, grad/param norm = 1.8468e-01, time/batch = 15.0481s	
14195/29850 (epoch 23.777), train_loss = 1.03159992, grad/param norm = 2.0988e-01, time/batch = 15.3808s	
14196/29850 (epoch 23.779), train_loss = 0.86990058, grad/param norm = 2.0701e-01, time/batch = 15.2270s	
14197/29850 (epoch 23.781), train_loss = 0.97925569, grad/param norm = 1.8683e-01, time/batch = 14.8190s	
14198/29850 (epoch 23.782), train_loss = 1.01113524, grad/param norm = 2.0266e-01, time/batch = 14.7994s	
14199/29850 (epoch 23.784), train_loss = 0.86016689, grad/param norm = 2.2729e-01, time/batch = 15.3880s	
14200/29850 (epoch 23.786), train_loss = 0.91852853, grad/param norm = 1.9760e-01, time/batch = 15.2350s	
14201/29850 (epoch 23.787), train_loss = 0.80730327, grad/param norm = 1.9877e-01, time/batch = 15.0603s	
14202/29850 (epoch 23.789), train_loss = 0.78420576, grad/param norm = 1.6811e-01, time/batch = 15.1219s	
14203/29850 (epoch 23.791), train_loss = 0.88430337, grad/param norm = 2.0461e-01, time/batch = 15.2022s	
14204/29850 (epoch 23.792), train_loss = 1.01555427, grad/param norm = 2.1094e-01, time/batch = 14.9775s	
14205/29850 (epoch 23.794), train_loss = 0.99684519, grad/param norm = 1.9459e-01, time/batch = 14.9738s	
14206/29850 (epoch 23.796), train_loss = 0.84494379, grad/param norm = 1.8398e-01, time/batch = 15.4575s	
14207/29850 (epoch 23.797), train_loss = 0.79105630, grad/param norm = 1.7964e-01, time/batch = 15.9757s	
14208/29850 (epoch 23.799), train_loss = 0.81159843, grad/param norm = 1.5758e-01, time/batch = 15.1279s	
14209/29850 (epoch 23.801), train_loss = 0.90230936, grad/param norm = 2.0120e-01, time/batch = 15.1374s	
14210/29850 (epoch 23.802), train_loss = 0.78424462, grad/param norm = 2.0465e-01, time/batch = 15.2208s	
14211/29850 (epoch 23.804), train_loss = 0.82607201, grad/param norm = 1.7541e-01, time/batch = 15.3076s	
14212/29850 (epoch 23.806), train_loss = 0.82233636, grad/param norm = 1.7369e-01, time/batch = 15.2354s	
14213/29850 (epoch 23.807), train_loss = 0.78844536, grad/param norm = 1.5873e-01, time/batch = 15.4367s	
14214/29850 (epoch 23.809), train_loss = 0.83576743, grad/param norm = 1.9131e-01, time/batch = 15.5788s	
14215/29850 (epoch 23.811), train_loss = 0.98087333, grad/param norm = 1.8999e-01, time/batch = 15.5262s	
14216/29850 (epoch 23.812), train_loss = 0.99108375, grad/param norm = 2.2868e-01, time/batch = 15.3896s	
14217/29850 (epoch 23.814), train_loss = 1.06461611, grad/param norm = 2.1405e-01, time/batch = 15.6459s	
14218/29850 (epoch 23.816), train_loss = 1.02724947, grad/param norm = 1.8388e-01, time/batch = 15.6185s	
14219/29850 (epoch 23.817), train_loss = 0.96206595, grad/param norm = 1.9775e-01, time/batch = 15.7708s	
14220/29850 (epoch 23.819), train_loss = 0.82064840, grad/param norm = 2.0875e-01, time/batch = 15.5497s	
14221/29850 (epoch 23.821), train_loss = 1.07182817, grad/param norm = 2.4514e-01, time/batch = 15.9634s	
14222/29850 (epoch 23.822), train_loss = 1.05789820, grad/param norm = 2.1034e-01, time/batch = 15.8584s	
14223/29850 (epoch 23.824), train_loss = 0.95364457, grad/param norm = 1.9162e-01, time/batch = 15.0594s	
14224/29850 (epoch 23.826), train_loss = 0.87633247, grad/param norm = 1.8643e-01, time/batch = 15.0573s	
14225/29850 (epoch 23.827), train_loss = 0.82728029, grad/param norm = 2.0150e-01, time/batch = 14.9008s	
14226/29850 (epoch 23.829), train_loss = 0.95334765, grad/param norm = 2.3370e-01, time/batch = 15.2044s	
14227/29850 (epoch 23.831), train_loss = 1.03101097, grad/param norm = 2.2031e-01, time/batch = 14.9762s	
14228/29850 (epoch 23.832), train_loss = 0.93190619, grad/param norm = 1.8118e-01, time/batch = 15.5350s	
14229/29850 (epoch 23.834), train_loss = 0.76427949, grad/param norm = 1.8965e-01, time/batch = 14.9107s	
14230/29850 (epoch 23.836), train_loss = 0.80358962, grad/param norm = 1.7078e-01, time/batch = 15.6743s	
14231/29850 (epoch 23.838), train_loss = 0.93672032, grad/param norm = 2.2872e-01, time/batch = 15.2297s	
14232/29850 (epoch 23.839), train_loss = 0.82005445, grad/param norm = 1.7471e-01, time/batch = 15.3038s	
14233/29850 (epoch 23.841), train_loss = 0.84716253, grad/param norm = 1.8023e-01, time/batch = 15.8056s	
14234/29850 (epoch 23.843), train_loss = 0.79414896, grad/param norm = 1.9486e-01, time/batch = 15.5735s	
14235/29850 (epoch 23.844), train_loss = 0.85861932, grad/param norm = 1.9657e-01, time/batch = 14.9071s	
14236/29850 (epoch 23.846), train_loss = 0.92936485, grad/param norm = 1.9622e-01, time/batch = 15.1399s	
14237/29850 (epoch 23.848), train_loss = 1.01388843, grad/param norm = 2.2980e-01, time/batch = 15.2093s	
14238/29850 (epoch 23.849), train_loss = 0.90041600, grad/param norm = 2.1627e-01, time/batch = 15.1359s	
14239/29850 (epoch 23.851), train_loss = 1.05121886, grad/param norm = 2.1242e-01, time/batch = 15.2098s	
14240/29850 (epoch 23.853), train_loss = 0.90639194, grad/param norm = 2.1592e-01, time/batch = 15.4416s	
14241/29850 (epoch 23.854), train_loss = 1.10317236, grad/param norm = 2.0618e-01, time/batch = 15.2216s	
14242/29850 (epoch 23.856), train_loss = 1.04285364, grad/param norm = 2.3230e-01, time/batch = 15.1361s	
14243/29850 (epoch 23.858), train_loss = 0.96443018, grad/param norm = 1.8999e-01, time/batch = 15.3781s	
14244/29850 (epoch 23.859), train_loss = 0.83375286, grad/param norm = 2.3507e-01, time/batch = 15.0593s	
14245/29850 (epoch 23.861), train_loss = 1.06676596, grad/param norm = 2.1640e-01, time/batch = 15.3787s	
14246/29850 (epoch 23.863), train_loss = 1.12164357, grad/param norm = 2.0960e-01, time/batch = 15.6420s	
14247/29850 (epoch 23.864), train_loss = 1.06468253, grad/param norm = 2.3337e-01, time/batch = 15.2226s	
14248/29850 (epoch 23.866), train_loss = 0.96293382, grad/param norm = 2.1270e-01, time/batch = 15.3019s	
14249/29850 (epoch 23.868), train_loss = 1.12389939, grad/param norm = 2.1699e-01, time/batch = 15.4527s	
14250/29850 (epoch 23.869), train_loss = 0.99778999, grad/param norm = 2.5371e-01, time/batch = 15.8854s	
14251/29850 (epoch 23.871), train_loss = 1.04415304, grad/param norm = 2.1570e-01, time/batch = 15.6967s	
14252/29850 (epoch 23.873), train_loss = 0.99563932, grad/param norm = 2.0355e-01, time/batch = 15.2268s	
14253/29850 (epoch 23.874), train_loss = 1.00195895, grad/param norm = 1.9729e-01, time/batch = 15.6188s	
14254/29850 (epoch 23.876), train_loss = 0.95377685, grad/param norm = 3.1211e-01, time/batch = 15.4682s	
14255/29850 (epoch 23.878), train_loss = 0.99120685, grad/param norm = 2.0066e-01, time/batch = 15.6105s	
14256/29850 (epoch 23.879), train_loss = 1.01298950, grad/param norm = 2.0473e-01, time/batch = 15.1517s	
14257/29850 (epoch 23.881), train_loss = 1.04673824, grad/param norm = 2.0542e-01, time/batch = 15.5333s	
14258/29850 (epoch 23.883), train_loss = 1.05471027, grad/param norm = 2.4647e-01, time/batch = 15.2144s	
14259/29850 (epoch 23.884), train_loss = 0.85761998, grad/param norm = 2.0090e-01, time/batch = 15.2260s	
14260/29850 (epoch 23.886), train_loss = 1.09264917, grad/param norm = 2.1936e-01, time/batch = 14.9907s	
14261/29850 (epoch 23.888), train_loss = 0.98261978, grad/param norm = 1.9162e-01, time/batch = 15.3803s	
14262/29850 (epoch 23.889), train_loss = 0.90505733, grad/param norm = 1.7060e-01, time/batch = 14.8019s	
14263/29850 (epoch 23.891), train_loss = 0.86640878, grad/param norm = 1.7456e-01, time/batch = 15.1283s	
14264/29850 (epoch 23.893), train_loss = 0.89222090, grad/param norm = 2.0300e-01, time/batch = 15.2253s	
14265/29850 (epoch 23.894), train_loss = 0.93418888, grad/param norm = 2.1683e-01, time/batch = 15.6484s	
14266/29850 (epoch 23.896), train_loss = 0.95174875, grad/param norm = 1.9515e-01, time/batch = 15.6725s	
14267/29850 (epoch 23.898), train_loss = 1.07025726, grad/param norm = 2.0932e-01, time/batch = 15.9027s	
14268/29850 (epoch 23.899), train_loss = 0.85591842, grad/param norm = 2.0102e-01, time/batch = 15.0958s	
14269/29850 (epoch 23.901), train_loss = 1.24367562, grad/param norm = 2.5238e-01, time/batch = 15.5823s	
14270/29850 (epoch 23.903), train_loss = 1.00894313, grad/param norm = 2.6424e-01, time/batch = 16.0546s	
14271/29850 (epoch 23.905), train_loss = 1.18579117, grad/param norm = 2.2251e-01, time/batch = 17.8705s	
14272/29850 (epoch 23.906), train_loss = 1.03919791, grad/param norm = 2.1113e-01, time/batch = 16.2278s	
14273/29850 (epoch 23.908), train_loss = 1.10552858, grad/param norm = 2.0141e-01, time/batch = 16.8993s	
14274/29850 (epoch 23.910), train_loss = 1.03241870, grad/param norm = 2.0229e-01, time/batch = 16.5454s	
14275/29850 (epoch 23.911), train_loss = 1.17732525, grad/param norm = 2.0306e-01, time/batch = 19.5383s	
14276/29850 (epoch 23.913), train_loss = 1.12333200, grad/param norm = 2.1367e-01, time/batch = 17.2929s	
14277/29850 (epoch 23.915), train_loss = 1.11473411, grad/param norm = 2.3298e-01, time/batch = 17.9647s	
14278/29850 (epoch 23.916), train_loss = 1.07165487, grad/param norm = 2.1157e-01, time/batch = 17.7272s	
14279/29850 (epoch 23.918), train_loss = 0.90974865, grad/param norm = 1.9073e-01, time/batch = 16.6259s	
14280/29850 (epoch 23.920), train_loss = 1.06548827, grad/param norm = 2.0024e-01, time/batch = 18.2103s	
14281/29850 (epoch 23.921), train_loss = 0.99231348, grad/param norm = 2.4135e-01, time/batch = 15.7875s	
14282/29850 (epoch 23.923), train_loss = 1.07245533, grad/param norm = 2.1218e-01, time/batch = 17.7063s	
14283/29850 (epoch 23.925), train_loss = 1.13225103, grad/param norm = 2.2282e-01, time/batch = 15.5464s	
14284/29850 (epoch 23.926), train_loss = 1.15419577, grad/param norm = 2.4182e-01, time/batch = 17.5267s	
14285/29850 (epoch 23.928), train_loss = 1.03869078, grad/param norm = 2.1130e-01, time/batch = 16.8809s	
14286/29850 (epoch 23.930), train_loss = 1.04906486, grad/param norm = 2.0989e-01, time/batch = 16.0405s	
14287/29850 (epoch 23.931), train_loss = 0.97852028, grad/param norm = 1.9669e-01, time/batch = 16.7795s	
14288/29850 (epoch 23.933), train_loss = 1.16355313, grad/param norm = 2.2564e-01, time/batch = 16.1807s	
14289/29850 (epoch 23.935), train_loss = 1.07327842, grad/param norm = 2.1140e-01, time/batch = 15.4048s	
14290/29850 (epoch 23.936), train_loss = 1.05166191, grad/param norm = 2.0856e-01, time/batch = 16.0094s	
14291/29850 (epoch 23.938), train_loss = 0.87908356, grad/param norm = 1.8442e-01, time/batch = 16.5178s	
14292/29850 (epoch 23.940), train_loss = 0.88385731, grad/param norm = 1.8598e-01, time/batch = 19.2062s	
14293/29850 (epoch 23.941), train_loss = 0.92824124, grad/param norm = 2.1524e-01, time/batch = 18.7877s	
14294/29850 (epoch 23.943), train_loss = 0.92701116, grad/param norm = 1.9924e-01, time/batch = 18.9537s	
14295/29850 (epoch 23.945), train_loss = 0.91783125, grad/param norm = 2.0106e-01, time/batch = 18.1190s	
14296/29850 (epoch 23.946), train_loss = 0.85889004, grad/param norm = 2.0505e-01, time/batch = 17.7138s	
14297/29850 (epoch 23.948), train_loss = 1.00159165, grad/param norm = 1.9690e-01, time/batch = 15.5486s	
14298/29850 (epoch 23.950), train_loss = 0.90804154, grad/param norm = 1.7738e-01, time/batch = 17.7147s	
14299/29850 (epoch 23.951), train_loss = 0.84410333, grad/param norm = 1.6699e-01, time/batch = 17.5801s	
14300/29850 (epoch 23.953), train_loss = 0.96301608, grad/param norm = 2.2163e-01, time/batch = 16.6040s	
14301/29850 (epoch 23.955), train_loss = 0.85538260, grad/param norm = 1.7603e-01, time/batch = 18.9627s	
14302/29850 (epoch 23.956), train_loss = 0.83216525, grad/param norm = 1.7053e-01, time/batch = 17.1229s	
14303/29850 (epoch 23.958), train_loss = 0.74090452, grad/param norm = 1.6240e-01, time/batch = 18.1942s	
14304/29850 (epoch 23.960), train_loss = 1.06374542, grad/param norm = 2.1801e-01, time/batch = 17.4517s	
14305/29850 (epoch 23.961), train_loss = 0.86837578, grad/param norm = 2.0597e-01, time/batch = 15.4702s	
14306/29850 (epoch 23.963), train_loss = 0.83517316, grad/param norm = 2.0321e-01, time/batch = 16.1327s	
14307/29850 (epoch 23.965), train_loss = 0.89739023, grad/param norm = 1.9530e-01, time/batch = 15.2435s	
14308/29850 (epoch 23.966), train_loss = 0.83177509, grad/param norm = 1.8789e-01, time/batch = 15.8755s	
14309/29850 (epoch 23.968), train_loss = 0.89571556, grad/param norm = 2.0473e-01, time/batch = 18.2117s	
14310/29850 (epoch 23.970), train_loss = 0.84407655, grad/param norm = 1.9284e-01, time/batch = 16.0176s	
14311/29850 (epoch 23.972), train_loss = 0.87121026, grad/param norm = 1.7230e-01, time/batch = 17.5586s	
14312/29850 (epoch 23.973), train_loss = 0.87558906, grad/param norm = 2.0103e-01, time/batch = 18.2253s	
14313/29850 (epoch 23.975), train_loss = 0.78739334, grad/param norm = 1.6964e-01, time/batch = 15.9910s	
14314/29850 (epoch 23.977), train_loss = 0.90465356, grad/param norm = 1.8263e-01, time/batch = 17.9462s	
14315/29850 (epoch 23.978), train_loss = 0.82391280, grad/param norm = 1.7345e-01, time/batch = 17.8730s	
14316/29850 (epoch 23.980), train_loss = 0.89501799, grad/param norm = 1.8152e-01, time/batch = 14.7562s	
14317/29850 (epoch 23.982), train_loss = 0.88402067, grad/param norm = 2.1553e-01, time/batch = 16.3885s	
14318/29850 (epoch 23.983), train_loss = 0.90335584, grad/param norm = 1.7003e-01, time/batch = 17.7994s	
14319/29850 (epoch 23.985), train_loss = 0.97764456, grad/param norm = 1.8718e-01, time/batch = 17.3733s	
14320/29850 (epoch 23.987), train_loss = 0.96637892, grad/param norm = 1.9186e-01, time/batch = 17.6934s	
14321/29850 (epoch 23.988), train_loss = 0.90920057, grad/param norm = 2.0691e-01, time/batch = 16.4353s	
14322/29850 (epoch 23.990), train_loss = 0.95914736, grad/param norm = 1.9355e-01, time/batch = 15.1289s	
14323/29850 (epoch 23.992), train_loss = 0.99189988, grad/param norm = 1.8211e-01, time/batch = 15.5337s	
14324/29850 (epoch 23.993), train_loss = 0.97448993, grad/param norm = 1.9255e-01, time/batch = 18.2987s	
14325/29850 (epoch 23.995), train_loss = 0.98708881, grad/param norm = 1.9118e-01, time/batch = 16.8062s	
14326/29850 (epoch 23.997), train_loss = 1.00958565, grad/param norm = 1.9794e-01, time/batch = 16.8161s	
14327/29850 (epoch 23.998), train_loss = 1.03077390, grad/param norm = 2.0723e-01, time/batch = 17.1379s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
14328/29850 (epoch 24.000), train_loss = 0.86221640, grad/param norm = 1.7983e-01, time/batch = 16.3089s	
14329/29850 (epoch 24.002), train_loss = 1.15105397, grad/param norm = 2.2626e-01, time/batch = 18.3780s	
14330/29850 (epoch 24.003), train_loss = 0.87723922, grad/param norm = 1.9978e-01, time/batch = 17.6450s	
14331/29850 (epoch 24.005), train_loss = 0.97259405, grad/param norm = 1.8359e-01, time/batch = 17.8717s	
14332/29850 (epoch 24.007), train_loss = 1.03233055, grad/param norm = 2.0800e-01, time/batch = 17.4007s	
14333/29850 (epoch 24.008), train_loss = 1.20806601, grad/param norm = 2.2709e-01, time/batch = 18.2132s	
14334/29850 (epoch 24.010), train_loss = 0.89085704, grad/param norm = 2.1047e-01, time/batch = 19.3860s	
14335/29850 (epoch 24.012), train_loss = 0.95581283, grad/param norm = 1.7749e-01, time/batch = 10.7079s	
14336/29850 (epoch 24.013), train_loss = 1.03234957, grad/param norm = 2.3704e-01, time/batch = 0.6873s	
14337/29850 (epoch 24.015), train_loss = 1.01730565, grad/param norm = 1.9463e-01, time/batch = 0.6837s	
14338/29850 (epoch 24.017), train_loss = 0.99065027, grad/param norm = 2.1852e-01, time/batch = 0.6686s	
14339/29850 (epoch 24.018), train_loss = 1.12832411, grad/param norm = 2.4522e-01, time/batch = 0.6574s	
14340/29850 (epoch 24.020), train_loss = 0.96064198, grad/param norm = 1.9429e-01, time/batch = 0.6573s	
14341/29850 (epoch 24.022), train_loss = 1.07270903, grad/param norm = 2.1020e-01, time/batch = 0.6691s	
14342/29850 (epoch 24.023), train_loss = 1.05124139, grad/param norm = 2.0592e-01, time/batch = 0.6668s	
14343/29850 (epoch 24.025), train_loss = 0.94730119, grad/param norm = 1.7924e-01, time/batch = 0.9508s	
14344/29850 (epoch 24.027), train_loss = 0.78319808, grad/param norm = 1.6649e-01, time/batch = 0.9667s	
14345/29850 (epoch 24.028), train_loss = 0.92674579, grad/param norm = 1.6471e-01, time/batch = 0.9619s	
14346/29850 (epoch 24.030), train_loss = 0.96271069, grad/param norm = 2.0075e-01, time/batch = 0.9815s	
14347/29850 (epoch 24.032), train_loss = 1.03442343, grad/param norm = 1.9563e-01, time/batch = 0.9743s	
14348/29850 (epoch 24.034), train_loss = 0.88173832, grad/param norm = 1.6209e-01, time/batch = 1.6643s	
14349/29850 (epoch 24.035), train_loss = 0.80968317, grad/param norm = 1.7498e-01, time/batch = 1.8434s	
14350/29850 (epoch 24.037), train_loss = 0.97705705, grad/param norm = 2.0522e-01, time/batch = 3.3099s	
14351/29850 (epoch 24.039), train_loss = 0.84827076, grad/param norm = 1.5928e-01, time/batch = 17.3852s	
14352/29850 (epoch 24.040), train_loss = 0.88461999, grad/param norm = 1.8293e-01, time/batch = 17.7959s	
14353/29850 (epoch 24.042), train_loss = 0.90047587, grad/param norm = 2.1004e-01, time/batch = 18.4503s	
14354/29850 (epoch 24.044), train_loss = 0.92724630, grad/param norm = 1.8090e-01, time/batch = 15.9741s	
14355/29850 (epoch 24.045), train_loss = 1.02090265, grad/param norm = 1.9863e-01, time/batch = 17.5478s	
14356/29850 (epoch 24.047), train_loss = 0.86713621, grad/param norm = 1.9965e-01, time/batch = 15.4797s	
14357/29850 (epoch 24.049), train_loss = 0.98768526, grad/param norm = 1.8093e-01, time/batch = 17.7864s	
14358/29850 (epoch 24.050), train_loss = 0.86959442, grad/param norm = 1.9064e-01, time/batch = 17.4621s	
14359/29850 (epoch 24.052), train_loss = 1.07259853, grad/param norm = 2.5381e-01, time/batch = 16.3606s	
14360/29850 (epoch 24.054), train_loss = 0.96746082, grad/param norm = 2.0159e-01, time/batch = 17.4360s	
14361/29850 (epoch 24.055), train_loss = 0.93893557, grad/param norm = 1.8735e-01, time/batch = 17.6357s	
14362/29850 (epoch 24.057), train_loss = 1.02844059, grad/param norm = 1.8373e-01, time/batch = 16.7251s	
14363/29850 (epoch 24.059), train_loss = 1.00985628, grad/param norm = 2.0264e-01, time/batch = 16.0549s	
14364/29850 (epoch 24.060), train_loss = 0.98298357, grad/param norm = 2.1222e-01, time/batch = 17.3771s	
14365/29850 (epoch 24.062), train_loss = 1.10099588, grad/param norm = 2.3513e-01, time/batch = 17.1567s	
14366/29850 (epoch 24.064), train_loss = 1.04556107, grad/param norm = 1.9981e-01, time/batch = 18.2062s	
14367/29850 (epoch 24.065), train_loss = 0.89152850, grad/param norm = 1.9120e-01, time/batch = 15.1851s	
14368/29850 (epoch 24.067), train_loss = 1.02304882, grad/param norm = 1.9336e-01, time/batch = 18.3777s	
14369/29850 (epoch 24.069), train_loss = 0.97684318, grad/param norm = 1.8459e-01, time/batch = 17.8728s	
14370/29850 (epoch 24.070), train_loss = 1.03255244, grad/param norm = 1.8812e-01, time/batch = 16.2116s	
14371/29850 (epoch 24.072), train_loss = 1.01824789, grad/param norm = 2.3522e-01, time/batch = 16.9577s	
14372/29850 (epoch 24.074), train_loss = 1.04317941, grad/param norm = 1.8050e-01, time/batch = 16.3914s	
14373/29850 (epoch 24.075), train_loss = 0.90524531, grad/param norm = 2.0422e-01, time/batch = 18.5392s	
14374/29850 (epoch 24.077), train_loss = 1.03923439, grad/param norm = 2.2786e-01, time/batch = 16.1868s	
14375/29850 (epoch 24.079), train_loss = 1.24273387, grad/param norm = 3.4666e-01, time/batch = 19.0450s	
14376/29850 (epoch 24.080), train_loss = 1.18822871, grad/param norm = 2.4566e-01, time/batch = 17.8838s	
14377/29850 (epoch 24.082), train_loss = 1.05529535, grad/param norm = 2.1915e-01, time/batch = 15.6318s	
14378/29850 (epoch 24.084), train_loss = 1.11653634, grad/param norm = 2.1992e-01, time/batch = 18.9609s	
14379/29850 (epoch 24.085), train_loss = 1.13705492, grad/param norm = 2.4650e-01, time/batch = 17.9789s	
14380/29850 (epoch 24.087), train_loss = 1.11424654, grad/param norm = 2.1342e-01, time/batch = 16.9513s	
14381/29850 (epoch 24.089), train_loss = 1.02831815, grad/param norm = 1.9679e-01, time/batch = 17.7160s	
14382/29850 (epoch 24.090), train_loss = 1.04833358, grad/param norm = 2.2618e-01, time/batch = 17.6422s	
14383/29850 (epoch 24.092), train_loss = 0.93198284, grad/param norm = 1.7878e-01, time/batch = 17.5718s	
14384/29850 (epoch 24.094), train_loss = 1.13437642, grad/param norm = 2.1161e-01, time/batch = 16.0986s	
14385/29850 (epoch 24.095), train_loss = 1.02303799, grad/param norm = 2.5514e-01, time/batch = 16.8756s	
14386/29850 (epoch 24.097), train_loss = 0.81837388, grad/param norm = 1.6511e-01, time/batch = 16.6387s	
14387/29850 (epoch 24.099), train_loss = 0.83649076, grad/param norm = 1.7513e-01, time/batch = 17.3759s	
14388/29850 (epoch 24.101), train_loss = 1.08650644, grad/param norm = 2.3107e-01, time/batch = 16.7266s	
14389/29850 (epoch 24.102), train_loss = 1.02152097, grad/param norm = 2.0314e-01, time/batch = 17.5377s	
14390/29850 (epoch 24.104), train_loss = 0.97457788, grad/param norm = 2.1088e-01, time/batch = 16.3830s	
14391/29850 (epoch 24.106), train_loss = 1.08763858, grad/param norm = 2.0218e-01, time/batch = 16.2036s	
14392/29850 (epoch 24.107), train_loss = 0.87746845, grad/param norm = 1.7541e-01, time/batch = 15.2284s	
14393/29850 (epoch 24.109), train_loss = 0.95215767, grad/param norm = 2.0350e-01, time/batch = 16.8772s	
14394/29850 (epoch 24.111), train_loss = 1.05327398, grad/param norm = 1.9154e-01, time/batch = 16.8002s	
14395/29850 (epoch 24.112), train_loss = 0.92036741, grad/param norm = 1.9122e-01, time/batch = 16.3937s	
14396/29850 (epoch 24.114), train_loss = 0.94553030, grad/param norm = 2.1036e-01, time/batch = 18.2938s	
14397/29850 (epoch 24.116), train_loss = 0.91044778, grad/param norm = 1.8224e-01, time/batch = 17.5550s	
14398/29850 (epoch 24.117), train_loss = 0.97068535, grad/param norm = 1.9531e-01, time/batch = 15.7990s	
14399/29850 (epoch 24.119), train_loss = 0.94083162, grad/param norm = 1.8257e-01, time/batch = 19.0267s	
14400/29850 (epoch 24.121), train_loss = 0.78014370, grad/param norm = 1.7739e-01, time/batch = 17.3052s	
14401/29850 (epoch 24.122), train_loss = 0.83373171, grad/param norm = 1.5783e-01, time/batch = 17.2755s	
14402/29850 (epoch 24.124), train_loss = 0.90669636, grad/param norm = 1.9018e-01, time/batch = 19.0192s	
14403/29850 (epoch 24.126), train_loss = 0.94404744, grad/param norm = 1.9040e-01, time/batch = 15.7094s	
14404/29850 (epoch 24.127), train_loss = 1.05718827, grad/param norm = 2.4871e-01, time/batch = 17.4461s	
14405/29850 (epoch 24.129), train_loss = 0.92623964, grad/param norm = 2.0404e-01, time/batch = 16.7175s	
14406/29850 (epoch 24.131), train_loss = 0.96884155, grad/param norm = 1.9619e-01, time/batch = 19.0467s	
14407/29850 (epoch 24.132), train_loss = 0.86367088, grad/param norm = 2.0921e-01, time/batch = 15.5961s	
14408/29850 (epoch 24.134), train_loss = 0.99090380, grad/param norm = 2.3768e-01, time/batch = 17.3799s	
14409/29850 (epoch 24.136), train_loss = 1.00538416, grad/param norm = 1.8520e-01, time/batch = 18.1291s	
14410/29850 (epoch 24.137), train_loss = 0.78968953, grad/param norm = 1.7640e-01, time/batch = 15.8734s	
14411/29850 (epoch 24.139), train_loss = 0.95415677, grad/param norm = 2.0232e-01, time/batch = 18.3798s	
14412/29850 (epoch 24.141), train_loss = 0.90231616, grad/param norm = 1.8100e-01, time/batch = 17.1185s	
14413/29850 (epoch 24.142), train_loss = 1.09335982, grad/param norm = 2.1979e-01, time/batch = 16.9009s	
14414/29850 (epoch 24.144), train_loss = 1.26145223, grad/param norm = 2.6480e-01, time/batch = 18.8024s	
14415/29850 (epoch 24.146), train_loss = 1.21552546, grad/param norm = 2.2642e-01, time/batch = 16.0384s	
14416/29850 (epoch 24.147), train_loss = 1.01858054, grad/param norm = 2.0933e-01, time/batch = 17.8895s	
14417/29850 (epoch 24.149), train_loss = 1.04152658, grad/param norm = 2.2937e-01, time/batch = 18.4756s	
14418/29850 (epoch 24.151), train_loss = 1.04693319, grad/param norm = 2.0511e-01, time/batch = 20.4955s	
14419/29850 (epoch 24.152), train_loss = 0.93717145, grad/param norm = 1.8654e-01, time/batch = 31.1287s	
14420/29850 (epoch 24.154), train_loss = 0.89404442, grad/param norm = 1.8804e-01, time/batch = 17.0451s	
14421/29850 (epoch 24.156), train_loss = 0.92505505, grad/param norm = 1.8402e-01, time/batch = 15.9685s	
14422/29850 (epoch 24.157), train_loss = 1.01135878, grad/param norm = 2.0038e-01, time/batch = 18.1296s	
14423/29850 (epoch 24.159), train_loss = 0.94906802, grad/param norm = 1.8539e-01, time/batch = 16.4698s	
14424/29850 (epoch 24.161), train_loss = 1.02640872, grad/param norm = 2.1133e-01, time/batch = 18.1175s	
14425/29850 (epoch 24.162), train_loss = 1.14887197, grad/param norm = 2.1337e-01, time/batch = 14.9705s	
14426/29850 (epoch 24.164), train_loss = 0.99369834, grad/param norm = 2.0569e-01, time/batch = 16.6899s	
14427/29850 (epoch 24.166), train_loss = 0.89837098, grad/param norm = 1.6950e-01, time/batch = 19.3801s	
14428/29850 (epoch 24.168), train_loss = 0.83688549, grad/param norm = 1.8624e-01, time/batch = 16.2220s	
14429/29850 (epoch 24.169), train_loss = 1.14474098, grad/param norm = 2.3133e-01, time/batch = 18.3894s	
14430/29850 (epoch 24.171), train_loss = 1.04560733, grad/param norm = 1.9794e-01, time/batch = 17.1369s	
14431/29850 (epoch 24.173), train_loss = 0.89478944, grad/param norm = 2.0198e-01, time/batch = 17.7082s	
14432/29850 (epoch 24.174), train_loss = 1.02083446, grad/param norm = 2.2895e-01, time/batch = 17.8759s	
14433/29850 (epoch 24.176), train_loss = 0.99149545, grad/param norm = 1.9396e-01, time/batch = 18.2233s	
14434/29850 (epoch 24.178), train_loss = 1.03402352, grad/param norm = 1.9979e-01, time/batch = 17.6264s	
14435/29850 (epoch 24.179), train_loss = 0.83741649, grad/param norm = 1.7217e-01, time/batch = 15.6075s	
14436/29850 (epoch 24.181), train_loss = 0.98206498, grad/param norm = 1.9613e-01, time/batch = 18.8626s	
14437/29850 (epoch 24.183), train_loss = 0.98727579, grad/param norm = 1.9960e-01, time/batch = 16.9009s	
14438/29850 (epoch 24.184), train_loss = 1.02111817, grad/param norm = 2.0238e-01, time/batch = 17.7994s	
14439/29850 (epoch 24.186), train_loss = 0.98268154, grad/param norm = 2.0230e-01, time/batch = 17.2143s	
14440/29850 (epoch 24.188), train_loss = 1.10513635, grad/param norm = 2.2609e-01, time/batch = 15.2792s	
14441/29850 (epoch 24.189), train_loss = 1.12793553, grad/param norm = 2.3770e-01, time/batch = 18.3039s	
14442/29850 (epoch 24.191), train_loss = 1.07248385, grad/param norm = 2.2124e-01, time/batch = 16.2715s	
14443/29850 (epoch 24.193), train_loss = 0.97508429, grad/param norm = 1.9578e-01, time/batch = 16.2219s	
14444/29850 (epoch 24.194), train_loss = 1.03306562, grad/param norm = 1.9863e-01, time/batch = 18.3813s	
14445/29850 (epoch 24.196), train_loss = 0.98081149, grad/param norm = 2.3408e-01, time/batch = 16.3776s	
14446/29850 (epoch 24.198), train_loss = 0.97240370, grad/param norm = 1.9260e-01, time/batch = 15.4957s	
14447/29850 (epoch 24.199), train_loss = 1.19832109, grad/param norm = 2.1726e-01, time/batch = 16.5623s	
14448/29850 (epoch 24.201), train_loss = 0.92045644, grad/param norm = 2.0738e-01, time/batch = 17.3111s	
14449/29850 (epoch 24.203), train_loss = 0.78902796, grad/param norm = 2.2457e-01, time/batch = 17.1300s	
14450/29850 (epoch 24.204), train_loss = 1.02352422, grad/param norm = 2.3317e-01, time/batch = 16.9885s	
14451/29850 (epoch 24.206), train_loss = 0.86323221, grad/param norm = 1.8833e-01, time/batch = 18.8605s	
14452/29850 (epoch 24.208), train_loss = 1.13125598, grad/param norm = 2.1332e-01, time/batch = 17.3614s	
14453/29850 (epoch 24.209), train_loss = 0.84461515, grad/param norm = 1.7891e-01, time/batch = 15.9851s	
14454/29850 (epoch 24.211), train_loss = 0.93684134, grad/param norm = 1.9866e-01, time/batch = 17.3960s	
14455/29850 (epoch 24.213), train_loss = 1.05282073, grad/param norm = 2.0168e-01, time/batch = 16.8129s	
14456/29850 (epoch 24.214), train_loss = 0.86052276, grad/param norm = 1.6020e-01, time/batch = 16.2167s	
14457/29850 (epoch 24.216), train_loss = 0.93376727, grad/param norm = 2.1442e-01, time/batch = 18.5436s	
14458/29850 (epoch 24.218), train_loss = 1.06027514, grad/param norm = 2.0869e-01, time/batch = 15.3702s	
14459/29850 (epoch 24.219), train_loss = 1.05899351, grad/param norm = 2.1063e-01, time/batch = 17.2130s	
14460/29850 (epoch 24.221), train_loss = 0.97848449, grad/param norm = 1.9186e-01, time/batch = 15.2872s	
14461/29850 (epoch 24.223), train_loss = 0.89478793, grad/param norm = 2.1294e-01, time/batch = 18.5527s	
14462/29850 (epoch 24.224), train_loss = 0.85794501, grad/param norm = 2.0024e-01, time/batch = 16.7166s	
14463/29850 (epoch 24.226), train_loss = 0.88499180, grad/param norm = 1.6956e-01, time/batch = 15.4651s	
14464/29850 (epoch 24.228), train_loss = 0.96538886, grad/param norm = 1.8409e-01, time/batch = 17.9791s	
14465/29850 (epoch 24.229), train_loss = 0.81061956, grad/param norm = 1.5371e-01, time/batch = 17.3686s	
14466/29850 (epoch 24.231), train_loss = 0.98535414, grad/param norm = 1.8590e-01, time/batch = 16.1956s	
14467/29850 (epoch 24.233), train_loss = 0.95035016, grad/param norm = 2.2292e-01, time/batch = 16.4685s	
14468/29850 (epoch 24.235), train_loss = 0.86803533, grad/param norm = 1.7845e-01, time/batch = 16.8966s	
14469/29850 (epoch 24.236), train_loss = 1.09125350, grad/param norm = 2.2611e-01, time/batch = 18.6233s	
14470/29850 (epoch 24.238), train_loss = 0.87005707, grad/param norm = 1.9212e-01, time/batch = 17.4568s	
14471/29850 (epoch 24.240), train_loss = 0.83952851, grad/param norm = 1.8962e-01, time/batch = 15.3833s	
14472/29850 (epoch 24.241), train_loss = 1.02950454, grad/param norm = 2.1982e-01, time/batch = 17.3079s	
14473/29850 (epoch 24.243), train_loss = 1.00387974, grad/param norm = 1.9420e-01, time/batch = 18.3656s	
14474/29850 (epoch 24.245), train_loss = 0.91751253, grad/param norm = 2.0623e-01, time/batch = 17.5322s	
14475/29850 (epoch 24.246), train_loss = 0.85163290, grad/param norm = 1.6291e-01, time/batch = 17.6350s	
14476/29850 (epoch 24.248), train_loss = 0.84602124, grad/param norm = 1.7975e-01, time/batch = 19.1926s	
14477/29850 (epoch 24.250), train_loss = 0.93317620, grad/param norm = 1.8433e-01, time/batch = 15.5142s	
14478/29850 (epoch 24.251), train_loss = 0.83481881, grad/param norm = 1.9440e-01, time/batch = 14.9485s	
14479/29850 (epoch 24.253), train_loss = 0.77082575, grad/param norm = 1.9982e-01, time/batch = 15.7040s	
14480/29850 (epoch 24.255), train_loss = 0.89640160, grad/param norm = 1.9025e-01, time/batch = 14.3842s	
14481/29850 (epoch 24.256), train_loss = 1.00916738, grad/param norm = 1.9766e-01, time/batch = 14.7892s	
14482/29850 (epoch 24.258), train_loss = 0.98479678, grad/param norm = 2.0639e-01, time/batch = 14.5241s	
14483/29850 (epoch 24.260), train_loss = 0.94442078, grad/param norm = 1.9094e-01, time/batch = 15.0880s	
14484/29850 (epoch 24.261), train_loss = 0.87025160, grad/param norm = 1.9088e-01, time/batch = 18.5142s	
14485/29850 (epoch 24.263), train_loss = 0.87220598, grad/param norm = 1.8296e-01, time/batch = 18.3766s	
14486/29850 (epoch 24.265), train_loss = 0.94458694, grad/param norm = 2.2047e-01, time/batch = 16.8928s	
14487/29850 (epoch 24.266), train_loss = 0.94288702, grad/param norm = 1.7765e-01, time/batch = 15.5280s	
14488/29850 (epoch 24.268), train_loss = 0.89932061, grad/param norm = 1.7034e-01, time/batch = 15.8535s	
14489/29850 (epoch 24.270), train_loss = 0.89352694, grad/param norm = 1.8794e-01, time/batch = 15.8822s	
14490/29850 (epoch 24.271), train_loss = 1.01079129, grad/param norm = 2.0365e-01, time/batch = 17.5485s	
14491/29850 (epoch 24.273), train_loss = 0.83032495, grad/param norm = 1.8786e-01, time/batch = 17.9438s	
14492/29850 (epoch 24.275), train_loss = 0.82497176, grad/param norm = 2.0530e-01, time/batch = 16.1329s	
14493/29850 (epoch 24.276), train_loss = 0.85051614, grad/param norm = 1.7887e-01, time/batch = 18.4595s	
14494/29850 (epoch 24.278), train_loss = 0.90165442, grad/param norm = 1.8227e-01, time/batch = 17.3820s	
14495/29850 (epoch 24.280), train_loss = 1.08623094, grad/param norm = 2.1950e-01, time/batch = 17.6176s	
14496/29850 (epoch 24.281), train_loss = 1.00606187, grad/param norm = 2.2417e-01, time/batch = 17.9658s	
14497/29850 (epoch 24.283), train_loss = 1.12875374, grad/param norm = 2.7618e-01, time/batch = 16.2881s	
14498/29850 (epoch 24.285), train_loss = 0.97382426, grad/param norm = 2.0041e-01, time/batch = 17.7933s	
14499/29850 (epoch 24.286), train_loss = 1.06029592, grad/param norm = 2.1017e-01, time/batch = 16.4479s	
14500/29850 (epoch 24.288), train_loss = 1.11057709, grad/param norm = 2.8774e-01, time/batch = 17.6337s	
14501/29850 (epoch 24.290), train_loss = 1.01644182, grad/param norm = 2.2081e-01, time/batch = 18.1300s	
14502/29850 (epoch 24.291), train_loss = 1.17737421, grad/param norm = 2.0474e-01, time/batch = 16.1338s	
14503/29850 (epoch 24.293), train_loss = 1.05757702, grad/param norm = 2.0859e-01, time/batch = 17.8154s	
14504/29850 (epoch 24.295), train_loss = 1.16893899, grad/param norm = 2.4566e-01, time/batch = 18.2238s	
14505/29850 (epoch 24.296), train_loss = 0.88792000, grad/param norm = 1.8981e-01, time/batch = 17.2981s	
14506/29850 (epoch 24.298), train_loss = 0.76147343, grad/param norm = 1.7974e-01, time/batch = 17.5445s	
14507/29850 (epoch 24.300), train_loss = 0.83353570, grad/param norm = 1.7500e-01, time/batch = 15.5270s	
14508/29850 (epoch 24.302), train_loss = 0.83532997, grad/param norm = 1.8767e-01, time/batch = 17.2965s	
14509/29850 (epoch 24.303), train_loss = 0.90363228, grad/param norm = 1.8657e-01, time/batch = 16.1350s	
14510/29850 (epoch 24.305), train_loss = 1.00434795, grad/param norm = 1.8403e-01, time/batch = 14.9109s	
14511/29850 (epoch 24.307), train_loss = 1.06264710, grad/param norm = 1.9110e-01, time/batch = 15.0300s	
14512/29850 (epoch 24.308), train_loss = 0.89439881, grad/param norm = 2.0114e-01, time/batch = 14.7354s	
14513/29850 (epoch 24.310), train_loss = 0.99939189, grad/param norm = 2.1049e-01, time/batch = 16.0376s	
14514/29850 (epoch 24.312), train_loss = 1.04712032, grad/param norm = 1.8406e-01, time/batch = 17.8011s	
14515/29850 (epoch 24.313), train_loss = 0.98364212, grad/param norm = 2.1298e-01, time/batch = 18.3900s	
14516/29850 (epoch 24.315), train_loss = 0.99369711, grad/param norm = 2.0580e-01, time/batch = 17.1184s	
14517/29850 (epoch 24.317), train_loss = 0.98650191, grad/param norm = 2.1939e-01, time/batch = 17.8003s	
14518/29850 (epoch 24.318), train_loss = 0.96154299, grad/param norm = 1.9765e-01, time/batch = 18.4611s	
14519/29850 (epoch 24.320), train_loss = 0.90949332, grad/param norm = 1.8484e-01, time/batch = 18.1947s	
14520/29850 (epoch 24.322), train_loss = 1.11951462, grad/param norm = 2.1789e-01, time/batch = 17.4643s	
14521/29850 (epoch 24.323), train_loss = 1.02758689, grad/param norm = 2.2847e-01, time/batch = 15.4547s	
14522/29850 (epoch 24.325), train_loss = 1.07791852, grad/param norm = 2.1659e-01, time/batch = 18.9636s	
14523/29850 (epoch 24.327), train_loss = 1.18521494, grad/param norm = 2.4342e-01, time/batch = 16.1014s	
14524/29850 (epoch 24.328), train_loss = 1.12046917, grad/param norm = 2.4276e-01, time/batch = 17.8091s	
14525/29850 (epoch 24.330), train_loss = 1.04239272, grad/param norm = 1.9196e-01, time/batch = 17.0457s	
14526/29850 (epoch 24.332), train_loss = 0.94813247, grad/param norm = 1.9704e-01, time/batch = 16.7898s	
14527/29850 (epoch 24.333), train_loss = 1.05614527, grad/param norm = 2.0103e-01, time/batch = 17.4637s	
14528/29850 (epoch 24.335), train_loss = 1.11549288, grad/param norm = 2.2150e-01, time/batch = 17.3771s	
14529/29850 (epoch 24.337), train_loss = 0.99720543, grad/param norm = 1.8882e-01, time/batch = 17.1244s	
14530/29850 (epoch 24.338), train_loss = 1.00791964, grad/param norm = 1.9354e-01, time/batch = 15.2292s	
14531/29850 (epoch 24.340), train_loss = 0.88858320, grad/param norm = 1.8155e-01, time/batch = 17.3747s	
14532/29850 (epoch 24.342), train_loss = 1.00403266, grad/param norm = 2.3521e-01, time/batch = 16.7249s	
14533/29850 (epoch 24.343), train_loss = 1.01006460, grad/param norm = 2.3691e-01, time/batch = 16.4389s	
14534/29850 (epoch 24.345), train_loss = 1.04228533, grad/param norm = 2.0713e-01, time/batch = 19.6096s	
14535/29850 (epoch 24.347), train_loss = 1.10309622, grad/param norm = 2.1329e-01, time/batch = 16.8648s	
14536/29850 (epoch 24.348), train_loss = 0.94649714, grad/param norm = 2.0215e-01, time/batch = 17.6931s	
14537/29850 (epoch 24.350), train_loss = 1.08339686, grad/param norm = 2.6834e-01, time/batch = 17.6194s	
14538/29850 (epoch 24.352), train_loss = 0.92950505, grad/param norm = 1.7982e-01, time/batch = 17.3869s	
14539/29850 (epoch 24.353), train_loss = 1.05070875, grad/param norm = 2.0451e-01, time/batch = 19.4590s	
14540/29850 (epoch 24.355), train_loss = 0.91953894, grad/param norm = 2.0743e-01, time/batch = 16.8432s	
14541/29850 (epoch 24.357), train_loss = 1.08398763, grad/param norm = 1.9536e-01, time/batch = 16.9667s	
14542/29850 (epoch 24.358), train_loss = 0.88610737, grad/param norm = 1.8562e-01, time/batch = 15.9600s	
14543/29850 (epoch 24.360), train_loss = 0.95670693, grad/param norm = 1.9801e-01, time/batch = 18.7141s	
14544/29850 (epoch 24.362), train_loss = 0.98197514, grad/param norm = 2.0214e-01, time/batch = 17.6917s	
14545/29850 (epoch 24.363), train_loss = 1.02598170, grad/param norm = 2.1607e-01, time/batch = 16.7318s	
14546/29850 (epoch 24.365), train_loss = 1.14794708, grad/param norm = 2.1495e-01, time/batch = 16.0621s	
14547/29850 (epoch 24.367), train_loss = 0.91885438, grad/param norm = 2.1169e-01, time/batch = 17.2212s	
14548/29850 (epoch 24.369), train_loss = 0.84970940, grad/param norm = 1.8791e-01, time/batch = 19.0466s	
14549/29850 (epoch 24.370), train_loss = 0.80053870, grad/param norm = 1.8542e-01, time/batch = 16.3748s	
14550/29850 (epoch 24.372), train_loss = 1.08966772, grad/param norm = 2.2041e-01, time/batch = 19.1994s	
14551/29850 (epoch 24.374), train_loss = 1.03773478, grad/param norm = 2.1670e-01, time/batch = 16.8848s	
14552/29850 (epoch 24.375), train_loss = 0.98184038, grad/param norm = 1.9511e-01, time/batch = 17.0995s	
14553/29850 (epoch 24.377), train_loss = 0.94545783, grad/param norm = 2.2276e-01, time/batch = 18.7188s	
14554/29850 (epoch 24.379), train_loss = 1.09652654, grad/param norm = 2.3021e-01, time/batch = 17.8703s	
14555/29850 (epoch 24.380), train_loss = 1.05249239, grad/param norm = 1.9893e-01, time/batch = 16.8968s	
14556/29850 (epoch 24.382), train_loss = 1.03802676, grad/param norm = 2.3301e-01, time/batch = 18.8585s	
14557/29850 (epoch 24.384), train_loss = 1.05232624, grad/param norm = 2.1086e-01, time/batch = 18.2787s	
14558/29850 (epoch 24.385), train_loss = 1.00843338, grad/param norm = 2.1126e-01, time/batch = 16.0328s	
14559/29850 (epoch 24.387), train_loss = 1.03036189, grad/param norm = 2.2110e-01, time/batch = 17.1599s	
14560/29850 (epoch 24.389), train_loss = 1.15088581, grad/param norm = 2.4030e-01, time/batch = 14.5739s	
14561/29850 (epoch 24.390), train_loss = 1.05898804, grad/param norm = 2.0226e-01, time/batch = 15.9727s	
14562/29850 (epoch 24.392), train_loss = 0.95935963, grad/param norm = 1.9258e-01, time/batch = 16.4655s	
14563/29850 (epoch 24.394), train_loss = 1.08074283, grad/param norm = 2.1077e-01, time/batch = 15.6970s	
14564/29850 (epoch 24.395), train_loss = 0.95688724, grad/param norm = 1.9992e-01, time/batch = 18.1096s	
14565/29850 (epoch 24.397), train_loss = 0.88319292, grad/param norm = 2.1865e-01, time/batch = 17.4727s	
14566/29850 (epoch 24.399), train_loss = 0.90007752, grad/param norm = 1.8271e-01, time/batch = 18.1350s	
14567/29850 (epoch 24.400), train_loss = 1.28001775, grad/param norm = 2.2180e-01, time/batch = 17.7227s	
14568/29850 (epoch 24.402), train_loss = 1.17257997, grad/param norm = 2.0291e-01, time/batch = 15.3013s	
14569/29850 (epoch 24.404), train_loss = 1.03331635, grad/param norm = 1.9437e-01, time/batch = 17.9584s	
14570/29850 (epoch 24.405), train_loss = 0.91870648, grad/param norm = 2.1987e-01, time/batch = 18.1432s	
14571/29850 (epoch 24.407), train_loss = 0.91780404, grad/param norm = 2.1141e-01, time/batch = 18.3670s	
14572/29850 (epoch 24.409), train_loss = 1.04998225, grad/param norm = 2.2315e-01, time/batch = 16.5470s	
14573/29850 (epoch 24.410), train_loss = 1.15086550, grad/param norm = 2.4238e-01, time/batch = 18.1934s	
14574/29850 (epoch 24.412), train_loss = 1.10942550, grad/param norm = 2.1479e-01, time/batch = 18.7153s	
14575/29850 (epoch 24.414), train_loss = 1.00635444, grad/param norm = 2.2435e-01, time/batch = 16.7857s	
14576/29850 (epoch 24.415), train_loss = 1.00373652, grad/param norm = 2.0705e-01, time/batch = 17.8901s	
14577/29850 (epoch 24.417), train_loss = 1.14294494, grad/param norm = 2.2749e-01, time/batch = 15.5428s	
14578/29850 (epoch 24.419), train_loss = 0.98306079, grad/param norm = 2.0851e-01, time/batch = 16.7731s	
14579/29850 (epoch 24.420), train_loss = 0.98928831, grad/param norm = 1.9834e-01, time/batch = 16.9732s	
14580/29850 (epoch 24.422), train_loss = 0.99057883, grad/param norm = 1.8620e-01, time/batch = 17.6156s	
14581/29850 (epoch 24.424), train_loss = 0.93084844, grad/param norm = 1.9376e-01, time/batch = 18.1205s	
14582/29850 (epoch 24.425), train_loss = 1.10208424, grad/param norm = 2.0170e-01, time/batch = 18.6078s	
14583/29850 (epoch 24.427), train_loss = 0.82041335, grad/param norm = 1.6888e-01, time/batch = 16.7825s	
14584/29850 (epoch 24.429), train_loss = 0.87076008, grad/param norm = 1.9003e-01, time/batch = 18.3798s	
14585/29850 (epoch 24.430), train_loss = 0.83589869, grad/param norm = 1.7500e-01, time/batch = 16.8745s	
14586/29850 (epoch 24.432), train_loss = 0.96984379, grad/param norm = 2.7851e-01, time/batch = 17.4772s	
14587/29850 (epoch 24.434), train_loss = 0.86641972, grad/param norm = 1.7871e-01, time/batch = 20.0389s	
14588/29850 (epoch 24.436), train_loss = 0.98685838, grad/param norm = 2.1141e-01, time/batch = 16.8733s	
14589/29850 (epoch 24.437), train_loss = 1.04316678, grad/param norm = 1.8533e-01, time/batch = 16.9476s	
14590/29850 (epoch 24.439), train_loss = 1.02843697, grad/param norm = 2.0634e-01, time/batch = 18.8060s	
14591/29850 (epoch 24.441), train_loss = 1.00434658, grad/param norm = 2.0369e-01, time/batch = 18.6139s	
14592/29850 (epoch 24.442), train_loss = 0.97798573, grad/param norm = 2.0007e-01, time/batch = 16.9234s	
14593/29850 (epoch 24.444), train_loss = 1.02873413, grad/param norm = 2.0493e-01, time/batch = 15.5618s	
14594/29850 (epoch 24.446), train_loss = 1.05532379, grad/param norm = 2.1091e-01, time/batch = 16.8892s	
14595/29850 (epoch 24.447), train_loss = 1.06314382, grad/param norm = 2.0819e-01, time/batch = 17.0454s	
14596/29850 (epoch 24.449), train_loss = 1.01285290, grad/param norm = 2.1195e-01, time/batch = 17.4565s	
14597/29850 (epoch 24.451), train_loss = 0.82505884, grad/param norm = 1.9059e-01, time/batch = 16.0270s	
14598/29850 (epoch 24.452), train_loss = 0.73805609, grad/param norm = 1.6637e-01, time/batch = 19.5905s	
14599/29850 (epoch 24.454), train_loss = 0.85183229, grad/param norm = 1.7715e-01, time/batch = 17.7007s	
14600/29850 (epoch 24.456), train_loss = 1.02304263, grad/param norm = 2.0087e-01, time/batch = 18.6292s	
14601/29850 (epoch 24.457), train_loss = 1.05619983, grad/param norm = 3.2093e-01, time/batch = 17.5333s	
14602/29850 (epoch 24.459), train_loss = 1.16682984, grad/param norm = 2.2775e-01, time/batch = 16.8829s	
14603/29850 (epoch 24.461), train_loss = 1.12974100, grad/param norm = 1.9596e-01, time/batch = 16.3928s	
14604/29850 (epoch 24.462), train_loss = 1.11484519, grad/param norm = 2.1328e-01, time/batch = 18.7801s	
14605/29850 (epoch 24.464), train_loss = 1.06017584, grad/param norm = 2.1755e-01, time/batch = 18.3766s	
14606/29850 (epoch 24.466), train_loss = 0.85862227, grad/param norm = 1.8758e-01, time/batch = 18.7163s	
14607/29850 (epoch 24.467), train_loss = 0.98923254, grad/param norm = 2.2605e-01, time/batch = 17.4719s	
14608/29850 (epoch 24.469), train_loss = 0.97195987, grad/param norm = 2.0766e-01, time/batch = 18.4705s	
14609/29850 (epoch 24.471), train_loss = 0.97334041, grad/param norm = 2.2536e-01, time/batch = 16.4456s	
14610/29850 (epoch 24.472), train_loss = 0.93395343, grad/param norm = 1.9791e-01, time/batch = 17.7273s	
14611/29850 (epoch 24.474), train_loss = 1.08874202, grad/param norm = 2.0805e-01, time/batch = 16.4799s	
14612/29850 (epoch 24.476), train_loss = 1.00216440, grad/param norm = 1.9142e-01, time/batch = 16.9670s	
14613/29850 (epoch 24.477), train_loss = 1.02677387, grad/param norm = 2.2101e-01, time/batch = 15.7054s	
14614/29850 (epoch 24.479), train_loss = 1.17131933, grad/param norm = 2.1527e-01, time/batch = 16.6342s	
14615/29850 (epoch 24.481), train_loss = 0.95253757, grad/param norm = 1.9034e-01, time/batch = 18.5239s	
14616/29850 (epoch 24.482), train_loss = 0.90721786, grad/param norm = 1.7338e-01, time/batch = 17.2004s	
14617/29850 (epoch 24.484), train_loss = 0.94893793, grad/param norm = 2.1028e-01, time/batch = 19.0299s	
14618/29850 (epoch 24.486), train_loss = 1.01185530, grad/param norm = 2.0254e-01, time/batch = 16.8901s	
14619/29850 (epoch 24.487), train_loss = 0.99234016, grad/param norm = 1.9280e-01, time/batch = 16.3646s	
14620/29850 (epoch 24.489), train_loss = 0.97722471, grad/param norm = 1.9412e-01, time/batch = 18.5183s	
14621/29850 (epoch 24.491), train_loss = 0.89194410, grad/param norm = 1.8485e-01, time/batch = 17.3833s	
14622/29850 (epoch 24.492), train_loss = 0.97299622, grad/param norm = 2.0529e-01, time/batch = 17.3760s	
14623/29850 (epoch 24.494), train_loss = 1.06581914, grad/param norm = 1.9311e-01, time/batch = 16.6412s	
14624/29850 (epoch 24.496), train_loss = 1.17139913, grad/param norm = 2.0908e-01, time/batch = 17.7058s	
14625/29850 (epoch 24.497), train_loss = 1.04283425, grad/param norm = 1.8245e-01, time/batch = 18.4637s	
14626/29850 (epoch 24.499), train_loss = 1.00311185, grad/param norm = 1.9440e-01, time/batch = 27.7138s	
14627/29850 (epoch 24.501), train_loss = 0.92284614, grad/param norm = 2.0609e-01, time/batch = 18.7253s	
14628/29850 (epoch 24.503), train_loss = 0.98991428, grad/param norm = 1.8790e-01, time/batch = 15.5634s	
14629/29850 (epoch 24.504), train_loss = 1.23639292, grad/param norm = 2.1553e-01, time/batch = 17.4570s	
14630/29850 (epoch 24.506), train_loss = 1.16461913, grad/param norm = 2.1502e-01, time/batch = 18.6389s	
14631/29850 (epoch 24.508), train_loss = 1.01931038, grad/param norm = 2.0272e-01, time/batch = 17.7715s	
14632/29850 (epoch 24.509), train_loss = 0.80629964, grad/param norm = 1.7705e-01, time/batch = 16.7127s	
14633/29850 (epoch 24.511), train_loss = 1.01303479, grad/param norm = 1.9186e-01, time/batch = 18.2835s	
14634/29850 (epoch 24.513), train_loss = 1.03377855, grad/param norm = 2.3276e-01, time/batch = 15.6237s	
14635/29850 (epoch 24.514), train_loss = 0.90944825, grad/param norm = 2.1128e-01, time/batch = 17.2743s	
14636/29850 (epoch 24.516), train_loss = 0.94789667, grad/param norm = 1.6936e-01, time/batch = 18.8637s	
14637/29850 (epoch 24.518), train_loss = 0.81674270, grad/param norm = 1.9467e-01, time/batch = 14.6765s	
14638/29850 (epoch 24.519), train_loss = 0.83554397, grad/param norm = 1.7285e-01, time/batch = 18.4625s	
14639/29850 (epoch 24.521), train_loss = 0.75889523, grad/param norm = 1.6272e-01, time/batch = 16.8704s	
14640/29850 (epoch 24.523), train_loss = 0.83583530, grad/param norm = 1.6953e-01, time/batch = 16.7256s	
14641/29850 (epoch 24.524), train_loss = 0.89963961, grad/param norm = 2.1176e-01, time/batch = 19.5301s	
14642/29850 (epoch 24.526), train_loss = 0.99538293, grad/param norm = 2.0253e-01, time/batch = 17.9391s	
14643/29850 (epoch 24.528), train_loss = 1.09397943, grad/param norm = 2.2953e-01, time/batch = 17.6902s	
14644/29850 (epoch 24.529), train_loss = 1.01969899, grad/param norm = 2.0514e-01, time/batch = 15.8799s	
14645/29850 (epoch 24.531), train_loss = 0.96935999, grad/param norm = 2.3600e-01, time/batch = 17.4746s	
14646/29850 (epoch 24.533), train_loss = 0.94970499, grad/param norm = 2.0437e-01, time/batch = 16.1545s	
14647/29850 (epoch 24.534), train_loss = 1.02156056, grad/param norm = 2.0280e-01, time/batch = 15.5359s	
14648/29850 (epoch 24.536), train_loss = 0.92714335, grad/param norm = 1.9723e-01, time/batch = 15.6251s	
14649/29850 (epoch 24.538), train_loss = 1.09610699, grad/param norm = 2.2115e-01, time/batch = 17.3725s	
14650/29850 (epoch 24.539), train_loss = 1.15176006, grad/param norm = 2.2248e-01, time/batch = 18.7039s	
14651/29850 (epoch 24.541), train_loss = 0.76216036, grad/param norm = 1.8507e-01, time/batch = 17.6418s	
14652/29850 (epoch 24.543), train_loss = 0.98346605, grad/param norm = 2.0323e-01, time/batch = 18.1322s	
14653/29850 (epoch 24.544), train_loss = 1.04492240, grad/param norm = 1.9831e-01, time/batch = 16.8872s	
14654/29850 (epoch 24.546), train_loss = 1.07462048, grad/param norm = 2.1333e-01, time/batch = 18.7955s	
14655/29850 (epoch 24.548), train_loss = 0.84912364, grad/param norm = 1.7732e-01, time/batch = 19.0547s	
14656/29850 (epoch 24.549), train_loss = 0.95726603, grad/param norm = 1.9712e-01, time/batch = 17.2016s	
14657/29850 (epoch 24.551), train_loss = 0.84719237, grad/param norm = 1.7219e-01, time/batch = 17.7871s	
14658/29850 (epoch 24.553), train_loss = 0.97429411, grad/param norm = 1.9808e-01, time/batch = 18.7906s	
14659/29850 (epoch 24.554), train_loss = 0.83243862, grad/param norm = 1.7248e-01, time/batch = 18.5284s	
14660/29850 (epoch 24.556), train_loss = 0.88015764, grad/param norm = 1.9908e-01, time/batch = 16.4439s	
14661/29850 (epoch 24.558), train_loss = 0.88776509, grad/param norm = 2.1717e-01, time/batch = 18.1335s	
14662/29850 (epoch 24.559), train_loss = 0.97451805, grad/param norm = 2.4743e-01, time/batch = 16.9565s	
14663/29850 (epoch 24.561), train_loss = 1.03872763, grad/param norm = 2.1837e-01, time/batch = 16.5470s	
14664/29850 (epoch 24.563), train_loss = 1.01950218, grad/param norm = 2.1499e-01, time/batch = 15.2415s	
14665/29850 (epoch 24.564), train_loss = 0.94314707, grad/param norm = 2.0705e-01, time/batch = 15.7964s	
14666/29850 (epoch 24.566), train_loss = 1.01515104, grad/param norm = 2.1054e-01, time/batch = 18.2197s	
14667/29850 (epoch 24.568), train_loss = 1.06134773, grad/param norm = 2.1188e-01, time/batch = 16.1857s	
14668/29850 (epoch 24.570), train_loss = 1.03049699, grad/param norm = 2.3358e-01, time/batch = 16.8755s	
14669/29850 (epoch 24.571), train_loss = 1.07321558, grad/param norm = 2.1304e-01, time/batch = 17.2934s	
14670/29850 (epoch 24.573), train_loss = 1.15054138, grad/param norm = 2.5115e-01, time/batch = 15.2280s	
14671/29850 (epoch 24.575), train_loss = 1.11912178, grad/param norm = 2.2586e-01, time/batch = 17.5449s	
14672/29850 (epoch 24.576), train_loss = 1.07907877, grad/param norm = 2.3462e-01, time/batch = 18.5517s	
14673/29850 (epoch 24.578), train_loss = 0.93456756, grad/param norm = 2.1155e-01, time/batch = 19.0228s	
14674/29850 (epoch 24.580), train_loss = 1.10857465, grad/param norm = 2.0319e-01, time/batch = 18.2972s	
14675/29850 (epoch 24.581), train_loss = 0.90745622, grad/param norm = 1.9544e-01, time/batch = 18.9469s	
14676/29850 (epoch 24.583), train_loss = 1.00140476, grad/param norm = 2.0529e-01, time/batch = 19.7835s	
14677/29850 (epoch 24.585), train_loss = 0.99812698, grad/param norm = 1.8575e-01, time/batch = 16.7487s	
14678/29850 (epoch 24.586), train_loss = 1.00441358, grad/param norm = 2.0128e-01, time/batch = 17.1566s	
14679/29850 (epoch 24.588), train_loss = 0.94491166, grad/param norm = 2.0015e-01, time/batch = 18.1305s	
14680/29850 (epoch 24.590), train_loss = 0.95426236, grad/param norm = 1.8272e-01, time/batch = 17.9681s	
14681/29850 (epoch 24.591), train_loss = 0.95305004, grad/param norm = 2.0261e-01, time/batch = 19.0233s	
14682/29850 (epoch 24.593), train_loss = 0.91285075, grad/param norm = 1.8878e-01, time/batch = 16.1344s	
14683/29850 (epoch 24.595), train_loss = 0.86188296, grad/param norm = 1.6074e-01, time/batch = 17.7737s	
14684/29850 (epoch 24.596), train_loss = 0.85755145, grad/param norm = 1.9862e-01, time/batch = 17.9610s	
14685/29850 (epoch 24.598), train_loss = 0.97746592, grad/param norm = 1.9930e-01, time/batch = 18.3855s	
14686/29850 (epoch 24.600), train_loss = 1.00887457, grad/param norm = 1.9323e-01, time/batch = 14.8804s	
14687/29850 (epoch 24.601), train_loss = 0.86524371, grad/param norm = 1.7580e-01, time/batch = 16.2185s	
14688/29850 (epoch 24.603), train_loss = 0.91746631, grad/param norm = 1.8377e-01, time/batch = 18.1324s	
14689/29850 (epoch 24.605), train_loss = 0.94665833, grad/param norm = 1.9401e-01, time/batch = 17.8792s	
14690/29850 (epoch 24.606), train_loss = 0.72168837, grad/param norm = 1.6144e-01, time/batch = 15.8736s	
14691/29850 (epoch 24.608), train_loss = 0.89626462, grad/param norm = 1.8885e-01, time/batch = 17.8830s	
14692/29850 (epoch 24.610), train_loss = 0.96633148, grad/param norm = 2.0625e-01, time/batch = 17.8882s	
14693/29850 (epoch 24.611), train_loss = 0.90408973, grad/param norm = 2.0605e-01, time/batch = 17.1272s	
14694/29850 (epoch 24.613), train_loss = 0.74127819, grad/param norm = 1.7102e-01, time/batch = 15.7967s	
14695/29850 (epoch 24.615), train_loss = 0.86613142, grad/param norm = 1.8205e-01, time/batch = 18.1432s	
14696/29850 (epoch 24.616), train_loss = 0.86344365, grad/param norm = 2.1235e-01, time/batch = 18.4675s	
14697/29850 (epoch 24.618), train_loss = 0.94243589, grad/param norm = 2.1528e-01, time/batch = 16.4690s	
14698/29850 (epoch 24.620), train_loss = 0.99316758, grad/param norm = 2.0622e-01, time/batch = 18.2116s	
14699/29850 (epoch 24.621), train_loss = 1.11990801, grad/param norm = 2.2130e-01, time/batch = 17.3061s	
14700/29850 (epoch 24.623), train_loss = 1.03177215, grad/param norm = 2.0080e-01, time/batch = 18.6961s	
14701/29850 (epoch 24.625), train_loss = 1.00383525, grad/param norm = 2.5255e-01, time/batch = 17.3735s	
14702/29850 (epoch 24.626), train_loss = 1.02859833, grad/param norm = 2.2328e-01, time/batch = 18.1256s	
14703/29850 (epoch 24.628), train_loss = 0.89644440, grad/param norm = 1.9091e-01, time/batch = 19.2947s	
14704/29850 (epoch 24.630), train_loss = 0.98513312, grad/param norm = 2.1164e-01, time/batch = 15.2792s	
14705/29850 (epoch 24.631), train_loss = 0.95469414, grad/param norm = 1.8396e-01, time/batch = 18.4663s	
14706/29850 (epoch 24.633), train_loss = 1.03957589, grad/param norm = 2.3399e-01, time/batch = 16.6992s	
14707/29850 (epoch 24.635), train_loss = 0.95153689, grad/param norm = 2.5604e-01, time/batch = 16.0364s	
14708/29850 (epoch 24.637), train_loss = 0.89552345, grad/param norm = 2.0130e-01, time/batch = 17.7619s	
14709/29850 (epoch 24.638), train_loss = 0.99783273, grad/param norm = 2.0668e-01, time/batch = 18.3090s	
14710/29850 (epoch 24.640), train_loss = 1.12397561, grad/param norm = 2.3260e-01, time/batch = 18.3000s	
14711/29850 (epoch 24.642), train_loss = 0.88077756, grad/param norm = 1.7025e-01, time/batch = 15.9546s	
14712/29850 (epoch 24.643), train_loss = 0.89913667, grad/param norm = 2.1284e-01, time/batch = 18.1300s	
14713/29850 (epoch 24.645), train_loss = 0.94058102, grad/param norm = 2.0420e-01, time/batch = 17.6211s	
14714/29850 (epoch 24.647), train_loss = 1.10442055, grad/param norm = 2.2331e-01, time/batch = 16.9715s	
14715/29850 (epoch 24.648), train_loss = 0.86059246, grad/param norm = 1.7648e-01, time/batch = 17.5585s	
14716/29850 (epoch 24.650), train_loss = 0.99134958, grad/param norm = 2.0329e-01, time/batch = 17.1355s	
14717/29850 (epoch 24.652), train_loss = 0.99004113, grad/param norm = 2.1781e-01, time/batch = 16.3819s	
14718/29850 (epoch 24.653), train_loss = 1.10521390, grad/param norm = 2.6357e-01, time/batch = 16.5366s	
14719/29850 (epoch 24.655), train_loss = 0.97304990, grad/param norm = 1.8896e-01, time/batch = 18.7260s	
14720/29850 (epoch 24.657), train_loss = 0.93557069, grad/param norm = 1.9995e-01, time/batch = 17.6120s	
14721/29850 (epoch 24.658), train_loss = 1.06684998, grad/param norm = 2.1775e-01, time/batch = 17.3761s	
14722/29850 (epoch 24.660), train_loss = 0.99422047, grad/param norm = 2.2115e-01, time/batch = 19.7678s	
14723/29850 (epoch 24.662), train_loss = 1.05003313, grad/param norm = 2.0740e-01, time/batch = 17.6222s	
14724/29850 (epoch 24.663), train_loss = 1.16780551, grad/param norm = 2.1673e-01, time/batch = 18.2915s	
14725/29850 (epoch 24.665), train_loss = 1.11627163, grad/param norm = 2.3134e-01, time/batch = 16.5402s	
14726/29850 (epoch 24.667), train_loss = 1.04194752, grad/param norm = 2.2906e-01, time/batch = 17.9449s	
14727/29850 (epoch 24.668), train_loss = 0.95816831, grad/param norm = 1.9587e-01, time/batch = 19.7866s	
14728/29850 (epoch 24.670), train_loss = 1.11010601, grad/param norm = 2.6702e-01, time/batch = 15.9353s	
14729/29850 (epoch 24.672), train_loss = 1.11966579, grad/param norm = 2.3965e-01, time/batch = 18.0603s	
14730/29850 (epoch 24.673), train_loss = 1.03320550, grad/param norm = 2.0706e-01, time/batch = 17.2929s	
14731/29850 (epoch 24.675), train_loss = 0.87282258, grad/param norm = 1.9565e-01, time/batch = 17.6993s	
14732/29850 (epoch 24.677), train_loss = 0.94721866, grad/param norm = 2.1276e-01, time/batch = 19.8437s	
14733/29850 (epoch 24.678), train_loss = 0.95847045, grad/param norm = 2.0227e-01, time/batch = 16.6236s	
14734/29850 (epoch 24.680), train_loss = 0.98669954, grad/param norm = 2.0469e-01, time/batch = 17.9512s	
14735/29850 (epoch 24.682), train_loss = 0.99242326, grad/param norm = 2.2453e-01, time/batch = 17.6449s	
14736/29850 (epoch 24.683), train_loss = 1.12836908, grad/param norm = 2.4116e-01, time/batch = 18.8779s	
14737/29850 (epoch 24.685), train_loss = 1.14682523, grad/param norm = 2.1557e-01, time/batch = 17.3804s	
14738/29850 (epoch 24.687), train_loss = 1.03254007, grad/param norm = 2.2844e-01, time/batch = 17.7135s	
14739/29850 (epoch 24.688), train_loss = 0.88595428, grad/param norm = 2.0439e-01, time/batch = 17.2750s	
14740/29850 (epoch 24.690), train_loss = 0.87652844, grad/param norm = 1.9836e-01, time/batch = 17.6431s	
14741/29850 (epoch 24.692), train_loss = 1.07907221, grad/param norm = 2.0288e-01, time/batch = 17.2748s	
14742/29850 (epoch 24.693), train_loss = 0.97220165, grad/param norm = 1.9972e-01, time/batch = 18.7853s	
14743/29850 (epoch 24.695), train_loss = 0.85353358, grad/param norm = 1.7599e-01, time/batch = 16.4495s	
14744/29850 (epoch 24.697), train_loss = 0.96992973, grad/param norm = 2.0581e-01, time/batch = 18.5343s	
14745/29850 (epoch 24.698), train_loss = 1.12207355, grad/param norm = 2.1475e-01, time/batch = 16.9435s	
14746/29850 (epoch 24.700), train_loss = 1.07545428, grad/param norm = 2.2988e-01, time/batch = 17.8952s	
14747/29850 (epoch 24.702), train_loss = 0.96692278, grad/param norm = 2.0324e-01, time/batch = 19.2851s	
14748/29850 (epoch 24.704), train_loss = 0.84980368, grad/param norm = 1.6738e-01, time/batch = 15.5430s	
14749/29850 (epoch 24.705), train_loss = 0.99427170, grad/param norm = 1.9650e-01, time/batch = 19.1293s	
14750/29850 (epoch 24.707), train_loss = 0.89509010, grad/param norm = 1.8333e-01, time/batch = 16.1474s	
14751/29850 (epoch 24.709), train_loss = 0.97729529, grad/param norm = 1.9338e-01, time/batch = 18.5317s	
14752/29850 (epoch 24.710), train_loss = 0.91901639, grad/param norm = 1.9180e-01, time/batch = 15.5125s	
14753/29850 (epoch 24.712), train_loss = 1.00385172, grad/param norm = 1.7781e-01, time/batch = 17.6341s	
14754/29850 (epoch 24.714), train_loss = 1.05674709, grad/param norm = 2.0987e-01, time/batch = 15.7499s	
14755/29850 (epoch 24.715), train_loss = 1.01882821, grad/param norm = 2.2281e-01, time/batch = 16.6055s	
14756/29850 (epoch 24.717), train_loss = 0.77033946, grad/param norm = 1.9474e-01, time/batch = 17.9635s	
14757/29850 (epoch 24.719), train_loss = 0.93487534, grad/param norm = 2.1439e-01, time/batch = 16.2590s	
14758/29850 (epoch 24.720), train_loss = 0.96990616, grad/param norm = 1.8488e-01, time/batch = 17.5483s	
14759/29850 (epoch 24.722), train_loss = 0.91352522, grad/param norm = 1.7971e-01, time/batch = 19.6102s	
14760/29850 (epoch 24.724), train_loss = 1.03716494, grad/param norm = 2.0994e-01, time/batch = 18.8783s	
14761/29850 (epoch 24.725), train_loss = 0.82544982, grad/param norm = 1.7965e-01, time/batch = 17.3795s	
14762/29850 (epoch 24.727), train_loss = 0.89903913, grad/param norm = 2.2288e-01, time/batch = 16.0787s	
14763/29850 (epoch 24.729), train_loss = 0.83251473, grad/param norm = 1.6683e-01, time/batch = 16.9716s	
14764/29850 (epoch 24.730), train_loss = 0.79921296, grad/param norm = 1.7349e-01, time/batch = 16.6450s	
14765/29850 (epoch 24.732), train_loss = 1.06388279, grad/param norm = 1.8731e-01, time/batch = 16.5503s	
14766/29850 (epoch 24.734), train_loss = 1.16363355, grad/param norm = 2.4172e-01, time/batch = 18.8085s	
14767/29850 (epoch 24.735), train_loss = 0.91495437, grad/param norm = 2.2101e-01, time/batch = 17.1177s	
14768/29850 (epoch 24.737), train_loss = 0.87920562, grad/param norm = 1.8763e-01, time/batch = 17.7824s	
14769/29850 (epoch 24.739), train_loss = 0.76247421, grad/param norm = 1.8140e-01, time/batch = 17.5374s	
14770/29850 (epoch 24.740), train_loss = 0.84241685, grad/param norm = 1.9074e-01, time/batch = 17.8175s	
14771/29850 (epoch 24.742), train_loss = 0.77675459, grad/param norm = 1.7213e-01, time/batch = 18.7196s	
14772/29850 (epoch 24.744), train_loss = 0.90578661, grad/param norm = 2.1160e-01, time/batch = 15.9384s	
14773/29850 (epoch 24.745), train_loss = 0.88895219, grad/param norm = 2.1513e-01, time/batch = 17.9431s	
14774/29850 (epoch 24.747), train_loss = 0.95403559, grad/param norm = 2.0642e-01, time/batch = 16.9713s	
14775/29850 (epoch 24.749), train_loss = 0.84172134, grad/param norm = 2.0668e-01, time/batch = 17.2165s	
14776/29850 (epoch 24.750), train_loss = 0.80626187, grad/param norm = 2.0071e-01, time/batch = 19.6197s	
14777/29850 (epoch 24.752), train_loss = 0.73284743, grad/param norm = 1.7729e-01, time/batch = 17.7237s	
14778/29850 (epoch 24.754), train_loss = 0.81931304, grad/param norm = 1.8499e-01, time/batch = 15.1039s	
14779/29850 (epoch 24.755), train_loss = 0.81180845, grad/param norm = 1.7575e-01, time/batch = 16.3680s	
14780/29850 (epoch 24.757), train_loss = 0.88242935, grad/param norm = 1.9455e-01, time/batch = 16.7032s	
14781/29850 (epoch 24.759), train_loss = 0.89246225, grad/param norm = 1.9210e-01, time/batch = 15.5319s	
14782/29850 (epoch 24.760), train_loss = 0.86296130, grad/param norm = 1.9033e-01, time/batch = 17.7098s	
14783/29850 (epoch 24.762), train_loss = 0.83488684, grad/param norm = 2.8826e-01, time/batch = 16.1452s	
14784/29850 (epoch 24.764), train_loss = 0.79472284, grad/param norm = 2.1660e-01, time/batch = 18.4768s	
14785/29850 (epoch 24.765), train_loss = 0.93350274, grad/param norm = 2.0941e-01, time/batch = 17.0457s	
14786/29850 (epoch 24.767), train_loss = 0.92773447, grad/param norm = 1.9905e-01, time/batch = 16.9561s	
14787/29850 (epoch 24.769), train_loss = 0.92369469, grad/param norm = 1.8467e-01, time/batch = 16.2884s	
14788/29850 (epoch 24.771), train_loss = 0.98631243, grad/param norm = 2.1095e-01, time/batch = 17.7916s	
14789/29850 (epoch 24.772), train_loss = 0.98508079, grad/param norm = 2.2099e-01, time/batch = 17.8696s	
14790/29850 (epoch 24.774), train_loss = 0.89048145, grad/param norm = 1.9383e-01, time/batch = 17.2244s	
14791/29850 (epoch 24.776), train_loss = 0.90901772, grad/param norm = 1.8954e-01, time/batch = 19.3706s	
14792/29850 (epoch 24.777), train_loss = 1.01134771, grad/param norm = 2.1395e-01, time/batch = 19.2225s	
14793/29850 (epoch 24.779), train_loss = 0.84292124, grad/param norm = 1.9006e-01, time/batch = 18.3459s	
14794/29850 (epoch 24.781), train_loss = 0.96081179, grad/param norm = 1.9705e-01, time/batch = 18.5569s	
14795/29850 (epoch 24.782), train_loss = 1.00011180, grad/param norm = 2.0832e-01, time/batch = 17.4659s	
14796/29850 (epoch 24.784), train_loss = 0.82632385, grad/param norm = 2.1696e-01, time/batch = 16.7125s	
14797/29850 (epoch 24.786), train_loss = 0.91355217, grad/param norm = 1.8168e-01, time/batch = 16.3507s	
14798/29850 (epoch 24.787), train_loss = 0.80631170, grad/param norm = 2.2613e-01, time/batch = 17.4360s	
14799/29850 (epoch 24.789), train_loss = 0.78184447, grad/param norm = 1.8285e-01, time/batch = 17.6939s	
14800/29850 (epoch 24.791), train_loss = 0.89256530, grad/param norm = 2.3757e-01, time/batch = 16.9693s	
14801/29850 (epoch 24.792), train_loss = 0.99832877, grad/param norm = 2.0939e-01, time/batch = 18.0333s	
14802/29850 (epoch 24.794), train_loss = 0.99586703, grad/param norm = 2.0502e-01, time/batch = 15.6998s	
14803/29850 (epoch 24.796), train_loss = 0.82284740, grad/param norm = 1.7937e-01, time/batch = 17.3012s	
14804/29850 (epoch 24.797), train_loss = 0.76975557, grad/param norm = 1.7578e-01, time/batch = 17.5417s	
14805/29850 (epoch 24.799), train_loss = 0.78665955, grad/param norm = 1.6388e-01, time/batch = 18.3009s	
14806/29850 (epoch 24.801), train_loss = 0.88454687, grad/param norm = 1.9574e-01, time/batch = 17.5306s	
14807/29850 (epoch 24.802), train_loss = 0.77143877, grad/param norm = 1.9692e-01, time/batch = 17.5415s	
14808/29850 (epoch 24.804), train_loss = 0.80463008, grad/param norm = 1.7736e-01, time/batch = 19.0485s	
14809/29850 (epoch 24.806), train_loss = 0.79653601, grad/param norm = 1.9286e-01, time/batch = 16.3286s	
14810/29850 (epoch 24.807), train_loss = 0.77544547, grad/param norm = 1.6488e-01, time/batch = 16.1061s	
14811/29850 (epoch 24.809), train_loss = 0.81896388, grad/param norm = 2.0316e-01, time/batch = 17.7133s	
14812/29850 (epoch 24.811), train_loss = 0.97257629, grad/param norm = 2.0799e-01, time/batch = 18.3785s	
14813/29850 (epoch 24.812), train_loss = 0.96632724, grad/param norm = 2.4032e-01, time/batch = 17.6906s	
14814/29850 (epoch 24.814), train_loss = 1.03128896, grad/param norm = 2.1072e-01, time/batch = 17.1098s	
14815/29850 (epoch 24.816), train_loss = 1.00502733, grad/param norm = 1.7504e-01, time/batch = 16.6160s	
14816/29850 (epoch 24.817), train_loss = 0.97524268, grad/param norm = 2.1943e-01, time/batch = 16.8013s	
14817/29850 (epoch 24.819), train_loss = 0.80980171, grad/param norm = 2.0943e-01, time/batch = 19.0230s	
14818/29850 (epoch 24.821), train_loss = 1.03627428, grad/param norm = 2.4817e-01, time/batch = 17.7945s	
14819/29850 (epoch 24.822), train_loss = 1.03027117, grad/param norm = 2.0333e-01, time/batch = 16.6249s	
14820/29850 (epoch 24.824), train_loss = 0.93694941, grad/param norm = 1.9240e-01, time/batch = 17.9615s	
14821/29850 (epoch 24.826), train_loss = 0.85544625, grad/param norm = 1.8969e-01, time/batch = 18.9794s	
14822/29850 (epoch 24.827), train_loss = 0.80131325, grad/param norm = 2.0165e-01, time/batch = 19.2976s	
14823/29850 (epoch 24.829), train_loss = 0.96239674, grad/param norm = 2.3762e-01, time/batch = 16.6370s	
14824/29850 (epoch 24.831), train_loss = 1.02714702, grad/param norm = 2.1602e-01, time/batch = 18.3879s	
14825/29850 (epoch 24.832), train_loss = 0.92026646, grad/param norm = 1.8185e-01, time/batch = 17.9687s	
14826/29850 (epoch 24.834), train_loss = 0.72902965, grad/param norm = 1.6817e-01, time/batch = 18.3820s	
14827/29850 (epoch 24.836), train_loss = 0.77755889, grad/param norm = 1.7423e-01, time/batch = 17.7995s	
14828/29850 (epoch 24.838), train_loss = 0.90105812, grad/param norm = 2.0926e-01, time/batch = 16.7926s	
14829/29850 (epoch 24.839), train_loss = 0.80579748, grad/param norm = 1.7433e-01, time/batch = 18.9558s	
14830/29850 (epoch 24.841), train_loss = 0.83777394, grad/param norm = 1.9090e-01, time/batch = 27.7537s	
14831/29850 (epoch 24.843), train_loss = 0.78302274, grad/param norm = 1.8368e-01, time/batch = 17.6340s	
14832/29850 (epoch 24.844), train_loss = 0.85906308, grad/param norm = 2.0156e-01, time/batch = 16.3966s	
14833/29850 (epoch 24.846), train_loss = 0.92346243, grad/param norm = 2.1369e-01, time/batch = 16.7145s	
14834/29850 (epoch 24.848), train_loss = 1.01139036, grad/param norm = 2.5557e-01, time/batch = 18.5503s	
14835/29850 (epoch 24.849), train_loss = 0.87371189, grad/param norm = 2.0163e-01, time/batch = 17.2172s	
14836/29850 (epoch 24.851), train_loss = 1.06452131, grad/param norm = 2.2781e-01, time/batch = 17.8699s	
14837/29850 (epoch 24.853), train_loss = 0.88550189, grad/param norm = 2.0978e-01, time/batch = 18.8609s	
14838/29850 (epoch 24.854), train_loss = 1.08544719, grad/param norm = 2.1730e-01, time/batch = 19.0364s	
14839/29850 (epoch 24.856), train_loss = 1.01423861, grad/param norm = 2.3169e-01, time/batch = 17.8820s	
14840/29850 (epoch 24.858), train_loss = 0.95787189, grad/param norm = 2.2825e-01, time/batch = 18.6921s	
14841/29850 (epoch 24.859), train_loss = 0.81162853, grad/param norm = 1.9572e-01, time/batch = 17.1447s	
14842/29850 (epoch 24.861), train_loss = 1.04991547, grad/param norm = 2.2231e-01, time/batch = 18.8855s	
14843/29850 (epoch 24.863), train_loss = 1.11750693, grad/param norm = 2.3189e-01, time/batch = 15.7586s	
14844/29850 (epoch 24.864), train_loss = 1.05676592, grad/param norm = 2.1828e-01, time/batch = 18.8044s	
14845/29850 (epoch 24.866), train_loss = 0.96765219, grad/param norm = 2.2785e-01, time/batch = 18.8888s	
14846/29850 (epoch 24.868), train_loss = 1.08722592, grad/param norm = 2.1209e-01, time/batch = 16.2128s	
14847/29850 (epoch 24.869), train_loss = 1.00365386, grad/param norm = 2.5527e-01, time/batch = 18.1448s	
14848/29850 (epoch 24.871), train_loss = 1.02863534, grad/param norm = 2.2346e-01, time/batch = 17.3811s	
14849/29850 (epoch 24.873), train_loss = 0.98102640, grad/param norm = 2.1289e-01, time/batch = 17.8005s	
14850/29850 (epoch 24.874), train_loss = 0.96781391, grad/param norm = 1.9534e-01, time/batch = 16.4345s	
14851/29850 (epoch 24.876), train_loss = 0.94952259, grad/param norm = 2.5704e-01, time/batch = 18.6276s	
14852/29850 (epoch 24.878), train_loss = 0.96186960, grad/param norm = 1.9310e-01, time/batch = 18.2017s	
14853/29850 (epoch 24.879), train_loss = 0.98455879, grad/param norm = 2.0932e-01, time/batch = 15.9596s	
14854/29850 (epoch 24.881), train_loss = 1.07119528, grad/param norm = 2.6807e-01, time/batch = 18.3871s	
14855/29850 (epoch 24.883), train_loss = 1.03466911, grad/param norm = 2.0969e-01, time/batch = 19.0370s	
14856/29850 (epoch 24.884), train_loss = 0.83932266, grad/param norm = 2.0675e-01, time/batch = 17.2186s	
14857/29850 (epoch 24.886), train_loss = 1.05590538, grad/param norm = 2.3257e-01, time/batch = 16.8699s	
14858/29850 (epoch 24.888), train_loss = 0.94994060, grad/param norm = 1.9117e-01, time/batch = 16.7979s	
14859/29850 (epoch 24.889), train_loss = 0.88467777, grad/param norm = 1.7758e-01, time/batch = 18.9469s	
14860/29850 (epoch 24.891), train_loss = 0.85646318, grad/param norm = 1.7397e-01, time/batch = 16.3913s	
14861/29850 (epoch 24.893), train_loss = 0.87504938, grad/param norm = 1.8287e-01, time/batch = 16.7296s	
14862/29850 (epoch 24.894), train_loss = 0.91635985, grad/param norm = 2.1517e-01, time/batch = 18.3992s	
14863/29850 (epoch 24.896), train_loss = 0.94662283, grad/param norm = 2.1221e-01, time/batch = 16.9670s	
14864/29850 (epoch 24.898), train_loss = 1.06506346, grad/param norm = 2.2000e-01, time/batch = 19.2027s	
14865/29850 (epoch 24.899), train_loss = 0.82804531, grad/param norm = 1.9788e-01, time/batch = 16.8921s	
14866/29850 (epoch 24.901), train_loss = 1.21884676, grad/param norm = 2.7050e-01, time/batch = 15.0352s	
14867/29850 (epoch 24.903), train_loss = 0.97732047, grad/param norm = 2.9585e-01, time/batch = 18.4421s	
14868/29850 (epoch 24.905), train_loss = 1.18497592, grad/param norm = 2.4054e-01, time/batch = 18.2952s	
14869/29850 (epoch 24.906), train_loss = 1.02185845, grad/param norm = 2.1815e-01, time/batch = 17.7914s	
14870/29850 (epoch 24.908), train_loss = 1.09333655, grad/param norm = 2.0878e-01, time/batch = 16.5378s	
14871/29850 (epoch 24.910), train_loss = 1.00834236, grad/param norm = 1.9646e-01, time/batch = 14.4294s	
14872/29850 (epoch 24.911), train_loss = 1.15619450, grad/param norm = 1.9321e-01, time/batch = 14.7361s	
14873/29850 (epoch 24.913), train_loss = 1.11070734, grad/param norm = 2.1588e-01, time/batch = 16.4258s	
14874/29850 (epoch 24.915), train_loss = 1.09268108, grad/param norm = 2.2827e-01, time/batch = 18.1933s	
14875/29850 (epoch 24.916), train_loss = 1.07273388, grad/param norm = 2.1085e-01, time/batch = 18.7881s	
14876/29850 (epoch 24.918), train_loss = 0.89954466, grad/param norm = 2.1678e-01, time/batch = 17.2106s	
14877/29850 (epoch 24.920), train_loss = 1.05918715, grad/param norm = 1.9973e-01, time/batch = 17.7971s	
14878/29850 (epoch 24.921), train_loss = 0.97814286, grad/param norm = 2.3219e-01, time/batch = 18.4589s	
14879/29850 (epoch 24.923), train_loss = 1.05136808, grad/param norm = 2.1767e-01, time/batch = 19.0462s	
14880/29850 (epoch 24.925), train_loss = 1.12574948, grad/param norm = 2.3288e-01, time/batch = 16.8608s	
14881/29850 (epoch 24.926), train_loss = 1.12200125, grad/param norm = 2.3635e-01, time/batch = 18.0422s	
14882/29850 (epoch 24.928), train_loss = 1.02117196, grad/param norm = 2.1324e-01, time/batch = 16.1426s	
14883/29850 (epoch 24.930), train_loss = 1.02511348, grad/param norm = 2.1547e-01, time/batch = 17.4003s	
14884/29850 (epoch 24.931), train_loss = 0.97031490, grad/param norm = 2.0806e-01, time/batch = 18.0332s	
14885/29850 (epoch 24.933), train_loss = 1.13616662, grad/param norm = 2.0747e-01, time/batch = 19.3871s	
14886/29850 (epoch 24.935), train_loss = 1.07107934, grad/param norm = 2.2436e-01, time/batch = 16.3731s	
14887/29850 (epoch 24.936), train_loss = 1.01488335, grad/param norm = 2.0800e-01, time/batch = 17.1233s	
14888/29850 (epoch 24.938), train_loss = 0.88202954, grad/param norm = 2.0344e-01, time/batch = 19.6289s	
14889/29850 (epoch 24.940), train_loss = 0.85229810, grad/param norm = 1.9323e-01, time/batch = 15.9897s	
14890/29850 (epoch 24.941), train_loss = 0.90817942, grad/param norm = 2.0703e-01, time/batch = 17.6249s	
14891/29850 (epoch 24.943), train_loss = 0.90104027, grad/param norm = 2.0491e-01, time/batch = 16.4471s	
14892/29850 (epoch 24.945), train_loss = 0.90789195, grad/param norm = 2.2221e-01, time/batch = 15.7802s	
14893/29850 (epoch 24.946), train_loss = 0.86194218, grad/param norm = 2.1103e-01, time/batch = 16.3176s	
14894/29850 (epoch 24.948), train_loss = 0.98128471, grad/param norm = 1.9089e-01, time/batch = 15.7963s	
14895/29850 (epoch 24.950), train_loss = 0.88835824, grad/param norm = 1.7657e-01, time/batch = 18.4554s	
14896/29850 (epoch 24.951), train_loss = 0.83138859, grad/param norm = 1.6958e-01, time/batch = 16.9006s	
14897/29850 (epoch 24.953), train_loss = 0.93964094, grad/param norm = 2.2158e-01, time/batch = 16.8873s	
14898/29850 (epoch 24.955), train_loss = 0.83768382, grad/param norm = 1.7313e-01, time/batch = 17.7868s	
14899/29850 (epoch 24.956), train_loss = 0.83313857, grad/param norm = 1.8230e-01, time/batch = 16.1180s	
14900/29850 (epoch 24.958), train_loss = 0.73934636, grad/param norm = 1.6659e-01, time/batch = 16.3021s	
14901/29850 (epoch 24.960), train_loss = 1.05302477, grad/param norm = 2.2073e-01, time/batch = 16.7941s	
14902/29850 (epoch 24.961), train_loss = 0.85486819, grad/param norm = 2.2122e-01, time/batch = 18.6248s	
14903/29850 (epoch 24.963), train_loss = 0.80874855, grad/param norm = 1.7324e-01, time/batch = 17.3755s	
14904/29850 (epoch 24.965), train_loss = 0.90244451, grad/param norm = 2.0781e-01, time/batch = 18.3678s	
14905/29850 (epoch 24.966), train_loss = 0.81073788, grad/param norm = 1.7897e-01, time/batch = 17.6868s	
14906/29850 (epoch 24.968), train_loss = 0.88110611, grad/param norm = 2.0806e-01, time/batch = 18.2225s	
14907/29850 (epoch 24.970), train_loss = 0.84672107, grad/param norm = 2.3595e-01, time/batch = 16.5599s	
14908/29850 (epoch 24.972), train_loss = 0.85653633, grad/param norm = 1.7062e-01, time/batch = 16.6381s	
14909/29850 (epoch 24.973), train_loss = 0.85804668, grad/param norm = 1.8752e-01, time/batch = 18.1086s	
14910/29850 (epoch 24.975), train_loss = 0.76696013, grad/param norm = 1.7174e-01, time/batch = 17.1505s	
14911/29850 (epoch 24.977), train_loss = 0.87968784, grad/param norm = 1.7903e-01, time/batch = 17.3777s	
14912/29850 (epoch 24.978), train_loss = 0.80367441, grad/param norm = 1.7131e-01, time/batch = 16.3876s	
14913/29850 (epoch 24.980), train_loss = 0.87415053, grad/param norm = 1.8756e-01, time/batch = 19.0472s	
14914/29850 (epoch 24.982), train_loss = 0.85420841, grad/param norm = 2.0092e-01, time/batch = 17.5598s	
14915/29850 (epoch 24.983), train_loss = 0.88452806, grad/param norm = 1.7295e-01, time/batch = 20.0742s	
14916/29850 (epoch 24.985), train_loss = 0.98035278, grad/param norm = 2.0091e-01, time/batch = 21.0871s	
14917/29850 (epoch 24.987), train_loss = 0.94487697, grad/param norm = 1.9527e-01, time/batch = 22.1683s	
14918/29850 (epoch 24.988), train_loss = 0.87446362, grad/param norm = 1.7464e-01, time/batch = 23.3876s	
14919/29850 (epoch 24.990), train_loss = 0.94896958, grad/param norm = 1.8843e-01, time/batch = 21.4326s	
14920/29850 (epoch 24.992), train_loss = 0.97898829, grad/param norm = 1.7792e-01, time/batch = 20.9175s	
14921/29850 (epoch 24.993), train_loss = 0.95822190, grad/param norm = 2.0083e-01, time/batch = 23.1270s	
14922/29850 (epoch 24.995), train_loss = 0.99361377, grad/param norm = 2.2139e-01, time/batch = 24.2514s	
14923/29850 (epoch 24.997), train_loss = 0.98750624, grad/param norm = 1.9605e-01, time/batch = 22.6802s	
14924/29850 (epoch 24.998), train_loss = 1.01329268, grad/param norm = 2.0145e-01, time/batch = 20.2106s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
14925/29850 (epoch 25.000), train_loss = 0.84662702, grad/param norm = 1.8161e-01, time/batch = 23.0015s	
14926/29850 (epoch 25.002), train_loss = 1.13227811, grad/param norm = 2.2980e-01, time/batch = 21.0329s	
14927/29850 (epoch 25.003), train_loss = 0.84807453, grad/param norm = 1.9697e-01, time/batch = 22.5037s	
14928/29850 (epoch 25.005), train_loss = 0.96164828, grad/param norm = 2.0558e-01, time/batch = 21.6748s	
14929/29850 (epoch 25.007), train_loss = 1.02404783, grad/param norm = 2.2078e-01, time/batch = 22.4127s	
14930/29850 (epoch 25.008), train_loss = 1.20826609, grad/param norm = 2.3212e-01, time/batch = 20.5093s	
14931/29850 (epoch 25.010), train_loss = 0.90128983, grad/param norm = 2.1013e-01, time/batch = 21.3369s	
14932/29850 (epoch 25.012), train_loss = 0.92184539, grad/param norm = 1.8008e-01, time/batch = 22.6750s	
14933/29850 (epoch 25.013), train_loss = 0.99273917, grad/param norm = 2.1355e-01, time/batch = 28.8519s	
14934/29850 (epoch 25.015), train_loss = 1.00678784, grad/param norm = 1.8584e-01, time/batch = 18.2762s	
14935/29850 (epoch 25.017), train_loss = 0.97204997, grad/param norm = 2.0809e-01, time/batch = 17.5635s	
14936/29850 (epoch 25.018), train_loss = 1.08636559, grad/param norm = 2.2868e-01, time/batch = 18.5540s	
14937/29850 (epoch 25.020), train_loss = 0.94152238, grad/param norm = 2.0361e-01, time/batch = 19.1056s	
14938/29850 (epoch 25.022), train_loss = 1.07083196, grad/param norm = 2.2732e-01, time/batch = 17.0285s	
14939/29850 (epoch 25.023), train_loss = 1.04612743, grad/param norm = 2.0313e-01, time/batch = 16.6358s	
14940/29850 (epoch 25.025), train_loss = 0.96383787, grad/param norm = 1.9498e-01, time/batch = 16.6911s	
14941/29850 (epoch 25.027), train_loss = 0.77378765, grad/param norm = 1.8357e-01, time/batch = 17.9398s	
14942/29850 (epoch 25.028), train_loss = 0.91182412, grad/param norm = 1.7365e-01, time/batch = 15.4725s	
14943/29850 (epoch 25.030), train_loss = 0.96468490, grad/param norm = 2.1005e-01, time/batch = 18.4520s	
14944/29850 (epoch 25.032), train_loss = 1.01314994, grad/param norm = 1.9065e-01, time/batch = 16.8836s	
14945/29850 (epoch 25.034), train_loss = 0.87299521, grad/param norm = 1.7859e-01, time/batch = 15.4284s	
14946/29850 (epoch 25.035), train_loss = 0.79709496, grad/param norm = 1.7512e-01, time/batch = 17.2982s	
14947/29850 (epoch 25.037), train_loss = 0.95245445, grad/param norm = 1.9211e-01, time/batch = 16.0478s	
14948/29850 (epoch 25.039), train_loss = 0.84370737, grad/param norm = 1.7129e-01, time/batch = 17.8088s	
14949/29850 (epoch 25.040), train_loss = 0.87827969, grad/param norm = 1.8526e-01, time/batch = 17.7034s	
14950/29850 (epoch 25.042), train_loss = 0.87188175, grad/param norm = 1.8867e-01, time/batch = 17.3895s	
14951/29850 (epoch 25.044), train_loss = 0.91316306, grad/param norm = 1.7769e-01, time/batch = 18.5454s	
14952/29850 (epoch 25.045), train_loss = 1.01233833, grad/param norm = 1.9189e-01, time/batch = 18.1440s	
14953/29850 (epoch 25.047), train_loss = 0.85903152, grad/param norm = 1.9003e-01, time/batch = 16.9667s	
14954/29850 (epoch 25.049), train_loss = 0.97127663, grad/param norm = 1.8567e-01, time/batch = 16.1024s	
14955/29850 (epoch 25.050), train_loss = 0.86210019, grad/param norm = 2.0371e-01, time/batch = 16.8869s	
14956/29850 (epoch 25.052), train_loss = 1.04800576, grad/param norm = 2.2266e-01, time/batch = 17.1338s	
14957/29850 (epoch 25.054), train_loss = 0.96365161, grad/param norm = 1.9249e-01, time/batch = 17.2161s	
14958/29850 (epoch 25.055), train_loss = 0.92245150, grad/param norm = 2.0095e-01, time/batch = 18.0458s	
14959/29850 (epoch 25.057), train_loss = 1.00059945, grad/param norm = 1.8692e-01, time/batch = 18.3764s	
14960/29850 (epoch 25.059), train_loss = 0.99853636, grad/param norm = 2.0503e-01, time/batch = 18.4691s	
14961/29850 (epoch 25.060), train_loss = 0.96831345, grad/param norm = 2.2195e-01, time/batch = 15.8449s	
14962/29850 (epoch 25.062), train_loss = 1.07527923, grad/param norm = 2.0954e-01, time/batch = 19.1256s	
14963/29850 (epoch 25.064), train_loss = 1.02942255, grad/param norm = 2.1130e-01, time/batch = 17.3015s	
14964/29850 (epoch 25.065), train_loss = 0.87723749, grad/param norm = 2.0599e-01, time/batch = 15.5100s	
14965/29850 (epoch 25.067), train_loss = 1.01424982, grad/param norm = 1.9024e-01, time/batch = 17.9490s	
14966/29850 (epoch 25.069), train_loss = 0.97672059, grad/param norm = 1.9104e-01, time/batch = 14.5934s	
14967/29850 (epoch 25.070), train_loss = 1.01404210, grad/param norm = 1.8726e-01, time/batch = 17.3579s	
14968/29850 (epoch 25.072), train_loss = 0.99226562, grad/param norm = 2.1334e-01, time/batch = 16.7156s	
14969/29850 (epoch 25.074), train_loss = 1.03109605, grad/param norm = 1.9325e-01, time/batch = 18.2955s	
14970/29850 (epoch 25.075), train_loss = 0.88933475, grad/param norm = 1.9667e-01, time/batch = 18.7737s	
14971/29850 (epoch 25.077), train_loss = 1.02006430, grad/param norm = 2.1981e-01, time/batch = 15.6907s	
14972/29850 (epoch 25.079), train_loss = 1.22405183, grad/param norm = 3.6928e-01, time/batch = 15.4352s	
14973/29850 (epoch 25.080), train_loss = 1.17252579, grad/param norm = 2.4672e-01, time/batch = 17.9537s	
14974/29850 (epoch 25.082), train_loss = 1.03530630, grad/param norm = 2.1554e-01, time/batch = 17.6280s	
14975/29850 (epoch 25.084), train_loss = 1.12781677, grad/param norm = 2.3399e-01, time/batch = 16.0525s	
14976/29850 (epoch 25.085), train_loss = 1.12518950, grad/param norm = 2.4857e-01, time/batch = 19.6326s	
14977/29850 (epoch 25.087), train_loss = 1.11768552, grad/param norm = 2.2033e-01, time/batch = 17.7219s	
14978/29850 (epoch 25.089), train_loss = 1.01420465, grad/param norm = 2.1116e-01, time/batch = 16.0379s	
14979/29850 (epoch 25.090), train_loss = 1.03102405, grad/param norm = 1.9785e-01, time/batch = 18.3046s	
14980/29850 (epoch 25.092), train_loss = 0.93748512, grad/param norm = 1.8746e-01, time/batch = 16.4648s	
14981/29850 (epoch 25.094), train_loss = 1.12416313, grad/param norm = 2.1615e-01, time/batch = 18.2135s	
14982/29850 (epoch 25.095), train_loss = 0.98861250, grad/param norm = 2.3634e-01, time/batch = 16.1024s	
14983/29850 (epoch 25.097), train_loss = 0.80723455, grad/param norm = 1.8873e-01, time/batch = 19.0482s	
14984/29850 (epoch 25.099), train_loss = 0.83867428, grad/param norm = 1.9220e-01, time/batch = 15.5037s	
14985/29850 (epoch 25.101), train_loss = 1.07064024, grad/param norm = 2.1666e-01, time/batch = 17.5316s	
14986/29850 (epoch 25.102), train_loss = 1.01062972, grad/param norm = 2.1793e-01, time/batch = 18.2219s	
14987/29850 (epoch 25.104), train_loss = 0.95134332, grad/param norm = 2.0300e-01, time/batch = 17.9544s	
14988/29850 (epoch 25.106), train_loss = 1.06655197, grad/param norm = 2.0545e-01, time/batch = 17.6185s	
14989/29850 (epoch 25.107), train_loss = 0.87258701, grad/param norm = 1.8124e-01, time/batch = 16.0620s	
14990/29850 (epoch 25.109), train_loss = 0.95853133, grad/param norm = 2.0222e-01, time/batch = 17.9756s	
14991/29850 (epoch 25.111), train_loss = 1.04857852, grad/param norm = 1.9254e-01, time/batch = 15.5716s	
14992/29850 (epoch 25.112), train_loss = 0.90989313, grad/param norm = 1.8690e-01, time/batch = 16.1326s	
14993/29850 (epoch 25.114), train_loss = 0.91789355, grad/param norm = 2.0722e-01, time/batch = 16.7157s	
14994/29850 (epoch 25.116), train_loss = 0.89161073, grad/param norm = 1.8545e-01, time/batch = 18.0609s	
14995/29850 (epoch 25.117), train_loss = 0.95355825, grad/param norm = 2.0190e-01, time/batch = 18.2914s	
14996/29850 (epoch 25.119), train_loss = 0.93849804, grad/param norm = 1.7813e-01, time/batch = 16.8833s	
14997/29850 (epoch 25.121), train_loss = 0.75939784, grad/param norm = 1.9168e-01, time/batch = 17.9699s	
14998/29850 (epoch 25.122), train_loss = 0.82651513, grad/param norm = 1.6484e-01, time/batch = 15.5687s	
14999/29850 (epoch 25.124), train_loss = 0.89590608, grad/param norm = 1.9920e-01, time/batch = 14.4780s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch25.13_1.7057.t7	
15000/29850 (epoch 25.126), train_loss = 0.91957468, grad/param norm = 1.9659e-01, time/batch = 16.9703s	
15001/29850 (epoch 25.127), train_loss = 1.58623114, grad/param norm = 3.0156e-01, time/batch = 16.2913s	
15002/29850 (epoch 25.129), train_loss = 0.91895074, grad/param norm = 2.0267e-01, time/batch = 16.7222s	
15003/29850 (epoch 25.131), train_loss = 0.92953199, grad/param norm = 1.8476e-01, time/batch = 18.5507s	
15004/29850 (epoch 25.132), train_loss = 0.84664684, grad/param norm = 1.9092e-01, time/batch = 17.2159s	
15005/29850 (epoch 25.134), train_loss = 0.95797879, grad/param norm = 1.8369e-01, time/batch = 18.0503s	
15006/29850 (epoch 25.136), train_loss = 1.00074043, grad/param norm = 1.9575e-01, time/batch = 17.4458s	
15007/29850 (epoch 25.137), train_loss = 0.79491095, grad/param norm = 1.8098e-01, time/batch = 17.9000s	
15008/29850 (epoch 25.139), train_loss = 0.94745183, grad/param norm = 2.0083e-01, time/batch = 17.1433s	
15009/29850 (epoch 25.141), train_loss = 0.88803478, grad/param norm = 1.9107e-01, time/batch = 16.7950s	
15010/29850 (epoch 25.142), train_loss = 1.09310993, grad/param norm = 2.4248e-01, time/batch = 16.0640s	
15011/29850 (epoch 25.144), train_loss = 1.23729349, grad/param norm = 2.5301e-01, time/batch = 15.6181s	
15012/29850 (epoch 25.146), train_loss = 1.21853816, grad/param norm = 2.4476e-01, time/batch = 17.6905s	
15013/29850 (epoch 25.147), train_loss = 1.02926756, grad/param norm = 2.1376e-01, time/batch = 16.4166s	
15014/29850 (epoch 25.149), train_loss = 1.02084364, grad/param norm = 2.1247e-01, time/batch = 16.8048s	
15015/29850 (epoch 25.151), train_loss = 1.02733078, grad/param norm = 2.1973e-01, time/batch = 18.9549s	
15016/29850 (epoch 25.152), train_loss = 0.93851031, grad/param norm = 1.9655e-01, time/batch = 17.4422s	
15017/29850 (epoch 25.154), train_loss = 0.89480933, grad/param norm = 1.9419e-01, time/batch = 18.4678s	
15018/29850 (epoch 25.156), train_loss = 0.90689253, grad/param norm = 1.8328e-01, time/batch = 17.9619s	
15019/29850 (epoch 25.157), train_loss = 1.00122266, grad/param norm = 1.9557e-01, time/batch = 17.9542s	
15020/29850 (epoch 25.159), train_loss = 0.93910016, grad/param norm = 2.0726e-01, time/batch = 16.4644s	
15021/29850 (epoch 25.161), train_loss = 0.99855372, grad/param norm = 2.2482e-01, time/batch = 18.2932s	
15022/29850 (epoch 25.162), train_loss = 1.12189340, grad/param norm = 2.3649e-01, time/batch = 18.8856s	
15023/29850 (epoch 25.164), train_loss = 0.98969093, grad/param norm = 2.0623e-01, time/batch = 26.7126s	
15024/29850 (epoch 25.166), train_loss = 0.88575230, grad/param norm = 1.8514e-01, time/batch = 26.5099s	
15025/29850 (epoch 25.168), train_loss = 0.82979197, grad/param norm = 1.7930e-01, time/batch = 16.2815s	
15026/29850 (epoch 25.169), train_loss = 1.13776400, grad/param norm = 2.5246e-01, time/batch = 17.2186s	
15027/29850 (epoch 25.171), train_loss = 1.03820457, grad/param norm = 2.0420e-01, time/batch = 16.8921s	
15028/29850 (epoch 25.173), train_loss = 0.88645833, grad/param norm = 2.0952e-01, time/batch = 17.2208s	
15029/29850 (epoch 25.174), train_loss = 1.00047758, grad/param norm = 2.2253e-01, time/batch = 17.2361s	
15030/29850 (epoch 25.176), train_loss = 0.97459148, grad/param norm = 2.0270e-01, time/batch = 17.1458s	
15031/29850 (epoch 25.178), train_loss = 1.02010778, grad/param norm = 2.0539e-01, time/batch = 19.0482s	
15032/29850 (epoch 25.179), train_loss = 0.82759342, grad/param norm = 1.8382e-01, time/batch = 15.2621s	
15033/29850 (epoch 25.181), train_loss = 0.97773749, grad/param norm = 2.0768e-01, time/batch = 17.8550s	
15034/29850 (epoch 25.183), train_loss = 0.98279688, grad/param norm = 1.9628e-01, time/batch = 18.3793s	
15035/29850 (epoch 25.184), train_loss = 1.00736727, grad/param norm = 2.0414e-01, time/batch = 17.2680s	
15036/29850 (epoch 25.186), train_loss = 0.98790376, grad/param norm = 2.2759e-01, time/batch = 18.1120s	
15037/29850 (epoch 25.188), train_loss = 1.08726342, grad/param norm = 2.1768e-01, time/batch = 19.3889s	
15038/29850 (epoch 25.189), train_loss = 1.10382381, grad/param norm = 2.3327e-01, time/batch = 19.0290s	
15039/29850 (epoch 25.191), train_loss = 1.05024101, grad/param norm = 2.0961e-01, time/batch = 15.7665s	
15040/29850 (epoch 25.193), train_loss = 0.95197005, grad/param norm = 1.9241e-01, time/batch = 18.4458s	
15041/29850 (epoch 25.194), train_loss = 1.01596219, grad/param norm = 1.9323e-01, time/batch = 17.4626s	
15042/29850 (epoch 25.196), train_loss = 0.95754769, grad/param norm = 2.1009e-01, time/batch = 16.7974s	
15043/29850 (epoch 25.198), train_loss = 0.96910816, grad/param norm = 2.0180e-01, time/batch = 17.7220s	
15044/29850 (epoch 25.199), train_loss = 1.18921601, grad/param norm = 2.4023e-01, time/batch = 16.9724s	
15045/29850 (epoch 25.201), train_loss = 0.91231752, grad/param norm = 2.0270e-01, time/batch = 17.7593s	
15046/29850 (epoch 25.203), train_loss = 0.75958860, grad/param norm = 2.1163e-01, time/batch = 19.2253s	
15047/29850 (epoch 25.204), train_loss = 0.99400241, grad/param norm = 2.1879e-01, time/batch = 17.4702s	
15048/29850 (epoch 25.206), train_loss = 0.87598082, grad/param norm = 2.0486e-01, time/batch = 18.5431s	
15049/29850 (epoch 25.208), train_loss = 1.11112186, grad/param norm = 2.1475e-01, time/batch = 18.1993s	
15050/29850 (epoch 25.209), train_loss = 0.83915318, grad/param norm = 1.8154e-01, time/batch = 16.7189s	
15051/29850 (epoch 25.211), train_loss = 0.91896376, grad/param norm = 1.8280e-01, time/batch = 17.7130s	
15052/29850 (epoch 25.213), train_loss = 1.04001943, grad/param norm = 2.1961e-01, time/batch = 16.7837s	
15053/29850 (epoch 25.214), train_loss = 0.84489604, grad/param norm = 1.6294e-01, time/batch = 16.6963s	
15054/29850 (epoch 25.216), train_loss = 0.91345750, grad/param norm = 2.2212e-01, time/batch = 18.8852s	
15055/29850 (epoch 25.218), train_loss = 1.05573601, grad/param norm = 2.0322e-01, time/batch = 18.3665s	
15056/29850 (epoch 25.219), train_loss = 1.04386880, grad/param norm = 2.2316e-01, time/batch = 18.0342s	
15057/29850 (epoch 25.221), train_loss = 0.96576216, grad/param norm = 1.8679e-01, time/batch = 16.5640s	
15058/29850 (epoch 25.223), train_loss = 0.87814180, grad/param norm = 2.1485e-01, time/batch = 17.8042s	
15059/29850 (epoch 25.224), train_loss = 0.84147442, grad/param norm = 1.9780e-01, time/batch = 16.8783s	
15060/29850 (epoch 25.226), train_loss = 0.87684551, grad/param norm = 1.8037e-01, time/batch = 17.7016s	
15061/29850 (epoch 25.228), train_loss = 0.95697891, grad/param norm = 1.8463e-01, time/batch = 16.7124s	
15062/29850 (epoch 25.229), train_loss = 0.79675932, grad/param norm = 1.5883e-01, time/batch = 16.0345s	
15063/29850 (epoch 25.231), train_loss = 0.97337163, grad/param norm = 1.8174e-01, time/batch = 14.5677s	
15064/29850 (epoch 25.233), train_loss = 0.93336139, grad/param norm = 2.0150e-01, time/batch = 18.4681s	
15065/29850 (epoch 25.235), train_loss = 0.85869030, grad/param norm = 1.7390e-01, time/batch = 18.7147s	
15066/29850 (epoch 25.236), train_loss = 1.07911228, grad/param norm = 2.3477e-01, time/batch = 15.8734s	
15067/29850 (epoch 25.238), train_loss = 0.86982236, grad/param norm = 1.9088e-01, time/batch = 16.9609s	
15068/29850 (epoch 25.240), train_loss = 0.82989613, grad/param norm = 1.8167e-01, time/batch = 17.9335s	
15069/29850 (epoch 25.241), train_loss = 1.01349561, grad/param norm = 2.3133e-01, time/batch = 17.6054s	
15070/29850 (epoch 25.243), train_loss = 0.98812400, grad/param norm = 1.7696e-01, time/batch = 18.5439s	
15071/29850 (epoch 25.245), train_loss = 0.89588710, grad/param norm = 2.0214e-01, time/batch = 17.4617s	
15072/29850 (epoch 25.246), train_loss = 0.83772659, grad/param norm = 1.7083e-01, time/batch = 18.8050s	
15073/29850 (epoch 25.248), train_loss = 0.83205190, grad/param norm = 1.7691e-01, time/batch = 16.4445s	
15074/29850 (epoch 25.250), train_loss = 0.92666224, grad/param norm = 1.8798e-01, time/batch = 17.8984s	
15075/29850 (epoch 25.251), train_loss = 0.82761343, grad/param norm = 2.0174e-01, time/batch = 15.4469s	
15076/29850 (epoch 25.253), train_loss = 0.76399571, grad/param norm = 2.1813e-01, time/batch = 17.9655s	
15077/29850 (epoch 25.255), train_loss = 0.87509094, grad/param norm = 1.9013e-01, time/batch = 18.2054s	
15078/29850 (epoch 25.256), train_loss = 1.00288149, grad/param norm = 2.0034e-01, time/batch = 17.1199s	
15079/29850 (epoch 25.258), train_loss = 0.96668963, grad/param norm = 2.0964e-01, time/batch = 18.7085s	
15080/29850 (epoch 25.260), train_loss = 0.93531240, grad/param norm = 2.0489e-01, time/batch = 17.2132s	
15081/29850 (epoch 25.261), train_loss = 0.86953742, grad/param norm = 2.1058e-01, time/batch = 18.6340s	
15082/29850 (epoch 25.263), train_loss = 0.87515277, grad/param norm = 1.9797e-01, time/batch = 19.4490s	
15083/29850 (epoch 25.265), train_loss = 0.92277563, grad/param norm = 1.8779e-01, time/batch = 16.7031s	
15084/29850 (epoch 25.266), train_loss = 0.93882402, grad/param norm = 2.1439e-01, time/batch = 18.9289s	
15085/29850 (epoch 25.268), train_loss = 0.88029939, grad/param norm = 1.8142e-01, time/batch = 17.9439s	
15086/29850 (epoch 25.270), train_loss = 0.89636392, grad/param norm = 1.9844e-01, time/batch = 17.7996s	
15087/29850 (epoch 25.271), train_loss = 0.99106700, grad/param norm = 1.8321e-01, time/batch = 17.0391s	
15088/29850 (epoch 25.273), train_loss = 0.83678330, grad/param norm = 2.0434e-01, time/batch = 19.0481s	
15089/29850 (epoch 25.275), train_loss = 0.84317096, grad/param norm = 2.0842e-01, time/batch = 18.0359s	
15090/29850 (epoch 25.276), train_loss = 0.85604186, grad/param norm = 1.9810e-01, time/batch = 16.8508s	
15091/29850 (epoch 25.278), train_loss = 0.89348739, grad/param norm = 1.8432e-01, time/batch = 17.7081s	
15092/29850 (epoch 25.280), train_loss = 1.07850534, grad/param norm = 2.3720e-01, time/batch = 18.0496s	
15093/29850 (epoch 25.281), train_loss = 0.98033933, grad/param norm = 2.2000e-01, time/batch = 16.6152s	
15094/29850 (epoch 25.283), train_loss = 1.08669937, grad/param norm = 2.1987e-01, time/batch = 19.0937s	
15095/29850 (epoch 25.285), train_loss = 0.97086684, grad/param norm = 2.0037e-01, time/batch = 16.1902s	
15096/29850 (epoch 25.286), train_loss = 1.04641786, grad/param norm = 2.2117e-01, time/batch = 17.5312s	
15097/29850 (epoch 25.288), train_loss = 1.07291314, grad/param norm = 2.6351e-01, time/batch = 17.7146s	
15098/29850 (epoch 25.290), train_loss = 0.99812681, grad/param norm = 2.1920e-01, time/batch = 18.1360s	
15099/29850 (epoch 25.291), train_loss = 1.16673877, grad/param norm = 2.1026e-01, time/batch = 18.5524s	
15100/29850 (epoch 25.293), train_loss = 1.04874538, grad/param norm = 2.0690e-01, time/batch = 17.6058s	
15101/29850 (epoch 25.295), train_loss = 1.12644832, grad/param norm = 2.2993e-01, time/batch = 16.9491s	
15102/29850 (epoch 25.296), train_loss = 0.85354209, grad/param norm = 1.8208e-01, time/batch = 17.5630s	
15103/29850 (epoch 25.298), train_loss = 0.75040019, grad/param norm = 1.8925e-01, time/batch = 16.7102s	
15104/29850 (epoch 25.300), train_loss = 0.84597676, grad/param norm = 1.9506e-01, time/batch = 15.9006s	
15105/29850 (epoch 25.302), train_loss = 0.80716243, grad/param norm = 1.8534e-01, time/batch = 16.5655s	
15106/29850 (epoch 25.303), train_loss = 0.88797943, grad/param norm = 1.8346e-01, time/batch = 17.4830s	
15107/29850 (epoch 25.305), train_loss = 0.99759490, grad/param norm = 2.0673e-01, time/batch = 16.5131s	
15108/29850 (epoch 25.307), train_loss = 1.05264451, grad/param norm = 1.9959e-01, time/batch = 15.8694s	
15109/29850 (epoch 25.308), train_loss = 0.86925967, grad/param norm = 1.9151e-01, time/batch = 17.8871s	
15110/29850 (epoch 25.310), train_loss = 0.99818547, grad/param norm = 2.2523e-01, time/batch = 16.7189s	
15111/29850 (epoch 25.312), train_loss = 1.03648706, grad/param norm = 1.8952e-01, time/batch = 18.2315s	
15112/29850 (epoch 25.313), train_loss = 0.96186333, grad/param norm = 2.0198e-01, time/batch = 18.0372s	
15113/29850 (epoch 25.315), train_loss = 0.95983787, grad/param norm = 1.9957e-01, time/batch = 17.4396s	
15114/29850 (epoch 25.317), train_loss = 0.97390737, grad/param norm = 2.2786e-01, time/batch = 17.9498s	
15115/29850 (epoch 25.318), train_loss = 0.92788896, grad/param norm = 2.0779e-01, time/batch = 16.3251s	
15116/29850 (epoch 25.320), train_loss = 0.88429338, grad/param norm = 1.7045e-01, time/batch = 17.6385s	
15117/29850 (epoch 25.322), train_loss = 1.11218687, grad/param norm = 2.1332e-01, time/batch = 17.5427s	
15118/29850 (epoch 25.323), train_loss = 1.00588828, grad/param norm = 2.1723e-01, time/batch = 19.3677s	
15119/29850 (epoch 25.325), train_loss = 1.07260389, grad/param norm = 2.2726e-01, time/batch = 18.4499s	
15120/29850 (epoch 25.327), train_loss = 1.18667285, grad/param norm = 2.2876e-01, time/batch = 17.2158s	
15121/29850 (epoch 25.328), train_loss = 1.09165159, grad/param norm = 2.3593e-01, time/batch = 17.0440s	
15122/29850 (epoch 25.330), train_loss = 1.01058924, grad/param norm = 1.9514e-01, time/batch = 18.3840s	
15123/29850 (epoch 25.332), train_loss = 0.93341441, grad/param norm = 2.0579e-01, time/batch = 18.6145s	
15124/29850 (epoch 25.333), train_loss = 1.03041418, grad/param norm = 2.1022e-01, time/batch = 16.5380s	
15125/29850 (epoch 25.335), train_loss = 1.07402293, grad/param norm = 2.0035e-01, time/batch = 15.4459s	
15126/29850 (epoch 25.337), train_loss = 0.99023901, grad/param norm = 2.0249e-01, time/batch = 16.8917s	
15127/29850 (epoch 25.338), train_loss = 0.99124090, grad/param norm = 2.0173e-01, time/batch = 16.9687s	
15128/29850 (epoch 25.340), train_loss = 0.87012149, grad/param norm = 1.9720e-01, time/batch = 18.3042s	
15129/29850 (epoch 25.342), train_loss = 1.00126095, grad/param norm = 2.3292e-01, time/batch = 18.1176s	
15130/29850 (epoch 25.343), train_loss = 1.00072092, grad/param norm = 2.1855e-01, time/batch = 15.3821s	
15131/29850 (epoch 25.345), train_loss = 1.03002420, grad/param norm = 2.0891e-01, time/batch = 18.6105s	
15132/29850 (epoch 25.347), train_loss = 1.08442456, grad/param norm = 2.3156e-01, time/batch = 19.3651s	
15133/29850 (epoch 25.348), train_loss = 0.92569123, grad/param norm = 1.9252e-01, time/batch = 18.1423s	
15134/29850 (epoch 25.350), train_loss = 1.04127621, grad/param norm = 2.1785e-01, time/batch = 18.3676s	
15135/29850 (epoch 25.352), train_loss = 0.91757820, grad/param norm = 1.8316e-01, time/batch = 18.5587s	
15136/29850 (epoch 25.353), train_loss = 1.04221584, grad/param norm = 2.1653e-01, time/batch = 18.3042s	
15137/29850 (epoch 25.355), train_loss = 0.90461926, grad/param norm = 1.9945e-01, time/batch = 16.1209s	
15138/29850 (epoch 25.357), train_loss = 1.07631057, grad/param norm = 2.0289e-01, time/batch = 18.3883s	
15139/29850 (epoch 25.358), train_loss = 0.88235581, grad/param norm = 1.9429e-01, time/batch = 17.7254s	
15140/29850 (epoch 25.360), train_loss = 0.94434369, grad/param norm = 1.9525e-01, time/batch = 17.9672s	
15141/29850 (epoch 25.362), train_loss = 0.97220148, grad/param norm = 2.2933e-01, time/batch = 17.2549s	
15142/29850 (epoch 25.363), train_loss = 1.00239013, grad/param norm = 2.2960e-01, time/batch = 16.3102s	
15143/29850 (epoch 25.365), train_loss = 1.12768996, grad/param norm = 2.1889e-01, time/batch = 18.6265s	
15144/29850 (epoch 25.367), train_loss = 0.92144885, grad/param norm = 2.1992e-01, time/batch = 16.6191s	
15145/29850 (epoch 25.369), train_loss = 0.84303344, grad/param norm = 1.9707e-01, time/batch = 15.8806s	
15146/29850 (epoch 25.370), train_loss = 0.79661885, grad/param norm = 1.9706e-01, time/batch = 16.4747s	
15147/29850 (epoch 25.372), train_loss = 1.04664446, grad/param norm = 2.1369e-01, time/batch = 18.6148s	
15148/29850 (epoch 25.374), train_loss = 1.03745555, grad/param norm = 2.1398e-01, time/batch = 16.2258s	
15149/29850 (epoch 25.375), train_loss = 0.97079572, grad/param norm = 1.9742e-01, time/batch = 19.2911s	
15150/29850 (epoch 25.377), train_loss = 0.92105383, grad/param norm = 2.0981e-01, time/batch = 16.0393s	
15151/29850 (epoch 25.379), train_loss = 1.09046187, grad/param norm = 2.2862e-01, time/batch = 16.0405s	
15152/29850 (epoch 25.380), train_loss = 1.02369469, grad/param norm = 2.0174e-01, time/batch = 19.0434s	
15153/29850 (epoch 25.382), train_loss = 1.01113367, grad/param norm = 2.3753e-01, time/batch = 18.8030s	
15154/29850 (epoch 25.384), train_loss = 1.05275363, grad/param norm = 2.0469e-01, time/batch = 16.3717s	
15155/29850 (epoch 25.385), train_loss = 1.00819163, grad/param norm = 2.1931e-01, time/batch = 17.7128s	
15156/29850 (epoch 25.387), train_loss = 1.01440606, grad/param norm = 2.2150e-01, time/batch = 17.3844s	
15157/29850 (epoch 25.389), train_loss = 1.12265120, grad/param norm = 2.2179e-01, time/batch = 19.0364s	
15158/29850 (epoch 25.390), train_loss = 1.05615568, grad/param norm = 1.9913e-01, time/batch = 15.3495s	
15159/29850 (epoch 25.392), train_loss = 0.96123191, grad/param norm = 2.1040e-01, time/batch = 18.4528s	
15160/29850 (epoch 25.394), train_loss = 1.06753136, grad/param norm = 2.0614e-01, time/batch = 18.6024s	
15161/29850 (epoch 25.395), train_loss = 0.94480118, grad/param norm = 2.1314e-01, time/batch = 17.7039s	
15162/29850 (epoch 25.397), train_loss = 0.87559405, grad/param norm = 2.1724e-01, time/batch = 18.9639s	
15163/29850 (epoch 25.399), train_loss = 0.89708105, grad/param norm = 1.8289e-01, time/batch = 15.2978s	
15164/29850 (epoch 25.400), train_loss = 1.28787706, grad/param norm = 2.5137e-01, time/batch = 17.8691s	
15165/29850 (epoch 25.402), train_loss = 1.16670672, grad/param norm = 2.0690e-01, time/batch = 15.8033s	
15166/29850 (epoch 25.404), train_loss = 1.00783386, grad/param norm = 2.0143e-01, time/batch = 18.3106s	
15167/29850 (epoch 25.405), train_loss = 0.93136156, grad/param norm = 2.2681e-01, time/batch = 18.6280s	
15168/29850 (epoch 25.407), train_loss = 0.89440513, grad/param norm = 1.9306e-01, time/batch = 16.4622s	
15169/29850 (epoch 25.409), train_loss = 1.04418856, grad/param norm = 2.4887e-01, time/batch = 16.3757s	
15170/29850 (epoch 25.410), train_loss = 1.14047548, grad/param norm = 2.3801e-01, time/batch = 18.8683s	
15171/29850 (epoch 25.412), train_loss = 1.08942337, grad/param norm = 2.1757e-01, time/batch = 18.2006s	
15172/29850 (epoch 25.414), train_loss = 0.98877133, grad/param norm = 2.1534e-01, time/batch = 17.4662s	
15173/29850 (epoch 25.415), train_loss = 1.00983319, grad/param norm = 2.3267e-01, time/batch = 18.2810s	
15174/29850 (epoch 25.417), train_loss = 1.12039024, grad/param norm = 2.2110e-01, time/batch = 17.1373s	
15175/29850 (epoch 25.419), train_loss = 0.96126196, grad/param norm = 2.0620e-01, time/batch = 16.0323s	
15176/29850 (epoch 25.420), train_loss = 0.98387018, grad/param norm = 2.0474e-01, time/batch = 18.0514s	
15177/29850 (epoch 25.422), train_loss = 0.97923219, grad/param norm = 2.2158e-01, time/batch = 16.6439s	
15178/29850 (epoch 25.424), train_loss = 0.90746045, grad/param norm = 2.1815e-01, time/batch = 14.9812s	
15179/29850 (epoch 25.425), train_loss = 1.06213716, grad/param norm = 2.1538e-01, time/batch = 17.8021s	
15180/29850 (epoch 25.427), train_loss = 0.82063102, grad/param norm = 1.7174e-01, time/batch = 17.8815s	
15181/29850 (epoch 25.429), train_loss = 0.88504027, grad/param norm = 2.0604e-01, time/batch = 18.6133s	
15182/29850 (epoch 25.430), train_loss = 0.81959146, grad/param norm = 1.7861e-01, time/batch = 17.7854s	
15183/29850 (epoch 25.432), train_loss = 0.93962009, grad/param norm = 2.2067e-01, time/batch = 18.7944s	
15184/29850 (epoch 25.434), train_loss = 0.87302343, grad/param norm = 1.9786e-01, time/batch = 19.3641s	
15185/29850 (epoch 25.436), train_loss = 0.98453843, grad/param norm = 2.1641e-01, time/batch = 16.5359s	
15186/29850 (epoch 25.437), train_loss = 1.03304083, grad/param norm = 1.8786e-01, time/batch = 18.4406s	
15187/29850 (epoch 25.439), train_loss = 1.00927157, grad/param norm = 2.0210e-01, time/batch = 17.8898s	
15188/29850 (epoch 25.441), train_loss = 0.98247702, grad/param norm = 1.9542e-01, time/batch = 16.6930s	
15189/29850 (epoch 25.442), train_loss = 0.96796358, grad/param norm = 1.9399e-01, time/batch = 16.7971s	
15190/29850 (epoch 25.444), train_loss = 1.01398500, grad/param norm = 2.2095e-01, time/batch = 19.6165s	
15191/29850 (epoch 25.446), train_loss = 1.03305940, grad/param norm = 2.1107e-01, time/batch = 18.2021s	
15192/29850 (epoch 25.447), train_loss = 1.04609719, grad/param norm = 2.0436e-01, time/batch = 15.4386s	
15193/29850 (epoch 25.449), train_loss = 0.98674471, grad/param norm = 2.0433e-01, time/batch = 18.4640s	
15194/29850 (epoch 25.451), train_loss = 0.79840734, grad/param norm = 1.7733e-01, time/batch = 17.3628s	
15195/29850 (epoch 25.452), train_loss = 0.71950616, grad/param norm = 1.6606e-01, time/batch = 15.6346s	
15196/29850 (epoch 25.454), train_loss = 0.82742195, grad/param norm = 1.7369e-01, time/batch = 17.2172s	
15197/29850 (epoch 25.456), train_loss = 1.02908576, grad/param norm = 2.0426e-01, time/batch = 17.6255s	
15198/29850 (epoch 25.457), train_loss = 1.04272891, grad/param norm = 3.4096e-01, time/batch = 17.5175s	
15199/29850 (epoch 25.459), train_loss = 1.14595235, grad/param norm = 2.3591e-01, time/batch = 16.5356s	
15200/29850 (epoch 25.461), train_loss = 1.12746851, grad/param norm = 2.0915e-01, time/batch = 18.1272s	
15201/29850 (epoch 25.462), train_loss = 1.11731002, grad/param norm = 2.3365e-01, time/batch = 19.0476s	
15202/29850 (epoch 25.464), train_loss = 1.03543816, grad/param norm = 2.0748e-01, time/batch = 17.7901s	
15203/29850 (epoch 25.466), train_loss = 0.85372105, grad/param norm = 2.1429e-01, time/batch = 18.5576s	
15204/29850 (epoch 25.467), train_loss = 0.94240475, grad/param norm = 2.1725e-01, time/batch = 17.3865s	
15205/29850 (epoch 25.469), train_loss = 0.94164574, grad/param norm = 1.8850e-01, time/batch = 17.0305s	
15206/29850 (epoch 25.471), train_loss = 0.95000249, grad/param norm = 2.0926e-01, time/batch = 16.1011s	
15207/29850 (epoch 25.472), train_loss = 0.91327481, grad/param norm = 1.8611e-01, time/batch = 17.2097s	
15208/29850 (epoch 25.474), train_loss = 1.06974469, grad/param norm = 2.0442e-01, time/batch = 19.5314s	
15209/29850 (epoch 25.476), train_loss = 0.97651424, grad/param norm = 1.7970e-01, time/batch = 17.8265s	
15210/29850 (epoch 25.477), train_loss = 1.00868137, grad/param norm = 2.4770e-01, time/batch = 17.4666s	
15211/29850 (epoch 25.479), train_loss = 1.17906319, grad/param norm = 2.4500e-01, time/batch = 17.7174s	
15212/29850 (epoch 25.481), train_loss = 0.93526603, grad/param norm = 1.8473e-01, time/batch = 17.3736s	
15213/29850 (epoch 25.482), train_loss = 0.89104757, grad/param norm = 1.6843e-01, time/batch = 18.6998s	
15214/29850 (epoch 25.484), train_loss = 0.93122473, grad/param norm = 1.9546e-01, time/batch = 16.9338s	
15215/29850 (epoch 25.486), train_loss = 1.01146506, grad/param norm = 2.1250e-01, time/batch = 18.1189s	
15216/29850 (epoch 25.487), train_loss = 0.98316640, grad/param norm = 2.0366e-01, time/batch = 14.8967s	
15217/29850 (epoch 25.489), train_loss = 0.95779117, grad/param norm = 1.9247e-01, time/batch = 18.6448s	
15218/29850 (epoch 25.491), train_loss = 0.88197166, grad/param norm = 1.8737e-01, time/batch = 17.2205s	
15219/29850 (epoch 25.492), train_loss = 0.97789912, grad/param norm = 2.2679e-01, time/batch = 15.2250s	
15220/29850 (epoch 25.494), train_loss = 1.04947946, grad/param norm = 1.9029e-01, time/batch = 17.0999s	
15221/29850 (epoch 25.496), train_loss = 1.14975022, grad/param norm = 2.0105e-01, time/batch = 17.8939s	
15222/29850 (epoch 25.497), train_loss = 1.03434053, grad/param norm = 1.9832e-01, time/batch = 17.5457s	
15223/29850 (epoch 25.499), train_loss = 0.99000732, grad/param norm = 2.0573e-01, time/batch = 16.8948s	
15224/29850 (epoch 25.501), train_loss = 0.91305996, grad/param norm = 2.0951e-01, time/batch = 16.2908s	
15225/29850 (epoch 25.503), train_loss = 1.01438393, grad/param norm = 1.9417e-01, time/batch = 18.4718s	
15226/29850 (epoch 25.504), train_loss = 1.22173283, grad/param norm = 2.1636e-01, time/batch = 24.6514s	
15227/29850 (epoch 25.506), train_loss = 1.16701289, grad/param norm = 2.2526e-01, time/batch = 22.6533s	
15228/29850 (epoch 25.508), train_loss = 1.00071667, grad/param norm = 2.1016e-01, time/batch = 15.0851s	
15229/29850 (epoch 25.509), train_loss = 0.80651824, grad/param norm = 1.8759e-01, time/batch = 16.2656s	
15230/29850 (epoch 25.511), train_loss = 1.01698933, grad/param norm = 2.0121e-01, time/batch = 15.3667s	
15231/29850 (epoch 25.513), train_loss = 1.01094429, grad/param norm = 2.2902e-01, time/batch = 16.3757s	
15232/29850 (epoch 25.514), train_loss = 0.91613468, grad/param norm = 2.3828e-01, time/batch = 17.5413s	
15233/29850 (epoch 25.516), train_loss = 0.92519820, grad/param norm = 1.6969e-01, time/batch = 18.2206s	
15234/29850 (epoch 25.518), train_loss = 0.82255479, grad/param norm = 1.9955e-01, time/batch = 19.0326s	
15235/29850 (epoch 25.519), train_loss = 0.81075011, grad/param norm = 1.7209e-01, time/batch = 17.9877s	
15236/29850 (epoch 25.521), train_loss = 0.75027000, grad/param norm = 1.7175e-01, time/batch = 17.3772s	
15237/29850 (epoch 25.523), train_loss = 0.81706820, grad/param norm = 1.7358e-01, time/batch = 19.4720s	
15238/29850 (epoch 25.524), train_loss = 0.88835964, grad/param norm = 2.0548e-01, time/batch = 16.1563s	
15239/29850 (epoch 25.526), train_loss = 0.96249956, grad/param norm = 2.0019e-01, time/batch = 17.7196s	
15240/29850 (epoch 25.528), train_loss = 1.06598223, grad/param norm = 2.2020e-01, time/batch = 18.8569s	
15241/29850 (epoch 25.529), train_loss = 1.00314211, grad/param norm = 2.0594e-01, time/batch = 18.7041s	
15242/29850 (epoch 25.531), train_loss = 0.95858791, grad/param norm = 2.0609e-01, time/batch = 17.0396s	
15243/29850 (epoch 25.533), train_loss = 0.94136036, grad/param norm = 1.9215e-01, time/batch = 16.7960s	
15244/29850 (epoch 25.534), train_loss = 1.01041699, grad/param norm = 2.1414e-01, time/batch = 17.8093s	
15245/29850 (epoch 25.536), train_loss = 0.91990418, grad/param norm = 2.2840e-01, time/batch = 15.5345s	
15246/29850 (epoch 25.538), train_loss = 1.08303947, grad/param norm = 2.1174e-01, time/batch = 16.6187s	
15247/29850 (epoch 25.539), train_loss = 1.12203947, grad/param norm = 2.0935e-01, time/batch = 18.3981s	
15248/29850 (epoch 25.541), train_loss = 0.74733593, grad/param norm = 1.9151e-01, time/batch = 15.3918s	
15249/29850 (epoch 25.543), train_loss = 0.96135993, grad/param norm = 2.1647e-01, time/batch = 17.1392s	
15250/29850 (epoch 25.544), train_loss = 1.02559144, grad/param norm = 1.9142e-01, time/batch = 18.0497s	
15251/29850 (epoch 25.546), train_loss = 1.06124035, grad/param norm = 2.1209e-01, time/batch = 19.1266s	
15252/29850 (epoch 25.548), train_loss = 0.82935151, grad/param norm = 1.7398e-01, time/batch = 18.8774s	
15253/29850 (epoch 25.549), train_loss = 0.93001141, grad/param norm = 2.0356e-01, time/batch = 16.2716s	
15254/29850 (epoch 25.551), train_loss = 0.83470285, grad/param norm = 1.7294e-01, time/batch = 18.3956s	
15255/29850 (epoch 25.553), train_loss = 0.95350844, grad/param norm = 1.8666e-01, time/batch = 18.4668s	
15256/29850 (epoch 25.554), train_loss = 0.83264122, grad/param norm = 1.9877e-01, time/batch = 17.1387s	
15257/29850 (epoch 25.556), train_loss = 0.86617031, grad/param norm = 2.0154e-01, time/batch = 17.1217s	
15258/29850 (epoch 25.558), train_loss = 0.87687906, grad/param norm = 1.8392e-01, time/batch = 19.1253s	
15259/29850 (epoch 25.559), train_loss = 0.92408509, grad/param norm = 1.8791e-01, time/batch = 16.4550s	
15260/29850 (epoch 25.561), train_loss = 1.02695516, grad/param norm = 2.2659e-01, time/batch = 15.4774s	
15261/29850 (epoch 25.563), train_loss = 0.99284872, grad/param norm = 2.0853e-01, time/batch = 17.6383s	
15262/29850 (epoch 25.564), train_loss = 0.93749261, grad/param norm = 2.2193e-01, time/batch = 17.7852s	
15263/29850 (epoch 25.566), train_loss = 0.99556587, grad/param norm = 2.3057e-01, time/batch = 15.3777s	
15264/29850 (epoch 25.568), train_loss = 1.04436986, grad/param norm = 1.9908e-01, time/batch = 18.8788s	
15265/29850 (epoch 25.570), train_loss = 1.02405349, grad/param norm = 2.2016e-01, time/batch = 15.8824s	
15266/29850 (epoch 25.571), train_loss = 1.05278023, grad/param norm = 2.1060e-01, time/batch = 17.8747s	
15267/29850 (epoch 25.573), train_loss = 1.14375088, grad/param norm = 2.5128e-01, time/batch = 17.1332s	
15268/29850 (epoch 25.575), train_loss = 1.11608768, grad/param norm = 2.1581e-01, time/batch = 19.0569s	
15269/29850 (epoch 25.576), train_loss = 1.06663435, grad/param norm = 2.0859e-01, time/batch = 16.2084s	
15270/29850 (epoch 25.578), train_loss = 0.92777003, grad/param norm = 2.0444e-01, time/batch = 17.1093s	
15271/29850 (epoch 25.580), train_loss = 1.08822488, grad/param norm = 2.6124e-01, time/batch = 18.4727s	
15272/29850 (epoch 25.581), train_loss = 0.90104249, grad/param norm = 2.1588e-01, time/batch = 19.8011s	
15273/29850 (epoch 25.583), train_loss = 0.98829167, grad/param norm = 2.1497e-01, time/batch = 16.2849s	
15274/29850 (epoch 25.585), train_loss = 0.98987871, grad/param norm = 1.8983e-01, time/batch = 19.0494s	
15275/29850 (epoch 25.586), train_loss = 1.00357074, grad/param norm = 2.2284e-01, time/batch = 18.9660s	
15276/29850 (epoch 25.588), train_loss = 0.93202692, grad/param norm = 2.1016e-01, time/batch = 17.6884s	
15277/29850 (epoch 25.590), train_loss = 0.94831121, grad/param norm = 1.9855e-01, time/batch = 17.6078s	
15278/29850 (epoch 25.591), train_loss = 0.95259037, grad/param norm = 2.1726e-01, time/batch = 18.1400s	
15279/29850 (epoch 25.593), train_loss = 0.90619836, grad/param norm = 2.0344e-01, time/batch = 17.0485s	
15280/29850 (epoch 25.595), train_loss = 0.84633122, grad/param norm = 1.7220e-01, time/batch = 16.0603s	
15281/29850 (epoch 25.596), train_loss = 0.83845097, grad/param norm = 1.8130e-01, time/batch = 18.4763s	
15282/29850 (epoch 25.598), train_loss = 0.96282038, grad/param norm = 1.9978e-01, time/batch = 16.1985s	
15283/29850 (epoch 25.600), train_loss = 1.00323095, grad/param norm = 2.2997e-01, time/batch = 17.9586s	
15284/29850 (epoch 25.601), train_loss = 0.85807170, grad/param norm = 1.7805e-01, time/batch = 15.7842s	
15285/29850 (epoch 25.603), train_loss = 0.91490332, grad/param norm = 1.9552e-01, time/batch = 16.6133s	
15286/29850 (epoch 25.605), train_loss = 0.93165814, grad/param norm = 2.0267e-01, time/batch = 18.2150s	
15287/29850 (epoch 25.606), train_loss = 0.70716456, grad/param norm = 1.7622e-01, time/batch = 15.3792s	
15288/29850 (epoch 25.608), train_loss = 0.87392913, grad/param norm = 1.7944e-01, time/batch = 15.4038s	
15289/29850 (epoch 25.610), train_loss = 0.95778436, grad/param norm = 2.0737e-01, time/batch = 18.4695s	
15290/29850 (epoch 25.611), train_loss = 0.88295677, grad/param norm = 1.9582e-01, time/batch = 16.6348s	
15291/29850 (epoch 25.613), train_loss = 0.74281067, grad/param norm = 1.8449e-01, time/batch = 16.7923s	
15292/29850 (epoch 25.615), train_loss = 0.85381074, grad/param norm = 1.7939e-01, time/batch = 18.7134s	
15293/29850 (epoch 25.616), train_loss = 0.85678273, grad/param norm = 2.2695e-01, time/batch = 18.0511s	
15294/29850 (epoch 25.618), train_loss = 0.90676342, grad/param norm = 1.9985e-01, time/batch = 16.1868s	
15295/29850 (epoch 25.620), train_loss = 0.96565657, grad/param norm = 2.1379e-01, time/batch = 15.0231s	
15296/29850 (epoch 25.621), train_loss = 1.09460300, grad/param norm = 2.1466e-01, time/batch = 18.0546s	
15297/29850 (epoch 25.623), train_loss = 1.02298362, grad/param norm = 2.1069e-01, time/batch = 17.0441s	
15298/29850 (epoch 25.625), train_loss = 0.97446483, grad/param norm = 1.9807e-01, time/batch = 16.8824s	
15299/29850 (epoch 25.626), train_loss = 0.99253604, grad/param norm = 2.0560e-01, time/batch = 17.6473s	
15300/29850 (epoch 25.628), train_loss = 0.88596286, grad/param norm = 1.9591e-01, time/batch = 16.2310s	
15301/29850 (epoch 25.630), train_loss = 0.96413346, grad/param norm = 2.0587e-01, time/batch = 16.2967s	
15302/29850 (epoch 25.631), train_loss = 0.94555423, grad/param norm = 1.8782e-01, time/batch = 19.4687s	
15303/29850 (epoch 25.633), train_loss = 1.00466580, grad/param norm = 2.1504e-01, time/batch = 17.5585s	
15304/29850 (epoch 25.635), train_loss = 0.91651015, grad/param norm = 2.2404e-01, time/batch = 17.1274s	
15305/29850 (epoch 25.637), train_loss = 0.87650591, grad/param norm = 2.2952e-01, time/batch = 18.3673s	
15306/29850 (epoch 25.638), train_loss = 0.99848434, grad/param norm = 2.2273e-01, time/batch = 17.6370s	
15307/29850 (epoch 25.640), train_loss = 1.10485447, grad/param norm = 2.3858e-01, time/batch = 17.6999s	
15308/29850 (epoch 25.642), train_loss = 0.89103647, grad/param norm = 2.1202e-01, time/batch = 17.4399s	
15309/29850 (epoch 25.643), train_loss = 0.88192766, grad/param norm = 2.0867e-01, time/batch = 18.4536s	
15310/29850 (epoch 25.645), train_loss = 0.92826155, grad/param norm = 2.0650e-01, time/batch = 18.3709s	
15311/29850 (epoch 25.647), train_loss = 1.08783403, grad/param norm = 2.2940e-01, time/batch = 15.6996s	
15312/29850 (epoch 25.648), train_loss = 0.85116532, grad/param norm = 1.8451e-01, time/batch = 16.6205s	
15313/29850 (epoch 25.650), train_loss = 0.98992407, grad/param norm = 2.0910e-01, time/batch = 16.5461s	
15314/29850 (epoch 25.652), train_loss = 0.97173030, grad/param norm = 2.3224e-01, time/batch = 16.8052s	
15315/29850 (epoch 25.653), train_loss = 1.07471241, grad/param norm = 2.4726e-01, time/batch = 17.5266s	
15316/29850 (epoch 25.655), train_loss = 0.95801159, grad/param norm = 1.8756e-01, time/batch = 18.9584s	
15317/29850 (epoch 25.657), train_loss = 0.90923789, grad/param norm = 1.9161e-01, time/batch = 16.0452s	
15318/29850 (epoch 25.658), train_loss = 1.06769887, grad/param norm = 2.1393e-01, time/batch = 17.0310s	
15319/29850 (epoch 25.660), train_loss = 0.97211587, grad/param norm = 2.1380e-01, time/batch = 16.6394s	
15320/29850 (epoch 25.662), train_loss = 1.06133896, grad/param norm = 2.2825e-01, time/batch = 16.4589s	
15321/29850 (epoch 25.663), train_loss = 1.15872300, grad/param norm = 2.2354e-01, time/batch = 18.1895s	
15322/29850 (epoch 25.665), train_loss = 1.10246879, grad/param norm = 2.3051e-01, time/batch = 17.3043s	
15323/29850 (epoch 25.667), train_loss = 1.02987887, grad/param norm = 2.9716e-01, time/batch = 17.4822s	
15324/29850 (epoch 25.668), train_loss = 0.94478131, grad/param norm = 2.1953e-01, time/batch = 18.8888s	
15325/29850 (epoch 25.670), train_loss = 1.09724602, grad/param norm = 2.5892e-01, time/batch = 17.7038s	
15326/29850 (epoch 25.672), train_loss = 1.07540778, grad/param norm = 2.3975e-01, time/batch = 18.3096s	
15327/29850 (epoch 25.673), train_loss = 1.04518763, grad/param norm = 2.4858e-01, time/batch = 18.0434s	
15328/29850 (epoch 25.675), train_loss = 0.86107776, grad/param norm = 2.0690e-01, time/batch = 17.1127s	
15329/29850 (epoch 25.677), train_loss = 0.93655774, grad/param norm = 2.0629e-01, time/batch = 15.4766s	
15330/29850 (epoch 25.678), train_loss = 0.95532880, grad/param norm = 2.0246e-01, time/batch = 17.1418s	
15331/29850 (epoch 25.680), train_loss = 0.96715069, grad/param norm = 1.9809e-01, time/batch = 18.2976s	
15332/29850 (epoch 25.682), train_loss = 0.98724156, grad/param norm = 2.1935e-01, time/batch = 16.8749s	
15333/29850 (epoch 25.683), train_loss = 1.10435950, grad/param norm = 2.2835e-01, time/batch = 18.6188s	
15334/29850 (epoch 25.685), train_loss = 1.12569204, grad/param norm = 1.8689e-01, time/batch = 15.9618s	
15335/29850 (epoch 25.687), train_loss = 1.02401283, grad/param norm = 2.0812e-01, time/batch = 16.9564s	
15336/29850 (epoch 25.688), train_loss = 0.87434016, grad/param norm = 1.9352e-01, time/batch = 16.6247s	
15337/29850 (epoch 25.690), train_loss = 0.84590512, grad/param norm = 1.9173e-01, time/batch = 17.2907s	
15338/29850 (epoch 25.692), train_loss = 1.05231995, grad/param norm = 2.1250e-01, time/batch = 15.1396s	
15339/29850 (epoch 25.693), train_loss = 0.96474794, grad/param norm = 2.1084e-01, time/batch = 17.5416s	
15340/29850 (epoch 25.695), train_loss = 0.83413237, grad/param norm = 1.6632e-01, time/batch = 17.5298s	
15341/29850 (epoch 25.697), train_loss = 0.95561459, grad/param norm = 2.1245e-01, time/batch = 16.3564s	
15342/29850 (epoch 25.698), train_loss = 1.11294223, grad/param norm = 2.1235e-01, time/batch = 16.6195s	
15343/29850 (epoch 25.700), train_loss = 1.06314757, grad/param norm = 2.3101e-01, time/batch = 18.2751s	
15344/29850 (epoch 25.702), train_loss = 0.96066064, grad/param norm = 2.0615e-01, time/batch = 16.9713s	
15345/29850 (epoch 25.704), train_loss = 0.84729855, grad/param norm = 1.7894e-01, time/batch = 18.8848s	
15346/29850 (epoch 25.705), train_loss = 0.98054629, grad/param norm = 1.9606e-01, time/batch = 17.6944s	
15347/29850 (epoch 25.707), train_loss = 0.88263283, grad/param norm = 2.0922e-01, time/batch = 17.6457s	
15348/29850 (epoch 25.709), train_loss = 0.97895163, grad/param norm = 2.2184e-01, time/batch = 17.2968s	
15349/29850 (epoch 25.710), train_loss = 0.90252775, grad/param norm = 2.1550e-01, time/batch = 16.6394s	
15350/29850 (epoch 25.712), train_loss = 0.98413547, grad/param norm = 1.8359e-01, time/batch = 17.9601s	
15351/29850 (epoch 25.714), train_loss = 1.04688274, grad/param norm = 2.0901e-01, time/batch = 16.4776s	
15352/29850 (epoch 25.715), train_loss = 0.99527342, grad/param norm = 2.1438e-01, time/batch = 15.8535s	
15353/29850 (epoch 25.717), train_loss = 0.76032943, grad/param norm = 1.8313e-01, time/batch = 17.3832s	
15354/29850 (epoch 25.719), train_loss = 0.91329478, grad/param norm = 1.9467e-01, time/batch = 17.1448s	
15355/29850 (epoch 25.720), train_loss = 0.96583431, grad/param norm = 1.9448e-01, time/batch = 19.2918s	
15356/29850 (epoch 25.722), train_loss = 0.90906116, grad/param norm = 1.7557e-01, time/batch = 16.2063s	
15357/29850 (epoch 25.724), train_loss = 1.00970758, grad/param norm = 2.1228e-01, time/batch = 18.2263s	
15358/29850 (epoch 25.725), train_loss = 0.82446164, grad/param norm = 1.9142e-01, time/batch = 18.3139s	
15359/29850 (epoch 25.727), train_loss = 0.88268461, grad/param norm = 2.0640e-01, time/batch = 17.6341s	
15360/29850 (epoch 25.729), train_loss = 0.82185870, grad/param norm = 1.6763e-01, time/batch = 18.0106s	
15361/29850 (epoch 25.730), train_loss = 0.79546306, grad/param norm = 1.8825e-01, time/batch = 18.3634s	
15362/29850 (epoch 25.732), train_loss = 1.04290158, grad/param norm = 2.0017e-01, time/batch = 17.2938s	
15363/29850 (epoch 25.734), train_loss = 1.13675328, grad/param norm = 2.9805e-01, time/batch = 17.0342s	
15364/29850 (epoch 25.735), train_loss = 0.89742294, grad/param norm = 2.0764e-01, time/batch = 17.8629s	
15365/29850 (epoch 25.737), train_loss = 0.86617934, grad/param norm = 1.9505e-01, time/batch = 18.8013s	
15366/29850 (epoch 25.739), train_loss = 0.76459215, grad/param norm = 2.0324e-01, time/batch = 15.4534s	
15367/29850 (epoch 25.740), train_loss = 0.83003116, grad/param norm = 1.9056e-01, time/batch = 17.7840s	
15368/29850 (epoch 25.742), train_loss = 0.76311242, grad/param norm = 1.7122e-01, time/batch = 17.3627s	
15369/29850 (epoch 25.744), train_loss = 0.90540309, grad/param norm = 2.2182e-01, time/batch = 17.7924s	
15370/29850 (epoch 25.745), train_loss = 0.89111727, grad/param norm = 2.1361e-01, time/batch = 17.9577s	
15371/29850 (epoch 25.747), train_loss = 0.93956355, grad/param norm = 2.0415e-01, time/batch = 17.5662s	
15372/29850 (epoch 25.749), train_loss = 0.82446947, grad/param norm = 1.9463e-01, time/batch = 18.4668s	
15373/29850 (epoch 25.750), train_loss = 0.77505999, grad/param norm = 1.8702e-01, time/batch = 17.9369s	
15374/29850 (epoch 25.752), train_loss = 0.71892320, grad/param norm = 1.9703e-01, time/batch = 16.7038s	
15375/29850 (epoch 25.754), train_loss = 0.81577059, grad/param norm = 1.8431e-01, time/batch = 17.3353s	
15376/29850 (epoch 25.755), train_loss = 0.80146831, grad/param norm = 1.8139e-01, time/batch = 17.7905s	
15377/29850 (epoch 25.757), train_loss = 0.86631508, grad/param norm = 1.7898e-01, time/batch = 18.1958s	
15378/29850 (epoch 25.759), train_loss = 0.86895408, grad/param norm = 1.9626e-01, time/batch = 17.6342s	
15379/29850 (epoch 25.760), train_loss = 0.84560192, grad/param norm = 2.0958e-01, time/batch = 17.5527s	
15380/29850 (epoch 25.762), train_loss = 0.80605578, grad/param norm = 2.1961e-01, time/batch = 18.5251s	
15381/29850 (epoch 25.764), train_loss = 0.77770895, grad/param norm = 2.1937e-01, time/batch = 17.2374s	
15382/29850 (epoch 25.765), train_loss = 0.90916418, grad/param norm = 2.4009e-01, time/batch = 17.2956s	
15383/29850 (epoch 25.767), train_loss = 0.90196148, grad/param norm = 1.9305e-01, time/batch = 17.2826s	
15384/29850 (epoch 25.769), train_loss = 0.91493546, grad/param norm = 1.8810e-01, time/batch = 16.2248s	
15385/29850 (epoch 25.771), train_loss = 0.96388528, grad/param norm = 1.9665e-01, time/batch = 17.6309s	
15386/29850 (epoch 25.772), train_loss = 0.96413162, grad/param norm = 2.2373e-01, time/batch = 15.7777s	
15387/29850 (epoch 25.774), train_loss = 0.87397425, grad/param norm = 1.8925e-01, time/batch = 16.9718s	
15388/29850 (epoch 25.776), train_loss = 0.88572974, grad/param norm = 1.7838e-01, time/batch = 16.9509s	
15389/29850 (epoch 25.777), train_loss = 1.00686985, grad/param norm = 2.1568e-01, time/batch = 19.3620s	
15390/29850 (epoch 25.779), train_loss = 0.83250823, grad/param norm = 1.9189e-01, time/batch = 16.8142s	
15391/29850 (epoch 25.781), train_loss = 0.95571973, grad/param norm = 1.9217e-01, time/batch = 18.3976s	
15392/29850 (epoch 25.782), train_loss = 0.97843086, grad/param norm = 1.9947e-01, time/batch = 14.5710s	
15393/29850 (epoch 25.784), train_loss = 0.81265387, grad/param norm = 2.5894e-01, time/batch = 17.6932s	
15394/29850 (epoch 25.786), train_loss = 0.89256469, grad/param norm = 2.0186e-01, time/batch = 17.4455s	
15395/29850 (epoch 25.787), train_loss = 0.76883424, grad/param norm = 2.0150e-01, time/batch = 18.2185s	
15396/29850 (epoch 25.789), train_loss = 0.77621063, grad/param norm = 1.7967e-01, time/batch = 17.1532s	
15397/29850 (epoch 25.791), train_loss = 0.86983904, grad/param norm = 2.3388e-01, time/batch = 15.3913s	
15398/29850 (epoch 25.792), train_loss = 0.99774143, grad/param norm = 2.1617e-01, time/batch = 18.2052s	
15399/29850 (epoch 25.794), train_loss = 0.96331735, grad/param norm = 1.9694e-01, time/batch = 17.4007s	
15400/29850 (epoch 25.796), train_loss = 0.82632329, grad/param norm = 1.9134e-01, time/batch = 17.5491s	
15401/29850 (epoch 25.797), train_loss = 0.74398504, grad/param norm = 1.7145e-01, time/batch = 17.7074s	
15402/29850 (epoch 25.799), train_loss = 0.78233808, grad/param norm = 1.7220e-01, time/batch = 16.9685s	
15403/29850 (epoch 25.801), train_loss = 0.85964811, grad/param norm = 1.9993e-01, time/batch = 17.2605s	
15404/29850 (epoch 25.802), train_loss = 0.76285258, grad/param norm = 2.1066e-01, time/batch = 15.8804s	
15405/29850 (epoch 25.804), train_loss = 0.79363001, grad/param norm = 1.6437e-01, time/batch = 19.1184s	
15406/29850 (epoch 25.806), train_loss = 0.77381016, grad/param norm = 1.8840e-01, time/batch = 18.2159s	
15407/29850 (epoch 25.807), train_loss = 0.77701133, grad/param norm = 1.7272e-01, time/batch = 15.4563s	
15408/29850 (epoch 25.809), train_loss = 0.80789933, grad/param norm = 2.1289e-01, time/batch = 19.2888s	
15409/29850 (epoch 25.811), train_loss = 0.96323520, grad/param norm = 2.0104e-01, time/batch = 18.1217s	
15410/29850 (epoch 25.812), train_loss = 0.94381635, grad/param norm = 2.3040e-01, time/batch = 18.3008s	
15411/29850 (epoch 25.814), train_loss = 1.01894838, grad/param norm = 2.3605e-01, time/batch = 18.1158s	
15412/29850 (epoch 25.816), train_loss = 1.00223572, grad/param norm = 1.8594e-01, time/batch = 17.3709s	
15413/29850 (epoch 25.817), train_loss = 0.94330696, grad/param norm = 2.0963e-01, time/batch = 18.4565s	
15414/29850 (epoch 25.819), train_loss = 0.80255376, grad/param norm = 2.0962e-01, time/batch = 16.5487s	
15415/29850 (epoch 25.821), train_loss = 1.03364339, grad/param norm = 2.3063e-01, time/batch = 17.2284s	
15416/29850 (epoch 25.822), train_loss = 1.01968756, grad/param norm = 2.0594e-01, time/batch = 16.2965s	
15417/29850 (epoch 25.824), train_loss = 0.90343225, grad/param norm = 1.8388e-01, time/batch = 18.1265s	
15418/29850 (epoch 25.826), train_loss = 0.84354159, grad/param norm = 1.9011e-01, time/batch = 18.7857s	
15419/29850 (epoch 25.827), train_loss = 0.80088148, grad/param norm = 2.2381e-01, time/batch = 17.7115s	
15420/29850 (epoch 25.829), train_loss = 0.93060211, grad/param norm = 2.2520e-01, time/batch = 17.9425s	
15421/29850 (epoch 25.831), train_loss = 1.00378221, grad/param norm = 2.2242e-01, time/batch = 17.8900s	
15422/29850 (epoch 25.832), train_loss = 0.92271591, grad/param norm = 1.8310e-01, time/batch = 17.1398s	
15423/29850 (epoch 25.834), train_loss = 0.71797157, grad/param norm = 1.7795e-01, time/batch = 17.9098s	
15424/29850 (epoch 25.836), train_loss = 0.75854213, grad/param norm = 1.7651e-01, time/batch = 17.2905s	
15425/29850 (epoch 25.838), train_loss = 0.89947683, grad/param norm = 2.2717e-01, time/batch = 18.6308s	
15426/29850 (epoch 25.839), train_loss = 0.78185418, grad/param norm = 1.8753e-01, time/batch = 16.0448s	
15427/29850 (epoch 25.841), train_loss = 0.81910030, grad/param norm = 1.8238e-01, time/batch = 16.7975s	
15428/29850 (epoch 25.843), train_loss = 0.77425690, grad/param norm = 2.2393e-01, time/batch = 19.2955s	
15429/29850 (epoch 25.844), train_loss = 0.84525364, grad/param norm = 2.1853e-01, time/batch = 18.1171s	
15430/29850 (epoch 25.846), train_loss = 0.89009791, grad/param norm = 1.8054e-01, time/batch = 16.7725s	
15431/29850 (epoch 25.848), train_loss = 0.97638294, grad/param norm = 2.3752e-01, time/batch = 30.6759s	
15432/29850 (epoch 25.849), train_loss = 0.87533950, grad/param norm = 2.1826e-01, time/batch = 19.0450s	
15433/29850 (epoch 25.851), train_loss = 1.01933083, grad/param norm = 2.1911e-01, time/batch = 16.1371s	
15434/29850 (epoch 25.853), train_loss = 0.86739927, grad/param norm = 2.2449e-01, time/batch = 19.1084s	
15435/29850 (epoch 25.854), train_loss = 1.08094371, grad/param norm = 2.4482e-01, time/batch = 18.5543s	
15436/29850 (epoch 25.856), train_loss = 0.99654118, grad/param norm = 2.3174e-01, time/batch = 15.9390s	
15437/29850 (epoch 25.858), train_loss = 0.94644845, grad/param norm = 2.2022e-01, time/batch = 15.1475s	
15438/29850 (epoch 25.859), train_loss = 0.81853590, grad/param norm = 2.5109e-01, time/batch = 15.3962s	
15439/29850 (epoch 25.861), train_loss = 1.05055434, grad/param norm = 2.4722e-01, time/batch = 15.3092s	
15440/29850 (epoch 25.863), train_loss = 1.09235279, grad/param norm = 2.2744e-01, time/batch = 18.0335s	
15441/29850 (epoch 25.864), train_loss = 1.03440234, grad/param norm = 2.1158e-01, time/batch = 17.8716s	
15442/29850 (epoch 25.866), train_loss = 0.94896582, grad/param norm = 2.5238e-01, time/batch = 17.7190s	
15443/29850 (epoch 25.868), train_loss = 1.10419713, grad/param norm = 2.3392e-01, time/batch = 19.2882s	
15444/29850 (epoch 25.869), train_loss = 0.99147556, grad/param norm = 2.4913e-01, time/batch = 16.3801s	
15445/29850 (epoch 25.871), train_loss = 1.02385086, grad/param norm = 2.2165e-01, time/batch = 18.8817s	
15446/29850 (epoch 25.873), train_loss = 0.98985922, grad/param norm = 2.6587e-01, time/batch = 15.8606s	
15447/29850 (epoch 25.874), train_loss = 0.98748792, grad/param norm = 2.0684e-01, time/batch = 17.6236s	
15448/29850 (epoch 25.876), train_loss = 0.95219270, grad/param norm = 4.3266e-01, time/batch = 17.7969s	
15449/29850 (epoch 25.878), train_loss = 0.95897640, grad/param norm = 1.9594e-01, time/batch = 15.6169s	
15450/29850 (epoch 25.879), train_loss = 0.99330988, grad/param norm = 2.2391e-01, time/batch = 18.1408s	
15451/29850 (epoch 25.881), train_loss = 1.03604965, grad/param norm = 2.2711e-01, time/batch = 16.4601s	
15452/29850 (epoch 25.883), train_loss = 1.02387897, grad/param norm = 2.1934e-01, time/batch = 18.5400s	
15453/29850 (epoch 25.884), train_loss = 0.83024587, grad/param norm = 2.1954e-01, time/batch = 15.6815s	
15454/29850 (epoch 25.886), train_loss = 1.05082744, grad/param norm = 2.5250e-01, time/batch = 16.4483s	
15455/29850 (epoch 25.888), train_loss = 0.94514134, grad/param norm = 2.2661e-01, time/batch = 19.2962s	
15456/29850 (epoch 25.889), train_loss = 0.87117242, grad/param norm = 1.7464e-01, time/batch = 17.3896s	
15457/29850 (epoch 25.891), train_loss = 0.84141502, grad/param norm = 1.8554e-01, time/batch = 18.7026s	
15458/29850 (epoch 25.893), train_loss = 0.89296528, grad/param norm = 2.1787e-01, time/batch = 16.1059s	
15459/29850 (epoch 25.894), train_loss = 0.91826113, grad/param norm = 2.2532e-01, time/batch = 18.6351s	
15460/29850 (epoch 25.896), train_loss = 0.93797157, grad/param norm = 2.2118e-01, time/batch = 18.1310s	
15461/29850 (epoch 25.898), train_loss = 1.07037268, grad/param norm = 2.3327e-01, time/batch = 17.1359s	
15462/29850 (epoch 25.899), train_loss = 0.84077563, grad/param norm = 2.1819e-01, time/batch = 17.8959s	
15463/29850 (epoch 25.901), train_loss = 1.21574173, grad/param norm = 3.0541e-01, time/batch = 15.1413s	
15464/29850 (epoch 25.903), train_loss = 0.98007444, grad/param norm = 3.8631e-01, time/batch = 17.1343s	
15465/29850 (epoch 25.905), train_loss = 1.18231645, grad/param norm = 2.2916e-01, time/batch = 17.8647s	
15466/29850 (epoch 25.906), train_loss = 1.00505287, grad/param norm = 2.1350e-01, time/batch = 17.8668s	
15467/29850 (epoch 25.908), train_loss = 1.07897781, grad/param norm = 2.0149e-01, time/batch = 16.3625s	
15468/29850 (epoch 25.910), train_loss = 1.00984446, grad/param norm = 2.0688e-01, time/batch = 16.9538s	
15469/29850 (epoch 25.911), train_loss = 1.15720529, grad/param norm = 2.2025e-01, time/batch = 16.5933s	
15470/29850 (epoch 25.913), train_loss = 1.10992021, grad/param norm = 2.2364e-01, time/batch = 17.6423s	
15471/29850 (epoch 25.915), train_loss = 1.09909778, grad/param norm = 2.3545e-01, time/batch = 18.3701s	
15472/29850 (epoch 25.916), train_loss = 1.05267009, grad/param norm = 2.3262e-01, time/batch = 18.3734s	
15473/29850 (epoch 25.918), train_loss = 0.87974002, grad/param norm = 1.8164e-01, time/batch = 18.5614s	
15474/29850 (epoch 25.920), train_loss = 1.03635059, grad/param norm = 1.9110e-01, time/batch = 17.3846s	
15475/29850 (epoch 25.921), train_loss = 0.97545480, grad/param norm = 2.3766e-01, time/batch = 18.9470s	
15476/29850 (epoch 25.923), train_loss = 1.02465060, grad/param norm = 2.3006e-01, time/batch = 16.8830s	
15477/29850 (epoch 25.925), train_loss = 1.09434238, grad/param norm = 2.3199e-01, time/batch = 17.1796s	
15478/29850 (epoch 25.926), train_loss = 1.12215149, grad/param norm = 2.5500e-01, time/batch = 17.3026s	
15479/29850 (epoch 25.928), train_loss = 0.99270338, grad/param norm = 2.0793e-01, time/batch = 18.5584s	
15480/29850 (epoch 25.930), train_loss = 1.00621783, grad/param norm = 1.8584e-01, time/batch = 19.3706s	
15481/29850 (epoch 25.931), train_loss = 0.94721179, grad/param norm = 2.0184e-01, time/batch = 17.2812s	
15482/29850 (epoch 25.933), train_loss = 1.11834868, grad/param norm = 2.0459e-01, time/batch = 18.4560s	
15483/29850 (epoch 25.935), train_loss = 1.04856006, grad/param norm = 2.2459e-01, time/batch = 17.1304s	
15484/29850 (epoch 25.936), train_loss = 0.99472399, grad/param norm = 1.9798e-01, time/batch = 17.2873s	
15485/29850 (epoch 25.938), train_loss = 0.86327610, grad/param norm = 1.9208e-01, time/batch = 16.7867s	
15486/29850 (epoch 25.940), train_loss = 0.86413565, grad/param norm = 1.8754e-01, time/batch = 19.2896s	
15487/29850 (epoch 25.941), train_loss = 0.89184898, grad/param norm = 2.1897e-01, time/batch = 15.8829s	
15488/29850 (epoch 25.943), train_loss = 0.87755596, grad/param norm = 1.9792e-01, time/batch = 15.5271s	
15489/29850 (epoch 25.945), train_loss = 0.89397822, grad/param norm = 2.1316e-01, time/batch = 17.9389s	
15490/29850 (epoch 25.946), train_loss = 0.84343804, grad/param norm = 1.9976e-01, time/batch = 18.8900s	
15491/29850 (epoch 25.948), train_loss = 0.98439890, grad/param norm = 1.9968e-01, time/batch = 17.8765s	
15492/29850 (epoch 25.950), train_loss = 0.88474179, grad/param norm = 1.8252e-01, time/batch = 16.9652s	
15493/29850 (epoch 25.951), train_loss = 0.82670255, grad/param norm = 1.7294e-01, time/batch = 18.4648s	
15494/29850 (epoch 25.953), train_loss = 0.92225863, grad/param norm = 2.4256e-01, time/batch = 19.5410s	
15495/29850 (epoch 25.955), train_loss = 0.84276757, grad/param norm = 1.8774e-01, time/batch = 17.3716s	
15496/29850 (epoch 25.956), train_loss = 0.82216323, grad/param norm = 1.9164e-01, time/batch = 17.2127s	
15497/29850 (epoch 25.958), train_loss = 0.72699169, grad/param norm = 1.5942e-01, time/batch = 19.8627s	
15498/29850 (epoch 25.960), train_loss = 1.03786244, grad/param norm = 2.2027e-01, time/batch = 17.1316s	
15499/29850 (epoch 25.961), train_loss = 0.82925428, grad/param norm = 1.8659e-01, time/batch = 16.8794s	
15500/29850 (epoch 25.963), train_loss = 0.82274356, grad/param norm = 2.2425e-01, time/batch = 18.3071s	
15501/29850 (epoch 25.965), train_loss = 0.87805507, grad/param norm = 2.1720e-01, time/batch = 19.1026s	
15502/29850 (epoch 25.966), train_loss = 0.81729400, grad/param norm = 1.9552e-01, time/batch = 18.1315s	
15503/29850 (epoch 25.968), train_loss = 0.85678340, grad/param norm = 1.9488e-01, time/batch = 18.3875s	
15504/29850 (epoch 25.970), train_loss = 0.82807023, grad/param norm = 2.1569e-01, time/batch = 18.2078s	
15505/29850 (epoch 25.972), train_loss = 0.84708191, grad/param norm = 1.7512e-01, time/batch = 17.7916s	
15506/29850 (epoch 25.973), train_loss = 0.87128911, grad/param norm = 2.0305e-01, time/batch = 19.8647s	
15507/29850 (epoch 25.975), train_loss = 0.75727742, grad/param norm = 1.8318e-01, time/batch = 16.5236s	
15508/29850 (epoch 25.977), train_loss = 0.87012061, grad/param norm = 1.8614e-01, time/batch = 17.2942s	
15509/29850 (epoch 25.978), train_loss = 0.79765047, grad/param norm = 1.7424e-01, time/batch = 15.3644s	
15510/29850 (epoch 25.980), train_loss = 0.86825805, grad/param norm = 1.8948e-01, time/batch = 18.6331s	
15511/29850 (epoch 25.982), train_loss = 0.83301246, grad/param norm = 1.9258e-01, time/batch = 15.8171s	
15512/29850 (epoch 25.983), train_loss = 0.87759165, grad/param norm = 1.7473e-01, time/batch = 16.8643s	
15513/29850 (epoch 25.985), train_loss = 0.95464266, grad/param norm = 1.9753e-01, time/batch = 19.7899s	
15514/29850 (epoch 25.987), train_loss = 0.92702988, grad/param norm = 1.7840e-01, time/batch = 16.8135s	
15515/29850 (epoch 25.988), train_loss = 0.87823045, grad/param norm = 1.8141e-01, time/batch = 16.3693s	
15516/29850 (epoch 25.990), train_loss = 0.93076980, grad/param norm = 1.8288e-01, time/batch = 18.4643s	
15517/29850 (epoch 25.992), train_loss = 0.97319766, grad/param norm = 1.8775e-01, time/batch = 17.4712s	
15518/29850 (epoch 25.993), train_loss = 0.94842665, grad/param norm = 1.9876e-01, time/batch = 17.6292s	
15519/29850 (epoch 25.995), train_loss = 0.95046489, grad/param norm = 1.9098e-01, time/batch = 18.6169s	
15520/29850 (epoch 25.997), train_loss = 0.97879791, grad/param norm = 2.1743e-01, time/batch = 18.4695s	
15521/29850 (epoch 25.998), train_loss = 0.99446059, grad/param norm = 2.0490e-01, time/batch = 17.0430s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
15522/29850 (epoch 26.000), train_loss = 0.82605983, grad/param norm = 1.8579e-01, time/batch = 16.9728s	
15523/29850 (epoch 26.002), train_loss = 1.10176926, grad/param norm = 2.1611e-01, time/batch = 19.5483s	
15524/29850 (epoch 26.003), train_loss = 0.83600283, grad/param norm = 2.0125e-01, time/batch = 18.7195s	
15525/29850 (epoch 26.005), train_loss = 0.94273788, grad/param norm = 1.8657e-01, time/batch = 16.5933s	
15526/29850 (epoch 26.007), train_loss = 1.00824627, grad/param norm = 2.3510e-01, time/batch = 18.7120s	
15527/29850 (epoch 26.008), train_loss = 1.16136913, grad/param norm = 2.1312e-01, time/batch = 16.7973s	
15528/29850 (epoch 26.010), train_loss = 0.87249121, grad/param norm = 2.1776e-01, time/batch = 18.5286s	
15529/29850 (epoch 26.012), train_loss = 0.93242729, grad/param norm = 1.9377e-01, time/batch = 16.8082s	
15530/29850 (epoch 26.013), train_loss = 0.98303211, grad/param norm = 2.2108e-01, time/batch = 17.7316s	
15531/29850 (epoch 26.015), train_loss = 0.98668767, grad/param norm = 2.0493e-01, time/batch = 18.8893s	
15532/29850 (epoch 26.017), train_loss = 0.94941839, grad/param norm = 2.1650e-01, time/batch = 17.1877s	
15533/29850 (epoch 26.018), train_loss = 1.06724189, grad/param norm = 2.2183e-01, time/batch = 15.3894s	
15534/29850 (epoch 26.020), train_loss = 0.92755690, grad/param norm = 2.0143e-01, time/batch = 17.1405s	
15535/29850 (epoch 26.022), train_loss = 1.05712615, grad/param norm = 2.4985e-01, time/batch = 17.5426s	
15536/29850 (epoch 26.023), train_loss = 1.01380465, grad/param norm = 1.9836e-01, time/batch = 16.5558s	
15537/29850 (epoch 26.025), train_loss = 0.91665150, grad/param norm = 1.7228e-01, time/batch = 18.6274s	
15538/29850 (epoch 26.027), train_loss = 0.75229011, grad/param norm = 1.9037e-01, time/batch = 16.9510s	
15539/29850 (epoch 26.028), train_loss = 0.89860847, grad/param norm = 1.8066e-01, time/batch = 16.7905s	
15540/29850 (epoch 26.030), train_loss = 0.95479715, grad/param norm = 2.1601e-01, time/batch = 18.5505s	
15541/29850 (epoch 26.032), train_loss = 1.00861194, grad/param norm = 2.0308e-01, time/batch = 20.1100s	
15542/29850 (epoch 26.034), train_loss = 0.86796961, grad/param norm = 1.9022e-01, time/batch = 16.2815s	
15543/29850 (epoch 26.035), train_loss = 0.77505395, grad/param norm = 1.6846e-01, time/batch = 19.4435s	
15544/29850 (epoch 26.037), train_loss = 0.94288383, grad/param norm = 2.1794e-01, time/batch = 17.7980s	
15545/29850 (epoch 26.039), train_loss = 0.82361575, grad/param norm = 1.6408e-01, time/batch = 17.2195s	
15546/29850 (epoch 26.040), train_loss = 0.85036001, grad/param norm = 1.7715e-01, time/batch = 17.0295s	
15547/29850 (epoch 26.042), train_loss = 0.86458719, grad/param norm = 2.0595e-01, time/batch = 18.2139s	
15548/29850 (epoch 26.044), train_loss = 0.91122693, grad/param norm = 1.9229e-01, time/batch = 15.8337s	
15549/29850 (epoch 26.045), train_loss = 1.00130305, grad/param norm = 1.9993e-01, time/batch = 16.9497s	
15550/29850 (epoch 26.047), train_loss = 0.85588704, grad/param norm = 2.0977e-01, time/batch = 18.3842s	
15551/29850 (epoch 26.049), train_loss = 0.97131225, grad/param norm = 1.8388e-01, time/batch = 18.0591s	
15552/29850 (epoch 26.050), train_loss = 0.83070450, grad/param norm = 1.9960e-01, time/batch = 18.1937s	
15553/29850 (epoch 26.052), train_loss = 1.02356732, grad/param norm = 2.1816e-01, time/batch = 18.8643s	
15554/29850 (epoch 26.054), train_loss = 0.94601704, grad/param norm = 1.9408e-01, time/batch = 16.5917s	
15555/29850 (epoch 26.055), train_loss = 0.90496198, grad/param norm = 1.8713e-01, time/batch = 16.7745s	
15556/29850 (epoch 26.057), train_loss = 0.98714829, grad/param norm = 1.7942e-01, time/batch = 17.0509s	
15557/29850 (epoch 26.059), train_loss = 0.98556200, grad/param norm = 2.0049e-01, time/batch = 17.6336s	
15558/29850 (epoch 26.060), train_loss = 0.95982115, grad/param norm = 2.1439e-01, time/batch = 19.1987s	
15559/29850 (epoch 26.062), train_loss = 1.04837915, grad/param norm = 2.3956e-01, time/batch = 17.2061s	
15560/29850 (epoch 26.064), train_loss = 1.00798618, grad/param norm = 2.1942e-01, time/batch = 17.7054s	
15561/29850 (epoch 26.065), train_loss = 0.86025207, grad/param norm = 1.9970e-01, time/batch = 16.7999s	
15562/29850 (epoch 26.067), train_loss = 0.99677971, grad/param norm = 1.8462e-01, time/batch = 17.2257s	
15563/29850 (epoch 26.069), train_loss = 0.96914607, grad/param norm = 1.9860e-01, time/batch = 16.9755s	
15564/29850 (epoch 26.070), train_loss = 0.98571230, grad/param norm = 1.7988e-01, time/batch = 18.2249s	
15565/29850 (epoch 26.072), train_loss = 0.97421320, grad/param norm = 2.3661e-01, time/batch = 17.1368s	
15566/29850 (epoch 26.074), train_loss = 1.03095038, grad/param norm = 2.0107e-01, time/batch = 15.6065s	
15567/29850 (epoch 26.075), train_loss = 0.88739562, grad/param norm = 2.0004e-01, time/batch = 17.7289s	
15568/29850 (epoch 26.077), train_loss = 0.99281962, grad/param norm = 2.2045e-01, time/batch = 17.8116s	
15569/29850 (epoch 26.079), train_loss = 1.20205185, grad/param norm = 2.8705e-01, time/batch = 17.6171s	
15570/29850 (epoch 26.080), train_loss = 1.13872086, grad/param norm = 2.3151e-01, time/batch = 16.4424s	
15571/29850 (epoch 26.082), train_loss = 1.01548430, grad/param norm = 2.1037e-01, time/batch = 19.1334s	
15572/29850 (epoch 26.084), train_loss = 1.10545798, grad/param norm = 2.1948e-01, time/batch = 18.4486s	
15573/29850 (epoch 26.085), train_loss = 1.13011651, grad/param norm = 2.4681e-01, time/batch = 17.0608s	
15574/29850 (epoch 26.087), train_loss = 1.08643449, grad/param norm = 2.0742e-01, time/batch = 18.1337s	
15575/29850 (epoch 26.089), train_loss = 0.98706318, grad/param norm = 2.0625e-01, time/batch = 18.8029s	
15576/29850 (epoch 26.090), train_loss = 1.03274682, grad/param norm = 2.2115e-01, time/batch = 16.9552s	
15577/29850 (epoch 26.092), train_loss = 0.92013937, grad/param norm = 2.0191e-01, time/batch = 18.0487s	
15578/29850 (epoch 26.094), train_loss = 1.10356070, grad/param norm = 2.2747e-01, time/batch = 16.2760s	
15579/29850 (epoch 26.095), train_loss = 0.99021953, grad/param norm = 2.5862e-01, time/batch = 18.3767s	
15580/29850 (epoch 26.097), train_loss = 0.78126160, grad/param norm = 1.7126e-01, time/batch = 17.8034s	
15581/29850 (epoch 26.099), train_loss = 0.81200002, grad/param norm = 1.7910e-01, time/batch = 17.5230s	
15582/29850 (epoch 26.101), train_loss = 1.06351019, grad/param norm = 2.1951e-01, time/batch = 18.6328s	
15583/29850 (epoch 26.102), train_loss = 1.00417399, grad/param norm = 2.2472e-01, time/batch = 16.8549s	
15584/29850 (epoch 26.104), train_loss = 0.93835120, grad/param norm = 1.9720e-01, time/batch = 17.3872s	
15585/29850 (epoch 26.106), train_loss = 1.04568850, grad/param norm = 1.9530e-01, time/batch = 17.7951s	
15586/29850 (epoch 26.107), train_loss = 0.85934241, grad/param norm = 1.6842e-01, time/batch = 16.2961s	
15587/29850 (epoch 26.109), train_loss = 0.94143113, grad/param norm = 2.1024e-01, time/batch = 18.1481s	
15588/29850 (epoch 26.111), train_loss = 1.02805271, grad/param norm = 1.9289e-01, time/batch = 17.5424s	
15589/29850 (epoch 26.112), train_loss = 0.89587900, grad/param norm = 1.9474e-01, time/batch = 17.3409s	
15590/29850 (epoch 26.114), train_loss = 0.93100862, grad/param norm = 2.2554e-01, time/batch = 18.6367s	
15591/29850 (epoch 26.116), train_loss = 0.86501761, grad/param norm = 1.8073e-01, time/batch = 18.2876s	
15592/29850 (epoch 26.117), train_loss = 0.93815708, grad/param norm = 2.0047e-01, time/batch = 16.3901s	
15593/29850 (epoch 26.119), train_loss = 0.91187835, grad/param norm = 1.9971e-01, time/batch = 17.6302s	
15594/29850 (epoch 26.121), train_loss = 0.77568474, grad/param norm = 1.9084e-01, time/batch = 19.1325s	
15595/29850 (epoch 26.122), train_loss = 0.81886077, grad/param norm = 1.8039e-01, time/batch = 17.6205s	
15596/29850 (epoch 26.124), train_loss = 0.87984958, grad/param norm = 1.9438e-01, time/batch = 17.2094s	
15597/29850 (epoch 26.126), train_loss = 0.90133992, grad/param norm = 1.9536e-01, time/batch = 18.3650s	
15598/29850 (epoch 26.127), train_loss = 1.04049970, grad/param norm = 2.5143e-01, time/batch = 19.6322s	
15599/29850 (epoch 26.129), train_loss = 0.92127481, grad/param norm = 1.9491e-01, time/batch = 18.1284s	
15600/29850 (epoch 26.131), train_loss = 0.94024667, grad/param norm = 2.0087e-01, time/batch = 16.4275s	
15601/29850 (epoch 26.132), train_loss = 0.83318324, grad/param norm = 1.9458e-01, time/batch = 17.7261s	
15602/29850 (epoch 26.134), train_loss = 0.94827176, grad/param norm = 2.0543e-01, time/batch = 17.4847s	
15603/29850 (epoch 26.136), train_loss = 0.98706732, grad/param norm = 1.8778e-01, time/batch = 15.8839s	
15604/29850 (epoch 26.137), train_loss = 0.77057861, grad/param norm = 1.7563e-01, time/batch = 16.4664s	
15605/29850 (epoch 26.139), train_loss = 0.91834978, grad/param norm = 1.8863e-01, time/batch = 18.6260s	
15606/29850 (epoch 26.141), train_loss = 0.86055101, grad/param norm = 1.9304e-01, time/batch = 17.3422s	
15607/29850 (epoch 26.142), train_loss = 1.05947599, grad/param norm = 2.1584e-01, time/batch = 18.4594s	
15608/29850 (epoch 26.144), train_loss = 1.20498278, grad/param norm = 2.3343e-01, time/batch = 17.5537s	
15609/29850 (epoch 26.146), train_loss = 1.20097080, grad/param norm = 2.2212e-01, time/batch = 19.5353s	
15610/29850 (epoch 26.147), train_loss = 1.01355998, grad/param norm = 2.1677e-01, time/batch = 18.9422s	
15611/29850 (epoch 26.149), train_loss = 1.01032112, grad/param norm = 2.0777e-01, time/batch = 20.0338s	
15612/29850 (epoch 26.151), train_loss = 1.01268442, grad/param norm = 2.1654e-01, time/batch = 18.1240s	
15613/29850 (epoch 26.152), train_loss = 0.92184932, grad/param norm = 1.9143e-01, time/batch = 17.3035s	
15614/29850 (epoch 26.154), train_loss = 0.86924117, grad/param norm = 1.9097e-01, time/batch = 17.3078s	
15615/29850 (epoch 26.156), train_loss = 0.87464908, grad/param norm = 1.7868e-01, time/batch = 20.0226s	
15616/29850 (epoch 26.157), train_loss = 0.99345647, grad/param norm = 2.0449e-01, time/batch = 16.7887s	
15617/29850 (epoch 26.159), train_loss = 0.90253834, grad/param norm = 1.7872e-01, time/batch = 16.4580s	
15618/29850 (epoch 26.161), train_loss = 0.98259602, grad/param norm = 2.1608e-01, time/batch = 16.3953s	
15619/29850 (epoch 26.162), train_loss = 1.09551751, grad/param norm = 2.1569e-01, time/batch = 18.9560s	
15620/29850 (epoch 26.164), train_loss = 0.97300149, grad/param norm = 2.2322e-01, time/batch = 19.1180s	
15621/29850 (epoch 26.166), train_loss = 0.88968527, grad/param norm = 1.9082e-01, time/batch = 18.8748s	
15622/29850 (epoch 26.168), train_loss = 0.81672927, grad/param norm = 1.8377e-01, time/batch = 17.6906s	
15623/29850 (epoch 26.169), train_loss = 1.10070179, grad/param norm = 2.2602e-01, time/batch = 16.7988s	
15624/29850 (epoch 26.171), train_loss = 1.02833472, grad/param norm = 2.1507e-01, time/batch = 15.7291s	
15625/29850 (epoch 26.173), train_loss = 0.86840648, grad/param norm = 2.1013e-01, time/batch = 17.2973s	
15626/29850 (epoch 26.174), train_loss = 0.97305802, grad/param norm = 2.3759e-01, time/batch = 18.4444s	
15627/29850 (epoch 26.176), train_loss = 0.97044003, grad/param norm = 2.2277e-01, time/batch = 19.5403s	
15628/29850 (epoch 26.178), train_loss = 1.00810256, grad/param norm = 2.2156e-01, time/batch = 17.8849s	
15629/29850 (epoch 26.179), train_loss = 0.82717110, grad/param norm = 1.9170e-01, time/batch = 17.5545s	
15630/29850 (epoch 26.181), train_loss = 0.98845457, grad/param norm = 2.3084e-01, time/batch = 16.7905s	
15631/29850 (epoch 26.183), train_loss = 0.96534329, grad/param norm = 2.0092e-01, time/batch = 20.1245s	
15632/29850 (epoch 26.184), train_loss = 0.97842315, grad/param norm = 1.9460e-01, time/batch = 19.3709s	
15633/29850 (epoch 26.186), train_loss = 0.96417169, grad/param norm = 2.3503e-01, time/batch = 11.5718s	
15634/29850 (epoch 26.188), train_loss = 1.07187833, grad/param norm = 2.3978e-01, time/batch = 0.6999s	
15635/29850 (epoch 26.189), train_loss = 1.08106294, grad/param norm = 2.2425e-01, time/batch = 0.6589s	
15636/29850 (epoch 26.191), train_loss = 1.04176049, grad/param norm = 2.1431e-01, time/batch = 0.6543s	
15637/29850 (epoch 26.193), train_loss = 0.94469448, grad/param norm = 1.9007e-01, time/batch = 0.6634s	
15638/29850 (epoch 26.194), train_loss = 1.00484906, grad/param norm = 1.9958e-01, time/batch = 0.6691s	
15639/29850 (epoch 26.196), train_loss = 0.94972681, grad/param norm = 2.1871e-01, time/batch = 0.6683s	
15640/29850 (epoch 26.198), train_loss = 0.95182909, grad/param norm = 2.1847e-01, time/batch = 0.6690s	
15641/29850 (epoch 26.199), train_loss = 1.17126175, grad/param norm = 2.1031e-01, time/batch = 0.6715s	
15642/29850 (epoch 26.201), train_loss = 0.89691123, grad/param norm = 2.9570e-01, time/batch = 0.6746s	
15643/29850 (epoch 26.203), train_loss = 0.74893643, grad/param norm = 2.0420e-01, time/batch = 0.6692s	
15644/29850 (epoch 26.204), train_loss = 0.98213968, grad/param norm = 2.2079e-01, time/batch = 0.6739s	
15645/29850 (epoch 26.206), train_loss = 0.86046944, grad/param norm = 2.0225e-01, time/batch = 0.6637s	
15646/29850 (epoch 26.208), train_loss = 1.10179312, grad/param norm = 2.1421e-01, time/batch = 0.6541s	
15647/29850 (epoch 26.209), train_loss = 0.83668726, grad/param norm = 1.9581e-01, time/batch = 0.7487s	
15648/29850 (epoch 26.211), train_loss = 0.90695010, grad/param norm = 1.9275e-01, time/batch = 0.9755s	
15649/29850 (epoch 26.213), train_loss = 1.01604747, grad/param norm = 2.1475e-01, time/batch = 0.9635s	
15650/29850 (epoch 26.214), train_loss = 0.84550728, grad/param norm = 1.7886e-01, time/batch = 0.9691s	
15651/29850 (epoch 26.216), train_loss = 0.90317847, grad/param norm = 2.3068e-01, time/batch = 0.9875s	
15652/29850 (epoch 26.218), train_loss = 1.04004222, grad/param norm = 2.1551e-01, time/batch = 1.0721s	
15653/29850 (epoch 26.219), train_loss = 1.00404829, grad/param norm = 2.3203e-01, time/batch = 1.7822s	
15654/29850 (epoch 26.221), train_loss = 0.96029484, grad/param norm = 1.9961e-01, time/batch = 1.7881s	
15655/29850 (epoch 26.223), train_loss = 0.85661437, grad/param norm = 2.0888e-01, time/batch = 7.7804s	
15656/29850 (epoch 26.224), train_loss = 0.83599766, grad/param norm = 1.9988e-01, time/batch = 17.3956s	
15657/29850 (epoch 26.226), train_loss = 0.87889098, grad/param norm = 1.8580e-01, time/batch = 17.6853s	
15658/29850 (epoch 26.228), train_loss = 0.93573038, grad/param norm = 1.8590e-01, time/batch = 17.8107s	
15659/29850 (epoch 26.229), train_loss = 0.78501424, grad/param norm = 1.6886e-01, time/batch = 17.1357s	
15660/29850 (epoch 26.231), train_loss = 0.96208163, grad/param norm = 2.0610e-01, time/batch = 17.9431s	
15661/29850 (epoch 26.233), train_loss = 0.94363444, grad/param norm = 2.1769e-01, time/batch = 16.4607s	
15662/29850 (epoch 26.235), train_loss = 0.86959120, grad/param norm = 1.9034e-01, time/batch = 19.1252s	
15663/29850 (epoch 26.236), train_loss = 1.06428695, grad/param norm = 2.6906e-01, time/batch = 19.3011s	
15664/29850 (epoch 26.238), train_loss = 0.84765457, grad/param norm = 1.9628e-01, time/batch = 17.4493s	
15665/29850 (epoch 26.240), train_loss = 0.80706847, grad/param norm = 1.8427e-01, time/batch = 18.6445s	
15666/29850 (epoch 26.241), train_loss = 1.00719728, grad/param norm = 2.5335e-01, time/batch = 15.7934s	
15667/29850 (epoch 26.243), train_loss = 0.99604930, grad/param norm = 2.1756e-01, time/batch = 17.1276s	
15668/29850 (epoch 26.245), train_loss = 0.87522060, grad/param norm = 1.9882e-01, time/batch = 16.3607s	
15669/29850 (epoch 26.246), train_loss = 0.82759651, grad/param norm = 1.7133e-01, time/batch = 19.7115s	
15670/29850 (epoch 26.248), train_loss = 0.80596233, grad/param norm = 1.6600e-01, time/batch = 18.3609s	
15671/29850 (epoch 26.250), train_loss = 0.91162728, grad/param norm = 1.8150e-01, time/batch = 15.1923s	
15672/29850 (epoch 26.251), train_loss = 0.80297620, grad/param norm = 1.8948e-01, time/batch = 19.3685s	
15673/29850 (epoch 26.253), train_loss = 0.75338444, grad/param norm = 2.0060e-01, time/batch = 18.6261s	
15674/29850 (epoch 26.255), train_loss = 0.85941529, grad/param norm = 1.9360e-01, time/batch = 16.3634s	
15675/29850 (epoch 26.256), train_loss = 0.98871984, grad/param norm = 2.0046e-01, time/batch = 16.2883s	
15676/29850 (epoch 26.258), train_loss = 0.95932760, grad/param norm = 2.0537e-01, time/batch = 16.5551s	
15677/29850 (epoch 26.260), train_loss = 0.91703300, grad/param norm = 1.9259e-01, time/batch = 17.1320s	
15678/29850 (epoch 26.261), train_loss = 0.86988140, grad/param norm = 2.1370e-01, time/batch = 17.3641s	
15679/29850 (epoch 26.263), train_loss = 0.85119231, grad/param norm = 2.0613e-01, time/batch = 18.7271s	
15680/29850 (epoch 26.265), train_loss = 0.91282630, grad/param norm = 1.9804e-01, time/batch = 18.9666s	
15681/29850 (epoch 26.266), train_loss = 0.93505056, grad/param norm = 2.0849e-01, time/batch = 19.1851s	
15682/29850 (epoch 26.268), train_loss = 0.86567827, grad/param norm = 1.7423e-01, time/batch = 18.0508s	
15683/29850 (epoch 26.270), train_loss = 0.87583780, grad/param norm = 2.0125e-01, time/batch = 16.2067s	
15684/29850 (epoch 26.271), train_loss = 0.99378923, grad/param norm = 2.0537e-01, time/batch = 16.1058s	
15685/29850 (epoch 26.273), train_loss = 0.83298616, grad/param norm = 2.1284e-01, time/batch = 15.6594s	
15686/29850 (epoch 26.275), train_loss = 0.80433258, grad/param norm = 1.9282e-01, time/batch = 16.9804s	
15687/29850 (epoch 26.276), train_loss = 0.81716439, grad/param norm = 1.7724e-01, time/batch = 18.6082s	
15688/29850 (epoch 26.278), train_loss = 0.87666687, grad/param norm = 1.9570e-01, time/batch = 17.1895s	
15689/29850 (epoch 26.280), train_loss = 1.08489907, grad/param norm = 2.8944e-01, time/batch = 17.9731s	
15690/29850 (epoch 26.281), train_loss = 0.96620673, grad/param norm = 2.0743e-01, time/batch = 16.7286s	
15691/29850 (epoch 26.283), train_loss = 1.08122240, grad/param norm = 2.6769e-01, time/batch = 17.7819s	
15692/29850 (epoch 26.285), train_loss = 0.97409607, grad/param norm = 2.1154e-01, time/batch = 18.4789s	
15693/29850 (epoch 26.286), train_loss = 1.03354195, grad/param norm = 2.2282e-01, time/batch = 17.0561s	
15694/29850 (epoch 26.288), train_loss = 1.07423189, grad/param norm = 2.7707e-01, time/batch = 16.8425s	
15695/29850 (epoch 26.290), train_loss = 0.97462552, grad/param norm = 2.2137e-01, time/batch = 17.9443s	
15696/29850 (epoch 26.291), train_loss = 1.15166671, grad/param norm = 2.1735e-01, time/batch = 18.8848s	
15697/29850 (epoch 26.293), train_loss = 1.05703038, grad/param norm = 2.2856e-01, time/batch = 17.7993s	
15698/29850 (epoch 26.295), train_loss = 1.11435336, grad/param norm = 2.2380e-01, time/batch = 19.5942s	
15699/29850 (epoch 26.296), train_loss = 0.85748854, grad/param norm = 2.0320e-01, time/batch = 17.3855s	
15700/29850 (epoch 26.298), train_loss = 0.73865700, grad/param norm = 1.7241e-01, time/batch = 17.9683s	
15701/29850 (epoch 26.300), train_loss = 0.82493317, grad/param norm = 1.7824e-01, time/batch = 15.8592s	
15702/29850 (epoch 26.302), train_loss = 0.81784654, grad/param norm = 2.1892e-01, time/batch = 19.4571s	
15703/29850 (epoch 26.303), train_loss = 0.87219845, grad/param norm = 1.8025e-01, time/batch = 18.8075s	
15704/29850 (epoch 26.305), train_loss = 0.98210378, grad/param norm = 1.9800e-01, time/batch = 17.0343s	
15705/29850 (epoch 26.307), train_loss = 1.03890095, grad/param norm = 1.9358e-01, time/batch = 17.4824s	
15706/29850 (epoch 26.308), train_loss = 0.85982190, grad/param norm = 2.2506e-01, time/batch = 16.5549s	
15707/29850 (epoch 26.310), train_loss = 0.97413623, grad/param norm = 2.1943e-01, time/batch = 19.4753s	
15708/29850 (epoch 26.312), train_loss = 1.01039687, grad/param norm = 1.9021e-01, time/batch = 17.6151s	
15709/29850 (epoch 26.313), train_loss = 0.94604870, grad/param norm = 2.1202e-01, time/batch = 15.4658s	
15710/29850 (epoch 26.315), train_loss = 0.95979816, grad/param norm = 2.0913e-01, time/batch = 15.4309s	
15711/29850 (epoch 26.317), train_loss = 0.94603792, grad/param norm = 2.1338e-01, time/batch = 17.5275s	
15712/29850 (epoch 26.318), train_loss = 0.92634574, grad/param norm = 2.0282e-01, time/batch = 19.0483s	
15713/29850 (epoch 26.320), train_loss = 0.87544659, grad/param norm = 1.7958e-01, time/batch = 18.8816s	
15714/29850 (epoch 26.322), train_loss = 1.09277479, grad/param norm = 2.1163e-01, time/batch = 18.0447s	
15715/29850 (epoch 26.323), train_loss = 0.98816765, grad/param norm = 2.2484e-01, time/batch = 17.9647s	
15716/29850 (epoch 26.325), train_loss = 1.04338441, grad/param norm = 2.0956e-01, time/batch = 18.6262s	
15717/29850 (epoch 26.327), train_loss = 1.15545694, grad/param norm = 2.2874e-01, time/batch = 18.7246s	
15718/29850 (epoch 26.328), train_loss = 1.08059155, grad/param norm = 2.4072e-01, time/batch = 17.6845s	
15719/29850 (epoch 26.330), train_loss = 0.99893693, grad/param norm = 1.9680e-01, time/batch = 17.9779s	
15720/29850 (epoch 26.332), train_loss = 0.92381284, grad/param norm = 2.0593e-01, time/batch = 18.8810s	
15721/29850 (epoch 26.333), train_loss = 1.01341443, grad/param norm = 2.1211e-01, time/batch = 16.7925s	
15722/29850 (epoch 26.335), train_loss = 1.07717196, grad/param norm = 2.1234e-01, time/batch = 18.1320s	
15723/29850 (epoch 26.337), train_loss = 0.97151701, grad/param norm = 1.9405e-01, time/batch = 16.2194s	
15724/29850 (epoch 26.338), train_loss = 0.96331954, grad/param norm = 1.8677e-01, time/batch = 17.6072s	
15725/29850 (epoch 26.340), train_loss = 0.83663933, grad/param norm = 1.7934e-01, time/batch = 17.7738s	
15726/29850 (epoch 26.342), train_loss = 0.96370841, grad/param norm = 2.2612e-01, time/batch = 19.3874s	
15727/29850 (epoch 26.343), train_loss = 0.98722060, grad/param norm = 2.4979e-01, time/batch = 15.4603s	
15728/29850 (epoch 26.345), train_loss = 1.03680115, grad/param norm = 2.4975e-01, time/batch = 16.0384s	
15729/29850 (epoch 26.347), train_loss = 1.07891001, grad/param norm = 2.2749e-01, time/batch = 19.4602s	
15730/29850 (epoch 26.348), train_loss = 0.92511795, grad/param norm = 2.0221e-01, time/batch = 17.7309s	
15731/29850 (epoch 26.350), train_loss = 1.04368599, grad/param norm = 2.6362e-01, time/batch = 17.9684s	
15732/29850 (epoch 26.352), train_loss = 0.91135604, grad/param norm = 2.1206e-01, time/batch = 18.6383s	
15733/29850 (epoch 26.353), train_loss = 1.03398224, grad/param norm = 2.2895e-01, time/batch = 17.1450s	
15734/29850 (epoch 26.355), train_loss = 0.91011036, grad/param norm = 2.0566e-01, time/batch = 18.3060s	
15735/29850 (epoch 26.357), train_loss = 1.06258883, grad/param norm = 1.9518e-01, time/batch = 18.2938s	
15736/29850 (epoch 26.358), train_loss = 0.88633011, grad/param norm = 1.9625e-01, time/batch = 17.9821s	
15737/29850 (epoch 26.360), train_loss = 0.92044487, grad/param norm = 1.8992e-01, time/batch = 14.9868s	
15738/29850 (epoch 26.362), train_loss = 0.94719567, grad/param norm = 2.2662e-01, time/batch = 16.9559s	
15739/29850 (epoch 26.363), train_loss = 0.98293123, grad/param norm = 2.0892e-01, time/batch = 15.9570s	
15740/29850 (epoch 26.365), train_loss = 1.09700923, grad/param norm = 2.1901e-01, time/batch = 17.5619s	
15741/29850 (epoch 26.367), train_loss = 0.89720246, grad/param norm = 2.0989e-01, time/batch = 17.7157s	
15742/29850 (epoch 26.369), train_loss = 0.83592289, grad/param norm = 2.1428e-01, time/batch = 19.1011s	
15743/29850 (epoch 26.370), train_loss = 0.77857573, grad/param norm = 1.9414e-01, time/batch = 17.6878s	
15744/29850 (epoch 26.372), train_loss = 1.04547619, grad/param norm = 2.2340e-01, time/batch = 15.8766s	
15745/29850 (epoch 26.374), train_loss = 0.99997628, grad/param norm = 2.1756e-01, time/batch = 16.3529s	
15746/29850 (epoch 26.375), train_loss = 0.96880979, grad/param norm = 1.9924e-01, time/batch = 19.4759s	
15747/29850 (epoch 26.377), train_loss = 0.90409848, grad/param norm = 2.0573e-01, time/batch = 18.1352s	
15748/29850 (epoch 26.379), train_loss = 1.07051753, grad/param norm = 2.3436e-01, time/batch = 17.6995s	
15749/29850 (epoch 26.380), train_loss = 1.02213253, grad/param norm = 2.2107e-01, time/batch = 17.5594s	
15750/29850 (epoch 26.382), train_loss = 0.99820301, grad/param norm = 2.2763e-01, time/batch = 19.3814s	
15751/29850 (epoch 26.384), train_loss = 1.05009137, grad/param norm = 2.1557e-01, time/batch = 18.2002s	
15752/29850 (epoch 26.385), train_loss = 0.97650569, grad/param norm = 2.1126e-01, time/batch = 18.6196s	
15753/29850 (epoch 26.387), train_loss = 1.01215133, grad/param norm = 2.2949e-01, time/batch = 17.3770s	
15754/29850 (epoch 26.389), train_loss = 1.09193736, grad/param norm = 2.1850e-01, time/batch = 17.0342s	
15755/29850 (epoch 26.390), train_loss = 1.02526192, grad/param norm = 1.9678e-01, time/batch = 16.9463s	
15756/29850 (epoch 26.392), train_loss = 0.94058349, grad/param norm = 2.0317e-01, time/batch = 17.6183s	
15757/29850 (epoch 26.394), train_loss = 1.04138141, grad/param norm = 1.9737e-01, time/batch = 17.4686s	
15758/29850 (epoch 26.395), train_loss = 0.94156586, grad/param norm = 2.3380e-01, time/batch = 16.8848s	
15759/29850 (epoch 26.397), train_loss = 0.85740987, grad/param norm = 2.2314e-01, time/batch = 18.5278s	
15760/29850 (epoch 26.399), train_loss = 0.87554952, grad/param norm = 1.8239e-01, time/batch = 17.9618s	
15761/29850 (epoch 26.400), train_loss = 1.24889030, grad/param norm = 2.3138e-01, time/batch = 17.2849s	
15762/29850 (epoch 26.402), train_loss = 1.14148663, grad/param norm = 2.2186e-01, time/batch = 18.4979s	
15763/29850 (epoch 26.404), train_loss = 1.00256657, grad/param norm = 2.0619e-01, time/batch = 17.8849s	
15764/29850 (epoch 26.405), train_loss = 0.90925651, grad/param norm = 2.0669e-01, time/batch = 19.6293s	
15765/29850 (epoch 26.407), train_loss = 0.89045329, grad/param norm = 2.1179e-01, time/batch = 17.2828s	
15766/29850 (epoch 26.409), train_loss = 1.01908474, grad/param norm = 2.3692e-01, time/batch = 19.2975s	
15767/29850 (epoch 26.410), train_loss = 1.11582143, grad/param norm = 2.8365e-01, time/batch = 17.3806s	
15768/29850 (epoch 26.412), train_loss = 1.08273756, grad/param norm = 2.1621e-01, time/batch = 16.8744s	
15769/29850 (epoch 26.414), train_loss = 0.97833505, grad/param norm = 2.1687e-01, time/batch = 19.2098s	
15770/29850 (epoch 26.415), train_loss = 0.97465298, grad/param norm = 2.0802e-01, time/batch = 15.9593s	
15771/29850 (epoch 26.417), train_loss = 1.11291542, grad/param norm = 2.3508e-01, time/batch = 18.2758s	
15772/29850 (epoch 26.419), train_loss = 0.96479090, grad/param norm = 1.9576e-01, time/batch = 17.8524s	
15773/29850 (epoch 26.420), train_loss = 0.96637721, grad/param norm = 1.9749e-01, time/batch = 17.3007s	
15774/29850 (epoch 26.422), train_loss = 0.96087306, grad/param norm = 2.0446e-01, time/batch = 17.8069s	
15775/29850 (epoch 26.424), train_loss = 0.88785610, grad/param norm = 2.0189e-01, time/batch = 16.4757s	
15776/29850 (epoch 26.425), train_loss = 1.06515171, grad/param norm = 2.1500e-01, time/batch = 20.0260s	
15777/29850 (epoch 26.427), train_loss = 0.80593683, grad/param norm = 2.0840e-01, time/batch = 16.4599s	
15778/29850 (epoch 26.429), train_loss = 0.86315614, grad/param norm = 2.3105e-01, time/batch = 17.7020s	
15779/29850 (epoch 26.430), train_loss = 0.80983885, grad/param norm = 1.7768e-01, time/batch = 19.1969s	
15780/29850 (epoch 26.432), train_loss = 0.92652751, grad/param norm = 2.2452e-01, time/batch = 17.1031s	
15781/29850 (epoch 26.434), train_loss = 0.84722517, grad/param norm = 1.7674e-01, time/batch = 19.3025s	
15782/29850 (epoch 26.436), train_loss = 0.97104541, grad/param norm = 2.3034e-01, time/batch = 17.2865s	
15783/29850 (epoch 26.437), train_loss = 1.01458809, grad/param norm = 1.9037e-01, time/batch = 19.4492s	
15784/29850 (epoch 26.439), train_loss = 0.98801638, grad/param norm = 2.0452e-01, time/batch = 18.8090s	
15785/29850 (epoch 26.441), train_loss = 0.97599346, grad/param norm = 2.1281e-01, time/batch = 17.2885s	
15786/29850 (epoch 26.442), train_loss = 0.96711342, grad/param norm = 1.9467e-01, time/batch = 17.4641s	
15787/29850 (epoch 26.444), train_loss = 1.00157543, grad/param norm = 2.0562e-01, time/batch = 18.8164s	
15788/29850 (epoch 26.446), train_loss = 1.03597552, grad/param norm = 2.2724e-01, time/batch = 16.5242s	
15789/29850 (epoch 26.447), train_loss = 1.05845252, grad/param norm = 2.2469e-01, time/batch = 15.0302s	
15790/29850 (epoch 26.449), train_loss = 0.98045597, grad/param norm = 2.2300e-01, time/batch = 17.5595s	
15791/29850 (epoch 26.451), train_loss = 0.78518101, grad/param norm = 1.8442e-01, time/batch = 18.1425s	
15792/29850 (epoch 26.452), train_loss = 0.70806274, grad/param norm = 1.6418e-01, time/batch = 16.2645s	
15793/29850 (epoch 26.454), train_loss = 0.80510318, grad/param norm = 1.8170e-01, time/batch = 19.0508s	
15794/29850 (epoch 26.456), train_loss = 1.00957600, grad/param norm = 2.0423e-01, time/batch = 17.3718s	
15795/29850 (epoch 26.457), train_loss = 1.01116441, grad/param norm = 2.5510e-01, time/batch = 18.2951s	
15796/29850 (epoch 26.459), train_loss = 1.11465783, grad/param norm = 2.2419e-01, time/batch = 18.6150s	
15797/29850 (epoch 26.461), train_loss = 1.09144200, grad/param norm = 1.9623e-01, time/batch = 17.9610s	
15798/29850 (epoch 26.462), train_loss = 1.10224109, grad/param norm = 2.4499e-01, time/batch = 16.7249s	
15799/29850 (epoch 26.464), train_loss = 1.04056132, grad/param norm = 2.3650e-01, time/batch = 17.4816s	
15800/29850 (epoch 26.466), train_loss = 0.83998827, grad/param norm = 2.0076e-01, time/batch = 17.3806s	
15801/29850 (epoch 26.467), train_loss = 0.94023660, grad/param norm = 2.3886e-01, time/batch = 18.0339s	
15802/29850 (epoch 26.469), train_loss = 0.95147664, grad/param norm = 2.2293e-01, time/batch = 15.7326s	
15803/29850 (epoch 26.471), train_loss = 0.94445768, grad/param norm = 2.0229e-01, time/batch = 17.5528s	
15804/29850 (epoch 26.472), train_loss = 0.89852593, grad/param norm = 1.8436e-01, time/batch = 19.7116s	
15805/29850 (epoch 26.474), train_loss = 1.05111464, grad/param norm = 2.0153e-01, time/batch = 17.0414s	
15806/29850 (epoch 26.476), train_loss = 0.96078529, grad/param norm = 1.8496e-01, time/batch = 18.4644s	
15807/29850 (epoch 26.477), train_loss = 0.99090549, grad/param norm = 2.2781e-01, time/batch = 16.1174s	
15808/29850 (epoch 26.479), train_loss = 1.15505486, grad/param norm = 2.1687e-01, time/batch = 17.8214s	
15809/29850 (epoch 26.481), train_loss = 0.92779086, grad/param norm = 2.0885e-01, time/batch = 17.6296s	
15810/29850 (epoch 26.482), train_loss = 0.87062045, grad/param norm = 1.7894e-01, time/batch = 18.3895s	
15811/29850 (epoch 26.484), train_loss = 0.93098322, grad/param norm = 2.0555e-01, time/batch = 16.7069s	
15812/29850 (epoch 26.486), train_loss = 0.99154462, grad/param norm = 2.0835e-01, time/batch = 16.6380s	
15813/29850 (epoch 26.487), train_loss = 0.97950135, grad/param norm = 2.1682e-01, time/batch = 16.1200s	
15814/29850 (epoch 26.489), train_loss = 0.94494429, grad/param norm = 1.9914e-01, time/batch = 18.4603s	
15815/29850 (epoch 26.491), train_loss = 0.86342538, grad/param norm = 1.8308e-01, time/batch = 18.7030s	
15816/29850 (epoch 26.492), train_loss = 0.96226001, grad/param norm = 2.0009e-01, time/batch = 20.1942s	
15817/29850 (epoch 26.494), train_loss = 1.04748101, grad/param norm = 2.1683e-01, time/batch = 16.7214s	
15818/29850 (epoch 26.496), train_loss = 1.13213350, grad/param norm = 2.0843e-01, time/batch = 18.8894s	
15819/29850 (epoch 26.497), train_loss = 0.99825128, grad/param norm = 1.9037e-01, time/batch = 17.7726s	
15820/29850 (epoch 26.499), train_loss = 0.98400176, grad/param norm = 2.1467e-01, time/batch = 18.0489s	
15821/29850 (epoch 26.501), train_loss = 0.89992944, grad/param norm = 2.3066e-01, time/batch = 19.6088s	
15822/29850 (epoch 26.503), train_loss = 1.00058078, grad/param norm = 2.1151e-01, time/batch = 17.2834s	
15823/29850 (epoch 26.504), train_loss = 1.17817081, grad/param norm = 2.1966e-01, time/batch = 19.8786s	
15824/29850 (epoch 26.506), train_loss = 1.12787179, grad/param norm = 2.2147e-01, time/batch = 17.1337s	
15825/29850 (epoch 26.508), train_loss = 0.98807338, grad/param norm = 1.8422e-01, time/batch = 17.1347s	
15826/29850 (epoch 26.509), train_loss = 0.78930957, grad/param norm = 1.7041e-01, time/batch = 17.4659s	
15827/29850 (epoch 26.511), train_loss = 0.99734663, grad/param norm = 1.9736e-01, time/batch = 20.1950s	
15828/29850 (epoch 26.513), train_loss = 0.99351469, grad/param norm = 2.4390e-01, time/batch = 17.3682s	
15829/29850 (epoch 26.514), train_loss = 0.88684053, grad/param norm = 2.1579e-01, time/batch = 18.8038s	
15830/29850 (epoch 26.516), train_loss = 0.92229574, grad/param norm = 1.7601e-01, time/batch = 18.6972s	
15831/29850 (epoch 26.518), train_loss = 0.79667891, grad/param norm = 1.9149e-01, time/batch = 19.6974s	
15832/29850 (epoch 26.519), train_loss = 0.79749150, grad/param norm = 1.7042e-01, time/batch = 16.8757s	
15833/29850 (epoch 26.521), train_loss = 0.73533575, grad/param norm = 1.8310e-01, time/batch = 17.4493s	
15834/29850 (epoch 26.523), train_loss = 0.79355665, grad/param norm = 1.6659e-01, time/batch = 16.3870s	
15835/29850 (epoch 26.524), train_loss = 0.87946668, grad/param norm = 2.1530e-01, time/batch = 16.0129s	
15836/29850 (epoch 26.526), train_loss = 0.96401090, grad/param norm = 2.1231e-01, time/batch = 17.2888s	
15837/29850 (epoch 26.528), train_loss = 1.06323953, grad/param norm = 2.3938e-01, time/batch = 18.8744s	
15838/29850 (epoch 26.529), train_loss = 1.00016948, grad/param norm = 2.2687e-01, time/batch = 19.5177s	
15839/29850 (epoch 26.531), train_loss = 0.94855900, grad/param norm = 2.1638e-01, time/batch = 17.2096s	
15840/29850 (epoch 26.533), train_loss = 0.93651328, grad/param norm = 2.0238e-01, time/batch = 17.0168s	
15841/29850 (epoch 26.534), train_loss = 1.00424803, grad/param norm = 2.1822e-01, time/batch = 16.8856s	
15842/29850 (epoch 26.536), train_loss = 0.88632100, grad/param norm = 1.9223e-01, time/batch = 17.1040s	
15843/29850 (epoch 26.538), train_loss = 1.08298798, grad/param norm = 2.3269e-01, time/batch = 17.9651s	
15844/29850 (epoch 26.539), train_loss = 1.13022557, grad/param norm = 2.3485e-01, time/batch = 16.1444s	
15845/29850 (epoch 26.541), train_loss = 0.72552238, grad/param norm = 1.8398e-01, time/batch = 17.3553s	
15846/29850 (epoch 26.543), train_loss = 0.94909180, grad/param norm = 2.0980e-01, time/batch = 17.5580s	
15847/29850 (epoch 26.544), train_loss = 1.01476543, grad/param norm = 2.0072e-01, time/batch = 17.4575s	
15848/29850 (epoch 26.546), train_loss = 1.04969517, grad/param norm = 2.1267e-01, time/batch = 18.6218s	
15849/29850 (epoch 26.548), train_loss = 0.84114858, grad/param norm = 2.0205e-01, time/batch = 17.4586s	
15850/29850 (epoch 26.549), train_loss = 0.91374429, grad/param norm = 1.9296e-01, time/batch = 17.7191s	
15851/29850 (epoch 26.551), train_loss = 0.80713031, grad/param norm = 1.6172e-01, time/batch = 18.6358s	
15852/29850 (epoch 26.553), train_loss = 0.93266986, grad/param norm = 1.9837e-01, time/batch = 17.7838s	
15853/29850 (epoch 26.554), train_loss = 0.81780499, grad/param norm = 1.9272e-01, time/batch = 17.9590s	
15854/29850 (epoch 26.556), train_loss = 0.83661091, grad/param norm = 1.7956e-01, time/batch = 18.3038s	
15855/29850 (epoch 26.558), train_loss = 0.84680499, grad/param norm = 1.7782e-01, time/batch = 20.1697s	
15856/29850 (epoch 26.559), train_loss = 0.92008371, grad/param norm = 2.1497e-01, time/batch = 30.4850s	
15857/29850 (epoch 26.561), train_loss = 1.00924290, grad/param norm = 2.1533e-01, time/batch = 14.9590s	
15858/29850 (epoch 26.563), train_loss = 0.97868455, grad/param norm = 2.1911e-01, time/batch = 16.4320s	
15859/29850 (epoch 26.564), train_loss = 0.92105012, grad/param norm = 2.2287e-01, time/batch = 19.0535s	
15860/29850 (epoch 26.566), train_loss = 0.97687400, grad/param norm = 2.1528e-01, time/batch = 17.5491s	
15861/29850 (epoch 26.568), train_loss = 1.04524596, grad/param norm = 2.1204e-01, time/batch = 17.9423s	
15862/29850 (epoch 26.570), train_loss = 0.98533609, grad/param norm = 2.1408e-01, time/batch = 17.7997s	
15863/29850 (epoch 26.571), train_loss = 1.04465567, grad/param norm = 2.1334e-01, time/batch = 19.7882s	
15864/29850 (epoch 26.573), train_loss = 1.12088454, grad/param norm = 2.4946e-01, time/batch = 19.3836s	
15865/29850 (epoch 26.575), train_loss = 1.11075249, grad/param norm = 2.2649e-01, time/batch = 18.0208s	
15866/29850 (epoch 26.576), train_loss = 1.07791979, grad/param norm = 2.5215e-01, time/batch = 16.3615s	
15867/29850 (epoch 26.578), train_loss = 0.91777549, grad/param norm = 2.4776e-01, time/batch = 18.3009s	
15868/29850 (epoch 26.580), train_loss = 1.06412092, grad/param norm = 2.0642e-01, time/batch = 16.2145s	
15869/29850 (epoch 26.581), train_loss = 0.87559867, grad/param norm = 1.9025e-01, time/batch = 16.1230s	
15870/29850 (epoch 26.583), train_loss = 0.97017290, grad/param norm = 2.1032e-01, time/batch = 19.1164s	
15871/29850 (epoch 26.585), train_loss = 0.99584674, grad/param norm = 2.1835e-01, time/batch = 17.9536s	
15872/29850 (epoch 26.586), train_loss = 0.99021052, grad/param norm = 2.1749e-01, time/batch = 17.0337s	
15873/29850 (epoch 26.588), train_loss = 0.91795806, grad/param norm = 2.0276e-01, time/batch = 18.4694s	
15874/29850 (epoch 26.590), train_loss = 0.94979844, grad/param norm = 2.1477e-01, time/batch = 16.6104s	
15875/29850 (epoch 26.591), train_loss = 0.94714255, grad/param norm = 2.2751e-01, time/batch = 17.2029s	
15876/29850 (epoch 26.593), train_loss = 0.88639459, grad/param norm = 1.8991e-01, time/batch = 18.2926s	
15877/29850 (epoch 26.595), train_loss = 0.84317095, grad/param norm = 1.6920e-01, time/batch = 17.7957s	
15878/29850 (epoch 26.596), train_loss = 0.82709466, grad/param norm = 1.9035e-01, time/batch = 17.9606s	
15879/29850 (epoch 26.598), train_loss = 0.94232470, grad/param norm = 1.9175e-01, time/batch = 18.1360s	
15880/29850 (epoch 26.600), train_loss = 0.98507189, grad/param norm = 2.1202e-01, time/batch = 17.8129s	
15881/29850 (epoch 26.601), train_loss = 0.82077377, grad/param norm = 1.7302e-01, time/batch = 18.6342s	
15882/29850 (epoch 26.603), train_loss = 0.88841155, grad/param norm = 1.8517e-01, time/batch = 18.3762s	
15883/29850 (epoch 26.605), train_loss = 0.93941810, grad/param norm = 2.1150e-01, time/batch = 16.4637s	
15884/29850 (epoch 26.606), train_loss = 0.70455418, grad/param norm = 1.7336e-01, time/batch = 19.1422s	
15885/29850 (epoch 26.608), train_loss = 0.85911054, grad/param norm = 1.8007e-01, time/batch = 16.2990s	
15886/29850 (epoch 26.610), train_loss = 0.93710017, grad/param norm = 2.0884e-01, time/batch = 19.1201s	
15887/29850 (epoch 26.611), train_loss = 0.86151457, grad/param norm = 1.9710e-01, time/batch = 19.4641s	
15888/29850 (epoch 26.613), train_loss = 0.71810619, grad/param norm = 1.8779e-01, time/batch = 17.0500s	
15889/29850 (epoch 26.615), train_loss = 0.83662759, grad/param norm = 1.8694e-01, time/batch = 17.6382s	
15890/29850 (epoch 26.616), train_loss = 0.85414247, grad/param norm = 2.5604e-01, time/batch = 16.5900s	
15891/29850 (epoch 26.618), train_loss = 0.91112739, grad/param norm = 2.1572e-01, time/batch = 18.8386s	
15892/29850 (epoch 26.620), train_loss = 0.95321517, grad/param norm = 1.9942e-01, time/batch = 16.1170s	
15893/29850 (epoch 26.621), train_loss = 1.08162496, grad/param norm = 2.1568e-01, time/batch = 17.8625s	
15894/29850 (epoch 26.623), train_loss = 1.02001190, grad/param norm = 2.2524e-01, time/batch = 17.2994s	
15895/29850 (epoch 26.625), train_loss = 0.98356122, grad/param norm = 2.8445e-01, time/batch = 16.9690s	
15896/29850 (epoch 26.626), train_loss = 0.99510931, grad/param norm = 2.1931e-01, time/batch = 18.1372s	
15897/29850 (epoch 26.628), train_loss = 0.89524853, grad/param norm = 2.2036e-01, time/batch = 19.3014s	
15898/29850 (epoch 26.630), train_loss = 0.95879610, grad/param norm = 2.2871e-01, time/batch = 15.8844s	
15899/29850 (epoch 26.631), train_loss = 0.94210609, grad/param norm = 1.9709e-01, time/batch = 18.3673s	
15900/29850 (epoch 26.633), train_loss = 1.00456165, grad/param norm = 3.1533e-01, time/batch = 19.0518s	
15901/29850 (epoch 26.635), train_loss = 0.91727809, grad/param norm = 2.1235e-01, time/batch = 18.7865s	
15902/29850 (epoch 26.637), train_loss = 0.86427443, grad/param norm = 1.9933e-01, time/batch = 16.8520s	
15903/29850 (epoch 26.638), train_loss = 0.99035536, grad/param norm = 2.0950e-01, time/batch = 19.7046s	
15904/29850 (epoch 26.640), train_loss = 1.09171551, grad/param norm = 2.2935e-01, time/batch = 18.3928s	
15905/29850 (epoch 26.642), train_loss = 0.86798286, grad/param norm = 1.8714e-01, time/batch = 16.2837s	
15906/29850 (epoch 26.643), train_loss = 0.87085158, grad/param norm = 2.2022e-01, time/batch = 18.1410s	
15907/29850 (epoch 26.645), train_loss = 0.91648563, grad/param norm = 2.0198e-01, time/batch = 15.8975s	
15908/29850 (epoch 26.647), train_loss = 1.08733750, grad/param norm = 2.5896e-01, time/batch = 14.5718s	
15909/29850 (epoch 26.648), train_loss = 0.84227762, grad/param norm = 1.8239e-01, time/batch = 17.9608s	
15910/29850 (epoch 26.650), train_loss = 0.97338963, grad/param norm = 2.1675e-01, time/batch = 19.0267s	
15911/29850 (epoch 26.652), train_loss = 0.95833093, grad/param norm = 2.2197e-01, time/batch = 15.6905s	
15912/29850 (epoch 26.653), train_loss = 1.06364524, grad/param norm = 2.4286e-01, time/batch = 16.5290s	
15913/29850 (epoch 26.655), train_loss = 0.93793126, grad/param norm = 1.8466e-01, time/batch = 17.7880s	
15914/29850 (epoch 26.657), train_loss = 0.91727876, grad/param norm = 2.0705e-01, time/batch = 18.8739s	
15915/29850 (epoch 26.658), train_loss = 1.06832357, grad/param norm = 2.2552e-01, time/batch = 18.2866s	
15916/29850 (epoch 26.660), train_loss = 0.94890787, grad/param norm = 2.2260e-01, time/batch = 18.6380s	
15917/29850 (epoch 26.662), train_loss = 1.04474462, grad/param norm = 2.5185e-01, time/batch = 19.0109s	
15918/29850 (epoch 26.663), train_loss = 1.15441867, grad/param norm = 2.3775e-01, time/batch = 18.2832s	
15919/29850 (epoch 26.665), train_loss = 1.09872723, grad/param norm = 2.3180e-01, time/batch = 17.4681s	
15920/29850 (epoch 26.667), train_loss = 1.00693781, grad/param norm = 2.9743e-01, time/batch = 19.1438s	
15921/29850 (epoch 26.668), train_loss = 0.93162016, grad/param norm = 2.2980e-01, time/batch = 17.6893s	
15922/29850 (epoch 26.670), train_loss = 1.10187729, grad/param norm = 2.8699e-01, time/batch = 16.7994s	
15923/29850 (epoch 26.672), train_loss = 1.07558877, grad/param norm = 2.3677e-01, time/batch = 15.9788s	
15924/29850 (epoch 26.673), train_loss = 1.00728419, grad/param norm = 2.1798e-01, time/batch = 17.3677s	
15925/29850 (epoch 26.675), train_loss = 0.84641679, grad/param norm = 1.9006e-01, time/batch = 16.8606s	
15926/29850 (epoch 26.677), train_loss = 0.91155017, grad/param norm = 1.9612e-01, time/batch = 16.2940s	
15927/29850 (epoch 26.678), train_loss = 0.93364895, grad/param norm = 1.9689e-01, time/batch = 18.3869s	
15928/29850 (epoch 26.680), train_loss = 0.95972730, grad/param norm = 2.0829e-01, time/batch = 17.0345s	
15929/29850 (epoch 26.682), train_loss = 0.99416423, grad/param norm = 2.3417e-01, time/batch = 16.9511s	
15930/29850 (epoch 26.683), train_loss = 1.08813759, grad/param norm = 2.4814e-01, time/batch = 19.1295s	
15931/29850 (epoch 26.685), train_loss = 1.12132806, grad/param norm = 2.0822e-01, time/batch = 19.6280s	
15932/29850 (epoch 26.687), train_loss = 1.00113423, grad/param norm = 2.0022e-01, time/batch = 18.6940s	
15933/29850 (epoch 26.688), train_loss = 0.86225525, grad/param norm = 1.9675e-01, time/batch = 17.6896s	
15934/29850 (epoch 26.690), train_loss = 0.83232601, grad/param norm = 1.8517e-01, time/batch = 17.7732s	
15935/29850 (epoch 26.692), train_loss = 1.06306090, grad/param norm = 2.2145e-01, time/batch = 17.7171s	
15936/29850 (epoch 26.693), train_loss = 0.93860195, grad/param norm = 1.9263e-01, time/batch = 19.1270s	
15937/29850 (epoch 26.695), train_loss = 0.83031334, grad/param norm = 1.7462e-01, time/batch = 17.3933s	
15938/29850 (epoch 26.697), train_loss = 0.95566133, grad/param norm = 2.0625e-01, time/batch = 19.0381s	
15939/29850 (epoch 26.698), train_loss = 1.07737505, grad/param norm = 2.0220e-01, time/batch = 17.4435s	
15940/29850 (epoch 26.700), train_loss = 1.04617945, grad/param norm = 2.4128e-01, time/batch = 16.7935s	
15941/29850 (epoch 26.702), train_loss = 0.94734840, grad/param norm = 2.0889e-01, time/batch = 18.4391s	
15942/29850 (epoch 26.704), train_loss = 0.84922254, grad/param norm = 1.7812e-01, time/batch = 17.3757s	
15943/29850 (epoch 26.705), train_loss = 0.96830803, grad/param norm = 2.0097e-01, time/batch = 18.6096s	
15944/29850 (epoch 26.707), train_loss = 0.89629322, grad/param norm = 2.1697e-01, time/batch = 18.1252s	
15945/29850 (epoch 26.709), train_loss = 0.93112669, grad/param norm = 1.8674e-01, time/batch = 15.2740s	
15946/29850 (epoch 26.710), train_loss = 0.91439291, grad/param norm = 2.2651e-01, time/batch = 18.4614s	
15947/29850 (epoch 26.712), train_loss = 0.97368898, grad/param norm = 1.8541e-01, time/batch = 18.0424s	
15948/29850 (epoch 26.714), train_loss = 1.04718217, grad/param norm = 2.4584e-01, time/batch = 19.8732s	
15949/29850 (epoch 26.715), train_loss = 0.98829621, grad/param norm = 2.1335e-01, time/batch = 15.5950s	
15950/29850 (epoch 26.717), train_loss = 0.74157718, grad/param norm = 1.8765e-01, time/batch = 19.7928s	
15951/29850 (epoch 26.719), train_loss = 0.91515071, grad/param norm = 2.0812e-01, time/batch = 17.2099s	
15952/29850 (epoch 26.720), train_loss = 0.94167323, grad/param norm = 1.9527e-01, time/batch = 16.6160s	
15953/29850 (epoch 26.722), train_loss = 0.88544432, grad/param norm = 1.7894e-01, time/batch = 19.6941s	
15954/29850 (epoch 26.724), train_loss = 1.00661994, grad/param norm = 2.2701e-01, time/batch = 17.7115s	
15955/29850 (epoch 26.725), train_loss = 0.81216191, grad/param norm = 1.8588e-01, time/batch = 17.8590s	
15956/29850 (epoch 26.727), train_loss = 0.88405431, grad/param norm = 2.2015e-01, time/batch = 16.0629s	
15957/29850 (epoch 26.729), train_loss = 0.81263842, grad/param norm = 1.7226e-01, time/batch = 16.3738s	
15958/29850 (epoch 26.730), train_loss = 0.77065111, grad/param norm = 1.8712e-01, time/batch = 16.3938s	
15959/29850 (epoch 26.732), train_loss = 1.03189383, grad/param norm = 1.9063e-01, time/batch = 15.3866s	
15960/29850 (epoch 26.734), train_loss = 1.12683994, grad/param norm = 2.4774e-01, time/batch = 17.6063s	
15961/29850 (epoch 26.735), train_loss = 0.88241282, grad/param norm = 2.3737e-01, time/batch = 16.6261s	
15962/29850 (epoch 26.737), train_loss = 0.85952779, grad/param norm = 2.0104e-01, time/batch = 17.3361s	
15963/29850 (epoch 26.739), train_loss = 0.74208078, grad/param norm = 2.0032e-01, time/batch = 18.6218s	
15964/29850 (epoch 26.740), train_loss = 0.81771753, grad/param norm = 2.0818e-01, time/batch = 18.2922s	
15965/29850 (epoch 26.742), train_loss = 0.74773234, grad/param norm = 1.7137e-01, time/batch = 19.1232s	
15966/29850 (epoch 26.744), train_loss = 0.89076365, grad/param norm = 2.2681e-01, time/batch = 17.5322s	
15967/29850 (epoch 26.745), train_loss = 0.89386094, grad/param norm = 2.6047e-01, time/batch = 17.7123s	
15968/29850 (epoch 26.747), train_loss = 0.93246109, grad/param norm = 2.2229e-01, time/batch = 19.3833s	
15969/29850 (epoch 26.749), train_loss = 0.81882594, grad/param norm = 2.0667e-01, time/batch = 17.4573s	
15970/29850 (epoch 26.750), train_loss = 0.77673222, grad/param norm = 1.9551e-01, time/batch = 17.5318s	
15971/29850 (epoch 26.752), train_loss = 0.69867232, grad/param norm = 1.8005e-01, time/batch = 18.1049s	
15972/29850 (epoch 26.754), train_loss = 0.79414947, grad/param norm = 1.8885e-01, time/batch = 17.9464s	
15973/29850 (epoch 26.755), train_loss = 0.80244007, grad/param norm = 1.9604e-01, time/batch = 17.3107s	
15974/29850 (epoch 26.757), train_loss = 0.84824292, grad/param norm = 1.8274e-01, time/batch = 17.2062s	
15975/29850 (epoch 26.759), train_loss = 0.85183815, grad/param norm = 1.8269e-01, time/batch = 18.2507s	
15976/29850 (epoch 26.760), train_loss = 0.83297184, grad/param norm = 1.9587e-01, time/batch = 18.0494s	
15977/29850 (epoch 26.762), train_loss = 0.81098560, grad/param norm = 2.1644e-01, time/batch = 17.3740s	
15978/29850 (epoch 26.764), train_loss = 0.75035295, grad/param norm = 1.8776e-01, time/batch = 17.2196s	
15979/29850 (epoch 26.765), train_loss = 0.90579109, grad/param norm = 2.0496e-01, time/batch = 17.9571s	
15980/29850 (epoch 26.767), train_loss = 0.89250563, grad/param norm = 1.9126e-01, time/batch = 18.7975s	
15981/29850 (epoch 26.769), train_loss = 0.89966192, grad/param norm = 1.9966e-01, time/batch = 17.6463s	
15982/29850 (epoch 26.771), train_loss = 0.96180355, grad/param norm = 2.0742e-01, time/batch = 17.5565s	
15983/29850 (epoch 26.772), train_loss = 0.95759917, grad/param norm = 2.1597e-01, time/batch = 18.9439s	
15984/29850 (epoch 26.774), train_loss = 0.86600461, grad/param norm = 1.9296e-01, time/batch = 19.7783s	
15985/29850 (epoch 26.776), train_loss = 0.88258615, grad/param norm = 1.8968e-01, time/batch = 17.3849s	
15986/29850 (epoch 26.777), train_loss = 0.99326577, grad/param norm = 2.0517e-01, time/batch = 17.1180s	
15987/29850 (epoch 26.779), train_loss = 0.83255625, grad/param norm = 1.9996e-01, time/batch = 19.1251s	
15988/29850 (epoch 26.781), train_loss = 0.93928843, grad/param norm = 2.0165e-01, time/batch = 20.2715s	
15989/29850 (epoch 26.782), train_loss = 0.96147018, grad/param norm = 2.0012e-01, time/batch = 15.9437s	
15990/29850 (epoch 26.784), train_loss = 0.78543938, grad/param norm = 2.0900e-01, time/batch = 16.3737s	
15991/29850 (epoch 26.786), train_loss = 0.87118192, grad/param norm = 1.9273e-01, time/batch = 14.9471s	
15992/29850 (epoch 26.787), train_loss = 0.76086079, grad/param norm = 2.0284e-01, time/batch = 15.6185s	
15993/29850 (epoch 26.789), train_loss = 0.75725163, grad/param norm = 1.7847e-01, time/batch = 18.1276s	
15994/29850 (epoch 26.791), train_loss = 0.85426017, grad/param norm = 2.2164e-01, time/batch = 19.1213s	
15995/29850 (epoch 26.792), train_loss = 0.95543562, grad/param norm = 2.1673e-01, time/batch = 17.1945s	
15996/29850 (epoch 26.794), train_loss = 0.94337034, grad/param norm = 1.8825e-01, time/batch = 17.2866s	
15997/29850 (epoch 26.796), train_loss = 0.80511839, grad/param norm = 1.7835e-01, time/batch = 18.9576s	
15998/29850 (epoch 26.797), train_loss = 0.74047494, grad/param norm = 1.9403e-01, time/batch = 19.7092s	
15999/29850 (epoch 26.799), train_loss = 0.76562406, grad/param norm = 1.7590e-01, time/batch = 16.5430s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch26.80_1.7589.t7	
16000/29850 (epoch 26.801), train_loss = 0.82524706, grad/param norm = 1.8021e-01, time/batch = 18.0517s	
16001/29850 (epoch 26.802), train_loss = 1.35263865, grad/param norm = 2.8294e-01, time/batch = 18.8625s	
16002/29850 (epoch 26.804), train_loss = 0.80706678, grad/param norm = 1.9425e-01, time/batch = 17.5304s	
16003/29850 (epoch 26.806), train_loss = 0.76709406, grad/param norm = 1.8940e-01, time/batch = 18.3014s	
16004/29850 (epoch 26.807), train_loss = 0.78602223, grad/param norm = 2.0571e-01, time/batch = 17.6493s	
16005/29850 (epoch 26.809), train_loss = 0.80481090, grad/param norm = 2.0122e-01, time/batch = 17.7774s	
16006/29850 (epoch 26.811), train_loss = 0.95556506, grad/param norm = 2.2160e-01, time/batch = 19.7721s	
16007/29850 (epoch 26.812), train_loss = 0.93482122, grad/param norm = 2.2416e-01, time/batch = 16.1202s	
16008/29850 (epoch 26.814), train_loss = 0.99323094, grad/param norm = 2.1869e-01, time/batch = 19.6986s	
16009/29850 (epoch 26.816), train_loss = 0.98422025, grad/param norm = 1.8965e-01, time/batch = 18.2667s	
16010/29850 (epoch 26.817), train_loss = 0.93832444, grad/param norm = 2.1660e-01, time/batch = 14.6675s	
16011/29850 (epoch 26.819), train_loss = 0.76862239, grad/param norm = 2.3732e-01, time/batch = 16.9339s	
16012/29850 (epoch 26.821), train_loss = 1.02643733, grad/param norm = 2.6537e-01, time/batch = 18.0215s	
16013/29850 (epoch 26.822), train_loss = 1.04272340, grad/param norm = 2.4168e-01, time/batch = 17.4691s	
16014/29850 (epoch 26.824), train_loss = 0.90289581, grad/param norm = 1.9173e-01, time/batch = 18.6960s	
16015/29850 (epoch 26.826), train_loss = 0.82195505, grad/param norm = 1.9200e-01, time/batch = 18.2777s	
16016/29850 (epoch 26.827), train_loss = 0.76518789, grad/param norm = 2.0762e-01, time/batch = 16.7988s	
16017/29850 (epoch 26.829), train_loss = 0.92757032, grad/param norm = 2.5435e-01, time/batch = 17.1302s	
16018/29850 (epoch 26.831), train_loss = 1.01169975, grad/param norm = 2.4090e-01, time/batch = 16.5514s	
16019/29850 (epoch 26.832), train_loss = 0.90264325, grad/param norm = 1.8427e-01, time/batch = 16.6115s	
16020/29850 (epoch 26.834), train_loss = 0.68751245, grad/param norm = 1.6095e-01, time/batch = 18.3062s	
16021/29850 (epoch 26.836), train_loss = 0.74640336, grad/param norm = 1.6959e-01, time/batch = 16.7925s	
16022/29850 (epoch 26.838), train_loss = 0.88388602, grad/param norm = 2.0913e-01, time/batch = 16.8559s	
16023/29850 (epoch 26.839), train_loss = 0.76343845, grad/param norm = 1.7657e-01, time/batch = 17.8718s	
16024/29850 (epoch 26.841), train_loss = 0.80617705, grad/param norm = 2.0740e-01, time/batch = 19.4542s	
16025/29850 (epoch 26.843), train_loss = 0.75352674, grad/param norm = 1.9482e-01, time/batch = 19.0400s	
16026/29850 (epoch 26.844), train_loss = 0.81808969, grad/param norm = 1.9890e-01, time/batch = 18.3731s	
16027/29850 (epoch 26.846), train_loss = 0.89470586, grad/param norm = 1.9687e-01, time/batch = 17.1538s	
16028/29850 (epoch 26.848), train_loss = 0.96691556, grad/param norm = 2.1611e-01, time/batch = 18.6264s	
16029/29850 (epoch 26.849), train_loss = 0.84121941, grad/param norm = 1.9199e-01, time/batch = 15.9710s	
16030/29850 (epoch 26.851), train_loss = 1.00551854, grad/param norm = 2.1168e-01, time/batch = 18.4715s	
16031/29850 (epoch 26.853), train_loss = 0.86345418, grad/param norm = 2.3247e-01, time/batch = 19.6146s	
16032/29850 (epoch 26.854), train_loss = 1.05951441, grad/param norm = 2.2407e-01, time/batch = 16.8578s	
16033/29850 (epoch 26.856), train_loss = 1.00262582, grad/param norm = 2.4971e-01, time/batch = 18.3894s	
16034/29850 (epoch 26.858), train_loss = 0.92351282, grad/param norm = 1.9774e-01, time/batch = 16.7790s	
16035/29850 (epoch 26.859), train_loss = 0.80106357, grad/param norm = 2.2996e-01, time/batch = 16.2969s	
16036/29850 (epoch 26.861), train_loss = 1.01736814, grad/param norm = 2.2630e-01, time/batch = 16.6370s	
16037/29850 (epoch 26.863), train_loss = 1.07583562, grad/param norm = 2.1992e-01, time/batch = 15.4697s	
16038/29850 (epoch 26.864), train_loss = 1.03895846, grad/param norm = 2.2845e-01, time/batch = 17.9635s	
16039/29850 (epoch 26.866), train_loss = 0.92480559, grad/param norm = 2.1826e-01, time/batch = 16.7774s	
16040/29850 (epoch 26.868), train_loss = 1.08842868, grad/param norm = 2.2405e-01, time/batch = 16.4045s	
16041/29850 (epoch 26.869), train_loss = 0.97891288, grad/param norm = 2.5775e-01, time/batch = 19.2826s	
16042/29850 (epoch 26.871), train_loss = 0.98581880, grad/param norm = 2.0119e-01, time/batch = 18.7163s	
16043/29850 (epoch 26.873), train_loss = 0.93936656, grad/param norm = 2.0773e-01, time/batch = 18.3607s	
16044/29850 (epoch 26.874), train_loss = 0.95983820, grad/param norm = 2.0781e-01, time/batch = 16.9633s	
16045/29850 (epoch 26.876), train_loss = 0.92731809, grad/param norm = 2.6343e-01, time/batch = 16.2735s	
16046/29850 (epoch 26.878), train_loss = 0.93142389, grad/param norm = 2.0235e-01, time/batch = 16.4712s	
16047/29850 (epoch 26.879), train_loss = 0.95416224, grad/param norm = 2.0476e-01, time/batch = 18.3908s	
16048/29850 (epoch 26.881), train_loss = 1.03686942, grad/param norm = 2.3373e-01, time/batch = 17.4701s	
16049/29850 (epoch 26.883), train_loss = 1.01486346, grad/param norm = 2.4149e-01, time/batch = 20.3420s	
16050/29850 (epoch 26.884), train_loss = 0.82526232, grad/param norm = 2.0314e-01, time/batch = 46.1338s	
16051/29850 (epoch 26.886), train_loss = 1.06159161, grad/param norm = 2.9725e-01, time/batch = 16.5964s	
16052/29850 (epoch 26.888), train_loss = 0.91406077, grad/param norm = 2.1463e-01, time/batch = 18.2930s	
16053/29850 (epoch 26.889), train_loss = 0.85477062, grad/param norm = 1.7552e-01, time/batch = 19.0472s	
16054/29850 (epoch 26.891), train_loss = 0.81456859, grad/param norm = 1.7452e-01, time/batch = 17.0400s	
16055/29850 (epoch 26.893), train_loss = 0.86056679, grad/param norm = 1.9601e-01, time/batch = 19.8713s	
16056/29850 (epoch 26.894), train_loss = 0.90209629, grad/param norm = 2.2441e-01, time/batch = 18.7174s	
16057/29850 (epoch 26.896), train_loss = 0.92747933, grad/param norm = 2.2949e-01, time/batch = 17.9639s	
16058/29850 (epoch 26.898), train_loss = 1.06566581, grad/param norm = 2.6308e-01, time/batch = 15.5090s	
16059/29850 (epoch 26.899), train_loss = 0.81147120, grad/param norm = 2.2179e-01, time/batch = 18.4454s	
16060/29850 (epoch 26.901), train_loss = 1.18421931, grad/param norm = 2.6381e-01, time/batch = 18.7217s	
16061/29850 (epoch 26.903), train_loss = 0.94805652, grad/param norm = 3.0416e-01, time/batch = 17.4568s	
16062/29850 (epoch 26.905), train_loss = 1.17121004, grad/param norm = 2.3066e-01, time/batch = 17.9534s	
16063/29850 (epoch 26.906), train_loss = 0.99057149, grad/param norm = 2.1116e-01, time/batch = 19.6933s	
16064/29850 (epoch 26.908), train_loss = 1.07864037, grad/param norm = 2.1363e-01, time/batch = 17.7567s	
16065/29850 (epoch 26.910), train_loss = 0.99000280, grad/param norm = 1.9354e-01, time/batch = 16.6860s	
16066/29850 (epoch 26.911), train_loss = 1.13903708, grad/param norm = 2.1143e-01, time/batch = 18.3167s	
16067/29850 (epoch 26.913), train_loss = 1.10420531, grad/param norm = 2.4619e-01, time/batch = 19.1184s	
16068/29850 (epoch 26.915), train_loss = 1.08072113, grad/param norm = 2.6279e-01, time/batch = 16.7069s	
16069/29850 (epoch 26.916), train_loss = 1.03907465, grad/param norm = 2.2229e-01, time/batch = 17.9595s	
16070/29850 (epoch 26.918), train_loss = 0.87406145, grad/param norm = 1.9475e-01, time/batch = 17.8665s	
16071/29850 (epoch 26.920), train_loss = 1.04576007, grad/param norm = 2.0705e-01, time/batch = 16.2198s	
16072/29850 (epoch 26.921), train_loss = 0.94697181, grad/param norm = 2.3687e-01, time/batch = 19.4378s	
16073/29850 (epoch 26.923), train_loss = 1.00595658, grad/param norm = 2.0681e-01, time/batch = 19.1256s	
16074/29850 (epoch 26.925), train_loss = 1.08811378, grad/param norm = 2.1865e-01, time/batch = 18.8670s	
16075/29850 (epoch 26.926), train_loss = 1.10446790, grad/param norm = 2.4644e-01, time/batch = 18.4518s	
16076/29850 (epoch 26.928), train_loss = 0.96787632, grad/param norm = 2.0125e-01, time/batch = 18.3736s	
16077/29850 (epoch 26.930), train_loss = 0.99559891, grad/param norm = 1.9442e-01, time/batch = 16.1899s	
16078/29850 (epoch 26.931), train_loss = 0.94423824, grad/param norm = 2.0726e-01, time/batch = 17.0310s	
16079/29850 (epoch 26.933), train_loss = 1.09543466, grad/param norm = 2.1221e-01, time/batch = 17.1158s	
16080/29850 (epoch 26.935), train_loss = 1.04174791, grad/param norm = 2.2516e-01, time/batch = 18.8033s	
16081/29850 (epoch 26.936), train_loss = 1.00172361, grad/param norm = 2.2081e-01, time/batch = 16.3018s	
16082/29850 (epoch 26.938), train_loss = 0.84150750, grad/param norm = 1.9173e-01, time/batch = 17.2207s	
16083/29850 (epoch 26.940), train_loss = 0.83397253, grad/param norm = 2.0929e-01, time/batch = 17.6355s	
16084/29850 (epoch 26.941), train_loss = 0.87096326, grad/param norm = 2.2848e-01, time/batch = 16.2112s	
16085/29850 (epoch 26.943), train_loss = 0.86265654, grad/param norm = 1.9146e-01, time/batch = 16.2794s	
16086/29850 (epoch 26.945), train_loss = 0.86427740, grad/param norm = 2.0649e-01, time/batch = 14.7906s	
16087/29850 (epoch 26.946), train_loss = 0.83143798, grad/param norm = 1.9258e-01, time/batch = 17.8846s	
16088/29850 (epoch 26.948), train_loss = 0.96652338, grad/param norm = 2.0195e-01, time/batch = 18.1081s	
16089/29850 (epoch 26.950), train_loss = 0.87482365, grad/param norm = 1.9673e-01, time/batch = 18.5300s	
16090/29850 (epoch 26.951), train_loss = 0.80968446, grad/param norm = 1.7017e-01, time/batch = 15.6983s	
16091/29850 (epoch 26.953), train_loss = 0.92139857, grad/param norm = 2.3161e-01, time/batch = 15.4989s	
16092/29850 (epoch 26.955), train_loss = 0.82263719, grad/param norm = 1.8664e-01, time/batch = 16.1888s	
16093/29850 (epoch 26.956), train_loss = 0.79727334, grad/param norm = 1.7207e-01, time/batch = 15.1070s	
16094/29850 (epoch 26.958), train_loss = 0.71562287, grad/param norm = 1.5537e-01, time/batch = 15.0990s	
16095/29850 (epoch 26.960), train_loss = 1.03083518, grad/param norm = 2.3000e-01, time/batch = 14.6842s	
16096/29850 (epoch 26.961), train_loss = 0.80836530, grad/param norm = 1.8372e-01, time/batch = 15.2110s	
16097/29850 (epoch 26.963), train_loss = 0.77800259, grad/param norm = 1.8098e-01, time/batch = 17.6342s	
16098/29850 (epoch 26.965), train_loss = 0.86330945, grad/param norm = 2.0636e-01, time/batch = 18.6314s	
16099/29850 (epoch 26.966), train_loss = 0.79608095, grad/param norm = 1.9129e-01, time/batch = 17.3664s	
16100/29850 (epoch 26.968), train_loss = 0.85520544, grad/param norm = 1.9726e-01, time/batch = 16.7020s	
16101/29850 (epoch 26.970), train_loss = 0.81920619, grad/param norm = 2.1386e-01, time/batch = 17.0453s	
16102/29850 (epoch 26.972), train_loss = 0.83283823, grad/param norm = 1.6602e-01, time/batch = 17.7160s	
16103/29850 (epoch 26.973), train_loss = 0.84045650, grad/param norm = 1.9054e-01, time/batch = 17.6127s	
16104/29850 (epoch 26.975), train_loss = 0.73456687, grad/param norm = 1.7760e-01, time/batch = 18.8030s	
16105/29850 (epoch 26.977), train_loss = 0.85607485, grad/param norm = 1.8136e-01, time/batch = 16.7954s	
16106/29850 (epoch 26.978), train_loss = 0.78123913, grad/param norm = 1.9223e-01, time/batch = 16.4588s	
16107/29850 (epoch 26.980), train_loss = 0.86210523, grad/param norm = 1.8760e-01, time/batch = 17.8936s	
16108/29850 (epoch 26.982), train_loss = 0.83258553, grad/param norm = 1.9646e-01, time/batch = 15.8797s	
16109/29850 (epoch 26.983), train_loss = 0.86429528, grad/param norm = 1.8022e-01, time/batch = 18.5269s	
16110/29850 (epoch 26.985), train_loss = 0.94067697, grad/param norm = 1.9904e-01, time/batch = 20.3432s	
16111/29850 (epoch 26.987), train_loss = 0.91701683, grad/param norm = 1.9549e-01, time/batch = 18.6183s	
16112/29850 (epoch 26.988), train_loss = 0.84733579, grad/param norm = 1.7065e-01, time/batch = 18.0478s	
16113/29850 (epoch 26.990), train_loss = 0.92785013, grad/param norm = 1.9369e-01, time/batch = 18.3633s	
16114/29850 (epoch 26.992), train_loss = 0.95699230, grad/param norm = 1.9027e-01, time/batch = 19.2076s	
16115/29850 (epoch 26.993), train_loss = 0.92361138, grad/param norm = 2.0173e-01, time/batch = 19.2956s	
16116/29850 (epoch 26.995), train_loss = 0.94451740, grad/param norm = 1.9919e-01, time/batch = 17.4378s	
16117/29850 (epoch 26.997), train_loss = 0.96090183, grad/param norm = 2.0429e-01, time/batch = 18.3623s	
16118/29850 (epoch 26.998), train_loss = 0.97667852, grad/param norm = 1.9851e-01, time/batch = 18.6890s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
16119/29850 (epoch 27.000), train_loss = 0.81833921, grad/param norm = 1.7131e-01, time/batch = 15.8512s	
16120/29850 (epoch 27.002), train_loss = 1.09301826, grad/param norm = 2.2344e-01, time/batch = 19.1182s	
16121/29850 (epoch 27.003), train_loss = 0.82082036, grad/param norm = 2.0738e-01, time/batch = 18.8654s	
16122/29850 (epoch 27.005), train_loss = 0.94571480, grad/param norm = 2.0729e-01, time/batch = 15.7726s	
16123/29850 (epoch 27.007), train_loss = 0.97680689, grad/param norm = 2.2035e-01, time/batch = 15.1468s	
16124/29850 (epoch 27.008), train_loss = 1.15224913, grad/param norm = 2.2417e-01, time/batch = 18.0483s	
16125/29850 (epoch 27.010), train_loss = 0.86665156, grad/param norm = 2.2272e-01, time/batch = 20.1134s	
16126/29850 (epoch 27.012), train_loss = 0.91061377, grad/param norm = 1.9224e-01, time/batch = 17.9577s	
16127/29850 (epoch 27.013), train_loss = 0.98164124, grad/param norm = 2.3339e-01, time/batch = 18.7839s	
16128/29850 (epoch 27.015), train_loss = 0.98265007, grad/param norm = 1.9471e-01, time/batch = 19.1252s	
16129/29850 (epoch 27.017), train_loss = 0.95421188, grad/param norm = 2.2254e-01, time/batch = 16.8701s	
16130/29850 (epoch 27.018), train_loss = 1.05401949, grad/param norm = 2.1890e-01, time/batch = 17.8588s	
16131/29850 (epoch 27.020), train_loss = 0.90700250, grad/param norm = 2.0919e-01, time/batch = 18.9360s	
16132/29850 (epoch 27.022), train_loss = 1.03332929, grad/param norm = 2.1809e-01, time/batch = 17.8702s	
16133/29850 (epoch 27.023), train_loss = 1.00728425, grad/param norm = 2.1060e-01, time/batch = 16.0246s	
16134/29850 (epoch 27.025), train_loss = 0.92874375, grad/param norm = 1.9873e-01, time/batch = 18.0412s	
16135/29850 (epoch 27.027), train_loss = 0.73933022, grad/param norm = 1.6593e-01, time/batch = 18.7222s	
16136/29850 (epoch 27.028), train_loss = 0.87646950, grad/param norm = 1.7192e-01, time/batch = 17.8438s	
16137/29850 (epoch 27.030), train_loss = 0.91809805, grad/param norm = 2.0589e-01, time/batch = 16.7304s	
16138/29850 (epoch 27.032), train_loss = 0.98469363, grad/param norm = 1.9556e-01, time/batch = 17.5472s	
16139/29850 (epoch 27.034), train_loss = 0.84772390, grad/param norm = 1.8439e-01, time/batch = 16.9591s	
16140/29850 (epoch 27.035), train_loss = 0.76207317, grad/param norm = 1.7400e-01, time/batch = 19.8677s	
16141/29850 (epoch 27.037), train_loss = 0.92994021, grad/param norm = 2.1062e-01, time/batch = 18.2804s	
16142/29850 (epoch 27.039), train_loss = 0.82143576, grad/param norm = 1.8097e-01, time/batch = 16.4502s	
16143/29850 (epoch 27.040), train_loss = 0.84195903, grad/param norm = 1.7594e-01, time/batch = 17.8814s	
16144/29850 (epoch 27.042), train_loss = 0.83674491, grad/param norm = 1.9298e-01, time/batch = 18.3725s	
16145/29850 (epoch 27.044), train_loss = 0.88370331, grad/param norm = 1.7305e-01, time/batch = 17.4718s	
16146/29850 (epoch 27.045), train_loss = 0.99829232, grad/param norm = 2.0388e-01, time/batch = 16.7984s	
16147/29850 (epoch 27.047), train_loss = 0.83013335, grad/param norm = 1.8201e-01, time/batch = 18.1310s	
16148/29850 (epoch 27.049), train_loss = 0.97521322, grad/param norm = 1.9081e-01, time/batch = 18.5512s	
16149/29850 (epoch 27.050), train_loss = 0.82393074, grad/param norm = 1.9515e-01, time/batch = 17.0937s	
16150/29850 (epoch 27.052), train_loss = 1.01757083, grad/param norm = 2.4068e-01, time/batch = 16.4624s	
16151/29850 (epoch 27.054), train_loss = 0.92915536, grad/param norm = 2.0836e-01, time/batch = 17.1364s	
16152/29850 (epoch 27.055), train_loss = 0.88260197, grad/param norm = 1.8714e-01, time/batch = 18.7962s	
16153/29850 (epoch 27.057), train_loss = 0.97547460, grad/param norm = 1.9493e-01, time/batch = 16.6277s	
16154/29850 (epoch 27.059), train_loss = 0.96856565, grad/param norm = 2.0501e-01, time/batch = 18.7134s	
16155/29850 (epoch 27.060), train_loss = 0.93998904, grad/param norm = 2.0979e-01, time/batch = 16.2966s	
16156/29850 (epoch 27.062), train_loss = 1.04520856, grad/param norm = 2.3336e-01, time/batch = 16.7951s	
16157/29850 (epoch 27.064), train_loss = 0.99936959, grad/param norm = 1.9961e-01, time/batch = 18.4570s	
16158/29850 (epoch 27.065), train_loss = 0.82792710, grad/param norm = 2.0612e-01, time/batch = 18.4487s	
16159/29850 (epoch 27.067), train_loss = 0.98736518, grad/param norm = 1.9708e-01, time/batch = 16.7732s	
16160/29850 (epoch 27.069), train_loss = 0.95664139, grad/param norm = 1.9098e-01, time/batch = 16.8100s	
16161/29850 (epoch 27.070), train_loss = 0.97451652, grad/param norm = 1.9891e-01, time/batch = 19.2933s	
16162/29850 (epoch 27.072), train_loss = 0.95306688, grad/param norm = 2.1477e-01, time/batch = 19.0372s	
16163/29850 (epoch 27.074), train_loss = 1.00615894, grad/param norm = 1.9905e-01, time/batch = 18.6077s	
16164/29850 (epoch 27.075), train_loss = 0.85555957, grad/param norm = 2.0614e-01, time/batch = 18.3765s	
16165/29850 (epoch 27.077), train_loss = 0.97262793, grad/param norm = 2.0106e-01, time/batch = 16.8980s	
16166/29850 (epoch 27.079), train_loss = 1.17776604, grad/param norm = 3.0073e-01, time/batch = 16.2164s	
16167/29850 (epoch 27.080), train_loss = 1.12022189, grad/param norm = 2.5519e-01, time/batch = 18.7129s	
16168/29850 (epoch 27.082), train_loss = 1.00348427, grad/param norm = 2.1800e-01, time/batch = 17.0559s	
16169/29850 (epoch 27.084), train_loss = 1.09753017, grad/param norm = 2.3291e-01, time/batch = 17.8078s	
16170/29850 (epoch 27.085), train_loss = 1.11099664, grad/param norm = 2.6109e-01, time/batch = 17.9549s	
16171/29850 (epoch 27.087), train_loss = 1.08874175, grad/param norm = 2.3664e-01, time/batch = 16.7243s	
16172/29850 (epoch 27.089), train_loss = 0.96942655, grad/param norm = 2.2192e-01, time/batch = 16.7809s	
16173/29850 (epoch 27.090), train_loss = 1.01690242, grad/param norm = 2.1387e-01, time/batch = 17.8622s	
16174/29850 (epoch 27.092), train_loss = 0.90055870, grad/param norm = 2.1445e-01, time/batch = 17.1383s	
16175/29850 (epoch 27.094), train_loss = 1.08456700, grad/param norm = 2.2780e-01, time/batch = 18.7004s	
16176/29850 (epoch 27.095), train_loss = 0.97318930, grad/param norm = 2.5635e-01, time/batch = 14.7434s	
16177/29850 (epoch 27.097), train_loss = 0.77737194, grad/param norm = 1.7996e-01, time/batch = 17.9778s	
16178/29850 (epoch 27.099), train_loss = 0.79908008, grad/param norm = 1.8374e-01, time/batch = 18.4624s	
16179/29850 (epoch 27.101), train_loss = 1.05072906, grad/param norm = 2.2907e-01, time/batch = 17.3872s	
16180/29850 (epoch 27.102), train_loss = 0.98369825, grad/param norm = 2.0799e-01, time/batch = 18.4471s	
16181/29850 (epoch 27.104), train_loss = 0.93565948, grad/param norm = 2.2271e-01, time/batch = 16.0532s	
16182/29850 (epoch 27.106), train_loss = 1.04139673, grad/param norm = 2.0337e-01, time/batch = 18.6213s	
16183/29850 (epoch 27.107), train_loss = 0.85817180, grad/param norm = 1.8923e-01, time/batch = 13.4644s	
16184/29850 (epoch 27.109), train_loss = 0.93602954, grad/param norm = 2.2256e-01, time/batch = 0.6691s	
16185/29850 (epoch 27.111), train_loss = 1.01518270, grad/param norm = 2.0813e-01, time/batch = 0.6677s	
16186/29850 (epoch 27.112), train_loss = 0.87868275, grad/param norm = 1.8516e-01, time/batch = 0.6526s	
16187/29850 (epoch 27.114), train_loss = 0.88529140, grad/param norm = 2.0511e-01, time/batch = 0.6543s	
16188/29850 (epoch 27.116), train_loss = 0.85550033, grad/param norm = 1.9653e-01, time/batch = 0.6796s	
16189/29850 (epoch 27.117), train_loss = 0.93853009, grad/param norm = 2.2082e-01, time/batch = 0.6610s	
16190/29850 (epoch 27.119), train_loss = 0.90514550, grad/param norm = 1.9102e-01, time/batch = 0.6689s	
16191/29850 (epoch 27.121), train_loss = 0.74965968, grad/param norm = 1.8621e-01, time/batch = 0.8726s	
16192/29850 (epoch 27.122), train_loss = 0.80148327, grad/param norm = 1.7038e-01, time/batch = 0.9771s	
16193/29850 (epoch 27.124), train_loss = 0.87038911, grad/param norm = 2.1744e-01, time/batch = 0.9580s	
16194/29850 (epoch 27.126), train_loss = 0.87719486, grad/param norm = 1.8837e-01, time/batch = 0.9696s	
16195/29850 (epoch 27.127), train_loss = 1.00079099, grad/param norm = 2.5549e-01, time/batch = 0.9941s	
16196/29850 (epoch 27.129), train_loss = 0.86972510, grad/param norm = 1.8807e-01, time/batch = 1.4812s	
16197/29850 (epoch 27.131), train_loss = 0.91106828, grad/param norm = 1.9233e-01, time/batch = 1.8545s	
16198/29850 (epoch 27.132), train_loss = 0.83213366, grad/param norm = 1.9947e-01, time/batch = 1.8106s	
16199/29850 (epoch 27.134), train_loss = 0.91739939, grad/param norm = 1.9847e-01, time/batch = 14.8268s	
16200/29850 (epoch 27.136), train_loss = 0.97841151, grad/param norm = 2.1750e-01, time/batch = 19.0394s	
16201/29850 (epoch 27.137), train_loss = 0.76192499, grad/param norm = 1.7387e-01, time/batch = 15.8715s	
16202/29850 (epoch 27.139), train_loss = 0.91370370, grad/param norm = 1.9438e-01, time/batch = 19.3814s	
16203/29850 (epoch 27.141), train_loss = 0.85064610, grad/param norm = 2.0085e-01, time/batch = 18.7162s	
16204/29850 (epoch 27.142), train_loss = 1.06194915, grad/param norm = 2.3491e-01, time/batch = 16.1297s	
16205/29850 (epoch 27.144), train_loss = 1.19497020, grad/param norm = 2.5741e-01, time/batch = 20.2919s	
16206/29850 (epoch 27.146), train_loss = 1.19599614, grad/param norm = 2.3478e-01, time/batch = 17.8822s	
16207/29850 (epoch 27.147), train_loss = 1.01382825, grad/param norm = 2.1116e-01, time/batch = 17.1305s	
16208/29850 (epoch 27.149), train_loss = 0.98659009, grad/param norm = 2.5777e-01, time/batch = 18.1213s	
16209/29850 (epoch 27.151), train_loss = 0.99091910, grad/param norm = 2.1296e-01, time/batch = 18.7980s	
16210/29850 (epoch 27.152), train_loss = 0.90466279, grad/param norm = 1.9311e-01, time/batch = 15.1999s	
16211/29850 (epoch 27.154), train_loss = 0.87087788, grad/param norm = 2.0207e-01, time/batch = 17.0450s	
16212/29850 (epoch 27.156), train_loss = 0.85012910, grad/param norm = 1.9276e-01, time/batch = 18.9573s	
16213/29850 (epoch 27.157), train_loss = 0.99000104, grad/param norm = 2.0435e-01, time/batch = 17.5519s	
16214/29850 (epoch 27.159), train_loss = 0.90459834, grad/param norm = 2.0820e-01, time/batch = 17.9606s	
16215/29850 (epoch 27.161), train_loss = 0.96994698, grad/param norm = 2.3896e-01, time/batch = 16.7176s	
16216/29850 (epoch 27.162), train_loss = 1.07277645, grad/param norm = 2.4515e-01, time/batch = 17.2285s	
16217/29850 (epoch 27.164), train_loss = 0.95385917, grad/param norm = 1.9893e-01, time/batch = 18.8760s	
16218/29850 (epoch 27.166), train_loss = 0.87080145, grad/param norm = 1.8763e-01, time/batch = 17.2019s	
16219/29850 (epoch 27.168), train_loss = 0.78971782, grad/param norm = 1.8463e-01, time/batch = 15.8782s	
16220/29850 (epoch 27.169), train_loss = 1.10845987, grad/param norm = 2.4160e-01, time/batch = 17.9657s	
16221/29850 (epoch 27.171), train_loss = 0.99759691, grad/param norm = 2.1688e-01, time/batch = 17.1024s	
16222/29850 (epoch 27.173), train_loss = 0.86362901, grad/param norm = 1.9753e-01, time/batch = 19.9579s	
16223/29850 (epoch 27.174), train_loss = 0.95383904, grad/param norm = 2.1587e-01, time/batch = 18.7126s	
16224/29850 (epoch 27.176), train_loss = 0.96220323, grad/param norm = 2.0141e-01, time/batch = 18.1033s	
16225/29850 (epoch 27.178), train_loss = 0.99747679, grad/param norm = 2.3014e-01, time/batch = 19.0200s	
16226/29850 (epoch 27.179), train_loss = 0.80193866, grad/param norm = 1.9075e-01, time/batch = 17.3089s	
16227/29850 (epoch 27.181), train_loss = 0.95956234, grad/param norm = 2.2214e-01, time/batch = 19.4637s	
16228/29850 (epoch 27.183), train_loss = 0.95932307, grad/param norm = 2.0152e-01, time/batch = 17.6880s	
16229/29850 (epoch 27.184), train_loss = 0.98694915, grad/param norm = 2.0768e-01, time/batch = 17.9597s	
16230/29850 (epoch 27.186), train_loss = 0.94225722, grad/param norm = 2.2362e-01, time/batch = 19.5335s	
16231/29850 (epoch 27.188), train_loss = 1.04780752, grad/param norm = 2.2459e-01, time/batch = 16.6056s	
16232/29850 (epoch 27.189), train_loss = 1.08707291, grad/param norm = 2.7396e-01, time/batch = 18.1372s	
16233/29850 (epoch 27.191), train_loss = 1.05763256, grad/param norm = 2.2818e-01, time/batch = 15.7246s	
16234/29850 (epoch 27.193), train_loss = 0.92809662, grad/param norm = 2.0265e-01, time/batch = 17.6247s	
16235/29850 (epoch 27.194), train_loss = 1.00492263, grad/param norm = 2.1624e-01, time/batch = 17.2900s	
16236/29850 (epoch 27.196), train_loss = 0.93421812, grad/param norm = 2.1322e-01, time/batch = 19.1654s	
16237/29850 (epoch 27.198), train_loss = 0.92084449, grad/param norm = 1.9790e-01, time/batch = 16.4743s	
16238/29850 (epoch 27.199), train_loss = 1.16464633, grad/param norm = 2.3035e-01, time/batch = 17.6956s	
16239/29850 (epoch 27.201), train_loss = 0.89294404, grad/param norm = 2.0683e-01, time/batch = 19.5391s	
16240/29850 (epoch 27.203), train_loss = 0.73957916, grad/param norm = 2.3214e-01, time/batch = 18.4059s	
16241/29850 (epoch 27.204), train_loss = 0.98730783, grad/param norm = 2.6238e-01, time/batch = 17.7739s	
16242/29850 (epoch 27.206), train_loss = 0.83589560, grad/param norm = 2.0085e-01, time/batch = 18.8887s	
16243/29850 (epoch 27.208), train_loss = 1.07583926, grad/param norm = 2.1586e-01, time/batch = 18.0414s	
16244/29850 (epoch 27.209), train_loss = 0.81435324, grad/param norm = 1.9125e-01, time/batch = 18.0350s	
16245/29850 (epoch 27.211), train_loss = 0.88975690, grad/param norm = 1.8886e-01, time/batch = 15.6887s	
16246/29850 (epoch 27.213), train_loss = 1.00172580, grad/param norm = 2.1533e-01, time/batch = 18.3734s	
16247/29850 (epoch 27.214), train_loss = 0.82824414, grad/param norm = 1.6297e-01, time/batch = 16.9037s	
16248/29850 (epoch 27.216), train_loss = 0.88413387, grad/param norm = 2.1478e-01, time/batch = 15.6276s	
16249/29850 (epoch 27.218), train_loss = 1.01227215, grad/param norm = 2.1908e-01, time/batch = 16.9748s	
16250/29850 (epoch 27.219), train_loss = 1.01944192, grad/param norm = 2.3690e-01, time/batch = 17.1251s	
16251/29850 (epoch 27.221), train_loss = 0.95680146, grad/param norm = 2.1669e-01, time/batch = 18.6243s	
16252/29850 (epoch 27.223), train_loss = 0.84768369, grad/param norm = 2.0912e-01, time/batch = 16.3983s	
16253/29850 (epoch 27.224), train_loss = 0.80812516, grad/param norm = 1.8768e-01, time/batch = 19.7190s	
16254/29850 (epoch 27.226), train_loss = 0.85605068, grad/param norm = 1.7367e-01, time/batch = 16.7888s	
16255/29850 (epoch 27.228), train_loss = 0.93132352, grad/param norm = 1.8759e-01, time/batch = 18.0951s	
16256/29850 (epoch 27.229), train_loss = 0.78221344, grad/param norm = 1.7254e-01, time/batch = 18.0518s	
16257/29850 (epoch 27.231), train_loss = 0.95664683, grad/param norm = 1.9661e-01, time/batch = 19.0514s	
16258/29850 (epoch 27.233), train_loss = 0.92896593, grad/param norm = 2.5032e-01, time/batch = 16.6444s	
16259/29850 (epoch 27.235), train_loss = 0.86886898, grad/param norm = 1.9334e-01, time/batch = 17.5621s	
16260/29850 (epoch 27.236), train_loss = 1.05448548, grad/param norm = 2.4063e-01, time/batch = 15.9541s	
16261/29850 (epoch 27.238), train_loss = 0.83650059, grad/param norm = 2.1022e-01, time/batch = 16.9603s	
16262/29850 (epoch 27.240), train_loss = 0.80869391, grad/param norm = 2.0106e-01, time/batch = 18.2846s	
16263/29850 (epoch 27.241), train_loss = 0.97758401, grad/param norm = 2.2151e-01, time/batch = 17.7963s	
16264/29850 (epoch 27.243), train_loss = 0.96931528, grad/param norm = 2.0057e-01, time/batch = 19.2251s	
16265/29850 (epoch 27.245), train_loss = 0.89372722, grad/param norm = 2.2684e-01, time/batch = 28.2939s	
16266/29850 (epoch 27.246), train_loss = 0.81719059, grad/param norm = 1.7690e-01, time/batch = 22.3318s	
16267/29850 (epoch 27.248), train_loss = 0.80688032, grad/param norm = 1.8838e-01, time/batch = 15.3318s	
16268/29850 (epoch 27.250), train_loss = 0.89465661, grad/param norm = 1.8623e-01, time/batch = 17.6233s	
16269/29850 (epoch 27.251), train_loss = 0.78701600, grad/param norm = 1.9009e-01, time/batch = 16.9890s	
16270/29850 (epoch 27.253), train_loss = 0.73693539, grad/param norm = 2.2495e-01, time/batch = 16.7247s	
16271/29850 (epoch 27.255), train_loss = 0.85408796, grad/param norm = 2.1061e-01, time/batch = 16.7941s	
16272/29850 (epoch 27.256), train_loss = 0.97380686, grad/param norm = 2.1141e-01, time/batch = 19.1302s	
16273/29850 (epoch 27.258), train_loss = 0.92711843, grad/param norm = 1.9065e-01, time/batch = 17.7201s	
16274/29850 (epoch 27.260), train_loss = 0.90442736, grad/param norm = 1.9397e-01, time/batch = 17.2178s	
16275/29850 (epoch 27.261), train_loss = 0.84573757, grad/param norm = 2.2350e-01, time/batch = 20.0374s	
16276/29850 (epoch 27.263), train_loss = 0.84139581, grad/param norm = 1.9959e-01, time/batch = 17.4746s	
16277/29850 (epoch 27.265), train_loss = 0.90831249, grad/param norm = 2.1388e-01, time/batch = 17.9518s	
16278/29850 (epoch 27.266), train_loss = 0.91144889, grad/param norm = 1.9419e-01, time/batch = 19.0262s	
16279/29850 (epoch 27.268), train_loss = 0.86806958, grad/param norm = 1.7880e-01, time/batch = 17.0576s	
16280/29850 (epoch 27.270), train_loss = 0.87365714, grad/param norm = 2.5010e-01, time/batch = 18.9676s	
16281/29850 (epoch 27.271), train_loss = 0.99324014, grad/param norm = 2.2539e-01, time/batch = 16.7025s	
16282/29850 (epoch 27.273), train_loss = 0.80679869, grad/param norm = 2.0103e-01, time/batch = 18.0410s	
16283/29850 (epoch 27.275), train_loss = 0.80317248, grad/param norm = 1.9477e-01, time/batch = 18.6510s	
16284/29850 (epoch 27.276), train_loss = 0.81075060, grad/param norm = 1.9215e-01, time/batch = 15.3671s	
16285/29850 (epoch 27.278), train_loss = 0.86225388, grad/param norm = 1.8550e-01, time/batch = 16.5287s	
16286/29850 (epoch 27.280), train_loss = 1.06491969, grad/param norm = 2.6739e-01, time/batch = 18.0433s	
16287/29850 (epoch 27.281), train_loss = 0.94204213, grad/param norm = 2.0266e-01, time/batch = 17.1346s	
16288/29850 (epoch 27.283), train_loss = 1.07209151, grad/param norm = 2.6115e-01, time/batch = 17.1967s	
16289/29850 (epoch 27.285), train_loss = 0.96633488, grad/param norm = 2.0872e-01, time/batch = 17.3109s	
16290/29850 (epoch 27.286), train_loss = 1.02256427, grad/param norm = 2.2303e-01, time/batch = 19.4428s	
16291/29850 (epoch 27.288), train_loss = 1.04120265, grad/param norm = 2.8504e-01, time/batch = 16.6268s	
16292/29850 (epoch 27.290), train_loss = 0.96516812, grad/param norm = 2.3581e-01, time/batch = 19.5112s	
16293/29850 (epoch 27.291), train_loss = 1.14812974, grad/param norm = 2.2598e-01, time/batch = 18.3001s	
16294/29850 (epoch 27.293), train_loss = 1.02855477, grad/param norm = 2.2490e-01, time/batch = 16.1450s	
16295/29850 (epoch 27.295), train_loss = 1.11148527, grad/param norm = 2.6478e-01, time/batch = 17.3005s	
16296/29850 (epoch 27.296), train_loss = 0.83784689, grad/param norm = 1.8858e-01, time/batch = 19.4478s	
16297/29850 (epoch 27.298), train_loss = 0.73849164, grad/param norm = 1.8721e-01, time/batch = 16.5494s	
16298/29850 (epoch 27.300), train_loss = 0.82098624, grad/param norm = 1.9041e-01, time/batch = 16.0926s	
16299/29850 (epoch 27.302), train_loss = 0.79973312, grad/param norm = 1.9474e-01, time/batch = 18.2202s	
16300/29850 (epoch 27.303), train_loss = 0.85766033, grad/param norm = 1.9875e-01, time/batch = 17.4674s	
16301/29850 (epoch 27.305), train_loss = 0.96838553, grad/param norm = 1.8955e-01, time/batch = 16.4616s	
16302/29850 (epoch 27.307), train_loss = 1.02437432, grad/param norm = 2.0902e-01, time/batch = 15.9793s	
16303/29850 (epoch 27.308), train_loss = 0.85815940, grad/param norm = 2.1584e-01, time/batch = 19.1273s	
16304/29850 (epoch 27.310), train_loss = 0.94045092, grad/param norm = 2.0613e-01, time/batch = 17.2108s	
16305/29850 (epoch 27.312), train_loss = 0.98967338, grad/param norm = 1.7916e-01, time/batch = 18.5173s	
16306/29850 (epoch 27.313), train_loss = 0.94462653, grad/param norm = 2.2620e-01, time/batch = 17.6309s	
16307/29850 (epoch 27.315), train_loss = 0.93906661, grad/param norm = 2.0711e-01, time/batch = 19.1303s	
16308/29850 (epoch 27.317), train_loss = 0.93976050, grad/param norm = 2.2992e-01, time/batch = 16.0279s	
16309/29850 (epoch 27.318), train_loss = 0.91370895, grad/param norm = 2.0702e-01, time/batch = 16.8542s	
16310/29850 (epoch 27.320), train_loss = 0.86377644, grad/param norm = 1.8862e-01, time/batch = 17.3888s	
16311/29850 (epoch 27.322), train_loss = 1.08758491, grad/param norm = 2.2488e-01, time/batch = 19.0317s	
16312/29850 (epoch 27.323), train_loss = 1.00112821, grad/param norm = 2.3752e-01, time/batch = 17.1268s	
16313/29850 (epoch 27.325), train_loss = 1.04095248, grad/param norm = 2.1411e-01, time/batch = 18.7208s	
16314/29850 (epoch 27.327), train_loss = 1.15819595, grad/param norm = 2.3995e-01, time/batch = 19.0426s	
16315/29850 (epoch 27.328), train_loss = 1.07384483, grad/param norm = 2.6076e-01, time/batch = 15.5989s	
16316/29850 (epoch 27.330), train_loss = 0.98726655, grad/param norm = 1.9565e-01, time/batch = 18.3794s	
16317/29850 (epoch 27.332), train_loss = 0.88273160, grad/param norm = 1.8728e-01, time/batch = 17.3710s	
16318/29850 (epoch 27.333), train_loss = 0.99151044, grad/param norm = 2.0724e-01, time/batch = 16.6952s	
16319/29850 (epoch 27.335), train_loss = 1.05585863, grad/param norm = 2.0453e-01, time/batch = 18.2079s	
16320/29850 (epoch 27.337), train_loss = 0.96336111, grad/param norm = 2.2373e-01, time/batch = 18.4691s	
16321/29850 (epoch 27.338), train_loss = 0.98267808, grad/param norm = 2.1519e-01, time/batch = 16.8563s	
16322/29850 (epoch 27.340), train_loss = 0.84296190, grad/param norm = 1.9562e-01, time/batch = 16.7328s	
16323/29850 (epoch 27.342), train_loss = 0.94522347, grad/param norm = 2.1514e-01, time/batch = 19.2180s	
16324/29850 (epoch 27.343), train_loss = 0.97016624, grad/param norm = 2.2236e-01, time/batch = 18.1313s	
16325/29850 (epoch 27.345), train_loss = 1.02949011, grad/param norm = 2.6603e-01, time/batch = 18.2918s	
16326/29850 (epoch 27.347), train_loss = 1.07403331, grad/param norm = 2.3584e-01, time/batch = 17.0617s	
16327/29850 (epoch 27.348), train_loss = 0.91003893, grad/param norm = 2.1115e-01, time/batch = 19.2867s	
16328/29850 (epoch 27.350), train_loss = 1.00414832, grad/param norm = 2.4856e-01, time/batch = 17.7775s	
16329/29850 (epoch 27.352), train_loss = 0.88697568, grad/param norm = 1.9905e-01, time/batch = 18.7856s	
16330/29850 (epoch 27.353), train_loss = 1.00033804, grad/param norm = 2.2268e-01, time/batch = 19.5351s	
16331/29850 (epoch 27.355), train_loss = 0.89426022, grad/param norm = 2.1152e-01, time/batch = 16.4561s	
16332/29850 (epoch 27.357), train_loss = 1.05722971, grad/param norm = 2.2561e-01, time/batch = 17.1812s	
16333/29850 (epoch 27.358), train_loss = 0.86381604, grad/param norm = 2.0527e-01, time/batch = 18.2003s	
16334/29850 (epoch 27.360), train_loss = 0.91055482, grad/param norm = 1.9923e-01, time/batch = 15.2171s	
16335/29850 (epoch 27.362), train_loss = 0.95050190, grad/param norm = 2.1298e-01, time/batch = 15.8902s	
16336/29850 (epoch 27.363), train_loss = 0.98590463, grad/param norm = 2.2563e-01, time/batch = 18.1200s	
16337/29850 (epoch 27.365), train_loss = 1.09922008, grad/param norm = 2.3695e-01, time/batch = 18.4631s	
16338/29850 (epoch 27.367), train_loss = 0.87094807, grad/param norm = 1.9820e-01, time/batch = 16.1963s	
16339/29850 (epoch 27.369), train_loss = 0.81976763, grad/param norm = 2.0582e-01, time/batch = 18.0442s	
16340/29850 (epoch 27.370), train_loss = 0.75949869, grad/param norm = 1.9147e-01, time/batch = 17.5583s	
16341/29850 (epoch 27.372), train_loss = 1.02302527, grad/param norm = 2.4021e-01, time/batch = 18.5340s	
16342/29850 (epoch 27.374), train_loss = 0.99851301, grad/param norm = 2.1008e-01, time/batch = 18.0303s	
16343/29850 (epoch 27.375), train_loss = 0.96487788, grad/param norm = 1.9549e-01, time/batch = 17.3058s	
16344/29850 (epoch 27.377), train_loss = 0.89882493, grad/param norm = 2.1394e-01, time/batch = 19.4588s	
16345/29850 (epoch 27.379), train_loss = 1.06619401, grad/param norm = 2.2068e-01, time/batch = 17.3797s	
16346/29850 (epoch 27.380), train_loss = 1.01479031, grad/param norm = 2.3368e-01, time/batch = 17.4675s	
16347/29850 (epoch 27.382), train_loss = 0.98938757, grad/param norm = 2.5410e-01, time/batch = 16.6771s	
16348/29850 (epoch 27.384), train_loss = 1.04176713, grad/param norm = 2.1386e-01, time/batch = 17.9360s	
16349/29850 (epoch 27.385), train_loss = 0.98498933, grad/param norm = 2.2011e-01, time/batch = 18.1239s	
16350/29850 (epoch 27.387), train_loss = 0.99572454, grad/param norm = 2.3128e-01, time/batch = 16.4857s	
16351/29850 (epoch 27.389), train_loss = 1.10006412, grad/param norm = 2.3939e-01, time/batch = 18.3022s	
16352/29850 (epoch 27.390), train_loss = 1.01329171, grad/param norm = 1.8904e-01, time/batch = 17.1959s	
16353/29850 (epoch 27.392), train_loss = 0.94210002, grad/param norm = 2.1418e-01, time/batch = 17.2737s	
16354/29850 (epoch 27.394), train_loss = 1.04254701, grad/param norm = 2.0851e-01, time/batch = 17.8052s	
16355/29850 (epoch 27.395), train_loss = 0.92237411, grad/param norm = 2.1150e-01, time/batch = 16.6143s	
16356/29850 (epoch 27.397), train_loss = 0.84842647, grad/param norm = 1.9899e-01, time/batch = 20.0387s	
16357/29850 (epoch 27.399), train_loss = 0.87226984, grad/param norm = 1.9081e-01, time/batch = 16.4049s	
16358/29850 (epoch 27.400), train_loss = 1.22481677, grad/param norm = 2.3684e-01, time/batch = 17.5463s	
16359/29850 (epoch 27.402), train_loss = 1.12312610, grad/param norm = 2.0690e-01, time/batch = 19.4285s	
16360/29850 (epoch 27.404), train_loss = 0.98151981, grad/param norm = 2.0428e-01, time/batch = 17.2907s	
16361/29850 (epoch 27.405), train_loss = 0.89205879, grad/param norm = 2.0941e-01, time/batch = 17.3171s	
16362/29850 (epoch 27.407), train_loss = 0.87009002, grad/param norm = 2.1953e-01, time/batch = 16.0484s	
16363/29850 (epoch 27.409), train_loss = 1.02019452, grad/param norm = 2.4816e-01, time/batch = 19.3807s	
16364/29850 (epoch 27.410), train_loss = 1.11844029, grad/param norm = 2.4147e-01, time/batch = 15.9433s	
16365/29850 (epoch 27.412), train_loss = 1.06915644, grad/param norm = 2.2966e-01, time/batch = 14.4741s	
16366/29850 (epoch 27.414), train_loss = 0.97913344, grad/param norm = 2.1641e-01, time/batch = 3.3251s	
16367/29850 (epoch 27.415), train_loss = 0.97028269, grad/param norm = 2.1626e-01, time/batch = 0.6465s	
16368/29850 (epoch 27.417), train_loss = 1.09850641, grad/param norm = 2.5121e-01, time/batch = 0.6429s	
16369/29850 (epoch 27.419), train_loss = 0.94427192, grad/param norm = 2.0592e-01, time/batch = 0.6484s	
16370/29850 (epoch 27.420), train_loss = 0.94591459, grad/param norm = 2.0448e-01, time/batch = 0.6516s	
16371/29850 (epoch 27.422), train_loss = 0.94127977, grad/param norm = 2.0338e-01, time/batch = 0.6441s	
16372/29850 (epoch 27.424), train_loss = 0.87431178, grad/param norm = 2.1407e-01, time/batch = 0.6448s	
16373/29850 (epoch 27.425), train_loss = 1.03618863, grad/param norm = 2.0281e-01, time/batch = 0.6782s	
16374/29850 (epoch 27.427), train_loss = 0.78533097, grad/param norm = 1.7195e-01, time/batch = 0.9583s	
16375/29850 (epoch 27.429), train_loss = 0.85826048, grad/param norm = 2.0426e-01, time/batch = 0.9550s	
16376/29850 (epoch 27.430), train_loss = 0.79450786, grad/param norm = 1.7506e-01, time/batch = 0.9746s	
16377/29850 (epoch 27.432), train_loss = 0.89997809, grad/param norm = 2.0608e-01, time/batch = 0.9684s	
16378/29850 (epoch 27.434), train_loss = 0.84831679, grad/param norm = 1.8364e-01, time/batch = 0.9407s	
16379/29850 (epoch 27.436), train_loss = 0.94594402, grad/param norm = 2.0959e-01, time/batch = 1.6796s	
16380/29850 (epoch 27.437), train_loss = 0.99677207, grad/param norm = 1.9315e-01, time/batch = 1.7555s	
16381/29850 (epoch 27.439), train_loss = 0.97999808, grad/param norm = 1.9205e-01, time/batch = 3.4734s	
16382/29850 (epoch 27.441), train_loss = 0.95437372, grad/param norm = 2.1855e-01, time/batch = 16.8903s	
16383/29850 (epoch 27.442), train_loss = 0.93249992, grad/param norm = 1.9425e-01, time/batch = 17.8194s	
16384/29850 (epoch 27.444), train_loss = 0.98400714, grad/param norm = 2.1144e-01, time/batch = 17.1787s	
16385/29850 (epoch 27.446), train_loss = 1.00613719, grad/param norm = 2.0629e-01, time/batch = 18.7881s	
16386/29850 (epoch 27.447), train_loss = 1.01427660, grad/param norm = 2.1820e-01, time/batch = 17.2166s	
16387/29850 (epoch 27.449), train_loss = 0.97956020, grad/param norm = 2.2543e-01, time/batch = 16.7820s	
16388/29850 (epoch 27.451), train_loss = 0.77655077, grad/param norm = 1.8095e-01, time/batch = 18.8528s	
16389/29850 (epoch 27.452), train_loss = 0.69746579, grad/param norm = 1.6406e-01, time/batch = 18.9683s	
16390/29850 (epoch 27.454), train_loss = 0.81324139, grad/param norm = 1.7583e-01, time/batch = 18.6061s	
16391/29850 (epoch 27.456), train_loss = 1.01367817, grad/param norm = 2.0903e-01, time/batch = 16.5299s	
16392/29850 (epoch 27.457), train_loss = 1.02077261, grad/param norm = 3.7262e-01, time/batch = 19.6281s	
16393/29850 (epoch 27.459), train_loss = 1.10896719, grad/param norm = 2.3816e-01, time/batch = 18.7228s	
16394/29850 (epoch 27.461), train_loss = 1.09665694, grad/param norm = 2.0933e-01, time/batch = 17.0510s	
16395/29850 (epoch 27.462), train_loss = 1.09380121, grad/param norm = 2.2447e-01, time/batch = 17.5471s	
16396/29850 (epoch 27.464), train_loss = 1.00533465, grad/param norm = 2.1954e-01, time/batch = 19.1257s	
16397/29850 (epoch 27.466), train_loss = 0.81811335, grad/param norm = 1.9885e-01, time/batch = 16.6212s	
16398/29850 (epoch 27.467), train_loss = 0.91264688, grad/param norm = 2.1670e-01, time/batch = 17.5409s	
16399/29850 (epoch 27.469), train_loss = 0.91040416, grad/param norm = 1.8613e-01, time/batch = 16.3656s	
16400/29850 (epoch 27.471), train_loss = 0.92005244, grad/param norm = 2.2149e-01, time/batch = 17.8877s	
16401/29850 (epoch 27.472), train_loss = 0.88796057, grad/param norm = 1.9958e-01, time/batch = 16.7124s	
16402/29850 (epoch 27.474), train_loss = 1.04726247, grad/param norm = 2.0791e-01, time/batch = 15.8003s	
16403/29850 (epoch 27.476), train_loss = 0.95251951, grad/param norm = 1.7922e-01, time/batch = 17.1017s	
16404/29850 (epoch 27.477), train_loss = 0.98674678, grad/param norm = 2.4970e-01, time/batch = 17.6162s	
16405/29850 (epoch 27.479), train_loss = 1.13156748, grad/param norm = 2.2043e-01, time/batch = 17.3013s	
16406/29850 (epoch 27.481), train_loss = 0.92865070, grad/param norm = 2.0784e-01, time/batch = 17.3232s	
16407/29850 (epoch 27.482), train_loss = 0.86090218, grad/param norm = 1.8516e-01, time/batch = 17.5559s	
16408/29850 (epoch 27.484), train_loss = 0.90510181, grad/param norm = 2.0048e-01, time/batch = 19.3606s	
16409/29850 (epoch 27.486), train_loss = 0.98476001, grad/param norm = 2.2574e-01, time/batch = 17.2970s	
16410/29850 (epoch 27.487), train_loss = 0.97262199, grad/param norm = 2.1935e-01, time/batch = 17.9760s	
16411/29850 (epoch 27.489), train_loss = 0.92597187, grad/param norm = 1.9592e-01, time/batch = 18.1925s	
16412/29850 (epoch 27.491), train_loss = 0.85971424, grad/param norm = 1.9698e-01, time/batch = 18.1256s	
16413/29850 (epoch 27.492), train_loss = 0.94647043, grad/param norm = 2.3035e-01, time/batch = 15.9032s	
16414/29850 (epoch 27.494), train_loss = 1.02743423, grad/param norm = 1.9925e-01, time/batch = 16.8626s	
16415/29850 (epoch 27.496), train_loss = 1.10162603, grad/param norm = 2.0335e-01, time/batch = 18.7027s	
16416/29850 (epoch 27.497), train_loss = 0.99059552, grad/param norm = 1.8547e-01, time/batch = 17.3068s	
16417/29850 (epoch 27.499), train_loss = 0.96588573, grad/param norm = 2.0636e-01, time/batch = 17.9616s	
16418/29850 (epoch 27.501), train_loss = 0.89900879, grad/param norm = 2.2485e-01, time/batch = 16.0083s	
16419/29850 (epoch 27.503), train_loss = 0.99357005, grad/param norm = 2.1103e-01, time/batch = 17.6146s	
16420/29850 (epoch 27.504), train_loss = 1.15404003, grad/param norm = 2.0788e-01, time/batch = 17.8737s	
16421/29850 (epoch 27.506), train_loss = 1.11403987, grad/param norm = 2.0268e-01, time/batch = 17.4618s	
16422/29850 (epoch 27.508), train_loss = 0.96478674, grad/param norm = 1.8764e-01, time/batch = 16.6055s	
16423/29850 (epoch 27.509), train_loss = 0.79391531, grad/param norm = 1.9940e-01, time/batch = 16.4753s	
16424/29850 (epoch 27.511), train_loss = 0.98251069, grad/param norm = 2.0297e-01, time/batch = 17.3860s	
16425/29850 (epoch 27.513), train_loss = 0.98426856, grad/param norm = 2.7558e-01, time/batch = 18.2958s	
16426/29850 (epoch 27.514), train_loss = 0.88184001, grad/param norm = 2.2305e-01, time/batch = 16.7315s	
16427/29850 (epoch 27.516), train_loss = 0.92285254, grad/param norm = 1.9020e-01, time/batch = 18.7950s	
16428/29850 (epoch 27.518), train_loss = 0.78069115, grad/param norm = 1.8781e-01, time/batch = 17.4599s	
16429/29850 (epoch 27.519), train_loss = 0.78124601, grad/param norm = 1.7848e-01, time/batch = 18.6260s	
16430/29850 (epoch 27.521), train_loss = 0.71844057, grad/param norm = 1.5966e-01, time/batch = 18.7916s	
16431/29850 (epoch 27.523), train_loss = 0.79221975, grad/param norm = 1.8058e-01, time/batch = 17.3600s	
16432/29850 (epoch 27.524), train_loss = 0.87269017, grad/param norm = 2.1792e-01, time/batch = 17.0524s	
16433/29850 (epoch 27.526), train_loss = 0.94797317, grad/param norm = 2.1997e-01, time/batch = 15.9535s	
16434/29850 (epoch 27.528), train_loss = 1.04334724, grad/param norm = 2.1908e-01, time/batch = 18.1294s	
16435/29850 (epoch 27.529), train_loss = 0.97313471, grad/param norm = 2.0978e-01, time/batch = 17.6136s	
16436/29850 (epoch 27.531), train_loss = 0.96785192, grad/param norm = 2.4684e-01, time/batch = 19.2091s	
16437/29850 (epoch 27.533), train_loss = 0.92853671, grad/param norm = 1.9939e-01, time/batch = 17.9302s	
16438/29850 (epoch 27.534), train_loss = 0.99012080, grad/param norm = 2.2157e-01, time/batch = 17.4477s	
16439/29850 (epoch 27.536), train_loss = 0.87431266, grad/param norm = 1.9529e-01, time/batch = 18.3775s	
16440/29850 (epoch 27.538), train_loss = 1.06128134, grad/param norm = 2.2819e-01, time/batch = 18.5565s	
16441/29850 (epoch 27.539), train_loss = 1.10012232, grad/param norm = 2.1609e-01, time/batch = 17.3626s	
16442/29850 (epoch 27.541), train_loss = 0.71842487, grad/param norm = 1.8726e-01, time/batch = 18.6211s	
16443/29850 (epoch 27.543), train_loss = 0.92463777, grad/param norm = 2.0827e-01, time/batch = 16.1305s	
16444/29850 (epoch 27.544), train_loss = 1.01952831, grad/param norm = 1.9540e-01, time/batch = 19.3804s	
16445/29850 (epoch 27.546), train_loss = 1.01078273, grad/param norm = 2.1248e-01, time/batch = 18.4363s	
16446/29850 (epoch 27.548), train_loss = 0.82616093, grad/param norm = 1.9506e-01, time/batch = 17.5403s	
16447/29850 (epoch 27.549), train_loss = 0.90334009, grad/param norm = 2.1696e-01, time/batch = 19.3852s	
16448/29850 (epoch 27.551), train_loss = 0.81846666, grad/param norm = 1.8723e-01, time/batch = 15.2597s	
16449/29850 (epoch 27.553), train_loss = 0.91795261, grad/param norm = 1.9100e-01, time/batch = 18.1287s	
16450/29850 (epoch 27.554), train_loss = 0.78425523, grad/param norm = 1.7940e-01, time/batch = 17.4743s	
16451/29850 (epoch 27.556), train_loss = 0.83879310, grad/param norm = 2.1293e-01, time/batch = 17.7104s	
16452/29850 (epoch 27.558), train_loss = 0.84008576, grad/param norm = 1.8942e-01, time/batch = 17.5467s	
16453/29850 (epoch 27.559), train_loss = 0.89011780, grad/param norm = 1.8884e-01, time/batch = 18.1362s	
16454/29850 (epoch 27.561), train_loss = 0.98799803, grad/param norm = 2.2380e-01, time/batch = 16.8762s	
16455/29850 (epoch 27.563), train_loss = 0.95771900, grad/param norm = 2.0049e-01, time/batch = 18.4635s	
16456/29850 (epoch 27.564), train_loss = 0.91354291, grad/param norm = 2.4235e-01, time/batch = 19.1270s	
16457/29850 (epoch 27.566), train_loss = 0.95833737, grad/param norm = 2.2526e-01, time/batch = 16.2969s	
16458/29850 (epoch 27.568), train_loss = 1.01249779, grad/param norm = 2.0192e-01, time/batch = 15.9475s	
16459/29850 (epoch 27.570), train_loss = 0.98449042, grad/param norm = 2.2953e-01, time/batch = 16.8896s	
16460/29850 (epoch 27.571), train_loss = 1.04203292, grad/param norm = 2.2151e-01, time/batch = 18.8837s	
16461/29850 (epoch 27.573), train_loss = 1.10410934, grad/param norm = 2.3350e-01, time/batch = 17.8867s	
16462/29850 (epoch 27.575), train_loss = 1.08639733, grad/param norm = 2.0960e-01, time/batch = 16.3803s	
16463/29850 (epoch 27.576), train_loss = 1.05475389, grad/param norm = 2.3498e-01, time/batch = 18.9565s	
16464/29850 (epoch 27.578), train_loss = 0.90187235, grad/param norm = 2.1042e-01, time/batch = 18.8952s	
16465/29850 (epoch 27.580), train_loss = 1.04695508, grad/param norm = 1.9968e-01, time/batch = 15.5464s	
16466/29850 (epoch 27.581), train_loss = 0.86403671, grad/param norm = 1.8382e-01, time/batch = 17.2088s	
16467/29850 (epoch 27.583), train_loss = 0.95304450, grad/param norm = 2.2332e-01, time/batch = 17.7948s	
16468/29850 (epoch 27.585), train_loss = 0.98210998, grad/param norm = 2.1655e-01, time/batch = 18.5370s	
16469/29850 (epoch 27.586), train_loss = 0.97171267, grad/param norm = 2.3701e-01, time/batch = 17.9637s	
16470/29850 (epoch 27.588), train_loss = 0.90376206, grad/param norm = 2.0856e-01, time/batch = 17.2156s	
16471/29850 (epoch 27.590), train_loss = 0.92197212, grad/param norm = 2.4534e-01, time/batch = 16.7066s	
16472/29850 (epoch 27.591), train_loss = 0.92295621, grad/param norm = 2.1642e-01, time/batch = 16.8017s	
16473/29850 (epoch 27.593), train_loss = 0.88566250, grad/param norm = 2.0425e-01, time/batch = 18.0579s	
16474/29850 (epoch 27.595), train_loss = 0.82208019, grad/param norm = 1.6837e-01, time/batch = 16.3582s	
16475/29850 (epoch 27.596), train_loss = 0.81076434, grad/param norm = 1.8951e-01, time/batch = 17.7082s	
16476/29850 (epoch 27.598), train_loss = 0.94272185, grad/param norm = 2.0476e-01, time/batch = 16.2044s	
16477/29850 (epoch 27.600), train_loss = 0.97711143, grad/param norm = 2.1303e-01, time/batch = 17.6136s	
16478/29850 (epoch 27.601), train_loss = 0.81962913, grad/param norm = 1.7189e-01, time/batch = 16.4746s	
16479/29850 (epoch 27.603), train_loss = 0.88219441, grad/param norm = 1.9306e-01, time/batch = 17.0372s	
16480/29850 (epoch 27.605), train_loss = 0.91532576, grad/param norm = 1.9276e-01, time/batch = 18.1417s	
16481/29850 (epoch 27.606), train_loss = 0.68260975, grad/param norm = 1.6890e-01, time/batch = 19.0500s	
16482/29850 (epoch 27.608), train_loss = 0.84307427, grad/param norm = 1.8546e-01, time/batch = 26.2576s	
16483/29850 (epoch 27.610), train_loss = 0.92564147, grad/param norm = 2.1368e-01, time/batch = 23.2258s	
16484/29850 (epoch 27.611), train_loss = 0.84729323, grad/param norm = 1.9138e-01, time/batch = 17.5578s	
16485/29850 (epoch 27.613), train_loss = 0.69480241, grad/param norm = 1.6950e-01, time/batch = 18.9407s	
16486/29850 (epoch 27.615), train_loss = 0.83187167, grad/param norm = 1.8795e-01, time/batch = 17.4536s	
16487/29850 (epoch 27.616), train_loss = 0.82259798, grad/param norm = 2.0103e-01, time/batch = 16.6339s	
16488/29850 (epoch 27.618), train_loss = 0.88803481, grad/param norm = 2.2383e-01, time/batch = 16.8666s	
16489/29850 (epoch 27.620), train_loss = 0.94540414, grad/param norm = 2.0641e-01, time/batch = 18.2206s	
16490/29850 (epoch 27.621), train_loss = 1.07390276, grad/param norm = 2.1520e-01, time/batch = 18.9636s	
16491/29850 (epoch 27.623), train_loss = 0.99816674, grad/param norm = 2.1489e-01, time/batch = 18.1981s	
16492/29850 (epoch 27.625), train_loss = 0.94856138, grad/param norm = 2.5533e-01, time/batch = 18.4521s	
16493/29850 (epoch 27.626), train_loss = 0.97629511, grad/param norm = 2.1031e-01, time/batch = 17.7212s	
16494/29850 (epoch 27.628), train_loss = 0.86288646, grad/param norm = 1.8761e-01, time/batch = 15.0400s	
16495/29850 (epoch 27.630), train_loss = 0.94894629, grad/param norm = 2.5252e-01, time/batch = 17.6717s	
16496/29850 (epoch 27.631), train_loss = 0.92236834, grad/param norm = 2.0986e-01, time/batch = 19.2725s	
16497/29850 (epoch 27.633), train_loss = 0.99456658, grad/param norm = 2.3058e-01, time/batch = 17.5484s	
16498/29850 (epoch 27.635), train_loss = 0.89692358, grad/param norm = 2.2594e-01, time/batch = 16.2870s	
16499/29850 (epoch 27.637), train_loss = 0.86111758, grad/param norm = 2.0376e-01, time/batch = 18.6342s	
16500/29850 (epoch 27.638), train_loss = 0.98243704, grad/param norm = 2.1497e-01, time/batch = 19.1279s	
16501/29850 (epoch 27.640), train_loss = 1.07012230, grad/param norm = 2.2424e-01, time/batch = 17.3725s	
16502/29850 (epoch 27.642), train_loss = 0.85561899, grad/param norm = 1.8378e-01, time/batch = 19.0173s	
16503/29850 (epoch 27.643), train_loss = 0.86238787, grad/param norm = 2.2455e-01, time/batch = 17.6047s	
16504/29850 (epoch 27.645), train_loss = 0.89827714, grad/param norm = 1.9908e-01, time/batch = 16.5340s	
16505/29850 (epoch 27.647), train_loss = 1.07724350, grad/param norm = 2.3319e-01, time/batch = 18.3588s	
16506/29850 (epoch 27.648), train_loss = 0.82179437, grad/param norm = 1.8305e-01, time/batch = 18.7942s	
16507/29850 (epoch 27.650), train_loss = 0.96638389, grad/param norm = 2.1169e-01, time/batch = 19.2039s	
16508/29850 (epoch 27.652), train_loss = 0.94412856, grad/param norm = 2.3093e-01, time/batch = 16.1205s	
16509/29850 (epoch 27.653), train_loss = 1.03047886, grad/param norm = 2.3307e-01, time/batch = 19.7794s	
16510/29850 (epoch 27.655), train_loss = 0.93561769, grad/param norm = 1.8257e-01, time/batch = 18.6363s	
16511/29850 (epoch 27.657), train_loss = 0.90905838, grad/param norm = 2.0659e-01, time/batch = 17.0557s	
16512/29850 (epoch 27.658), train_loss = 1.04312502, grad/param norm = 2.0412e-01, time/batch = 17.5350s	
16513/29850 (epoch 27.660), train_loss = 0.92886263, grad/param norm = 2.2507e-01, time/batch = 18.2952s	
16514/29850 (epoch 27.662), train_loss = 1.02022969, grad/param norm = 2.2626e-01, time/batch = 18.3781s	
16515/29850 (epoch 27.663), train_loss = 1.13637460, grad/param norm = 2.2248e-01, time/batch = 16.1115s	
16516/29850 (epoch 27.665), train_loss = 1.07693006, grad/param norm = 2.3788e-01, time/batch = 17.5516s	
16517/29850 (epoch 27.667), train_loss = 0.99672838, grad/param norm = 2.3222e-01, time/batch = 18.3119s	
16518/29850 (epoch 27.668), train_loss = 0.92669761, grad/param norm = 2.3088e-01, time/batch = 15.8842s	
16519/29850 (epoch 27.670), train_loss = 1.06988915, grad/param norm = 2.7476e-01, time/batch = 17.0930s	
16520/29850 (epoch 27.672), train_loss = 1.06542767, grad/param norm = 2.5487e-01, time/batch = 18.6325s	
16521/29850 (epoch 27.673), train_loss = 0.99672354, grad/param norm = 2.2565e-01, time/batch = 16.4370s	
16522/29850 (epoch 27.675), train_loss = 0.82763983, grad/param norm = 1.8791e-01, time/batch = 18.4391s	
16523/29850 (epoch 27.677), train_loss = 0.91340842, grad/param norm = 2.0320e-01, time/batch = 19.2930s	
16524/29850 (epoch 27.678), train_loss = 0.92602682, grad/param norm = 1.9668e-01, time/batch = 18.8012s	
16525/29850 (epoch 27.680), train_loss = 0.93101822, grad/param norm = 2.0010e-01, time/batch = 16.1738s	
16526/29850 (epoch 27.682), train_loss = 0.94896896, grad/param norm = 2.1454e-01, time/batch = 18.4668s	
16527/29850 (epoch 27.683), train_loss = 1.07510563, grad/param norm = 2.3851e-01, time/batch = 17.7176s	
16528/29850 (epoch 27.685), train_loss = 1.11838224, grad/param norm = 1.9356e-01, time/batch = 18.0379s	
16529/29850 (epoch 27.687), train_loss = 0.98459182, grad/param norm = 2.2000e-01, time/batch = 19.9524s	
16530/29850 (epoch 27.688), train_loss = 0.82645428, grad/param norm = 1.9396e-01, time/batch = 15.6566s	
16531/29850 (epoch 27.690), train_loss = 0.82522186, grad/param norm = 1.8567e-01, time/batch = 16.5583s	
16532/29850 (epoch 27.692), train_loss = 1.03757820, grad/param norm = 2.0856e-01, time/batch = 16.4378s	
16533/29850 (epoch 27.693), train_loss = 0.93453397, grad/param norm = 2.0197e-01, time/batch = 17.2240s	
16534/29850 (epoch 27.695), train_loss = 0.82710425, grad/param norm = 1.9437e-01, time/batch = 16.4001s	
16535/29850 (epoch 27.697), train_loss = 0.93904808, grad/param norm = 2.0447e-01, time/batch = 16.7184s	
16536/29850 (epoch 27.698), train_loss = 1.07851532, grad/param norm = 2.1075e-01, time/batch = 15.5518s	
16537/29850 (epoch 27.700), train_loss = 1.03625429, grad/param norm = 2.2018e-01, time/batch = 16.3122s	
16538/29850 (epoch 27.702), train_loss = 0.95426474, grad/param norm = 2.0715e-01, time/batch = 16.0571s	
16539/29850 (epoch 27.704), train_loss = 0.83595119, grad/param norm = 2.0469e-01, time/batch = 17.8524s	
16540/29850 (epoch 27.705), train_loss = 0.95673296, grad/param norm = 2.0632e-01, time/batch = 19.8700s	
16541/29850 (epoch 27.707), train_loss = 0.86360348, grad/param norm = 2.1510e-01, time/batch = 16.9505s	
16542/29850 (epoch 27.709), train_loss = 0.94195819, grad/param norm = 2.2381e-01, time/batch = 16.5549s	
16543/29850 (epoch 27.710), train_loss = 0.86817246, grad/param norm = 1.9501e-01, time/batch = 16.3757s	
16544/29850 (epoch 27.712), train_loss = 0.96388840, grad/param norm = 1.8826e-01, time/batch = 17.5957s	
16545/29850 (epoch 27.714), train_loss = 1.03093304, grad/param norm = 2.3754e-01, time/batch = 18.1260s	
16546/29850 (epoch 27.715), train_loss = 0.96614339, grad/param norm = 2.2783e-01, time/batch = 18.0357s	
16547/29850 (epoch 27.717), train_loss = 0.71776522, grad/param norm = 1.8439e-01, time/batch = 19.2188s	
16548/29850 (epoch 27.719), train_loss = 0.89990858, grad/param norm = 1.9538e-01, time/batch = 19.4816s	
16549/29850 (epoch 27.720), train_loss = 0.94376339, grad/param norm = 2.0868e-01, time/batch = 16.6749s	
16550/29850 (epoch 27.722), train_loss = 0.86726765, grad/param norm = 1.7967e-01, time/batch = 18.3072s	
16551/29850 (epoch 27.724), train_loss = 0.98779090, grad/param norm = 2.2627e-01, time/batch = 16.6442s	
16552/29850 (epoch 27.725), train_loss = 0.81898914, grad/param norm = 1.7951e-01, time/batch = 17.7923s	
16553/29850 (epoch 27.727), train_loss = 0.85091827, grad/param norm = 2.1455e-01, time/batch = 16.0304s	
16554/29850 (epoch 27.729), train_loss = 0.80621196, grad/param norm = 1.8525e-01, time/batch = 16.3984s	
16555/29850 (epoch 27.730), train_loss = 0.75221661, grad/param norm = 1.8178e-01, time/batch = 14.9600s	
16556/29850 (epoch 27.732), train_loss = 1.01580330, grad/param norm = 1.9202e-01, time/batch = 16.3615s	
16557/29850 (epoch 27.734), train_loss = 1.11295360, grad/param norm = 2.3186e-01, time/batch = 16.7124s	
16558/29850 (epoch 27.735), train_loss = 0.86390547, grad/param norm = 2.1666e-01, time/batch = 16.1330s	
16559/29850 (epoch 27.737), train_loss = 0.83124974, grad/param norm = 1.8967e-01, time/batch = 16.9619s	
16560/29850 (epoch 27.739), train_loss = 0.71973015, grad/param norm = 1.8460e-01, time/batch = 14.8652s	
16561/29850 (epoch 27.740), train_loss = 0.81150268, grad/param norm = 2.0033e-01, time/batch = 15.9534s	
16562/29850 (epoch 27.742), train_loss = 0.73766939, grad/param norm = 1.8633e-01, time/batch = 16.3581s	
16563/29850 (epoch 27.744), train_loss = 0.86512938, grad/param norm = 2.2074e-01, time/batch = 16.4505s	
16564/29850 (epoch 27.745), train_loss = 0.86152056, grad/param norm = 2.0670e-01, time/batch = 16.2116s	
16565/29850 (epoch 27.747), train_loss = 0.90027387, grad/param norm = 2.0544e-01, time/batch = 17.3755s	
16566/29850 (epoch 27.749), train_loss = 0.80642661, grad/param norm = 2.1957e-01, time/batch = 19.7991s	
16567/29850 (epoch 27.750), train_loss = 0.76007668, grad/param norm = 1.8580e-01, time/batch = 15.0428s	
16568/29850 (epoch 27.752), train_loss = 0.68333377, grad/param norm = 1.7126e-01, time/batch = 16.5694s	
16569/29850 (epoch 27.754), train_loss = 0.77809757, grad/param norm = 1.9563e-01, time/batch = 18.7088s	
16570/29850 (epoch 27.755), train_loss = 0.78405648, grad/param norm = 1.9307e-01, time/batch = 16.4696s	
16571/29850 (epoch 27.757), train_loss = 0.82927045, grad/param norm = 1.7978e-01, time/batch = 19.0501s	
16572/29850 (epoch 27.759), train_loss = 0.81943178, grad/param norm = 1.7481e-01, time/batch = 18.2175s	
16573/29850 (epoch 27.760), train_loss = 0.83105553, grad/param norm = 2.2082e-01, time/batch = 16.1922s	
16574/29850 (epoch 27.762), train_loss = 0.78519223, grad/param norm = 2.2825e-01, time/batch = 18.7821s	
16575/29850 (epoch 27.764), train_loss = 0.72280404, grad/param norm = 1.9053e-01, time/batch = 16.4441s	
16576/29850 (epoch 27.765), train_loss = 0.88484071, grad/param norm = 2.1557e-01, time/batch = 18.4662s	
16577/29850 (epoch 27.767), train_loss = 0.86843443, grad/param norm = 1.8340e-01, time/batch = 17.1258s	
16578/29850 (epoch 27.769), train_loss = 0.89242472, grad/param norm = 2.0221e-01, time/batch = 18.2109s	
16579/29850 (epoch 27.771), train_loss = 0.94339908, grad/param norm = 2.0822e-01, time/batch = 17.3965s	
16580/29850 (epoch 27.772), train_loss = 0.92591436, grad/param norm = 2.1471e-01, time/batch = 17.3040s	
16581/29850 (epoch 27.774), train_loss = 0.87642933, grad/param norm = 2.0192e-01, time/batch = 18.6187s	
16582/29850 (epoch 27.776), train_loss = 0.86781647, grad/param norm = 1.9497e-01, time/batch = 16.0364s	
16583/29850 (epoch 27.777), train_loss = 0.98173837, grad/param norm = 2.1651e-01, time/batch = 18.6468s	
16584/29850 (epoch 27.779), train_loss = 0.81339545, grad/param norm = 1.9555e-01, time/batch = 15.1084s	
16585/29850 (epoch 27.781), train_loss = 0.93303065, grad/param norm = 2.3079e-01, time/batch = 18.2176s	
16586/29850 (epoch 27.782), train_loss = 0.96386739, grad/param norm = 2.1539e-01, time/batch = 16.9669s	
16587/29850 (epoch 27.784), train_loss = 0.78995365, grad/param norm = 2.7715e-01, time/batch = 16.4424s	
16588/29850 (epoch 27.786), train_loss = 0.85299914, grad/param norm = 1.8287e-01, time/batch = 15.9653s	
16589/29850 (epoch 27.787), train_loss = 0.73609543, grad/param norm = 2.0345e-01, time/batch = 17.7936s	
16590/29850 (epoch 27.789), train_loss = 0.75360549, grad/param norm = 1.8614e-01, time/batch = 15.8811s	
16591/29850 (epoch 27.791), train_loss = 0.84615347, grad/param norm = 2.1019e-01, time/batch = 17.6202s	
16592/29850 (epoch 27.792), train_loss = 0.95998992, grad/param norm = 2.1231e-01, time/batch = 15.2085s	
16593/29850 (epoch 27.794), train_loss = 0.92741065, grad/param norm = 1.9296e-01, time/batch = 16.9711s	
16594/29850 (epoch 27.796), train_loss = 0.79737791, grad/param norm = 1.8416e-01, time/batch = 16.6381s	
16595/29850 (epoch 27.797), train_loss = 0.72454077, grad/param norm = 1.8321e-01, time/batch = 15.7991s	
16596/29850 (epoch 27.799), train_loss = 0.73696545, grad/param norm = 1.6369e-01, time/batch = 16.7302s	
16597/29850 (epoch 27.801), train_loss = 0.81846441, grad/param norm = 1.8119e-01, time/batch = 17.6369s	
16598/29850 (epoch 27.802), train_loss = 0.74392295, grad/param norm = 1.9285e-01, time/batch = 16.0512s	
16599/29850 (epoch 27.804), train_loss = 0.76838466, grad/param norm = 1.7990e-01, time/batch = 16.7972s	
16600/29850 (epoch 27.806), train_loss = 0.76059328, grad/param norm = 1.8605e-01, time/batch = 17.2167s	
16601/29850 (epoch 27.807), train_loss = 0.74945225, grad/param norm = 1.6481e-01, time/batch = 17.2156s	
16602/29850 (epoch 27.809), train_loss = 0.77704196, grad/param norm = 1.9683e-01, time/batch = 16.2062s	
16603/29850 (epoch 27.811), train_loss = 0.93722840, grad/param norm = 2.0175e-01, time/batch = 15.6519s	
16604/29850 (epoch 27.812), train_loss = 0.93444652, grad/param norm = 2.4372e-01, time/batch = 15.3803s	
16605/29850 (epoch 27.814), train_loss = 0.98834854, grad/param norm = 2.1304e-01, time/batch = 16.7100s	
16606/29850 (epoch 27.816), train_loss = 0.97778316, grad/param norm = 2.0087e-01, time/batch = 15.2132s	
16607/29850 (epoch 27.817), train_loss = 0.92417384, grad/param norm = 2.1672e-01, time/batch = 17.6370s	
16608/29850 (epoch 27.819), train_loss = 0.76817154, grad/param norm = 2.2282e-01, time/batch = 15.9523s	
16609/29850 (epoch 27.821), train_loss = 0.99595229, grad/param norm = 2.5854e-01, time/batch = 15.4578s	
16610/29850 (epoch 27.822), train_loss = 0.99869843, grad/param norm = 2.1364e-01, time/batch = 15.4053s	
16611/29850 (epoch 27.824), train_loss = 0.89013924, grad/param norm = 1.8734e-01, time/batch = 16.0899s	
16612/29850 (epoch 27.826), train_loss = 0.80094098, grad/param norm = 1.9898e-01, time/batch = 16.8922s	
16613/29850 (epoch 27.827), train_loss = 0.74449914, grad/param norm = 1.9893e-01, time/batch = 15.7135s	
16614/29850 (epoch 27.829), train_loss = 0.90493283, grad/param norm = 2.3355e-01, time/batch = 15.2808s	
16615/29850 (epoch 27.831), train_loss = 0.99021581, grad/param norm = 2.3869e-01, time/batch = 18.3791s	
16616/29850 (epoch 27.832), train_loss = 0.89683436, grad/param norm = 1.8679e-01, time/batch = 16.9555s	
16617/29850 (epoch 27.834), train_loss = 0.68765218, grad/param norm = 1.6760e-01, time/batch = 19.1155s	
16618/29850 (epoch 27.836), train_loss = 0.73388399, grad/param norm = 1.8757e-01, time/batch = 16.8817s	
16619/29850 (epoch 27.838), train_loss = 0.84618776, grad/param norm = 2.1355e-01, time/batch = 17.7750s	
16620/29850 (epoch 27.839), train_loss = 0.74098357, grad/param norm = 1.7912e-01, time/batch = 16.1241s	
16621/29850 (epoch 27.841), train_loss = 0.78710387, grad/param norm = 1.8712e-01, time/batch = 17.5459s	
16622/29850 (epoch 27.843), train_loss = 0.72537822, grad/param norm = 1.8435e-01, time/batch = 17.4708s	
16623/29850 (epoch 27.844), train_loss = 0.80067261, grad/param norm = 1.9959e-01, time/batch = 17.2934s	
16624/29850 (epoch 27.846), train_loss = 0.90686935, grad/param norm = 2.0910e-01, time/batch = 16.7967s	
16625/29850 (epoch 27.848), train_loss = 0.94245112, grad/param norm = 2.2375e-01, time/batch = 18.8839s	
16626/29850 (epoch 27.849), train_loss = 0.84192127, grad/param norm = 2.1268e-01, time/batch = 15.8497s	
16627/29850 (epoch 27.851), train_loss = 0.99981950, grad/param norm = 2.3242e-01, time/batch = 18.2840s	
16628/29850 (epoch 27.853), train_loss = 0.82764017, grad/param norm = 2.0955e-01, time/batch = 17.7952s	
16629/29850 (epoch 27.854), train_loss = 1.04139742, grad/param norm = 2.2212e-01, time/batch = 17.8755s	
16630/29850 (epoch 27.856), train_loss = 0.97604135, grad/param norm = 2.3273e-01, time/batch = 15.6155s	
16631/29850 (epoch 27.858), train_loss = 0.91643060, grad/param norm = 1.9806e-01, time/batch = 17.6432s	
16632/29850 (epoch 27.859), train_loss = 0.78513214, grad/param norm = 2.3227e-01, time/batch = 17.4678s	
16633/29850 (epoch 27.861), train_loss = 1.02105054, grad/param norm = 2.4048e-01, time/batch = 17.4651s	
16634/29850 (epoch 27.863), train_loss = 1.08248319, grad/param norm = 2.4632e-01, time/batch = 17.5246s	
16635/29850 (epoch 27.864), train_loss = 1.02038365, grad/param norm = 2.4373e-01, time/batch = 15.4652s	
16636/29850 (epoch 27.866), train_loss = 0.90809352, grad/param norm = 2.3046e-01, time/batch = 18.7222s	
16637/29850 (epoch 27.868), train_loss = 1.09566703, grad/param norm = 2.6415e-01, time/batch = 16.6270s	
16638/29850 (epoch 27.869), train_loss = 0.97006929, grad/param norm = 2.3572e-01, time/batch = 15.7153s	
16639/29850 (epoch 27.871), train_loss = 0.98272672, grad/param norm = 2.1142e-01, time/batch = 15.1518s	
16640/29850 (epoch 27.873), train_loss = 0.94431202, grad/param norm = 2.4597e-01, time/batch = 18.2130s	
16641/29850 (epoch 27.874), train_loss = 0.94559313, grad/param norm = 2.1245e-01, time/batch = 19.2694s	
16642/29850 (epoch 27.876), train_loss = 0.90207332, grad/param norm = 3.3864e-01, time/batch = 18.2929s	
16643/29850 (epoch 27.878), train_loss = 0.92578920, grad/param norm = 1.9673e-01, time/batch = 17.3674s	
16644/29850 (epoch 27.879), train_loss = 0.94381840, grad/param norm = 2.0834e-01, time/batch = 16.8755s	
16645/29850 (epoch 27.881), train_loss = 1.00412442, grad/param norm = 2.2051e-01, time/batch = 19.1908s	
16646/29850 (epoch 27.883), train_loss = 1.00590310, grad/param norm = 2.2979e-01, time/batch = 19.7956s	
16647/29850 (epoch 27.884), train_loss = 0.82163828, grad/param norm = 2.0331e-01, time/batch = 16.5955s	
16648/29850 (epoch 27.886), train_loss = 1.03188396, grad/param norm = 2.5346e-01, time/batch = 18.3053s	
16649/29850 (epoch 27.888), train_loss = 0.92667695, grad/param norm = 2.2253e-01, time/batch = 17.6265s	
16650/29850 (epoch 27.889), train_loss = 0.85041445, grad/param norm = 1.7870e-01, time/batch = 16.7001s	
16651/29850 (epoch 27.891), train_loss = 0.81569363, grad/param norm = 1.7858e-01, time/batch = 17.2814s	
16652/29850 (epoch 27.893), train_loss = 0.87287596, grad/param norm = 2.0602e-01, time/batch = 19.2086s	
16653/29850 (epoch 27.894), train_loss = 0.90126287, grad/param norm = 2.4608e-01, time/batch = 18.5461s	
16654/29850 (epoch 27.896), train_loss = 0.92074018, grad/param norm = 2.2853e-01, time/batch = 16.9537s	
16655/29850 (epoch 27.898), train_loss = 1.05201309, grad/param norm = 2.4344e-01, time/batch = 16.1872s	
16656/29850 (epoch 27.899), train_loss = 0.81854826, grad/param norm = 2.0557e-01, time/batch = 17.2927s	
16657/29850 (epoch 27.901), train_loss = 1.18332626, grad/param norm = 3.1287e-01, time/batch = 18.2957s	
16658/29850 (epoch 27.903), train_loss = 0.95987972, grad/param norm = 2.9329e-01, time/batch = 16.2892s	
16659/29850 (epoch 27.905), train_loss = 1.16882257, grad/param norm = 2.4167e-01, time/batch = 18.7215s	
16660/29850 (epoch 27.906), train_loss = 0.97508916, grad/param norm = 2.1912e-01, time/batch = 16.1387s	
16661/29850 (epoch 27.908), train_loss = 1.06011727, grad/param norm = 2.1373e-01, time/batch = 18.0431s	
16662/29850 (epoch 27.910), train_loss = 0.99186964, grad/param norm = 1.9940e-01, time/batch = 19.0372s	
16663/29850 (epoch 27.911), train_loss = 1.13863979, grad/param norm = 2.2652e-01, time/batch = 17.6316s	
16664/29850 (epoch 27.913), train_loss = 1.07762222, grad/param norm = 2.1924e-01, time/batch = 16.8372s	
16665/29850 (epoch 27.915), train_loss = 1.06800736, grad/param norm = 2.2746e-01, time/batch = 15.6228s	
16666/29850 (epoch 27.916), train_loss = 1.01473908, grad/param norm = 2.1753e-01, time/batch = 19.7056s	
16667/29850 (epoch 27.918), train_loss = 0.85858599, grad/param norm = 1.9764e-01, time/batch = 17.5453s	
16668/29850 (epoch 27.920), train_loss = 1.04526422, grad/param norm = 1.9684e-01, time/batch = 19.7107s	
16669/29850 (epoch 27.921), train_loss = 0.94673009, grad/param norm = 2.4307e-01, time/batch = 16.8778s	
16670/29850 (epoch 27.923), train_loss = 0.98687081, grad/param norm = 2.2160e-01, time/batch = 17.6445s	
16671/29850 (epoch 27.925), train_loss = 1.08482454, grad/param norm = 2.3416e-01, time/batch = 15.5271s	
16672/29850 (epoch 27.926), train_loss = 1.08498687, grad/param norm = 2.4172e-01, time/batch = 16.2059s	
16673/29850 (epoch 27.928), train_loss = 0.96145513, grad/param norm = 2.2720e-01, time/batch = 18.3095s	
16674/29850 (epoch 27.930), train_loss = 0.98059523, grad/param norm = 2.2524e-01, time/batch = 15.1995s	
16675/29850 (epoch 27.931), train_loss = 0.92765249, grad/param norm = 1.9951e-01, time/batch = 19.0369s	
16676/29850 (epoch 27.933), train_loss = 1.09463407, grad/param norm = 2.1407e-01, time/batch = 17.9575s	
16677/29850 (epoch 27.935), train_loss = 1.02528568, grad/param norm = 2.5653e-01, time/batch = 16.4723s	
16678/29850 (epoch 27.936), train_loss = 0.95362034, grad/param norm = 2.2306e-01, time/batch = 16.2845s	
16679/29850 (epoch 27.938), train_loss = 0.83524323, grad/param norm = 1.9431e-01, time/batch = 17.9835s	
16680/29850 (epoch 27.940), train_loss = 0.82796035, grad/param norm = 1.9853e-01, time/batch = 19.6174s	
16681/29850 (epoch 27.941), train_loss = 0.88162098, grad/param norm = 2.3352e-01, time/batch = 17.0504s	
16682/29850 (epoch 27.943), train_loss = 0.84763014, grad/param norm = 1.9496e-01, time/batch = 19.4489s	
16683/29850 (epoch 27.945), train_loss = 0.86331644, grad/param norm = 2.2950e-01, time/batch = 18.5520s	
16684/29850 (epoch 27.946), train_loss = 0.82943532, grad/param norm = 2.0462e-01, time/batch = 16.9690s	
16685/29850 (epoch 27.948), train_loss = 0.95651333, grad/param norm = 1.8988e-01, time/batch = 16.8699s	
16686/29850 (epoch 27.950), train_loss = 0.87112223, grad/param norm = 1.9220e-01, time/batch = 18.0274s	
16687/29850 (epoch 27.951), train_loss = 0.79314662, grad/param norm = 1.8200e-01, time/batch = 19.8716s	
16688/29850 (epoch 27.953), train_loss = 0.91417554, grad/param norm = 2.6819e-01, time/batch = 33.5858s	
16689/29850 (epoch 27.955), train_loss = 0.82061597, grad/param norm = 1.8957e-01, time/batch = 16.1048s	
16690/29850 (epoch 27.956), train_loss = 0.80026111, grad/param norm = 1.9081e-01, time/batch = 16.6118s	
16691/29850 (epoch 27.958), train_loss = 0.69593417, grad/param norm = 1.6120e-01, time/batch = 17.2984s	
16692/29850 (epoch 27.960), train_loss = 1.01481422, grad/param norm = 2.3730e-01, time/batch = 16.2940s	
16693/29850 (epoch 27.961), train_loss = 0.80192045, grad/param norm = 1.9722e-01, time/batch = 16.2080s	
16694/29850 (epoch 27.963), train_loss = 0.77717734, grad/param norm = 1.9101e-01, time/batch = 16.3928s	
16695/29850 (epoch 27.965), train_loss = 0.84582999, grad/param norm = 2.1646e-01, time/batch = 16.0426s	
16696/29850 (epoch 27.966), train_loss = 0.79804686, grad/param norm = 1.9686e-01, time/batch = 16.5495s	
16697/29850 (epoch 27.968), train_loss = 0.83439326, grad/param norm = 1.9807e-01, time/batch = 18.4371s	
16698/29850 (epoch 27.970), train_loss = 0.78439832, grad/param norm = 2.0842e-01, time/batch = 17.3944s	
16699/29850 (epoch 27.972), train_loss = 0.82575640, grad/param norm = 1.6843e-01, time/batch = 18.9734s	
16700/29850 (epoch 27.973), train_loss = 0.83528850, grad/param norm = 1.9465e-01, time/batch = 18.9687s	
16701/29850 (epoch 27.975), train_loss = 0.70638416, grad/param norm = 1.7798e-01, time/batch = 17.5411s	
16702/29850 (epoch 27.977), train_loss = 0.84501611, grad/param norm = 1.8175e-01, time/batch = 17.8724s	
16703/29850 (epoch 27.978), train_loss = 0.77322418, grad/param norm = 1.9312e-01, time/batch = 18.6339s	
16704/29850 (epoch 27.980), train_loss = 0.82930410, grad/param norm = 1.7190e-01, time/batch = 16.5369s	
16705/29850 (epoch 27.982), train_loss = 0.80373749, grad/param norm = 1.9477e-01, time/batch = 14.9880s	
16706/29850 (epoch 27.983), train_loss = 0.84840185, grad/param norm = 1.7640e-01, time/batch = 17.9593s	
16707/29850 (epoch 27.985), train_loss = 0.93150687, grad/param norm = 1.9588e-01, time/batch = 18.2033s	
16708/29850 (epoch 27.987), train_loss = 0.90861778, grad/param norm = 2.0692e-01, time/batch = 16.1356s	
16709/29850 (epoch 27.988), train_loss = 0.84789307, grad/param norm = 1.8833e-01, time/batch = 18.5405s	
16710/29850 (epoch 27.990), train_loss = 0.90157254, grad/param norm = 1.8551e-01, time/batch = 17.2289s	
16711/29850 (epoch 27.992), train_loss = 0.93837747, grad/param norm = 1.7918e-01, time/batch = 15.7923s	
16712/29850 (epoch 27.993), train_loss = 0.91928503, grad/param norm = 2.2476e-01, time/batch = 19.3607s	
16713/29850 (epoch 27.995), train_loss = 0.92402613, grad/param norm = 2.0447e-01, time/batch = 18.7889s	
16714/29850 (epoch 27.997), train_loss = 0.95277426, grad/param norm = 2.0035e-01, time/batch = 15.6876s	
16715/29850 (epoch 27.998), train_loss = 0.95365201, grad/param norm = 1.8235e-01, time/batch = 19.1213s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
16716/29850 (epoch 28.000), train_loss = 0.79681634, grad/param norm = 1.8563e-01, time/batch = 17.1076s	
16717/29850 (epoch 28.002), train_loss = 1.07685543, grad/param norm = 2.3263e-01, time/batch = 17.3790s	
16718/29850 (epoch 28.003), train_loss = 0.81205159, grad/param norm = 1.9593e-01, time/batch = 18.0346s	
16719/29850 (epoch 28.005), train_loss = 0.91245084, grad/param norm = 1.8791e-01, time/batch = 18.2823s	
16720/29850 (epoch 28.007), train_loss = 1.00300025, grad/param norm = 2.3400e-01, time/batch = 18.7984s	
16721/29850 (epoch 28.008), train_loss = 1.12301327, grad/param norm = 2.3829e-01, time/batch = 16.8622s	
16722/29850 (epoch 28.010), train_loss = 0.83554709, grad/param norm = 2.1626e-01, time/batch = 17.7800s	
16723/29850 (epoch 28.012), train_loss = 0.89135857, grad/param norm = 1.8329e-01, time/batch = 18.5449s	
16724/29850 (epoch 28.013), train_loss = 0.96042659, grad/param norm = 2.3205e-01, time/batch = 17.2032s	
16725/29850 (epoch 28.015), train_loss = 0.95757315, grad/param norm = 1.8538e-01, time/batch = 16.8974s	
16726/29850 (epoch 28.017), train_loss = 0.94004303, grad/param norm = 2.2470e-01, time/batch = 18.2237s	
16727/29850 (epoch 28.018), train_loss = 1.05598069, grad/param norm = 2.2145e-01, time/batch = 16.7890s	
16728/29850 (epoch 28.020), train_loss = 0.90781096, grad/param norm = 2.1265e-01, time/batch = 16.2217s	
16729/29850 (epoch 28.022), train_loss = 1.02177707, grad/param norm = 2.3188e-01, time/batch = 17.5580s	
16730/29850 (epoch 28.023), train_loss = 1.01314376, grad/param norm = 2.1228e-01, time/batch = 18.0351s	
16731/29850 (epoch 28.025), train_loss = 0.90540503, grad/param norm = 1.9485e-01, time/batch = 15.8143s	
16732/29850 (epoch 28.027), train_loss = 0.72723685, grad/param norm = 1.8104e-01, time/batch = 16.9699s	
16733/29850 (epoch 28.028), train_loss = 0.86886603, grad/param norm = 1.8526e-01, time/batch = 17.7035s	
16734/29850 (epoch 28.030), train_loss = 0.90886983, grad/param norm = 2.1404e-01, time/batch = 18.6870s	
16735/29850 (epoch 28.032), train_loss = 0.98309152, grad/param norm = 2.1186e-01, time/batch = 17.7646s	
16736/29850 (epoch 28.034), train_loss = 0.82938538, grad/param norm = 1.7885e-01, time/batch = 18.0472s	
16737/29850 (epoch 28.035), train_loss = 0.76469908, grad/param norm = 1.8630e-01, time/batch = 15.1922s	
16738/29850 (epoch 28.037), train_loss = 0.93018402, grad/param norm = 2.2916e-01, time/batch = 17.7716s	
16739/29850 (epoch 28.039), train_loss = 0.80372061, grad/param norm = 1.9988e-01, time/batch = 18.4610s	
16740/29850 (epoch 28.040), train_loss = 0.82150493, grad/param norm = 1.7823e-01, time/batch = 16.5493s	
16741/29850 (epoch 28.042), train_loss = 0.84662015, grad/param norm = 2.1617e-01, time/batch = 17.6992s	
16742/29850 (epoch 28.044), train_loss = 0.87173419, grad/param norm = 1.8131e-01, time/batch = 19.0462s	
16743/29850 (epoch 28.045), train_loss = 0.97100422, grad/param norm = 1.9065e-01, time/batch = 16.9690s	
16744/29850 (epoch 28.047), train_loss = 0.81722273, grad/param norm = 2.0101e-01, time/batch = 17.5375s	
16745/29850 (epoch 28.049), train_loss = 0.93896638, grad/param norm = 1.9768e-01, time/batch = 18.1964s	
16746/29850 (epoch 28.050), train_loss = 0.81727136, grad/param norm = 2.0623e-01, time/batch = 19.9398s	
16747/29850 (epoch 28.052), train_loss = 1.00447490, grad/param norm = 2.6178e-01, time/batch = 16.6315s	
16748/29850 (epoch 28.054), train_loss = 0.90990746, grad/param norm = 1.7817e-01, time/batch = 14.6441s	
16749/29850 (epoch 28.055), train_loss = 0.86771443, grad/param norm = 1.9716e-01, time/batch = 18.6274s	
16750/29850 (epoch 28.057), train_loss = 0.96405978, grad/param norm = 2.0957e-01, time/batch = 16.9470s	
16751/29850 (epoch 28.059), train_loss = 0.95517276, grad/param norm = 2.0522e-01, time/batch = 14.9529s	
16752/29850 (epoch 28.060), train_loss = 0.90656922, grad/param norm = 1.9980e-01, time/batch = 15.1897s	
16753/29850 (epoch 28.062), train_loss = 1.00513560, grad/param norm = 2.1940e-01, time/batch = 15.1282s	
16754/29850 (epoch 28.064), train_loss = 0.97007846, grad/param norm = 1.9865e-01, time/batch = 15.1926s	
16755/29850 (epoch 28.065), train_loss = 0.81135164, grad/param norm = 1.9252e-01, time/batch = 14.9260s	
16756/29850 (epoch 28.067), train_loss = 0.96269626, grad/param norm = 1.8653e-01, time/batch = 15.5262s	
16757/29850 (epoch 28.069), train_loss = 0.94927657, grad/param norm = 1.9381e-01, time/batch = 18.1033s	
16758/29850 (epoch 28.070), train_loss = 0.95920615, grad/param norm = 1.9802e-01, time/batch = 18.3529s	
16759/29850 (epoch 28.072), train_loss = 0.94054309, grad/param norm = 2.3220e-01, time/batch = 17.2165s	
16760/29850 (epoch 28.074), train_loss = 0.99344335, grad/param norm = 1.8660e-01, time/batch = 16.8881s	
16761/29850 (epoch 28.075), train_loss = 0.85543095, grad/param norm = 2.2627e-01, time/batch = 17.4723s	
16762/29850 (epoch 28.077), train_loss = 0.97346666, grad/param norm = 2.2164e-01, time/batch = 16.1553s	
16763/29850 (epoch 28.079), train_loss = 1.15685633, grad/param norm = 3.0162e-01, time/batch = 17.1229s	
16764/29850 (epoch 28.080), train_loss = 1.12071891, grad/param norm = 2.4981e-01, time/batch = 19.7806s	
16765/29850 (epoch 28.082), train_loss = 0.98451426, grad/param norm = 2.1812e-01, time/batch = 19.4513s	
16766/29850 (epoch 28.084), train_loss = 1.11985708, grad/param norm = 2.5401e-01, time/batch = 18.1149s	
16767/29850 (epoch 28.085), train_loss = 1.10429378, grad/param norm = 2.7122e-01, time/batch = 16.2899s	
16768/29850 (epoch 28.087), train_loss = 1.06955179, grad/param norm = 2.2722e-01, time/batch = 17.6261s	
16769/29850 (epoch 28.089), train_loss = 0.96067717, grad/param norm = 2.2054e-01, time/batch = 18.7823s	
16770/29850 (epoch 28.090), train_loss = 1.01251174, grad/param norm = 2.1390e-01, time/batch = 17.7726s	
16771/29850 (epoch 28.092), train_loss = 0.89343330, grad/param norm = 2.0163e-01, time/batch = 20.1203s	
16772/29850 (epoch 28.094), train_loss = 1.05540088, grad/param norm = 2.1550e-01, time/batch = 17.6320s	
16773/29850 (epoch 28.095), train_loss = 0.98337515, grad/param norm = 2.9716e-01, time/batch = 17.7731s	
16774/29850 (epoch 28.097), train_loss = 0.75912629, grad/param norm = 1.8335e-01, time/batch = 17.0509s	
16775/29850 (epoch 28.099), train_loss = 0.80378296, grad/param norm = 2.0562e-01, time/batch = 18.2189s	
16776/29850 (epoch 28.101), train_loss = 1.03105630, grad/param norm = 2.1726e-01, time/batch = 16.2780s	
16777/29850 (epoch 28.102), train_loss = 0.97157766, grad/param norm = 2.0029e-01, time/batch = 17.5569s	
16778/29850 (epoch 28.104), train_loss = 0.93263737, grad/param norm = 2.3830e-01, time/batch = 17.0193s	
16779/29850 (epoch 28.106), train_loss = 1.03088385, grad/param norm = 2.1314e-01, time/batch = 16.2962s	
16780/29850 (epoch 28.107), train_loss = 0.85337280, grad/param norm = 1.8700e-01, time/batch = 16.8599s	
16781/29850 (epoch 28.109), train_loss = 0.91801095, grad/param norm = 2.0548e-01, time/batch = 19.1121s	
16782/29850 (epoch 28.111), train_loss = 0.98826725, grad/param norm = 1.8011e-01, time/batch = 19.1180s	
16783/29850 (epoch 28.112), train_loss = 0.85829340, grad/param norm = 1.9751e-01, time/batch = 16.7887s	
16784/29850 (epoch 28.114), train_loss = 0.88928433, grad/param norm = 2.1817e-01, time/batch = 17.4096s	
16785/29850 (epoch 28.116), train_loss = 0.82227353, grad/param norm = 1.6820e-01, time/batch = 18.9563s	
16786/29850 (epoch 28.117), train_loss = 0.91716727, grad/param norm = 2.1005e-01, time/batch = 16.2842s	
16787/29850 (epoch 28.119), train_loss = 0.88437153, grad/param norm = 1.9040e-01, time/batch = 16.2846s	
16788/29850 (epoch 28.121), train_loss = 0.73617330, grad/param norm = 1.9290e-01, time/batch = 18.4695s	
16789/29850 (epoch 28.122), train_loss = 0.79545564, grad/param norm = 1.7637e-01, time/batch = 18.2108s	
16790/29850 (epoch 28.124), train_loss = 0.85096985, grad/param norm = 1.8535e-01, time/batch = 17.1932s	
16791/29850 (epoch 28.126), train_loss = 0.85437344, grad/param norm = 1.8629e-01, time/batch = 18.1424s	
16792/29850 (epoch 28.127), train_loss = 0.98888227, grad/param norm = 2.5342e-01, time/batch = 17.4642s	
16793/29850 (epoch 28.129), train_loss = 0.89389628, grad/param norm = 2.1488e-01, time/batch = 17.4357s	
16794/29850 (epoch 28.131), train_loss = 0.91110961, grad/param norm = 2.0427e-01, time/batch = 17.5421s	
16795/29850 (epoch 28.132), train_loss = 0.82660168, grad/param norm = 2.3443e-01, time/batch = 17.5136s	
16796/29850 (epoch 28.134), train_loss = 0.89616268, grad/param norm = 1.9706e-01, time/batch = 15.5582s	
16797/29850 (epoch 28.136), train_loss = 0.97053196, grad/param norm = 2.1990e-01, time/batch = 19.5972s	
16798/29850 (epoch 28.137), train_loss = 0.75024859, grad/param norm = 1.8346e-01, time/batch = 17.4460s	
16799/29850 (epoch 28.139), train_loss = 0.90216668, grad/param norm = 1.9691e-01, time/batch = 18.7913s	
16800/29850 (epoch 28.141), train_loss = 0.82832756, grad/param norm = 1.8762e-01, time/batch = 18.1198s	
16801/29850 (epoch 28.142), train_loss = 1.05510029, grad/param norm = 2.6175e-01, time/batch = 18.6311s	
16802/29850 (epoch 28.144), train_loss = 1.16942718, grad/param norm = 2.5692e-01, time/batch = 18.0518s	
16803/29850 (epoch 28.146), train_loss = 1.19881113, grad/param norm = 2.5200e-01, time/batch = 17.0312s	
16804/29850 (epoch 28.147), train_loss = 1.00611636, grad/param norm = 2.3754e-01, time/batch = 19.7094s	
16805/29850 (epoch 28.149), train_loss = 0.97848869, grad/param norm = 2.3101e-01, time/batch = 17.6421s	
16806/29850 (epoch 28.151), train_loss = 0.98730933, grad/param norm = 2.1431e-01, time/batch = 17.9561s	
16807/29850 (epoch 28.152), train_loss = 0.89154485, grad/param norm = 1.8359e-01, time/batch = 18.5220s	
16808/29850 (epoch 28.154), train_loss = 0.85031393, grad/param norm = 2.1403e-01, time/batch = 16.6552s	
16809/29850 (epoch 28.156), train_loss = 0.85228016, grad/param norm = 1.8664e-01, time/batch = 17.6360s	
16810/29850 (epoch 28.157), train_loss = 0.96591005, grad/param norm = 2.1937e-01, time/batch = 15.2693s	
16811/29850 (epoch 28.159), train_loss = 0.87699492, grad/param norm = 2.0479e-01, time/batch = 17.6928s	
16812/29850 (epoch 28.161), train_loss = 0.92900682, grad/param norm = 2.1881e-01, time/batch = 18.7917s	
16813/29850 (epoch 28.162), train_loss = 1.05802478, grad/param norm = 2.2935e-01, time/batch = 17.2470s	
16814/29850 (epoch 28.164), train_loss = 0.95980808, grad/param norm = 2.2977e-01, time/batch = 17.4977s	
16815/29850 (epoch 28.166), train_loss = 0.87719970, grad/param norm = 1.9394e-01, time/batch = 19.4645s	
16816/29850 (epoch 28.168), train_loss = 0.77407500, grad/param norm = 1.8493e-01, time/batch = 18.5443s	
16817/29850 (epoch 28.169), train_loss = 1.09077059, grad/param norm = 2.2729e-01, time/batch = 18.8549s	
16818/29850 (epoch 28.171), train_loss = 0.99791637, grad/param norm = 2.2056e-01, time/batch = 19.2085s	
16819/29850 (epoch 28.173), train_loss = 0.83687880, grad/param norm = 1.7882e-01, time/batch = 19.1148s	
16820/29850 (epoch 28.174), train_loss = 0.95080666, grad/param norm = 2.2997e-01, time/batch = 17.6955s	
16821/29850 (epoch 28.176), train_loss = 0.94259049, grad/param norm = 2.0274e-01, time/batch = 17.7779s	
16822/29850 (epoch 28.178), train_loss = 0.98013169, grad/param norm = 2.2781e-01, time/batch = 17.1090s	
16823/29850 (epoch 28.179), train_loss = 0.78304792, grad/param norm = 1.8828e-01, time/batch = 16.0211s	
16824/29850 (epoch 28.181), train_loss = 0.95306244, grad/param norm = 2.2809e-01, time/batch = 17.7222s	
16825/29850 (epoch 28.183), train_loss = 0.93639245, grad/param norm = 1.9889e-01, time/batch = 17.9621s	
16826/29850 (epoch 28.184), train_loss = 0.98733757, grad/param norm = 2.2601e-01, time/batch = 17.2266s	
16827/29850 (epoch 28.186), train_loss = 0.92561864, grad/param norm = 2.2671e-01, time/batch = 18.1370s	
16828/29850 (epoch 28.188), train_loss = 1.06396812, grad/param norm = 2.3055e-01, time/batch = 17.3870s	
16829/29850 (epoch 28.189), train_loss = 1.05186670, grad/param norm = 2.6547e-01, time/batch = 17.2110s	
16830/29850 (epoch 28.191), train_loss = 1.02527909, grad/param norm = 2.1242e-01, time/batch = 16.7206s	
16831/29850 (epoch 28.193), train_loss = 0.92553184, grad/param norm = 2.1338e-01, time/batch = 16.2268s	
16832/29850 (epoch 28.194), train_loss = 1.00144379, grad/param norm = 2.4222e-01, time/batch = 18.3769s	
16833/29850 (epoch 28.196), train_loss = 0.90915087, grad/param norm = 2.2618e-01, time/batch = 16.4643s	
16834/29850 (epoch 28.198), train_loss = 0.89967427, grad/param norm = 2.0604e-01, time/batch = 18.4644s	
16835/29850 (epoch 28.199), train_loss = 1.15328489, grad/param norm = 2.4963e-01, time/batch = 16.5489s	
16836/29850 (epoch 28.201), train_loss = 0.88798852, grad/param norm = 2.3816e-01, time/batch = 15.9159s	
16837/29850 (epoch 28.203), train_loss = 0.71384885, grad/param norm = 1.9300e-01, time/batch = 17.8734s	
16838/29850 (epoch 28.204), train_loss = 0.94335612, grad/param norm = 2.4901e-01, time/batch = 16.9720s	
16839/29850 (epoch 28.206), train_loss = 0.83590420, grad/param norm = 2.2689e-01, time/batch = 18.6377s	
16840/29850 (epoch 28.208), train_loss = 1.07592208, grad/param norm = 2.3442e-01, time/batch = 17.2692s	
16841/29850 (epoch 28.209), train_loss = 0.81159602, grad/param norm = 1.8842e-01, time/batch = 16.8861s	
16842/29850 (epoch 28.211), train_loss = 0.88983857, grad/param norm = 2.0322e-01, time/batch = 18.1338s	
16843/29850 (epoch 28.213), train_loss = 0.99304003, grad/param norm = 2.1198e-01, time/batch = 18.2975s	
16844/29850 (epoch 28.214), train_loss = 0.83160153, grad/param norm = 1.7762e-01, time/batch = 19.2785s	
16845/29850 (epoch 28.216), train_loss = 0.85838845, grad/param norm = 2.1417e-01, time/batch = 18.1145s	
16846/29850 (epoch 28.218), train_loss = 1.00055464, grad/param norm = 2.2419e-01, time/batch = 17.4476s	
16847/29850 (epoch 28.219), train_loss = 0.98786826, grad/param norm = 2.2110e-01, time/batch = 17.5321s	
16848/29850 (epoch 28.221), train_loss = 0.93473232, grad/param norm = 1.9561e-01, time/batch = 19.4481s	
16849/29850 (epoch 28.223), train_loss = 0.83997988, grad/param norm = 2.3715e-01, time/batch = 17.0932s	
16850/29850 (epoch 28.224), train_loss = 0.80828995, grad/param norm = 2.0837e-01, time/batch = 17.1329s	
16851/29850 (epoch 28.226), train_loss = 0.84972503, grad/param norm = 1.7851e-01, time/batch = 16.2699s	
16852/29850 (epoch 28.228), train_loss = 0.89150903, grad/param norm = 1.7360e-01, time/batch = 18.2035s	
16853/29850 (epoch 28.229), train_loss = 0.76480611, grad/param norm = 1.6405e-01, time/batch = 18.3949s	
16854/29850 (epoch 28.231), train_loss = 0.94173162, grad/param norm = 2.0220e-01, time/batch = 16.0424s	
16855/29850 (epoch 28.233), train_loss = 0.90739671, grad/param norm = 2.0581e-01, time/batch = 18.9734s	
16856/29850 (epoch 28.235), train_loss = 0.84881776, grad/param norm = 1.7850e-01, time/batch = 19.0127s	
16857/29850 (epoch 28.236), train_loss = 1.04870177, grad/param norm = 2.3008e-01, time/batch = 16.5296s	
16858/29850 (epoch 28.238), train_loss = 0.81040168, grad/param norm = 1.9178e-01, time/batch = 18.0269s	
16859/29850 (epoch 28.240), train_loss = 0.78736338, grad/param norm = 1.8615e-01, time/batch = 18.6968s	
16860/29850 (epoch 28.241), train_loss = 0.97698729, grad/param norm = 2.3647e-01, time/batch = 17.4349s	
16861/29850 (epoch 28.243), train_loss = 0.95162259, grad/param norm = 2.1805e-01, time/batch = 18.5362s	
16862/29850 (epoch 28.245), train_loss = 0.86528352, grad/param norm = 2.1301e-01, time/batch = 16.4637s	
16863/29850 (epoch 28.246), train_loss = 0.77897224, grad/param norm = 1.6074e-01, time/batch = 17.0515s	
16864/29850 (epoch 28.248), train_loss = 0.78778315, grad/param norm = 1.9151e-01, time/batch = 17.9632s	
16865/29850 (epoch 28.250), train_loss = 0.88654074, grad/param norm = 1.8179e-01, time/batch = 18.1176s	
16866/29850 (epoch 28.251), train_loss = 0.78429131, grad/param norm = 1.9574e-01, time/batch = 19.0547s	
16867/29850 (epoch 28.253), train_loss = 0.73024482, grad/param norm = 2.2518e-01, time/batch = 16.7929s	
16868/29850 (epoch 28.255), train_loss = 0.84640469, grad/param norm = 2.0590e-01, time/batch = 20.1162s	
16869/29850 (epoch 28.256), train_loss = 0.96630557, grad/param norm = 2.1687e-01, time/batch = 17.4509s	
16870/29850 (epoch 28.258), train_loss = 0.93322339, grad/param norm = 2.1019e-01, time/batch = 18.7818s	
16871/29850 (epoch 28.260), train_loss = 0.89913761, grad/param norm = 1.9821e-01, time/batch = 17.0488s	
16872/29850 (epoch 28.261), train_loss = 0.83585062, grad/param norm = 2.0802e-01, time/batch = 18.7203s	
16873/29850 (epoch 28.263), train_loss = 0.82952954, grad/param norm = 1.9458e-01, time/batch = 17.2782s	
16874/29850 (epoch 28.265), train_loss = 0.89924879, grad/param norm = 2.0893e-01, time/batch = 15.9483s	
16875/29850 (epoch 28.266), train_loss = 0.89918967, grad/param norm = 2.0207e-01, time/batch = 15.6281s	
16876/29850 (epoch 28.268), train_loss = 0.86453920, grad/param norm = 1.9076e-01, time/batch = 17.7227s	
16877/29850 (epoch 28.270), train_loss = 0.85097775, grad/param norm = 2.0248e-01, time/batch = 17.3849s	
16878/29850 (epoch 28.271), train_loss = 0.97432410, grad/param norm = 2.2833e-01, time/batch = 17.6261s	
16879/29850 (epoch 28.273), train_loss = 0.81687229, grad/param norm = 2.2363e-01, time/batch = 18.7078s	
16880/29850 (epoch 28.275), train_loss = 0.80002537, grad/param norm = 2.1521e-01, time/batch = 16.2236s	
16881/29850 (epoch 28.276), train_loss = 0.78991180, grad/param norm = 1.7507e-01, time/batch = 17.3620s	
16882/29850 (epoch 28.278), train_loss = 0.87095420, grad/param norm = 1.9459e-01, time/batch = 17.1060s	
16883/29850 (epoch 28.280), train_loss = 1.06422211, grad/param norm = 2.7662e-01, time/batch = 18.5398s	
16884/29850 (epoch 28.281), train_loss = 0.93584839, grad/param norm = 2.1316e-01, time/batch = 17.3693s	
16885/29850 (epoch 28.283), train_loss = 1.06899678, grad/param norm = 2.9480e-01, time/batch = 14.7325s	
16886/29850 (epoch 28.285), train_loss = 0.95213049, grad/param norm = 2.0497e-01, time/batch = 14.6021s	
16887/29850 (epoch 28.286), train_loss = 1.01087884, grad/param norm = 2.3326e-01, time/batch = 15.6105s	
16888/29850 (epoch 28.288), train_loss = 1.03593679, grad/param norm = 2.7427e-01, time/batch = 17.7799s	
16889/29850 (epoch 28.290), train_loss = 0.93485706, grad/param norm = 2.3697e-01, time/batch = 18.1214s	
16890/29850 (epoch 28.291), train_loss = 1.15807929, grad/param norm = 2.5161e-01, time/batch = 19.2081s	
16891/29850 (epoch 28.293), train_loss = 1.01891759, grad/param norm = 2.2788e-01, time/batch = 23.4520s	
16892/29850 (epoch 28.295), train_loss = 1.09742014, grad/param norm = 2.8274e-01, time/batch = 24.0508s	
16893/29850 (epoch 28.296), train_loss = 0.82880369, grad/param norm = 1.9607e-01, time/batch = 15.2898s	
16894/29850 (epoch 28.298), train_loss = 0.73618413, grad/param norm = 1.9160e-01, time/batch = 16.4655s	
16895/29850 (epoch 28.300), train_loss = 0.80792353, grad/param norm = 1.9907e-01, time/batch = 16.8108s	
16896/29850 (epoch 28.302), train_loss = 0.79084941, grad/param norm = 2.1385e-01, time/batch = 18.6300s	
16897/29850 (epoch 28.303), train_loss = 0.84101452, grad/param norm = 1.9995e-01, time/batch = 16.2802s	
16898/29850 (epoch 28.305), train_loss = 0.96498947, grad/param norm = 2.0643e-01, time/batch = 17.5417s	
16899/29850 (epoch 28.307), train_loss = 1.00380469, grad/param norm = 1.9028e-01, time/batch = 18.3095s	
16900/29850 (epoch 28.308), train_loss = 0.83418677, grad/param norm = 2.0524e-01, time/batch = 18.2289s	
16901/29850 (epoch 28.310), train_loss = 0.94223800, grad/param norm = 2.2054e-01, time/batch = 15.9677s	
16902/29850 (epoch 28.312), train_loss = 0.96666500, grad/param norm = 1.8505e-01, time/batch = 18.4780s	
16903/29850 (epoch 28.313), train_loss = 0.92862210, grad/param norm = 2.3112e-01, time/batch = 18.2280s	
16904/29850 (epoch 28.315), train_loss = 0.92451573, grad/param norm = 2.0199e-01, time/batch = 15.5223s	
16905/29850 (epoch 28.317), train_loss = 0.93417523, grad/param norm = 2.3458e-01, time/batch = 17.8821s	
16906/29850 (epoch 28.318), train_loss = 0.89498056, grad/param norm = 2.0495e-01, time/batch = 17.3022s	
16907/29850 (epoch 28.320), train_loss = 0.84656682, grad/param norm = 1.7857e-01, time/batch = 19.0384s	
16908/29850 (epoch 28.322), train_loss = 1.07846407, grad/param norm = 2.2324e-01, time/batch = 17.3034s	
16909/29850 (epoch 28.323), train_loss = 0.98820065, grad/param norm = 2.5176e-01, time/batch = 17.0407s	
16910/29850 (epoch 28.325), train_loss = 1.02431168, grad/param norm = 2.2168e-01, time/batch = 18.6999s	
16911/29850 (epoch 28.327), train_loss = 1.12889208, grad/param norm = 2.1561e-01, time/batch = 15.7995s	
16912/29850 (epoch 28.328), train_loss = 1.05246772, grad/param norm = 2.3063e-01, time/batch = 18.8842s	
16913/29850 (epoch 28.330), train_loss = 0.98186467, grad/param norm = 2.0174e-01, time/batch = 18.3707s	
16914/29850 (epoch 28.332), train_loss = 0.88212559, grad/param norm = 2.0611e-01, time/batch = 16.1074s	
16915/29850 (epoch 28.333), train_loss = 0.99675562, grad/param norm = 2.2060e-01, time/batch = 19.3674s	
16916/29850 (epoch 28.335), train_loss = 1.04105358, grad/param norm = 2.2027e-01, time/batch = 17.9486s	
16917/29850 (epoch 28.337), train_loss = 0.94559923, grad/param norm = 2.1643e-01, time/batch = 18.8830s	
16918/29850 (epoch 28.338), train_loss = 0.95299666, grad/param norm = 1.9532e-01, time/batch = 18.2858s	
16919/29850 (epoch 28.340), train_loss = 0.82295590, grad/param norm = 1.9779e-01, time/batch = 18.7013s	
16920/29850 (epoch 28.342), train_loss = 0.94242086, grad/param norm = 2.3418e-01, time/batch = 18.7179s	
16921/29850 (epoch 28.343), train_loss = 0.95853751, grad/param norm = 2.4159e-01, time/batch = 18.4541s	
16922/29850 (epoch 28.345), train_loss = 1.01262784, grad/param norm = 2.4823e-01, time/batch = 17.6296s	
16923/29850 (epoch 28.347), train_loss = 1.04150045, grad/param norm = 2.1980e-01, time/batch = 19.1289s	
16924/29850 (epoch 28.348), train_loss = 0.88625724, grad/param norm = 2.0450e-01, time/batch = 16.2170s	
16925/29850 (epoch 28.350), train_loss = 0.99999042, grad/param norm = 2.4527e-01, time/batch = 17.3780s	
16926/29850 (epoch 28.352), train_loss = 0.88032201, grad/param norm = 2.0770e-01, time/batch = 18.7960s	
16927/29850 (epoch 28.353), train_loss = 0.99377109, grad/param norm = 2.0474e-01, time/batch = 17.8834s	
16928/29850 (epoch 28.355), train_loss = 0.89306374, grad/param norm = 2.0516e-01, time/batch = 18.2053s	
16929/29850 (epoch 28.357), train_loss = 1.02227214, grad/param norm = 2.0647e-01, time/batch = 16.6297s	
16930/29850 (epoch 28.358), train_loss = 0.85117659, grad/param norm = 2.0442e-01, time/batch = 17.5415s	
16931/29850 (epoch 28.360), train_loss = 0.89947616, grad/param norm = 2.0455e-01, time/batch = 17.8716s	
16932/29850 (epoch 28.362), train_loss = 0.92916459, grad/param norm = 2.0543e-01, time/batch = 17.8873s	
16933/29850 (epoch 28.363), train_loss = 0.96404245, grad/param norm = 2.1469e-01, time/batch = 16.4529s	
16934/29850 (epoch 28.365), train_loss = 1.07857019, grad/param norm = 2.4008e-01, time/batch = 16.1892s	
16935/29850 (epoch 28.367), train_loss = 0.87213986, grad/param norm = 2.6376e-01, time/batch = 17.2996s	
16936/29850 (epoch 28.369), train_loss = 0.80980225, grad/param norm = 2.0329e-01, time/batch = 17.7169s	
16937/29850 (epoch 28.370), train_loss = 0.75317459, grad/param norm = 1.7807e-01, time/batch = 19.2917s	
16938/29850 (epoch 28.372), train_loss = 1.02313163, grad/param norm = 2.2788e-01, time/batch = 17.1197s	
16939/29850 (epoch 28.374), train_loss = 0.97790932, grad/param norm = 1.9004e-01, time/batch = 18.9598s	
16940/29850 (epoch 28.375), train_loss = 0.95560716, grad/param norm = 1.9179e-01, time/batch = 20.5038s	
16941/29850 (epoch 28.377), train_loss = 0.86129195, grad/param norm = 2.0256e-01, time/batch = 16.2803s	
16942/29850 (epoch 28.379), train_loss = 1.05020723, grad/param norm = 2.3031e-01, time/batch = 18.7838s	
16943/29850 (epoch 28.380), train_loss = 0.98715776, grad/param norm = 2.2770e-01, time/batch = 17.9724s	
16944/29850 (epoch 28.382), train_loss = 0.97532605, grad/param norm = 2.2989e-01, time/batch = 17.3023s	
16945/29850 (epoch 28.384), train_loss = 1.02756400, grad/param norm = 2.2380e-01, time/batch = 15.8020s	
16946/29850 (epoch 28.385), train_loss = 0.97167674, grad/param norm = 2.3760e-01, time/batch = 15.6325s	
16947/29850 (epoch 28.387), train_loss = 0.99962584, grad/param norm = 2.3882e-01, time/batch = 17.2058s	
16948/29850 (epoch 28.389), train_loss = 1.08232632, grad/param norm = 2.3726e-01, time/batch = 18.2872s	
16949/29850 (epoch 28.390), train_loss = 0.99128317, grad/param norm = 1.8967e-01, time/batch = 17.9661s	
16950/29850 (epoch 28.392), train_loss = 0.94096128, grad/param norm = 2.6481e-01, time/batch = 19.0424s	
16951/29850 (epoch 28.394), train_loss = 1.02841525, grad/param norm = 2.2860e-01, time/batch = 16.7922s	
16952/29850 (epoch 28.395), train_loss = 0.90041051, grad/param norm = 2.3521e-01, time/batch = 16.1047s	
16953/29850 (epoch 28.397), train_loss = 0.84161346, grad/param norm = 2.2806e-01, time/batch = 17.4729s	
16954/29850 (epoch 28.399), train_loss = 0.84745327, grad/param norm = 1.8773e-01, time/batch = 18.8784s	
16955/29850 (epoch 28.400), train_loss = 1.21481366, grad/param norm = 2.2482e-01, time/batch = 18.3567s	
16956/29850 (epoch 28.402), train_loss = 1.10932353, grad/param norm = 2.1890e-01, time/batch = 17.9724s	
16957/29850 (epoch 28.404), train_loss = 0.98167387, grad/param norm = 2.0985e-01, time/batch = 18.7202s	
16958/29850 (epoch 28.405), train_loss = 0.89406838, grad/param norm = 2.2793e-01, time/batch = 16.2003s	
16959/29850 (epoch 28.407), train_loss = 0.85930443, grad/param norm = 2.1397e-01, time/batch = 17.7894s	
16960/29850 (epoch 28.409), train_loss = 0.97906185, grad/param norm = 2.2329e-01, time/batch = 17.7172s	
16961/29850 (epoch 28.410), train_loss = 1.07603616, grad/param norm = 2.2649e-01, time/batch = 15.7832s	
16962/29850 (epoch 28.412), train_loss = 1.07032097, grad/param norm = 2.1483e-01, time/batch = 17.7143s	
16963/29850 (epoch 28.414), train_loss = 0.95657017, grad/param norm = 2.2091e-01, time/batch = 17.8003s	
16964/29850 (epoch 28.415), train_loss = 0.94054697, grad/param norm = 2.1407e-01, time/batch = 17.0435s	
16965/29850 (epoch 28.417), train_loss = 1.07139730, grad/param norm = 2.3445e-01, time/batch = 16.9543s	
16966/29850 (epoch 28.419), train_loss = 0.93648720, grad/param norm = 2.0679e-01, time/batch = 14.4217s	
16967/29850 (epoch 28.420), train_loss = 0.94640275, grad/param norm = 2.1781e-01, time/batch = 17.0280s	
16968/29850 (epoch 28.422), train_loss = 0.93231341, grad/param norm = 2.1256e-01, time/batch = 17.3580s	
16969/29850 (epoch 28.424), train_loss = 0.86164667, grad/param norm = 1.9568e-01, time/batch = 17.1891s	
16970/29850 (epoch 28.425), train_loss = 1.02171496, grad/param norm = 2.2478e-01, time/batch = 19.4617s	
16971/29850 (epoch 28.427), train_loss = 0.77367579, grad/param norm = 1.8145e-01, time/batch = 18.8878s	
16972/29850 (epoch 28.429), train_loss = 0.84055178, grad/param norm = 2.0529e-01, time/batch = 17.9530s	
16973/29850 (epoch 28.430), train_loss = 0.77978729, grad/param norm = 1.7632e-01, time/batch = 18.2107s	
16974/29850 (epoch 28.432), train_loss = 0.89118736, grad/param norm = 2.2964e-01, time/batch = 18.1352s	
16975/29850 (epoch 28.434), train_loss = 0.83411883, grad/param norm = 1.8154e-01, time/batch = 15.6633s	
16976/29850 (epoch 28.436), train_loss = 0.93389956, grad/param norm = 2.1438e-01, time/batch = 17.2107s	
16977/29850 (epoch 28.437), train_loss = 0.99299254, grad/param norm = 2.2257e-01, time/batch = 18.2162s	
16978/29850 (epoch 28.439), train_loss = 0.97247521, grad/param norm = 1.9018e-01, time/batch = 17.9630s	
16979/29850 (epoch 28.441), train_loss = 0.94408075, grad/param norm = 2.2191e-01, time/batch = 18.1306s	
16980/29850 (epoch 28.442), train_loss = 0.94778681, grad/param norm = 2.2270e-01, time/batch = 18.7135s	
16981/29850 (epoch 28.444), train_loss = 0.97350858, grad/param norm = 2.2486e-01, time/batch = 15.8105s	
16982/29850 (epoch 28.446), train_loss = 1.00480640, grad/param norm = 2.2116e-01, time/batch = 17.6137s	
16983/29850 (epoch 28.447), train_loss = 1.01069374, grad/param norm = 2.3542e-01, time/batch = 18.8732s	
16984/29850 (epoch 28.449), train_loss = 0.95826780, grad/param norm = 2.2316e-01, time/batch = 17.5495s	
16985/29850 (epoch 28.451), train_loss = 0.75738514, grad/param norm = 2.0473e-01, time/batch = 18.1164s	
16986/29850 (epoch 28.452), train_loss = 0.68985123, grad/param norm = 1.7016e-01, time/batch = 17.3768s	
16987/29850 (epoch 28.454), train_loss = 0.77571444, grad/param norm = 1.6633e-01, time/batch = 19.1272s	
16988/29850 (epoch 28.456), train_loss = 0.99707913, grad/param norm = 2.1356e-01, time/batch = 18.2867s	
16989/29850 (epoch 28.457), train_loss = 1.01104031, grad/param norm = 2.7723e-01, time/batch = 16.3545s	
16990/29850 (epoch 28.459), train_loss = 1.08171141, grad/param norm = 2.2886e-01, time/batch = 18.5470s	
16991/29850 (epoch 28.461), train_loss = 1.07949822, grad/param norm = 2.0917e-01, time/batch = 18.4665s	
16992/29850 (epoch 28.462), train_loss = 1.07303257, grad/param norm = 2.3076e-01, time/batch = 16.6926s	
16993/29850 (epoch 28.464), train_loss = 0.99493682, grad/param norm = 2.2067e-01, time/batch = 17.8175s	
16994/29850 (epoch 28.466), train_loss = 0.81459435, grad/param norm = 2.1109e-01, time/batch = 17.3911s	
16995/29850 (epoch 28.467), train_loss = 0.90022507, grad/param norm = 2.1808e-01, time/batch = 16.7901s	
16996/29850 (epoch 28.469), train_loss = 0.90434414, grad/param norm = 1.9074e-01, time/batch = 17.5464s	
16997/29850 (epoch 28.471), train_loss = 0.89816498, grad/param norm = 2.1217e-01, time/batch = 19.0439s	
16998/29850 (epoch 28.472), train_loss = 0.87188956, grad/param norm = 2.1379e-01, time/batch = 16.2027s	
16999/29850 (epoch 28.474), train_loss = 1.03884068, grad/param norm = 2.3005e-01, time/batch = 19.0286s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch28.48_1.7779.t7	
17000/29850 (epoch 28.476), train_loss = 0.94673791, grad/param norm = 1.8673e-01, time/batch = 15.2998s	
17001/29850 (epoch 28.477), train_loss = 1.74405307, grad/param norm = 3.0868e-01, time/batch = 18.0359s	
17002/29850 (epoch 28.479), train_loss = 1.11561694, grad/param norm = 2.2677e-01, time/batch = 16.4588s	
17003/29850 (epoch 28.481), train_loss = 0.90498176, grad/param norm = 2.0994e-01, time/batch = 18.0588s	
17004/29850 (epoch 28.482), train_loss = 0.85476916, grad/param norm = 1.7340e-01, time/batch = 16.6915s	
17005/29850 (epoch 28.484), train_loss = 0.90563054, grad/param norm = 1.9987e-01, time/batch = 16.1973s	
17006/29850 (epoch 28.486), train_loss = 0.97257199, grad/param norm = 2.5610e-01, time/batch = 19.1982s	
17007/29850 (epoch 28.487), train_loss = 0.96581487, grad/param norm = 2.3095e-01, time/batch = 18.8531s	
17008/29850 (epoch 28.489), train_loss = 0.94993489, grad/param norm = 2.0964e-01, time/batch = 16.1173s	
17009/29850 (epoch 28.491), train_loss = 0.86315232, grad/param norm = 2.0583e-01, time/batch = 15.8715s	
17010/29850 (epoch 28.492), train_loss = 0.92501926, grad/param norm = 1.9484e-01, time/batch = 19.6051s	
17011/29850 (epoch 28.494), train_loss = 1.00335002, grad/param norm = 1.9819e-01, time/batch = 18.4455s	
17012/29850 (epoch 28.496), train_loss = 1.09156555, grad/param norm = 2.0902e-01, time/batch = 17.2815s	
17013/29850 (epoch 28.497), train_loss = 0.98901724, grad/param norm = 1.9047e-01, time/batch = 17.7916s	
17014/29850 (epoch 28.499), train_loss = 0.95769679, grad/param norm = 2.0407e-01, time/batch = 18.4694s	
17015/29850 (epoch 28.501), train_loss = 0.88302125, grad/param norm = 2.5978e-01, time/batch = 17.2052s	
17016/29850 (epoch 28.503), train_loss = 0.97899067, grad/param norm = 2.2213e-01, time/batch = 19.2896s	
17017/29850 (epoch 28.504), train_loss = 1.15434184, grad/param norm = 2.2393e-01, time/batch = 17.8906s	
17018/29850 (epoch 28.506), train_loss = 1.10678008, grad/param norm = 2.4386e-01, time/batch = 17.4376s	
17019/29850 (epoch 28.508), train_loss = 0.94426604, grad/param norm = 1.8883e-01, time/batch = 17.4742s	
17020/29850 (epoch 28.509), train_loss = 0.76219433, grad/param norm = 1.7394e-01, time/batch = 17.5637s	
17021/29850 (epoch 28.511), train_loss = 0.97154357, grad/param norm = 2.0101e-01, time/batch = 18.2922s	
17022/29850 (epoch 28.513), train_loss = 0.96523244, grad/param norm = 2.3968e-01, time/batch = 17.5259s	
17023/29850 (epoch 28.514), train_loss = 0.86552119, grad/param norm = 2.2194e-01, time/batch = 18.0540s	
17024/29850 (epoch 28.516), train_loss = 0.89829385, grad/param norm = 1.7998e-01, time/batch = 17.5436s	
17025/29850 (epoch 28.518), train_loss = 0.77993813, grad/param norm = 2.1224e-01, time/batch = 16.6078s	
17026/29850 (epoch 28.519), train_loss = 0.75204428, grad/param norm = 1.7127e-01, time/batch = 17.0473s	
17027/29850 (epoch 28.521), train_loss = 0.70088093, grad/param norm = 2.1367e-01, time/batch = 17.4595s	
17028/29850 (epoch 28.523), train_loss = 0.77265174, grad/param norm = 1.5577e-01, time/batch = 16.9435s	
17029/29850 (epoch 28.524), train_loss = 0.85582680, grad/param norm = 2.3943e-01, time/batch = 16.0104s	
17030/29850 (epoch 28.526), train_loss = 0.93383901, grad/param norm = 2.1950e-01, time/batch = 18.2151s	
17031/29850 (epoch 28.528), train_loss = 1.02923472, grad/param norm = 2.3348e-01, time/batch = 18.6264s	
17032/29850 (epoch 28.529), train_loss = 0.97758184, grad/param norm = 2.1848e-01, time/batch = 17.2810s	
17033/29850 (epoch 28.531), train_loss = 0.93162305, grad/param norm = 2.2482e-01, time/batch = 14.7326s	
17034/29850 (epoch 28.533), train_loss = 0.91812892, grad/param norm = 2.0485e-01, time/batch = 15.7008s	
17035/29850 (epoch 28.534), train_loss = 0.97065241, grad/param norm = 2.2269e-01, time/batch = 18.4730s	
17036/29850 (epoch 28.536), train_loss = 0.86952149, grad/param norm = 2.2826e-01, time/batch = 17.5911s	
17037/29850 (epoch 28.538), train_loss = 1.07622673, grad/param norm = 2.9691e-01, time/batch = 18.3890s	
17038/29850 (epoch 28.539), train_loss = 1.09503698, grad/param norm = 2.1877e-01, time/batch = 16.8028s	
17039/29850 (epoch 28.541), train_loss = 0.71421184, grad/param norm = 2.0468e-01, time/batch = 16.0168s	
17040/29850 (epoch 28.543), train_loss = 0.91061909, grad/param norm = 2.1788e-01, time/batch = 18.7889s	
17041/29850 (epoch 28.544), train_loss = 1.01964208, grad/param norm = 2.1406e-01, time/batch = 16.8689s	
17042/29850 (epoch 28.546), train_loss = 1.01098671, grad/param norm = 2.2471e-01, time/batch = 16.2955s	
17043/29850 (epoch 28.548), train_loss = 0.81316838, grad/param norm = 1.9231e-01, time/batch = 19.5434s	
17044/29850 (epoch 28.549), train_loss = 0.88346689, grad/param norm = 1.9564e-01, time/batch = 18.7192s	
17045/29850 (epoch 28.551), train_loss = 0.80453420, grad/param norm = 1.7816e-01, time/batch = 16.6393s	
17046/29850 (epoch 28.553), train_loss = 0.91969989, grad/param norm = 1.9001e-01, time/batch = 17.4557s	
17047/29850 (epoch 28.554), train_loss = 0.77455682, grad/param norm = 1.8098e-01, time/batch = 18.3079s	
17048/29850 (epoch 28.556), train_loss = 0.84030434, grad/param norm = 2.1458e-01, time/batch = 17.9493s	
17049/29850 (epoch 28.558), train_loss = 0.83481342, grad/param norm = 2.0374e-01, time/batch = 16.7099s	
17050/29850 (epoch 28.559), train_loss = 0.88130627, grad/param norm = 1.9693e-01, time/batch = 17.4318s	
17051/29850 (epoch 28.561), train_loss = 0.96615507, grad/param norm = 2.1746e-01, time/batch = 17.4613s	
17052/29850 (epoch 28.563), train_loss = 0.96226641, grad/param norm = 2.1631e-01, time/batch = 18.3792s	
17053/29850 (epoch 28.564), train_loss = 0.90249588, grad/param norm = 2.1534e-01, time/batch = 16.8729s	
17054/29850 (epoch 28.566), train_loss = 0.94788175, grad/param norm = 2.1348e-01, time/batch = 18.2259s	
17055/29850 (epoch 28.568), train_loss = 1.01400102, grad/param norm = 2.1496e-01, time/batch = 15.9764s	
17056/29850 (epoch 28.570), train_loss = 0.98317250, grad/param norm = 2.5302e-01, time/batch = 16.0448s	
17057/29850 (epoch 28.571), train_loss = 1.00405440, grad/param norm = 2.0334e-01, time/batch = 17.7085s	
17058/29850 (epoch 28.573), train_loss = 1.09529833, grad/param norm = 2.6563e-01, time/batch = 17.3792s	
17059/29850 (epoch 28.575), train_loss = 1.07741694, grad/param norm = 2.2122e-01, time/batch = 17.0278s	
17060/29850 (epoch 28.576), train_loss = 1.05401221, grad/param norm = 2.4409e-01, time/batch = 17.8471s	
17061/29850 (epoch 28.578), train_loss = 0.89734987, grad/param norm = 2.0314e-01, time/batch = 18.9418s	
17062/29850 (epoch 28.580), train_loss = 1.04851265, grad/param norm = 2.0931e-01, time/batch = 19.3802s	
17063/29850 (epoch 28.581), train_loss = 0.83714587, grad/param norm = 1.8363e-01, time/batch = 19.0252s	
17064/29850 (epoch 28.583), train_loss = 0.94686609, grad/param norm = 2.1223e-01, time/batch = 17.7166s	
17065/29850 (epoch 28.585), train_loss = 0.96993839, grad/param norm = 2.0874e-01, time/batch = 17.4407s	
17066/29850 (epoch 28.586), train_loss = 0.95776478, grad/param norm = 2.2991e-01, time/batch = 16.8897s	
17067/29850 (epoch 28.588), train_loss = 0.88852989, grad/param norm = 2.0006e-01, time/batch = 17.8903s	
17068/29850 (epoch 28.590), train_loss = 0.90368820, grad/param norm = 1.8974e-01, time/batch = 17.7249s	
17069/29850 (epoch 28.591), train_loss = 0.90730852, grad/param norm = 2.2896e-01, time/batch = 18.0336s	
17070/29850 (epoch 28.593), train_loss = 0.87959722, grad/param norm = 2.0490e-01, time/batch = 18.2824s	
17071/29850 (epoch 28.595), train_loss = 0.80556469, grad/param norm = 1.7796e-01, time/batch = 17.8070s	
17072/29850 (epoch 28.596), train_loss = 0.80393820, grad/param norm = 1.8117e-01, time/batch = 17.9590s	
17073/29850 (epoch 28.598), train_loss = 0.93687576, grad/param norm = 2.0768e-01, time/batch = 14.8800s	
17074/29850 (epoch 28.600), train_loss = 0.97130695, grad/param norm = 2.2894e-01, time/batch = 16.4850s	
17075/29850 (epoch 28.601), train_loss = 0.81293575, grad/param norm = 1.7401e-01, time/batch = 17.4584s	
17076/29850 (epoch 28.603), train_loss = 0.86356891, grad/param norm = 1.8784e-01, time/batch = 15.8746s	
17077/29850 (epoch 28.605), train_loss = 0.90435407, grad/param norm = 1.9678e-01, time/batch = 16.8073s	
17078/29850 (epoch 28.606), train_loss = 0.67743758, grad/param norm = 1.8463e-01, time/batch = 19.8733s	
17079/29850 (epoch 28.608), train_loss = 0.84093957, grad/param norm = 1.9226e-01, time/batch = 15.2075s	
17080/29850 (epoch 28.610), train_loss = 0.89276213, grad/param norm = 2.0772e-01, time/batch = 16.7972s	
17081/29850 (epoch 28.611), train_loss = 0.82200749, grad/param norm = 1.8219e-01, time/batch = 19.4586s	
17082/29850 (epoch 28.613), train_loss = 0.70115003, grad/param norm = 1.8339e-01, time/batch = 19.2152s	
17083/29850 (epoch 28.615), train_loss = 0.80786024, grad/param norm = 1.8120e-01, time/batch = 17.2050s	
17084/29850 (epoch 28.616), train_loss = 0.81761248, grad/param norm = 2.0101e-01, time/batch = 18.1416s	
17085/29850 (epoch 28.618), train_loss = 0.87838010, grad/param norm = 2.1476e-01, time/batch = 17.1372s	
17086/29850 (epoch 28.620), train_loss = 0.94043952, grad/param norm = 2.1189e-01, time/batch = 17.7884s	
17087/29850 (epoch 28.621), train_loss = 1.06487526, grad/param norm = 2.3055e-01, time/batch = 32.2755s	
17088/29850 (epoch 28.623), train_loss = 0.99067855, grad/param norm = 2.2370e-01, time/batch = 16.9015s	
17089/29850 (epoch 28.625), train_loss = 0.94963849, grad/param norm = 2.8209e-01, time/batch = 17.6910s	
17090/29850 (epoch 28.626), train_loss = 0.95802942, grad/param norm = 2.1670e-01, time/batch = 18.2071s	
17091/29850 (epoch 28.628), train_loss = 0.87187822, grad/param norm = 1.9722e-01, time/batch = 18.9499s	
17092/29850 (epoch 28.630), train_loss = 0.95957181, grad/param norm = 2.6064e-01, time/batch = 16.0397s	
17093/29850 (epoch 28.631), train_loss = 0.92312528, grad/param norm = 2.0292e-01, time/batch = 18.3709s	
17094/29850 (epoch 28.633), train_loss = 0.98696067, grad/param norm = 2.7356e-01, time/batch = 19.5376s	
17095/29850 (epoch 28.635), train_loss = 0.89581853, grad/param norm = 2.6097e-01, time/batch = 18.9705s	
17096/29850 (epoch 28.637), train_loss = 0.85806738, grad/param norm = 2.1313e-01, time/batch = 16.9347s	
17097/29850 (epoch 28.638), train_loss = 0.97509584, grad/param norm = 2.2875e-01, time/batch = 19.3644s	
17098/29850 (epoch 28.640), train_loss = 1.06062420, grad/param norm = 2.2584e-01, time/batch = 17.2918s	
17099/29850 (epoch 28.642), train_loss = 0.85685476, grad/param norm = 1.8805e-01, time/batch = 16.3571s	
17100/29850 (epoch 28.643), train_loss = 0.84228268, grad/param norm = 2.0780e-01, time/batch = 17.8068s	
17101/29850 (epoch 28.645), train_loss = 0.89280244, grad/param norm = 1.9996e-01, time/batch = 17.1298s	
17102/29850 (epoch 28.647), train_loss = 1.04617487, grad/param norm = 2.3210e-01, time/batch = 17.5494s	
17103/29850 (epoch 28.648), train_loss = 0.82893463, grad/param norm = 1.7304e-01, time/batch = 17.7535s	
17104/29850 (epoch 28.650), train_loss = 0.93999580, grad/param norm = 2.0771e-01, time/batch = 18.7279s	
17105/29850 (epoch 28.652), train_loss = 0.91872799, grad/param norm = 2.2167e-01, time/batch = 17.2270s	
17106/29850 (epoch 28.653), train_loss = 1.02700157, grad/param norm = 2.4690e-01, time/batch = 17.9521s	
17107/29850 (epoch 28.655), train_loss = 0.93448892, grad/param norm = 1.9803e-01, time/batch = 18.2885s	
17108/29850 (epoch 28.657), train_loss = 0.89826462, grad/param norm = 1.9859e-01, time/batch = 18.0464s	
17109/29850 (epoch 28.658), train_loss = 1.02589221, grad/param norm = 2.1287e-01, time/batch = 16.9538s	
17110/29850 (epoch 28.660), train_loss = 0.92233715, grad/param norm = 2.1494e-01, time/batch = 18.5399s	
17111/29850 (epoch 28.662), train_loss = 1.02011638, grad/param norm = 2.4274e-01, time/batch = 17.2324s	
17112/29850 (epoch 28.663), train_loss = 1.12310759, grad/param norm = 2.3545e-01, time/batch = 18.2044s	
17113/29850 (epoch 28.665), train_loss = 1.08965501, grad/param norm = 2.2437e-01, time/batch = 18.9502s	
17114/29850 (epoch 28.667), train_loss = 0.99107540, grad/param norm = 3.8823e-01, time/batch = 16.5235s	
17115/29850 (epoch 28.668), train_loss = 0.91060601, grad/param norm = 2.4056e-01, time/batch = 19.1304s	
17116/29850 (epoch 28.670), train_loss = 1.04651963, grad/param norm = 2.8885e-01, time/batch = 17.1096s	
17117/29850 (epoch 28.672), train_loss = 1.08018946, grad/param norm = 2.7207e-01, time/batch = 18.0132s	
17118/29850 (epoch 28.673), train_loss = 0.98393681, grad/param norm = 2.1735e-01, time/batch = 18.6443s	
17119/29850 (epoch 28.675), train_loss = 0.83901544, grad/param norm = 2.1209e-01, time/batch = 16.7869s	
17120/29850 (epoch 28.677), train_loss = 0.90360973, grad/param norm = 2.1844e-01, time/batch = 16.9685s	
17121/29850 (epoch 28.678), train_loss = 0.91831105, grad/param norm = 2.0293e-01, time/batch = 18.7090s	
17122/29850 (epoch 28.680), train_loss = 0.91988953, grad/param norm = 1.8975e-01, time/batch = 17.7171s	
17123/29850 (epoch 28.682), train_loss = 0.93834549, grad/param norm = 2.1324e-01, time/batch = 18.7940s	
17124/29850 (epoch 28.683), train_loss = 1.06221809, grad/param norm = 2.3610e-01, time/batch = 18.8724s	
17125/29850 (epoch 28.685), train_loss = 1.09963988, grad/param norm = 2.0934e-01, time/batch = 16.2175s	
17126/29850 (epoch 28.687), train_loss = 0.96510627, grad/param norm = 2.0676e-01, time/batch = 16.6926s	
17127/29850 (epoch 28.688), train_loss = 0.82639830, grad/param norm = 1.9501e-01, time/batch = 17.6270s	
17128/29850 (epoch 28.690), train_loss = 0.83506246, grad/param norm = 2.1153e-01, time/batch = 18.8844s	
17129/29850 (epoch 28.692), train_loss = 1.03186406, grad/param norm = 2.2180e-01, time/batch = 16.2676s	
17130/29850 (epoch 28.693), train_loss = 0.91644586, grad/param norm = 2.0842e-01, time/batch = 18.8661s	
17131/29850 (epoch 28.695), train_loss = 0.80836830, grad/param norm = 1.7517e-01, time/batch = 16.6924s	
17132/29850 (epoch 28.697), train_loss = 0.92066928, grad/param norm = 1.9874e-01, time/batch = 17.8817s	
17133/29850 (epoch 28.698), train_loss = 1.07013484, grad/param norm = 2.0787e-01, time/batch = 17.2885s	
17134/29850 (epoch 28.700), train_loss = 1.02107154, grad/param norm = 2.2230e-01, time/batch = 18.5430s	
17135/29850 (epoch 28.702), train_loss = 0.93089991, grad/param norm = 2.0937e-01, time/batch = 19.0357s	
17136/29850 (epoch 28.704), train_loss = 0.81761345, grad/param norm = 1.7877e-01, time/batch = 15.9443s	
17137/29850 (epoch 28.705), train_loss = 0.95190116, grad/param norm = 2.2018e-01, time/batch = 17.3551s	
17138/29850 (epoch 28.707), train_loss = 0.84353531, grad/param norm = 2.0907e-01, time/batch = 16.0540s	
17139/29850 (epoch 28.709), train_loss = 0.91157205, grad/param norm = 2.1838e-01, time/batch = 15.9043s	
17140/29850 (epoch 28.710), train_loss = 0.87224470, grad/param norm = 2.0220e-01, time/batch = 15.3558s	
17141/29850 (epoch 28.712), train_loss = 0.93920572, grad/param norm = 1.7639e-01, time/batch = 18.0415s	
17142/29850 (epoch 28.714), train_loss = 1.00662662, grad/param norm = 2.1824e-01, time/batch = 16.8032s	
17143/29850 (epoch 28.715), train_loss = 0.95156090, grad/param norm = 2.0873e-01, time/batch = 16.8655s	
17144/29850 (epoch 28.717), train_loss = 0.71980424, grad/param norm = 2.1633e-01, time/batch = 17.3031s	
17145/29850 (epoch 28.719), train_loss = 0.88664328, grad/param norm = 2.2549e-01, time/batch = 19.3749s	
17146/29850 (epoch 28.720), train_loss = 0.92343020, grad/param norm = 1.9040e-01, time/batch = 18.4543s	
17147/29850 (epoch 28.722), train_loss = 0.84676105, grad/param norm = 1.7553e-01, time/batch = 18.5390s	
17148/29850 (epoch 28.724), train_loss = 0.95635926, grad/param norm = 2.1276e-01, time/batch = 19.2841s	
17149/29850 (epoch 28.725), train_loss = 0.82020690, grad/param norm = 1.8959e-01, time/batch = 16.8915s	
17150/29850 (epoch 28.727), train_loss = 0.84129891, grad/param norm = 2.1921e-01, time/batch = 17.7767s	
17151/29850 (epoch 28.729), train_loss = 0.77812361, grad/param norm = 1.6431e-01, time/batch = 17.3844s	
17152/29850 (epoch 28.730), train_loss = 0.74887784, grad/param norm = 1.9071e-01, time/batch = 18.4811s	
17153/29850 (epoch 28.732), train_loss = 1.00559182, grad/param norm = 1.9391e-01, time/batch = 17.3619s	
17154/29850 (epoch 28.734), train_loss = 1.10193403, grad/param norm = 2.3617e-01, time/batch = 18.2638s	
17155/29850 (epoch 28.735), train_loss = 0.86116675, grad/param norm = 2.1412e-01, time/batch = 18.1308s	
17156/29850 (epoch 28.737), train_loss = 0.82083078, grad/param norm = 1.9494e-01, time/batch = 17.4502s	
17157/29850 (epoch 28.739), train_loss = 0.72935292, grad/param norm = 2.2223e-01, time/batch = 15.9385s	
17158/29850 (epoch 28.740), train_loss = 0.80251680, grad/param norm = 2.1081e-01, time/batch = 15.9570s	
17159/29850 (epoch 28.742), train_loss = 0.70353059, grad/param norm = 1.6754e-01, time/batch = 16.7200s	
17160/29850 (epoch 28.744), train_loss = 0.83879023, grad/param norm = 2.1589e-01, time/batch = 16.4513s	
17161/29850 (epoch 28.745), train_loss = 0.85690762, grad/param norm = 2.9179e-01, time/batch = 18.4670s	
17162/29850 (epoch 28.747), train_loss = 0.89502087, grad/param norm = 2.1237e-01, time/batch = 16.8021s	
17163/29850 (epoch 28.749), train_loss = 0.80579441, grad/param norm = 2.3354e-01, time/batch = 17.1372s	
17164/29850 (epoch 28.750), train_loss = 0.76406463, grad/param norm = 2.0547e-01, time/batch = 16.9624s	
17165/29850 (epoch 28.752), train_loss = 0.66399435, grad/param norm = 1.6621e-01, time/batch = 17.0393s	
17166/29850 (epoch 28.754), train_loss = 0.77125897, grad/param norm = 1.9414e-01, time/batch = 16.7255s	
17167/29850 (epoch 28.755), train_loss = 0.77477152, grad/param norm = 1.9979e-01, time/batch = 16.4479s	
17168/29850 (epoch 28.757), train_loss = 0.81081046, grad/param norm = 1.7911e-01, time/batch = 18.1254s	
17169/29850 (epoch 28.759), train_loss = 0.81840932, grad/param norm = 1.9203e-01, time/batch = 17.1303s	
17170/29850 (epoch 28.760), train_loss = 0.81571304, grad/param norm = 2.2830e-01, time/batch = 17.1758s	
17171/29850 (epoch 28.762), train_loss = 0.76122095, grad/param norm = 2.2424e-01, time/batch = 17.2859s	
17172/29850 (epoch 28.764), train_loss = 0.71154464, grad/param norm = 2.0874e-01, time/batch = 17.4390s	
17173/29850 (epoch 28.765), train_loss = 0.87191805, grad/param norm = 2.0978e-01, time/batch = 18.4732s	
17174/29850 (epoch 28.767), train_loss = 0.88568373, grad/param norm = 2.0466e-01, time/batch = 17.0411s	
17175/29850 (epoch 28.769), train_loss = 0.87873464, grad/param norm = 1.9540e-01, time/batch = 14.5935s	
17176/29850 (epoch 28.771), train_loss = 0.93805668, grad/param norm = 2.0289e-01, time/batch = 16.5997s	
17177/29850 (epoch 28.772), train_loss = 0.90589386, grad/param norm = 2.0608e-01, time/batch = 16.0309s	
17178/29850 (epoch 28.774), train_loss = 0.84237807, grad/param norm = 1.9715e-01, time/batch = 17.2004s	
17179/29850 (epoch 28.776), train_loss = 0.85830184, grad/param norm = 1.9037e-01, time/batch = 16.9741s	
17180/29850 (epoch 28.777), train_loss = 0.99388738, grad/param norm = 2.3034e-01, time/batch = 18.5434s	
17181/29850 (epoch 28.779), train_loss = 0.80322089, grad/param norm = 1.9559e-01, time/batch = 15.7111s	
17182/29850 (epoch 28.781), train_loss = 0.93021256, grad/param norm = 2.0849e-01, time/batch = 17.2110s	
17183/29850 (epoch 28.782), train_loss = 0.93322998, grad/param norm = 2.0271e-01, time/batch = 16.4798s	
17184/29850 (epoch 28.784), train_loss = 0.76083798, grad/param norm = 2.2703e-01, time/batch = 15.8113s	
17185/29850 (epoch 28.786), train_loss = 0.85444767, grad/param norm = 2.0612e-01, time/batch = 15.6278s	
17186/29850 (epoch 28.787), train_loss = 0.74949096, grad/param norm = 2.3430e-01, time/batch = 16.5758s	
17187/29850 (epoch 28.789), train_loss = 0.74859221, grad/param norm = 1.8938e-01, time/batch = 14.9076s	
17188/29850 (epoch 28.791), train_loss = 0.83566738, grad/param norm = 2.5866e-01, time/batch = 16.8770s	
17189/29850 (epoch 28.792), train_loss = 0.94554404, grad/param norm = 2.4347e-01, time/batch = 15.5593s	
17190/29850 (epoch 28.794), train_loss = 0.93744598, grad/param norm = 2.1147e-01, time/batch = 16.3266s	
17191/29850 (epoch 28.796), train_loss = 0.79011332, grad/param norm = 1.8182e-01, time/batch = 17.4738s	
17192/29850 (epoch 28.797), train_loss = 0.71168459, grad/param norm = 1.7225e-01, time/batch = 15.9298s	
17193/29850 (epoch 28.799), train_loss = 0.73215883, grad/param norm = 1.6231e-01, time/batch = 15.9344s	
17194/29850 (epoch 28.801), train_loss = 0.80469791, grad/param norm = 2.0666e-01, time/batch = 17.9632s	
17195/29850 (epoch 28.802), train_loss = 0.74747228, grad/param norm = 2.0889e-01, time/batch = 17.2072s	
17196/29850 (epoch 28.804), train_loss = 0.76717059, grad/param norm = 1.7327e-01, time/batch = 16.7950s	
17197/29850 (epoch 28.806), train_loss = 0.73518153, grad/param norm = 1.7797e-01, time/batch = 19.1279s	
17198/29850 (epoch 28.807), train_loss = 0.74551400, grad/param norm = 1.8919e-01, time/batch = 19.5449s	
17199/29850 (epoch 28.809), train_loss = 0.76542553, grad/param norm = 1.9491e-01, time/batch = 17.4434s	
17200/29850 (epoch 28.811), train_loss = 0.92028607, grad/param norm = 2.2203e-01, time/batch = 19.4520s	
17201/29850 (epoch 28.812), train_loss = 0.90783230, grad/param norm = 2.2578e-01, time/batch = 19.1272s	
17202/29850 (epoch 28.814), train_loss = 0.98649245, grad/param norm = 2.3345e-01, time/batch = 17.1066s	
17203/29850 (epoch 28.816), train_loss = 0.97305367, grad/param norm = 2.0395e-01, time/batch = 17.7227s	
17204/29850 (epoch 28.817), train_loss = 0.91139439, grad/param norm = 2.2075e-01, time/batch = 18.7978s	
17205/29850 (epoch 28.819), train_loss = 0.75298373, grad/param norm = 2.0911e-01, time/batch = 17.3726s	
17206/29850 (epoch 28.821), train_loss = 0.98643791, grad/param norm = 2.6469e-01, time/batch = 16.6875s	
17207/29850 (epoch 28.822), train_loss = 0.98410944, grad/param norm = 2.2457e-01, time/batch = 16.9041s	
17208/29850 (epoch 28.824), train_loss = 0.88259528, grad/param norm = 2.1935e-01, time/batch = 17.2952s	
17209/29850 (epoch 28.826), train_loss = 0.77731079, grad/param norm = 1.7850e-01, time/batch = 16.5403s	
17210/29850 (epoch 28.827), train_loss = 0.72509588, grad/param norm = 2.1264e-01, time/batch = 17.8810s	
17211/29850 (epoch 28.829), train_loss = 0.89267859, grad/param norm = 3.8647e-01, time/batch = 19.2248s	
17212/29850 (epoch 28.831), train_loss = 1.00258368, grad/param norm = 2.5385e-01, time/batch = 16.6983s	
17213/29850 (epoch 28.832), train_loss = 0.90038186, grad/param norm = 1.9717e-01, time/batch = 16.7849s	
17214/29850 (epoch 28.834), train_loss = 0.69892559, grad/param norm = 1.8281e-01, time/batch = 16.4600s	
17215/29850 (epoch 28.836), train_loss = 0.72919782, grad/param norm = 1.7966e-01, time/batch = 17.8926s	
17216/29850 (epoch 28.838), train_loss = 0.84286749, grad/param norm = 2.0919e-01, time/batch = 17.2161s	
17217/29850 (epoch 28.839), train_loss = 0.74696240, grad/param norm = 2.0117e-01, time/batch = 17.7948s	
17218/29850 (epoch 28.841), train_loss = 0.79007693, grad/param norm = 1.8463e-01, time/batch = 18.7021s	
17219/29850 (epoch 28.843), train_loss = 0.73797375, grad/param norm = 2.3865e-01, time/batch = 17.7739s	
17220/29850 (epoch 28.844), train_loss = 0.79098796, grad/param norm = 1.9990e-01, time/batch = 18.7156s	
17221/29850 (epoch 28.846), train_loss = 0.85839866, grad/param norm = 1.9861e-01, time/batch = 17.3878s	
17222/29850 (epoch 28.848), train_loss = 0.94099095, grad/param norm = 2.3638e-01, time/batch = 18.2831s	
17223/29850 (epoch 28.849), train_loss = 0.81523469, grad/param norm = 1.8669e-01, time/batch = 17.8619s	
17224/29850 (epoch 28.851), train_loss = 0.99981046, grad/param norm = 2.2291e-01, time/batch = 16.9683s	
17225/29850 (epoch 28.853), train_loss = 0.83109004, grad/param norm = 2.0429e-01, time/batch = 19.2916s	
17226/29850 (epoch 28.854), train_loss = 1.03526910, grad/param norm = 2.2728e-01, time/batch = 17.6067s	
17227/29850 (epoch 28.856), train_loss = 0.97958293, grad/param norm = 2.5220e-01, time/batch = 17.8849s	
17228/29850 (epoch 28.858), train_loss = 0.91702978, grad/param norm = 2.1849e-01, time/batch = 18.4268s	
17229/29850 (epoch 28.859), train_loss = 0.79409394, grad/param norm = 2.3229e-01, time/batch = 16.3572s	
17230/29850 (epoch 28.861), train_loss = 0.99924615, grad/param norm = 2.2865e-01, time/batch = 18.5629s	
17231/29850 (epoch 28.863), train_loss = 1.05376190, grad/param norm = 2.4511e-01, time/batch = 19.5380s	
17232/29850 (epoch 28.864), train_loss = 0.99636919, grad/param norm = 2.4268e-01, time/batch = 17.3705s	
17233/29850 (epoch 28.866), train_loss = 0.91844428, grad/param norm = 2.3243e-01, time/batch = 17.2028s	
17234/29850 (epoch 28.868), train_loss = 1.06332549, grad/param norm = 2.2950e-01, time/batch = 17.9720s	
17235/29850 (epoch 28.869), train_loss = 0.95538684, grad/param norm = 2.4895e-01, time/batch = 18.7122s	
17236/29850 (epoch 28.871), train_loss = 0.97047770, grad/param norm = 2.0488e-01, time/batch = 19.1992s	
17237/29850 (epoch 28.873), train_loss = 0.92867048, grad/param norm = 2.1984e-01, time/batch = 17.8738s	
17238/29850 (epoch 28.874), train_loss = 0.94910628, grad/param norm = 2.4841e-01, time/batch = 15.9598s	
17239/29850 (epoch 28.876), train_loss = 0.88401321, grad/param norm = 2.8326e-01, time/batch = 16.3688s	
17240/29850 (epoch 28.878), train_loss = 0.91926134, grad/param norm = 2.1170e-01, time/batch = 16.8731s	
17241/29850 (epoch 28.879), train_loss = 0.91961223, grad/param norm = 2.0675e-01, time/batch = 17.7249s	
17242/29850 (epoch 28.881), train_loss = 1.00950555, grad/param norm = 2.3925e-01, time/batch = 17.4618s	
17243/29850 (epoch 28.883), train_loss = 0.98464001, grad/param norm = 2.3830e-01, time/batch = 18.7094s	
17244/29850 (epoch 28.884), train_loss = 0.78996431, grad/param norm = 1.8724e-01, time/batch = 17.4723s	
17245/29850 (epoch 28.886), train_loss = 1.00211613, grad/param norm = 2.2130e-01, time/batch = 17.9490s	
17246/29850 (epoch 28.888), train_loss = 0.89674442, grad/param norm = 2.1829e-01, time/batch = 17.8500s	
17247/29850 (epoch 28.889), train_loss = 0.82000743, grad/param norm = 1.8004e-01, time/batch = 16.4481s	
17248/29850 (epoch 28.891), train_loss = 0.79921312, grad/param norm = 1.8182e-01, time/batch = 16.3934s	
17249/29850 (epoch 28.893), train_loss = 0.85285445, grad/param norm = 1.9407e-01, time/batch = 16.4723s	
17250/29850 (epoch 28.894), train_loss = 0.85724123, grad/param norm = 2.2247e-01, time/batch = 19.3676s	
17251/29850 (epoch 28.896), train_loss = 0.92194558, grad/param norm = 2.6445e-01, time/batch = 19.3597s	
17252/29850 (epoch 28.898), train_loss = 1.02540094, grad/param norm = 2.2544e-01, time/batch = 18.6099s	
17253/29850 (epoch 28.899), train_loss = 0.82273254, grad/param norm = 2.4581e-01, time/batch = 19.0060s	
17254/29850 (epoch 28.901), train_loss = 1.14888623, grad/param norm = 3.1518e-01, time/batch = 18.3763s	
17255/29850 (epoch 28.903), train_loss = 0.95244845, grad/param norm = 3.8240e-01, time/batch = 18.8821s	
17256/29850 (epoch 28.905), train_loss = 1.15966426, grad/param norm = 2.4591e-01, time/batch = 16.1846s	
17257/29850 (epoch 28.906), train_loss = 0.95127612, grad/param norm = 2.2195e-01, time/batch = 17.8743s	
17258/29850 (epoch 28.908), train_loss = 1.08527182, grad/param norm = 2.5874e-01, time/batch = 17.7284s	
17259/29850 (epoch 28.910), train_loss = 0.99809398, grad/param norm = 2.2566e-01, time/batch = 17.3499s	
17260/29850 (epoch 28.911), train_loss = 1.14231663, grad/param norm = 2.3112e-01, time/batch = 16.1464s	
17261/29850 (epoch 28.913), train_loss = 1.05598688, grad/param norm = 2.4206e-01, time/batch = 16.6940s	
17262/29850 (epoch 28.915), train_loss = 1.06636239, grad/param norm = 2.3969e-01, time/batch = 17.1138s	
17263/29850 (epoch 28.916), train_loss = 0.99306902, grad/param norm = 2.2018e-01, time/batch = 17.0443s	
17264/29850 (epoch 28.918), train_loss = 0.85771038, grad/param norm = 2.0568e-01, time/batch = 19.2152s	
17265/29850 (epoch 28.920), train_loss = 1.03459387, grad/param norm = 2.0688e-01, time/batch = 18.3790s	
17266/29850 (epoch 28.921), train_loss = 0.92920128, grad/param norm = 2.3171e-01, time/batch = 17.4620s	
17267/29850 (epoch 28.923), train_loss = 0.95670299, grad/param norm = 1.9594e-01, time/batch = 19.2103s	
17268/29850 (epoch 28.925), train_loss = 1.05942967, grad/param norm = 2.3118e-01, time/batch = 17.5476s	
17269/29850 (epoch 28.926), train_loss = 1.07136965, grad/param norm = 2.5883e-01, time/batch = 15.2631s	
17270/29850 (epoch 28.928), train_loss = 0.93911687, grad/param norm = 2.2329e-01, time/batch = 16.9502s	
17271/29850 (epoch 28.930), train_loss = 0.97691998, grad/param norm = 2.0534e-01, time/batch = 18.8029s	
17272/29850 (epoch 28.931), train_loss = 0.93889050, grad/param norm = 2.2108e-01, time/batch = 19.9536s	
17273/29850 (epoch 28.933), train_loss = 1.08641138, grad/param norm = 2.5080e-01, time/batch = 17.5986s	
17274/29850 (epoch 28.935), train_loss = 1.01803455, grad/param norm = 2.4340e-01, time/batch = 18.1464s	
17275/29850 (epoch 28.936), train_loss = 0.97477337, grad/param norm = 2.3467e-01, time/batch = 16.2039s	
17276/29850 (epoch 28.938), train_loss = 0.83534897, grad/param norm = 2.0326e-01, time/batch = 17.6234s	
17277/29850 (epoch 28.940), train_loss = 0.80765437, grad/param norm = 1.8654e-01, time/batch = 18.9503s	
17278/29850 (epoch 28.941), train_loss = 0.84845736, grad/param norm = 2.2662e-01, time/batch = 16.9365s	
17279/29850 (epoch 28.943), train_loss = 0.84751902, grad/param norm = 2.0195e-01, time/batch = 16.5363s	
17280/29850 (epoch 28.945), train_loss = 0.84894121, grad/param norm = 2.4799e-01, time/batch = 18.6088s	
17281/29850 (epoch 28.946), train_loss = 0.81971859, grad/param norm = 2.1112e-01, time/batch = 18.3821s	
17282/29850 (epoch 28.948), train_loss = 0.92516184, grad/param norm = 1.9019e-01, time/batch = 14.4213s	
17283/29850 (epoch 28.950), train_loss = 0.86319539, grad/param norm = 1.9931e-01, time/batch = 16.7023s	
17284/29850 (epoch 28.951), train_loss = 0.76797614, grad/param norm = 1.7299e-01, time/batch = 17.0390s	
17285/29850 (epoch 28.953), train_loss = 0.88831328, grad/param norm = 2.2367e-01, time/batch = 19.2952s	
17286/29850 (epoch 28.955), train_loss = 0.79239281, grad/param norm = 1.8847e-01, time/batch = 18.2053s	
17287/29850 (epoch 28.956), train_loss = 0.78848804, grad/param norm = 1.9227e-01, time/batch = 19.5370s	
17288/29850 (epoch 28.958), train_loss = 0.69526852, grad/param norm = 1.5027e-01, time/batch = 17.9828s	
17289/29850 (epoch 28.960), train_loss = 0.99337061, grad/param norm = 2.3529e-01, time/batch = 18.8712s	
17290/29850 (epoch 28.961), train_loss = 0.80015680, grad/param norm = 2.0714e-01, time/batch = 30.6734s	
17291/29850 (epoch 28.963), train_loss = 0.76468656, grad/param norm = 1.9931e-01, time/batch = 17.4605s	
17292/29850 (epoch 28.965), train_loss = 0.83732071, grad/param norm = 2.0376e-01, time/batch = 15.8108s	
17293/29850 (epoch 28.966), train_loss = 0.76901212, grad/param norm = 1.9039e-01, time/batch = 17.6329s	
17294/29850 (epoch 28.968), train_loss = 0.81196015, grad/param norm = 1.9114e-01, time/batch = 18.1236s	
17295/29850 (epoch 28.970), train_loss = 0.78018254, grad/param norm = 2.1553e-01, time/batch = 16.7269s	
17296/29850 (epoch 28.972), train_loss = 0.79693962, grad/param norm = 1.6314e-01, time/batch = 18.0336s	
17297/29850 (epoch 28.973), train_loss = 0.81392222, grad/param norm = 1.9282e-01, time/batch = 16.2528s	
17298/29850 (epoch 28.975), train_loss = 0.69923920, grad/param norm = 1.7230e-01, time/batch = 17.7148s	
17299/29850 (epoch 28.977), train_loss = 0.83682077, grad/param norm = 1.8420e-01, time/batch = 17.5403s	
17300/29850 (epoch 28.978), train_loss = 0.75002589, grad/param norm = 1.7695e-01, time/batch = 19.2843s	
17301/29850 (epoch 28.980), train_loss = 0.83827012, grad/param norm = 1.9040e-01, time/batch = 17.6231s	
17302/29850 (epoch 28.982), train_loss = 0.79809989, grad/param norm = 1.9440e-01, time/batch = 17.5476s	
17303/29850 (epoch 28.983), train_loss = 0.83918795, grad/param norm = 1.7519e-01, time/batch = 17.7021s	
17304/29850 (epoch 28.985), train_loss = 0.93652275, grad/param norm = 1.9822e-01, time/batch = 19.6921s	
17305/29850 (epoch 28.987), train_loss = 0.90608457, grad/param norm = 2.1012e-01, time/batch = 18.5386s	
17306/29850 (epoch 28.988), train_loss = 0.81730623, grad/param norm = 1.6909e-01, time/batch = 16.7715s	
17307/29850 (epoch 28.990), train_loss = 0.88933831, grad/param norm = 1.9752e-01, time/batch = 17.9657s	
17308/29850 (epoch 28.992), train_loss = 0.91447411, grad/param norm = 1.8226e-01, time/batch = 18.4715s	
17309/29850 (epoch 28.993), train_loss = 0.92196431, grad/param norm = 2.3000e-01, time/batch = 16.8748s	
17310/29850 (epoch 28.995), train_loss = 0.90200767, grad/param norm = 2.0120e-01, time/batch = 18.7682s	
17311/29850 (epoch 28.997), train_loss = 0.94743585, grad/param norm = 2.0893e-01, time/batch = 19.2707s	
17312/29850 (epoch 28.998), train_loss = 0.94181344, grad/param norm = 2.0437e-01, time/batch = 16.2066s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
17313/29850 (epoch 29.000), train_loss = 0.78879375, grad/param norm = 1.8604e-01, time/batch = 20.2833s	
17314/29850 (epoch 29.002), train_loss = 1.05725385, grad/param norm = 2.3312e-01, time/batch = 17.6238s	
17315/29850 (epoch 29.003), train_loss = 0.79864738, grad/param norm = 2.3087e-01, time/batch = 16.1293s	
17316/29850 (epoch 29.005), train_loss = 0.92265163, grad/param norm = 2.0747e-01, time/batch = 17.6906s	
17317/29850 (epoch 29.007), train_loss = 1.00279367, grad/param norm = 2.5071e-01, time/batch = 18.8539s	
17318/29850 (epoch 29.008), train_loss = 1.11547469, grad/param norm = 2.1932e-01, time/batch = 19.5350s	
17319/29850 (epoch 29.010), train_loss = 0.84409529, grad/param norm = 2.2726e-01, time/batch = 16.3808s	
17320/29850 (epoch 29.012), train_loss = 0.88556047, grad/param norm = 1.9431e-01, time/batch = 19.0430s	
17321/29850 (epoch 29.013), train_loss = 0.95031368, grad/param norm = 2.3837e-01, time/batch = 17.8746s	
17322/29850 (epoch 29.015), train_loss = 0.96057352, grad/param norm = 2.0905e-01, time/batch = 16.7920s	
17323/29850 (epoch 29.017), train_loss = 0.93869672, grad/param norm = 2.3159e-01, time/batch = 15.9432s	
17324/29850 (epoch 29.018), train_loss = 1.05427342, grad/param norm = 2.4121e-01, time/batch = 17.8855s	
17325/29850 (epoch 29.020), train_loss = 0.89191858, grad/param norm = 2.2753e-01, time/batch = 17.0705s	
17326/29850 (epoch 29.022), train_loss = 0.98357694, grad/param norm = 2.1956e-01, time/batch = 15.3506s	
17327/29850 (epoch 29.023), train_loss = 0.99528213, grad/param norm = 2.0866e-01, time/batch = 18.3782s	
17328/29850 (epoch 29.025), train_loss = 0.89407747, grad/param norm = 1.8573e-01, time/batch = 19.3749s	
17329/29850 (epoch 29.027), train_loss = 0.71712760, grad/param norm = 1.8484e-01, time/batch = 16.3766s	
17330/29850 (epoch 29.028), train_loss = 0.85499672, grad/param norm = 1.9254e-01, time/batch = 19.3552s	
17331/29850 (epoch 29.030), train_loss = 0.87793512, grad/param norm = 2.1732e-01, time/batch = 17.0380s	
17332/29850 (epoch 29.032), train_loss = 0.95588172, grad/param norm = 1.8702e-01, time/batch = 18.4391s	
17333/29850 (epoch 29.034), train_loss = 0.83423810, grad/param norm = 1.9714e-01, time/batch = 20.5995s	
17334/29850 (epoch 29.035), train_loss = 0.73513629, grad/param norm = 1.7127e-01, time/batch = 16.6174s	
17335/29850 (epoch 29.037), train_loss = 0.90254397, grad/param norm = 2.1259e-01, time/batch = 18.4583s	
17336/29850 (epoch 29.039), train_loss = 0.79611711, grad/param norm = 1.7621e-01, time/batch = 16.6835s	
17337/29850 (epoch 29.040), train_loss = 0.82094806, grad/param norm = 1.9110e-01, time/batch = 20.0464s	
17338/29850 (epoch 29.042), train_loss = 0.80230780, grad/param norm = 1.8441e-01, time/batch = 17.7004s	
17339/29850 (epoch 29.044), train_loss = 0.85017060, grad/param norm = 1.8556e-01, time/batch = 16.7027s	
17340/29850 (epoch 29.045), train_loss = 0.95513569, grad/param norm = 2.0509e-01, time/batch = 17.4568s	
17341/29850 (epoch 29.047), train_loss = 0.79343791, grad/param norm = 1.8154e-01, time/batch = 16.2963s	
17342/29850 (epoch 29.049), train_loss = 0.93779615, grad/param norm = 1.9697e-01, time/batch = 18.6288s	
17343/29850 (epoch 29.050), train_loss = 0.79851153, grad/param norm = 1.9262e-01, time/batch = 18.2745s	
17344/29850 (epoch 29.052), train_loss = 0.99902036, grad/param norm = 2.2381e-01, time/batch = 19.6189s	
17345/29850 (epoch 29.054), train_loss = 0.91595083, grad/param norm = 2.4474e-01, time/batch = 17.0347s	
17346/29850 (epoch 29.055), train_loss = 0.87378735, grad/param norm = 2.0926e-01, time/batch = 16.9650s	
17347/29850 (epoch 29.057), train_loss = 0.94633195, grad/param norm = 1.9264e-01, time/batch = 17.6974s	
17348/29850 (epoch 29.059), train_loss = 0.95517386, grad/param norm = 2.1456e-01, time/batch = 17.6907s	
17349/29850 (epoch 29.060), train_loss = 0.90855358, grad/param norm = 2.2601e-01, time/batch = 18.1232s	
17350/29850 (epoch 29.062), train_loss = 1.01204863, grad/param norm = 2.3498e-01, time/batch = 18.1323s	
17351/29850 (epoch 29.064), train_loss = 0.95612653, grad/param norm = 2.0585e-01, time/batch = 19.7061s	
17352/29850 (epoch 29.065), train_loss = 0.79622749, grad/param norm = 1.9532e-01, time/batch = 18.0324s	
17353/29850 (epoch 29.067), train_loss = 0.96486196, grad/param norm = 1.9881e-01, time/batch = 15.2840s	
17354/29850 (epoch 29.069), train_loss = 0.93389705, grad/param norm = 1.9314e-01, time/batch = 16.4764s	
17355/29850 (epoch 29.070), train_loss = 0.94979615, grad/param norm = 1.9696e-01, time/batch = 18.5665s	
17356/29850 (epoch 29.072), train_loss = 0.92206378, grad/param norm = 2.0927e-01, time/batch = 15.7835s	
17357/29850 (epoch 29.074), train_loss = 0.98707818, grad/param norm = 2.0512e-01, time/batch = 18.7980s	
17358/29850 (epoch 29.075), train_loss = 0.82183561, grad/param norm = 2.0365e-01, time/batch = 17.4779s	
17359/29850 (epoch 29.077), train_loss = 0.95082429, grad/param norm = 2.0413e-01, time/batch = 18.9532s	
17360/29850 (epoch 29.079), train_loss = 1.14417349, grad/param norm = 4.6178e-01, time/batch = 17.8720s	
17361/29850 (epoch 29.080), train_loss = 1.09872180, grad/param norm = 2.7213e-01, time/batch = 18.1289s	
17362/29850 (epoch 29.082), train_loss = 0.98280894, grad/param norm = 2.1991e-01, time/batch = 16.6393s	
17363/29850 (epoch 29.084), train_loss = 1.09403890, grad/param norm = 2.2911e-01, time/batch = 16.9621s	
17364/29850 (epoch 29.085), train_loss = 1.09824958, grad/param norm = 3.0769e-01, time/batch = 17.0562s	
17365/29850 (epoch 29.087), train_loss = 1.05698138, grad/param norm = 2.3709e-01, time/batch = 16.6492s	
17366/29850 (epoch 29.089), train_loss = 0.94053822, grad/param norm = 2.0708e-01, time/batch = 14.6422s	
17367/29850 (epoch 29.090), train_loss = 1.00352980, grad/param norm = 2.1621e-01, time/batch = 17.8779s	
17368/29850 (epoch 29.092), train_loss = 0.86003264, grad/param norm = 1.8012e-01, time/batch = 19.6998s	
17369/29850 (epoch 29.094), train_loss = 1.07828783, grad/param norm = 2.3852e-01, time/batch = 17.6913s	
17370/29850 (epoch 29.095), train_loss = 0.99763537, grad/param norm = 3.5963e-01, time/batch = 17.0294s	
17371/29850 (epoch 29.097), train_loss = 0.75661741, grad/param norm = 1.8409e-01, time/batch = 18.7073s	
17372/29850 (epoch 29.099), train_loss = 0.77774767, grad/param norm = 1.7408e-01, time/batch = 19.7145s	
17373/29850 (epoch 29.101), train_loss = 1.01871114, grad/param norm = 2.1824e-01, time/batch = 16.1019s	
17374/29850 (epoch 29.102), train_loss = 0.98968382, grad/param norm = 2.4841e-01, time/batch = 17.6312s	
17375/29850 (epoch 29.104), train_loss = 0.89500871, grad/param norm = 2.2272e-01, time/batch = 17.9754s	
17376/29850 (epoch 29.106), train_loss = 1.01874795, grad/param norm = 2.0686e-01, time/batch = 17.0563s	
17377/29850 (epoch 29.107), train_loss = 0.85514187, grad/param norm = 2.0157e-01, time/batch = 18.0336s	
17378/29850 (epoch 29.109), train_loss = 0.92928886, grad/param norm = 2.4438e-01, time/batch = 17.8873s	
17379/29850 (epoch 29.111), train_loss = 0.97524835, grad/param norm = 1.9770e-01, time/batch = 16.8055s	
17380/29850 (epoch 29.112), train_loss = 0.86487634, grad/param norm = 2.2086e-01, time/batch = 18.3542s	
17381/29850 (epoch 29.114), train_loss = 0.87264035, grad/param norm = 2.3141e-01, time/batch = 17.0511s	
17382/29850 (epoch 29.116), train_loss = 0.84703179, grad/param norm = 1.8850e-01, time/batch = 19.9539s	
17383/29850 (epoch 29.117), train_loss = 0.90984913, grad/param norm = 2.4373e-01, time/batch = 15.6281s	
17384/29850 (epoch 29.119), train_loss = 0.88765371, grad/param norm = 2.2012e-01, time/batch = 17.4557s	
17385/29850 (epoch 29.121), train_loss = 0.73676168, grad/param norm = 1.9411e-01, time/batch = 15.3966s	
17386/29850 (epoch 29.122), train_loss = 0.77357032, grad/param norm = 1.7366e-01, time/batch = 18.7041s	
17387/29850 (epoch 29.124), train_loss = 0.82898215, grad/param norm = 1.9762e-01, time/batch = 17.4632s	
17388/29850 (epoch 29.126), train_loss = 0.86105835, grad/param norm = 1.8782e-01, time/batch = 19.0159s	
17389/29850 (epoch 29.127), train_loss = 0.97468783, grad/param norm = 2.3406e-01, time/batch = 18.2246s	
17390/29850 (epoch 29.129), train_loss = 0.86654104, grad/param norm = 1.9169e-01, time/batch = 15.6921s	
17391/29850 (epoch 29.131), train_loss = 0.89820625, grad/param norm = 1.9564e-01, time/batch = 17.4546s	
17392/29850 (epoch 29.132), train_loss = 0.82128348, grad/param norm = 2.4466e-01, time/batch = 17.7210s	
17393/29850 (epoch 29.134), train_loss = 0.87362818, grad/param norm = 2.0968e-01, time/batch = 17.7861s	
17394/29850 (epoch 29.136), train_loss = 0.95830666, grad/param norm = 2.1470e-01, time/batch = 19.6967s	
17395/29850 (epoch 29.137), train_loss = 0.74772667, grad/param norm = 1.7856e-01, time/batch = 15.0335s	
17396/29850 (epoch 29.139), train_loss = 0.90726933, grad/param norm = 2.0236e-01, time/batch = 16.8692s	
17397/29850 (epoch 29.141), train_loss = 0.81538746, grad/param norm = 1.9076e-01, time/batch = 17.2707s	
17398/29850 (epoch 29.142), train_loss = 1.03509985, grad/param norm = 2.3180e-01, time/batch = 17.8799s	
17399/29850 (epoch 29.144), train_loss = 1.17186122, grad/param norm = 2.6528e-01, time/batch = 18.5430s	
17400/29850 (epoch 29.146), train_loss = 1.16454064, grad/param norm = 2.5707e-01, time/batch = 17.0361s	
17401/29850 (epoch 29.147), train_loss = 1.00588851, grad/param norm = 2.3399e-01, time/batch = 18.4565s	
17402/29850 (epoch 29.149), train_loss = 0.95239515, grad/param norm = 2.0990e-01, time/batch = 17.8723s	
17403/29850 (epoch 29.151), train_loss = 0.96824219, grad/param norm = 2.2365e-01, time/batch = 17.7932s	
17404/29850 (epoch 29.152), train_loss = 0.87454196, grad/param norm = 1.9650e-01, time/batch = 17.3669s	
17405/29850 (epoch 29.154), train_loss = 0.86261892, grad/param norm = 2.2457e-01, time/batch = 19.9490s	
17406/29850 (epoch 29.156), train_loss = 0.83333034, grad/param norm = 1.9438e-01, time/batch = 19.3700s	
17407/29850 (epoch 29.157), train_loss = 0.94369534, grad/param norm = 2.0281e-01, time/batch = 16.8596s	
17408/29850 (epoch 29.159), train_loss = 0.86513377, grad/param norm = 1.9336e-01, time/batch = 17.4635s	
17409/29850 (epoch 29.161), train_loss = 0.92961745, grad/param norm = 2.1946e-01, time/batch = 16.1204s	
17410/29850 (epoch 29.162), train_loss = 1.05470704, grad/param norm = 2.4732e-01, time/batch = 17.2787s	
17411/29850 (epoch 29.164), train_loss = 0.93366811, grad/param norm = 2.0831e-01, time/batch = 18.3631s	
17412/29850 (epoch 29.166), train_loss = 0.87189809, grad/param norm = 2.0967e-01, time/batch = 17.9638s	
17413/29850 (epoch 29.168), train_loss = 0.77788412, grad/param norm = 1.8421e-01, time/batch = 15.7896s	
17414/29850 (epoch 29.169), train_loss = 1.06219105, grad/param norm = 2.5172e-01, time/batch = 17.7818s	
17415/29850 (epoch 29.171), train_loss = 0.99171968, grad/param norm = 2.1812e-01, time/batch = 17.9750s	
17416/29850 (epoch 29.173), train_loss = 0.83225171, grad/param norm = 2.0306e-01, time/batch = 19.3640s	
17417/29850 (epoch 29.174), train_loss = 0.94353214, grad/param norm = 2.3907e-01, time/batch = 18.6066s	
17418/29850 (epoch 29.176), train_loss = 0.92573499, grad/param norm = 2.0136e-01, time/batch = 19.7071s	
17419/29850 (epoch 29.178), train_loss = 0.95376576, grad/param norm = 2.2095e-01, time/batch = 17.3888s	
17420/29850 (epoch 29.179), train_loss = 0.78322893, grad/param norm = 1.8435e-01, time/batch = 17.4529s	
17421/29850 (epoch 29.181), train_loss = 0.93451555, grad/param norm = 2.1825e-01, time/batch = 19.2138s	
17422/29850 (epoch 29.183), train_loss = 0.92794909, grad/param norm = 2.0579e-01, time/batch = 18.2123s	
17423/29850 (epoch 29.184), train_loss = 0.95057936, grad/param norm = 2.0336e-01, time/batch = 17.8608s	
17424/29850 (epoch 29.186), train_loss = 0.92651168, grad/param norm = 2.3715e-01, time/batch = 18.9673s	
17425/29850 (epoch 29.188), train_loss = 1.03702248, grad/param norm = 2.2350e-01, time/batch = 17.1375s	
17426/29850 (epoch 29.189), train_loss = 1.02648534, grad/param norm = 2.5421e-01, time/batch = 18.1220s	
17427/29850 (epoch 29.191), train_loss = 1.01575868, grad/param norm = 2.1707e-01, time/batch = 17.3578s	
17428/29850 (epoch 29.193), train_loss = 0.91270983, grad/param norm = 2.0857e-01, time/batch = 15.9784s	
17429/29850 (epoch 29.194), train_loss = 0.98899499, grad/param norm = 2.2368e-01, time/batch = 17.7823s	
17430/29850 (epoch 29.196), train_loss = 0.91059476, grad/param norm = 2.0711e-01, time/batch = 16.0135s	
17431/29850 (epoch 29.198), train_loss = 0.90294559, grad/param norm = 2.1770e-01, time/batch = 16.5535s	
17432/29850 (epoch 29.199), train_loss = 1.13383915, grad/param norm = 2.3476e-01, time/batch = 19.1969s	
17433/29850 (epoch 29.201), train_loss = 0.86719423, grad/param norm = 2.0444e-01, time/batch = 18.6763s	
17434/29850 (epoch 29.203), train_loss = 0.71188031, grad/param norm = 2.1532e-01, time/batch = 18.2987s	
17435/29850 (epoch 29.204), train_loss = 0.94125443, grad/param norm = 2.4543e-01, time/batch = 18.2066s	
17436/29850 (epoch 29.206), train_loss = 0.82441141, grad/param norm = 2.4106e-01, time/batch = 17.2120s	
17437/29850 (epoch 29.208), train_loss = 1.06080440, grad/param norm = 2.4580e-01, time/batch = 16.2029s	
17438/29850 (epoch 29.209), train_loss = 0.79601506, grad/param norm = 1.8084e-01, time/batch = 17.9647s	
17439/29850 (epoch 29.211), train_loss = 0.87933551, grad/param norm = 2.1930e-01, time/batch = 19.0387s	
17440/29850 (epoch 29.213), train_loss = 0.99636296, grad/param norm = 2.1642e-01, time/batch = 16.9472s	
17441/29850 (epoch 29.214), train_loss = 0.80533245, grad/param norm = 1.7420e-01, time/batch = 18.9460s	
17442/29850 (epoch 29.216), train_loss = 0.85891181, grad/param norm = 2.0455e-01, time/batch = 16.8087s	
17443/29850 (epoch 29.218), train_loss = 0.97903062, grad/param norm = 2.2173e-01, time/batch = 18.2929s	
17444/29850 (epoch 29.219), train_loss = 0.97771856, grad/param norm = 2.4614e-01, time/batch = 16.6951s	
17445/29850 (epoch 29.221), train_loss = 0.93352137, grad/param norm = 2.1971e-01, time/batch = 17.3898s	
17446/29850 (epoch 29.223), train_loss = 0.80638050, grad/param norm = 2.2138e-01, time/batch = 18.2982s	
17447/29850 (epoch 29.224), train_loss = 0.79288989, grad/param norm = 1.9637e-01, time/batch = 16.6107s	
17448/29850 (epoch 29.226), train_loss = 0.85335706, grad/param norm = 1.8680e-01, time/batch = 19.1023s	
17449/29850 (epoch 29.228), train_loss = 0.89634358, grad/param norm = 1.9950e-01, time/batch = 18.0528s	
17450/29850 (epoch 29.229), train_loss = 0.75725236, grad/param norm = 1.8168e-01, time/batch = 18.1029s	
17451/29850 (epoch 29.231), train_loss = 0.94217634, grad/param norm = 2.0931e-01, time/batch = 18.7750s	
17452/29850 (epoch 29.233), train_loss = 0.91266524, grad/param norm = 2.3689e-01, time/batch = 15.3707s	
17453/29850 (epoch 29.235), train_loss = 0.83043982, grad/param norm = 1.7959e-01, time/batch = 19.1203s	
17454/29850 (epoch 29.236), train_loss = 1.03626492, grad/param norm = 2.5191e-01, time/batch = 18.0167s	
17455/29850 (epoch 29.238), train_loss = 0.80387602, grad/param norm = 2.0725e-01, time/batch = 18.5360s	
17456/29850 (epoch 29.240), train_loss = 0.78553582, grad/param norm = 1.7871e-01, time/batch = 17.9664s	
17457/29850 (epoch 29.241), train_loss = 0.96693836, grad/param norm = 2.2898e-01, time/batch = 15.5180s	
17458/29850 (epoch 29.243), train_loss = 0.93954836, grad/param norm = 2.0400e-01, time/batch = 18.7891s	
17459/29850 (epoch 29.245), train_loss = 0.85734418, grad/param norm = 2.1525e-01, time/batch = 19.1232s	
17460/29850 (epoch 29.246), train_loss = 0.79358817, grad/param norm = 1.7362e-01, time/batch = 18.2865s	
17461/29850 (epoch 29.248), train_loss = 0.77673056, grad/param norm = 2.0465e-01, time/batch = 19.6213s	
17462/29850 (epoch 29.250), train_loss = 0.88757331, grad/param norm = 1.9584e-01, time/batch = 19.3725s	
17463/29850 (epoch 29.251), train_loss = 0.76983847, grad/param norm = 2.0648e-01, time/batch = 16.0282s	
17464/29850 (epoch 29.253), train_loss = 0.73812408, grad/param norm = 2.2791e-01, time/batch = 18.2218s	
17465/29850 (epoch 29.255), train_loss = 0.82798414, grad/param norm = 1.9456e-01, time/batch = 18.8873s	
17466/29850 (epoch 29.256), train_loss = 0.95220984, grad/param norm = 2.1123e-01, time/batch = 18.1245s	
17467/29850 (epoch 29.258), train_loss = 0.94143571, grad/param norm = 2.2853e-01, time/batch = 16.8755s	
17468/29850 (epoch 29.260), train_loss = 0.87879571, grad/param norm = 1.8487e-01, time/batch = 17.9581s	
17469/29850 (epoch 29.261), train_loss = 0.83303992, grad/param norm = 2.4480e-01, time/batch = 16.9529s	
17470/29850 (epoch 29.263), train_loss = 0.82707368, grad/param norm = 1.9834e-01, time/batch = 18.0446s	
17471/29850 (epoch 29.265), train_loss = 0.87421284, grad/param norm = 2.1755e-01, time/batch = 19.4605s	
17472/29850 (epoch 29.266), train_loss = 0.88692210, grad/param norm = 2.4399e-01, time/batch = 16.3883s	
17473/29850 (epoch 29.268), train_loss = 0.84987818, grad/param norm = 1.7526e-01, time/batch = 17.1093s	
17474/29850 (epoch 29.270), train_loss = 0.85132361, grad/param norm = 2.1752e-01, time/batch = 17.4381s	
17475/29850 (epoch 29.271), train_loss = 0.95382485, grad/param norm = 2.3914e-01, time/batch = 17.0489s	
17476/29850 (epoch 29.273), train_loss = 0.78695461, grad/param norm = 1.9628e-01, time/batch = 17.3039s	
17477/29850 (epoch 29.275), train_loss = 0.77243991, grad/param norm = 2.0106e-01, time/batch = 16.7123s	
17478/29850 (epoch 29.276), train_loss = 0.78753420, grad/param norm = 1.8786e-01, time/batch = 18.2859s	
17479/29850 (epoch 29.278), train_loss = 0.84763432, grad/param norm = 1.9494e-01, time/batch = 19.1132s	
17480/29850 (epoch 29.280), train_loss = 1.05476897, grad/param norm = 2.8939e-01, time/batch = 15.8715s	
17481/29850 (epoch 29.281), train_loss = 0.92450714, grad/param norm = 2.1701e-01, time/batch = 16.0376s	
17482/29850 (epoch 29.283), train_loss = 1.04919538, grad/param norm = 2.5375e-01, time/batch = 14.9875s	
17483/29850 (epoch 29.285), train_loss = 0.95911236, grad/param norm = 2.0348e-01, time/batch = 15.6190s	
17484/29850 (epoch 29.286), train_loss = 0.99769894, grad/param norm = 2.2360e-01, time/batch = 18.4559s	
17485/29850 (epoch 29.288), train_loss = 1.02020570, grad/param norm = 2.7446e-01, time/batch = 18.1101s	
17486/29850 (epoch 29.290), train_loss = 0.91421740, grad/param norm = 2.3112e-01, time/batch = 17.8783s	
17487/29850 (epoch 29.291), train_loss = 1.12874196, grad/param norm = 2.3958e-01, time/batch = 14.9771s	
17488/29850 (epoch 29.293), train_loss = 1.02329995, grad/param norm = 2.3843e-01, time/batch = 17.4374s	
17489/29850 (epoch 29.295), train_loss = 1.07396164, grad/param norm = 2.4827e-01, time/batch = 18.2109s	
17490/29850 (epoch 29.296), train_loss = 0.83206901, grad/param norm = 2.0025e-01, time/batch = 18.1388s	
17491/29850 (epoch 29.298), train_loss = 0.71631009, grad/param norm = 1.8273e-01, time/batch = 27.8883s	
17492/29850 (epoch 29.300), train_loss = 0.80384870, grad/param norm = 2.0179e-01, time/batch = 22.2499s	
17493/29850 (epoch 29.302), train_loss = 0.77032454, grad/param norm = 1.9389e-01, time/batch = 16.5341s	
17494/29850 (epoch 29.303), train_loss = 0.84112184, grad/param norm = 2.0844e-01, time/batch = 17.3033s	
17495/29850 (epoch 29.305), train_loss = 0.96672326, grad/param norm = 2.0514e-01, time/batch = 18.0402s	
17496/29850 (epoch 29.307), train_loss = 0.98919790, grad/param norm = 2.0914e-01, time/batch = 16.7637s	
17497/29850 (epoch 29.308), train_loss = 0.82078195, grad/param norm = 1.9416e-01, time/batch = 17.4317s	
17498/29850 (epoch 29.310), train_loss = 0.93375343, grad/param norm = 2.2084e-01, time/batch = 19.1377s	
17499/29850 (epoch 29.312), train_loss = 0.97890041, grad/param norm = 1.9433e-01, time/batch = 16.5231s	
17500/29850 (epoch 29.313), train_loss = 0.92970150, grad/param norm = 2.2998e-01, time/batch = 17.4564s	
17501/29850 (epoch 29.315), train_loss = 0.91403633, grad/param norm = 2.0907e-01, time/batch = 18.9711s	
17502/29850 (epoch 29.317), train_loss = 0.90411605, grad/param norm = 2.0640e-01, time/batch = 17.0478s	
17503/29850 (epoch 29.318), train_loss = 0.89253163, grad/param norm = 2.1437e-01, time/batch = 18.4639s	
17504/29850 (epoch 29.320), train_loss = 0.84595180, grad/param norm = 1.9934e-01, time/batch = 16.6015s	
17505/29850 (epoch 29.322), train_loss = 1.05492164, grad/param norm = 2.2337e-01, time/batch = 18.3949s	
17506/29850 (epoch 29.323), train_loss = 0.97166814, grad/param norm = 2.3767e-01, time/batch = 18.9677s	
17507/29850 (epoch 29.325), train_loss = 1.00071799, grad/param norm = 2.1390e-01, time/batch = 15.8759s	
17508/29850 (epoch 29.327), train_loss = 1.12909043, grad/param norm = 2.3359e-01, time/batch = 16.7201s	
17509/29850 (epoch 29.328), train_loss = 1.07204810, grad/param norm = 3.3215e-01, time/batch = 17.1409s	
17510/29850 (epoch 29.330), train_loss = 0.97338507, grad/param norm = 2.1067e-01, time/batch = 17.4520s	
17511/29850 (epoch 29.332), train_loss = 0.86147692, grad/param norm = 2.0433e-01, time/batch = 19.1169s	
17512/29850 (epoch 29.333), train_loss = 0.98118569, grad/param norm = 2.2255e-01, time/batch = 18.5234s	
17513/29850 (epoch 29.335), train_loss = 1.02757002, grad/param norm = 2.0898e-01, time/batch = 17.9688s	
17514/29850 (epoch 29.337), train_loss = 0.95011039, grad/param norm = 2.4489e-01, time/batch = 17.3274s	
17515/29850 (epoch 29.338), train_loss = 0.96052282, grad/param norm = 2.0520e-01, time/batch = 18.1274s	
17516/29850 (epoch 29.340), train_loss = 0.82400354, grad/param norm = 2.0917e-01, time/batch = 17.7881s	
17517/29850 (epoch 29.342), train_loss = 0.92371456, grad/param norm = 2.3399e-01, time/batch = 17.6934s	
17518/29850 (epoch 29.343), train_loss = 0.92901402, grad/param norm = 2.4770e-01, time/batch = 18.2238s	
17519/29850 (epoch 29.345), train_loss = 1.00540453, grad/param norm = 2.5426e-01, time/batch = 15.4601s	
17520/29850 (epoch 29.347), train_loss = 1.02824441, grad/param norm = 2.3038e-01, time/batch = 17.1382s	
17521/29850 (epoch 29.348), train_loss = 0.87621912, grad/param norm = 2.1435e-01, time/batch = 17.6157s	
17522/29850 (epoch 29.350), train_loss = 0.98607379, grad/param norm = 2.7328e-01, time/batch = 18.5224s	
17523/29850 (epoch 29.352), train_loss = 0.87131659, grad/param norm = 2.0571e-01, time/batch = 18.7193s	
17524/29850 (epoch 29.353), train_loss = 0.99496105, grad/param norm = 2.3006e-01, time/batch = 15.5637s	
17525/29850 (epoch 29.355), train_loss = 0.88329324, grad/param norm = 2.3339e-01, time/batch = 16.1840s	
17526/29850 (epoch 29.357), train_loss = 0.99968002, grad/param norm = 2.0896e-01, time/batch = 17.1456s	
17527/29850 (epoch 29.358), train_loss = 0.84509663, grad/param norm = 2.1595e-01, time/batch = 17.9490s	
17528/29850 (epoch 29.360), train_loss = 0.89605098, grad/param norm = 1.9494e-01, time/batch = 17.6248s	
17529/29850 (epoch 29.362), train_loss = 0.91863953, grad/param norm = 2.5287e-01, time/batch = 17.7980s	
17530/29850 (epoch 29.363), train_loss = 0.97510668, grad/param norm = 2.2595e-01, time/batch = 15.8655s	
17531/29850 (epoch 29.365), train_loss = 1.06221671, grad/param norm = 2.4496e-01, time/batch = 17.0209s	
17532/29850 (epoch 29.367), train_loss = 0.84616937, grad/param norm = 1.8172e-01, time/batch = 19.4609s	
17533/29850 (epoch 29.369), train_loss = 0.79703220, grad/param norm = 2.2272e-01, time/batch = 16.7996s	
17534/29850 (epoch 29.370), train_loss = 0.74126996, grad/param norm = 1.9671e-01, time/batch = 15.7574s	
17535/29850 (epoch 29.372), train_loss = 0.98825394, grad/param norm = 2.1385e-01, time/batch = 19.2971s	
17536/29850 (epoch 29.374), train_loss = 0.97047672, grad/param norm = 2.1765e-01, time/batch = 18.8763s	
17537/29850 (epoch 29.375), train_loss = 0.94327360, grad/param norm = 2.0452e-01, time/batch = 15.8095s	
17538/29850 (epoch 29.377), train_loss = 0.86047975, grad/param norm = 2.3092e-01, time/batch = 17.3003s	
17539/29850 (epoch 29.379), train_loss = 1.05451090, grad/param norm = 2.6035e-01, time/batch = 18.5099s	
17540/29850 (epoch 29.380), train_loss = 0.99632700, grad/param norm = 2.1643e-01, time/batch = 18.4430s	
17541/29850 (epoch 29.382), train_loss = 0.94350255, grad/param norm = 2.4292e-01, time/batch = 17.6160s	
17542/29850 (epoch 29.384), train_loss = 1.00922795, grad/param norm = 2.2578e-01, time/batch = 18.4509s	
17543/29850 (epoch 29.385), train_loss = 0.97443940, grad/param norm = 2.3088e-01, time/batch = 17.6431s	
17544/29850 (epoch 29.387), train_loss = 0.99143474, grad/param norm = 2.6774e-01, time/batch = 17.4373s	
17545/29850 (epoch 29.389), train_loss = 1.06170446, grad/param norm = 2.5698e-01, time/batch = 17.5385s	
17546/29850 (epoch 29.390), train_loss = 1.00193408, grad/param norm = 2.0348e-01, time/batch = 19.8842s	
17547/29850 (epoch 29.392), train_loss = 0.92450160, grad/param norm = 2.2016e-01, time/batch = 17.1308s	
17548/29850 (epoch 29.394), train_loss = 1.01284513, grad/param norm = 2.0333e-01, time/batch = 17.2041s	
17549/29850 (epoch 29.395), train_loss = 0.89785604, grad/param norm = 2.0811e-01, time/batch = 18.8780s	
17550/29850 (epoch 29.397), train_loss = 0.81479849, grad/param norm = 2.1824e-01, time/batch = 18.4599s	
17551/29850 (epoch 29.399), train_loss = 0.84463437, grad/param norm = 1.9514e-01, time/batch = 17.6293s	
17552/29850 (epoch 29.400), train_loss = 1.21331992, grad/param norm = 2.6276e-01, time/batch = 17.6475s	
17553/29850 (epoch 29.402), train_loss = 1.11191957, grad/param norm = 2.1950e-01, time/batch = 17.3064s	
17554/29850 (epoch 29.404), train_loss = 0.96474458, grad/param norm = 2.1452e-01, time/batch = 17.5430s	
17555/29850 (epoch 29.405), train_loss = 0.87736336, grad/param norm = 2.2042e-01, time/batch = 17.4730s	
17556/29850 (epoch 29.407), train_loss = 0.85305422, grad/param norm = 1.9606e-01, time/batch = 18.0477s	
17557/29850 (epoch 29.409), train_loss = 0.96052508, grad/param norm = 2.1333e-01, time/batch = 16.7856s	
17558/29850 (epoch 29.410), train_loss = 1.06730586, grad/param norm = 2.3666e-01, time/batch = 16.8694s	
17559/29850 (epoch 29.412), train_loss = 1.06010058, grad/param norm = 2.3237e-01, time/batch = 17.8780s	
17560/29850 (epoch 29.414), train_loss = 0.95350448, grad/param norm = 2.3808e-01, time/batch = 17.2033s	
17561/29850 (epoch 29.415), train_loss = 0.93802597, grad/param norm = 2.0748e-01, time/batch = 17.7918s	
17562/29850 (epoch 29.417), train_loss = 1.09465488, grad/param norm = 2.3042e-01, time/batch = 18.3592s	
17563/29850 (epoch 29.419), train_loss = 0.92474056, grad/param norm = 2.2047e-01, time/batch = 16.7256s	
17564/29850 (epoch 29.420), train_loss = 0.93562321, grad/param norm = 2.1426e-01, time/batch = 17.3794s	
17565/29850 (epoch 29.422), train_loss = 0.90887159, grad/param norm = 1.9908e-01, time/batch = 17.6946s	
17566/29850 (epoch 29.424), train_loss = 0.86334840, grad/param norm = 2.0659e-01, time/batch = 16.3541s	
17567/29850 (epoch 29.425), train_loss = 1.02684564, grad/param norm = 2.1957e-01, time/batch = 16.6913s	
17568/29850 (epoch 29.427), train_loss = 0.77133405, grad/param norm = 2.0376e-01, time/batch = 17.6208s	
17569/29850 (epoch 29.429), train_loss = 0.82343599, grad/param norm = 2.0048e-01, time/batch = 18.3856s	
17570/29850 (epoch 29.430), train_loss = 0.77512930, grad/param norm = 1.8579e-01, time/batch = 19.0419s	
17571/29850 (epoch 29.432), train_loss = 0.89065904, grad/param norm = 2.8794e-01, time/batch = 18.0295s	
17572/29850 (epoch 29.434), train_loss = 0.86144436, grad/param norm = 2.0323e-01, time/batch = 20.0376s	
17573/29850 (epoch 29.436), train_loss = 0.91419134, grad/param norm = 2.0698e-01, time/batch = 19.7028s	
17574/29850 (epoch 29.437), train_loss = 0.97763100, grad/param norm = 2.0216e-01, time/batch = 15.4265s	
17575/29850 (epoch 29.439), train_loss = 0.96791083, grad/param norm = 1.8832e-01, time/batch = 17.8674s	
17576/29850 (epoch 29.441), train_loss = 0.93556874, grad/param norm = 2.3641e-01, time/batch = 17.0619s	
17577/29850 (epoch 29.442), train_loss = 0.90364707, grad/param norm = 1.9383e-01, time/batch = 18.0413s	
17578/29850 (epoch 29.444), train_loss = 0.96580735, grad/param norm = 2.3414e-01, time/batch = 17.7221s	
17579/29850 (epoch 29.446), train_loss = 1.00514753, grad/param norm = 2.2765e-01, time/batch = 19.0454s	
17580/29850 (epoch 29.447), train_loss = 0.99570679, grad/param norm = 2.5648e-01, time/batch = 18.3920s	
17581/29850 (epoch 29.449), train_loss = 0.95887264, grad/param norm = 2.1997e-01, time/batch = 15.5392s	
17582/29850 (epoch 29.451), train_loss = 0.74831055, grad/param norm = 1.7359e-01, time/batch = 18.0347s	
17583/29850 (epoch 29.452), train_loss = 0.69031920, grad/param norm = 1.8996e-01, time/batch = 16.9010s	
17584/29850 (epoch 29.454), train_loss = 0.77117772, grad/param norm = 1.7524e-01, time/batch = 19.7987s	
17585/29850 (epoch 29.456), train_loss = 1.00303223, grad/param norm = 2.2978e-01, time/batch = 18.1969s	
17586/29850 (epoch 29.457), train_loss = 0.97362897, grad/param norm = 2.3433e-01, time/batch = 17.3747s	
17587/29850 (epoch 29.459), train_loss = 1.06560081, grad/param norm = 2.4109e-01, time/batch = 19.3796s	
17588/29850 (epoch 29.461), train_loss = 1.07125861, grad/param norm = 2.2505e-01, time/batch = 16.2849s	
17589/29850 (epoch 29.462), train_loss = 1.03925007, grad/param norm = 2.1093e-01, time/batch = 19.1970s	
17590/29850 (epoch 29.464), train_loss = 0.96874588, grad/param norm = 2.4220e-01, time/batch = 19.0381s	
17591/29850 (epoch 29.466), train_loss = 0.80930268, grad/param norm = 2.0160e-01, time/batch = 16.6209s	
17592/29850 (epoch 29.467), train_loss = 0.89384796, grad/param norm = 2.2018e-01, time/batch = 17.9551s	
17593/29850 (epoch 29.469), train_loss = 0.89894526, grad/param norm = 2.0748e-01, time/batch = 17.0252s	
17594/29850 (epoch 29.471), train_loss = 0.91290221, grad/param norm = 2.4721e-01, time/batch = 16.8166s	
17595/29850 (epoch 29.472), train_loss = 0.83618233, grad/param norm = 2.0537e-01, time/batch = 15.8524s	
17596/29850 (epoch 29.474), train_loss = 1.01880960, grad/param norm = 2.0400e-01, time/batch = 17.2121s	
17597/29850 (epoch 29.476), train_loss = 0.94831111, grad/param norm = 2.2379e-01, time/batch = 19.0349s	
17598/29850 (epoch 29.477), train_loss = 0.97510934, grad/param norm = 2.2619e-01, time/batch = 15.8838s	
17599/29850 (epoch 29.479), train_loss = 1.12511799, grad/param norm = 2.5203e-01, time/batch = 17.0004s	
17600/29850 (epoch 29.481), train_loss = 0.92309631, grad/param norm = 2.1662e-01, time/batch = 18.2881s	
17601/29850 (epoch 29.482), train_loss = 0.84327996, grad/param norm = 1.8215e-01, time/batch = 18.9314s	
17602/29850 (epoch 29.484), train_loss = 0.88986284, grad/param norm = 2.4006e-01, time/batch = 19.3640s	
17603/29850 (epoch 29.486), train_loss = 0.95676560, grad/param norm = 2.3137e-01, time/batch = 18.2955s	
17604/29850 (epoch 29.487), train_loss = 0.94927083, grad/param norm = 2.1102e-01, time/batch = 19.3890s	
17605/29850 (epoch 29.489), train_loss = 0.92999566, grad/param norm = 2.1142e-01, time/batch = 15.5528s	
17606/29850 (epoch 29.491), train_loss = 0.83447072, grad/param norm = 1.9862e-01, time/batch = 18.9609s	
17607/29850 (epoch 29.492), train_loss = 0.93572182, grad/param norm = 2.2837e-01, time/batch = 14.7970s	
17608/29850 (epoch 29.494), train_loss = 0.99488193, grad/param norm = 2.1389e-01, time/batch = 18.1009s	
17609/29850 (epoch 29.496), train_loss = 1.04834996, grad/param norm = 2.0645e-01, time/batch = 18.0300s	
17610/29850 (epoch 29.497), train_loss = 0.95985763, grad/param norm = 1.9167e-01, time/batch = 17.7214s	
17611/29850 (epoch 29.499), train_loss = 0.94662159, grad/param norm = 2.0263e-01, time/batch = 16.1105s	
17612/29850 (epoch 29.501), train_loss = 0.86365883, grad/param norm = 2.3112e-01, time/batch = 17.0027s	
17613/29850 (epoch 29.503), train_loss = 0.97098574, grad/param norm = 2.2604e-01, time/batch = 18.3827s	
17614/29850 (epoch 29.504), train_loss = 1.11951496, grad/param norm = 2.1821e-01, time/batch = 19.0458s	
17615/29850 (epoch 29.506), train_loss = 1.09488232, grad/param norm = 2.2290e-01, time/batch = 15.6083s	
17616/29850 (epoch 29.508), train_loss = 0.94089845, grad/param norm = 2.0483e-01, time/batch = 18.2863s	
17617/29850 (epoch 29.509), train_loss = 0.75204807, grad/param norm = 1.8481e-01, time/batch = 19.2784s	
17618/29850 (epoch 29.511), train_loss = 0.97102560, grad/param norm = 2.3937e-01, time/batch = 18.4588s	
17619/29850 (epoch 29.513), train_loss = 0.93981688, grad/param norm = 2.6610e-01, time/batch = 18.9542s	
17620/29850 (epoch 29.514), train_loss = 0.84366284, grad/param norm = 2.1017e-01, time/batch = 18.8724s	
17621/29850 (epoch 29.516), train_loss = 0.88890511, grad/param norm = 1.8303e-01, time/batch = 16.6145s	
17622/29850 (epoch 29.518), train_loss = 0.77945722, grad/param norm = 2.2142e-01, time/batch = 16.9387s	
17623/29850 (epoch 29.519), train_loss = 0.75834431, grad/param norm = 1.8970e-01, time/batch = 18.1207s	
17624/29850 (epoch 29.521), train_loss = 0.69559632, grad/param norm = 1.6350e-01, time/batch = 18.8769s	
17625/29850 (epoch 29.523), train_loss = 0.75929866, grad/param norm = 1.6430e-01, time/batch = 17.2087s	
17626/29850 (epoch 29.524), train_loss = 0.82910096, grad/param norm = 2.0713e-01, time/batch = 17.6336s	
17627/29850 (epoch 29.526), train_loss = 0.91932650, grad/param norm = 2.3205e-01, time/batch = 17.3128s	
17628/29850 (epoch 29.528), train_loss = 1.02296279, grad/param norm = 2.3876e-01, time/batch = 18.3679s	
17629/29850 (epoch 29.529), train_loss = 0.96262850, grad/param norm = 2.3539e-01, time/batch = 17.7823s	
17630/29850 (epoch 29.531), train_loss = 0.94715267, grad/param norm = 2.4680e-01, time/batch = 18.3790s	
17631/29850 (epoch 29.533), train_loss = 0.92090829, grad/param norm = 2.1916e-01, time/batch = 17.3805s	
17632/29850 (epoch 29.534), train_loss = 0.97567650, grad/param norm = 2.5499e-01, time/batch = 16.4521s	
17633/29850 (epoch 29.536), train_loss = 0.85989747, grad/param norm = 2.1027e-01, time/batch = 19.0577s	
17634/29850 (epoch 29.538), train_loss = 1.06980900, grad/param norm = 2.6117e-01, time/batch = 16.1271s	
17635/29850 (epoch 29.539), train_loss = 1.06609805, grad/param norm = 2.2728e-01, time/batch = 17.0403s	
17636/29850 (epoch 29.541), train_loss = 0.71169194, grad/param norm = 2.0670e-01, time/batch = 18.6197s	
17637/29850 (epoch 29.543), train_loss = 0.89555436, grad/param norm = 2.1053e-01, time/batch = 19.1091s	
17638/29850 (epoch 29.544), train_loss = 0.98161987, grad/param norm = 2.0856e-01, time/batch = 18.4317s	
17639/29850 (epoch 29.546), train_loss = 0.98808062, grad/param norm = 2.0560e-01, time/batch = 17.2888s	
17640/29850 (epoch 29.548), train_loss = 0.79978308, grad/param norm = 2.0644e-01, time/batch = 18.5301s	
17641/29850 (epoch 29.549), train_loss = 0.87366808, grad/param norm = 1.9472e-01, time/batch = 17.7185s	
17642/29850 (epoch 29.551), train_loss = 0.79096200, grad/param norm = 1.7612e-01, time/batch = 8.1213s	
17643/29850 (epoch 29.553), train_loss = 0.91170753, grad/param norm = 2.0420e-01, time/batch = 0.6891s	
17644/29850 (epoch 29.554), train_loss = 0.76284468, grad/param norm = 1.9222e-01, time/batch = 0.6819s	
17645/29850 (epoch 29.556), train_loss = 0.81706581, grad/param norm = 1.9129e-01, time/batch = 0.6618s	
17646/29850 (epoch 29.558), train_loss = 0.82091201, grad/param norm = 1.7959e-01, time/batch = 0.6649s	
17647/29850 (epoch 29.559), train_loss = 0.86513870, grad/param norm = 1.8421e-01, time/batch = 0.6855s	
17648/29850 (epoch 29.561), train_loss = 0.96789350, grad/param norm = 2.3565e-01, time/batch = 0.6790s	
17649/29850 (epoch 29.563), train_loss = 0.93845903, grad/param norm = 2.1553e-01, time/batch = 0.7170s	
17650/29850 (epoch 29.564), train_loss = 0.88045699, grad/param norm = 2.1668e-01, time/batch = 0.9708s	
17651/29850 (epoch 29.566), train_loss = 0.93484388, grad/param norm = 2.8735e-01, time/batch = 0.9885s	
17652/29850 (epoch 29.568), train_loss = 0.99511418, grad/param norm = 1.9895e-01, time/batch = 0.9748s	
17653/29850 (epoch 29.570), train_loss = 0.96556486, grad/param norm = 2.3999e-01, time/batch = 0.9975s	
17654/29850 (epoch 29.571), train_loss = 0.99877282, grad/param norm = 2.0684e-01, time/batch = 1.1018s	
17655/29850 (epoch 29.573), train_loss = 1.08145726, grad/param norm = 2.5903e-01, time/batch = 1.8734s	
17656/29850 (epoch 29.575), train_loss = 1.08968043, grad/param norm = 2.4776e-01, time/batch = 1.8294s	
17657/29850 (epoch 29.576), train_loss = 1.02296186, grad/param norm = 2.4095e-01, time/batch = 8.7775s	
17658/29850 (epoch 29.578), train_loss = 0.89586538, grad/param norm = 2.2686e-01, time/batch = 17.2980s	
17659/29850 (epoch 29.580), train_loss = 1.02188589, grad/param norm = 2.2173e-01, time/batch = 17.1175s	
17660/29850 (epoch 29.581), train_loss = 0.84632654, grad/param norm = 1.9583e-01, time/batch = 19.0408s	
17661/29850 (epoch 29.583), train_loss = 0.92301951, grad/param norm = 2.1789e-01, time/batch = 16.3645s	
17662/29850 (epoch 29.585), train_loss = 0.95078754, grad/param norm = 1.9386e-01, time/batch = 16.1299s	
17663/29850 (epoch 29.586), train_loss = 0.95984599, grad/param norm = 2.3101e-01, time/batch = 17.5209s	
17664/29850 (epoch 29.588), train_loss = 0.85393451, grad/param norm = 1.8814e-01, time/batch = 19.5504s	
17665/29850 (epoch 29.590), train_loss = 0.87679046, grad/param norm = 2.0442e-01, time/batch = 17.3812s	
17666/29850 (epoch 29.591), train_loss = 0.89901398, grad/param norm = 2.2064e-01, time/batch = 17.7097s	
17667/29850 (epoch 29.593), train_loss = 0.83280232, grad/param norm = 1.8835e-01, time/batch = 18.7994s	
17668/29850 (epoch 29.595), train_loss = 0.81169842, grad/param norm = 1.7212e-01, time/batch = 17.6431s	
17669/29850 (epoch 29.596), train_loss = 0.79942576, grad/param norm = 1.9563e-01, time/batch = 17.9549s	
17670/29850 (epoch 29.598), train_loss = 0.92180947, grad/param norm = 2.0661e-01, time/batch = 17.3882s	
17671/29850 (epoch 29.600), train_loss = 0.94457275, grad/param norm = 2.1851e-01, time/batch = 19.7097s	
17672/29850 (epoch 29.601), train_loss = 0.79740946, grad/param norm = 1.8080e-01, time/batch = 18.2998s	
17673/29850 (epoch 29.603), train_loss = 0.86173431, grad/param norm = 2.3644e-01, time/batch = 15.8733s	
17674/29850 (epoch 29.605), train_loss = 0.88712155, grad/param norm = 2.0250e-01, time/batch = 18.0591s	
17675/29850 (epoch 29.606), train_loss = 0.65867109, grad/param norm = 1.7715e-01, time/batch = 17.9780s	
17676/29850 (epoch 29.608), train_loss = 0.82504393, grad/param norm = 1.9745e-01, time/batch = 16.0565s	
17677/29850 (epoch 29.610), train_loss = 0.87474423, grad/param norm = 2.2468e-01, time/batch = 19.1167s	
17678/29850 (epoch 29.611), train_loss = 0.81465542, grad/param norm = 1.9972e-01, time/batch = 16.9407s	
17679/29850 (epoch 29.613), train_loss = 0.68188046, grad/param norm = 1.6643e-01, time/batch = 15.6223s	
17680/29850 (epoch 29.615), train_loss = 0.79564940, grad/param norm = 1.8159e-01, time/batch = 17.3745s	
17681/29850 (epoch 29.616), train_loss = 0.79509803, grad/param norm = 2.0447e-01, time/batch = 17.1914s	
17682/29850 (epoch 29.618), train_loss = 0.86600214, grad/param norm = 2.0241e-01, time/batch = 18.4586s	
17683/29850 (epoch 29.620), train_loss = 0.92616931, grad/param norm = 1.9341e-01, time/batch = 16.5301s	
17684/29850 (epoch 29.621), train_loss = 1.05482605, grad/param norm = 2.4831e-01, time/batch = 20.3515s	
17685/29850 (epoch 29.623), train_loss = 0.96845740, grad/param norm = 2.1721e-01, time/batch = 19.1999s	
17686/29850 (epoch 29.625), train_loss = 0.91163681, grad/param norm = 2.4082e-01, time/batch = 17.5512s	
17687/29850 (epoch 29.626), train_loss = 0.94763160, grad/param norm = 2.1439e-01, time/batch = 20.0162s	
17688/29850 (epoch 29.628), train_loss = 0.87820602, grad/param norm = 2.0675e-01, time/batch = 17.8104s	
17689/29850 (epoch 29.630), train_loss = 0.92661534, grad/param norm = 2.2681e-01, time/batch = 18.6064s	
17690/29850 (epoch 29.631), train_loss = 0.90478069, grad/param norm = 1.9651e-01, time/batch = 15.5987s	
17691/29850 (epoch 29.633), train_loss = 0.98689343, grad/param norm = 2.6037e-01, time/batch = 17.9636s	
17692/29850 (epoch 29.635), train_loss = 0.87324726, grad/param norm = 2.3175e-01, time/batch = 18.6269s	
17693/29850 (epoch 29.637), train_loss = 0.84228359, grad/param norm = 2.2899e-01, time/batch = 17.0532s	
17694/29850 (epoch 29.638), train_loss = 0.97118022, grad/param norm = 2.2242e-01, time/batch = 19.1992s	
17695/29850 (epoch 29.640), train_loss = 1.05368265, grad/param norm = 2.7537e-01, time/batch = 17.3849s	
17696/29850 (epoch 29.642), train_loss = 0.82757097, grad/param norm = 1.9059e-01, time/batch = 15.9584s	
17697/29850 (epoch 29.643), train_loss = 0.83843638, grad/param norm = 2.2924e-01, time/batch = 17.3699s	
17698/29850 (epoch 29.645), train_loss = 0.88632152, grad/param norm = 2.0278e-01, time/batch = 15.0542s	
17699/29850 (epoch 29.647), train_loss = 1.03488604, grad/param norm = 2.5571e-01, time/batch = 19.7845s	
17700/29850 (epoch 29.648), train_loss = 0.81653101, grad/param norm = 1.9227e-01, time/batch = 17.2856s	
17701/29850 (epoch 29.650), train_loss = 0.94202025, grad/param norm = 2.1758e-01, time/batch = 17.4744s	
17702/29850 (epoch 29.652), train_loss = 0.92267747, grad/param norm = 2.4858e-01, time/batch = 18.7866s	
17703/29850 (epoch 29.653), train_loss = 1.01627622, grad/param norm = 2.2157e-01, time/batch = 17.1315s	
17704/29850 (epoch 29.655), train_loss = 0.91400222, grad/param norm = 1.9217e-01, time/batch = 19.5060s	
17705/29850 (epoch 29.657), train_loss = 0.88442429, grad/param norm = 1.9682e-01, time/batch = 18.1727s	
17706/29850 (epoch 29.658), train_loss = 1.01180059, grad/param norm = 2.1106e-01, time/batch = 20.4101s	
17707/29850 (epoch 29.660), train_loss = 0.87848307, grad/param norm = 1.9644e-01, time/batch = 26.2200s	
17708/29850 (epoch 29.662), train_loss = 1.00093384, grad/param norm = 2.4632e-01, time/batch = 17.1298s	
17709/29850 (epoch 29.663), train_loss = 1.10729715, grad/param norm = 2.3536e-01, time/batch = 16.4619s	
17710/29850 (epoch 29.665), train_loss = 1.05566274, grad/param norm = 2.2648e-01, time/batch = 15.5723s	
17711/29850 (epoch 29.667), train_loss = 0.97531163, grad/param norm = 2.7353e-01, time/batch = 16.3859s	
17712/29850 (epoch 29.668), train_loss = 0.89539039, grad/param norm = 2.2872e-01, time/batch = 16.2894s	
17713/29850 (epoch 29.670), train_loss = 1.03060681, grad/param norm = 2.8284e-01, time/batch = 17.1690s	
17714/29850 (epoch 29.672), train_loss = 1.02721627, grad/param norm = 2.3871e-01, time/batch = 19.1890s	
17715/29850 (epoch 29.673), train_loss = 0.95573398, grad/param norm = 2.2731e-01, time/batch = 17.4714s	
17716/29850 (epoch 29.675), train_loss = 0.83344405, grad/param norm = 2.0601e-01, time/batch = 16.5373s	
17717/29850 (epoch 29.677), train_loss = 0.89433939, grad/param norm = 2.1861e-01, time/batch = 17.0329s	
17718/29850 (epoch 29.678), train_loss = 0.90964139, grad/param norm = 2.1023e-01, time/batch = 19.4578s	
17719/29850 (epoch 29.680), train_loss = 0.90578001, grad/param norm = 1.9601e-01, time/batch = 17.5434s	
17720/29850 (epoch 29.682), train_loss = 0.90430231, grad/param norm = 2.2188e-01, time/batch = 19.0262s	
17721/29850 (epoch 29.683), train_loss = 1.05873973, grad/param norm = 2.4133e-01, time/batch = 18.0365s	
17722/29850 (epoch 29.685), train_loss = 1.10398369, grad/param norm = 2.1176e-01, time/batch = 18.9662s	
17723/29850 (epoch 29.687), train_loss = 0.95470216, grad/param norm = 2.0872e-01, time/batch = 16.4491s	
17724/29850 (epoch 29.688), train_loss = 0.81293468, grad/param norm = 2.0604e-01, time/batch = 18.2990s	
17725/29850 (epoch 29.690), train_loss = 0.80997219, grad/param norm = 1.8854e-01, time/batch = 17.5470s	
17726/29850 (epoch 29.692), train_loss = 1.03116986, grad/param norm = 2.3737e-01, time/batch = 16.6983s	
17727/29850 (epoch 29.693), train_loss = 0.90790272, grad/param norm = 1.9092e-01, time/batch = 19.4388s	
17728/29850 (epoch 29.695), train_loss = 0.78714954, grad/param norm = 1.6158e-01, time/batch = 18.0431s	
17729/29850 (epoch 29.697), train_loss = 0.91254805, grad/param norm = 2.0167e-01, time/batch = 16.1286s	
17730/29850 (epoch 29.698), train_loss = 1.05283518, grad/param norm = 2.1104e-01, time/batch = 16.6759s	
17731/29850 (epoch 29.700), train_loss = 1.01196065, grad/param norm = 2.3289e-01, time/batch = 19.0556s	
17732/29850 (epoch 29.702), train_loss = 0.92232894, grad/param norm = 2.0350e-01, time/batch = 17.9630s	
17733/29850 (epoch 29.704), train_loss = 0.82568726, grad/param norm = 2.0980e-01, time/batch = 16.4404s	
17734/29850 (epoch 29.705), train_loss = 0.90977918, grad/param norm = 2.0124e-01, time/batch = 18.7187s	
17735/29850 (epoch 29.707), train_loss = 0.84876658, grad/param norm = 2.1381e-01, time/batch = 18.2730s	
17736/29850 (epoch 29.709), train_loss = 0.91730528, grad/param norm = 2.2702e-01, time/batch = 16.1182s	
17737/29850 (epoch 29.710), train_loss = 0.85066017, grad/param norm = 2.1107e-01, time/batch = 18.8593s	
17738/29850 (epoch 29.712), train_loss = 0.94690855, grad/param norm = 2.0015e-01, time/batch = 16.8835s	
17739/29850 (epoch 29.714), train_loss = 1.00007501, grad/param norm = 2.1825e-01, time/batch = 19.5467s	
17740/29850 (epoch 29.715), train_loss = 0.93146703, grad/param norm = 2.0733e-01, time/batch = 18.9301s	
17741/29850 (epoch 29.717), train_loss = 0.69871120, grad/param norm = 1.8324e-01, time/batch = 16.5381s	
17742/29850 (epoch 29.719), train_loss = 0.89013258, grad/param norm = 2.1430e-01, time/batch = 16.6220s	
17743/29850 (epoch 29.720), train_loss = 0.90624566, grad/param norm = 2.0075e-01, time/batch = 17.2244s	
17744/29850 (epoch 29.722), train_loss = 0.81587933, grad/param norm = 1.6125e-01, time/batch = 19.1068s	
17745/29850 (epoch 29.724), train_loss = 0.92218694, grad/param norm = 2.0045e-01, time/batch = 17.4600s	
17746/29850 (epoch 29.725), train_loss = 0.80939795, grad/param norm = 1.8408e-01, time/batch = 16.0371s	
17747/29850 (epoch 29.727), train_loss = 0.82754192, grad/param norm = 2.0805e-01, time/batch = 17.3082s	
17748/29850 (epoch 29.729), train_loss = 0.77134097, grad/param norm = 1.7205e-01, time/batch = 17.8823s	
17749/29850 (epoch 29.730), train_loss = 0.73222169, grad/param norm = 1.9245e-01, time/batch = 19.8787s	
17750/29850 (epoch 29.732), train_loss = 0.99226159, grad/param norm = 1.9462e-01, time/batch = 17.7008s	
17751/29850 (epoch 29.734), train_loss = 1.06574518, grad/param norm = 2.1882e-01, time/batch = 18.5437s	
17752/29850 (epoch 29.735), train_loss = 0.83819189, grad/param norm = 2.0599e-01, time/batch = 17.8744s	
17753/29850 (epoch 29.737), train_loss = 0.79784444, grad/param norm = 1.8191e-01, time/batch = 16.1311s	
17754/29850 (epoch 29.739), train_loss = 0.69464316, grad/param norm = 1.7975e-01, time/batch = 15.4412s	
17755/29850 (epoch 29.740), train_loss = 0.78819160, grad/param norm = 1.9107e-01, time/batch = 18.3003s	
17756/29850 (epoch 29.742), train_loss = 0.69055695, grad/param norm = 1.6607e-01, time/batch = 17.9811s	
17757/29850 (epoch 29.744), train_loss = 0.83113458, grad/param norm = 2.4625e-01, time/batch = 15.3651s	
17758/29850 (epoch 29.745), train_loss = 0.87060071, grad/param norm = 2.7223e-01, time/batch = 18.6323s	
17759/29850 (epoch 29.747), train_loss = 0.87472629, grad/param norm = 1.9553e-01, time/batch = 17.4596s	
17760/29850 (epoch 29.749), train_loss = 0.79100141, grad/param norm = 2.0889e-01, time/batch = 16.5383s	
17761/29850 (epoch 29.750), train_loss = 0.73984212, grad/param norm = 2.0306e-01, time/batch = 19.6165s	
17762/29850 (epoch 29.752), train_loss = 0.68572778, grad/param norm = 1.9989e-01, time/batch = 16.5233s	
17763/29850 (epoch 29.754), train_loss = 0.76151322, grad/param norm = 2.1149e-01, time/batch = 16.2211s	
17764/29850 (epoch 29.755), train_loss = 0.76811736, grad/param norm = 1.9917e-01, time/batch = 18.2125s	
17765/29850 (epoch 29.757), train_loss = 0.79036190, grad/param norm = 1.7195e-01, time/batch = 17.5521s	
17766/29850 (epoch 29.759), train_loss = 0.79480482, grad/param norm = 1.8052e-01, time/batch = 18.5695s	
17767/29850 (epoch 29.760), train_loss = 0.81292196, grad/param norm = 2.0336e-01, time/batch = 18.1192s	
17768/29850 (epoch 29.762), train_loss = 0.77246167, grad/param norm = 2.4518e-01, time/batch = 17.9737s	
17769/29850 (epoch 29.764), train_loss = 0.72479306, grad/param norm = 2.2418e-01, time/batch = 19.2769s	
17770/29850 (epoch 29.765), train_loss = 0.85654223, grad/param norm = 2.5121e-01, time/batch = 16.6169s	
17771/29850 (epoch 29.767), train_loss = 0.84243853, grad/param norm = 1.8596e-01, time/batch = 17.6341s	
17772/29850 (epoch 29.769), train_loss = 0.86949181, grad/param norm = 2.1919e-01, time/batch = 15.1092s	
17773/29850 (epoch 29.771), train_loss = 0.93335728, grad/param norm = 2.0627e-01, time/batch = 18.5572s	
17774/29850 (epoch 29.772), train_loss = 0.89885560, grad/param norm = 2.2827e-01, time/batch = 16.4634s	
17775/29850 (epoch 29.774), train_loss = 0.83043347, grad/param norm = 2.0477e-01, time/batch = 18.2194s	
17776/29850 (epoch 29.776), train_loss = 0.85582968, grad/param norm = 2.0692e-01, time/batch = 18.2194s	
17777/29850 (epoch 29.777), train_loss = 0.96626943, grad/param norm = 2.1607e-01, time/batch = 16.9487s	
17778/29850 (epoch 29.779), train_loss = 0.79202279, grad/param norm = 1.9146e-01, time/batch = 17.7166s	
17779/29850 (epoch 29.781), train_loss = 0.93171796, grad/param norm = 2.2455e-01, time/batch = 19.4344s	
17780/29850 (epoch 29.782), train_loss = 0.91949379, grad/param norm = 2.0637e-01, time/batch = 15.9665s	
17781/29850 (epoch 29.784), train_loss = 0.75191474, grad/param norm = 2.1312e-01, time/batch = 19.2048s	
17782/29850 (epoch 29.786), train_loss = 0.81633945, grad/param norm = 1.8902e-01, time/batch = 15.4017s	
17783/29850 (epoch 29.787), train_loss = 0.73454243, grad/param norm = 2.1931e-01, time/batch = 17.0377s	
17784/29850 (epoch 29.789), train_loss = 0.72080273, grad/param norm = 1.7974e-01, time/batch = 15.8698s	
17785/29850 (epoch 29.791), train_loss = 0.82519063, grad/param norm = 2.2300e-01, time/batch = 17.0435s	
17786/29850 (epoch 29.792), train_loss = 0.93900975, grad/param norm = 2.4107e-01, time/batch = 18.6965s	
17787/29850 (epoch 29.794), train_loss = 0.91542700, grad/param norm = 2.0244e-01, time/batch = 16.0227s	
17788/29850 (epoch 29.796), train_loss = 0.76674959, grad/param norm = 1.7673e-01, time/batch = 17.4390s	
17789/29850 (epoch 29.797), train_loss = 0.70114331, grad/param norm = 1.7598e-01, time/batch = 16.9430s	
17790/29850 (epoch 29.799), train_loss = 0.73416375, grad/param norm = 1.8078e-01, time/batch = 18.6320s	
17791/29850 (epoch 29.801), train_loss = 0.77628861, grad/param norm = 1.7924e-01, time/batch = 18.3455s	
17792/29850 (epoch 29.802), train_loss = 0.70343747, grad/param norm = 1.8927e-01, time/batch = 16.8671s	
17793/29850 (epoch 29.804), train_loss = 0.74967281, grad/param norm = 1.7440e-01, time/batch = 17.7718s	
17794/29850 (epoch 29.806), train_loss = 0.73508448, grad/param norm = 1.9659e-01, time/batch = 16.5512s	
17795/29850 (epoch 29.807), train_loss = 0.73254485, grad/param norm = 1.9115e-01, time/batch = 18.7010s	
17796/29850 (epoch 29.809), train_loss = 0.74688222, grad/param norm = 1.9315e-01, time/batch = 16.8647s	
17797/29850 (epoch 29.811), train_loss = 0.89788552, grad/param norm = 2.1600e-01, time/batch = 16.4543s	
17798/29850 (epoch 29.812), train_loss = 0.89767933, grad/param norm = 2.1023e-01, time/batch = 18.0436s	
17799/29850 (epoch 29.814), train_loss = 0.97495717, grad/param norm = 2.7965e-01, time/batch = 19.1255s	
17800/29850 (epoch 29.816), train_loss = 0.95735162, grad/param norm = 1.9953e-01, time/batch = 18.5256s	
17801/29850 (epoch 29.817), train_loss = 0.90187566, grad/param norm = 2.3863e-01, time/batch = 16.2916s	
17802/29850 (epoch 29.819), train_loss = 0.73430691, grad/param norm = 2.0424e-01, time/batch = 19.8006s	
17803/29850 (epoch 29.821), train_loss = 0.95215774, grad/param norm = 2.5032e-01, time/batch = 18.2178s	
17804/29850 (epoch 29.822), train_loss = 0.97751921, grad/param norm = 2.3738e-01, time/batch = 17.0619s	
17805/29850 (epoch 29.824), train_loss = 0.87578660, grad/param norm = 2.2746e-01, time/batch = 16.8446s	
17806/29850 (epoch 29.826), train_loss = 0.78252351, grad/param norm = 1.9714e-01, time/batch = 18.5267s	
17807/29850 (epoch 29.827), train_loss = 0.71325620, grad/param norm = 2.1112e-01, time/batch = 14.8489s	
17808/29850 (epoch 29.829), train_loss = 0.87535355, grad/param norm = 2.3564e-01, time/batch = 16.1900s	
17809/29850 (epoch 29.831), train_loss = 0.97031859, grad/param norm = 2.2683e-01, time/batch = 15.0343s	
17810/29850 (epoch 29.832), train_loss = 0.90164057, grad/param norm = 1.9904e-01, time/batch = 15.2819s	
17811/29850 (epoch 29.834), train_loss = 0.66839834, grad/param norm = 1.7298e-01, time/batch = 17.0470s	
17812/29850 (epoch 29.836), train_loss = 0.71680447, grad/param norm = 1.7834e-01, time/batch = 16.6425s	
17813/29850 (epoch 29.838), train_loss = 0.83221823, grad/param norm = 2.1137e-01, time/batch = 16.6423s	
17814/29850 (epoch 29.839), train_loss = 0.74240587, grad/param norm = 2.1142e-01, time/batch = 17.7922s	
17815/29850 (epoch 29.841), train_loss = 0.76589480, grad/param norm = 1.8481e-01, time/batch = 16.3658s	
17816/29850 (epoch 29.843), train_loss = 0.71761747, grad/param norm = 2.0143e-01, time/batch = 19.1357s	
17817/29850 (epoch 29.844), train_loss = 0.76184975, grad/param norm = 1.8610e-01, time/batch = 17.1268s	
17818/29850 (epoch 29.846), train_loss = 0.86718650, grad/param norm = 1.9953e-01, time/batch = 17.6195s	
17819/29850 (epoch 29.848), train_loss = 0.92312761, grad/param norm = 2.2685e-01, time/batch = 14.5673s	
17820/29850 (epoch 29.849), train_loss = 0.80914504, grad/param norm = 1.9375e-01, time/batch = 17.4343s	
17821/29850 (epoch 29.851), train_loss = 0.99792450, grad/param norm = 2.2790e-01, time/batch = 18.7940s	
17822/29850 (epoch 29.853), train_loss = 0.84534587, grad/param norm = 2.9219e-01, time/batch = 16.2001s	
17823/29850 (epoch 29.854), train_loss = 1.01402011, grad/param norm = 2.2582e-01, time/batch = 19.2904s	
17824/29850 (epoch 29.856), train_loss = 0.97074847, grad/param norm = 2.5396e-01, time/batch = 18.3156s	
17825/29850 (epoch 29.858), train_loss = 0.88444923, grad/param norm = 2.2438e-01, time/batch = 17.2036s	
17826/29850 (epoch 29.859), train_loss = 0.77523496, grad/param norm = 2.2670e-01, time/batch = 15.3005s	
17827/29850 (epoch 29.861), train_loss = 0.98910761, grad/param norm = 2.3161e-01, time/batch = 17.2038s	
17828/29850 (epoch 29.863), train_loss = 1.02757607, grad/param norm = 2.5690e-01, time/batch = 18.3081s	
17829/29850 (epoch 29.864), train_loss = 0.98663367, grad/param norm = 2.4415e-01, time/batch = 15.5147s	
17830/29850 (epoch 29.866), train_loss = 0.90827832, grad/param norm = 2.6047e-01, time/batch = 15.3351s	
17831/29850 (epoch 29.868), train_loss = 1.07088328, grad/param norm = 2.3722e-01, time/batch = 16.2274s	
17832/29850 (epoch 29.869), train_loss = 0.94610873, grad/param norm = 2.5191e-01, time/batch = 15.5471s	
17833/29850 (epoch 29.871), train_loss = 0.95771521, grad/param norm = 2.1799e-01, time/batch = 17.7117s	
17834/29850 (epoch 29.873), train_loss = 0.90590616, grad/param norm = 2.2530e-01, time/batch = 18.3860s	
17835/29850 (epoch 29.874), train_loss = 0.91843165, grad/param norm = 2.1698e-01, time/batch = 15.2837s	
17836/29850 (epoch 29.876), train_loss = 0.88481733, grad/param norm = 3.3959e-01, time/batch = 16.3575s	
17837/29850 (epoch 29.878), train_loss = 0.89569810, grad/param norm = 1.9232e-01, time/batch = 17.2120s	
17838/29850 (epoch 29.879), train_loss = 0.90201596, grad/param norm = 2.0577e-01, time/batch = 17.3041s	
17839/29850 (epoch 29.881), train_loss = 0.99901213, grad/param norm = 2.2346e-01, time/batch = 16.2725s	
17840/29850 (epoch 29.883), train_loss = 0.96087659, grad/param norm = 2.2027e-01, time/batch = 17.3733s	
17841/29850 (epoch 29.884), train_loss = 0.79500366, grad/param norm = 1.9074e-01, time/batch = 19.1064s	
17842/29850 (epoch 29.886), train_loss = 0.99018612, grad/param norm = 2.2629e-01, time/batch = 18.8671s	
17843/29850 (epoch 29.888), train_loss = 0.87910473, grad/param norm = 2.2283e-01, time/batch = 15.3484s	
17844/29850 (epoch 29.889), train_loss = 0.81896762, grad/param norm = 1.9688e-01, time/batch = 18.7098s	
17845/29850 (epoch 29.891), train_loss = 0.79671025, grad/param norm = 1.8604e-01, time/batch = 16.9795s	
17846/29850 (epoch 29.893), train_loss = 0.86263253, grad/param norm = 2.0810e-01, time/batch = 17.0489s	
17847/29850 (epoch 29.894), train_loss = 0.85955424, grad/param norm = 2.3490e-01, time/batch = 16.4439s	
17848/29850 (epoch 29.896), train_loss = 0.88881505, grad/param norm = 2.2244e-01, time/batch = 18.7155s	
17849/29850 (epoch 29.898), train_loss = 1.03269683, grad/param norm = 2.3915e-01, time/batch = 17.2840s	
17850/29850 (epoch 29.899), train_loss = 0.80164699, grad/param norm = 2.1189e-01, time/batch = 18.1090s	
17851/29850 (epoch 29.901), train_loss = 1.13448065, grad/param norm = 3.2404e-01, time/batch = 18.5538s	
17852/29850 (epoch 29.903), train_loss = 0.94527362, grad/param norm = 3.0762e-01, time/batch = 17.9691s	
17853/29850 (epoch 29.905), train_loss = 1.14864830, grad/param norm = 2.4578e-01, time/batch = 15.7913s	
17854/29850 (epoch 29.906), train_loss = 0.94069371, grad/param norm = 2.2675e-01, time/batch = 19.0485s	
17855/29850 (epoch 29.908), train_loss = 1.03165026, grad/param norm = 2.1587e-01, time/batch = 19.5396s	
17856/29850 (epoch 29.910), train_loss = 0.98182004, grad/param norm = 2.1777e-01, time/batch = 17.6208s	
17857/29850 (epoch 29.911), train_loss = 1.11291410, grad/param norm = 2.1184e-01, time/batch = 15.5221s	
17858/29850 (epoch 29.913), train_loss = 1.04994715, grad/param norm = 2.3237e-01, time/batch = 18.1323s	
17859/29850 (epoch 29.915), train_loss = 1.02965023, grad/param norm = 2.1911e-01, time/batch = 18.6454s	
17860/29850 (epoch 29.916), train_loss = 0.97873221, grad/param norm = 2.1574e-01, time/batch = 16.3666s	
17861/29850 (epoch 29.918), train_loss = 0.84263227, grad/param norm = 1.8657e-01, time/batch = 17.7841s	
17862/29850 (epoch 29.920), train_loss = 1.00504201, grad/param norm = 2.0317e-01, time/batch = 18.1246s	
17863/29850 (epoch 29.921), train_loss = 0.90116617, grad/param norm = 2.1842e-01, time/batch = 17.5491s	
17864/29850 (epoch 29.923), train_loss = 0.95930127, grad/param norm = 2.2717e-01, time/batch = 16.7292s	
17865/29850 (epoch 29.925), train_loss = 1.05467658, grad/param norm = 2.3031e-01, time/batch = 16.2581s	
17866/29850 (epoch 29.926), train_loss = 1.06070637, grad/param norm = 2.6082e-01, time/batch = 16.2021s	
17867/29850 (epoch 29.928), train_loss = 0.92966556, grad/param norm = 2.1445e-01, time/batch = 15.7936s	
17868/29850 (epoch 29.930), train_loss = 0.97254368, grad/param norm = 2.3140e-01, time/batch = 18.8830s	
17869/29850 (epoch 29.931), train_loss = 0.91003963, grad/param norm = 2.1890e-01, time/batch = 18.2150s	
17870/29850 (epoch 29.933), train_loss = 1.07889067, grad/param norm = 2.4648e-01, time/batch = 17.3808s	
17871/29850 (epoch 29.935), train_loss = 0.99478747, grad/param norm = 2.2323e-01, time/batch = 19.0445s	
17872/29850 (epoch 29.936), train_loss = 0.94145090, grad/param norm = 2.2364e-01, time/batch = 16.4473s	
17873/29850 (epoch 29.938), train_loss = 0.81751712, grad/param norm = 2.1212e-01, time/batch = 17.3653s	
17874/29850 (epoch 29.940), train_loss = 0.81003690, grad/param norm = 1.9439e-01, time/batch = 17.7064s	
17875/29850 (epoch 29.941), train_loss = 0.84460949, grad/param norm = 2.2974e-01, time/batch = 17.3907s	
17876/29850 (epoch 29.943), train_loss = 0.83623007, grad/param norm = 1.8519e-01, time/batch = 18.2085s	
17877/29850 (epoch 29.945), train_loss = 0.83129308, grad/param norm = 2.2218e-01, time/batch = 16.4578s	
17878/29850 (epoch 29.946), train_loss = 0.80819083, grad/param norm = 2.2343e-01, time/batch = 16.8925s	
17879/29850 (epoch 29.948), train_loss = 0.91937705, grad/param norm = 1.9117e-01, time/batch = 18.7844s	
17880/29850 (epoch 29.950), train_loss = 0.86512057, grad/param norm = 1.8427e-01, time/batch = 16.6155s	
17881/29850 (epoch 29.951), train_loss = 0.75452761, grad/param norm = 1.7735e-01, time/batch = 16.5419s	
17882/29850 (epoch 29.953), train_loss = 0.86857630, grad/param norm = 2.3444e-01, time/batch = 18.3744s	
17883/29850 (epoch 29.955), train_loss = 0.78817802, grad/param norm = 1.8312e-01, time/batch = 15.5539s	
17884/29850 (epoch 29.956), train_loss = 0.79591726, grad/param norm = 1.8997e-01, time/batch = 17.5292s	
17885/29850 (epoch 29.958), train_loss = 0.67613422, grad/param norm = 1.7899e-01, time/batch = 18.8719s	
17886/29850 (epoch 29.960), train_loss = 0.99487266, grad/param norm = 2.4138e-01, time/batch = 17.8123s	
17887/29850 (epoch 29.961), train_loss = 0.79005527, grad/param norm = 2.0374e-01, time/batch = 17.0167s	
17888/29850 (epoch 29.963), train_loss = 0.74737484, grad/param norm = 1.9497e-01, time/batch = 19.5285s	
17889/29850 (epoch 29.965), train_loss = 0.83144433, grad/param norm = 2.2897e-01, time/batch = 19.3743s	
17890/29850 (epoch 29.966), train_loss = 0.77170572, grad/param norm = 2.0527e-01, time/batch = 17.1881s	
17891/29850 (epoch 29.968), train_loss = 0.81090543, grad/param norm = 2.3168e-01, time/batch = 18.5115s	
17892/29850 (epoch 29.970), train_loss = 0.79953198, grad/param norm = 2.1888e-01, time/batch = 20.3496s	
17893/29850 (epoch 29.972), train_loss = 0.80442817, grad/param norm = 1.7898e-01, time/batch = 18.0586s	
17894/29850 (epoch 29.973), train_loss = 0.79597675, grad/param norm = 1.9799e-01, time/batch = 16.5378s	
17895/29850 (epoch 29.975), train_loss = 0.69140047, grad/param norm = 1.9322e-01, time/batch = 17.3611s	
17896/29850 (epoch 29.977), train_loss = 0.83109250, grad/param norm = 1.9890e-01, time/batch = 17.3722s	
17897/29850 (epoch 29.978), train_loss = 0.72850044, grad/param norm = 1.7087e-01, time/batch = 16.5165s	
17898/29850 (epoch 29.980), train_loss = 0.81581089, grad/param norm = 1.8561e-01, time/batch = 18.3717s	
17899/29850 (epoch 29.982), train_loss = 0.77743187, grad/param norm = 1.8529e-01, time/batch = 17.6532s	
17900/29850 (epoch 29.983), train_loss = 0.81791602, grad/param norm = 1.8242e-01, time/batch = 15.8814s	
17901/29850 (epoch 29.985), train_loss = 0.92218670, grad/param norm = 2.2866e-01, time/batch = 18.8560s	
17902/29850 (epoch 29.987), train_loss = 0.89396475, grad/param norm = 2.1570e-01, time/batch = 15.7843s	
17903/29850 (epoch 29.988), train_loss = 0.81094228, grad/param norm = 1.7446e-01, time/batch = 18.4680s	
17904/29850 (epoch 29.990), train_loss = 0.87746086, grad/param norm = 1.8085e-01, time/batch = 16.7075s	
17905/29850 (epoch 29.992), train_loss = 0.91089690, grad/param norm = 1.8937e-01, time/batch = 17.2865s	
17906/29850 (epoch 29.993), train_loss = 0.89888828, grad/param norm = 2.1477e-01, time/batch = 20.2089s	
17907/29850 (epoch 29.995), train_loss = 0.90079309, grad/param norm = 2.1279e-01, time/batch = 18.5313s	
17908/29850 (epoch 29.997), train_loss = 0.91721577, grad/param norm = 2.1343e-01, time/batch = 19.7890s	
17909/29850 (epoch 29.998), train_loss = 0.93843009, grad/param norm = 2.2631e-01, time/batch = 17.7882s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
17910/29850 (epoch 30.000), train_loss = 0.78274346, grad/param norm = 1.9005e-01, time/batch = 19.3364s	
17911/29850 (epoch 30.002), train_loss = 1.03857594, grad/param norm = 2.1925e-01, time/batch = 30.6164s	
17912/29850 (epoch 30.003), train_loss = 0.79483086, grad/param norm = 2.1926e-01, time/batch = 16.2846s	
17913/29850 (epoch 30.005), train_loss = 0.90810932, grad/param norm = 2.0441e-01, time/batch = 17.1198s	
17914/29850 (epoch 30.007), train_loss = 0.96728821, grad/param norm = 2.3021e-01, time/batch = 18.2799s	
17915/29850 (epoch 30.008), train_loss = 1.11679514, grad/param norm = 2.4543e-01, time/batch = 17.7041s	
17916/29850 (epoch 30.010), train_loss = 0.83056201, grad/param norm = 2.2230e-01, time/batch = 16.2934s	
17917/29850 (epoch 30.012), train_loss = 0.86062937, grad/param norm = 1.9650e-01, time/batch = 17.7127s	
17918/29850 (epoch 30.013), train_loss = 0.93308435, grad/param norm = 2.2526e-01, time/batch = 18.4669s	
17919/29850 (epoch 30.015), train_loss = 0.94298196, grad/param norm = 1.8892e-01, time/batch = 18.5461s	
17920/29850 (epoch 30.017), train_loss = 0.92681034, grad/param norm = 2.2855e-01, time/batch = 17.1855s	
17921/29850 (epoch 30.018), train_loss = 1.04742631, grad/param norm = 2.7271e-01, time/batch = 18.7015s	
17922/29850 (epoch 30.020), train_loss = 0.88256221, grad/param norm = 2.2379e-01, time/batch = 17.4373s	
17923/29850 (epoch 30.022), train_loss = 0.97929004, grad/param norm = 2.1900e-01, time/batch = 16.4499s	
17924/29850 (epoch 30.023), train_loss = 0.96440234, grad/param norm = 1.8629e-01, time/batch = 18.1282s	
17925/29850 (epoch 30.025), train_loss = 0.87372840, grad/param norm = 1.9575e-01, time/batch = 19.4507s	
17926/29850 (epoch 30.027), train_loss = 0.69917223, grad/param norm = 2.1479e-01, time/batch = 17.2068s	
17927/29850 (epoch 30.028), train_loss = 0.84005858, grad/param norm = 1.8684e-01, time/batch = 16.1913s	
17928/29850 (epoch 30.030), train_loss = 0.88051273, grad/param norm = 2.3741e-01, time/batch = 18.3880s	
17929/29850 (epoch 30.032), train_loss = 0.94532305, grad/param norm = 1.9931e-01, time/batch = 18.6271s	
17930/29850 (epoch 30.034), train_loss = 0.80576664, grad/param norm = 1.9120e-01, time/batch = 16.3725s	
17931/29850 (epoch 30.035), train_loss = 0.73518324, grad/param norm = 1.8940e-01, time/batch = 18.9666s	
17932/29850 (epoch 30.037), train_loss = 0.88938845, grad/param norm = 2.1023e-01, time/batch = 18.8765s	
17933/29850 (epoch 30.039), train_loss = 0.77946452, grad/param norm = 1.8665e-01, time/batch = 15.5292s	
17934/29850 (epoch 30.040), train_loss = 0.80087547, grad/param norm = 1.8553e-01, time/batch = 18.2713s	
17935/29850 (epoch 30.042), train_loss = 0.80042389, grad/param norm = 1.9003e-01, time/batch = 18.4711s	
17936/29850 (epoch 30.044), train_loss = 0.85782132, grad/param norm = 1.8868e-01, time/batch = 16.3898s	
17937/29850 (epoch 30.045), train_loss = 0.95481950, grad/param norm = 2.1147e-01, time/batch = 17.6666s	
17938/29850 (epoch 30.047), train_loss = 0.77754342, grad/param norm = 1.8937e-01, time/batch = 19.1191s	
17939/29850 (epoch 30.049), train_loss = 0.92473811, grad/param norm = 2.0406e-01, time/batch = 15.1535s	
17940/29850 (epoch 30.050), train_loss = 0.79782607, grad/param norm = 2.2561e-01, time/batch = 15.2603s	
17941/29850 (epoch 30.052), train_loss = 0.98880716, grad/param norm = 2.3562e-01, time/batch = 15.4539s	
17942/29850 (epoch 30.054), train_loss = 0.89017656, grad/param norm = 1.8801e-01, time/batch = 19.7943s	
17943/29850 (epoch 30.055), train_loss = 0.85311237, grad/param norm = 2.0488e-01, time/batch = 16.6070s	
17944/29850 (epoch 30.057), train_loss = 0.92718215, grad/param norm = 1.9696e-01, time/batch = 16.2756s	
17945/29850 (epoch 30.059), train_loss = 0.93885204, grad/param norm = 2.0176e-01, time/batch = 18.3946s	
17946/29850 (epoch 30.060), train_loss = 0.89481272, grad/param norm = 2.1017e-01, time/batch = 18.4589s	
17947/29850 (epoch 30.062), train_loss = 1.00421322, grad/param norm = 2.4967e-01, time/batch = 17.2053s	
17948/29850 (epoch 30.064), train_loss = 0.95108810, grad/param norm = 2.0384e-01, time/batch = 17.5218s	
17949/29850 (epoch 30.065), train_loss = 0.78249096, grad/param norm = 1.9119e-01, time/batch = 18.2867s	
17950/29850 (epoch 30.067), train_loss = 0.93619975, grad/param norm = 2.0216e-01, time/batch = 16.0079s	
17951/29850 (epoch 30.069), train_loss = 0.93845639, grad/param norm = 1.9893e-01, time/batch = 16.6248s	
17952/29850 (epoch 30.070), train_loss = 0.94466016, grad/param norm = 2.0609e-01, time/batch = 17.7749s	
17953/29850 (epoch 30.072), train_loss = 0.90360436, grad/param norm = 2.0946e-01, time/batch = 18.9559s	
17954/29850 (epoch 30.074), train_loss = 0.97874463, grad/param norm = 2.0169e-01, time/batch = 16.2703s	
17955/29850 (epoch 30.075), train_loss = 0.82634351, grad/param norm = 2.3311e-01, time/batch = 19.2066s	
17956/29850 (epoch 30.077), train_loss = 0.95049892, grad/param norm = 2.2091e-01, time/batch = 18.2340s	
17957/29850 (epoch 30.079), train_loss = 1.13915785, grad/param norm = 3.3496e-01, time/batch = 16.2171s	
17958/29850 (epoch 30.080), train_loss = 1.10384680, grad/param norm = 2.5785e-01, time/batch = 19.1151s	
17959/29850 (epoch 30.082), train_loss = 0.95018735, grad/param norm = 2.1022e-01, time/batch = 17.4604s	
17960/29850 (epoch 30.084), train_loss = 1.08760060, grad/param norm = 2.3386e-01, time/batch = 18.4500s	
17961/29850 (epoch 30.085), train_loss = 1.09343050, grad/param norm = 2.6270e-01, time/batch = 19.4475s	
17962/29850 (epoch 30.087), train_loss = 1.05875840, grad/param norm = 2.4687e-01, time/batch = 17.2076s	
17963/29850 (epoch 30.089), train_loss = 0.93702112, grad/param norm = 2.1278e-01, time/batch = 16.9034s	
17964/29850 (epoch 30.090), train_loss = 0.98127757, grad/param norm = 2.2403e-01, time/batch = 18.0426s	
17965/29850 (epoch 30.092), train_loss = 0.84627591, grad/param norm = 1.7770e-01, time/batch = 17.7689s	
17966/29850 (epoch 30.094), train_loss = 1.05725621, grad/param norm = 2.1770e-01, time/batch = 18.4610s	
17967/29850 (epoch 30.095), train_loss = 0.97372215, grad/param norm = 2.7997e-01, time/batch = 15.6631s	
17968/29850 (epoch 30.097), train_loss = 0.72830943, grad/param norm = 1.5950e-01, time/batch = 15.9272s	
17969/29850 (epoch 30.099), train_loss = 0.76287957, grad/param norm = 1.8449e-01, time/batch = 15.4867s	
17970/29850 (epoch 30.101), train_loss = 1.00118873, grad/param norm = 2.3057e-01, time/batch = 18.1414s	
17971/29850 (epoch 30.102), train_loss = 0.96763327, grad/param norm = 2.4175e-01, time/batch = 17.1230s	
17972/29850 (epoch 30.104), train_loss = 0.89653945, grad/param norm = 2.2454e-01, time/batch = 19.6976s	
17973/29850 (epoch 30.106), train_loss = 1.00391202, grad/param norm = 2.2474e-01, time/batch = 17.7963s	
17974/29850 (epoch 30.107), train_loss = 0.85351635, grad/param norm = 2.1139e-01, time/batch = 16.5468s	
17975/29850 (epoch 30.109), train_loss = 0.92566197, grad/param norm = 2.1438e-01, time/batch = 16.3854s	
17976/29850 (epoch 30.111), train_loss = 0.96957543, grad/param norm = 1.9128e-01, time/batch = 17.0648s	
17977/29850 (epoch 30.112), train_loss = 0.83224534, grad/param norm = 1.8222e-01, time/batch = 17.1888s	
17978/29850 (epoch 30.114), train_loss = 0.85977024, grad/param norm = 2.2493e-01, time/batch = 16.9184s	
17979/29850 (epoch 30.116), train_loss = 0.82046775, grad/param norm = 1.8292e-01, time/batch = 16.5413s	
17980/29850 (epoch 30.117), train_loss = 0.89580911, grad/param norm = 2.3030e-01, time/batch = 17.0685s	
17981/29850 (epoch 30.119), train_loss = 0.88141884, grad/param norm = 2.0087e-01, time/batch = 16.9614s	
17982/29850 (epoch 30.121), train_loss = 0.71549487, grad/param norm = 1.7837e-01, time/batch = 17.7926s	
17983/29850 (epoch 30.122), train_loss = 0.76236745, grad/param norm = 1.5750e-01, time/batch = 16.4235s	
17984/29850 (epoch 30.124), train_loss = 0.82935849, grad/param norm = 1.9311e-01, time/batch = 15.1689s	
17985/29850 (epoch 30.126), train_loss = 0.82951590, grad/param norm = 1.8847e-01, time/batch = 17.2604s	
17986/29850 (epoch 30.127), train_loss = 0.97569523, grad/param norm = 2.5127e-01, time/batch = 18.8028s	
17987/29850 (epoch 30.129), train_loss = 0.85116108, grad/param norm = 1.8966e-01, time/batch = 15.7802s	
17988/29850 (epoch 30.131), train_loss = 0.90310101, grad/param norm = 2.0597e-01, time/batch = 17.5368s	
17989/29850 (epoch 30.132), train_loss = 0.79050953, grad/param norm = 2.5282e-01, time/batch = 16.2781s	
17990/29850 (epoch 30.134), train_loss = 0.87019027, grad/param norm = 2.1433e-01, time/batch = 19.5267s	
17991/29850 (epoch 30.136), train_loss = 0.96138215, grad/param norm = 2.0493e-01, time/batch = 18.3817s	
17992/29850 (epoch 30.137), train_loss = 0.74659217, grad/param norm = 1.8485e-01, time/batch = 19.3777s	
17993/29850 (epoch 30.139), train_loss = 0.88018564, grad/param norm = 2.0181e-01, time/batch = 19.0390s	
17994/29850 (epoch 30.141), train_loss = 0.80184943, grad/param norm = 2.0874e-01, time/batch = 17.2200s	
17995/29850 (epoch 30.142), train_loss = 1.02634557, grad/param norm = 2.4283e-01, time/batch = 15.7768s	
17996/29850 (epoch 30.144), train_loss = 1.13120002, grad/param norm = 2.3081e-01, time/batch = 15.6389s	
17997/29850 (epoch 30.146), train_loss = 1.14418640, grad/param norm = 2.3939e-01, time/batch = 17.1338s	
17998/29850 (epoch 30.147), train_loss = 0.97763553, grad/param norm = 2.2440e-01, time/batch = 16.6329s	
17999/29850 (epoch 30.149), train_loss = 0.92631893, grad/param norm = 2.0196e-01, time/batch = 15.8007s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch30.15_1.7902.t7	
18000/29850 (epoch 30.151), train_loss = 0.95466514, grad/param norm = 2.1219e-01, time/batch = 18.4593s	
18001/29850 (epoch 30.152), train_loss = 1.24446013, grad/param norm = 2.5130e-01, time/batch = 17.9573s	
18002/29850 (epoch 30.154), train_loss = 0.85672443, grad/param norm = 2.2956e-01, time/batch = 18.3719s	
18003/29850 (epoch 30.156), train_loss = 0.82999043, grad/param norm = 2.0333e-01, time/batch = 19.2847s	
18004/29850 (epoch 30.157), train_loss = 0.95435524, grad/param norm = 2.3470e-01, time/batch = 17.5505s	
18005/29850 (epoch 30.159), train_loss = 0.85341390, grad/param norm = 1.9684e-01, time/batch = 15.8065s	
18006/29850 (epoch 30.161), train_loss = 0.91720155, grad/param norm = 2.3003e-01, time/batch = 15.5949s	
18007/29850 (epoch 30.162), train_loss = 1.01346532, grad/param norm = 2.2644e-01, time/batch = 15.9903s	
18008/29850 (epoch 30.164), train_loss = 0.92798228, grad/param norm = 2.1202e-01, time/batch = 16.2288s	
18009/29850 (epoch 30.166), train_loss = 0.86902183, grad/param norm = 2.1066e-01, time/batch = 16.4347s	
18010/29850 (epoch 30.168), train_loss = 0.76905940, grad/param norm = 1.8625e-01, time/batch = 19.1936s	
18011/29850 (epoch 30.169), train_loss = 1.04247666, grad/param norm = 2.2324e-01, time/batch = 16.6898s	
18012/29850 (epoch 30.171), train_loss = 0.97032303, grad/param norm = 2.1783e-01, time/batch = 16.3371s	
18013/29850 (epoch 30.173), train_loss = 0.81458388, grad/param norm = 2.0232e-01, time/batch = 15.0607s	
18014/29850 (epoch 30.174), train_loss = 0.93810355, grad/param norm = 2.4224e-01, time/batch = 14.6995s	
18015/29850 (epoch 30.176), train_loss = 0.93088472, grad/param norm = 1.9449e-01, time/batch = 15.1096s	
18016/29850 (epoch 30.178), train_loss = 0.94122113, grad/param norm = 2.5586e-01, time/batch = 14.6376s	
18017/29850 (epoch 30.179), train_loss = 0.77598228, grad/param norm = 1.8900e-01, time/batch = 14.3208s	
18018/29850 (epoch 30.181), train_loss = 0.92524642, grad/param norm = 2.2034e-01, time/batch = 14.4100s	
18019/29850 (epoch 30.183), train_loss = 0.90809930, grad/param norm = 1.9145e-01, time/batch = 14.7433s	
18020/29850 (epoch 30.184), train_loss = 0.95534667, grad/param norm = 2.1135e-01, time/batch = 14.8823s	
18021/29850 (epoch 30.186), train_loss = 0.91058224, grad/param norm = 2.1680e-01, time/batch = 14.4916s	
18022/29850 (epoch 30.188), train_loss = 1.01619744, grad/param norm = 2.1773e-01, time/batch = 14.5816s	
18023/29850 (epoch 30.189), train_loss = 1.01021877, grad/param norm = 2.4133e-01, time/batch = 14.3396s	
18024/29850 (epoch 30.191), train_loss = 1.00475143, grad/param norm = 2.2012e-01, time/batch = 15.2696s	
18025/29850 (epoch 30.193), train_loss = 0.89621781, grad/param norm = 1.9872e-01, time/batch = 14.7045s	
18026/29850 (epoch 30.194), train_loss = 0.97980630, grad/param norm = 2.1346e-01, time/batch = 14.5637s	
18027/29850 (epoch 30.196), train_loss = 0.90938669, grad/param norm = 2.1708e-01, time/batch = 14.3289s	
18028/29850 (epoch 30.198), train_loss = 0.86906149, grad/param norm = 1.9597e-01, time/batch = 14.6511s	
18029/29850 (epoch 30.199), train_loss = 1.11041003, grad/param norm = 2.2843e-01, time/batch = 14.3244s	
18030/29850 (epoch 30.201), train_loss = 0.85214144, grad/param norm = 2.3734e-01, time/batch = 14.5778s	
18031/29850 (epoch 30.203), train_loss = 0.70117081, grad/param norm = 2.1089e-01, time/batch = 14.5020s	
18032/29850 (epoch 30.204), train_loss = 0.93189548, grad/param norm = 2.6945e-01, time/batch = 15.1786s	
18033/29850 (epoch 30.206), train_loss = 0.80159130, grad/param norm = 2.0115e-01, time/batch = 14.9589s	
18034/29850 (epoch 30.208), train_loss = 1.03964772, grad/param norm = 2.3155e-01, time/batch = 14.5886s	
18035/29850 (epoch 30.209), train_loss = 0.79985562, grad/param norm = 2.1309e-01, time/batch = 14.5688s	
18036/29850 (epoch 30.211), train_loss = 0.87062333, grad/param norm = 2.2150e-01, time/batch = 14.7279s	
18037/29850 (epoch 30.213), train_loss = 0.97228167, grad/param norm = 2.2400e-01, time/batch = 15.4043s	
18038/29850 (epoch 30.214), train_loss = 0.79964634, grad/param norm = 1.7091e-01, time/batch = 14.7144s	
18039/29850 (epoch 30.216), train_loss = 0.84029171, grad/param norm = 2.0137e-01, time/batch = 14.4164s	
18040/29850 (epoch 30.218), train_loss = 0.95380606, grad/param norm = 2.2709e-01, time/batch = 14.8898s	
18041/29850 (epoch 30.219), train_loss = 0.94802031, grad/param norm = 2.2055e-01, time/batch = 15.0240s	
18042/29850 (epoch 30.221), train_loss = 0.91104275, grad/param norm = 2.1451e-01, time/batch = 14.8686s	
18043/29850 (epoch 30.223), train_loss = 0.80156298, grad/param norm = 2.3408e-01, time/batch = 14.2451s	
18044/29850 (epoch 30.224), train_loss = 0.79324734, grad/param norm = 2.0124e-01, time/batch = 14.9501s	
18045/29850 (epoch 30.226), train_loss = 0.82358342, grad/param norm = 1.8002e-01, time/batch = 14.4173s	
18046/29850 (epoch 30.228), train_loss = 0.88835368, grad/param norm = 1.9657e-01, time/batch = 14.4163s	
18047/29850 (epoch 30.229), train_loss = 0.73833510, grad/param norm = 1.7186e-01, time/batch = 15.0233s	
18048/29850 (epoch 30.231), train_loss = 0.93251565, grad/param norm = 2.0719e-01, time/batch = 14.9560s	
18049/29850 (epoch 30.233), train_loss = 0.90290217, grad/param norm = 2.2571e-01, time/batch = 14.5704s	
18050/29850 (epoch 30.235), train_loss = 0.82292250, grad/param norm = 1.8104e-01, time/batch = 15.4164s	
18051/29850 (epoch 30.236), train_loss = 1.02645305, grad/param norm = 2.4194e-01, time/batch = 14.4917s	
18052/29850 (epoch 30.238), train_loss = 0.77860494, grad/param norm = 1.9919e-01, time/batch = 14.6981s	
18053/29850 (epoch 30.240), train_loss = 0.77447033, grad/param norm = 2.1939e-01, time/batch = 14.4032s	
18054/29850 (epoch 30.241), train_loss = 0.94462618, grad/param norm = 2.5226e-01, time/batch = 14.3457s	
18055/29850 (epoch 30.243), train_loss = 0.94453418, grad/param norm = 2.1572e-01, time/batch = 14.7903s	
18056/29850 (epoch 30.245), train_loss = 0.83057127, grad/param norm = 2.2889e-01, time/batch = 14.9719s	
18057/29850 (epoch 30.246), train_loss = 0.75382614, grad/param norm = 1.6110e-01, time/batch = 14.4992s	
18058/29850 (epoch 30.248), train_loss = 0.75156345, grad/param norm = 1.7409e-01, time/batch = 14.6505s	
18059/29850 (epoch 30.250), train_loss = 0.85665770, grad/param norm = 1.8600e-01, time/batch = 14.5716s	
18060/29850 (epoch 30.251), train_loss = 0.74384923, grad/param norm = 2.0533e-01, time/batch = 14.4902s	
18061/29850 (epoch 30.253), train_loss = 0.71649625, grad/param norm = 1.9968e-01, time/batch = 14.6627s	
18062/29850 (epoch 30.255), train_loss = 0.81588952, grad/param norm = 1.9329e-01, time/batch = 14.4922s	
18063/29850 (epoch 30.256), train_loss = 0.94229798, grad/param norm = 2.1491e-01, time/batch = 14.5677s	
18064/29850 (epoch 30.258), train_loss = 0.91776408, grad/param norm = 2.1451e-01, time/batch = 14.5782s	
18065/29850 (epoch 30.260), train_loss = 0.87523531, grad/param norm = 1.9013e-01, time/batch = 14.7263s	
18066/29850 (epoch 30.261), train_loss = 0.80190454, grad/param norm = 2.1905e-01, time/batch = 14.4247s	
18067/29850 (epoch 30.263), train_loss = 0.81417385, grad/param norm = 1.9110e-01, time/batch = 14.6520s	
18068/29850 (epoch 30.265), train_loss = 0.87973810, grad/param norm = 2.0225e-01, time/batch = 14.3340s	
18069/29850 (epoch 30.266), train_loss = 0.88221940, grad/param norm = 2.1162e-01, time/batch = 14.7418s	
18070/29850 (epoch 30.268), train_loss = 0.83488109, grad/param norm = 1.7670e-01, time/batch = 14.0078s	
18071/29850 (epoch 30.270), train_loss = 0.82872237, grad/param norm = 1.9426e-01, time/batch = 14.1576s	
18072/29850 (epoch 30.271), train_loss = 0.92892902, grad/param norm = 2.2433e-01, time/batch = 14.4143s	
18073/29850 (epoch 30.273), train_loss = 0.77351689, grad/param norm = 1.8862e-01, time/batch = 15.1021s	
18074/29850 (epoch 30.275), train_loss = 0.78002082, grad/param norm = 2.2220e-01, time/batch = 14.5431s	
18075/29850 (epoch 30.276), train_loss = 0.77263240, grad/param norm = 1.8814e-01, time/batch = 14.7927s	
18076/29850 (epoch 30.278), train_loss = 0.84854665, grad/param norm = 2.0688e-01, time/batch = 15.1855s	
18077/29850 (epoch 30.280), train_loss = 1.03564922, grad/param norm = 2.6784e-01, time/batch = 14.7297s	
18078/29850 (epoch 30.281), train_loss = 0.89588877, grad/param norm = 1.8828e-01, time/batch = 14.5723s	
18079/29850 (epoch 30.283), train_loss = 1.02407330, grad/param norm = 2.5583e-01, time/batch = 14.4233s	
18080/29850 (epoch 30.285), train_loss = 0.95068827, grad/param norm = 2.0384e-01, time/batch = 14.4163s	
18081/29850 (epoch 30.286), train_loss = 0.97260251, grad/param norm = 2.0892e-01, time/batch = 14.8827s	
18082/29850 (epoch 30.288), train_loss = 1.01585623, grad/param norm = 2.9833e-01, time/batch = 14.9724s	
18083/29850 (epoch 30.290), train_loss = 0.89935142, grad/param norm = 2.2196e-01, time/batch = 14.6444s	
18084/29850 (epoch 30.291), train_loss = 1.13221465, grad/param norm = 2.4106e-01, time/batch = 14.4331s	
18085/29850 (epoch 30.293), train_loss = 1.00693674, grad/param norm = 2.2521e-01, time/batch = 14.8094s	
18086/29850 (epoch 30.295), train_loss = 1.06451969, grad/param norm = 2.1498e-01, time/batch = 14.3470s	
18087/29850 (epoch 30.296), train_loss = 0.81759824, grad/param norm = 1.9620e-01, time/batch = 14.8879s	
18088/29850 (epoch 30.298), train_loss = 0.68521390, grad/param norm = 1.7981e-01, time/batch = 14.2589s	
18089/29850 (epoch 30.300), train_loss = 0.78748806, grad/param norm = 1.9585e-01, time/batch = 14.8823s	
18090/29850 (epoch 30.302), train_loss = 0.78362134, grad/param norm = 2.1339e-01, time/batch = 15.4363s	
18091/29850 (epoch 30.303), train_loss = 0.83124222, grad/param norm = 2.1066e-01, time/batch = 15.1256s	
18092/29850 (epoch 30.305), train_loss = 0.94706618, grad/param norm = 2.0561e-01, time/batch = 15.1300s	
18093/29850 (epoch 30.307), train_loss = 0.96358909, grad/param norm = 1.9292e-01, time/batch = 15.5508s	
18094/29850 (epoch 30.308), train_loss = 0.80282272, grad/param norm = 2.0245e-01, time/batch = 15.0107s	
18095/29850 (epoch 30.310), train_loss = 0.90901496, grad/param norm = 2.3109e-01, time/batch = 14.7260s	
18096/29850 (epoch 30.312), train_loss = 0.94564922, grad/param norm = 2.0706e-01, time/batch = 14.5755s	
18097/29850 (epoch 30.313), train_loss = 0.90376814, grad/param norm = 2.1547e-01, time/batch = 15.1025s	
18098/29850 (epoch 30.315), train_loss = 0.90819308, grad/param norm = 2.2239e-01, time/batch = 14.2583s	
18099/29850 (epoch 30.317), train_loss = 0.90213088, grad/param norm = 2.1930e-01, time/batch = 14.3338s	
18100/29850 (epoch 30.318), train_loss = 0.89210842, grad/param norm = 2.0628e-01, time/batch = 14.5576s	
18101/29850 (epoch 30.320), train_loss = 0.82014769, grad/param norm = 1.8492e-01, time/batch = 14.6422s	
18102/29850 (epoch 30.322), train_loss = 1.04367837, grad/param norm = 2.2856e-01, time/batch = 14.8893s	
18103/29850 (epoch 30.323), train_loss = 0.95675359, grad/param norm = 2.2892e-01, time/batch = 14.9617s	
18104/29850 (epoch 30.325), train_loss = 0.98687908, grad/param norm = 2.2399e-01, time/batch = 15.0742s	
18105/29850 (epoch 30.327), train_loss = 1.12271246, grad/param norm = 2.5763e-01, time/batch = 15.0114s	
18106/29850 (epoch 30.328), train_loss = 1.04839347, grad/param norm = 2.7054e-01, time/batch = 14.2985s	
18107/29850 (epoch 30.330), train_loss = 0.97177711, grad/param norm = 2.0502e-01, time/batch = 14.6432s	
18108/29850 (epoch 30.332), train_loss = 0.84816849, grad/param norm = 2.0624e-01, time/batch = 14.1789s	
18109/29850 (epoch 30.333), train_loss = 0.96170593, grad/param norm = 2.1137e-01, time/batch = 14.6373s	
18110/29850 (epoch 30.335), train_loss = 1.02365585, grad/param norm = 2.1487e-01, time/batch = 14.2469s	
18111/29850 (epoch 30.337), train_loss = 0.92777869, grad/param norm = 2.1645e-01, time/batch = 14.1756s	
18112/29850 (epoch 30.338), train_loss = 0.94722308, grad/param norm = 2.0112e-01, time/batch = 14.2415s	
18113/29850 (epoch 30.340), train_loss = 0.79261083, grad/param norm = 2.0496e-01, time/batch = 14.5468s	
18114/29850 (epoch 30.342), train_loss = 0.90590514, grad/param norm = 2.4936e-01, time/batch = 14.3167s	
18115/29850 (epoch 30.343), train_loss = 0.91802762, grad/param norm = 2.7514e-01, time/batch = 14.7193s	
18116/29850 (epoch 30.345), train_loss = 1.01153551, grad/param norm = 2.6954e-01, time/batch = 15.4247s	
18117/29850 (epoch 30.347), train_loss = 1.01230910, grad/param norm = 2.3885e-01, time/batch = 14.6516s	
18118/29850 (epoch 30.348), train_loss = 0.85770742, grad/param norm = 2.4632e-01, time/batch = 14.5750s	
18119/29850 (epoch 30.350), train_loss = 0.97555531, grad/param norm = 3.0388e-01, time/batch = 14.4172s	
18120/29850 (epoch 30.352), train_loss = 0.86407838, grad/param norm = 2.0706e-01, time/batch = 14.4075s	
18121/29850 (epoch 30.353), train_loss = 0.96708947, grad/param norm = 2.2034e-01, time/batch = 14.2428s	
18122/29850 (epoch 30.355), train_loss = 0.86499095, grad/param norm = 2.1140e-01, time/batch = 15.1012s	
18123/29850 (epoch 30.357), train_loss = 0.99585742, grad/param norm = 2.1849e-01, time/batch = 14.4327s	
18124/29850 (epoch 30.358), train_loss = 0.83421565, grad/param norm = 2.2116e-01, time/batch = 14.2437s	
18125/29850 (epoch 30.360), train_loss = 0.89802003, grad/param norm = 2.4108e-01, time/batch = 15.8853s	
18126/29850 (epoch 30.362), train_loss = 0.91675678, grad/param norm = 2.3789e-01, time/batch = 25.7768s	
18127/29850 (epoch 30.363), train_loss = 0.95592240, grad/param norm = 2.3202e-01, time/batch = 14.1592s	
18128/29850 (epoch 30.365), train_loss = 1.05299530, grad/param norm = 2.2306e-01, time/batch = 14.2432s	
18129/29850 (epoch 30.367), train_loss = 0.85171704, grad/param norm = 1.9333e-01, time/batch = 14.5675s	
18130/29850 (epoch 30.369), train_loss = 0.79063190, grad/param norm = 2.4190e-01, time/batch = 17.8839s	
18131/29850 (epoch 30.370), train_loss = 0.73866826, grad/param norm = 1.8356e-01, time/batch = 15.3121s	
18132/29850 (epoch 30.372), train_loss = 0.99856539, grad/param norm = 2.2156e-01, time/batch = 15.5310s	
18133/29850 (epoch 30.374), train_loss = 0.96368032, grad/param norm = 2.0395e-01, time/batch = 15.9384s	
18134/29850 (epoch 30.375), train_loss = 0.91942911, grad/param norm = 1.9003e-01, time/batch = 15.1476s	
18135/29850 (epoch 30.377), train_loss = 0.84123973, grad/param norm = 2.1049e-01, time/batch = 17.9726s	
18136/29850 (epoch 30.379), train_loss = 1.04961493, grad/param norm = 2.6187e-01, time/batch = 16.2728s	
18137/29850 (epoch 30.380), train_loss = 0.96989645, grad/param norm = 2.2983e-01, time/batch = 16.3831s	
18138/29850 (epoch 30.382), train_loss = 0.94595997, grad/param norm = 2.2469e-01, time/batch = 17.9805s	
18139/29850 (epoch 30.384), train_loss = 1.00237259, grad/param norm = 2.2228e-01, time/batch = 18.6297s	
18140/29850 (epoch 30.385), train_loss = 0.95070499, grad/param norm = 2.2133e-01, time/batch = 17.1303s	
18141/29850 (epoch 30.387), train_loss = 0.97737140, grad/param norm = 2.3203e-01, time/batch = 17.8528s	
18142/29850 (epoch 30.389), train_loss = 1.04642655, grad/param norm = 2.3225e-01, time/batch = 18.4627s	
18143/29850 (epoch 30.390), train_loss = 0.96531245, grad/param norm = 1.8745e-01, time/batch = 16.0099s	
18144/29850 (epoch 30.392), train_loss = 0.91424366, grad/param norm = 2.4510e-01, time/batch = 18.4700s	
18145/29850 (epoch 30.394), train_loss = 0.99418601, grad/param norm = 2.0785e-01, time/batch = 17.1376s	
18146/29850 (epoch 30.395), train_loss = 0.88284304, grad/param norm = 2.3728e-01, time/batch = 17.2412s	
18147/29850 (epoch 30.397), train_loss = 0.80711054, grad/param norm = 2.1901e-01, time/batch = 15.4898s	
18148/29850 (epoch 30.399), train_loss = 0.84153609, grad/param norm = 2.0503e-01, time/batch = 17.6089s	
18149/29850 (epoch 30.400), train_loss = 1.18650083, grad/param norm = 2.6809e-01, time/batch = 15.7845s	
18150/29850 (epoch 30.402), train_loss = 1.08887659, grad/param norm = 2.1731e-01, time/batch = 16.1161s	
18151/29850 (epoch 30.404), train_loss = 0.95600590, grad/param norm = 2.1754e-01, time/batch = 17.2097s	
18152/29850 (epoch 30.405), train_loss = 0.87409917, grad/param norm = 2.4405e-01, time/batch = 15.8985s	
18153/29850 (epoch 30.407), train_loss = 0.84043298, grad/param norm = 1.9120e-01, time/batch = 17.8856s	
18154/29850 (epoch 30.409), train_loss = 0.97964466, grad/param norm = 2.4587e-01, time/batch = 17.4655s	
18155/29850 (epoch 30.410), train_loss = 1.04654966, grad/param norm = 2.1979e-01, time/batch = 19.1136s	
18156/29850 (epoch 30.412), train_loss = 1.04244330, grad/param norm = 2.2892e-01, time/batch = 18.8902s	
18157/29850 (epoch 30.414), train_loss = 0.95850940, grad/param norm = 2.4148e-01, time/batch = 15.7598s	
18158/29850 (epoch 30.415), train_loss = 0.93718613, grad/param norm = 2.0896e-01, time/batch = 15.2910s	
18159/29850 (epoch 30.417), train_loss = 1.05892773, grad/param norm = 2.3325e-01, time/batch = 16.3469s	
18160/29850 (epoch 30.419), train_loss = 0.89786791, grad/param norm = 2.0178e-01, time/batch = 18.0336s	
18161/29850 (epoch 30.420), train_loss = 0.91613392, grad/param norm = 2.1004e-01, time/batch = 16.6270s	
18162/29850 (epoch 30.422), train_loss = 0.90297228, grad/param norm = 2.0315e-01, time/batch = 18.0548s	
18163/29850 (epoch 30.424), train_loss = 0.85477521, grad/param norm = 2.1101e-01, time/batch = 19.1314s	
18164/29850 (epoch 30.425), train_loss = 1.01871190, grad/param norm = 2.5415e-01, time/batch = 18.1296s	
18165/29850 (epoch 30.427), train_loss = 0.74368163, grad/param norm = 2.0277e-01, time/batch = 17.6321s	
18166/29850 (epoch 30.429), train_loss = 0.83081256, grad/param norm = 2.4526e-01, time/batch = 15.8541s	
18167/29850 (epoch 30.430), train_loss = 0.76336397, grad/param norm = 1.8721e-01, time/batch = 16.8482s	
18168/29850 (epoch 30.432), train_loss = 0.88428182, grad/param norm = 2.3977e-01, time/batch = 18.0290s	
18169/29850 (epoch 30.434), train_loss = 0.82497467, grad/param norm = 1.8862e-01, time/batch = 15.7014s	
18170/29850 (epoch 30.436), train_loss = 0.90221650, grad/param norm = 2.2001e-01, time/batch = 15.3993s	
18171/29850 (epoch 30.437), train_loss = 0.97686524, grad/param norm = 2.2227e-01, time/batch = 15.9284s	
18172/29850 (epoch 30.439), train_loss = 0.94733908, grad/param norm = 1.9426e-01, time/batch = 14.5852s	
18173/29850 (epoch 30.441), train_loss = 0.93245499, grad/param norm = 2.2428e-01, time/batch = 16.6429s	
18174/29850 (epoch 30.442), train_loss = 0.90913789, grad/param norm = 2.2099e-01, time/batch = 15.4628s	
18175/29850 (epoch 30.444), train_loss = 0.94469676, grad/param norm = 2.2412e-01, time/batch = 16.1077s	
18176/29850 (epoch 30.446), train_loss = 0.97624291, grad/param norm = 2.1057e-01, time/batch = 16.9730s	
18177/29850 (epoch 30.447), train_loss = 0.99208110, grad/param norm = 2.3632e-01, time/batch = 17.4554s	
18178/29850 (epoch 30.449), train_loss = 0.94633596, grad/param norm = 2.2881e-01, time/batch = 15.8723s	
18179/29850 (epoch 30.451), train_loss = 0.72959571, grad/param norm = 1.7663e-01, time/batch = 18.1370s	
18180/29850 (epoch 30.452), train_loss = 0.66272539, grad/param norm = 1.8131e-01, time/batch = 17.0433s	
18181/29850 (epoch 30.454), train_loss = 0.77645375, grad/param norm = 1.9976e-01, time/batch = 17.7262s	
18182/29850 (epoch 30.456), train_loss = 0.98075777, grad/param norm = 2.2977e-01, time/batch = 17.2957s	
18183/29850 (epoch 30.457), train_loss = 0.98183237, grad/param norm = 3.0702e-01, time/batch = 18.3069s	
18184/29850 (epoch 30.459), train_loss = 1.06289588, grad/param norm = 2.4871e-01, time/batch = 17.5542s	
18185/29850 (epoch 30.461), train_loss = 1.05174694, grad/param norm = 2.1659e-01, time/batch = 15.8815s	
18186/29850 (epoch 30.462), train_loss = 1.06449663, grad/param norm = 2.2908e-01, time/batch = 17.3443s	
18187/29850 (epoch 30.464), train_loss = 0.96205964, grad/param norm = 2.0136e-01, time/batch = 16.2771s	
18188/29850 (epoch 30.466), train_loss = 0.79625147, grad/param norm = 2.2749e-01, time/batch = 17.7914s	
18189/29850 (epoch 30.467), train_loss = 0.87028248, grad/param norm = 2.2789e-01, time/batch = 16.6033s	
18190/29850 (epoch 30.469), train_loss = 0.88520733, grad/param norm = 2.0614e-01, time/batch = 19.9455s	
18191/29850 (epoch 30.471), train_loss = 0.87856348, grad/param norm = 2.1311e-01, time/batch = 18.2102s	
18192/29850 (epoch 30.472), train_loss = 0.83262835, grad/param norm = 1.9648e-01, time/batch = 16.2151s	
18193/29850 (epoch 30.474), train_loss = 1.00495341, grad/param norm = 2.0770e-01, time/batch = 18.7124s	
18194/29850 (epoch 30.476), train_loss = 0.93640685, grad/param norm = 1.9937e-01, time/batch = 17.2130s	
18195/29850 (epoch 30.477), train_loss = 0.95172142, grad/param norm = 2.2966e-01, time/batch = 17.2794s	
18196/29850 (epoch 30.479), train_loss = 1.09369805, grad/param norm = 2.1658e-01, time/batch = 15.9485s	
18197/29850 (epoch 30.481), train_loss = 0.88875725, grad/param norm = 2.0780e-01, time/batch = 17.2743s	
18198/29850 (epoch 30.482), train_loss = 0.82593352, grad/param norm = 1.7982e-01, time/batch = 14.7757s	
18199/29850 (epoch 30.484), train_loss = 0.87126363, grad/param norm = 1.9871e-01, time/batch = 15.7080s	
18200/29850 (epoch 30.486), train_loss = 0.95979027, grad/param norm = 2.2083e-01, time/batch = 15.7160s	
18201/29850 (epoch 30.487), train_loss = 0.94855164, grad/param norm = 2.1705e-01, time/batch = 15.3255s	
18202/29850 (epoch 30.489), train_loss = 0.92727758, grad/param norm = 2.0697e-01, time/batch = 15.5473s	
18203/29850 (epoch 30.491), train_loss = 0.82555354, grad/param norm = 1.9566e-01, time/batch = 16.6990s	
18204/29850 (epoch 30.492), train_loss = 0.91905736, grad/param norm = 2.1344e-01, time/batch = 17.3613s	
18205/29850 (epoch 30.494), train_loss = 0.97577580, grad/param norm = 2.0449e-01, time/batch = 17.2304s	
18206/29850 (epoch 30.496), train_loss = 1.04501925, grad/param norm = 2.1495e-01, time/batch = 15.5979s	
18207/29850 (epoch 30.497), train_loss = 0.95768830, grad/param norm = 1.9037e-01, time/batch = 16.7989s	
18208/29850 (epoch 30.499), train_loss = 0.92867179, grad/param norm = 2.1112e-01, time/batch = 15.9634s	
18209/29850 (epoch 30.501), train_loss = 0.85389795, grad/param norm = 2.4465e-01, time/batch = 19.3815s	
18210/29850 (epoch 30.503), train_loss = 0.96965641, grad/param norm = 2.2562e-01, time/batch = 17.3829s	
18211/29850 (epoch 30.504), train_loss = 1.12787434, grad/param norm = 2.4117e-01, time/batch = 16.1094s	
18212/29850 (epoch 30.506), train_loss = 1.08766828, grad/param norm = 2.2957e-01, time/batch = 18.8627s	
18213/29850 (epoch 30.508), train_loss = 0.91523290, grad/param norm = 2.0540e-01, time/batch = 17.1335s	
18214/29850 (epoch 30.509), train_loss = 0.75962989, grad/param norm = 1.8778e-01, time/batch = 16.4528s	
18215/29850 (epoch 30.511), train_loss = 0.95592449, grad/param norm = 2.2554e-01, time/batch = 17.6474s	
18216/29850 (epoch 30.513), train_loss = 0.92817825, grad/param norm = 2.7176e-01, time/batch = 18.3902s	
18217/29850 (epoch 30.514), train_loss = 0.83557555, grad/param norm = 1.9331e-01, time/batch = 18.2773s	
18218/29850 (epoch 30.516), train_loss = 0.86739212, grad/param norm = 1.8059e-01, time/batch = 19.6961s	
18219/29850 (epoch 30.518), train_loss = 0.74981740, grad/param norm = 1.9436e-01, time/batch = 17.3031s	
18220/29850 (epoch 30.519), train_loss = 0.74300261, grad/param norm = 1.8715e-01, time/batch = 16.2855s	
18221/29850 (epoch 30.521), train_loss = 0.68402587, grad/param norm = 1.6625e-01, time/batch = 17.2709s	
18222/29850 (epoch 30.523), train_loss = 0.75371216, grad/param norm = 1.6376e-01, time/batch = 18.1996s	
18223/29850 (epoch 30.524), train_loss = 0.84001542, grad/param norm = 2.1754e-01, time/batch = 16.4422s	
18224/29850 (epoch 30.526), train_loss = 0.89463848, grad/param norm = 2.1698e-01, time/batch = 17.9558s	
18225/29850 (epoch 30.528), train_loss = 1.01529598, grad/param norm = 2.6360e-01, time/batch = 18.3986s	
18226/29850 (epoch 30.529), train_loss = 0.96046255, grad/param norm = 2.2860e-01, time/batch = 15.3474s	
18227/29850 (epoch 30.531), train_loss = 0.91479528, grad/param norm = 2.5274e-01, time/batch = 16.7819s	
18228/29850 (epoch 30.533), train_loss = 0.89808345, grad/param norm = 2.0578e-01, time/batch = 15.3543s	
18229/29850 (epoch 30.534), train_loss = 0.96186993, grad/param norm = 2.2743e-01, time/batch = 14.4146s	
18230/29850 (epoch 30.536), train_loss = 0.86832806, grad/param norm = 2.2393e-01, time/batch = 14.3330s	
18231/29850 (epoch 30.538), train_loss = 1.03491682, grad/param norm = 2.2997e-01, time/batch = 14.9660s	
18232/29850 (epoch 30.539), train_loss = 1.07063356, grad/param norm = 2.3087e-01, time/batch = 14.7358s	
18233/29850 (epoch 30.541), train_loss = 0.67545030, grad/param norm = 1.8624e-01, time/batch = 14.4209s	
18234/29850 (epoch 30.543), train_loss = 0.88906205, grad/param norm = 2.2666e-01, time/batch = 14.6292s	
18235/29850 (epoch 30.544), train_loss = 0.98767999, grad/param norm = 2.1387e-01, time/batch = 14.6281s	
18236/29850 (epoch 30.546), train_loss = 0.97966763, grad/param norm = 2.2139e-01, time/batch = 14.6460s	
18237/29850 (epoch 30.548), train_loss = 0.77181843, grad/param norm = 1.8920e-01, time/batch = 14.2370s	
18238/29850 (epoch 30.549), train_loss = 0.86107271, grad/param norm = 2.1209e-01, time/batch = 14.0929s	
18239/29850 (epoch 30.551), train_loss = 0.78219325, grad/param norm = 1.8003e-01, time/batch = 14.9289s	
18240/29850 (epoch 30.553), train_loss = 0.89744258, grad/param norm = 1.9550e-01, time/batch = 14.0919s	
18241/29850 (epoch 30.554), train_loss = 0.75604094, grad/param norm = 2.1521e-01, time/batch = 14.0023s	
18242/29850 (epoch 30.556), train_loss = 0.81035471, grad/param norm = 2.0580e-01, time/batch = 13.9286s	
18243/29850 (epoch 30.558), train_loss = 0.81443716, grad/param norm = 1.9409e-01, time/batch = 14.2426s	
18244/29850 (epoch 30.559), train_loss = 0.83869509, grad/param norm = 1.9534e-01, time/batch = 14.0979s	
18245/29850 (epoch 30.561), train_loss = 0.93718422, grad/param norm = 2.2616e-01, time/batch = 14.6935s	
18246/29850 (epoch 30.563), train_loss = 0.93274481, grad/param norm = 2.2090e-01, time/batch = 14.5631s	
18247/29850 (epoch 30.564), train_loss = 0.88956802, grad/param norm = 2.8034e-01, time/batch = 14.2486s	
18248/29850 (epoch 30.566), train_loss = 0.91072004, grad/param norm = 1.9856e-01, time/batch = 14.6525s	
18249/29850 (epoch 30.568), train_loss = 0.99649450, grad/param norm = 2.0881e-01, time/batch = 14.5816s	
18250/29850 (epoch 30.570), train_loss = 0.94927303, grad/param norm = 2.6567e-01, time/batch = 15.0963s	
18251/29850 (epoch 30.571), train_loss = 1.00981967, grad/param norm = 2.2402e-01, time/batch = 15.1813s	
18252/29850 (epoch 30.573), train_loss = 1.08198252, grad/param norm = 2.5551e-01, time/batch = 14.8929s	
18253/29850 (epoch 30.575), train_loss = 1.10020137, grad/param norm = 2.5049e-01, time/batch = 14.4967s	
18254/29850 (epoch 30.576), train_loss = 1.02677019, grad/param norm = 2.4845e-01, time/batch = 15.0361s	
18255/29850 (epoch 30.578), train_loss = 0.85743595, grad/param norm = 1.9827e-01, time/batch = 14.4763s	
18256/29850 (epoch 30.580), train_loss = 0.99629085, grad/param norm = 2.0360e-01, time/batch = 15.1959s	
18257/29850 (epoch 30.581), train_loss = 0.81866641, grad/param norm = 1.9053e-01, time/batch = 14.4878s	
18258/29850 (epoch 30.583), train_loss = 0.93448923, grad/param norm = 2.4464e-01, time/batch = 14.2558s	
18259/29850 (epoch 30.585), train_loss = 0.94089283, grad/param norm = 1.9754e-01, time/batch = 14.5622s	
18260/29850 (epoch 30.586), train_loss = 0.93370439, grad/param norm = 2.2146e-01, time/batch = 14.8022s	
18261/29850 (epoch 30.588), train_loss = 0.83831579, grad/param norm = 2.0933e-01, time/batch = 14.3435s	
18262/29850 (epoch 30.590), train_loss = 0.85378162, grad/param norm = 1.7830e-01, time/batch = 14.5616s	
18263/29850 (epoch 30.591), train_loss = 0.87870177, grad/param norm = 2.2413e-01, time/batch = 13.7686s	
18264/29850 (epoch 30.593), train_loss = 0.84199192, grad/param norm = 1.8967e-01, time/batch = 14.4020s	
18265/29850 (epoch 30.595), train_loss = 0.77678620, grad/param norm = 1.7383e-01, time/batch = 14.0149s	
18266/29850 (epoch 30.596), train_loss = 0.77621230, grad/param norm = 1.7994e-01, time/batch = 14.3870s	
18267/29850 (epoch 30.598), train_loss = 0.90096440, grad/param norm = 2.0707e-01, time/batch = 14.3341s	
18268/29850 (epoch 30.600), train_loss = 0.93697274, grad/param norm = 2.3142e-01, time/batch = 15.4437s	
18269/29850 (epoch 30.601), train_loss = 0.78549681, grad/param norm = 1.7275e-01, time/batch = 14.1750s	
18270/29850 (epoch 30.603), train_loss = 0.86307375, grad/param norm = 2.1095e-01, time/batch = 14.7330s	
18271/29850 (epoch 30.605), train_loss = 0.86658332, grad/param norm = 1.9506e-01, time/batch = 14.3408s	
18272/29850 (epoch 30.606), train_loss = 0.64370398, grad/param norm = 1.8325e-01, time/batch = 14.9303s	
18273/29850 (epoch 30.608), train_loss = 0.79969806, grad/param norm = 1.9128e-01, time/batch = 14.7481s	
18274/29850 (epoch 30.610), train_loss = 0.85962365, grad/param norm = 2.0405e-01, time/batch = 14.5614s	
18275/29850 (epoch 30.611), train_loss = 0.80079645, grad/param norm = 1.8833e-01, time/batch = 14.5475s	
18276/29850 (epoch 30.613), train_loss = 0.67707155, grad/param norm = 1.6858e-01, time/batch = 14.5659s	
18277/29850 (epoch 30.615), train_loss = 0.78474677, grad/param norm = 1.8433e-01, time/batch = 14.4119s	
18278/29850 (epoch 30.616), train_loss = 0.79112694, grad/param norm = 2.0972e-01, time/batch = 14.1755s	
18279/29850 (epoch 30.618), train_loss = 0.86188024, grad/param norm = 2.0301e-01, time/batch = 14.2393s	
18280/29850 (epoch 30.620), train_loss = 0.91634780, grad/param norm = 2.1389e-01, time/batch = 14.6255s	
18281/29850 (epoch 30.621), train_loss = 1.02270419, grad/param norm = 2.3516e-01, time/batch = 15.0318s	
18282/29850 (epoch 30.623), train_loss = 0.96002949, grad/param norm = 2.1129e-01, time/batch = 14.0519s	
18283/29850 (epoch 30.625), train_loss = 0.91217769, grad/param norm = 2.5480e-01, time/batch = 14.5761s	
18284/29850 (epoch 30.626), train_loss = 0.92112293, grad/param norm = 2.2646e-01, time/batch = 14.9027s	
18285/29850 (epoch 30.628), train_loss = 0.86923592, grad/param norm = 2.2375e-01, time/batch = 14.3292s	
18286/29850 (epoch 30.630), train_loss = 0.91252141, grad/param norm = 2.2650e-01, time/batch = 14.3443s	
18287/29850 (epoch 30.631), train_loss = 0.90534700, grad/param norm = 2.1344e-01, time/batch = 14.0668s	
18288/29850 (epoch 30.633), train_loss = 0.94909519, grad/param norm = 2.3547e-01, time/batch = 14.2403s	
18289/29850 (epoch 30.635), train_loss = 0.85925109, grad/param norm = 2.3068e-01, time/batch = 14.6488s	
18290/29850 (epoch 30.637), train_loss = 0.82677960, grad/param norm = 2.0760e-01, time/batch = 14.1513s	
18291/29850 (epoch 30.638), train_loss = 0.92433282, grad/param norm = 2.0280e-01, time/batch = 14.2558s	
18292/29850 (epoch 30.640), train_loss = 1.02703084, grad/param norm = 2.3430e-01, time/batch = 14.8155s	
18293/29850 (epoch 30.642), train_loss = 0.80642528, grad/param norm = 1.7615e-01, time/batch = 15.4262s	
18294/29850 (epoch 30.643), train_loss = 0.81414547, grad/param norm = 2.3170e-01, time/batch = 14.6615s	
18295/29850 (epoch 30.645), train_loss = 0.87972109, grad/param norm = 2.2160e-01, time/batch = 14.1558s	
18296/29850 (epoch 30.647), train_loss = 1.03310221, grad/param norm = 2.4096e-01, time/batch = 14.6308s	
18297/29850 (epoch 30.648), train_loss = 0.80788569, grad/param norm = 1.8532e-01, time/batch = 15.0891s	
18298/29850 (epoch 30.650), train_loss = 0.90881940, grad/param norm = 2.2047e-01, time/batch = 14.4604s	
18299/29850 (epoch 30.652), train_loss = 0.87508215, grad/param norm = 2.0043e-01, time/batch = 14.9572s	
18300/29850 (epoch 30.653), train_loss = 0.99794364, grad/param norm = 2.4019e-01, time/batch = 14.5685s	
18301/29850 (epoch 30.655), train_loss = 0.90586678, grad/param norm = 1.9065e-01, time/batch = 15.0273s	
18302/29850 (epoch 30.657), train_loss = 0.89579590, grad/param norm = 2.2391e-01, time/batch = 14.4230s	
18303/29850 (epoch 30.658), train_loss = 0.98913506, grad/param norm = 2.0939e-01, time/batch = 14.3195s	
18304/29850 (epoch 30.660), train_loss = 0.88071453, grad/param norm = 2.2790e-01, time/batch = 14.1757s	
18305/29850 (epoch 30.662), train_loss = 0.99321729, grad/param norm = 2.3711e-01, time/batch = 15.4293s	
18306/29850 (epoch 30.663), train_loss = 1.11194969, grad/param norm = 2.3651e-01, time/batch = 14.4803s	
18307/29850 (epoch 30.665), train_loss = 1.03881833, grad/param norm = 2.2817e-01, time/batch = 14.0917s	
18308/29850 (epoch 30.667), train_loss = 0.94572523, grad/param norm = 2.1833e-01, time/batch = 13.9967s	
18309/29850 (epoch 30.668), train_loss = 0.87066903, grad/param norm = 2.4348e-01, time/batch = 14.5720s	
18310/29850 (epoch 30.670), train_loss = 1.02082803, grad/param norm = 2.7089e-01, time/batch = 14.0034s	
18311/29850 (epoch 30.672), train_loss = 1.01482045, grad/param norm = 2.5472e-01, time/batch = 14.3284s	
18312/29850 (epoch 30.673), train_loss = 0.94089769, grad/param norm = 2.3317e-01, time/batch = 14.4740s	
18313/29850 (epoch 30.675), train_loss = 0.81808022, grad/param norm = 2.2061e-01, time/batch = 14.7161s	
18314/29850 (epoch 30.677), train_loss = 0.87087389, grad/param norm = 2.2919e-01, time/batch = 15.1711s	
18315/29850 (epoch 30.678), train_loss = 0.91231792, grad/param norm = 2.1146e-01, time/batch = 14.8117s	
18316/29850 (epoch 30.680), train_loss = 0.88782822, grad/param norm = 1.9858e-01, time/batch = 14.4131s	
18317/29850 (epoch 30.682), train_loss = 0.89828149, grad/param norm = 2.4002e-01, time/batch = 14.7264s	
18318/29850 (epoch 30.683), train_loss = 1.03512835, grad/param norm = 2.7635e-01, time/batch = 14.6445s	
18319/29850 (epoch 30.685), train_loss = 1.08745758, grad/param norm = 2.1716e-01, time/batch = 14.9603s	
18320/29850 (epoch 30.687), train_loss = 0.95549958, grad/param norm = 2.1674e-01, time/batch = 14.4667s	
18321/29850 (epoch 30.688), train_loss = 0.81781635, grad/param norm = 2.2258e-01, time/batch = 15.0059s	
18322/29850 (epoch 30.690), train_loss = 0.78968213, grad/param norm = 1.8319e-01, time/batch = 14.6352s	
18323/29850 (epoch 30.692), train_loss = 1.01108554, grad/param norm = 2.2803e-01, time/batch = 14.9198s	
18324/29850 (epoch 30.693), train_loss = 0.89118827, grad/param norm = 2.0127e-01, time/batch = 14.5598s	
18325/29850 (epoch 30.695), train_loss = 0.78074362, grad/param norm = 1.7380e-01, time/batch = 15.3050s	
18326/29850 (epoch 30.697), train_loss = 0.90750546, grad/param norm = 2.0620e-01, time/batch = 15.6058s	
18327/29850 (epoch 30.698), train_loss = 1.03248604, grad/param norm = 2.2883e-01, time/batch = 15.2208s	
18328/29850 (epoch 30.700), train_loss = 1.01838539, grad/param norm = 2.6077e-01, time/batch = 16.7996s	
18329/29850 (epoch 30.702), train_loss = 0.89973062, grad/param norm = 1.9842e-01, time/batch = 15.2149s	
18330/29850 (epoch 30.704), train_loss = 0.79623754, grad/param norm = 2.0951e-01, time/batch = 15.6506s	
18331/29850 (epoch 30.705), train_loss = 0.90865007, grad/param norm = 2.1164e-01, time/batch = 14.8862s	
18332/29850 (epoch 30.707), train_loss = 0.83759891, grad/param norm = 2.0797e-01, time/batch = 15.7218s	
18333/29850 (epoch 30.709), train_loss = 0.89179570, grad/param norm = 2.0795e-01, time/batch = 9.8934s	
18334/29850 (epoch 30.710), train_loss = 0.84723953, grad/param norm = 2.1638e-01, time/batch = 0.6746s	
18335/29850 (epoch 30.712), train_loss = 0.93366409, grad/param norm = 1.8962e-01, time/batch = 0.6753s	
18336/29850 (epoch 30.714), train_loss = 0.98602262, grad/param norm = 2.2286e-01, time/batch = 0.6710s	
18337/29850 (epoch 30.715), train_loss = 0.93117369, grad/param norm = 2.1262e-01, time/batch = 0.6636s	
18338/29850 (epoch 30.717), train_loss = 0.68698697, grad/param norm = 1.9025e-01, time/batch = 0.6686s	
18339/29850 (epoch 30.719), train_loss = 0.87034377, grad/param norm = 2.0923e-01, time/batch = 0.6526s	
18340/29850 (epoch 30.720), train_loss = 0.90008391, grad/param norm = 1.9929e-01, time/batch = 0.6517s	
18341/29850 (epoch 30.722), train_loss = 0.81036412, grad/param norm = 1.7167e-01, time/batch = 0.9579s	
18342/29850 (epoch 30.724), train_loss = 0.93454462, grad/param norm = 2.2709e-01, time/batch = 0.9807s	
18343/29850 (epoch 30.725), train_loss = 0.80376043, grad/param norm = 1.9588e-01, time/batch = 0.9548s	
18344/29850 (epoch 30.727), train_loss = 0.80595665, grad/param norm = 2.0932e-01, time/batch = 0.9681s	
18345/29850 (epoch 30.729), train_loss = 0.76251051, grad/param norm = 1.8048e-01, time/batch = 0.9650s	
18346/29850 (epoch 30.730), train_loss = 0.72611157, grad/param norm = 1.7904e-01, time/batch = 1.6539s	
18347/29850 (epoch 30.732), train_loss = 0.99941276, grad/param norm = 2.0985e-01, time/batch = 1.7784s	
18348/29850 (epoch 30.734), train_loss = 1.08370904, grad/param norm = 2.3075e-01, time/batch = 1.7653s	
18349/29850 (epoch 30.735), train_loss = 0.81910973, grad/param norm = 2.0589e-01, time/batch = 14.6287s	
18350/29850 (epoch 30.737), train_loss = 0.79793176, grad/param norm = 2.0200e-01, time/batch = 14.4706s	
18351/29850 (epoch 30.739), train_loss = 0.69225616, grad/param norm = 1.8139e-01, time/batch = 14.6451s	
18352/29850 (epoch 30.740), train_loss = 0.76946578, grad/param norm = 1.9973e-01, time/batch = 15.5494s	
18353/29850 (epoch 30.742), train_loss = 0.68657241, grad/param norm = 1.8566e-01, time/batch = 15.3549s	
18354/29850 (epoch 30.744), train_loss = 0.80258238, grad/param norm = 2.1969e-01, time/batch = 14.5656s	
18355/29850 (epoch 30.745), train_loss = 0.83125705, grad/param norm = 2.0825e-01, time/batch = 14.9613s	
18356/29850 (epoch 30.747), train_loss = 0.88082000, grad/param norm = 2.1076e-01, time/batch = 15.0363s	
18357/29850 (epoch 30.749), train_loss = 0.76265004, grad/param norm = 1.9489e-01, time/batch = 14.7417s	
18358/29850 (epoch 30.750), train_loss = 0.71734130, grad/param norm = 1.7606e-01, time/batch = 17.4700s	
18359/29850 (epoch 30.752), train_loss = 0.64961397, grad/param norm = 1.7388e-01, time/batch = 16.5402s	
18360/29850 (epoch 30.754), train_loss = 0.73419596, grad/param norm = 1.9620e-01, time/batch = 16.0533s	
18361/29850 (epoch 30.755), train_loss = 0.73622117, grad/param norm = 2.0164e-01, time/batch = 17.2180s	
18362/29850 (epoch 30.757), train_loss = 0.77123486, grad/param norm = 1.7780e-01, time/batch = 16.3936s	
18363/29850 (epoch 30.759), train_loss = 0.78271713, grad/param norm = 1.7953e-01, time/batch = 16.1337s	
18364/29850 (epoch 30.760), train_loss = 0.80274674, grad/param norm = 2.1048e-01, time/batch = 15.7946s	
18365/29850 (epoch 30.762), train_loss = 0.74283732, grad/param norm = 2.0656e-01, time/batch = 15.1170s	
18366/29850 (epoch 30.764), train_loss = 0.68601106, grad/param norm = 2.3693e-01, time/batch = 22.0754s	
18367/29850 (epoch 30.765), train_loss = 0.84380001, grad/param norm = 2.2164e-01, time/batch = 25.7360s	
18368/29850 (epoch 30.767), train_loss = 0.85112590, grad/param norm = 2.1553e-01, time/batch = 15.8168s	
18369/29850 (epoch 30.769), train_loss = 0.84702492, grad/param norm = 2.0334e-01, time/batch = 16.1832s	
18370/29850 (epoch 30.771), train_loss = 0.93035651, grad/param norm = 2.1843e-01, time/batch = 15.7986s	
18371/29850 (epoch 30.772), train_loss = 0.88032140, grad/param norm = 2.2269e-01, time/batch = 17.0260s	
18372/29850 (epoch 30.774), train_loss = 0.84437840, grad/param norm = 2.1772e-01, time/batch = 17.0279s	
18373/29850 (epoch 30.776), train_loss = 0.85310797, grad/param norm = 2.0365e-01, time/batch = 16.1311s	
18374/29850 (epoch 30.777), train_loss = 0.95217290, grad/param norm = 2.0757e-01, time/batch = 16.7981s	
18375/29850 (epoch 30.779), train_loss = 0.77699966, grad/param norm = 2.1914e-01, time/batch = 19.1261s	
18376/29850 (epoch 30.781), train_loss = 0.91616583, grad/param norm = 2.1011e-01, time/batch = 15.2777s	
18377/29850 (epoch 30.782), train_loss = 0.89354529, grad/param norm = 1.9532e-01, time/batch = 17.2801s	
18378/29850 (epoch 30.784), train_loss = 0.74532516, grad/param norm = 2.2376e-01, time/batch = 16.8078s	
18379/29850 (epoch 30.786), train_loss = 0.80696712, grad/param norm = 2.1030e-01, time/batch = 19.2761s	
18380/29850 (epoch 30.787), train_loss = 0.70587102, grad/param norm = 2.0709e-01, time/batch = 17.4339s	
18381/29850 (epoch 30.789), train_loss = 0.71315761, grad/param norm = 1.7753e-01, time/batch = 18.5308s	
18382/29850 (epoch 30.791), train_loss = 0.81242181, grad/param norm = 2.2663e-01, time/batch = 15.1679s	
18383/29850 (epoch 30.792), train_loss = 0.91716012, grad/param norm = 2.1740e-01, time/batch = 15.2921s	
18384/29850 (epoch 30.794), train_loss = 0.89084920, grad/param norm = 1.9714e-01, time/batch = 15.9657s	
18385/29850 (epoch 30.796), train_loss = 0.76620617, grad/param norm = 1.9751e-01, time/batch = 14.8858s	
18386/29850 (epoch 30.797), train_loss = 0.68527754, grad/param norm = 1.8997e-01, time/batch = 16.8206s	
18387/29850 (epoch 30.799), train_loss = 0.73093191, grad/param norm = 1.9166e-01, time/batch = 14.6545s	
18388/29850 (epoch 30.801), train_loss = 0.75591923, grad/param norm = 1.7558e-01, time/batch = 17.9625s	
18389/29850 (epoch 30.802), train_loss = 0.70785918, grad/param norm = 1.9830e-01, time/batch = 17.6324s	
18390/29850 (epoch 30.804), train_loss = 0.74000333, grad/param norm = 1.7714e-01, time/batch = 17.2739s	
18391/29850 (epoch 30.806), train_loss = 0.71913100, grad/param norm = 1.9783e-01, time/batch = 18.6996s	
18392/29850 (epoch 30.807), train_loss = 0.74349428, grad/param norm = 1.8902e-01, time/batch = 17.2184s	
18393/29850 (epoch 30.809), train_loss = 0.74672838, grad/param norm = 2.0771e-01, time/batch = 15.4195s	
18394/29850 (epoch 30.811), train_loss = 0.89992700, grad/param norm = 2.3125e-01, time/batch = 16.2912s	
18395/29850 (epoch 30.812), train_loss = 0.88304344, grad/param norm = 2.2127e-01, time/batch = 15.1675s	
18396/29850 (epoch 30.814), train_loss = 0.95077724, grad/param norm = 2.1419e-01, time/batch = 18.7303s	
18397/29850 (epoch 30.816), train_loss = 0.95273164, grad/param norm = 2.0610e-01, time/batch = 17.8722s	
18398/29850 (epoch 30.817), train_loss = 0.91320962, grad/param norm = 2.8244e-01, time/batch = 17.1144s	
18399/29850 (epoch 30.819), train_loss = 0.70777673, grad/param norm = 1.8919e-01, time/batch = 15.2565s	
18400/29850 (epoch 30.821), train_loss = 0.96130699, grad/param norm = 2.9996e-01, time/batch = 15.0472s	
18401/29850 (epoch 30.822), train_loss = 0.97541263, grad/param norm = 2.3680e-01, time/batch = 15.1280s	
18402/29850 (epoch 30.824), train_loss = 0.87098214, grad/param norm = 2.1027e-01, time/batch = 16.3154s	
18403/29850 (epoch 30.826), train_loss = 0.77493311, grad/param norm = 1.9063e-01, time/batch = 15.7773s	
18404/29850 (epoch 30.827), train_loss = 0.70954442, grad/param norm = 2.3375e-01, time/batch = 18.1197s	
18405/29850 (epoch 30.829), train_loss = 0.86075492, grad/param norm = 2.3074e-01, time/batch = 15.1886s	
18406/29850 (epoch 30.831), train_loss = 0.95904596, grad/param norm = 2.3237e-01, time/batch = 17.8715s	
18407/29850 (epoch 30.832), train_loss = 0.87609194, grad/param norm = 1.9058e-01, time/batch = 15.1370s	
18408/29850 (epoch 30.834), train_loss = 0.67187805, grad/param norm = 1.8645e-01, time/batch = 16.7779s	
18409/29850 (epoch 30.836), train_loss = 0.69839078, grad/param norm = 1.9117e-01, time/batch = 16.0206s	
18410/29850 (epoch 30.838), train_loss = 0.82293591, grad/param norm = 2.4712e-01, time/batch = 18.3618s	
18411/29850 (epoch 30.839), train_loss = 0.71358158, grad/param norm = 2.0268e-01, time/batch = 19.0430s	
18412/29850 (epoch 30.841), train_loss = 0.76187213, grad/param norm = 1.8808e-01, time/batch = 15.9583s	
18413/29850 (epoch 30.843), train_loss = 0.70472938, grad/param norm = 1.9617e-01, time/batch = 17.6452s	
18414/29850 (epoch 30.844), train_loss = 0.76839000, grad/param norm = 2.0940e-01, time/batch = 16.3785s	
18415/29850 (epoch 30.846), train_loss = 0.84955213, grad/param norm = 2.0164e-01, time/batch = 16.8805s	
18416/29850 (epoch 30.848), train_loss = 0.91387078, grad/param norm = 2.3497e-01, time/batch = 16.7186s	
18417/29850 (epoch 30.849), train_loss = 0.79317937, grad/param norm = 2.0801e-01, time/batch = 15.3300s	
18418/29850 (epoch 30.851), train_loss = 0.98398684, grad/param norm = 2.2830e-01, time/batch = 17.8572s	
18419/29850 (epoch 30.853), train_loss = 0.80772418, grad/param norm = 2.2364e-01, time/batch = 16.3462s	
18420/29850 (epoch 30.854), train_loss = 1.00024416, grad/param norm = 2.2802e-01, time/batch = 17.2922s	
18421/29850 (epoch 30.856), train_loss = 0.94932743, grad/param norm = 2.4925e-01, time/batch = 15.8548s	
18422/29850 (epoch 30.858), train_loss = 0.88711815, grad/param norm = 2.2317e-01, time/batch = 15.1970s	
18423/29850 (epoch 30.859), train_loss = 0.77325478, grad/param norm = 2.5705e-01, time/batch = 16.3563s	
18424/29850 (epoch 30.861), train_loss = 0.98685526, grad/param norm = 2.4555e-01, time/batch = 15.1325s	
18425/29850 (epoch 30.863), train_loss = 1.02384050, grad/param norm = 2.8343e-01, time/batch = 18.3049s	
18426/29850 (epoch 30.864), train_loss = 0.96648476, grad/param norm = 2.2448e-01, time/batch = 15.5045s	
18427/29850 (epoch 30.866), train_loss = 0.89524036, grad/param norm = 2.4853e-01, time/batch = 17.2840s	
18428/29850 (epoch 30.868), train_loss = 1.04424733, grad/param norm = 2.5183e-01, time/batch = 16.7184s	
18429/29850 (epoch 30.869), train_loss = 0.94010523, grad/param norm = 2.4178e-01, time/batch = 17.5715s	
18430/29850 (epoch 30.871), train_loss = 0.95370284, grad/param norm = 2.2154e-01, time/batch = 16.1998s	
18431/29850 (epoch 30.873), train_loss = 0.90665745, grad/param norm = 2.5358e-01, time/batch = 18.0415s	
18432/29850 (epoch 30.874), train_loss = 0.92243281, grad/param norm = 2.1962e-01, time/batch = 18.3864s	
18433/29850 (epoch 30.876), train_loss = 0.93216640, grad/param norm = 5.0727e-01, time/batch = 16.4427s	
18434/29850 (epoch 30.878), train_loss = 0.90414506, grad/param norm = 2.1666e-01, time/batch = 18.5470s	
18435/29850 (epoch 30.879), train_loss = 0.90902582, grad/param norm = 2.5137e-01, time/batch = 15.3605s	
18436/29850 (epoch 30.881), train_loss = 0.98393808, grad/param norm = 2.1507e-01, time/batch = 17.2034s	
18437/29850 (epoch 30.883), train_loss = 0.96570026, grad/param norm = 2.5309e-01, time/batch = 15.6539s	
18438/29850 (epoch 30.884), train_loss = 0.80565701, grad/param norm = 2.1721e-01, time/batch = 18.0516s	
18439/29850 (epoch 30.886), train_loss = 1.02567242, grad/param norm = 3.2078e-01, time/batch = 17.8125s	
18440/29850 (epoch 30.888), train_loss = 0.88381855, grad/param norm = 2.4057e-01, time/batch = 16.8691s	
18441/29850 (epoch 30.889), train_loss = 0.80376539, grad/param norm = 2.0221e-01, time/batch = 19.5937s	
18442/29850 (epoch 30.891), train_loss = 0.77225488, grad/param norm = 1.8216e-01, time/batch = 16.3553s	
18443/29850 (epoch 30.893), train_loss = 0.84721848, grad/param norm = 2.3030e-01, time/batch = 16.6832s	
18444/29850 (epoch 30.894), train_loss = 0.86014800, grad/param norm = 2.2086e-01, time/batch = 15.4916s	
18445/29850 (epoch 30.896), train_loss = 0.90126961, grad/param norm = 2.7539e-01, time/batch = 15.2638s	
18446/29850 (epoch 30.898), train_loss = 1.02578334, grad/param norm = 2.8028e-01, time/batch = 17.3874s	
18447/29850 (epoch 30.899), train_loss = 0.78153734, grad/param norm = 2.0667e-01, time/batch = 16.9675s	
18448/29850 (epoch 30.901), train_loss = 1.11862556, grad/param norm = 2.8204e-01, time/batch = 15.5382s	
18449/29850 (epoch 30.903), train_loss = 0.91474002, grad/param norm = 2.9102e-01, time/batch = 17.5459s	
18450/29850 (epoch 30.905), train_loss = 1.14243415, grad/param norm = 2.3406e-01, time/batch = 19.2185s	
18451/29850 (epoch 30.906), train_loss = 0.93136610, grad/param norm = 2.3361e-01, time/batch = 17.8751s	
18452/29850 (epoch 30.908), train_loss = 1.04047223, grad/param norm = 2.2633e-01, time/batch = 16.2925s	
18453/29850 (epoch 30.910), train_loss = 0.94464855, grad/param norm = 2.1842e-01, time/batch = 17.8937s	
18454/29850 (epoch 30.911), train_loss = 1.12030237, grad/param norm = 2.1456e-01, time/batch = 17.0263s	
18455/29850 (epoch 30.913), train_loss = 1.01662543, grad/param norm = 2.1894e-01, time/batch = 15.8627s	
18456/29850 (epoch 30.915), train_loss = 1.03063328, grad/param norm = 2.6576e-01, time/batch = 16.3020s	
18457/29850 (epoch 30.916), train_loss = 0.98841860, grad/param norm = 2.2143e-01, time/batch = 16.9746s	
18458/29850 (epoch 30.918), train_loss = 0.84794203, grad/param norm = 2.1359e-01, time/batch = 15.2145s	
18459/29850 (epoch 30.920), train_loss = 1.00565896, grad/param norm = 2.0428e-01, time/batch = 17.0561s	
18460/29850 (epoch 30.921), train_loss = 0.90286575, grad/param norm = 2.4775e-01, time/batch = 15.7215s	
18461/29850 (epoch 30.923), train_loss = 0.91734300, grad/param norm = 2.1939e-01, time/batch = 17.0434s	
18462/29850 (epoch 30.925), train_loss = 1.05914749, grad/param norm = 2.4497e-01, time/batch = 16.4713s	
18463/29850 (epoch 30.926), train_loss = 1.04702817, grad/param norm = 2.7829e-01, time/batch = 16.6454s	
18464/29850 (epoch 30.928), train_loss = 0.93056988, grad/param norm = 2.5131e-01, time/batch = 19.6302s	
18465/29850 (epoch 30.930), train_loss = 0.94672218, grad/param norm = 2.0436e-01, time/batch = 15.7210s	
18466/29850 (epoch 30.931), train_loss = 0.90837476, grad/param norm = 2.2461e-01, time/batch = 18.7842s	
18467/29850 (epoch 30.933), train_loss = 1.04326028, grad/param norm = 2.2564e-01, time/batch = 18.1380s	
18468/29850 (epoch 30.935), train_loss = 0.96637942, grad/param norm = 2.3134e-01, time/batch = 15.3294s	
18469/29850 (epoch 30.936), train_loss = 0.93847176, grad/param norm = 2.3427e-01, time/batch = 14.8936s	
18470/29850 (epoch 30.938), train_loss = 0.81567441, grad/param norm = 1.8752e-01, time/batch = 14.9664s	
18471/29850 (epoch 30.940), train_loss = 0.80483270, grad/param norm = 2.0363e-01, time/batch = 14.7771s	
18472/29850 (epoch 30.941), train_loss = 0.82171310, grad/param norm = 2.1123e-01, time/batch = 14.7057s	
18473/29850 (epoch 30.943), train_loss = 0.82764431, grad/param norm = 2.1596e-01, time/batch = 14.9384s	
18474/29850 (epoch 30.945), train_loss = 0.80796865, grad/param norm = 2.0001e-01, time/batch = 16.7127s	
18475/29850 (epoch 30.946), train_loss = 0.79804564, grad/param norm = 2.2356e-01, time/batch = 17.4404s	
18476/29850 (epoch 30.948), train_loss = 0.91722462, grad/param norm = 2.0866e-01, time/batch = 16.5273s	
18477/29850 (epoch 30.950), train_loss = 0.82391171, grad/param norm = 1.8263e-01, time/batch = 17.6330s	
18478/29850 (epoch 30.951), train_loss = 0.75262481, grad/param norm = 2.0246e-01, time/batch = 17.4756s	
18479/29850 (epoch 30.953), train_loss = 0.86882232, grad/param norm = 2.4082e-01, time/batch = 17.6976s	
18480/29850 (epoch 30.955), train_loss = 0.76765590, grad/param norm = 1.9031e-01, time/batch = 16.5308s	
18481/29850 (epoch 30.956), train_loss = 0.77749665, grad/param norm = 1.9157e-01, time/batch = 18.3686s	
18482/29850 (epoch 30.958), train_loss = 0.68298705, grad/param norm = 1.6102e-01, time/batch = 15.7670s	
18483/29850 (epoch 30.960), train_loss = 0.97852250, grad/param norm = 2.2374e-01, time/batch = 18.0366s	
18484/29850 (epoch 30.961), train_loss = 0.77658630, grad/param norm = 2.3947e-01, time/batch = 19.2145s	
18485/29850 (epoch 30.963), train_loss = 0.73292587, grad/param norm = 1.8250e-01, time/batch = 15.9690s	
18486/29850 (epoch 30.965), train_loss = 0.81770854, grad/param norm = 2.2193e-01, time/batch = 18.2661s	
18487/29850 (epoch 30.966), train_loss = 0.76970686, grad/param norm = 2.1360e-01, time/batch = 17.7181s	
18488/29850 (epoch 30.968), train_loss = 0.80667357, grad/param norm = 2.3115e-01, time/batch = 18.9523s	
18489/29850 (epoch 30.970), train_loss = 0.76801993, grad/param norm = 2.1965e-01, time/batch = 18.5444s	
18490/29850 (epoch 30.972), train_loss = 0.77590221, grad/param norm = 1.7396e-01, time/batch = 15.6617s	
18491/29850 (epoch 30.973), train_loss = 0.78661878, grad/param norm = 1.9739e-01, time/batch = 15.0256s	
18492/29850 (epoch 30.975), train_loss = 0.67058665, grad/param norm = 1.8296e-01, time/batch = 14.7841s	
18493/29850 (epoch 30.977), train_loss = 0.81873154, grad/param norm = 1.9397e-01, time/batch = 17.2986s	
18494/29850 (epoch 30.978), train_loss = 0.72733205, grad/param norm = 1.7731e-01, time/batch = 17.1961s	
18495/29850 (epoch 30.980), train_loss = 0.80183976, grad/param norm = 1.8250e-01, time/batch = 17.6374s	
18496/29850 (epoch 30.982), train_loss = 0.77702870, grad/param norm = 2.0050e-01, time/batch = 19.1165s	
18497/29850 (epoch 30.983), train_loss = 0.80318380, grad/param norm = 1.6995e-01, time/batch = 15.3414s	
18498/29850 (epoch 30.985), train_loss = 0.91838386, grad/param norm = 2.1843e-01, time/batch = 16.5313s	
18499/29850 (epoch 30.987), train_loss = 0.88297962, grad/param norm = 2.1884e-01, time/batch = 18.2284s	
18500/29850 (epoch 30.988), train_loss = 0.79903246, grad/param norm = 1.8807e-01, time/batch = 17.7020s	
18501/29850 (epoch 30.990), train_loss = 0.87791225, grad/param norm = 2.1059e-01, time/batch = 17.8488s	
18502/29850 (epoch 30.992), train_loss = 0.89898582, grad/param norm = 1.8829e-01, time/batch = 18.0528s	
18503/29850 (epoch 30.993), train_loss = 0.88551313, grad/param norm = 2.1601e-01, time/batch = 18.5476s	
18504/29850 (epoch 30.995), train_loss = 0.89752971, grad/param norm = 2.2758e-01, time/batch = 18.2876s	
18505/29850 (epoch 30.997), train_loss = 0.90432515, grad/param norm = 2.2058e-01, time/batch = 18.4680s	
18506/29850 (epoch 30.998), train_loss = 0.92134651, grad/param norm = 2.1471e-01, time/batch = 15.4511s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
18507/29850 (epoch 31.000), train_loss = 0.76884167, grad/param norm = 1.9824e-01, time/batch = 16.8553s	
18508/29850 (epoch 31.002), train_loss = 1.04724018, grad/param norm = 2.3112e-01, time/batch = 17.6346s	
18509/29850 (epoch 31.003), train_loss = 0.77007227, grad/param norm = 2.2095e-01, time/batch = 17.4010s	
18510/29850 (epoch 31.005), train_loss = 0.89678802, grad/param norm = 2.0269e-01, time/batch = 17.5484s	
18511/29850 (epoch 31.007), train_loss = 0.96558840, grad/param norm = 2.4509e-01, time/batch = 18.7312s	
18512/29850 (epoch 31.008), train_loss = 1.08407406, grad/param norm = 2.1667e-01, time/batch = 17.2973s	
18513/29850 (epoch 31.010), train_loss = 0.80724502, grad/param norm = 2.0766e-01, time/batch = 18.6946s	
18514/29850 (epoch 31.012), train_loss = 0.85568766, grad/param norm = 2.0155e-01, time/batch = 16.6981s	
18515/29850 (epoch 31.013), train_loss = 0.92220620, grad/param norm = 2.3517e-01, time/batch = 16.2046s	
18516/29850 (epoch 31.015), train_loss = 0.94905322, grad/param norm = 2.3527e-01, time/batch = 17.9621s	
18517/29850 (epoch 31.017), train_loss = 0.91812094, grad/param norm = 2.2987e-01, time/batch = 16.5538s	
18518/29850 (epoch 31.018), train_loss = 1.02349216, grad/param norm = 2.2592e-01, time/batch = 16.6216s	
18519/29850 (epoch 31.020), train_loss = 0.87376322, grad/param norm = 2.0238e-01, time/batch = 15.9498s	
18520/29850 (epoch 31.022), train_loss = 0.95597457, grad/param norm = 2.2864e-01, time/batch = 18.9636s	
18521/29850 (epoch 31.023), train_loss = 0.95744724, grad/param norm = 1.9111e-01, time/batch = 16.0341s	
18522/29850 (epoch 31.025), train_loss = 0.86512240, grad/param norm = 1.8677e-01, time/batch = 19.3800s	
18523/29850 (epoch 31.027), train_loss = 0.69222448, grad/param norm = 2.0119e-01, time/batch = 18.9638s	
18524/29850 (epoch 31.028), train_loss = 0.84295994, grad/param norm = 2.0678e-01, time/batch = 16.5271s	
18525/29850 (epoch 31.030), train_loss = 0.84598522, grad/param norm = 2.3448e-01, time/batch = 16.0248s	
18526/29850 (epoch 31.032), train_loss = 0.93167270, grad/param norm = 1.9242e-01, time/batch = 17.3832s	
18527/29850 (epoch 31.034), train_loss = 0.79622115, grad/param norm = 1.9462e-01, time/batch = 18.1321s	
18528/29850 (epoch 31.035), train_loss = 0.71413653, grad/param norm = 1.8794e-01, time/batch = 17.5158s	
18529/29850 (epoch 31.037), train_loss = 0.88029182, grad/param norm = 2.0955e-01, time/batch = 18.6993s	
18530/29850 (epoch 31.039), train_loss = 0.77451395, grad/param norm = 1.7332e-01, time/batch = 18.2318s	
18531/29850 (epoch 31.040), train_loss = 0.78107494, grad/param norm = 1.8533e-01, time/batch = 15.9489s	
18532/29850 (epoch 31.042), train_loss = 0.77839854, grad/param norm = 2.2777e-01, time/batch = 16.8260s	
18533/29850 (epoch 31.044), train_loss = 0.84502059, grad/param norm = 1.9948e-01, time/batch = 17.5683s	
18534/29850 (epoch 31.045), train_loss = 0.95599991, grad/param norm = 2.1891e-01, time/batch = 17.6165s	
18535/29850 (epoch 31.047), train_loss = 0.78812368, grad/param norm = 1.9913e-01, time/batch = 17.1835s	
18536/29850 (epoch 31.049), train_loss = 0.91223489, grad/param norm = 2.0668e-01, time/batch = 15.3516s	
18537/29850 (epoch 31.050), train_loss = 0.78932796, grad/param norm = 2.1657e-01, time/batch = 17.8233s	
18538/29850 (epoch 31.052), train_loss = 0.98144487, grad/param norm = 2.4736e-01, time/batch = 15.6235s	
18539/29850 (epoch 31.054), train_loss = 0.87943053, grad/param norm = 1.9886e-01, time/batch = 14.7431s	
18540/29850 (epoch 31.055), train_loss = 0.83882726, grad/param norm = 2.2415e-01, time/batch = 18.9584s	
18541/29850 (epoch 31.057), train_loss = 0.91920203, grad/param norm = 1.9217e-01, time/batch = 18.4536s	
18542/29850 (epoch 31.059), train_loss = 0.93207718, grad/param norm = 2.2048e-01, time/batch = 17.3591s	
18543/29850 (epoch 31.060), train_loss = 0.87460869, grad/param norm = 1.9579e-01, time/batch = 17.6328s	
18544/29850 (epoch 31.062), train_loss = 0.99201032, grad/param norm = 2.4883e-01, time/batch = 17.4741s	
18545/29850 (epoch 31.064), train_loss = 0.94020200, grad/param norm = 2.3014e-01, time/batch = 15.6669s	
18546/29850 (epoch 31.065), train_loss = 0.76367379, grad/param norm = 1.9178e-01, time/batch = 15.8127s	
18547/29850 (epoch 31.067), train_loss = 0.92689723, grad/param norm = 2.0543e-01, time/batch = 17.2148s	
18548/29850 (epoch 31.069), train_loss = 0.92389725, grad/param norm = 2.1071e-01, time/batch = 16.9586s	
18549/29850 (epoch 31.070), train_loss = 0.92320957, grad/param norm = 2.0706e-01, time/batch = 17.8564s	
18550/29850 (epoch 31.072), train_loss = 0.89608834, grad/param norm = 2.2087e-01, time/batch = 17.8929s	
18551/29850 (epoch 31.074), train_loss = 0.95735580, grad/param norm = 1.9550e-01, time/batch = 17.8118s	
18552/29850 (epoch 31.075), train_loss = 0.81622066, grad/param norm = 2.3461e-01, time/batch = 17.1240s	
18553/29850 (epoch 31.077), train_loss = 0.92397874, grad/param norm = 2.1643e-01, time/batch = 16.9580s	
18554/29850 (epoch 31.079), train_loss = 1.11750636, grad/param norm = 3.1653e-01, time/batch = 18.8020s	
18555/29850 (epoch 31.080), train_loss = 1.08447445, grad/param norm = 2.6522e-01, time/batch = 17.3008s	
18556/29850 (epoch 31.082), train_loss = 0.95756543, grad/param norm = 2.2423e-01, time/batch = 18.8647s	
18557/29850 (epoch 31.084), train_loss = 1.08459345, grad/param norm = 2.5077e-01, time/batch = 16.3901s	
18558/29850 (epoch 31.085), train_loss = 1.07909687, grad/param norm = 2.5461e-01, time/batch = 16.5673s	
18559/29850 (epoch 31.087), train_loss = 1.04022281, grad/param norm = 2.3844e-01, time/batch = 15.9604s	
18560/29850 (epoch 31.089), train_loss = 0.92730318, grad/param norm = 2.1970e-01, time/batch = 16.4679s	
18561/29850 (epoch 31.090), train_loss = 0.96115744, grad/param norm = 2.0632e-01, time/batch = 16.8949s	
18562/29850 (epoch 31.092), train_loss = 0.83955539, grad/param norm = 1.8531e-01, time/batch = 16.3758s	
18563/29850 (epoch 31.094), train_loss = 1.04103055, grad/param norm = 2.3169e-01, time/batch = 18.4540s	
18564/29850 (epoch 31.095), train_loss = 0.95681463, grad/param norm = 2.9956e-01, time/batch = 17.8722s	
18565/29850 (epoch 31.097), train_loss = 0.73056014, grad/param norm = 1.8221e-01, time/batch = 17.9691s	
18566/29850 (epoch 31.099), train_loss = 0.76832143, grad/param norm = 2.0245e-01, time/batch = 18.2014s	
18567/29850 (epoch 31.101), train_loss = 0.99306911, grad/param norm = 2.2930e-01, time/batch = 16.8148s	
18568/29850 (epoch 31.102), train_loss = 0.96655883, grad/param norm = 2.4211e-01, time/batch = 19.8612s	
18569/29850 (epoch 31.104), train_loss = 0.87868392, grad/param norm = 2.3099e-01, time/batch = 17.6915s	
18570/29850 (epoch 31.106), train_loss = 0.99522820, grad/param norm = 2.1616e-01, time/batch = 19.0434s	
18571/29850 (epoch 31.107), train_loss = 0.83953924, grad/param norm = 2.0104e-01, time/batch = 16.1887s	
18572/29850 (epoch 31.109), train_loss = 0.90221608, grad/param norm = 2.1659e-01, time/batch = 16.3310s	
18573/29850 (epoch 31.111), train_loss = 0.97214675, grad/param norm = 2.1651e-01, time/batch = 18.7099s	
18574/29850 (epoch 31.112), train_loss = 0.81701255, grad/param norm = 2.0511e-01, time/batch = 18.0424s	
18575/29850 (epoch 31.114), train_loss = 0.86147493, grad/param norm = 2.2558e-01, time/batch = 19.0418s	
18576/29850 (epoch 31.116), train_loss = 0.81777455, grad/param norm = 1.9371e-01, time/batch = 32.2656s	
18577/29850 (epoch 31.117), train_loss = 0.86560260, grad/param norm = 2.0319e-01, time/batch = 16.0025s	
18578/29850 (epoch 31.119), train_loss = 0.86271390, grad/param norm = 1.9297e-01, time/batch = 15.4986s	
18579/29850 (epoch 31.121), train_loss = 0.72090993, grad/param norm = 1.9582e-01, time/batch = 15.1501s	
18580/29850 (epoch 31.122), train_loss = 0.75418000, grad/param norm = 1.6912e-01, time/batch = 15.5337s	
18581/29850 (epoch 31.124), train_loss = 0.81901598, grad/param norm = 2.1751e-01, time/batch = 17.7167s	
18582/29850 (epoch 31.126), train_loss = 0.82614291, grad/param norm = 1.9835e-01, time/batch = 16.2632s	
18583/29850 (epoch 31.127), train_loss = 0.95449531, grad/param norm = 2.5794e-01, time/batch = 18.1364s	
18584/29850 (epoch 31.129), train_loss = 0.84229288, grad/param norm = 1.9954e-01, time/batch = 17.5493s	
18585/29850 (epoch 31.131), train_loss = 0.89477730, grad/param norm = 2.0145e-01, time/batch = 16.5964s	
18586/29850 (epoch 31.132), train_loss = 0.77116696, grad/param norm = 2.2241e-01, time/batch = 19.0078s	
18587/29850 (epoch 31.134), train_loss = 0.84337661, grad/param norm = 2.1643e-01, time/batch = 16.6319s	
18588/29850 (epoch 31.136), train_loss = 0.92728660, grad/param norm = 2.0310e-01, time/batch = 17.8864s	
18589/29850 (epoch 31.137), train_loss = 0.72735487, grad/param norm = 1.9298e-01, time/batch = 15.7761s	
18590/29850 (epoch 31.139), train_loss = 0.87213515, grad/param norm = 2.0748e-01, time/batch = 17.0325s	
18591/29850 (epoch 31.141), train_loss = 0.79607466, grad/param norm = 2.2145e-01, time/batch = 17.7780s	
18592/29850 (epoch 31.142), train_loss = 1.01676535, grad/param norm = 2.3428e-01, time/batch = 17.5204s	
18593/29850 (epoch 31.144), train_loss = 1.12861928, grad/param norm = 2.6151e-01, time/batch = 16.6291s	
18594/29850 (epoch 31.146), train_loss = 1.13096720, grad/param norm = 2.4829e-01, time/batch = 18.4660s	
18595/29850 (epoch 31.147), train_loss = 0.98646537, grad/param norm = 2.3671e-01, time/batch = 16.1098s	
18596/29850 (epoch 31.149), train_loss = 0.92882163, grad/param norm = 2.0894e-01, time/batch = 15.9577s	
18597/29850 (epoch 31.151), train_loss = 0.94130066, grad/param norm = 2.1649e-01, time/batch = 17.9587s	
18598/29850 (epoch 31.152), train_loss = 0.88095339, grad/param norm = 2.1086e-01, time/batch = 17.3077s	
18599/29850 (epoch 31.154), train_loss = 0.85210993, grad/param norm = 2.2468e-01, time/batch = 17.1146s	
18600/29850 (epoch 31.156), train_loss = 0.81684920, grad/param norm = 2.1509e-01, time/batch = 16.7133s	
18601/29850 (epoch 31.157), train_loss = 0.93542115, grad/param norm = 2.1380e-01, time/batch = 19.4534s	
18602/29850 (epoch 31.159), train_loss = 0.85547386, grad/param norm = 2.6639e-01, time/batch = 17.4600s	
18603/29850 (epoch 31.161), train_loss = 0.90809200, grad/param norm = 2.1652e-01, time/batch = 17.8428s	
18604/29850 (epoch 31.162), train_loss = 1.00965207, grad/param norm = 2.2883e-01, time/batch = 19.1295s	
18605/29850 (epoch 31.164), train_loss = 0.92395618, grad/param norm = 2.1949e-01, time/batch = 16.4415s	
18606/29850 (epoch 31.166), train_loss = 0.85115108, grad/param norm = 2.0840e-01, time/batch = 16.9541s	
18607/29850 (epoch 31.168), train_loss = 0.75252550, grad/param norm = 1.8205e-01, time/batch = 17.1254s	
18608/29850 (epoch 31.169), train_loss = 1.03653069, grad/param norm = 2.3604e-01, time/batch = 17.4620s	
18609/29850 (epoch 31.171), train_loss = 0.96628164, grad/param norm = 2.3681e-01, time/batch = 17.7082s	
18610/29850 (epoch 31.173), train_loss = 0.81539648, grad/param norm = 2.0159e-01, time/batch = 16.6292s	
18611/29850 (epoch 31.174), train_loss = 0.92205520, grad/param norm = 2.2772e-01, time/batch = 17.0211s	
18612/29850 (epoch 31.176), train_loss = 0.90560604, grad/param norm = 2.1741e-01, time/batch = 16.3727s	
18613/29850 (epoch 31.178), train_loss = 0.93977409, grad/param norm = 2.3971e-01, time/batch = 15.2089s	
18614/29850 (epoch 31.179), train_loss = 0.76696310, grad/param norm = 2.0686e-01, time/batch = 19.2945s	
18615/29850 (epoch 31.181), train_loss = 0.89852280, grad/param norm = 2.0566e-01, time/batch = 16.4685s	
18616/29850 (epoch 31.183), train_loss = 0.90447348, grad/param norm = 1.8741e-01, time/batch = 17.8602s	
18617/29850 (epoch 31.184), train_loss = 0.94907627, grad/param norm = 2.4214e-01, time/batch = 18.4527s	
18618/29850 (epoch 31.186), train_loss = 0.90085421, grad/param norm = 2.2759e-01, time/batch = 17.6352s	
18619/29850 (epoch 31.188), train_loss = 1.02988971, grad/param norm = 2.4336e-01, time/batch = 17.3589s	
18620/29850 (epoch 31.189), train_loss = 1.00051653, grad/param norm = 2.5017e-01, time/batch = 16.2048s	
18621/29850 (epoch 31.191), train_loss = 0.98847963, grad/param norm = 2.1402e-01, time/batch = 17.3569s	
18622/29850 (epoch 31.193), train_loss = 0.89190643, grad/param norm = 2.1133e-01, time/batch = 19.2166s	
18623/29850 (epoch 31.194), train_loss = 0.96920673, grad/param norm = 2.6118e-01, time/batch = 19.1068s	
18624/29850 (epoch 31.196), train_loss = 0.89214924, grad/param norm = 2.1265e-01, time/batch = 18.4451s	
18625/29850 (epoch 31.198), train_loss = 0.88666405, grad/param norm = 2.1462e-01, time/batch = 18.5391s	
18626/29850 (epoch 31.199), train_loss = 1.10890900, grad/param norm = 2.3223e-01, time/batch = 18.1979s	
18627/29850 (epoch 31.201), train_loss = 0.83176634, grad/param norm = 1.9092e-01, time/batch = 17.2027s	
18628/29850 (epoch 31.203), train_loss = 0.69017444, grad/param norm = 2.1418e-01, time/batch = 16.4857s	
18629/29850 (epoch 31.204), train_loss = 0.91774387, grad/param norm = 2.5823e-01, time/batch = 18.0488s	
18630/29850 (epoch 31.206), train_loss = 0.79355511, grad/param norm = 2.0149e-01, time/batch = 16.1286s	
18631/29850 (epoch 31.208), train_loss = 1.02054587, grad/param norm = 2.2132e-01, time/batch = 17.8565s	
18632/29850 (epoch 31.209), train_loss = 0.78486900, grad/param norm = 1.9370e-01, time/batch = 16.1253s	
18633/29850 (epoch 31.211), train_loss = 0.84317589, grad/param norm = 1.9101e-01, time/batch = 16.6183s	
18634/29850 (epoch 31.213), train_loss = 0.97162843, grad/param norm = 2.3353e-01, time/batch = 18.2633s	
18635/29850 (epoch 31.214), train_loss = 0.79957616, grad/param norm = 1.7531e-01, time/batch = 18.1383s	
18636/29850 (epoch 31.216), train_loss = 0.83353380, grad/param norm = 2.2020e-01, time/batch = 17.3891s	
18637/29850 (epoch 31.218), train_loss = 0.92872159, grad/param norm = 2.1726e-01, time/batch = 17.4538s	
18638/29850 (epoch 31.219), train_loss = 0.95794518, grad/param norm = 2.6121e-01, time/batch = 18.8769s	
18639/29850 (epoch 31.221), train_loss = 0.89739912, grad/param norm = 2.4611e-01, time/batch = 17.8711s	
18640/29850 (epoch 31.223), train_loss = 0.78655434, grad/param norm = 2.3373e-01, time/batch = 17.4491s	
18641/29850 (epoch 31.224), train_loss = 0.76341666, grad/param norm = 1.9697e-01, time/batch = 16.8060s	
18642/29850 (epoch 31.226), train_loss = 0.81248414, grad/param norm = 1.8529e-01, time/batch = 19.5278s	
18643/29850 (epoch 31.228), train_loss = 0.87278868, grad/param norm = 2.2237e-01, time/batch = 18.1116s	
18644/29850 (epoch 31.229), train_loss = 0.72890896, grad/param norm = 1.7696e-01, time/batch = 16.1811s	
18645/29850 (epoch 31.231), train_loss = 0.90083468, grad/param norm = 2.0545e-01, time/batch = 18.7849s	
18646/29850 (epoch 31.233), train_loss = 0.88073110, grad/param norm = 2.3244e-01, time/batch = 17.9755s	
18647/29850 (epoch 31.235), train_loss = 0.81809717, grad/param norm = 1.8191e-01, time/batch = 16.6223s	
18648/29850 (epoch 31.236), train_loss = 1.03516251, grad/param norm = 2.5022e-01, time/batch = 17.1185s	
18649/29850 (epoch 31.238), train_loss = 0.77844113, grad/param norm = 1.9801e-01, time/batch = 18.2227s	
18650/29850 (epoch 31.240), train_loss = 0.75027018, grad/param norm = 1.9520e-01, time/batch = 16.2881s	
18651/29850 (epoch 31.241), train_loss = 0.94106049, grad/param norm = 3.0735e-01, time/batch = 17.9533s	
18652/29850 (epoch 31.243), train_loss = 0.94425150, grad/param norm = 2.4881e-01, time/batch = 17.8062s	
18653/29850 (epoch 31.245), train_loss = 0.82971216, grad/param norm = 2.0922e-01, time/batch = 16.1427s	
18654/29850 (epoch 31.246), train_loss = 0.75148402, grad/param norm = 1.8240e-01, time/batch = 14.9345s	
18655/29850 (epoch 31.248), train_loss = 0.73959796, grad/param norm = 1.7954e-01, time/batch = 18.7018s	
18656/29850 (epoch 31.250), train_loss = 0.85682804, grad/param norm = 1.8717e-01, time/batch = 16.4774s	
18657/29850 (epoch 31.251), train_loss = 0.75004792, grad/param norm = 2.2211e-01, time/batch = 17.2885s	
18658/29850 (epoch 31.253), train_loss = 0.71591960, grad/param norm = 2.0899e-01, time/batch = 18.2792s	
18659/29850 (epoch 31.255), train_loss = 0.79760901, grad/param norm = 1.9944e-01, time/batch = 18.9446s	
18660/29850 (epoch 31.256), train_loss = 0.92452626, grad/param norm = 2.0747e-01, time/batch = 18.2976s	
18661/29850 (epoch 31.258), train_loss = 0.90865692, grad/param norm = 2.1251e-01, time/batch = 15.2765s	
18662/29850 (epoch 31.260), train_loss = 0.86178343, grad/param norm = 1.9332e-01, time/batch = 18.8723s	
18663/29850 (epoch 31.261), train_loss = 0.78866685, grad/param norm = 2.1794e-01, time/batch = 17.6097s	
18664/29850 (epoch 31.263), train_loss = 0.80081024, grad/param norm = 2.0623e-01, time/batch = 18.0410s	
18665/29850 (epoch 31.265), train_loss = 0.86015452, grad/param norm = 2.3744e-01, time/batch = 17.6285s	
18666/29850 (epoch 31.266), train_loss = 0.86581110, grad/param norm = 2.1382e-01, time/batch = 20.3638s	
18667/29850 (epoch 31.268), train_loss = 0.85011245, grad/param norm = 2.3644e-01, time/batch = 17.0232s	
18668/29850 (epoch 31.270), train_loss = 0.83205776, grad/param norm = 2.3164e-01, time/batch = 18.7760s	
18669/29850 (epoch 31.271), train_loss = 0.92943397, grad/param norm = 2.0787e-01, time/batch = 18.8622s	
18670/29850 (epoch 31.273), train_loss = 0.78766096, grad/param norm = 2.4937e-01, time/batch = 17.7718s	
18671/29850 (epoch 31.275), train_loss = 0.77051291, grad/param norm = 2.0178e-01, time/batch = 17.6987s	
18672/29850 (epoch 31.276), train_loss = 0.75847689, grad/param norm = 1.8070e-01, time/batch = 17.8435s	
18673/29850 (epoch 31.278), train_loss = 0.84030724, grad/param norm = 2.1167e-01, time/batch = 18.3877s	
18674/29850 (epoch 31.280), train_loss = 1.01167800, grad/param norm = 2.5984e-01, time/batch = 18.1975s	
18675/29850 (epoch 31.281), train_loss = 0.89667793, grad/param norm = 2.0448e-01, time/batch = 15.6127s	
18676/29850 (epoch 31.283), train_loss = 1.01409158, grad/param norm = 2.5399e-01, time/batch = 17.2816s	
18677/29850 (epoch 31.285), train_loss = 0.94745353, grad/param norm = 2.1015e-01, time/batch = 17.2693s	
18678/29850 (epoch 31.286), train_loss = 0.97712216, grad/param norm = 2.2488e-01, time/batch = 17.8644s	
18679/29850 (epoch 31.288), train_loss = 1.00171040, grad/param norm = 3.3258e-01, time/batch = 16.9542s	
18680/29850 (epoch 31.290), train_loss = 0.90225373, grad/param norm = 2.3442e-01, time/batch = 18.1152s	
18681/29850 (epoch 31.291), train_loss = 1.10129409, grad/param norm = 2.3251e-01, time/batch = 16.0856s	
18682/29850 (epoch 31.293), train_loss = 0.99819486, grad/param norm = 2.6605e-01, time/batch = 17.5421s	
18683/29850 (epoch 31.295), train_loss = 1.06851282, grad/param norm = 2.5149e-01, time/batch = 18.1370s	
18684/29850 (epoch 31.296), train_loss = 0.80098899, grad/param norm = 1.9112e-01, time/batch = 16.7761s	
18685/29850 (epoch 31.298), train_loss = 0.68945309, grad/param norm = 1.8594e-01, time/batch = 18.2981s	
18686/29850 (epoch 31.300), train_loss = 0.78598583, grad/param norm = 2.0560e-01, time/batch = 19.6273s	
18687/29850 (epoch 31.302), train_loss = 0.77244448, grad/param norm = 1.9294e-01, time/batch = 18.0395s	
18688/29850 (epoch 31.303), train_loss = 0.82690399, grad/param norm = 2.1460e-01, time/batch = 19.7799s	
18689/29850 (epoch 31.305), train_loss = 0.94040127, grad/param norm = 2.1977e-01, time/batch = 17.7126s	
18690/29850 (epoch 31.307), train_loss = 0.96513058, grad/param norm = 2.0578e-01, time/batch = 18.2092s	
18691/29850 (epoch 31.308), train_loss = 0.81604975, grad/param norm = 2.7518e-01, time/batch = 16.9516s	
18692/29850 (epoch 31.310), train_loss = 0.88591383, grad/param norm = 2.1729e-01, time/batch = 17.3895s	
18693/29850 (epoch 31.312), train_loss = 0.94442642, grad/param norm = 2.0360e-01, time/batch = 19.2148s	
18694/29850 (epoch 31.313), train_loss = 0.90296383, grad/param norm = 2.1680e-01, time/batch = 15.7662s	
18695/29850 (epoch 31.315), train_loss = 0.88529103, grad/param norm = 2.0377e-01, time/batch = 16.2095s	
18696/29850 (epoch 31.317), train_loss = 0.90071041, grad/param norm = 2.3550e-01, time/batch = 15.5084s	
18697/29850 (epoch 31.318), train_loss = 0.88845521, grad/param norm = 2.1615e-01, time/batch = 18.7083s	
18698/29850 (epoch 31.320), train_loss = 0.81329033, grad/param norm = 1.9049e-01, time/batch = 17.1888s	
18699/29850 (epoch 31.322), train_loss = 1.04303891, grad/param norm = 2.6730e-01, time/batch = 17.0162s	
18700/29850 (epoch 31.323), train_loss = 0.93736480, grad/param norm = 2.2724e-01, time/batch = 19.2023s	
18701/29850 (epoch 31.325), train_loss = 0.98505027, grad/param norm = 2.1770e-01, time/batch = 15.3866s	
18702/29850 (epoch 31.327), train_loss = 1.13745581, grad/param norm = 2.3726e-01, time/batch = 19.0375s	
18703/29850 (epoch 31.328), train_loss = 1.02832867, grad/param norm = 2.7117e-01, time/batch = 17.2240s	
18704/29850 (epoch 31.330), train_loss = 0.94724132, grad/param norm = 1.9726e-01, time/batch = 17.3761s	
18705/29850 (epoch 31.332), train_loss = 0.84492167, grad/param norm = 2.1677e-01, time/batch = 16.8627s	
18706/29850 (epoch 31.333), train_loss = 0.95557556, grad/param norm = 2.2733e-01, time/batch = 18.8885s	
18707/29850 (epoch 31.335), train_loss = 0.98751430, grad/param norm = 2.1339e-01, time/batch = 18.1326s	
18708/29850 (epoch 31.337), train_loss = 0.90566006, grad/param norm = 2.2401e-01, time/batch = 16.4697s	
18709/29850 (epoch 31.338), train_loss = 0.92436785, grad/param norm = 1.9793e-01, time/batch = 17.9684s	
18710/29850 (epoch 31.340), train_loss = 0.79322051, grad/param norm = 1.9506e-01, time/batch = 15.0980s	
18711/29850 (epoch 31.342), train_loss = 0.91562953, grad/param norm = 2.6380e-01, time/batch = 17.3548s	
18712/29850 (epoch 31.343), train_loss = 0.91991816, grad/param norm = 2.5322e-01, time/batch = 17.8079s	
18713/29850 (epoch 31.345), train_loss = 0.98872352, grad/param norm = 2.7252e-01, time/batch = 17.2136s	
18714/29850 (epoch 31.347), train_loss = 0.99688535, grad/param norm = 2.3036e-01, time/batch = 15.9553s	
18715/29850 (epoch 31.348), train_loss = 0.86040220, grad/param norm = 2.4236e-01, time/batch = 18.2837s	
18716/29850 (epoch 31.350), train_loss = 0.95669746, grad/param norm = 2.5646e-01, time/batch = 18.1281s	
18717/29850 (epoch 31.352), train_loss = 0.85542729, grad/param norm = 2.2169e-01, time/batch = 17.2179s	
18718/29850 (epoch 31.353), train_loss = 0.96075483, grad/param norm = 2.3060e-01, time/batch = 16.4529s	
18719/29850 (epoch 31.355), train_loss = 0.86341233, grad/param norm = 2.1763e-01, time/batch = 17.0571s	
18720/29850 (epoch 31.357), train_loss = 0.97476543, grad/param norm = 2.0739e-01, time/batch = 16.9681s	
18721/29850 (epoch 31.358), train_loss = 0.82812421, grad/param norm = 2.1411e-01, time/batch = 17.3850s	
18722/29850 (epoch 31.360), train_loss = 0.87901905, grad/param norm = 2.0554e-01, time/batch = 17.8649s	
18723/29850 (epoch 31.362), train_loss = 0.89382996, grad/param norm = 2.1213e-01, time/batch = 17.1401s	
18724/29850 (epoch 31.363), train_loss = 0.94614226, grad/param norm = 2.1421e-01, time/batch = 18.8699s	
18725/29850 (epoch 31.365), train_loss = 1.05498503, grad/param norm = 2.4977e-01, time/batch = 17.9564s	
18726/29850 (epoch 31.367), train_loss = 0.84416906, grad/param norm = 2.0854e-01, time/batch = 16.6193s	
18727/29850 (epoch 31.369), train_loss = 0.77354714, grad/param norm = 2.0276e-01, time/batch = 18.9546s	
18728/29850 (epoch 31.370), train_loss = 0.72011826, grad/param norm = 2.0079e-01, time/batch = 17.6170s	
18729/29850 (epoch 31.372), train_loss = 0.99666471, grad/param norm = 2.3163e-01, time/batch = 18.5495s	
18730/29850 (epoch 31.374), train_loss = 0.95428778, grad/param norm = 2.0390e-01, time/batch = 18.4701s	
18731/29850 (epoch 31.375), train_loss = 0.91643216, grad/param norm = 2.0792e-01, time/batch = 17.9347s	
18732/29850 (epoch 31.377), train_loss = 0.84028778, grad/param norm = 2.2648e-01, time/batch = 19.4250s	
18733/29850 (epoch 31.379), train_loss = 1.02307766, grad/param norm = 2.3918e-01, time/batch = 17.5843s	
18734/29850 (epoch 31.380), train_loss = 0.95277442, grad/param norm = 2.2275e-01, time/batch = 16.3719s	
18735/29850 (epoch 31.382), train_loss = 0.93345755, grad/param norm = 2.4284e-01, time/batch = 16.3472s	
18736/29850 (epoch 31.384), train_loss = 0.97397060, grad/param norm = 2.3915e-01, time/batch = 18.9570s	
18737/29850 (epoch 31.385), train_loss = 0.93142749, grad/param norm = 2.3140e-01, time/batch = 17.4588s	
18738/29850 (epoch 31.387), train_loss = 0.94139297, grad/param norm = 2.2232e-01, time/batch = 16.9293s	
18739/29850 (epoch 31.389), train_loss = 1.03273265, grad/param norm = 2.2726e-01, time/batch = 18.5522s	
18740/29850 (epoch 31.390), train_loss = 0.95838979, grad/param norm = 1.9063e-01, time/batch = 17.8579s	
18741/29850 (epoch 31.392), train_loss = 0.88399558, grad/param norm = 2.2025e-01, time/batch = 19.6981s	
18742/29850 (epoch 31.394), train_loss = 0.97484100, grad/param norm = 2.0504e-01, time/batch = 18.9265s	
18743/29850 (epoch 31.395), train_loss = 0.85698903, grad/param norm = 2.3724e-01, time/batch = 18.5562s	
18744/29850 (epoch 31.397), train_loss = 0.78779234, grad/param norm = 2.2170e-01, time/batch = 17.9687s	
18745/29850 (epoch 31.399), train_loss = 0.82928231, grad/param norm = 2.0324e-01, time/batch = 16.1851s	
18746/29850 (epoch 31.400), train_loss = 1.15857060, grad/param norm = 2.3344e-01, time/batch = 18.7861s	
18747/29850 (epoch 31.402), train_loss = 1.07108471, grad/param norm = 2.1413e-01, time/batch = 15.5540s	
18748/29850 (epoch 31.404), train_loss = 0.91877554, grad/param norm = 2.1450e-01, time/batch = 17.1124s	
18749/29850 (epoch 31.405), train_loss = 0.85898375, grad/param norm = 2.3985e-01, time/batch = 16.7700s	
18750/29850 (epoch 31.407), train_loss = 0.82421457, grad/param norm = 1.8427e-01, time/batch = 18.0552s	
18751/29850 (epoch 31.409), train_loss = 0.95621914, grad/param norm = 2.4622e-01, time/batch = 17.3819s	
18752/29850 (epoch 31.410), train_loss = 1.03212160, grad/param norm = 2.4629e-01, time/batch = 16.8445s	
18753/29850 (epoch 31.412), train_loss = 1.02017485, grad/param norm = 2.2101e-01, time/batch = 19.6988s	
18754/29850 (epoch 31.414), train_loss = 0.92736534, grad/param norm = 2.3235e-01, time/batch = 18.1311s	
18755/29850 (epoch 31.415), train_loss = 0.90889200, grad/param norm = 2.0692e-01, time/batch = 17.1985s	
18756/29850 (epoch 31.417), train_loss = 1.05939304, grad/param norm = 2.6410e-01, time/batch = 17.7914s	
18757/29850 (epoch 31.419), train_loss = 0.88333575, grad/param norm = 1.9601e-01, time/batch = 17.4529s	
18758/29850 (epoch 31.420), train_loss = 0.90053932, grad/param norm = 2.1982e-01, time/batch = 16.7902s	
18759/29850 (epoch 31.422), train_loss = 0.89642212, grad/param norm = 2.4074e-01, time/batch = 16.9417s	
18760/29850 (epoch 31.424), train_loss = 0.84211933, grad/param norm = 2.1846e-01, time/batch = 19.2096s	
18761/29850 (epoch 31.425), train_loss = 0.99657976, grad/param norm = 2.0491e-01, time/batch = 19.7126s	
18762/29850 (epoch 31.427), train_loss = 0.74588464, grad/param norm = 2.1499e-01, time/batch = 15.9515s	
18763/29850 (epoch 31.429), train_loss = 0.81723405, grad/param norm = 2.2159e-01, time/batch = 18.2328s	
18764/29850 (epoch 31.430), train_loss = 0.74832595, grad/param norm = 1.7566e-01, time/batch = 17.1481s	
18765/29850 (epoch 31.432), train_loss = 0.83747899, grad/param norm = 2.4631e-01, time/batch = 17.3828s	
18766/29850 (epoch 31.434), train_loss = 0.82089284, grad/param norm = 1.8234e-01, time/batch = 19.4625s	
18767/29850 (epoch 31.436), train_loss = 0.91239736, grad/param norm = 2.6158e-01, time/batch = 17.7107s	
18768/29850 (epoch 31.437), train_loss = 0.96421394, grad/param norm = 2.1659e-01, time/batch = 18.3755s	
18769/29850 (epoch 31.439), train_loss = 0.94339565, grad/param norm = 2.0288e-01, time/batch = 18.9321s	
18770/29850 (epoch 31.441), train_loss = 0.92707618, grad/param norm = 2.4131e-01, time/batch = 18.9549s	
18771/29850 (epoch 31.442), train_loss = 0.87763574, grad/param norm = 1.9428e-01, time/batch = 15.8680s	
18772/29850 (epoch 31.444), train_loss = 0.94313467, grad/param norm = 2.6476e-01, time/batch = 16.8768s	
18773/29850 (epoch 31.446), train_loss = 0.97369025, grad/param norm = 2.2795e-01, time/batch = 18.6254s	
18774/29850 (epoch 31.447), train_loss = 0.97933779, grad/param norm = 2.1848e-01, time/batch = 18.4608s	
18775/29850 (epoch 31.449), train_loss = 0.92620892, grad/param norm = 2.2770e-01, time/batch = 15.0316s	
18776/29850 (epoch 31.451), train_loss = 0.72267364, grad/param norm = 1.9603e-01, time/batch = 16.5717s	
18777/29850 (epoch 31.452), train_loss = 0.64851897, grad/param norm = 1.7656e-01, time/batch = 17.9519s	
18778/29850 (epoch 31.454), train_loss = 0.75832879, grad/param norm = 1.7858e-01, time/batch = 18.5400s	
18779/29850 (epoch 31.456), train_loss = 0.97542830, grad/param norm = 2.2145e-01, time/batch = 32.2633s	
18780/29850 (epoch 31.457), train_loss = 0.97829215, grad/param norm = 2.7788e-01, time/batch = 17.5235s	
18781/29850 (epoch 31.459), train_loss = 1.04964026, grad/param norm = 2.2254e-01, time/batch = 15.6098s	
18782/29850 (epoch 31.461), train_loss = 1.03142213, grad/param norm = 2.1643e-01, time/batch = 19.0305s	
18783/29850 (epoch 31.462), train_loss = 1.04495202, grad/param norm = 2.3923e-01, time/batch = 17.6192s	
18784/29850 (epoch 31.464), train_loss = 0.94892370, grad/param norm = 2.0226e-01, time/batch = 17.2670s	
18785/29850 (epoch 31.466), train_loss = 0.78061117, grad/param norm = 1.9762e-01, time/batch = 17.0815s	
18786/29850 (epoch 31.467), train_loss = 0.87145019, grad/param norm = 2.2346e-01, time/batch = 17.4730s	
18787/29850 (epoch 31.469), train_loss = 0.87460252, grad/param norm = 2.3530e-01, time/batch = 20.0397s	
18788/29850 (epoch 31.471), train_loss = 0.87165695, grad/param norm = 2.1482e-01, time/batch = 16.7138s	
18789/29850 (epoch 31.472), train_loss = 0.82898323, grad/param norm = 2.1063e-01, time/batch = 17.4539s	
18790/29850 (epoch 31.474), train_loss = 0.99613100, grad/param norm = 2.0919e-01, time/batch = 17.6825s	
18791/29850 (epoch 31.476), train_loss = 0.91487476, grad/param norm = 1.7903e-01, time/batch = 18.4434s	
18792/29850 (epoch 31.477), train_loss = 0.93144833, grad/param norm = 2.2803e-01, time/batch = 19.3742s	
18793/29850 (epoch 31.479), train_loss = 1.09526330, grad/param norm = 2.4766e-01, time/batch = 17.5445s	
18794/29850 (epoch 31.481), train_loss = 0.87785742, grad/param norm = 2.0096e-01, time/batch = 19.3557s	
18795/29850 (epoch 31.482), train_loss = 0.82151862, grad/param norm = 1.9497e-01, time/batch = 16.3518s	
18796/29850 (epoch 31.484), train_loss = 0.85376725, grad/param norm = 2.0993e-01, time/batch = 17.3077s	
18797/29850 (epoch 31.486), train_loss = 0.93721894, grad/param norm = 2.5997e-01, time/batch = 19.3678s	
18798/29850 (epoch 31.487), train_loss = 0.93293955, grad/param norm = 2.2561e-01, time/batch = 16.7791s	
18799/29850 (epoch 31.489), train_loss = 0.92447122, grad/param norm = 2.1425e-01, time/batch = 19.5306s	
18800/29850 (epoch 31.491), train_loss = 0.80197026, grad/param norm = 1.8787e-01, time/batch = 18.8794s	
18801/29850 (epoch 31.492), train_loss = 0.92461956, grad/param norm = 2.3109e-01, time/batch = 17.0117s	
18802/29850 (epoch 31.494), train_loss = 0.97241501, grad/param norm = 2.3340e-01, time/batch = 15.6874s	
18803/29850 (epoch 31.496), train_loss = 1.01500584, grad/param norm = 2.0271e-01, time/batch = 18.5514s	
18804/29850 (epoch 31.497), train_loss = 0.93764648, grad/param norm = 2.0095e-01, time/batch = 18.5461s	
18805/29850 (epoch 31.499), train_loss = 0.93654645, grad/param norm = 2.1861e-01, time/batch = 15.6945s	
18806/29850 (epoch 31.501), train_loss = 0.82436230, grad/param norm = 2.1868e-01, time/batch = 17.2129s	
18807/29850 (epoch 31.503), train_loss = 0.94696301, grad/param norm = 2.1344e-01, time/batch = 18.5515s	
18808/29850 (epoch 31.504), train_loss = 1.11235568, grad/param norm = 2.2019e-01, time/batch = 17.2119s	
18809/29850 (epoch 31.506), train_loss = 1.07405299, grad/param norm = 2.1757e-01, time/batch = 18.2265s	
18810/29850 (epoch 31.508), train_loss = 0.91611819, grad/param norm = 1.8713e-01, time/batch = 17.3936s	
18811/29850 (epoch 31.509), train_loss = 0.74105875, grad/param norm = 2.0405e-01, time/batch = 18.1015s	
18812/29850 (epoch 31.511), train_loss = 0.93427100, grad/param norm = 2.2673e-01, time/batch = 18.2067s	
18813/29850 (epoch 31.513), train_loss = 0.91347262, grad/param norm = 2.5347e-01, time/batch = 16.8717s	
18814/29850 (epoch 31.514), train_loss = 0.82378642, grad/param norm = 2.1686e-01, time/batch = 17.9693s	
18815/29850 (epoch 31.516), train_loss = 0.86980360, grad/param norm = 1.9488e-01, time/batch = 15.7286s	
18816/29850 (epoch 31.518), train_loss = 0.74634524, grad/param norm = 2.0140e-01, time/batch = 18.3795s	
18817/29850 (epoch 31.519), train_loss = 0.73236883, grad/param norm = 1.7547e-01, time/batch = 16.9699s	
18818/29850 (epoch 31.521), train_loss = 0.66315824, grad/param norm = 1.7643e-01, time/batch = 17.5254s	
18819/29850 (epoch 31.523), train_loss = 0.73716333, grad/param norm = 1.6871e-01, time/batch = 19.2271s	
18820/29850 (epoch 31.524), train_loss = 0.81785562, grad/param norm = 2.2432e-01, time/batch = 16.5276s	
18821/29850 (epoch 31.526), train_loss = 0.88613271, grad/param norm = 2.0498e-01, time/batch = 18.7724s	
18822/29850 (epoch 31.528), train_loss = 0.99882633, grad/param norm = 2.3918e-01, time/batch = 16.7923s	
18823/29850 (epoch 31.529), train_loss = 0.95218430, grad/param norm = 2.5068e-01, time/batch = 17.4653s	
18824/29850 (epoch 31.531), train_loss = 0.91517174, grad/param norm = 2.5321e-01, time/batch = 19.1407s	
18825/29850 (epoch 31.533), train_loss = 0.89616487, grad/param norm = 2.3040e-01, time/batch = 16.9678s	
18826/29850 (epoch 31.534), train_loss = 0.95388827, grad/param norm = 2.3366e-01, time/batch = 18.6426s	
18827/29850 (epoch 31.536), train_loss = 0.83533674, grad/param norm = 2.2134e-01, time/batch = 17.6325s	
18828/29850 (epoch 31.538), train_loss = 1.02788432, grad/param norm = 2.5646e-01, time/batch = 18.1138s	
18829/29850 (epoch 31.539), train_loss = 1.06024522, grad/param norm = 2.3516e-01, time/batch = 16.4795s	
18830/29850 (epoch 31.541), train_loss = 0.68352754, grad/param norm = 1.9431e-01, time/batch = 16.1999s	
18831/29850 (epoch 31.543), train_loss = 0.86167680, grad/param norm = 2.1143e-01, time/batch = 15.7749s	
18832/29850 (epoch 31.544), train_loss = 0.97803113, grad/param norm = 2.3954e-01, time/batch = 16.2138s	
18833/29850 (epoch 31.546), train_loss = 0.98651807, grad/param norm = 2.3821e-01, time/batch = 14.9439s	
18834/29850 (epoch 31.548), train_loss = 0.75834250, grad/param norm = 1.9395e-01, time/batch = 14.8622s	
18835/29850 (epoch 31.549), train_loss = 0.85135645, grad/param norm = 1.9254e-01, time/batch = 15.8872s	
18836/29850 (epoch 31.551), train_loss = 0.77054324, grad/param norm = 1.8424e-01, time/batch = 15.4309s	
18837/29850 (epoch 31.553), train_loss = 0.91634017, grad/param norm = 2.1547e-01, time/batch = 14.5869s	
18838/29850 (epoch 31.554), train_loss = 0.75074556, grad/param norm = 1.8180e-01, time/batch = 14.7668s	
18839/29850 (epoch 31.556), train_loss = 0.78557298, grad/param norm = 2.0586e-01, time/batch = 14.7104s	
18840/29850 (epoch 31.558), train_loss = 0.80769797, grad/param norm = 1.8246e-01, time/batch = 16.6377s	
18841/29850 (epoch 31.559), train_loss = 0.84154472, grad/param norm = 1.9740e-01, time/batch = 17.7983s	
18842/29850 (epoch 31.561), train_loss = 0.93035749, grad/param norm = 2.4486e-01, time/batch = 18.8599s	
18843/29850 (epoch 31.563), train_loss = 0.93037364, grad/param norm = 2.3060e-01, time/batch = 16.9061s	
18844/29850 (epoch 31.564), train_loss = 0.85081073, grad/param norm = 2.2280e-01, time/batch = 18.5305s	
18845/29850 (epoch 31.566), train_loss = 0.89887160, grad/param norm = 2.0837e-01, time/batch = 15.6169s	
18846/29850 (epoch 31.568), train_loss = 0.99092091, grad/param norm = 2.1393e-01, time/batch = 18.5467s	
18847/29850 (epoch 31.570), train_loss = 0.96151666, grad/param norm = 2.5446e-01, time/batch = 16.6771s	
18848/29850 (epoch 31.571), train_loss = 0.99739527, grad/param norm = 2.3163e-01, time/batch = 17.7232s	
18849/29850 (epoch 31.573), train_loss = 1.05392916, grad/param norm = 2.3301e-01, time/batch = 18.3849s	
18850/29850 (epoch 31.575), train_loss = 1.05712481, grad/param norm = 2.1390e-01, time/batch = 17.4341s	
18851/29850 (epoch 31.576), train_loss = 1.00084128, grad/param norm = 2.6347e-01, time/batch = 18.8662s	
18852/29850 (epoch 31.578), train_loss = 0.85054424, grad/param norm = 2.1655e-01, time/batch = 18.3788s	
18853/29850 (epoch 31.580), train_loss = 1.01433584, grad/param norm = 2.4242e-01, time/batch = 16.6583s	
18854/29850 (epoch 31.581), train_loss = 0.82652135, grad/param norm = 2.1911e-01, time/batch = 20.2072s	
18855/29850 (epoch 31.583), train_loss = 0.88825284, grad/param norm = 2.1559e-01, time/batch = 17.9811s	
18856/29850 (epoch 31.585), train_loss = 0.92498747, grad/param norm = 2.2431e-01, time/batch = 15.5420s	
18857/29850 (epoch 31.586), train_loss = 0.93039035, grad/param norm = 2.3576e-01, time/batch = 17.4675s	
18858/29850 (epoch 31.588), train_loss = 0.82251958, grad/param norm = 1.9800e-01, time/batch = 18.8098s	
18859/29850 (epoch 31.590), train_loss = 0.84608071, grad/param norm = 1.9957e-01, time/batch = 17.6391s	
18860/29850 (epoch 31.591), train_loss = 0.88282448, grad/param norm = 2.1008e-01, time/batch = 16.4677s	
18861/29850 (epoch 31.593), train_loss = 0.82868018, grad/param norm = 2.1023e-01, time/batch = 18.5349s	
18862/29850 (epoch 31.595), train_loss = 0.76465326, grad/param norm = 1.6203e-01, time/batch = 19.4647s	
18863/29850 (epoch 31.596), train_loss = 0.78103715, grad/param norm = 2.0143e-01, time/batch = 17.8584s	
18864/29850 (epoch 31.598), train_loss = 0.88482896, grad/param norm = 2.0654e-01, time/batch = 17.1302s	
18865/29850 (epoch 31.600), train_loss = 0.90786712, grad/param norm = 2.1284e-01, time/batch = 17.1533s	
18866/29850 (epoch 31.601), train_loss = 0.77314957, grad/param norm = 1.8198e-01, time/batch = 18.8795s	
18867/29850 (epoch 31.603), train_loss = 0.83946234, grad/param norm = 1.9780e-01, time/batch = 18.7091s	
18868/29850 (epoch 31.605), train_loss = 0.86501974, grad/param norm = 2.0419e-01, time/batch = 18.1187s	
18869/29850 (epoch 31.606), train_loss = 0.63621150, grad/param norm = 1.8333e-01, time/batch = 16.8648s	
18870/29850 (epoch 31.608), train_loss = 0.78015104, grad/param norm = 2.0171e-01, time/batch = 16.9500s	
18871/29850 (epoch 31.610), train_loss = 0.85300760, grad/param norm = 2.2313e-01, time/batch = 19.6102s	
18872/29850 (epoch 31.611), train_loss = 0.78889625, grad/param norm = 1.9075e-01, time/batch = 16.8105s	
18873/29850 (epoch 31.613), train_loss = 0.67107752, grad/param norm = 1.6979e-01, time/batch = 17.6065s	
18874/29850 (epoch 31.615), train_loss = 0.76872670, grad/param norm = 1.8533e-01, time/batch = 16.2799s	
18875/29850 (epoch 31.616), train_loss = 0.78403968, grad/param norm = 2.2709e-01, time/batch = 19.8690s	
18876/29850 (epoch 31.618), train_loss = 0.83299750, grad/param norm = 1.8319e-01, time/batch = 18.9554s	
18877/29850 (epoch 31.620), train_loss = 0.90398127, grad/param norm = 2.2206e-01, time/batch = 14.7425s	
18878/29850 (epoch 31.621), train_loss = 1.01560900, grad/param norm = 2.3488e-01, time/batch = 19.0382s	
18879/29850 (epoch 31.623), train_loss = 0.94509970, grad/param norm = 2.1080e-01, time/batch = 19.1139s	
18880/29850 (epoch 31.625), train_loss = 0.88968851, grad/param norm = 2.1731e-01, time/batch = 16.3710s	
18881/29850 (epoch 31.626), train_loss = 0.89179408, grad/param norm = 2.2378e-01, time/batch = 18.1268s	
18882/29850 (epoch 31.628), train_loss = 0.84875420, grad/param norm = 2.0180e-01, time/batch = 17.8844s	
18883/29850 (epoch 31.630), train_loss = 0.90576658, grad/param norm = 2.3420e-01, time/batch = 17.7691s	
18884/29850 (epoch 31.631), train_loss = 0.88034992, grad/param norm = 2.0722e-01, time/batch = 17.2894s	
18885/29850 (epoch 31.633), train_loss = 0.92625511, grad/param norm = 2.4115e-01, time/batch = 17.0624s	
18886/29850 (epoch 31.635), train_loss = 0.83381827, grad/param norm = 2.0662e-01, time/batch = 16.9445s	
18887/29850 (epoch 31.637), train_loss = 0.81507057, grad/param norm = 2.0894e-01, time/batch = 17.1719s	
18888/29850 (epoch 31.638), train_loss = 0.93180039, grad/param norm = 2.1968e-01, time/batch = 18.9581s	
18889/29850 (epoch 31.640), train_loss = 1.03327803, grad/param norm = 2.5269e-01, time/batch = 17.4509s	
18890/29850 (epoch 31.642), train_loss = 0.80244616, grad/param norm = 1.8743e-01, time/batch = 17.8667s	
18891/29850 (epoch 31.643), train_loss = 0.80736686, grad/param norm = 2.2181e-01, time/batch = 15.6458s	
18892/29850 (epoch 31.645), train_loss = 0.88233053, grad/param norm = 2.1963e-01, time/batch = 19.4617s	
18893/29850 (epoch 31.647), train_loss = 1.00982674, grad/param norm = 2.3573e-01, time/batch = 17.3778s	
18894/29850 (epoch 31.648), train_loss = 0.77768991, grad/param norm = 1.8406e-01, time/batch = 16.3381s	
18895/29850 (epoch 31.650), train_loss = 0.89838245, grad/param norm = 2.1287e-01, time/batch = 18.6106s	
18896/29850 (epoch 31.652), train_loss = 0.87264290, grad/param norm = 2.5900e-01, time/batch = 16.0533s	
18897/29850 (epoch 31.653), train_loss = 0.96504970, grad/param norm = 2.1783e-01, time/batch = 16.2045s	
18898/29850 (epoch 31.655), train_loss = 0.89249088, grad/param norm = 1.8397e-01, time/batch = 17.2087s	
18899/29850 (epoch 31.657), train_loss = 0.87185077, grad/param norm = 2.1149e-01, time/batch = 18.3813s	
18900/29850 (epoch 31.658), train_loss = 0.99341390, grad/param norm = 2.2373e-01, time/batch = 17.3681s	
18901/29850 (epoch 31.660), train_loss = 0.86391748, grad/param norm = 2.1862e-01, time/batch = 15.4372s	
18902/29850 (epoch 31.662), train_loss = 0.97925284, grad/param norm = 2.3335e-01, time/batch = 18.2140s	
18903/29850 (epoch 31.663), train_loss = 1.07875388, grad/param norm = 2.3208e-01, time/batch = 18.6149s	
18904/29850 (epoch 31.665), train_loss = 1.02441452, grad/param norm = 2.4133e-01, time/batch = 15.6996s	
18905/29850 (epoch 31.667), train_loss = 0.96547529, grad/param norm = 2.7712e-01, time/batch = 18.9643s	
18906/29850 (epoch 31.668), train_loss = 0.85844209, grad/param norm = 2.6702e-01, time/batch = 17.2301s	
18907/29850 (epoch 31.670), train_loss = 1.01745850, grad/param norm = 3.1387e-01, time/batch = 18.5333s	
18908/29850 (epoch 31.672), train_loss = 0.98302501, grad/param norm = 2.6764e-01, time/batch = 17.1382s	
18909/29850 (epoch 31.673), train_loss = 0.91933950, grad/param norm = 2.3837e-01, time/batch = 19.0381s	
18910/29850 (epoch 31.675), train_loss = 0.79197773, grad/param norm = 1.9148e-01, time/batch = 18.9558s	
18911/29850 (epoch 31.677), train_loss = 0.86598455, grad/param norm = 2.3073e-01, time/batch = 18.0428s	
18912/29850 (epoch 31.678), train_loss = 0.89591259, grad/param norm = 2.1080e-01, time/batch = 19.2890s	
18913/29850 (epoch 31.680), train_loss = 0.86810235, grad/param norm = 1.8836e-01, time/batch = 20.2678s	
18914/29850 (epoch 31.682), train_loss = 0.89782082, grad/param norm = 2.3284e-01, time/batch = 16.6827s	
18915/29850 (epoch 31.683), train_loss = 1.02894095, grad/param norm = 2.3179e-01, time/batch = 16.1090s	
18916/29850 (epoch 31.685), train_loss = 1.09747216, grad/param norm = 2.9473e-01, time/batch = 16.4718s	
18917/29850 (epoch 31.687), train_loss = 0.95014585, grad/param norm = 2.3004e-01, time/batch = 17.2087s	
18918/29850 (epoch 31.688), train_loss = 0.80438546, grad/param norm = 2.1477e-01, time/batch = 18.2162s	
18919/29850 (epoch 31.690), train_loss = 0.79110769, grad/param norm = 2.0634e-01, time/batch = 16.7231s	
18920/29850 (epoch 31.692), train_loss = 1.00164447, grad/param norm = 2.2315e-01, time/batch = 18.7093s	
18921/29850 (epoch 31.693), train_loss = 0.88731625, grad/param norm = 1.9565e-01, time/batch = 15.9793s	
18922/29850 (epoch 31.695), train_loss = 0.78103643, grad/param norm = 1.7980e-01, time/batch = 18.9581s	
18923/29850 (epoch 31.697), train_loss = 0.89615251, grad/param norm = 2.0663e-01, time/batch = 18.6288s	
18924/29850 (epoch 31.698), train_loss = 1.03380280, grad/param norm = 2.1154e-01, time/batch = 16.2713s	
18925/29850 (epoch 31.700), train_loss = 0.98564593, grad/param norm = 2.4268e-01, time/batch = 16.7246s	
18926/29850 (epoch 31.702), train_loss = 0.90908073, grad/param norm = 2.2458e-01, time/batch = 17.4377s	
18927/29850 (epoch 31.704), train_loss = 0.78989942, grad/param norm = 2.0066e-01, time/batch = 16.9327s	
18928/29850 (epoch 31.705), train_loss = 0.89019412, grad/param norm = 2.1391e-01, time/batch = 17.3526s	
18929/29850 (epoch 31.707), train_loss = 0.82513567, grad/param norm = 2.3929e-01, time/batch = 19.8710s	
18930/29850 (epoch 31.709), train_loss = 0.89226271, grad/param norm = 2.1869e-01, time/batch = 18.9554s	
18931/29850 (epoch 31.710), train_loss = 0.83290152, grad/param norm = 2.3209e-01, time/batch = 18.2699s	
18932/29850 (epoch 31.712), train_loss = 0.91181185, grad/param norm = 1.8681e-01, time/batch = 19.0413s	
18933/29850 (epoch 31.714), train_loss = 0.97626366, grad/param norm = 2.2724e-01, time/batch = 17.8504s	
18934/29850 (epoch 31.715), train_loss = 0.91779104, grad/param norm = 2.4988e-01, time/batch = 17.6111s	
18935/29850 (epoch 31.717), train_loss = 0.67270775, grad/param norm = 1.8652e-01, time/batch = 17.2660s	
18936/29850 (epoch 31.719), train_loss = 0.85875020, grad/param norm = 2.1876e-01, time/batch = 17.5466s	
18937/29850 (epoch 31.720), train_loss = 0.88612330, grad/param norm = 1.9175e-01, time/batch = 17.2757s	
18938/29850 (epoch 31.722), train_loss = 0.80925257, grad/param norm = 1.7303e-01, time/batch = 17.4419s	
18939/29850 (epoch 31.724), train_loss = 0.93418620, grad/param norm = 2.7341e-01, time/batch = 16.9311s	
18940/29850 (epoch 31.725), train_loss = 0.79026954, grad/param norm = 1.9631e-01, time/batch = 18.1963s	
18941/29850 (epoch 31.727), train_loss = 0.79877581, grad/param norm = 2.4321e-01, time/batch = 15.6076s	
18942/29850 (epoch 31.729), train_loss = 0.75588568, grad/param norm = 1.7545e-01, time/batch = 17.0343s	
18943/29850 (epoch 31.730), train_loss = 0.71174483, grad/param norm = 1.8789e-01, time/batch = 18.3812s	
18944/29850 (epoch 31.732), train_loss = 0.99297910, grad/param norm = 2.1091e-01, time/batch = 17.2955s	
18945/29850 (epoch 31.734), train_loss = 1.06715211, grad/param norm = 2.7190e-01, time/batch = 18.2902s	
18946/29850 (epoch 31.735), train_loss = 0.81708864, grad/param norm = 2.2168e-01, time/batch = 19.0480s	
18947/29850 (epoch 31.737), train_loss = 0.77557109, grad/param norm = 1.7727e-01, time/batch = 17.8782s	
18948/29850 (epoch 31.739), train_loss = 0.69171364, grad/param norm = 2.2019e-01, time/batch = 17.4324s	
18949/29850 (epoch 31.740), train_loss = 0.76713570, grad/param norm = 2.1261e-01, time/batch = 17.0502s	
18950/29850 (epoch 31.742), train_loss = 0.67704121, grad/param norm = 1.6382e-01, time/batch = 16.7248s	
18951/29850 (epoch 31.744), train_loss = 0.80849612, grad/param norm = 2.4840e-01, time/batch = 17.4510s	
18952/29850 (epoch 31.745), train_loss = 0.81715541, grad/param norm = 2.1182e-01, time/batch = 18.6184s	
18953/29850 (epoch 31.747), train_loss = 0.86356279, grad/param norm = 2.2427e-01, time/batch = 17.8050s	
18954/29850 (epoch 31.749), train_loss = 0.77119539, grad/param norm = 2.3134e-01, time/batch = 17.7631s	
18955/29850 (epoch 31.750), train_loss = 0.72872516, grad/param norm = 1.9614e-01, time/batch = 19.2741s	
18956/29850 (epoch 31.752), train_loss = 0.64059705, grad/param norm = 1.8251e-01, time/batch = 16.7031s	
18957/29850 (epoch 31.754), train_loss = 0.71858200, grad/param norm = 2.3551e-01, time/batch = 17.3874s	
18958/29850 (epoch 31.755), train_loss = 0.72068755, grad/param norm = 1.7880e-01, time/batch = 16.9160s	
18959/29850 (epoch 31.757), train_loss = 0.76546612, grad/param norm = 1.8763e-01, time/batch = 17.9647s	
18960/29850 (epoch 31.759), train_loss = 0.77104390, grad/param norm = 1.8326e-01, time/batch = 19.3813s	
18961/29850 (epoch 31.760), train_loss = 0.78681298, grad/param norm = 2.0752e-01, time/batch = 17.2853s	
18962/29850 (epoch 31.762), train_loss = 0.73443487, grad/param norm = 2.2861e-01, time/batch = 18.4666s	
18963/29850 (epoch 31.764), train_loss = 0.67624006, grad/param norm = 2.2026e-01, time/batch = 15.9437s	
18964/29850 (epoch 31.765), train_loss = 0.82405185, grad/param norm = 2.1241e-01, time/batch = 17.6219s	
18965/29850 (epoch 31.767), train_loss = 0.82463446, grad/param norm = 1.9140e-01, time/batch = 15.7892s	
18966/29850 (epoch 31.769), train_loss = 0.83181629, grad/param norm = 1.9409e-01, time/batch = 16.1388s	
18967/29850 (epoch 31.771), train_loss = 0.89089862, grad/param norm = 1.9851e-01, time/batch = 18.5573s	
18968/29850 (epoch 31.772), train_loss = 0.87541847, grad/param norm = 2.1426e-01, time/batch = 16.1248s	
18969/29850 (epoch 31.774), train_loss = 0.82072354, grad/param norm = 1.9273e-01, time/batch = 16.9509s	
18970/29850 (epoch 31.776), train_loss = 0.83201449, grad/param norm = 1.9401e-01, time/batch = 16.8671s	
18971/29850 (epoch 31.777), train_loss = 0.94245620, grad/param norm = 2.5089e-01, time/batch = 18.1784s	
18972/29850 (epoch 31.779), train_loss = 0.76933150, grad/param norm = 2.0814e-01, time/batch = 16.4249s	
18973/29850 (epoch 31.781), train_loss = 0.88061447, grad/param norm = 2.0012e-01, time/batch = 17.7101s	
18974/29850 (epoch 31.782), train_loss = 0.89126095, grad/param norm = 2.0498e-01, time/batch = 19.1248s	
18975/29850 (epoch 31.784), train_loss = 0.73641696, grad/param norm = 2.4141e-01, time/batch = 16.6991s	
18976/29850 (epoch 31.786), train_loss = 0.79489125, grad/param norm = 1.9234e-01, time/batch = 17.5481s	
18977/29850 (epoch 31.787), train_loss = 0.69433678, grad/param norm = 2.1177e-01, time/batch = 18.2939s	
18978/29850 (epoch 31.789), train_loss = 0.70155927, grad/param norm = 1.8074e-01, time/batch = 17.5285s	
18979/29850 (epoch 31.791), train_loss = 0.80322539, grad/param norm = 2.3243e-01, time/batch = 18.2950s	
18980/29850 (epoch 31.792), train_loss = 0.90497714, grad/param norm = 2.1565e-01, time/batch = 18.2903s	
18981/29850 (epoch 31.794), train_loss = 0.86231117, grad/param norm = 1.8680e-01, time/batch = 15.2472s	
18982/29850 (epoch 31.796), train_loss = 0.74602136, grad/param norm = 1.8910e-01, time/batch = 32.1984s	
18983/29850 (epoch 31.797), train_loss = 0.67861594, grad/param norm = 1.8547e-01, time/batch = 18.1006s	
18984/29850 (epoch 31.799), train_loss = 0.69348257, grad/param norm = 1.6559e-01, time/batch = 15.5224s	
18985/29850 (epoch 31.801), train_loss = 0.75351166, grad/param norm = 1.8171e-01, time/batch = 19.4529s	
18986/29850 (epoch 31.802), train_loss = 0.68246125, grad/param norm = 1.9430e-01, time/batch = 18.8590s	
18987/29850 (epoch 31.804), train_loss = 0.74779610, grad/param norm = 2.2072e-01, time/batch = 17.8665s	
18988/29850 (epoch 31.806), train_loss = 0.69881457, grad/param norm = 2.0952e-01, time/batch = 16.4572s	
18989/29850 (epoch 31.807), train_loss = 0.71580554, grad/param norm = 1.8237e-01, time/batch = 18.4593s	
18990/29850 (epoch 31.809), train_loss = 0.73353301, grad/param norm = 2.0869e-01, time/batch = 19.5664s	
18991/29850 (epoch 31.811), train_loss = 0.88945469, grad/param norm = 2.2983e-01, time/batch = 15.6351s	
18992/29850 (epoch 31.812), train_loss = 0.87227186, grad/param norm = 2.2772e-01, time/batch = 17.3744s	
18993/29850 (epoch 31.814), train_loss = 0.94714125, grad/param norm = 2.4021e-01, time/batch = 17.4403s	
18994/29850 (epoch 31.816), train_loss = 0.94866224, grad/param norm = 2.1328e-01, time/batch = 18.1801s	
18995/29850 (epoch 31.817), train_loss = 0.89505612, grad/param norm = 2.7032e-01, time/batch = 17.9777s	
18996/29850 (epoch 31.819), train_loss = 0.73582668, grad/param norm = 2.1732e-01, time/batch = 19.2794s	
18997/29850 (epoch 31.821), train_loss = 0.98215863, grad/param norm = 2.5164e-01, time/batch = 17.6357s	
18998/29850 (epoch 31.822), train_loss = 0.95401815, grad/param norm = 2.2436e-01, time/batch = 7.6672s	
18999/29850 (epoch 31.824), train_loss = 0.85274665, grad/param norm = 2.0789e-01, time/batch = 0.6760s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch31.83_1.8025.t7	
19000/29850 (epoch 31.826), train_loss = 0.74976201, grad/param norm = 1.8383e-01, time/batch = 0.6652s	
19001/29850 (epoch 31.827), train_loss = 1.28773088, grad/param norm = 3.4490e-01, time/batch = 0.9975s	
19002/29850 (epoch 31.829), train_loss = 0.84898497, grad/param norm = 2.5230e-01, time/batch = 1.6750s	
19003/29850 (epoch 31.831), train_loss = 0.96860957, grad/param norm = 2.2358e-01, time/batch = 1.8491s	
19004/29850 (epoch 31.832), train_loss = 0.86968641, grad/param norm = 1.9005e-01, time/batch = 3.2238s	
19005/29850 (epoch 31.834), train_loss = 0.65627346, grad/param norm = 1.7220e-01, time/batch = 17.5500s	
19006/29850 (epoch 31.836), train_loss = 0.69532950, grad/param norm = 1.8034e-01, time/batch = 14.7999s	
19007/29850 (epoch 31.838), train_loss = 0.79167345, grad/param norm = 2.4660e-01, time/batch = 16.2835s	
19008/29850 (epoch 31.839), train_loss = 0.70168264, grad/param norm = 1.9928e-01, time/batch = 17.0419s	
19009/29850 (epoch 31.841), train_loss = 0.74207448, grad/param norm = 1.7192e-01, time/batch = 19.2885s	
19010/29850 (epoch 31.843), train_loss = 0.68516381, grad/param norm = 1.9838e-01, time/batch = 17.3636s	
19011/29850 (epoch 31.844), train_loss = 0.75094102, grad/param norm = 2.0512e-01, time/batch = 18.6119s	
19012/29850 (epoch 31.846), train_loss = 0.84393716, grad/param norm = 2.3132e-01, time/batch = 17.0370s	
19013/29850 (epoch 31.848), train_loss = 0.89948733, grad/param norm = 2.1955e-01, time/batch = 18.3742s	
19014/29850 (epoch 31.849), train_loss = 0.78363858, grad/param norm = 2.3356e-01, time/batch = 17.2767s	
19015/29850 (epoch 31.851), train_loss = 0.98202328, grad/param norm = 2.3855e-01, time/batch = 18.3832s	
19016/29850 (epoch 31.853), train_loss = 0.79158999, grad/param norm = 2.2508e-01, time/batch = 15.4598s	
19017/29850 (epoch 31.854), train_loss = 0.96409349, grad/param norm = 2.3656e-01, time/batch = 16.8813s	
19018/29850 (epoch 31.856), train_loss = 0.94624507, grad/param norm = 2.6220e-01, time/batch = 18.2066s	
19019/29850 (epoch 31.858), train_loss = 0.85538152, grad/param norm = 2.1614e-01, time/batch = 18.7770s	
19020/29850 (epoch 31.859), train_loss = 0.75226691, grad/param norm = 2.1933e-01, time/batch = 18.3714s	
19021/29850 (epoch 31.861), train_loss = 0.95941463, grad/param norm = 2.2145e-01, time/batch = 18.1955s	
19022/29850 (epoch 31.863), train_loss = 1.01992133, grad/param norm = 2.4153e-01, time/batch = 16.8922s	
19023/29850 (epoch 31.864), train_loss = 0.94823652, grad/param norm = 2.3846e-01, time/batch = 19.0307s	
19024/29850 (epoch 31.866), train_loss = 0.88364117, grad/param norm = 2.5063e-01, time/batch = 17.6236s	
19025/29850 (epoch 31.868), train_loss = 1.01875911, grad/param norm = 2.3023e-01, time/batch = 18.3657s	
19026/29850 (epoch 31.869), train_loss = 0.94630363, grad/param norm = 2.6973e-01, time/batch = 17.3885s	
19027/29850 (epoch 31.871), train_loss = 0.95219475, grad/param norm = 2.2420e-01, time/batch = 16.4475s	
19028/29850 (epoch 31.873), train_loss = 0.88946826, grad/param norm = 2.4370e-01, time/batch = 17.5531s	
19029/29850 (epoch 31.874), train_loss = 0.90545140, grad/param norm = 2.2985e-01, time/batch = 19.1192s	
19030/29850 (epoch 31.876), train_loss = 0.89394603, grad/param norm = 4.9329e-01, time/batch = 17.5426s	
19031/29850 (epoch 31.878), train_loss = 0.89483129, grad/param norm = 2.3721e-01, time/batch = 18.5447s	
19032/29850 (epoch 31.879), train_loss = 0.92594820, grad/param norm = 2.3698e-01, time/batch = 15.5247s	
19033/29850 (epoch 31.881), train_loss = 0.98478563, grad/param norm = 2.5115e-01, time/batch = 18.7626s	
19034/29850 (epoch 31.883), train_loss = 0.94207986, grad/param norm = 2.5383e-01, time/batch = 18.0170s	
19035/29850 (epoch 31.884), train_loss = 0.79430436, grad/param norm = 2.2072e-01, time/batch = 18.7932s	
19036/29850 (epoch 31.886), train_loss = 0.98757431, grad/param norm = 2.5824e-01, time/batch = 16.8704s	
19037/29850 (epoch 31.888), train_loss = 0.87186387, grad/param norm = 2.3231e-01, time/batch = 16.6871s	
19038/29850 (epoch 31.889), train_loss = 0.79515689, grad/param norm = 1.8543e-01, time/batch = 16.7790s	
19039/29850 (epoch 31.891), train_loss = 0.78570559, grad/param norm = 2.0102e-01, time/batch = 16.2935s	
19040/29850 (epoch 31.893), train_loss = 0.83144595, grad/param norm = 2.0232e-01, time/batch = 16.9588s	
19041/29850 (epoch 31.894), train_loss = 0.84760200, grad/param norm = 2.2989e-01, time/batch = 17.6134s	
19042/29850 (epoch 31.896), train_loss = 0.88049891, grad/param norm = 2.2745e-01, time/batch = 18.2154s	
19043/29850 (epoch 31.898), train_loss = 1.00344425, grad/param norm = 2.5372e-01, time/batch = 19.8641s	
19044/29850 (epoch 31.899), train_loss = 0.78324444, grad/param norm = 2.2633e-01, time/batch = 16.0945s	
19045/29850 (epoch 31.901), train_loss = 1.09232202, grad/param norm = 3.2757e-01, time/batch = 19.3445s	
19046/29850 (epoch 31.903), train_loss = 0.91592748, grad/param norm = 2.8493e-01, time/batch = 19.3738s	
19047/29850 (epoch 31.905), train_loss = 1.14055948, grad/param norm = 2.7013e-01, time/batch = 18.4501s	
19048/29850 (epoch 31.906), train_loss = 0.91035254, grad/param norm = 2.3262e-01, time/batch = 17.1283s	
19049/29850 (epoch 31.908), train_loss = 1.04118114, grad/param norm = 2.7208e-01, time/batch = 18.6278s	
19050/29850 (epoch 31.910), train_loss = 0.94802161, grad/param norm = 2.2215e-01, time/batch = 18.3878s	
19051/29850 (epoch 31.911), train_loss = 1.11440705, grad/param norm = 2.4479e-01, time/batch = 17.8650s	
19052/29850 (epoch 31.913), train_loss = 1.03241205, grad/param norm = 2.4827e-01, time/batch = 18.9555s	
19053/29850 (epoch 31.915), train_loss = 1.02725654, grad/param norm = 2.2532e-01, time/batch = 19.1398s	
19054/29850 (epoch 31.916), train_loss = 0.98351930, grad/param norm = 2.2342e-01, time/batch = 16.0335s	
19055/29850 (epoch 31.918), train_loss = 0.82898323, grad/param norm = 2.1208e-01, time/batch = 18.3059s	
19056/29850 (epoch 31.920), train_loss = 1.00668934, grad/param norm = 2.1074e-01, time/batch = 18.1982s	
19057/29850 (epoch 31.921), train_loss = 0.89651671, grad/param norm = 2.3059e-01, time/batch = 15.7910s	
19058/29850 (epoch 31.923), train_loss = 0.90606625, grad/param norm = 2.0474e-01, time/batch = 20.5346s	
19059/29850 (epoch 31.925), train_loss = 1.04260866, grad/param norm = 2.3439e-01, time/batch = 17.7024s	
19060/29850 (epoch 31.926), train_loss = 1.02963262, grad/param norm = 2.5681e-01, time/batch = 17.9395s	
19061/29850 (epoch 31.928), train_loss = 0.91086962, grad/param norm = 2.2119e-01, time/batch = 19.4428s	
19062/29850 (epoch 31.930), train_loss = 0.93820524, grad/param norm = 2.2201e-01, time/batch = 17.2090s	
19063/29850 (epoch 31.931), train_loss = 0.89331538, grad/param norm = 2.2516e-01, time/batch = 18.5506s	
19064/29850 (epoch 31.933), train_loss = 1.04452342, grad/param norm = 2.6216e-01, time/batch = 17.7894s	
19065/29850 (epoch 31.935), train_loss = 0.96925204, grad/param norm = 2.3968e-01, time/batch = 19.1433s	
19066/29850 (epoch 31.936), train_loss = 0.93682168, grad/param norm = 2.4107e-01, time/batch = 17.2996s	
19067/29850 (epoch 31.938), train_loss = 0.79836954, grad/param norm = 2.1220e-01, time/batch = 16.4257s	
19068/29850 (epoch 31.940), train_loss = 0.79356001, grad/param norm = 1.9841e-01, time/batch = 19.7072s	
19069/29850 (epoch 31.941), train_loss = 0.82181926, grad/param norm = 2.3669e-01, time/batch = 18.2158s	
19070/29850 (epoch 31.943), train_loss = 0.80493276, grad/param norm = 1.9090e-01, time/batch = 17.5391s	
19071/29850 (epoch 31.945), train_loss = 0.81300146, grad/param norm = 2.2825e-01, time/batch = 19.3526s	
19072/29850 (epoch 31.946), train_loss = 0.79438373, grad/param norm = 2.0821e-01, time/batch = 16.3101s	
19073/29850 (epoch 31.948), train_loss = 0.88636952, grad/param norm = 1.9741e-01, time/batch = 18.3816s	
19074/29850 (epoch 31.950), train_loss = 0.82515359, grad/param norm = 1.9288e-01, time/batch = 18.0401s	
19075/29850 (epoch 31.951), train_loss = 0.73846603, grad/param norm = 1.9519e-01, time/batch = 19.1349s	
19076/29850 (epoch 31.953), train_loss = 0.84914076, grad/param norm = 2.2652e-01, time/batch = 18.2032s	
19077/29850 (epoch 31.955), train_loss = 0.75594809, grad/param norm = 1.9730e-01, time/batch = 15.0382s	
19078/29850 (epoch 31.956), train_loss = 0.77028418, grad/param norm = 1.7912e-01, time/batch = 19.0485s	
19079/29850 (epoch 31.958), train_loss = 0.67051147, grad/param norm = 1.6787e-01, time/batch = 18.0472s	
19080/29850 (epoch 31.960), train_loss = 0.95957392, grad/param norm = 2.4530e-01, time/batch = 17.3659s	
19081/29850 (epoch 31.961), train_loss = 0.76048061, grad/param norm = 2.0409e-01, time/batch = 16.2963s	
19082/29850 (epoch 31.963), train_loss = 0.73924336, grad/param norm = 2.0425e-01, time/batch = 16.8582s	
19083/29850 (epoch 31.965), train_loss = 0.79415811, grad/param norm = 1.9820e-01, time/batch = 18.5190s	
19084/29850 (epoch 31.966), train_loss = 0.75188323, grad/param norm = 2.0071e-01, time/batch = 16.4533s	
19085/29850 (epoch 31.968), train_loss = 0.78731601, grad/param norm = 2.2455e-01, time/batch = 19.2765s	
19086/29850 (epoch 31.970), train_loss = 0.77853734, grad/param norm = 2.3146e-01, time/batch = 17.9665s	
19087/29850 (epoch 31.972), train_loss = 0.77808623, grad/param norm = 1.9867e-01, time/batch = 16.3627s	
19088/29850 (epoch 31.973), train_loss = 0.78125769, grad/param norm = 2.0045e-01, time/batch = 18.5505s	
19089/29850 (epoch 31.975), train_loss = 0.66687530, grad/param norm = 1.6374e-01, time/batch = 15.4929s	
19090/29850 (epoch 31.977), train_loss = 0.82042132, grad/param norm = 2.0948e-01, time/batch = 16.1265s	
19091/29850 (epoch 31.978), train_loss = 0.72128917, grad/param norm = 1.9199e-01, time/batch = 17.6044s	
19092/29850 (epoch 31.980), train_loss = 0.78561124, grad/param norm = 1.8144e-01, time/batch = 17.9625s	
19093/29850 (epoch 31.982), train_loss = 0.76240742, grad/param norm = 1.9393e-01, time/batch = 17.5271s	
19094/29850 (epoch 31.983), train_loss = 0.81068092, grad/param norm = 1.9990e-01, time/batch = 16.8478s	
19095/29850 (epoch 31.985), train_loss = 0.89087128, grad/param norm = 2.2680e-01, time/batch = 18.6305s	
19096/29850 (epoch 31.987), train_loss = 0.87880023, grad/param norm = 2.1098e-01, time/batch = 18.4641s	
19097/29850 (epoch 31.988), train_loss = 0.80297589, grad/param norm = 1.8458e-01, time/batch = 17.6143s	
19098/29850 (epoch 31.990), train_loss = 0.86840750, grad/param norm = 1.8595e-01, time/batch = 14.5794s	
19099/29850 (epoch 31.992), train_loss = 0.89329908, grad/param norm = 1.9101e-01, time/batch = 18.1396s	
19100/29850 (epoch 31.993), train_loss = 0.87863481, grad/param norm = 2.2889e-01, time/batch = 18.5348s	
19101/29850 (epoch 31.995), train_loss = 0.87807518, grad/param norm = 1.9982e-01, time/batch = 15.9622s	
19102/29850 (epoch 31.997), train_loss = 0.88569090, grad/param norm = 1.7942e-01, time/batch = 18.0416s	
19103/29850 (epoch 31.998), train_loss = 0.90876098, grad/param norm = 2.1223e-01, time/batch = 18.3968s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
19104/29850 (epoch 32.000), train_loss = 0.73126870, grad/param norm = 1.8267e-01, time/batch = 17.0298s	
19105/29850 (epoch 32.002), train_loss = 1.00871699, grad/param norm = 2.3038e-01, time/batch = 17.6977s	
19106/29850 (epoch 32.003), train_loss = 0.74752608, grad/param norm = 2.1120e-01, time/batch = 17.0673s	
19107/29850 (epoch 32.005), train_loss = 0.90030531, grad/param norm = 2.1730e-01, time/batch = 15.8765s	
19108/29850 (epoch 32.007), train_loss = 0.96991948, grad/param norm = 2.7151e-01, time/batch = 15.6236s	
19109/29850 (epoch 32.008), train_loss = 1.08047549, grad/param norm = 2.2370e-01, time/batch = 19.6253s	
19110/29850 (epoch 32.010), train_loss = 0.78856852, grad/param norm = 2.1255e-01, time/batch = 17.3798s	
19111/29850 (epoch 32.012), train_loss = 0.84673544, grad/param norm = 1.9347e-01, time/batch = 16.4584s	
19112/29850 (epoch 32.013), train_loss = 0.91130329, grad/param norm = 2.2772e-01, time/batch = 16.4137s	
19113/29850 (epoch 32.015), train_loss = 0.93949839, grad/param norm = 2.2942e-01, time/batch = 17.3920s	
19114/29850 (epoch 32.017), train_loss = 0.91777397, grad/param norm = 2.4150e-01, time/batch = 19.4403s	
19115/29850 (epoch 32.018), train_loss = 1.02073538, grad/param norm = 2.4486e-01, time/batch = 17.4305s	
19116/29850 (epoch 32.020), train_loss = 0.85714744, grad/param norm = 2.2359e-01, time/batch = 18.2263s	
19117/29850 (epoch 32.022), train_loss = 0.95643870, grad/param norm = 2.2823e-01, time/batch = 18.7177s	
19118/29850 (epoch 32.023), train_loss = 0.95740142, grad/param norm = 1.9857e-01, time/batch = 15.3726s	
19119/29850 (epoch 32.025), train_loss = 0.84739188, grad/param norm = 1.8365e-01, time/batch = 16.8857s	
19120/29850 (epoch 32.027), train_loss = 0.69137986, grad/param norm = 1.9132e-01, time/batch = 17.2021s	
19121/29850 (epoch 32.028), train_loss = 0.82384722, grad/param norm = 2.0368e-01, time/batch = 17.9446s	
19122/29850 (epoch 32.030), train_loss = 0.83461912, grad/param norm = 2.2454e-01, time/batch = 17.6734s	
19123/29850 (epoch 32.032), train_loss = 0.92715162, grad/param norm = 2.0379e-01, time/batch = 18.0476s	
19124/29850 (epoch 32.034), train_loss = 0.78750544, grad/param norm = 2.0484e-01, time/batch = 19.0518s	
19125/29850 (epoch 32.035), train_loss = 0.70717590, grad/param norm = 1.8859e-01, time/batch = 17.2187s	
19126/29850 (epoch 32.037), train_loss = 0.86503987, grad/param norm = 1.8810e-01, time/batch = 19.1830s	
19127/29850 (epoch 32.039), train_loss = 0.76173072, grad/param norm = 1.7108e-01, time/batch = 17.3840s	
19128/29850 (epoch 32.040), train_loss = 0.78227485, grad/param norm = 1.9977e-01, time/batch = 15.5909s	
19129/29850 (epoch 32.042), train_loss = 0.77998412, grad/param norm = 2.1511e-01, time/batch = 18.9549s	
19130/29850 (epoch 32.044), train_loss = 0.84804564, grad/param norm = 2.0757e-01, time/batch = 17.9605s	
19131/29850 (epoch 32.045), train_loss = 0.91752068, grad/param norm = 2.2649e-01, time/batch = 18.2707s	
19132/29850 (epoch 32.047), train_loss = 0.76654763, grad/param norm = 1.8781e-01, time/batch = 16.4414s	
19133/29850 (epoch 32.049), train_loss = 0.89837317, grad/param norm = 2.1848e-01, time/batch = 17.5063s	
19134/29850 (epoch 32.050), train_loss = 0.79489733, grad/param norm = 2.1023e-01, time/batch = 15.7009s	
19135/29850 (epoch 32.052), train_loss = 0.98529986, grad/param norm = 2.2362e-01, time/batch = 16.2234s	
19136/29850 (epoch 32.054), train_loss = 0.85320602, grad/param norm = 1.9083e-01, time/batch = 19.2068s	
19137/29850 (epoch 32.055), train_loss = 0.83712442, grad/param norm = 2.0034e-01, time/batch = 17.5496s	
19138/29850 (epoch 32.057), train_loss = 0.92568100, grad/param norm = 2.1858e-01, time/batch = 18.2119s	
19139/29850 (epoch 32.059), train_loss = 0.91537659, grad/param norm = 2.1171e-01, time/batch = 17.3880s	
19140/29850 (epoch 32.060), train_loss = 0.87856877, grad/param norm = 2.1565e-01, time/batch = 15.8206s	
19141/29850 (epoch 32.062), train_loss = 0.95162927, grad/param norm = 2.2425e-01, time/batch = 18.2251s	
19142/29850 (epoch 32.064), train_loss = 0.93975649, grad/param norm = 2.2332e-01, time/batch = 15.6227s	
19143/29850 (epoch 32.065), train_loss = 0.76469883, grad/param norm = 1.9263e-01, time/batch = 14.7585s	
19144/29850 (epoch 32.067), train_loss = 0.90295606, grad/param norm = 1.8582e-01, time/batch = 15.8109s	
19145/29850 (epoch 32.069), train_loss = 0.90290817, grad/param norm = 1.9441e-01, time/batch = 17.2875s	
19146/29850 (epoch 32.070), train_loss = 0.90604389, grad/param norm = 2.0503e-01, time/batch = 16.1170s	
19147/29850 (epoch 32.072), train_loss = 0.88507507, grad/param norm = 2.3393e-01, time/batch = 18.0523s	
19148/29850 (epoch 32.074), train_loss = 0.95139279, grad/param norm = 1.9503e-01, time/batch = 16.9461s	
19149/29850 (epoch 32.075), train_loss = 0.81042920, grad/param norm = 2.2202e-01, time/batch = 17.6913s	
19150/29850 (epoch 32.077), train_loss = 0.94948468, grad/param norm = 2.6392e-01, time/batch = 18.5266s	
19151/29850 (epoch 32.079), train_loss = 1.10037010, grad/param norm = 3.1185e-01, time/batch = 18.5497s	
19152/29850 (epoch 32.080), train_loss = 1.06209451, grad/param norm = 2.4268e-01, time/batch = 17.2102s	
19153/29850 (epoch 32.082), train_loss = 0.92513493, grad/param norm = 2.0992e-01, time/batch = 17.5528s	
19154/29850 (epoch 32.084), train_loss = 1.07001100, grad/param norm = 2.5612e-01, time/batch = 18.7877s	
19155/29850 (epoch 32.085), train_loss = 1.04751228, grad/param norm = 2.4385e-01, time/batch = 19.3691s	
19156/29850 (epoch 32.087), train_loss = 1.01845243, grad/param norm = 2.4224e-01, time/batch = 16.2764s	
19157/29850 (epoch 32.089), train_loss = 0.92209113, grad/param norm = 2.1255e-01, time/batch = 18.7978s	
19158/29850 (epoch 32.090), train_loss = 0.94683912, grad/param norm = 2.0742e-01, time/batch = 16.6273s	
19159/29850 (epoch 32.092), train_loss = 0.83154737, grad/param norm = 2.4548e-01, time/batch = 16.7912s	
19160/29850 (epoch 32.094), train_loss = 1.02452268, grad/param norm = 2.3306e-01, time/batch = 18.4564s	
19161/29850 (epoch 32.095), train_loss = 0.95392388, grad/param norm = 2.8094e-01, time/batch = 16.7802s	
19162/29850 (epoch 32.097), train_loss = 0.71940763, grad/param norm = 2.1127e-01, time/batch = 18.0326s	
19163/29850 (epoch 32.099), train_loss = 0.74677477, grad/param norm = 2.0163e-01, time/batch = 16.1861s	
19164/29850 (epoch 32.101), train_loss = 0.97483869, grad/param norm = 2.1595e-01, time/batch = 18.3840s	
19165/29850 (epoch 32.102), train_loss = 0.94544720, grad/param norm = 2.2634e-01, time/batch = 18.7169s	
19166/29850 (epoch 32.104), train_loss = 0.86694526, grad/param norm = 2.1383e-01, time/batch = 16.5184s	
19167/29850 (epoch 32.106), train_loss = 0.98467598, grad/param norm = 2.1035e-01, time/batch = 19.1952s	
19168/29850 (epoch 32.107), train_loss = 0.82187721, grad/param norm = 2.0410e-01, time/batch = 18.1983s	
19169/29850 (epoch 32.109), train_loss = 0.89759928, grad/param norm = 2.1016e-01, time/batch = 18.4404s	
19170/29850 (epoch 32.111), train_loss = 0.94347275, grad/param norm = 2.1926e-01, time/batch = 19.8677s	
19171/29850 (epoch 32.112), train_loss = 0.80171521, grad/param norm = 2.2023e-01, time/batch = 18.2867s	
19172/29850 (epoch 32.114), train_loss = 0.84360457, grad/param norm = 2.2683e-01, time/batch = 17.7751s	
19173/29850 (epoch 32.116), train_loss = 0.81775329, grad/param norm = 1.9656e-01, time/batch = 17.0154s	
19174/29850 (epoch 32.117), train_loss = 0.86691909, grad/param norm = 2.4174e-01, time/batch = 17.6322s	
19175/29850 (epoch 32.119), train_loss = 0.85747782, grad/param norm = 2.0273e-01, time/batch = 17.7923s	
19176/29850 (epoch 32.121), train_loss = 0.70159250, grad/param norm = 2.0817e-01, time/batch = 16.3747s	
19177/29850 (epoch 32.122), train_loss = 0.74089675, grad/param norm = 1.5534e-01, time/batch = 18.2877s	
19178/29850 (epoch 32.124), train_loss = 0.81154501, grad/param norm = 2.1842e-01, time/batch = 18.5397s	
19179/29850 (epoch 32.126), train_loss = 0.81562812, grad/param norm = 1.7956e-01, time/batch = 17.0165s	
19180/29850 (epoch 32.127), train_loss = 0.92575447, grad/param norm = 2.4854e-01, time/batch = 20.0235s	
19181/29850 (epoch 32.129), train_loss = 0.85425401, grad/param norm = 2.0804e-01, time/batch = 18.4613s	
19182/29850 (epoch 32.131), train_loss = 0.87965292, grad/param norm = 2.0353e-01, time/batch = 18.5275s	
19183/29850 (epoch 32.132), train_loss = 0.76184902, grad/param norm = 2.9606e-01, time/batch = 18.8743s	
19184/29850 (epoch 32.134), train_loss = 0.83650794, grad/param norm = 2.1097e-01, time/batch = 16.9223s	
19185/29850 (epoch 32.136), train_loss = 0.93937611, grad/param norm = 2.0028e-01, time/batch = 16.4811s	
19186/29850 (epoch 32.137), train_loss = 0.72070822, grad/param norm = 1.9059e-01, time/batch = 18.4395s	
19187/29850 (epoch 32.139), train_loss = 0.87191681, grad/param norm = 2.2770e-01, time/batch = 19.2005s	
19188/29850 (epoch 32.141), train_loss = 0.79044677, grad/param norm = 2.2322e-01, time/batch = 17.5378s	
19189/29850 (epoch 32.142), train_loss = 1.00182868, grad/param norm = 2.5103e-01, time/batch = 26.5740s	
19190/29850 (epoch 32.144), train_loss = 1.11806292, grad/param norm = 2.4292e-01, time/batch = 22.9024s	
19191/29850 (epoch 32.146), train_loss = 1.12601289, grad/param norm = 2.3035e-01, time/batch = 16.7998s	
19192/29850 (epoch 32.147), train_loss = 0.96858754, grad/param norm = 2.3199e-01, time/batch = 16.5115s	
19193/29850 (epoch 32.149), train_loss = 0.92672266, grad/param norm = 2.2013e-01, time/batch = 15.3739s	
19194/29850 (epoch 32.151), train_loss = 0.93748792, grad/param norm = 2.2457e-01, time/batch = 15.0328s	
19195/29850 (epoch 32.152), train_loss = 0.85718770, grad/param norm = 2.0705e-01, time/batch = 14.8010s	
19196/29850 (epoch 32.154), train_loss = 0.81773815, grad/param norm = 2.2020e-01, time/batch = 14.9225s	
19197/29850 (epoch 32.156), train_loss = 0.80340780, grad/param norm = 2.0255e-01, time/batch = 14.1688s	
19198/29850 (epoch 32.157), train_loss = 0.93666466, grad/param norm = 2.1910e-01, time/batch = 14.7257s	
19199/29850 (epoch 32.159), train_loss = 0.83689743, grad/param norm = 1.9689e-01, time/batch = 14.4120s	
19200/29850 (epoch 32.161), train_loss = 0.89161955, grad/param norm = 2.2470e-01, time/batch = 14.6445s	
19201/29850 (epoch 32.162), train_loss = 1.00176988, grad/param norm = 2.2550e-01, time/batch = 14.8035s	
19202/29850 (epoch 32.164), train_loss = 0.92074342, grad/param norm = 2.2649e-01, time/batch = 14.5672s	
19203/29850 (epoch 32.166), train_loss = 0.85022597, grad/param norm = 2.2324e-01, time/batch = 14.4259s	
19204/29850 (epoch 32.168), train_loss = 0.74952890, grad/param norm = 1.7817e-01, time/batch = 14.7183s	
19205/29850 (epoch 32.169), train_loss = 1.02613710, grad/param norm = 2.4009e-01, time/batch = 14.4228s	
19206/29850 (epoch 32.171), train_loss = 0.93698159, grad/param norm = 2.0897e-01, time/batch = 14.7385s	
19207/29850 (epoch 32.173), train_loss = 0.80738946, grad/param norm = 2.1855e-01, time/batch = 14.4165s	
19208/29850 (epoch 32.174), train_loss = 0.91704016, grad/param norm = 2.3662e-01, time/batch = 15.0981s	
19209/29850 (epoch 32.176), train_loss = 0.89256741, grad/param norm = 2.1832e-01, time/batch = 14.5582s	
19210/29850 (epoch 32.178), train_loss = 0.92556153, grad/param norm = 2.2088e-01, time/batch = 14.4269s	
19211/29850 (epoch 32.179), train_loss = 0.75638595, grad/param norm = 2.0774e-01, time/batch = 14.4976s	
19212/29850 (epoch 32.181), train_loss = 0.90337674, grad/param norm = 2.1170e-01, time/batch = 15.0605s	
19213/29850 (epoch 32.183), train_loss = 0.87973371, grad/param norm = 2.0099e-01, time/batch = 14.5788s	
19214/29850 (epoch 32.184), train_loss = 0.93917735, grad/param norm = 2.3071e-01, time/batch = 14.5002s	
19215/29850 (epoch 32.186), train_loss = 0.91865054, grad/param norm = 2.6365e-01, time/batch = 14.6441s	
19216/29850 (epoch 32.188), train_loss = 1.02050684, grad/param norm = 2.4276e-01, time/batch = 15.1157s	
19217/29850 (epoch 32.189), train_loss = 1.00327964, grad/param norm = 2.6182e-01, time/batch = 14.3326s	
19218/29850 (epoch 32.191), train_loss = 0.99947924, grad/param norm = 2.3820e-01, time/batch = 14.5729s	
19219/29850 (epoch 32.193), train_loss = 0.87015619, grad/param norm = 2.0143e-01, time/batch = 14.3343s	
19220/29850 (epoch 32.194), train_loss = 0.95650328, grad/param norm = 2.1344e-01, time/batch = 14.6509s	
19221/29850 (epoch 32.196), train_loss = 0.87628227, grad/param norm = 2.1841e-01, time/batch = 15.1352s	
19222/29850 (epoch 32.198), train_loss = 0.86250760, grad/param norm = 2.0285e-01, time/batch = 14.4958s	
19223/29850 (epoch 32.199), train_loss = 1.09149343, grad/param norm = 2.4040e-01, time/batch = 14.3337s	
19224/29850 (epoch 32.201), train_loss = 0.82920567, grad/param norm = 2.0750e-01, time/batch = 14.5759s	
19225/29850 (epoch 32.203), train_loss = 0.66569512, grad/param norm = 1.9614e-01, time/batch = 14.4955s	
19226/29850 (epoch 32.204), train_loss = 0.89267144, grad/param norm = 2.4859e-01, time/batch = 14.5075s	
19227/29850 (epoch 32.206), train_loss = 0.78605956, grad/param norm = 2.3574e-01, time/batch = 14.3428s	
19228/29850 (epoch 32.208), train_loss = 1.02683990, grad/param norm = 2.1698e-01, time/batch = 14.6483s	
19229/29850 (epoch 32.209), train_loss = 0.77055121, grad/param norm = 1.9091e-01, time/batch = 14.4851s	
19230/29850 (epoch 32.211), train_loss = 0.84391508, grad/param norm = 2.1170e-01, time/batch = 14.1752s	
19231/29850 (epoch 32.213), train_loss = 0.93717182, grad/param norm = 2.2335e-01, time/batch = 14.8027s	
19232/29850 (epoch 32.214), train_loss = 0.76971477, grad/param norm = 1.6916e-01, time/batch = 14.6357s	
19233/29850 (epoch 32.216), train_loss = 0.80798590, grad/param norm = 1.9925e-01, time/batch = 14.7896s	
19234/29850 (epoch 32.218), train_loss = 0.91142741, grad/param norm = 2.1036e-01, time/batch = 14.2526s	
19235/29850 (epoch 32.219), train_loss = 0.92711612, grad/param norm = 2.1037e-01, time/batch = 14.4010s	
19236/29850 (epoch 32.221), train_loss = 0.89891644, grad/param norm = 2.3510e-01, time/batch = 14.4837s	
19237/29850 (epoch 32.223), train_loss = 0.77839925, grad/param norm = 2.3596e-01, time/batch = 14.2407s	
19238/29850 (epoch 32.224), train_loss = 0.74568883, grad/param norm = 1.8463e-01, time/batch = 14.1679s	
19239/29850 (epoch 32.226), train_loss = 0.78994627, grad/param norm = 1.6915e-01, time/batch = 14.1585s	
19240/29850 (epoch 32.228), train_loss = 0.85549185, grad/param norm = 2.1103e-01, time/batch = 14.0018s	
19241/29850 (epoch 32.229), train_loss = 0.71336533, grad/param norm = 1.7533e-01, time/batch = 15.2503s	
19242/29850 (epoch 32.231), train_loss = 0.88015501, grad/param norm = 2.0503e-01, time/batch = 14.5013s	
19243/29850 (epoch 32.233), train_loss = 0.88709796, grad/param norm = 2.2579e-01, time/batch = 14.3348s	
19244/29850 (epoch 32.235), train_loss = 0.79357307, grad/param norm = 1.9316e-01, time/batch = 15.1108s	
19245/29850 (epoch 32.236), train_loss = 1.01158177, grad/param norm = 2.6304e-01, time/batch = 14.9657s	
19246/29850 (epoch 32.238), train_loss = 0.75012745, grad/param norm = 1.9617e-01, time/batch = 14.3406s	
19247/29850 (epoch 32.240), train_loss = 0.76231400, grad/param norm = 1.8784e-01, time/batch = 14.5873s	
19248/29850 (epoch 32.241), train_loss = 0.94863153, grad/param norm = 2.5346e-01, time/batch = 14.1735s	
19249/29850 (epoch 32.243), train_loss = 0.92469196, grad/param norm = 2.0966e-01, time/batch = 16.5355s	
19250/29850 (epoch 32.245), train_loss = 0.82404823, grad/param norm = 2.3982e-01, time/batch = 14.3435s	
19251/29850 (epoch 32.246), train_loss = 0.73363770, grad/param norm = 1.6188e-01, time/batch = 14.5616s	
19252/29850 (epoch 32.248), train_loss = 0.72611835, grad/param norm = 1.8018e-01, time/batch = 14.2554s	
19253/29850 (epoch 32.250), train_loss = 0.82863536, grad/param norm = 1.8117e-01, time/batch = 14.5747s	
19254/29850 (epoch 32.251), train_loss = 0.73113662, grad/param norm = 2.1239e-01, time/batch = 14.2582s	
19255/29850 (epoch 32.253), train_loss = 0.71707278, grad/param norm = 2.1970e-01, time/batch = 14.5870s	
19256/29850 (epoch 32.255), train_loss = 0.78954200, grad/param norm = 2.0137e-01, time/batch = 14.4864s	
19257/29850 (epoch 32.256), train_loss = 0.92288793, grad/param norm = 2.3142e-01, time/batch = 15.1193s	
19258/29850 (epoch 32.258), train_loss = 0.92409528, grad/param norm = 2.4440e-01, time/batch = 14.2549s	
19259/29850 (epoch 32.260), train_loss = 0.86425874, grad/param norm = 2.0253e-01, time/batch = 14.6628s	
19260/29850 (epoch 32.261), train_loss = 0.78920474, grad/param norm = 2.1120e-01, time/batch = 14.9283s	
19261/29850 (epoch 32.263), train_loss = 0.79095503, grad/param norm = 1.9778e-01, time/batch = 14.4777s	
19262/29850 (epoch 32.265), train_loss = 0.86016145, grad/param norm = 2.3794e-01, time/batch = 14.0863s	
19263/29850 (epoch 32.266), train_loss = 0.86593744, grad/param norm = 2.4098e-01, time/batch = 14.3376s	
19264/29850 (epoch 32.268), train_loss = 0.82531502, grad/param norm = 2.0512e-01, time/batch = 14.0950s	
19265/29850 (epoch 32.270), train_loss = 0.79588135, grad/param norm = 2.2019e-01, time/batch = 14.7737s	
19266/29850 (epoch 32.271), train_loss = 0.94091233, grad/param norm = 2.5934e-01, time/batch = 15.3271s	
19267/29850 (epoch 32.273), train_loss = 0.74406018, grad/param norm = 2.2892e-01, time/batch = 15.1593s	
19268/29850 (epoch 32.275), train_loss = 0.75500173, grad/param norm = 2.2112e-01, time/batch = 14.8330s	
19269/29850 (epoch 32.276), train_loss = 0.74184509, grad/param norm = 1.7814e-01, time/batch = 14.5378s	
19270/29850 (epoch 32.278), train_loss = 0.82663403, grad/param norm = 2.0964e-01, time/batch = 13.9337s	
19271/29850 (epoch 32.280), train_loss = 1.01483607, grad/param norm = 2.9091e-01, time/batch = 14.3363s	
19272/29850 (epoch 32.281), train_loss = 0.88970348, grad/param norm = 2.1722e-01, time/batch = 14.4057s	
19273/29850 (epoch 32.283), train_loss = 1.00805609, grad/param norm = 2.7677e-01, time/batch = 14.7212s	
19274/29850 (epoch 32.285), train_loss = 0.94589405, grad/param norm = 2.0848e-01, time/batch = 14.4929s	
19275/29850 (epoch 32.286), train_loss = 0.95881499, grad/param norm = 2.2562e-01, time/batch = 14.3378s	
19276/29850 (epoch 32.288), train_loss = 0.97676930, grad/param norm = 3.0782e-01, time/batch = 14.3240s	
19277/29850 (epoch 32.290), train_loss = 0.90075648, grad/param norm = 2.5278e-01, time/batch = 14.2340s	
19278/29850 (epoch 32.291), train_loss = 1.09252454, grad/param norm = 2.4926e-01, time/batch = 14.9022s	
19279/29850 (epoch 32.293), train_loss = 0.97190767, grad/param norm = 2.2950e-01, time/batch = 18.1170s	
19280/29850 (epoch 32.295), train_loss = 1.04232132, grad/param norm = 2.1152e-01, time/batch = 17.4564s	
19281/29850 (epoch 32.296), train_loss = 0.78295570, grad/param norm = 1.8770e-01, time/batch = 17.0133s	
19282/29850 (epoch 32.298), train_loss = 0.69048398, grad/param norm = 2.4040e-01, time/batch = 18.0620s	
19283/29850 (epoch 32.300), train_loss = 0.78144154, grad/param norm = 1.9449e-01, time/batch = 18.0498s	
19284/29850 (epoch 32.302), train_loss = 0.74342034, grad/param norm = 1.9523e-01, time/batch = 18.8674s	
19285/29850 (epoch 32.303), train_loss = 0.81984449, grad/param norm = 2.1762e-01, time/batch = 18.2958s	
19286/29850 (epoch 32.305), train_loss = 0.92432100, grad/param norm = 2.0076e-01, time/batch = 19.7157s	
19287/29850 (epoch 32.307), train_loss = 0.95725010, grad/param norm = 2.0903e-01, time/batch = 18.2088s	
19288/29850 (epoch 32.308), train_loss = 0.79425302, grad/param norm = 2.1568e-01, time/batch = 15.9056s	
19289/29850 (epoch 32.310), train_loss = 0.90051223, grad/param norm = 2.4859e-01, time/batch = 14.5357s	
19290/29850 (epoch 32.312), train_loss = 0.93135357, grad/param norm = 1.9276e-01, time/batch = 15.1693s	
19291/29850 (epoch 32.313), train_loss = 0.88424743, grad/param norm = 2.1560e-01, time/batch = 15.1024s	
19292/29850 (epoch 32.315), train_loss = 0.88659369, grad/param norm = 2.1445e-01, time/batch = 15.8817s	
19293/29850 (epoch 32.317), train_loss = 0.87409488, grad/param norm = 2.1693e-01, time/batch = 16.2769s	
19294/29850 (epoch 32.318), train_loss = 0.87576261, grad/param norm = 2.1851e-01, time/batch = 15.4291s	
19295/29850 (epoch 32.320), train_loss = 0.80093121, grad/param norm = 2.0192e-01, time/batch = 15.7171s	
19296/29850 (epoch 32.322), train_loss = 1.00291644, grad/param norm = 2.2108e-01, time/batch = 17.3143s	
19297/29850 (epoch 32.323), train_loss = 0.93490283, grad/param norm = 2.2689e-01, time/batch = 16.5566s	
19298/29850 (epoch 32.325), train_loss = 0.97351047, grad/param norm = 2.1537e-01, time/batch = 16.5761s	
19299/29850 (epoch 32.327), train_loss = 1.10486969, grad/param norm = 2.3486e-01, time/batch = 15.9654s	
19300/29850 (epoch 32.328), train_loss = 1.01619398, grad/param norm = 2.6230e-01, time/batch = 17.5716s	
19301/29850 (epoch 32.330), train_loss = 0.94527503, grad/param norm = 2.0128e-01, time/batch = 18.7966s	
19302/29850 (epoch 32.332), train_loss = 0.82481390, grad/param norm = 2.0264e-01, time/batch = 16.2109s	
19303/29850 (epoch 32.333), train_loss = 0.92412866, grad/param norm = 2.1401e-01, time/batch = 18.4536s	
19304/29850 (epoch 32.335), train_loss = 0.98411787, grad/param norm = 2.0512e-01, time/batch = 16.2153s	
19305/29850 (epoch 32.337), train_loss = 0.90290826, grad/param norm = 2.2333e-01, time/batch = 15.3219s	
19306/29850 (epoch 32.338), train_loss = 0.92895845, grad/param norm = 2.0180e-01, time/batch = 15.4301s	
19307/29850 (epoch 32.340), train_loss = 0.77051332, grad/param norm = 1.9492e-01, time/batch = 15.4615s	
19308/29850 (epoch 32.342), train_loss = 0.90331881, grad/param norm = 2.5856e-01, time/batch = 15.9851s	
19309/29850 (epoch 32.343), train_loss = 0.89554751, grad/param norm = 2.4155e-01, time/batch = 17.8041s	
19310/29850 (epoch 32.345), train_loss = 0.99179180, grad/param norm = 2.5441e-01, time/batch = 16.7895s	
19311/29850 (epoch 32.347), train_loss = 0.98414395, grad/param norm = 2.3292e-01, time/batch = 19.4637s	
19312/29850 (epoch 32.348), train_loss = 0.83669516, grad/param norm = 2.4308e-01, time/batch = 15.5395s	
19313/29850 (epoch 32.350), train_loss = 0.96919626, grad/param norm = 2.6139e-01, time/batch = 15.1106s	
19314/29850 (epoch 32.352), train_loss = 0.83493335, grad/param norm = 1.9422e-01, time/batch = 16.1564s	
19315/29850 (epoch 32.353), train_loss = 0.95656429, grad/param norm = 2.1721e-01, time/batch = 15.5098s	
19316/29850 (epoch 32.355), train_loss = 0.85343509, grad/param norm = 2.3115e-01, time/batch = 18.5362s	
19317/29850 (epoch 32.357), train_loss = 0.96071368, grad/param norm = 2.1312e-01, time/batch = 17.9640s	
19318/29850 (epoch 32.358), train_loss = 0.84957567, grad/param norm = 2.3625e-01, time/batch = 16.5493s	
19319/29850 (epoch 32.360), train_loss = 0.85724666, grad/param norm = 2.1331e-01, time/batch = 18.4605s	
19320/29850 (epoch 32.362), train_loss = 0.87063629, grad/param norm = 2.2230e-01, time/batch = 16.8680s	
19321/29850 (epoch 32.363), train_loss = 0.94664061, grad/param norm = 2.3825e-01, time/batch = 19.7648s	
19322/29850 (epoch 32.365), train_loss = 1.04639387, grad/param norm = 2.4868e-01, time/batch = 18.2084s	
19323/29850 (epoch 32.367), train_loss = 0.83026066, grad/param norm = 2.0752e-01, time/batch = 17.0367s	
19324/29850 (epoch 32.369), train_loss = 0.76302205, grad/param norm = 2.2386e-01, time/batch = 17.0290s	
19325/29850 (epoch 32.370), train_loss = 0.71313994, grad/param norm = 1.8557e-01, time/batch = 17.0634s	
19326/29850 (epoch 32.372), train_loss = 0.98547639, grad/param norm = 2.2565e-01, time/batch = 16.6448s	
19327/29850 (epoch 32.374), train_loss = 0.96399946, grad/param norm = 2.0591e-01, time/batch = 15.2710s	
19328/29850 (epoch 32.375), train_loss = 0.89972071, grad/param norm = 2.1750e-01, time/batch = 16.7440s	
19329/29850 (epoch 32.377), train_loss = 0.80320551, grad/param norm = 2.4816e-01, time/batch = 17.5758s	
19330/29850 (epoch 32.379), train_loss = 1.01007647, grad/param norm = 2.4228e-01, time/batch = 17.9505s	
19331/29850 (epoch 32.380), train_loss = 0.93446798, grad/param norm = 2.1283e-01, time/batch = 16.3436s	
19332/29850 (epoch 32.382), train_loss = 0.92908691, grad/param norm = 2.3298e-01, time/batch = 19.3654s	
19333/29850 (epoch 32.384), train_loss = 0.96239003, grad/param norm = 2.3370e-01, time/batch = 18.3825s	
19334/29850 (epoch 32.385), train_loss = 0.92565515, grad/param norm = 2.2678e-01, time/batch = 17.6119s	
19335/29850 (epoch 32.387), train_loss = 0.97216446, grad/param norm = 2.7016e-01, time/batch = 19.7187s	
19336/29850 (epoch 32.389), train_loss = 1.02758128, grad/param norm = 2.4848e-01, time/batch = 16.1211s	
19337/29850 (epoch 32.390), train_loss = 0.95917964, grad/param norm = 2.1024e-01, time/batch = 17.0436s	
19338/29850 (epoch 32.392), train_loss = 0.89390161, grad/param norm = 2.4201e-01, time/batch = 19.6383s	
19339/29850 (epoch 32.394), train_loss = 0.97803373, grad/param norm = 2.3577e-01, time/batch = 17.1303s	
19340/29850 (epoch 32.395), train_loss = 0.84328456, grad/param norm = 2.3750e-01, time/batch = 17.2944s	
19341/29850 (epoch 32.397), train_loss = 0.80672146, grad/param norm = 2.6396e-01, time/batch = 16.2164s	
19342/29850 (epoch 32.399), train_loss = 0.80760959, grad/param norm = 1.9963e-01, time/batch = 14.6588s	
19343/29850 (epoch 32.400), train_loss = 1.16013782, grad/param norm = 2.4719e-01, time/batch = 18.5427s	
19344/29850 (epoch 32.402), train_loss = 1.05524606, grad/param norm = 2.2548e-01, time/batch = 17.1387s	
19345/29850 (epoch 32.404), train_loss = 0.93315758, grad/param norm = 2.2658e-01, time/batch = 18.6149s	
19346/29850 (epoch 32.405), train_loss = 0.84040732, grad/param norm = 2.1720e-01, time/batch = 19.2921s	
19347/29850 (epoch 32.407), train_loss = 0.83155376, grad/param norm = 2.2670e-01, time/batch = 16.1101s	
19348/29850 (epoch 32.409), train_loss = 0.92972164, grad/param norm = 2.1348e-01, time/batch = 18.9490s	
19349/29850 (epoch 32.410), train_loss = 1.00590905, grad/param norm = 2.2452e-01, time/batch = 17.9746s	
19350/29850 (epoch 32.412), train_loss = 1.00695144, grad/param norm = 2.1711e-01, time/batch = 18.4533s	
19351/29850 (epoch 32.414), train_loss = 0.92139155, grad/param norm = 2.3889e-01, time/batch = 18.0313s	
19352/29850 (epoch 32.415), train_loss = 0.91569824, grad/param norm = 2.0780e-01, time/batch = 17.4636s	
19353/29850 (epoch 32.417), train_loss = 1.04694987, grad/param norm = 3.0025e-01, time/batch = 19.7021s	
19354/29850 (epoch 32.419), train_loss = 0.89198330, grad/param norm = 2.3683e-01, time/batch = 16.0166s	
19355/29850 (epoch 32.420), train_loss = 0.90295950, grad/param norm = 2.2299e-01, time/batch = 17.0376s	
19356/29850 (epoch 32.422), train_loss = 0.87955902, grad/param norm = 2.0119e-01, time/batch = 19.6169s	
19357/29850 (epoch 32.424), train_loss = 0.81997051, grad/param norm = 2.0422e-01, time/batch = 17.5236s	
19358/29850 (epoch 32.425), train_loss = 0.98810995, grad/param norm = 2.2450e-01, time/batch = 17.1355s	
19359/29850 (epoch 32.427), train_loss = 0.71700579, grad/param norm = 2.0219e-01, time/batch = 17.1347s	
19360/29850 (epoch 32.429), train_loss = 0.79732689, grad/param norm = 2.0464e-01, time/batch = 15.7484s	
19361/29850 (epoch 32.430), train_loss = 0.74694049, grad/param norm = 1.9125e-01, time/batch = 18.5349s	
19362/29850 (epoch 32.432), train_loss = 0.84336649, grad/param norm = 2.5344e-01, time/batch = 18.0699s	
19363/29850 (epoch 32.434), train_loss = 0.79632489, grad/param norm = 1.9885e-01, time/batch = 17.2125s	
19364/29850 (epoch 32.436), train_loss = 0.88821466, grad/param norm = 2.5201e-01, time/batch = 15.6149s	
19365/29850 (epoch 32.437), train_loss = 0.94239052, grad/param norm = 2.1345e-01, time/batch = 19.1165s	
19366/29850 (epoch 32.439), train_loss = 0.92411809, grad/param norm = 1.9728e-01, time/batch = 17.9705s	
19367/29850 (epoch 32.441), train_loss = 0.91336411, grad/param norm = 2.3907e-01, time/batch = 17.6337s	
19368/29850 (epoch 32.442), train_loss = 0.88807232, grad/param norm = 2.1117e-01, time/batch = 19.7231s	
19369/29850 (epoch 32.444), train_loss = 0.91869652, grad/param norm = 2.3033e-01, time/batch = 17.9699s	
19370/29850 (epoch 32.446), train_loss = 0.96442254, grad/param norm = 2.3932e-01, time/batch = 17.2966s	
19371/29850 (epoch 32.447), train_loss = 0.96606736, grad/param norm = 2.2486e-01, time/batch = 15.5865s	
19372/29850 (epoch 32.449), train_loss = 0.92206666, grad/param norm = 2.4281e-01, time/batch = 19.5153s	
19373/29850 (epoch 32.451), train_loss = 0.71469707, grad/param norm = 1.9646e-01, time/batch = 18.6291s	
19374/29850 (epoch 32.452), train_loss = 0.64096622, grad/param norm = 1.9358e-01, time/batch = 16.1891s	
19375/29850 (epoch 32.454), train_loss = 0.77213064, grad/param norm = 2.0254e-01, time/batch = 18.3717s	
19376/29850 (epoch 32.456), train_loss = 0.96636179, grad/param norm = 2.3397e-01, time/batch = 17.8823s	
19377/29850 (epoch 32.457), train_loss = 0.94655761, grad/param norm = 2.7771e-01, time/batch = 17.6268s	
19378/29850 (epoch 32.459), train_loss = 1.02982802, grad/param norm = 2.3036e-01, time/batch = 16.1890s	
19379/29850 (epoch 32.461), train_loss = 1.02150419, grad/param norm = 2.3942e-01, time/batch = 18.6223s	
19380/29850 (epoch 32.462), train_loss = 1.03082464, grad/param norm = 2.2919e-01, time/batch = 18.6895s	
19381/29850 (epoch 32.464), train_loss = 0.92697680, grad/param norm = 2.0680e-01, time/batch = 15.8474s	
19382/29850 (epoch 32.466), train_loss = 0.76481187, grad/param norm = 2.0536e-01, time/batch = 18.0508s	
19383/29850 (epoch 32.467), train_loss = 0.85027719, grad/param norm = 2.4491e-01, time/batch = 18.3052s	
19384/29850 (epoch 32.469), train_loss = 0.87187406, grad/param norm = 2.0817e-01, time/batch = 17.6284s	
19385/29850 (epoch 32.471), train_loss = 0.85790584, grad/param norm = 2.2677e-01, time/batch = 17.1097s	
19386/29850 (epoch 32.472), train_loss = 0.81536071, grad/param norm = 2.1883e-01, time/batch = 18.1181s	
19387/29850 (epoch 32.474), train_loss = 0.98662815, grad/param norm = 2.1721e-01, time/batch = 18.6983s	
19388/29850 (epoch 32.476), train_loss = 0.89802413, grad/param norm = 1.9383e-01, time/batch = 17.2209s	
19389/29850 (epoch 32.477), train_loss = 0.93450107, grad/param norm = 2.4274e-01, time/batch = 18.1349s	
19390/29850 (epoch 32.479), train_loss = 1.09762885, grad/param norm = 2.5996e-01, time/batch = 18.7965s	
19391/29850 (epoch 32.481), train_loss = 0.88258919, grad/param norm = 2.3251e-01, time/batch = 16.0509s	
19392/29850 (epoch 32.482), train_loss = 0.80253679, grad/param norm = 1.7531e-01, time/batch = 17.2171s	
19393/29850 (epoch 32.484), train_loss = 0.85038232, grad/param norm = 1.9987e-01, time/batch = 17.0668s	
19394/29850 (epoch 32.486), train_loss = 0.92294193, grad/param norm = 2.3919e-01, time/batch = 17.2797s	
19395/29850 (epoch 32.487), train_loss = 0.91708131, grad/param norm = 2.1351e-01, time/batch = 15.1681s	
19396/29850 (epoch 32.489), train_loss = 0.91691107, grad/param norm = 2.3325e-01, time/batch = 14.6324s	
19397/29850 (epoch 32.491), train_loss = 0.81024480, grad/param norm = 2.0783e-01, time/batch = 15.6603s	
19398/29850 (epoch 32.492), train_loss = 0.90419359, grad/param norm = 2.2799e-01, time/batch = 15.7134s	
19399/29850 (epoch 32.494), train_loss = 0.95831180, grad/param norm = 2.0207e-01, time/batch = 15.7976s	
19400/29850 (epoch 32.496), train_loss = 1.00603322, grad/param norm = 2.1742e-01, time/batch = 16.1319s	
19401/29850 (epoch 32.497), train_loss = 0.92911212, grad/param norm = 2.0210e-01, time/batch = 17.4575s	
19402/29850 (epoch 32.499), train_loss = 0.91316543, grad/param norm = 2.0416e-01, time/batch = 16.8750s	
19403/29850 (epoch 32.501), train_loss = 0.81716749, grad/param norm = 2.4305e-01, time/batch = 16.0471s	
19404/29850 (epoch 32.503), train_loss = 0.94497797, grad/param norm = 2.3221e-01, time/batch = 16.4757s	
19405/29850 (epoch 32.504), train_loss = 1.09963298, grad/param norm = 2.4205e-01, time/batch = 17.7962s	
19406/29850 (epoch 32.506), train_loss = 1.07020397, grad/param norm = 2.5863e-01, time/batch = 17.3714s	
19407/29850 (epoch 32.508), train_loss = 0.91994819, grad/param norm = 1.9827e-01, time/batch = 19.2953s	
19408/29850 (epoch 32.509), train_loss = 0.72900600, grad/param norm = 2.1055e-01, time/batch = 18.8768s	
19409/29850 (epoch 32.511), train_loss = 0.92350966, grad/param norm = 2.1759e-01, time/batch = 31.2690s	
19410/29850 (epoch 32.513), train_loss = 0.89478963, grad/param norm = 2.6886e-01, time/batch = 16.9613s	
19411/29850 (epoch 32.514), train_loss = 0.81361773, grad/param norm = 2.0241e-01, time/batch = 15.9789s	
19412/29850 (epoch 32.516), train_loss = 0.84850987, grad/param norm = 1.8186e-01, time/batch = 19.2834s	
19413/29850 (epoch 32.518), train_loss = 0.73868172, grad/param norm = 1.9437e-01, time/batch = 19.2723s	
19414/29850 (epoch 32.519), train_loss = 0.71899175, grad/param norm = 1.8665e-01, time/batch = 17.8065s	
19415/29850 (epoch 32.521), train_loss = 0.67908480, grad/param norm = 1.8619e-01, time/batch = 16.7134s	
19416/29850 (epoch 32.523), train_loss = 0.72247940, grad/param norm = 1.7187e-01, time/batch = 17.2181s	
19417/29850 (epoch 32.524), train_loss = 0.80385725, grad/param norm = 2.0171e-01, time/batch = 18.1767s	
19418/29850 (epoch 32.526), train_loss = 0.86551258, grad/param norm = 2.3540e-01, time/batch = 15.2615s	
19419/29850 (epoch 32.528), train_loss = 0.96714656, grad/param norm = 2.3078e-01, time/batch = 18.9555s	
19420/29850 (epoch 32.529), train_loss = 0.95439591, grad/param norm = 2.4607e-01, time/batch = 17.8930s	
19421/29850 (epoch 32.531), train_loss = 0.89775055, grad/param norm = 2.7996e-01, time/batch = 17.7893s	
19422/29850 (epoch 32.533), train_loss = 0.89899918, grad/param norm = 2.1948e-01, time/batch = 19.7900s	
19423/29850 (epoch 32.534), train_loss = 0.93071005, grad/param norm = 2.2089e-01, time/batch = 18.0336s	
19424/29850 (epoch 32.536), train_loss = 0.83012582, grad/param norm = 2.3312e-01, time/batch = 18.8714s	
19425/29850 (epoch 32.538), train_loss = 1.02703511, grad/param norm = 2.5966e-01, time/batch = 18.2768s	
19426/29850 (epoch 32.539), train_loss = 1.03785327, grad/param norm = 2.4030e-01, time/batch = 18.7009s	
19427/29850 (epoch 32.541), train_loss = 0.66292871, grad/param norm = 1.8531e-01, time/batch = 16.9507s	
19428/29850 (epoch 32.543), train_loss = 0.85629924, grad/param norm = 2.1764e-01, time/batch = 16.1310s	
19429/29850 (epoch 32.544), train_loss = 0.99034217, grad/param norm = 2.3286e-01, time/batch = 15.6955s	
19430/29850 (epoch 32.546), train_loss = 0.96000942, grad/param norm = 2.2673e-01, time/batch = 18.2960s	
19431/29850 (epoch 32.548), train_loss = 0.74395236, grad/param norm = 1.8636e-01, time/batch = 16.9424s	
19432/29850 (epoch 32.549), train_loss = 0.84804950, grad/param norm = 2.0635e-01, time/batch = 15.4233s	
19433/29850 (epoch 32.551), train_loss = 0.77830274, grad/param norm = 1.9416e-01, time/batch = 19.6067s	
19434/29850 (epoch 32.553), train_loss = 0.90011984, grad/param norm = 2.1682e-01, time/batch = 16.2978s	
19435/29850 (epoch 32.554), train_loss = 0.73620913, grad/param norm = 1.8451e-01, time/batch = 17.6235s	
19436/29850 (epoch 32.556), train_loss = 0.78893920, grad/param norm = 2.6437e-01, time/batch = 18.2752s	
19437/29850 (epoch 32.558), train_loss = 0.79553520, grad/param norm = 2.0761e-01, time/batch = 17.4426s	
19438/29850 (epoch 32.559), train_loss = 0.82131588, grad/param norm = 1.9132e-01, time/batch = 18.2848s	
19439/29850 (epoch 32.561), train_loss = 0.93561629, grad/param norm = 2.5351e-01, time/batch = 18.3777s	
19440/29850 (epoch 32.563), train_loss = 0.92085108, grad/param norm = 2.1986e-01, time/batch = 15.8393s	
19441/29850 (epoch 32.564), train_loss = 0.85300977, grad/param norm = 2.4798e-01, time/batch = 15.4621s	
19442/29850 (epoch 32.566), train_loss = 0.88208815, grad/param norm = 2.0703e-01, time/batch = 15.5653s	
19443/29850 (epoch 32.568), train_loss = 0.99006239, grad/param norm = 2.3472e-01, time/batch = 14.9543s	
19444/29850 (epoch 32.570), train_loss = 0.92493658, grad/param norm = 2.5698e-01, time/batch = 16.2238s	
19445/29850 (epoch 32.571), train_loss = 0.97847770, grad/param norm = 2.3388e-01, time/batch = 15.9222s	
19446/29850 (epoch 32.573), train_loss = 1.05359880, grad/param norm = 2.3907e-01, time/batch = 14.8037s	
19447/29850 (epoch 32.575), train_loss = 1.06895380, grad/param norm = 2.2159e-01, time/batch = 18.2276s	
19448/29850 (epoch 32.576), train_loss = 0.98849678, grad/param norm = 2.4131e-01, time/batch = 16.8133s	
19449/29850 (epoch 32.578), train_loss = 0.82845084, grad/param norm = 2.2283e-01, time/batch = 15.7263s	
19450/29850 (epoch 32.580), train_loss = 0.98593023, grad/param norm = 2.1789e-01, time/batch = 15.8638s	
19451/29850 (epoch 32.581), train_loss = 0.82248417, grad/param norm = 2.2324e-01, time/batch = 19.3719s	
19452/29850 (epoch 32.583), train_loss = 0.87927955, grad/param norm = 2.1068e-01, time/batch = 18.9574s	
19453/29850 (epoch 32.585), train_loss = 0.92259661, grad/param norm = 2.1640e-01, time/batch = 15.6156s	
19454/29850 (epoch 32.586), train_loss = 0.92210446, grad/param norm = 2.4287e-01, time/batch = 15.7811s	
19455/29850 (epoch 32.588), train_loss = 0.83286756, grad/param norm = 2.1091e-01, time/batch = 16.7318s	
19456/29850 (epoch 32.590), train_loss = 0.84524747, grad/param norm = 2.2361e-01, time/batch = 17.7886s	
19457/29850 (epoch 32.591), train_loss = 0.85430975, grad/param norm = 1.9946e-01, time/batch = 17.1978s	
19458/29850 (epoch 32.593), train_loss = 0.81960612, grad/param norm = 1.9601e-01, time/batch = 18.6128s	
19459/29850 (epoch 32.595), train_loss = 0.73907045, grad/param norm = 1.6300e-01, time/batch = 18.0493s	
19460/29850 (epoch 32.596), train_loss = 0.77108003, grad/param norm = 1.9799e-01, time/batch = 17.1832s	
19461/29850 (epoch 32.598), train_loss = 0.88679726, grad/param norm = 2.1309e-01, time/batch = 18.7997s	
19462/29850 (epoch 32.600), train_loss = 0.92617638, grad/param norm = 2.3752e-01, time/batch = 15.7925s	
19463/29850 (epoch 32.601), train_loss = 0.77224035, grad/param norm = 1.9070e-01, time/batch = 18.0461s	
19464/29850 (epoch 32.603), train_loss = 0.81990860, grad/param norm = 2.0492e-01, time/batch = 19.1347s	
19465/29850 (epoch 32.605), train_loss = 0.86209843, grad/param norm = 2.1946e-01, time/batch = 17.7106s	
19466/29850 (epoch 32.606), train_loss = 0.63213779, grad/param norm = 1.8312e-01, time/batch = 18.0292s	
19467/29850 (epoch 32.608), train_loss = 0.78666025, grad/param norm = 2.0728e-01, time/batch = 15.0417s	
19468/29850 (epoch 32.610), train_loss = 0.83576448, grad/param norm = 2.0554e-01, time/batch = 20.1942s	
19469/29850 (epoch 32.611), train_loss = 0.78270368, grad/param norm = 1.9935e-01, time/batch = 19.8601s	
19470/29850 (epoch 32.613), train_loss = 0.66121621, grad/param norm = 1.7455e-01, time/batch = 18.7770s	
19471/29850 (epoch 32.615), train_loss = 0.76335000, grad/param norm = 1.9848e-01, time/batch = 19.1269s	
19472/29850 (epoch 32.616), train_loss = 0.75776265, grad/param norm = 2.1633e-01, time/batch = 16.7640s	
19473/29850 (epoch 32.618), train_loss = 0.84322414, grad/param norm = 2.0766e-01, time/batch = 18.1712s	
19474/29850 (epoch 32.620), train_loss = 0.89747730, grad/param norm = 2.1646e-01, time/batch = 17.5519s	
19475/29850 (epoch 32.621), train_loss = 1.01234753, grad/param norm = 2.4169e-01, time/batch = 15.6625s	
19476/29850 (epoch 32.623), train_loss = 0.94249781, grad/param norm = 2.5974e-01, time/batch = 16.3647s	
19477/29850 (epoch 32.625), train_loss = 0.88057939, grad/param norm = 2.6455e-01, time/batch = 15.5804s	
19478/29850 (epoch 32.626), train_loss = 0.89388065, grad/param norm = 2.3387e-01, time/batch = 17.7901s	
19479/29850 (epoch 32.628), train_loss = 0.84756225, grad/param norm = 1.9897e-01, time/batch = 19.1224s	
19480/29850 (epoch 32.630), train_loss = 0.90250191, grad/param norm = 2.4026e-01, time/batch = 16.9624s	
19481/29850 (epoch 32.631), train_loss = 0.87392156, grad/param norm = 2.1550e-01, time/batch = 18.2911s	
19482/29850 (epoch 32.633), train_loss = 0.92444956, grad/param norm = 2.5860e-01, time/batch = 15.4571s	
19483/29850 (epoch 32.635), train_loss = 0.82548426, grad/param norm = 2.2722e-01, time/batch = 17.4606s	
19484/29850 (epoch 32.637), train_loss = 0.79622421, grad/param norm = 2.1458e-01, time/batch = 18.3641s	
19485/29850 (epoch 32.638), train_loss = 0.91187980, grad/param norm = 2.2944e-01, time/batch = 18.0481s	
19486/29850 (epoch 32.640), train_loss = 1.00148589, grad/param norm = 2.6548e-01, time/batch = 17.7243s	
19487/29850 (epoch 32.642), train_loss = 0.82403385, grad/param norm = 2.0251e-01, time/batch = 17.0163s	
19488/29850 (epoch 32.643), train_loss = 0.79798634, grad/param norm = 2.2734e-01, time/batch = 16.9443s	
19489/29850 (epoch 32.645), train_loss = 0.88681721, grad/param norm = 2.3925e-01, time/batch = 18.2879s	
19490/29850 (epoch 32.647), train_loss = 1.00244233, grad/param norm = 2.3134e-01, time/batch = 17.4471s	
19491/29850 (epoch 32.648), train_loss = 0.78719418, grad/param norm = 2.0056e-01, time/batch = 19.5195s	
19492/29850 (epoch 32.650), train_loss = 0.90170427, grad/param norm = 2.2395e-01, time/batch = 17.8866s	
19493/29850 (epoch 32.652), train_loss = 0.87855280, grad/param norm = 2.4756e-01, time/batch = 17.7074s	
19494/29850 (epoch 32.653), train_loss = 0.96788280, grad/param norm = 2.3889e-01, time/batch = 17.8651s	
19495/29850 (epoch 32.655), train_loss = 0.88180600, grad/param norm = 2.0540e-01, time/batch = 17.7297s	
19496/29850 (epoch 32.657), train_loss = 0.87125601, grad/param norm = 2.2058e-01, time/batch = 17.4621s	
19497/29850 (epoch 32.658), train_loss = 0.96746823, grad/param norm = 2.1156e-01, time/batch = 17.2022s	
19498/29850 (epoch 32.660), train_loss = 0.86039929, grad/param norm = 2.4253e-01, time/batch = 17.4549s	
19499/29850 (epoch 32.662), train_loss = 0.97656901, grad/param norm = 2.3491e-01, time/batch = 15.4007s	
19500/29850 (epoch 32.663), train_loss = 1.07272414, grad/param norm = 2.4974e-01, time/batch = 16.4186s	
19501/29850 (epoch 32.665), train_loss = 1.01457894, grad/param norm = 2.5646e-01, time/batch = 15.6028s	
19502/29850 (epoch 32.667), train_loss = 0.94340699, grad/param norm = 2.6778e-01, time/batch = 16.8164s	
19503/29850 (epoch 32.668), train_loss = 0.85906373, grad/param norm = 2.4690e-01, time/batch = 17.1300s	
19504/29850 (epoch 32.670), train_loss = 0.99373123, grad/param norm = 3.0214e-01, time/batch = 15.8114s	
19505/29850 (epoch 32.672), train_loss = 0.98163370, grad/param norm = 2.6173e-01, time/batch = 18.3737s	
19506/29850 (epoch 32.673), train_loss = 0.91170390, grad/param norm = 2.2605e-01, time/batch = 17.6427s	
19507/29850 (epoch 32.675), train_loss = 0.80883318, grad/param norm = 2.3854e-01, time/batch = 15.5561s	
19508/29850 (epoch 32.677), train_loss = 0.84987444, grad/param norm = 2.2623e-01, time/batch = 15.6415s	
19509/29850 (epoch 32.678), train_loss = 0.88140649, grad/param norm = 2.1511e-01, time/batch = 19.5355s	
19510/29850 (epoch 32.680), train_loss = 0.87924732, grad/param norm = 2.2546e-01, time/batch = 18.9545s	
19511/29850 (epoch 32.682), train_loss = 0.88477403, grad/param norm = 2.2778e-01, time/batch = 16.2808s	
19512/29850 (epoch 32.683), train_loss = 1.00040517, grad/param norm = 2.4578e-01, time/batch = 16.9676s	
19513/29850 (epoch 32.685), train_loss = 1.07049746, grad/param norm = 2.3635e-01, time/batch = 17.3930s	
19514/29850 (epoch 32.687), train_loss = 0.92613030, grad/param norm = 2.2948e-01, time/batch = 17.0647s	
19515/29850 (epoch 32.688), train_loss = 0.77383197, grad/param norm = 2.0729e-01, time/batch = 17.5543s	
19516/29850 (epoch 32.690), train_loss = 0.78033572, grad/param norm = 1.9854e-01, time/batch = 18.6224s	
19517/29850 (epoch 32.692), train_loss = 1.00499782, grad/param norm = 2.1038e-01, time/batch = 16.1148s	
19518/29850 (epoch 32.693), train_loss = 0.87704350, grad/param norm = 2.1873e-01, time/batch = 15.3805s	
19519/29850 (epoch 32.695), train_loss = 0.76480959, grad/param norm = 1.7115e-01, time/batch = 18.5520s	
19520/29850 (epoch 32.697), train_loss = 0.87998660, grad/param norm = 2.0477e-01, time/batch = 17.3891s	
19521/29850 (epoch 32.698), train_loss = 1.00986515, grad/param norm = 2.0826e-01, time/batch = 17.1405s	
19522/29850 (epoch 32.700), train_loss = 0.96827796, grad/param norm = 2.5056e-01, time/batch = 16.7124s	
19523/29850 (epoch 32.702), train_loss = 0.89959351, grad/param norm = 2.2812e-01, time/batch = 18.4438s	
19524/29850 (epoch 32.704), train_loss = 0.78145363, grad/param norm = 2.1076e-01, time/batch = 18.3718s	
19525/29850 (epoch 32.705), train_loss = 0.90496923, grad/param norm = 2.3519e-01, time/batch = 15.6508s	
19526/29850 (epoch 32.707), train_loss = 0.82737998, grad/param norm = 2.3261e-01, time/batch = 15.0109s	
19527/29850 (epoch 32.709), train_loss = 0.86100232, grad/param norm = 2.3697e-01, time/batch = 16.0478s	
19528/29850 (epoch 32.710), train_loss = 0.82250594, grad/param norm = 2.2294e-01, time/batch = 18.1005s	
19529/29850 (epoch 32.712), train_loss = 0.90950818, grad/param norm = 2.0671e-01, time/batch = 16.7003s	
19530/29850 (epoch 32.714), train_loss = 0.96602527, grad/param norm = 2.3557e-01, time/batch = 17.7939s	
19531/29850 (epoch 32.715), train_loss = 0.91070768, grad/param norm = 2.7064e-01, time/batch = 15.9306s	
19532/29850 (epoch 32.717), train_loss = 0.66809084, grad/param norm = 1.9228e-01, time/batch = 16.7078s	
19533/29850 (epoch 32.719), train_loss = 0.83583021, grad/param norm = 1.9935e-01, time/batch = 19.4550s	
19534/29850 (epoch 32.720), train_loss = 0.88609704, grad/param norm = 2.0303e-01, time/batch = 17.1239s	
19535/29850 (epoch 32.722), train_loss = 0.79570286, grad/param norm = 1.9281e-01, time/batch = 16.8574s	
19536/29850 (epoch 32.724), train_loss = 0.90882625, grad/param norm = 2.5087e-01, time/batch = 15.1952s	
19537/29850 (epoch 32.725), train_loss = 0.78230299, grad/param norm = 2.0619e-01, time/batch = 15.1044s	
19538/29850 (epoch 32.727), train_loss = 0.77866494, grad/param norm = 1.9944e-01, time/batch = 18.1891s	
19539/29850 (epoch 32.729), train_loss = 0.74092976, grad/param norm = 1.8710e-01, time/batch = 16.7894s	
19540/29850 (epoch 32.730), train_loss = 0.69308910, grad/param norm = 1.8294e-01, time/batch = 19.4475s	
19541/29850 (epoch 32.732), train_loss = 0.99250931, grad/param norm = 2.0321e-01, time/batch = 19.7952s	
19542/29850 (epoch 32.734), train_loss = 1.03515286, grad/param norm = 2.3293e-01, time/batch = 18.0370s	
19543/29850 (epoch 32.735), train_loss = 0.80087724, grad/param norm = 2.2516e-01, time/batch = 19.7842s	
19544/29850 (epoch 32.737), train_loss = 0.77896934, grad/param norm = 1.9973e-01, time/batch = 18.9577s	
19545/29850 (epoch 32.739), train_loss = 0.68945039, grad/param norm = 2.1691e-01, time/batch = 15.6027s	
19546/29850 (epoch 32.740), train_loss = 0.73997845, grad/param norm = 2.0721e-01, time/batch = 16.6165s	
19547/29850 (epoch 32.742), train_loss = 0.65493245, grad/param norm = 1.6137e-01, time/batch = 16.3936s	
19548/29850 (epoch 32.744), train_loss = 0.78138643, grad/param norm = 2.3567e-01, time/batch = 19.2103s	
19549/29850 (epoch 32.745), train_loss = 0.83545137, grad/param norm = 2.3017e-01, time/batch = 16.8583s	
19550/29850 (epoch 32.747), train_loss = 0.84823063, grad/param norm = 2.1818e-01, time/batch = 17.7347s	
19551/29850 (epoch 32.749), train_loss = 0.75284147, grad/param norm = 2.0918e-01, time/batch = 17.3070s	
19552/29850 (epoch 32.750), train_loss = 0.71189202, grad/param norm = 2.0702e-01, time/batch = 16.4652s	
19553/29850 (epoch 32.752), train_loss = 0.62406926, grad/param norm = 1.9426e-01, time/batch = 19.1902s	
19554/29850 (epoch 32.754), train_loss = 0.69937564, grad/param norm = 1.8642e-01, time/batch = 16.3582s	
19555/29850 (epoch 32.755), train_loss = 0.71615752, grad/param norm = 2.0773e-01, time/batch = 19.3644s	
19556/29850 (epoch 32.757), train_loss = 0.75396774, grad/param norm = 1.7762e-01, time/batch = 15.3884s	
19557/29850 (epoch 32.759), train_loss = 0.77292896, grad/param norm = 1.9958e-01, time/batch = 18.0440s	
19558/29850 (epoch 32.760), train_loss = 0.77613423, grad/param norm = 2.0767e-01, time/batch = 19.5362s	
19559/29850 (epoch 32.762), train_loss = 0.72261777, grad/param norm = 2.2357e-01, time/batch = 16.9456s	
19560/29850 (epoch 32.764), train_loss = 0.65631504, grad/param norm = 1.9203e-01, time/batch = 16.1383s	
19561/29850 (epoch 32.765), train_loss = 0.82870509, grad/param norm = 2.2495e-01, time/batch = 19.2978s	
19562/29850 (epoch 32.767), train_loss = 0.81976181, grad/param norm = 1.9968e-01, time/batch = 15.5700s	
19563/29850 (epoch 32.769), train_loss = 0.83286987, grad/param norm = 2.2313e-01, time/batch = 15.5931s	
19564/29850 (epoch 32.771), train_loss = 0.88961285, grad/param norm = 2.1450e-01, time/batch = 15.2819s	
19565/29850 (epoch 32.772), train_loss = 0.85031038, grad/param norm = 2.3758e-01, time/batch = 17.6074s	
19566/29850 (epoch 32.774), train_loss = 0.79425293, grad/param norm = 2.0444e-01, time/batch = 17.1304s	
19567/29850 (epoch 32.776), train_loss = 0.82811844, grad/param norm = 2.0512e-01, time/batch = 17.3787s	
19568/29850 (epoch 32.777), train_loss = 0.93703456, grad/param norm = 2.6034e-01, time/batch = 19.0406s	
19569/29850 (epoch 32.779), train_loss = 0.75427767, grad/param norm = 2.0197e-01, time/batch = 17.2071s	
19570/29850 (epoch 32.781), train_loss = 0.88179533, grad/param norm = 2.1082e-01, time/batch = 17.5329s	
19571/29850 (epoch 32.782), train_loss = 0.89079616, grad/param norm = 2.1397e-01, time/batch = 17.1411s	
19572/29850 (epoch 32.784), train_loss = 0.72199670, grad/param norm = 2.4437e-01, time/batch = 19.7077s	
19573/29850 (epoch 32.786), train_loss = 0.78323518, grad/param norm = 1.8713e-01, time/batch = 16.5491s	
19574/29850 (epoch 32.787), train_loss = 0.68963471, grad/param norm = 2.1526e-01, time/batch = 19.3722s	
19575/29850 (epoch 32.789), train_loss = 0.68289196, grad/param norm = 1.8512e-01, time/batch = 16.4000s	
19576/29850 (epoch 32.791), train_loss = 0.77556949, grad/param norm = 2.4625e-01, time/batch = 17.1236s	
19577/29850 (epoch 32.792), train_loss = 0.87885402, grad/param norm = 2.5109e-01, time/batch = 18.4862s	
19578/29850 (epoch 32.794), train_loss = 0.86624693, grad/param norm = 2.0864e-01, time/batch = 19.0595s	
19579/29850 (epoch 32.796), train_loss = 0.74167519, grad/param norm = 1.9348e-01, time/batch = 18.2011s	
19580/29850 (epoch 32.797), train_loss = 0.65775253, grad/param norm = 1.9506e-01, time/batch = 15.9674s	
19581/29850 (epoch 32.799), train_loss = 0.70191500, grad/param norm = 1.7376e-01, time/batch = 16.5488s	
19582/29850 (epoch 32.801), train_loss = 0.74354788, grad/param norm = 1.9976e-01, time/batch = 17.7825s	
19583/29850 (epoch 32.802), train_loss = 0.68330471, grad/param norm = 2.2245e-01, time/batch = 16.7015s	
19584/29850 (epoch 32.804), train_loss = 0.73893331, grad/param norm = 1.7531e-01, time/batch = 14.1673s	
19585/29850 (epoch 32.806), train_loss = 0.68801933, grad/param norm = 1.8304e-01, time/batch = 18.1370s	
19586/29850 (epoch 32.807), train_loss = 0.69450756, grad/param norm = 1.6604e-01, time/batch = 17.0575s	
19587/29850 (epoch 32.809), train_loss = 0.72088589, grad/param norm = 2.0133e-01, time/batch = 16.5305s	
19588/29850 (epoch 32.811), train_loss = 0.88736124, grad/param norm = 2.4488e-01, time/batch = 17.8859s	
19589/29850 (epoch 32.812), train_loss = 0.87682456, grad/param norm = 2.5806e-01, time/batch = 17.8567s	
19590/29850 (epoch 32.814), train_loss = 0.92431045, grad/param norm = 2.1973e-01, time/batch = 17.9492s	
19591/29850 (epoch 32.816), train_loss = 0.93899246, grad/param norm = 2.1787e-01, time/batch = 19.4538s	
19592/29850 (epoch 32.817), train_loss = 0.88322974, grad/param norm = 2.4608e-01, time/batch = 18.2188s	
19593/29850 (epoch 32.819), train_loss = 0.71453558, grad/param norm = 2.0657e-01, time/batch = 17.6994s	
19594/29850 (epoch 32.821), train_loss = 0.95052470, grad/param norm = 2.6245e-01, time/batch = 17.8705s	
19595/29850 (epoch 32.822), train_loss = 0.93140364, grad/param norm = 2.1823e-01, time/batch = 17.2266s	
19596/29850 (epoch 32.824), train_loss = 0.82745297, grad/param norm = 2.0331e-01, time/batch = 16.0110s	
19597/29850 (epoch 32.826), train_loss = 0.74580315, grad/param norm = 1.9138e-01, time/batch = 16.6760s	
19598/29850 (epoch 32.827), train_loss = 0.69576240, grad/param norm = 2.3414e-01, time/batch = 17.2899s	
19599/29850 (epoch 32.829), train_loss = 0.84245199, grad/param norm = 2.4357e-01, time/batch = 16.7839s	
19600/29850 (epoch 32.831), train_loss = 0.94029669, grad/param norm = 2.4534e-01, time/batch = 16.8573s	
19601/29850 (epoch 32.832), train_loss = 0.86679427, grad/param norm = 2.0005e-01, time/batch = 18.1902s	
19602/29850 (epoch 32.834), train_loss = 0.65082217, grad/param norm = 1.7946e-01, time/batch = 18.0276s	
19603/29850 (epoch 32.836), train_loss = 0.67163922, grad/param norm = 1.7599e-01, time/batch = 19.1256s	
19604/29850 (epoch 32.838), train_loss = 0.78852328, grad/param norm = 2.7762e-01, time/batch = 16.8653s	
19605/29850 (epoch 32.839), train_loss = 0.69368938, grad/param norm = 2.1424e-01, time/batch = 18.1891s	
19606/29850 (epoch 32.841), train_loss = 0.76161168, grad/param norm = 2.0685e-01, time/batch = 16.7046s	
19607/29850 (epoch 32.843), train_loss = 0.68738461, grad/param norm = 2.1257e-01, time/batch = 15.7858s	
19608/29850 (epoch 32.844), train_loss = 0.75726663, grad/param norm = 2.0254e-01, time/batch = 18.3747s	
19609/29850 (epoch 32.846), train_loss = 0.84210003, grad/param norm = 2.2229e-01, time/batch = 19.2005s	
19610/29850 (epoch 32.848), train_loss = 0.89504335, grad/param norm = 2.3297e-01, time/batch = 17.2950s	
19611/29850 (epoch 32.849), train_loss = 0.77211851, grad/param norm = 2.1176e-01, time/batch = 17.8723s	
19612/29850 (epoch 32.851), train_loss = 0.98355946, grad/param norm = 2.5006e-01, time/batch = 18.0568s	
19613/29850 (epoch 32.853), train_loss = 0.78535098, grad/param norm = 2.2125e-01, time/batch = 18.7129s	
19614/29850 (epoch 32.854), train_loss = 0.96790701, grad/param norm = 2.5379e-01, time/batch = 29.4409s	
19615/29850 (epoch 32.856), train_loss = 0.92160212, grad/param norm = 2.4394e-01, time/batch = 14.7184s	
19616/29850 (epoch 32.858), train_loss = 0.85227128, grad/param norm = 2.4155e-01, time/batch = 14.5018s	
19617/29850 (epoch 32.859), train_loss = 0.74335783, grad/param norm = 2.1802e-01, time/batch = 14.8167s	
19618/29850 (epoch 32.861), train_loss = 0.94397639, grad/param norm = 2.2867e-01, time/batch = 14.6535s	
19619/29850 (epoch 32.863), train_loss = 0.97933736, grad/param norm = 2.3024e-01, time/batch = 14.3453s	
19620/29850 (epoch 32.864), train_loss = 0.96415287, grad/param norm = 2.6836e-01, time/batch = 15.4687s	
19621/29850 (epoch 32.866), train_loss = 0.86033654, grad/param norm = 2.4511e-01, time/batch = 15.4366s	
19622/29850 (epoch 32.868), train_loss = 1.02100337, grad/param norm = 2.3508e-01, time/batch = 14.7363s	
19623/29850 (epoch 32.869), train_loss = 0.91158827, grad/param norm = 2.5732e-01, time/batch = 14.9731s	
19624/29850 (epoch 32.871), train_loss = 0.93521205, grad/param norm = 2.3504e-01, time/batch = 16.0687s	
19625/29850 (epoch 32.873), train_loss = 0.86961711, grad/param norm = 2.1750e-01, time/batch = 17.4590s	
19626/29850 (epoch 32.874), train_loss = 0.86432177, grad/param norm = 2.0629e-01, time/batch = 15.1936s	
19627/29850 (epoch 32.876), train_loss = 0.85728097, grad/param norm = 2.6896e-01, time/batch = 14.7360s	
19628/29850 (epoch 32.878), train_loss = 0.87385434, grad/param norm = 2.2219e-01, time/batch = 17.1214s	
19629/29850 (epoch 32.879), train_loss = 0.89583990, grad/param norm = 2.0989e-01, time/batch = 16.0642s	
19630/29850 (epoch 32.881), train_loss = 0.96822383, grad/param norm = 2.2928e-01, time/batch = 18.5540s	
19631/29850 (epoch 32.883), train_loss = 0.94562491, grad/param norm = 2.3106e-01, time/batch = 17.3211s	
19632/29850 (epoch 32.884), train_loss = 0.74821936, grad/param norm = 1.9679e-01, time/batch = 16.2802s	
19633/29850 (epoch 32.886), train_loss = 0.96310328, grad/param norm = 2.7773e-01, time/batch = 17.9549s	
19634/29850 (epoch 32.888), train_loss = 0.86509416, grad/param norm = 2.3925e-01, time/batch = 18.6196s	
19635/29850 (epoch 32.889), train_loss = 0.77384897, grad/param norm = 1.8016e-01, time/batch = 17.7858s	
19636/29850 (epoch 32.891), train_loss = 0.76349208, grad/param norm = 1.9035e-01, time/batch = 18.5510s	
19637/29850 (epoch 32.893), train_loss = 0.81782159, grad/param norm = 1.8775e-01, time/batch = 16.9723s	
19638/29850 (epoch 32.894), train_loss = 0.85432815, grad/param norm = 2.4501e-01, time/batch = 18.7984s	
19639/29850 (epoch 32.896), train_loss = 0.86009080, grad/param norm = 2.0227e-01, time/batch = 16.5259s	
19640/29850 (epoch 32.898), train_loss = 0.98832699, grad/param norm = 2.4519e-01, time/batch = 16.6472s	
19641/29850 (epoch 32.899), train_loss = 0.77712850, grad/param norm = 2.3552e-01, time/batch = 15.6355s	
19642/29850 (epoch 32.901), train_loss = 1.06887630, grad/param norm = 2.9679e-01, time/batch = 14.8046s	
19643/29850 (epoch 32.903), train_loss = 0.91570556, grad/param norm = 4.3576e-01, time/batch = 14.7334s	
19644/29850 (epoch 32.905), train_loss = 1.12874813, grad/param norm = 2.4502e-01, time/batch = 15.0238s	
19645/29850 (epoch 32.906), train_loss = 0.90378304, grad/param norm = 2.4102e-01, time/batch = 14.4193s	
19646/29850 (epoch 32.908), train_loss = 1.01293766, grad/param norm = 2.2781e-01, time/batch = 14.5712s	
19647/29850 (epoch 32.910), train_loss = 0.94055078, grad/param norm = 2.1678e-01, time/batch = 14.6566s	
19648/29850 (epoch 32.911), train_loss = 1.10916792, grad/param norm = 2.4589e-01, time/batch = 14.3374s	
19649/29850 (epoch 32.913), train_loss = 1.01086442, grad/param norm = 2.4337e-01, time/batch = 15.0253s	
19650/29850 (epoch 32.915), train_loss = 0.98197182, grad/param norm = 2.2356e-01, time/batch = 14.4854s	
19651/29850 (epoch 32.916), train_loss = 0.96746910, grad/param norm = 2.5340e-01, time/batch = 14.7380s	
19652/29850 (epoch 32.918), train_loss = 0.81247035, grad/param norm = 2.1217e-01, time/batch = 14.7234s	
19653/29850 (epoch 32.920), train_loss = 0.99296735, grad/param norm = 2.1327e-01, time/batch = 14.6437s	
19654/29850 (epoch 32.921), train_loss = 0.87291136, grad/param norm = 2.2902e-01, time/batch = 14.8762s	
19655/29850 (epoch 32.923), train_loss = 0.90648293, grad/param norm = 2.1273e-01, time/batch = 14.6410s	
19656/29850 (epoch 32.925), train_loss = 1.01220131, grad/param norm = 2.4792e-01, time/batch = 14.1659s	
19657/29850 (epoch 32.926), train_loss = 1.03183389, grad/param norm = 2.6238e-01, time/batch = 13.9250s	
19658/29850 (epoch 32.928), train_loss = 0.90355144, grad/param norm = 2.2063e-01, time/batch = 14.3252s	
19659/29850 (epoch 32.930), train_loss = 0.93024929, grad/param norm = 2.2037e-01, time/batch = 14.7162s	
19660/29850 (epoch 32.931), train_loss = 0.89523650, grad/param norm = 2.3007e-01, time/batch = 15.2392s	
19661/29850 (epoch 32.933), train_loss = 1.02854873, grad/param norm = 2.4268e-01, time/batch = 14.7264s	
19662/29850 (epoch 32.935), train_loss = 0.95322807, grad/param norm = 2.1799e-01, time/batch = 14.8087s	
19663/29850 (epoch 32.936), train_loss = 0.92280413, grad/param norm = 2.2064e-01, time/batch = 14.7394s	
19664/29850 (epoch 32.938), train_loss = 0.80440042, grad/param norm = 2.5282e-01, time/batch = 14.0899s	
19665/29850 (epoch 32.940), train_loss = 0.78724417, grad/param norm = 2.0561e-01, time/batch = 14.3023s	
19666/29850 (epoch 32.941), train_loss = 0.81124616, grad/param norm = 2.3811e-01, time/batch = 14.3259s	
19667/29850 (epoch 32.943), train_loss = 0.80695833, grad/param norm = 2.1326e-01, time/batch = 14.7121s	
19668/29850 (epoch 32.945), train_loss = 0.78466162, grad/param norm = 2.2391e-01, time/batch = 14.1771s	
19669/29850 (epoch 32.946), train_loss = 0.78868303, grad/param norm = 2.1765e-01, time/batch = 14.0880s	
19670/29850 (epoch 32.948), train_loss = 0.88592367, grad/param norm = 2.2016e-01, time/batch = 14.2497s	
19671/29850 (epoch 32.950), train_loss = 0.82081563, grad/param norm = 1.7476e-01, time/batch = 12.0061s	
19672/29850 (epoch 32.951), train_loss = 0.72871494, grad/param norm = 1.8382e-01, time/batch = 0.6445s	
19673/29850 (epoch 32.953), train_loss = 0.86284329, grad/param norm = 2.8842e-01, time/batch = 0.6391s	
19674/29850 (epoch 32.955), train_loss = 0.75040189, grad/param norm = 1.9915e-01, time/batch = 0.6416s	
19675/29850 (epoch 32.956), train_loss = 0.76875182, grad/param norm = 1.8541e-01, time/batch = 0.6497s	
19676/29850 (epoch 32.958), train_loss = 0.66330410, grad/param norm = 1.7400e-01, time/batch = 0.6516s	
19677/29850 (epoch 32.960), train_loss = 0.97808941, grad/param norm = 2.4997e-01, time/batch = 0.6720s	
19678/29850 (epoch 32.961), train_loss = 0.76357695, grad/param norm = 2.3064e-01, time/batch = 0.6722s	
19679/29850 (epoch 32.963), train_loss = 0.73071997, grad/param norm = 2.1866e-01, time/batch = 0.8438s	
19680/29850 (epoch 32.965), train_loss = 0.78991022, grad/param norm = 2.1782e-01, time/batch = 0.9726s	
19681/29850 (epoch 32.966), train_loss = 0.74008469, grad/param norm = 1.9731e-01, time/batch = 0.9597s	
19682/29850 (epoch 32.968), train_loss = 0.78193118, grad/param norm = 2.1231e-01, time/batch = 0.9518s	
19683/29850 (epoch 32.970), train_loss = 0.74358498, grad/param norm = 2.0989e-01, time/batch = 0.9491s	
19684/29850 (epoch 32.972), train_loss = 0.76765609, grad/param norm = 1.7726e-01, time/batch = 1.2846s	
19685/29850 (epoch 32.973), train_loss = 0.76684365, grad/param norm = 1.8922e-01, time/batch = 1.7816s	
19686/29850 (epoch 32.975), train_loss = 0.67610711, grad/param norm = 1.9886e-01, time/batch = 1.7563s	
19687/29850 (epoch 32.977), train_loss = 0.80490171, grad/param norm = 1.9577e-01, time/batch = 8.8562s	
19688/29850 (epoch 32.978), train_loss = 0.70651986, grad/param norm = 1.7921e-01, time/batch = 14.4917s	
19689/29850 (epoch 32.980), train_loss = 0.78017670, grad/param norm = 1.8095e-01, time/batch = 14.4924s	
19690/29850 (epoch 32.982), train_loss = 0.76833174, grad/param norm = 2.0852e-01, time/batch = 14.9590s	
19691/29850 (epoch 32.983), train_loss = 0.77800122, grad/param norm = 1.7325e-01, time/batch = 14.5907s	
19692/29850 (epoch 32.985), train_loss = 0.89319120, grad/param norm = 2.2528e-01, time/batch = 14.5010s	
19693/29850 (epoch 32.987), train_loss = 0.85275760, grad/param norm = 2.3441e-01, time/batch = 14.3409s	
19694/29850 (epoch 32.988), train_loss = 0.79011513, grad/param norm = 1.9422e-01, time/batch = 15.1912s	
19695/29850 (epoch 32.990), train_loss = 0.87746217, grad/param norm = 2.0331e-01, time/batch = 14.1728s	
19696/29850 (epoch 32.992), train_loss = 0.89331866, grad/param norm = 1.9820e-01, time/batch = 14.2526s	
19697/29850 (epoch 32.993), train_loss = 0.86173470, grad/param norm = 2.1235e-01, time/batch = 14.4084s	
19698/29850 (epoch 32.995), train_loss = 0.88173318, grad/param norm = 2.6701e-01, time/batch = 14.7148s	
19699/29850 (epoch 32.997), train_loss = 0.87680411, grad/param norm = 2.0520e-01, time/batch = 14.5712s	
19700/29850 (epoch 32.998), train_loss = 0.89333124, grad/param norm = 1.9881e-01, time/batch = 14.4742s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
19701/29850 (epoch 33.000), train_loss = 0.73975229, grad/param norm = 1.9341e-01, time/batch = 15.5820s	
19702/29850 (epoch 33.002), train_loss = 0.97685022, grad/param norm = 2.1452e-01, time/batch = 15.4087s	
19703/29850 (epoch 33.003), train_loss = 0.73091613, grad/param norm = 2.1872e-01, time/batch = 15.0354s	
19704/29850 (epoch 33.005), train_loss = 0.89200291, grad/param norm = 1.9929e-01, time/batch = 14.4000s	
19705/29850 (epoch 33.007), train_loss = 0.95230064, grad/param norm = 2.3114e-01, time/batch = 14.0855s	
19706/29850 (epoch 33.008), train_loss = 1.06835190, grad/param norm = 2.5672e-01, time/batch = 14.9452s	
19707/29850 (epoch 33.010), train_loss = 0.78750740, grad/param norm = 2.2271e-01, time/batch = 14.4891s	
19708/29850 (epoch 33.012), train_loss = 0.83086223, grad/param norm = 2.0651e-01, time/batch = 14.5034s	
19709/29850 (epoch 33.013), train_loss = 0.89276892, grad/param norm = 2.2720e-01, time/batch = 14.8867s	
19710/29850 (epoch 33.015), train_loss = 0.93906409, grad/param norm = 2.3503e-01, time/batch = 14.6462s	
19711/29850 (epoch 33.017), train_loss = 0.90605800, grad/param norm = 2.3820e-01, time/batch = 14.4236s	
19712/29850 (epoch 33.018), train_loss = 1.01902137, grad/param norm = 2.5526e-01, time/batch = 14.3331s	
19713/29850 (epoch 33.020), train_loss = 0.85902100, grad/param norm = 2.1151e-01, time/batch = 14.4138s	
19714/29850 (epoch 33.022), train_loss = 0.93889062, grad/param norm = 2.5260e-01, time/batch = 15.0311s	
19715/29850 (epoch 33.023), train_loss = 0.93153762, grad/param norm = 1.9422e-01, time/batch = 14.4090s	
19716/29850 (epoch 33.025), train_loss = 0.84532801, grad/param norm = 2.1375e-01, time/batch = 14.1737s	
19717/29850 (epoch 33.027), train_loss = 0.67760575, grad/param norm = 2.0038e-01, time/batch = 14.6403s	
19718/29850 (epoch 33.028), train_loss = 0.79533209, grad/param norm = 1.9369e-01, time/batch = 14.4865s	
19719/29850 (epoch 33.030), train_loss = 0.81620851, grad/param norm = 2.3161e-01, time/batch = 14.0907s	
19720/29850 (epoch 33.032), train_loss = 0.90323517, grad/param norm = 1.8609e-01, time/batch = 14.0121s	
19721/29850 (epoch 33.034), train_loss = 0.77436741, grad/param norm = 1.9026e-01, time/batch = 14.1744s	
19722/29850 (epoch 33.035), train_loss = 0.70479346, grad/param norm = 1.9276e-01, time/batch = 14.5661s	
19723/29850 (epoch 33.037), train_loss = 0.84659197, grad/param norm = 1.9556e-01, time/batch = 14.4915s	
19724/29850 (epoch 33.039), train_loss = 0.74939206, grad/param norm = 1.7807e-01, time/batch = 14.3394s	
19725/29850 (epoch 33.040), train_loss = 0.76309603, grad/param norm = 1.8732e-01, time/batch = 14.4908s	
19726/29850 (epoch 33.042), train_loss = 0.77545928, grad/param norm = 2.0908e-01, time/batch = 15.2211s	
19727/29850 (epoch 33.044), train_loss = 0.82825499, grad/param norm = 1.9104e-01, time/batch = 14.7298s	
19728/29850 (epoch 33.045), train_loss = 0.92386458, grad/param norm = 2.2048e-01, time/batch = 14.3148s	
19729/29850 (epoch 33.047), train_loss = 0.75228173, grad/param norm = 1.7717e-01, time/batch = 14.7365s	
19730/29850 (epoch 33.049), train_loss = 0.88043978, grad/param norm = 2.1986e-01, time/batch = 14.0824s	
19731/29850 (epoch 33.050), train_loss = 0.77528721, grad/param norm = 1.8652e-01, time/batch = 14.7434s	
19732/29850 (epoch 33.052), train_loss = 0.96836914, grad/param norm = 2.5966e-01, time/batch = 14.3405s	
19733/29850 (epoch 33.054), train_loss = 0.85781030, grad/param norm = 2.3446e-01, time/batch = 14.5594s	
19734/29850 (epoch 33.055), train_loss = 0.81179167, grad/param norm = 2.0541e-01, time/batch = 14.6533s	
19735/29850 (epoch 33.057), train_loss = 0.89121262, grad/param norm = 1.9650e-01, time/batch = 14.8768s	
19736/29850 (epoch 33.059), train_loss = 0.90703899, grad/param norm = 2.1363e-01, time/batch = 14.0144s	
19737/29850 (epoch 33.060), train_loss = 0.86993829, grad/param norm = 2.1880e-01, time/batch = 14.3340s	
19738/29850 (epoch 33.062), train_loss = 0.95603598, grad/param norm = 2.2631e-01, time/batch = 14.5581s	
19739/29850 (epoch 33.064), train_loss = 0.92476291, grad/param norm = 2.2199e-01, time/batch = 14.6343s	
19740/29850 (epoch 33.065), train_loss = 0.74419080, grad/param norm = 1.8660e-01, time/batch = 14.1584s	
19741/29850 (epoch 33.067), train_loss = 0.90526550, grad/param norm = 2.0196e-01, time/batch = 14.4153s	
19742/29850 (epoch 33.069), train_loss = 0.90798762, grad/param norm = 2.0184e-01, time/batch = 15.4884s	
19743/29850 (epoch 33.070), train_loss = 0.90426615, grad/param norm = 2.1326e-01, time/batch = 14.6969s	
19744/29850 (epoch 33.072), train_loss = 0.87549816, grad/param norm = 2.4193e-01, time/batch = 14.9213s	
19745/29850 (epoch 33.074), train_loss = 0.93253505, grad/param norm = 2.0195e-01, time/batch = 14.2411s	
19746/29850 (epoch 33.075), train_loss = 0.80552865, grad/param norm = 2.4346e-01, time/batch = 14.1708s	
19747/29850 (epoch 33.077), train_loss = 0.91288921, grad/param norm = 2.2657e-01, time/batch = 15.3389s	
19748/29850 (epoch 33.079), train_loss = 1.09850324, grad/param norm = 3.2447e-01, time/batch = 15.4182s	
19749/29850 (epoch 33.080), train_loss = 1.04744674, grad/param norm = 2.3497e-01, time/batch = 14.5011s	
19750/29850 (epoch 33.082), train_loss = 0.91987403, grad/param norm = 2.1115e-01, time/batch = 14.5807s	
19751/29850 (epoch 33.084), train_loss = 1.04480143, grad/param norm = 2.6475e-01, time/batch = 14.8266s	
19752/29850 (epoch 33.085), train_loss = 1.05796653, grad/param norm = 2.5256e-01, time/batch = 14.3444s	
19753/29850 (epoch 33.087), train_loss = 1.00657261, grad/param norm = 2.4291e-01, time/batch = 14.7982s	
19754/29850 (epoch 33.089), train_loss = 0.92102599, grad/param norm = 2.0981e-01, time/batch = 14.2648s	
19755/29850 (epoch 33.090), train_loss = 0.92488123, grad/param norm = 2.0950e-01, time/batch = 15.0347s	
19756/29850 (epoch 33.092), train_loss = 0.82950288, grad/param norm = 2.0931e-01, time/batch = 14.7307s	
19757/29850 (epoch 33.094), train_loss = 1.02334194, grad/param norm = 2.3340e-01, time/batch = 14.1723s	
19758/29850 (epoch 33.095), train_loss = 0.94330129, grad/param norm = 2.6749e-01, time/batch = 14.2518s	
19759/29850 (epoch 33.097), train_loss = 0.69776054, grad/param norm = 1.8216e-01, time/batch = 14.9538s	
19760/29850 (epoch 33.099), train_loss = 0.73612019, grad/param norm = 2.0023e-01, time/batch = 14.5755s	
19761/29850 (epoch 33.101), train_loss = 0.95578064, grad/param norm = 2.2111e-01, time/batch = 14.7169s	
19762/29850 (epoch 33.102), train_loss = 0.94508443, grad/param norm = 2.4440e-01, time/batch = 15.0230s	
19763/29850 (epoch 33.104), train_loss = 0.85745992, grad/param norm = 2.5377e-01, time/batch = 14.6379s	
19764/29850 (epoch 33.106), train_loss = 0.97089087, grad/param norm = 2.1205e-01, time/batch = 14.4983s	
19765/29850 (epoch 33.107), train_loss = 0.80924684, grad/param norm = 1.8450e-01, time/batch = 14.4993s	
19766/29850 (epoch 33.109), train_loss = 0.88924793, grad/param norm = 2.1045e-01, time/batch = 14.6193s	
19767/29850 (epoch 33.111), train_loss = 0.93675711, grad/param norm = 2.2135e-01, time/batch = 14.7296s	
19768/29850 (epoch 33.112), train_loss = 0.78766106, grad/param norm = 1.8955e-01, time/batch = 14.2479s	
19769/29850 (epoch 33.114), train_loss = 0.82577327, grad/param norm = 2.0968e-01, time/batch = 13.6892s	
19770/29850 (epoch 33.116), train_loss = 0.81562775, grad/param norm = 2.0579e-01, time/batch = 14.6400s	
19771/29850 (epoch 33.117), train_loss = 0.85335147, grad/param norm = 2.2227e-01, time/batch = 14.2453s	
19772/29850 (epoch 33.119), train_loss = 0.82677245, grad/param norm = 1.9832e-01, time/batch = 14.7465s	
19773/29850 (epoch 33.121), train_loss = 0.69326709, grad/param norm = 1.9154e-01, time/batch = 14.4092s	
19774/29850 (epoch 33.122), train_loss = 0.73716201, grad/param norm = 1.5984e-01, time/batch = 15.0377s	
19775/29850 (epoch 33.124), train_loss = 0.78661989, grad/param norm = 2.1771e-01, time/batch = 15.0770s	
19776/29850 (epoch 33.126), train_loss = 0.80913416, grad/param norm = 1.8542e-01, time/batch = 15.0510s	
19777/29850 (epoch 33.127), train_loss = 0.93012746, grad/param norm = 2.6326e-01, time/batch = 14.9614s	
19778/29850 (epoch 33.129), train_loss = 0.82413567, grad/param norm = 2.1038e-01, time/batch = 14.9654s	
19779/29850 (epoch 33.131), train_loss = 0.86897928, grad/param norm = 2.0138e-01, time/batch = 14.7916s	
19780/29850 (epoch 33.132), train_loss = 0.74302202, grad/param norm = 2.1135e-01, time/batch = 14.6591s	
19781/29850 (epoch 33.134), train_loss = 0.82172122, grad/param norm = 2.0859e-01, time/batch = 14.3409s	
19782/29850 (epoch 33.136), train_loss = 0.92872248, grad/param norm = 2.0543e-01, time/batch = 14.3496s	
19783/29850 (epoch 33.137), train_loss = 0.71482170, grad/param norm = 1.8940e-01, time/batch = 14.4049s	
19784/29850 (epoch 33.139), train_loss = 0.86416467, grad/param norm = 2.1016e-01, time/batch = 14.7263s	
19785/29850 (epoch 33.141), train_loss = 0.77492060, grad/param norm = 2.2061e-01, time/batch = 14.9000s	
19786/29850 (epoch 33.142), train_loss = 1.00326518, grad/param norm = 2.3864e-01, time/batch = 14.7256s	
19787/29850 (epoch 33.144), train_loss = 1.09089478, grad/param norm = 2.5463e-01, time/batch = 14.8052s	
19788/29850 (epoch 33.146), train_loss = 1.10233291, grad/param norm = 2.4069e-01, time/batch = 15.3512s	
19789/29850 (epoch 33.147), train_loss = 0.97383059, grad/param norm = 2.2538e-01, time/batch = 14.2566s	
19790/29850 (epoch 33.149), train_loss = 0.91911421, grad/param norm = 2.4296e-01, time/batch = 14.4213s	
19791/29850 (epoch 33.151), train_loss = 0.92255785, grad/param norm = 2.3595e-01, time/batch = 14.4138s	
19792/29850 (epoch 33.152), train_loss = 0.85112329, grad/param norm = 2.1210e-01, time/batch = 14.8738s	
19793/29850 (epoch 33.154), train_loss = 0.81572736, grad/param norm = 2.1874e-01, time/batch = 14.5707s	
19794/29850 (epoch 33.156), train_loss = 0.80169470, grad/param norm = 2.1910e-01, time/batch = 14.5819s	
19795/29850 (epoch 33.157), train_loss = 0.91703790, grad/param norm = 2.3006e-01, time/batch = 14.0013s	
19796/29850 (epoch 33.159), train_loss = 0.83070466, grad/param norm = 2.0185e-01, time/batch = 14.8707s	
19797/29850 (epoch 33.161), train_loss = 0.87848902, grad/param norm = 2.3064e-01, time/batch = 14.0104s	
19798/29850 (epoch 33.162), train_loss = 0.97620877, grad/param norm = 2.1949e-01, time/batch = 14.5588s	
19799/29850 (epoch 33.164), train_loss = 0.90235652, grad/param norm = 2.2222e-01, time/batch = 14.2543s	
19800/29850 (epoch 33.166), train_loss = 0.84310610, grad/param norm = 2.1184e-01, time/batch = 14.7181s	
19801/29850 (epoch 33.168), train_loss = 0.73443769, grad/param norm = 1.8150e-01, time/batch = 14.3445s	
19802/29850 (epoch 33.169), train_loss = 0.99760050, grad/param norm = 2.3937e-01, time/batch = 14.7081s	
19803/29850 (epoch 33.171), train_loss = 0.91747241, grad/param norm = 2.0021e-01, time/batch = 13.9269s	
19804/29850 (epoch 33.173), train_loss = 0.78908094, grad/param norm = 2.1001e-01, time/batch = 14.2368s	
19805/29850 (epoch 33.174), train_loss = 0.88182630, grad/param norm = 2.3064e-01, time/batch = 13.9294s	
19806/29850 (epoch 33.176), train_loss = 0.89709073, grad/param norm = 2.1212e-01, time/batch = 14.0890s	
19807/29850 (epoch 33.178), train_loss = 0.90686052, grad/param norm = 2.8656e-01, time/batch = 14.8168s	
19808/29850 (epoch 33.179), train_loss = 0.74973855, grad/param norm = 2.0643e-01, time/batch = 15.5826s	
19809/29850 (epoch 33.181), train_loss = 0.89009509, grad/param norm = 2.2639e-01, time/batch = 14.8846s	
19810/29850 (epoch 33.183), train_loss = 0.88475644, grad/param norm = 1.9109e-01, time/batch = 14.2587s	
19811/29850 (epoch 33.184), train_loss = 0.92591638, grad/param norm = 2.2324e-01, time/batch = 14.4217s	
19812/29850 (epoch 33.186), train_loss = 0.87367677, grad/param norm = 2.2129e-01, time/batch = 14.4011s	
19813/29850 (epoch 33.188), train_loss = 1.00619766, grad/param norm = 2.3459e-01, time/batch = 14.6556s	
19814/29850 (epoch 33.189), train_loss = 0.99664218, grad/param norm = 2.7885e-01, time/batch = 14.4213s	
19815/29850 (epoch 33.191), train_loss = 0.96799515, grad/param norm = 2.1776e-01, time/batch = 14.2590s	
19816/29850 (epoch 33.193), train_loss = 0.86578853, grad/param norm = 2.0480e-01, time/batch = 14.4035s	
19817/29850 (epoch 33.194), train_loss = 0.96314426, grad/param norm = 2.3606e-01, time/batch = 14.8072s	
19818/29850 (epoch 33.196), train_loss = 0.86041078, grad/param norm = 2.2612e-01, time/batch = 14.5000s	
19819/29850 (epoch 33.198), train_loss = 0.83182142, grad/param norm = 2.2151e-01, time/batch = 14.4201s	
19820/29850 (epoch 33.199), train_loss = 1.07354370, grad/param norm = 2.4523e-01, time/batch = 14.7147s	
19821/29850 (epoch 33.201), train_loss = 0.81432785, grad/param norm = 2.4262e-01, time/batch = 14.8181s	
19822/29850 (epoch 33.203), train_loss = 0.66030471, grad/param norm = 2.0661e-01, time/batch = 14.4163s	
19823/29850 (epoch 33.204), train_loss = 0.84580782, grad/param norm = 2.2537e-01, time/batch = 14.4816s	
19824/29850 (epoch 33.206), train_loss = 0.76835780, grad/param norm = 2.1728e-01, time/batch = 14.0072s	
19825/29850 (epoch 33.208), train_loss = 1.01102326, grad/param norm = 2.4835e-01, time/batch = 14.5566s	
19826/29850 (epoch 33.209), train_loss = 0.77479202, grad/param norm = 2.1638e-01, time/batch = 14.0897s	
19827/29850 (epoch 33.211), train_loss = 0.82771525, grad/param norm = 2.0477e-01, time/batch = 14.2562s	
19828/29850 (epoch 33.213), train_loss = 0.94011235, grad/param norm = 2.5185e-01, time/batch = 14.5025s	
19829/29850 (epoch 33.214), train_loss = 0.76969099, grad/param norm = 1.8961e-01, time/batch = 15.1007s	
19830/29850 (epoch 33.216), train_loss = 0.81018609, grad/param norm = 2.2654e-01, time/batch = 15.0243s	
19831/29850 (epoch 33.218), train_loss = 0.89093198, grad/param norm = 2.0506e-01, time/batch = 14.4869s	
19832/29850 (epoch 33.219), train_loss = 0.93236752, grad/param norm = 2.6312e-01, time/batch = 14.2531s	
19833/29850 (epoch 33.221), train_loss = 0.88610771, grad/param norm = 2.5375e-01, time/batch = 14.9635s	
19834/29850 (epoch 33.223), train_loss = 0.75642522, grad/param norm = 2.1016e-01, time/batch = 15.2557s	
19835/29850 (epoch 33.224), train_loss = 0.75983562, grad/param norm = 2.4659e-01, time/batch = 14.2502s	
19836/29850 (epoch 33.226), train_loss = 0.79216374, grad/param norm = 1.9443e-01, time/batch = 14.4180s	
19837/29850 (epoch 33.228), train_loss = 0.85303328, grad/param norm = 2.0448e-01, time/batch = 14.7939s	
19838/29850 (epoch 33.229), train_loss = 0.71256157, grad/param norm = 1.8721e-01, time/batch = 14.4630s	
19839/29850 (epoch 33.231), train_loss = 0.86140647, grad/param norm = 2.0199e-01, time/batch = 14.0116s	
19840/29850 (epoch 33.233), train_loss = 0.86089629, grad/param norm = 2.1229e-01, time/batch = 13.9244s	
19841/29850 (epoch 33.235), train_loss = 0.80159777, grad/param norm = 2.0354e-01, time/batch = 14.4072s	
19842/29850 (epoch 33.236), train_loss = 1.01032236, grad/param norm = 2.5996e-01, time/batch = 14.3347s	
19843/29850 (epoch 33.238), train_loss = 0.75747435, grad/param norm = 2.2693e-01, time/batch = 14.3284s	
19844/29850 (epoch 33.240), train_loss = 0.74211669, grad/param norm = 1.9013e-01, time/batch = 14.3448s	
19845/29850 (epoch 33.241), train_loss = 0.91635294, grad/param norm = 2.1685e-01, time/batch = 14.6408s	
19846/29850 (epoch 33.243), train_loss = 0.91398832, grad/param norm = 2.1077e-01, time/batch = 14.5047s	
19847/29850 (epoch 33.245), train_loss = 0.80405875, grad/param norm = 2.1514e-01, time/batch = 14.1031s	
19848/29850 (epoch 33.246), train_loss = 0.73981229, grad/param norm = 1.7888e-01, time/batch = 14.4880s	
19849/29850 (epoch 33.248), train_loss = 0.73062389, grad/param norm = 1.8161e-01, time/batch = 14.9646s	
19850/29850 (epoch 33.250), train_loss = 0.82828882, grad/param norm = 1.8827e-01, time/batch = 14.7308s	
19851/29850 (epoch 33.251), train_loss = 0.73341671, grad/param norm = 2.0546e-01, time/batch = 14.6513s	
19852/29850 (epoch 33.253), train_loss = 0.69065834, grad/param norm = 2.1067e-01, time/batch = 14.6372s	
19853/29850 (epoch 33.255), train_loss = 0.78154971, grad/param norm = 2.1357e-01, time/batch = 14.4129s	
19854/29850 (epoch 33.256), train_loss = 0.89779510, grad/param norm = 2.1952e-01, time/batch = 14.4271s	
19855/29850 (epoch 33.258), train_loss = 0.90360896, grad/param norm = 2.2641e-01, time/batch = 14.2644s	
19856/29850 (epoch 33.260), train_loss = 0.84659646, grad/param norm = 1.9397e-01, time/batch = 14.6550s	
19857/29850 (epoch 33.261), train_loss = 0.78816933, grad/param norm = 2.4172e-01, time/batch = 14.4071s	
19858/29850 (epoch 33.263), train_loss = 0.79295576, grad/param norm = 2.0240e-01, time/batch = 15.2150s	
19859/29850 (epoch 33.265), train_loss = 0.86025937, grad/param norm = 2.4141e-01, time/batch = 14.4269s	
19860/29850 (epoch 33.266), train_loss = 0.83512084, grad/param norm = 2.1552e-01, time/batch = 14.3416s	
19861/29850 (epoch 33.268), train_loss = 0.81435282, grad/param norm = 1.8100e-01, time/batch = 15.0854s	
19862/29850 (epoch 33.270), train_loss = 0.80570810, grad/param norm = 2.5251e-01, time/batch = 15.2741s	
19863/29850 (epoch 33.271), train_loss = 0.92051746, grad/param norm = 2.3077e-01, time/batch = 15.6288s	
19864/29850 (epoch 33.273), train_loss = 0.74888318, grad/param norm = 2.0834e-01, time/batch = 16.4937s	
19865/29850 (epoch 33.275), train_loss = 0.74922458, grad/param norm = 2.1740e-01, time/batch = 16.9397s	
19866/29850 (epoch 33.276), train_loss = 0.73465190, grad/param norm = 1.8591e-01, time/batch = 16.7996s	
19867/29850 (epoch 33.278), train_loss = 0.81142563, grad/param norm = 2.1327e-01, time/batch = 18.5447s	
19868/29850 (epoch 33.280), train_loss = 1.01674578, grad/param norm = 3.0749e-01, time/batch = 18.0515s	
19869/29850 (epoch 33.281), train_loss = 0.88161505, grad/param norm = 2.2269e-01, time/batch = 30.9120s	
19870/29850 (epoch 33.283), train_loss = 0.98326126, grad/param norm = 2.5929e-01, time/batch = 15.7758s	
19871/29850 (epoch 33.285), train_loss = 0.93690583, grad/param norm = 2.3332e-01, time/batch = 16.2983s	
19872/29850 (epoch 33.286), train_loss = 0.97497539, grad/param norm = 2.5837e-01, time/batch = 18.2012s	
19873/29850 (epoch 33.288), train_loss = 0.97170957, grad/param norm = 2.8946e-01, time/batch = 16.2906s	
19874/29850 (epoch 33.290), train_loss = 0.88497055, grad/param norm = 2.5969e-01, time/batch = 18.9541s	
19875/29850 (epoch 33.291), train_loss = 1.07997614, grad/param norm = 2.4071e-01, time/batch = 15.3725s	
19876/29850 (epoch 33.293), train_loss = 0.97396876, grad/param norm = 2.4877e-01, time/batch = 17.8922s	
19877/29850 (epoch 33.295), train_loss = 1.03370309, grad/param norm = 2.2325e-01, time/batch = 18.7992s	
19878/29850 (epoch 33.296), train_loss = 0.78015553, grad/param norm = 2.0025e-01, time/batch = 17.3088s	
19879/29850 (epoch 33.298), train_loss = 0.66166772, grad/param norm = 1.7533e-01, time/batch = 17.0590s	
19880/29850 (epoch 33.300), train_loss = 0.76458339, grad/param norm = 1.9266e-01, time/batch = 19.2919s	
19881/29850 (epoch 33.302), train_loss = 0.76233520, grad/param norm = 2.4516e-01, time/batch = 18.3623s	
19882/29850 (epoch 33.303), train_loss = 0.81033803, grad/param norm = 2.3220e-01, time/batch = 15.6862s	
19883/29850 (epoch 33.305), train_loss = 0.92435454, grad/param norm = 2.1172e-01, time/batch = 18.7078s	
19884/29850 (epoch 33.307), train_loss = 0.94419561, grad/param norm = 2.0734e-01, time/batch = 17.4723s	
19885/29850 (epoch 33.308), train_loss = 0.76212300, grad/param norm = 2.0451e-01, time/batch = 16.3756s	
19886/29850 (epoch 33.310), train_loss = 0.88572556, grad/param norm = 2.1458e-01, time/batch = 16.9827s	
19887/29850 (epoch 33.312), train_loss = 0.92952461, grad/param norm = 2.0785e-01, time/batch = 18.2022s	
19888/29850 (epoch 33.313), train_loss = 0.88398899, grad/param norm = 2.1506e-01, time/batch = 17.9424s	
19889/29850 (epoch 33.315), train_loss = 0.88936669, grad/param norm = 2.2176e-01, time/batch = 17.0582s	
19890/29850 (epoch 33.317), train_loss = 0.86753961, grad/param norm = 2.2441e-01, time/batch = 16.2856s	
19891/29850 (epoch 33.318), train_loss = 0.85730777, grad/param norm = 2.0594e-01, time/batch = 16.6858s	
19892/29850 (epoch 33.320), train_loss = 0.79429086, grad/param norm = 2.1586e-01, time/batch = 15.5927s	
19893/29850 (epoch 33.322), train_loss = 1.01086515, grad/param norm = 2.4598e-01, time/batch = 17.4569s	
19894/29850 (epoch 33.323), train_loss = 0.91587191, grad/param norm = 2.2695e-01, time/batch = 17.4672s	
19895/29850 (epoch 33.325), train_loss = 0.96862636, grad/param norm = 2.0323e-01, time/batch = 18.2011s	
19896/29850 (epoch 33.327), train_loss = 1.08542992, grad/param norm = 2.4301e-01, time/batch = 19.1178s	
19897/29850 (epoch 33.328), train_loss = 1.01524535, grad/param norm = 2.9522e-01, time/batch = 18.2095s	
19898/29850 (epoch 33.330), train_loss = 0.94147498, grad/param norm = 2.0584e-01, time/batch = 18.8004s	
19899/29850 (epoch 33.332), train_loss = 0.84914811, grad/param norm = 2.3860e-01, time/batch = 16.6275s	
19900/29850 (epoch 33.333), train_loss = 0.93732554, grad/param norm = 2.5534e-01, time/batch = 18.3747s	
19901/29850 (epoch 33.335), train_loss = 0.96995726, grad/param norm = 2.1339e-01, time/batch = 18.6487s	
19902/29850 (epoch 33.337), train_loss = 0.89091691, grad/param norm = 2.2556e-01, time/batch = 16.2962s	
19903/29850 (epoch 33.338), train_loss = 0.90332143, grad/param norm = 2.1185e-01, time/batch = 17.2973s	
19904/29850 (epoch 33.340), train_loss = 0.76115117, grad/param norm = 1.9787e-01, time/batch = 17.1406s	
19905/29850 (epoch 33.342), train_loss = 0.89217649, grad/param norm = 2.5326e-01, time/batch = 18.3704s	
19906/29850 (epoch 33.343), train_loss = 0.88206017, grad/param norm = 2.3375e-01, time/batch = 18.8729s	
19907/29850 (epoch 33.345), train_loss = 0.96924735, grad/param norm = 2.5188e-01, time/batch = 16.2772s	
19908/29850 (epoch 33.347), train_loss = 0.97086080, grad/param norm = 2.3136e-01, time/batch = 19.8621s	
19909/29850 (epoch 33.348), train_loss = 0.81772324, grad/param norm = 2.3820e-01, time/batch = 15.5291s	
19910/29850 (epoch 33.350), train_loss = 0.95192753, grad/param norm = 2.4690e-01, time/batch = 19.0425s	
19911/29850 (epoch 33.352), train_loss = 0.83812039, grad/param norm = 2.0577e-01, time/batch = 17.6270s	
19912/29850 (epoch 33.353), train_loss = 0.90999541, grad/param norm = 2.1291e-01, time/batch = 15.9412s	
19913/29850 (epoch 33.355), train_loss = 0.84891917, grad/param norm = 2.3954e-01, time/batch = 19.1341s	
19914/29850 (epoch 33.357), train_loss = 0.94226796, grad/param norm = 2.1597e-01, time/batch = 18.6283s	
19915/29850 (epoch 33.358), train_loss = 0.80546562, grad/param norm = 2.0443e-01, time/batch = 17.5476s	
19916/29850 (epoch 33.360), train_loss = 0.85731904, grad/param norm = 2.0577e-01, time/batch = 17.0536s	
19917/29850 (epoch 33.362), train_loss = 0.86028317, grad/param norm = 2.0400e-01, time/batch = 19.2879s	
19918/29850 (epoch 33.363), train_loss = 0.90796093, grad/param norm = 2.1578e-01, time/batch = 19.1381s	
19919/29850 (epoch 33.365), train_loss = 1.01714181, grad/param norm = 2.5487e-01, time/batch = 16.6186s	
19920/29850 (epoch 33.367), train_loss = 0.80532927, grad/param norm = 1.9225e-01, time/batch = 19.2159s	
19921/29850 (epoch 33.369), train_loss = 0.74457736, grad/param norm = 2.1314e-01, time/batch = 17.3692s	
19922/29850 (epoch 33.370), train_loss = 0.70350642, grad/param norm = 1.8672e-01, time/batch = 16.5201s	
19923/29850 (epoch 33.372), train_loss = 0.97023410, grad/param norm = 2.2740e-01, time/batch = 18.8867s	
19924/29850 (epoch 33.374), train_loss = 0.96458377, grad/param norm = 2.1568e-01, time/batch = 18.7142s	
19925/29850 (epoch 33.375), train_loss = 0.89489732, grad/param norm = 2.1269e-01, time/batch = 15.6202s	
19926/29850 (epoch 33.377), train_loss = 0.80350542, grad/param norm = 2.2907e-01, time/batch = 16.8557s	
19927/29850 (epoch 33.379), train_loss = 1.00613569, grad/param norm = 2.4556e-01, time/batch = 16.0316s	
19928/29850 (epoch 33.380), train_loss = 0.92224647, grad/param norm = 2.1406e-01, time/batch = 17.7946s	
19929/29850 (epoch 33.382), train_loss = 0.90007406, grad/param norm = 2.6628e-01, time/batch = 17.5378s	
19930/29850 (epoch 33.384), train_loss = 0.94666986, grad/param norm = 2.0973e-01, time/batch = 17.8012s	
19931/29850 (epoch 33.385), train_loss = 0.91211892, grad/param norm = 2.1547e-01, time/batch = 20.1363s	
19932/29850 (epoch 33.387), train_loss = 0.92891451, grad/param norm = 2.2933e-01, time/batch = 16.2185s	
19933/29850 (epoch 33.389), train_loss = 1.00339270, grad/param norm = 2.4012e-01, time/batch = 18.8032s	
19934/29850 (epoch 33.390), train_loss = 0.96773515, grad/param norm = 2.2610e-01, time/batch = 17.5560s	
19935/29850 (epoch 33.392), train_loss = 0.86297990, grad/param norm = 2.2886e-01, time/batch = 18.6985s	
19936/29850 (epoch 33.394), train_loss = 0.98340467, grad/param norm = 2.4752e-01, time/batch = 16.9200s	
19937/29850 (epoch 33.395), train_loss = 0.82704912, grad/param norm = 2.2008e-01, time/batch = 18.5506s	
19938/29850 (epoch 33.397), train_loss = 0.77874397, grad/param norm = 2.2977e-01, time/batch = 15.2940s	
19939/29850 (epoch 33.399), train_loss = 0.79794392, grad/param norm = 2.1716e-01, time/batch = 17.2929s	
19940/29850 (epoch 33.400), train_loss = 1.15632643, grad/param norm = 2.5359e-01, time/batch = 18.2802s	
19941/29850 (epoch 33.402), train_loss = 1.03726013, grad/param norm = 2.2152e-01, time/batch = 17.5558s	
19942/29850 (epoch 33.404), train_loss = 0.89895717, grad/param norm = 2.1613e-01, time/batch = 18.0397s	
19943/29850 (epoch 33.405), train_loss = 0.82871412, grad/param norm = 2.2649e-01, time/batch = 16.6200s	
19944/29850 (epoch 33.407), train_loss = 0.81236007, grad/param norm = 2.0363e-01, time/batch = 15.6871s	
19945/29850 (epoch 33.409), train_loss = 0.91916228, grad/param norm = 2.2526e-01, time/batch = 19.0491s	
19946/29850 (epoch 33.410), train_loss = 0.99915538, grad/param norm = 2.1687e-01, time/batch = 18.3654s	
19947/29850 (epoch 33.412), train_loss = 0.99934814, grad/param norm = 2.4608e-01, time/batch = 19.4508s	
19948/29850 (epoch 33.414), train_loss = 0.91072796, grad/param norm = 2.4752e-01, time/batch = 18.7721s	
19949/29850 (epoch 33.415), train_loss = 0.88819974, grad/param norm = 1.9668e-01, time/batch = 15.9699s	
19950/29850 (epoch 33.417), train_loss = 1.03678451, grad/param norm = 2.5509e-01, time/batch = 19.7836s	
19951/29850 (epoch 33.419), train_loss = 0.88185836, grad/param norm = 2.5864e-01, time/batch = 19.0516s	
19952/29850 (epoch 33.420), train_loss = 0.89461368, grad/param norm = 2.3498e-01, time/batch = 19.7506s	
19953/29850 (epoch 33.422), train_loss = 0.89241471, grad/param norm = 2.2161e-01, time/batch = 19.8091s	
19954/29850 (epoch 33.424), train_loss = 0.81181738, grad/param norm = 2.1206e-01, time/batch = 22.9915s	
19955/29850 (epoch 33.425), train_loss = 0.98449614, grad/param norm = 2.5519e-01, time/batch = 27.0141s	
19956/29850 (epoch 33.427), train_loss = 0.71022544, grad/param norm = 2.0956e-01, time/batch = 21.6647s	
19957/29850 (epoch 33.429), train_loss = 0.79326513, grad/param norm = 2.1291e-01, time/batch = 24.2754s	
19958/29850 (epoch 33.430), train_loss = 0.73669693, grad/param norm = 1.7784e-01, time/batch = 19.2958s	
19959/29850 (epoch 33.432), train_loss = 0.82593568, grad/param norm = 2.2560e-01, time/batch = 22.9460s	
19960/29850 (epoch 33.434), train_loss = 0.79290711, grad/param norm = 1.8548e-01, time/batch = 23.3935s	
19961/29850 (epoch 33.436), train_loss = 0.86072740, grad/param norm = 2.1493e-01, time/batch = 22.7499s	
19962/29850 (epoch 33.437), train_loss = 0.93275939, grad/param norm = 2.1117e-01, time/batch = 29.0890s	
19963/29850 (epoch 33.439), train_loss = 0.92904305, grad/param norm = 2.0097e-01, time/batch = 24.2938s	
19964/29850 (epoch 33.441), train_loss = 0.89096754, grad/param norm = 2.2081e-01, time/batch = 24.8027s	
19965/29850 (epoch 33.442), train_loss = 0.86425044, grad/param norm = 2.1092e-01, time/batch = 24.0579s	
19966/29850 (epoch 33.444), train_loss = 0.89524639, grad/param norm = 2.2713e-01, time/batch = 25.2906s	
19967/29850 (epoch 33.446), train_loss = 0.95458539, grad/param norm = 2.2930e-01, time/batch = 24.8676s	
19968/29850 (epoch 33.447), train_loss = 0.96357590, grad/param norm = 2.4044e-01, time/batch = 24.9671s	
19969/29850 (epoch 33.449), train_loss = 0.89786636, grad/param norm = 2.3000e-01, time/batch = 25.7086s	
19970/29850 (epoch 33.451), train_loss = 0.68891676, grad/param norm = 1.7572e-01, time/batch = 23.2273s	
19971/29850 (epoch 33.452), train_loss = 0.63038514, grad/param norm = 1.8689e-01, time/batch = 32.0256s	
19972/29850 (epoch 33.454), train_loss = 0.75939639, grad/param norm = 1.8504e-01, time/batch = 25.6002s	
19973/29850 (epoch 33.456), train_loss = 0.94419233, grad/param norm = 2.4221e-01, time/batch = 18.8065s	
19974/29850 (epoch 33.457), train_loss = 0.95314200, grad/param norm = 2.7436e-01, time/batch = 17.9663s	
19975/29850 (epoch 33.459), train_loss = 1.01983349, grad/param norm = 2.3817e-01, time/batch = 16.0212s	
19976/29850 (epoch 33.461), train_loss = 1.01509418, grad/param norm = 2.3401e-01, time/batch = 16.0705s	
19977/29850 (epoch 33.462), train_loss = 1.02494638, grad/param norm = 2.3061e-01, time/batch = 16.7932s	
19978/29850 (epoch 33.464), train_loss = 0.92201384, grad/param norm = 2.2151e-01, time/batch = 16.4021s	
19979/29850 (epoch 33.466), train_loss = 0.76765149, grad/param norm = 2.0353e-01, time/batch = 15.6244s	
19980/29850 (epoch 33.467), train_loss = 0.83312570, grad/param norm = 2.2645e-01, time/batch = 15.9641s	
19981/29850 (epoch 33.469), train_loss = 0.85424213, grad/param norm = 2.0280e-01, time/batch = 16.3215s	
19982/29850 (epoch 33.471), train_loss = 0.85255409, grad/param norm = 2.2750e-01, time/batch = 15.8129s	
19983/29850 (epoch 33.472), train_loss = 0.80478135, grad/param norm = 2.2034e-01, time/batch = 16.3152s	
19984/29850 (epoch 33.474), train_loss = 0.97099222, grad/param norm = 2.1710e-01, time/batch = 16.6378s	
19985/29850 (epoch 33.476), train_loss = 0.89667345, grad/param norm = 1.9909e-01, time/batch = 15.6051s	
19986/29850 (epoch 33.477), train_loss = 0.90810005, grad/param norm = 2.3719e-01, time/batch = 15.8831s	
19987/29850 (epoch 33.479), train_loss = 1.07871171, grad/param norm = 2.4859e-01, time/batch = 16.0352s	
19988/29850 (epoch 33.481), train_loss = 0.85818311, grad/param norm = 2.1602e-01, time/batch = 15.5807s	
19989/29850 (epoch 33.482), train_loss = 0.79571188, grad/param norm = 1.7640e-01, time/batch = 15.0996s	
19990/29850 (epoch 33.484), train_loss = 0.83165084, grad/param norm = 2.0805e-01, time/batch = 14.5815s	
19991/29850 (epoch 33.486), train_loss = 0.92576380, grad/param norm = 2.4649e-01, time/batch = 16.1541s	
19992/29850 (epoch 33.487), train_loss = 0.88890239, grad/param norm = 2.1118e-01, time/batch = 15.4881s	
19993/29850 (epoch 33.489), train_loss = 0.88981279, grad/param norm = 2.1443e-01, time/batch = 15.7527s	
19994/29850 (epoch 33.491), train_loss = 0.78688821, grad/param norm = 1.8597e-01, time/batch = 16.0616s	
19995/29850 (epoch 33.492), train_loss = 0.89520312, grad/param norm = 2.5552e-01, time/batch = 16.2576s	
19996/29850 (epoch 33.494), train_loss = 0.94247448, grad/param norm = 2.2641e-01, time/batch = 15.8990s	
19997/29850 (epoch 33.496), train_loss = 0.98715803, grad/param norm = 2.1411e-01, time/batch = 15.3950s	
19998/29850 (epoch 33.497), train_loss = 0.91132636, grad/param norm = 2.0247e-01, time/batch = 15.0552s	
19999/29850 (epoch 33.499), train_loss = 0.90621410, grad/param norm = 2.0522e-01, time/batch = 16.0042s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch33.50_1.8231.t7	
20000/29850 (epoch 33.501), train_loss = 0.80799724, grad/param norm = 2.6716e-01, time/batch = 15.1608s	
20001/29850 (epoch 33.503), train_loss = 1.48960485, grad/param norm = 2.6796e-01, time/batch = 15.3949s	
20002/29850 (epoch 33.504), train_loss = 1.08200005, grad/param norm = 2.2160e-01, time/batch = 16.3175s	
20003/29850 (epoch 33.506), train_loss = 1.06149306, grad/param norm = 2.3187e-01, time/batch = 15.9043s	
20004/29850 (epoch 33.508), train_loss = 0.92282409, grad/param norm = 2.0828e-01, time/batch = 16.0704s	
20005/29850 (epoch 33.509), train_loss = 0.73825127, grad/param norm = 2.3117e-01, time/batch = 16.4584s	
20006/29850 (epoch 33.511), train_loss = 0.92604218, grad/param norm = 2.4846e-01, time/batch = 15.9981s	
20007/29850 (epoch 33.513), train_loss = 0.92079474, grad/param norm = 3.3362e-01, time/batch = 16.2204s	
20008/29850 (epoch 33.514), train_loss = 0.80475013, grad/param norm = 2.1967e-01, time/batch = 16.4564s	
20009/29850 (epoch 33.516), train_loss = 0.85017201, grad/param norm = 1.8957e-01, time/batch = 15.7291s	
20010/29850 (epoch 33.518), train_loss = 0.72768088, grad/param norm = 1.9181e-01, time/batch = 15.9723s	
20011/29850 (epoch 33.519), train_loss = 0.71578781, grad/param norm = 1.9476e-01, time/batch = 15.1592s	
20012/29850 (epoch 33.521), train_loss = 0.65006337, grad/param norm = 1.7274e-01, time/batch = 15.2796s	
20013/29850 (epoch 33.523), train_loss = 0.73541192, grad/param norm = 1.9699e-01, time/batch = 15.2983s	
20014/29850 (epoch 33.524), train_loss = 0.78899063, grad/param norm = 2.3777e-01, time/batch = 16.4915s	
20015/29850 (epoch 33.526), train_loss = 0.85806209, grad/param norm = 2.3243e-01, time/batch = 16.2432s	
20016/29850 (epoch 33.528), train_loss = 0.95075071, grad/param norm = 2.3329e-01, time/batch = 15.1318s	
20017/29850 (epoch 33.529), train_loss = 0.92145112, grad/param norm = 2.0505e-01, time/batch = 17.5487s	
20018/29850 (epoch 33.531), train_loss = 0.88805591, grad/param norm = 2.5348e-01, time/batch = 15.3806s	
20019/29850 (epoch 33.533), train_loss = 0.87331803, grad/param norm = 2.2226e-01, time/batch = 16.7869s	
20020/29850 (epoch 33.534), train_loss = 0.93366036, grad/param norm = 2.2656e-01, time/batch = 16.6260s	
20021/29850 (epoch 33.536), train_loss = 0.82425372, grad/param norm = 2.4466e-01, time/batch = 16.9822s	
20022/29850 (epoch 33.538), train_loss = 1.01300655, grad/param norm = 2.6655e-01, time/batch = 16.5557s	
20023/29850 (epoch 33.539), train_loss = 1.02999215, grad/param norm = 2.5330e-01, time/batch = 16.1016s	
20024/29850 (epoch 33.541), train_loss = 0.67551003, grad/param norm = 2.1059e-01, time/batch = 16.2236s	
20025/29850 (epoch 33.543), train_loss = 0.83966234, grad/param norm = 2.1337e-01, time/batch = 16.8172s	
20026/29850 (epoch 33.544), train_loss = 0.96831364, grad/param norm = 2.3639e-01, time/batch = 15.9935s	
20027/29850 (epoch 33.546), train_loss = 0.93379514, grad/param norm = 2.1817e-01, time/batch = 16.1323s	
20028/29850 (epoch 33.548), train_loss = 0.74399675, grad/param norm = 1.9319e-01, time/batch = 15.8653s	
20029/29850 (epoch 33.549), train_loss = 0.83984590, grad/param norm = 2.0109e-01, time/batch = 15.4015s	
20030/29850 (epoch 33.551), train_loss = 0.77227113, grad/param norm = 1.9846e-01, time/batch = 15.6654s	
20031/29850 (epoch 33.553), train_loss = 0.87844946, grad/param norm = 2.1017e-01, time/batch = 16.6312s	
20032/29850 (epoch 33.554), train_loss = 0.71913757, grad/param norm = 2.0724e-01, time/batch = 16.2127s	
20033/29850 (epoch 33.556), train_loss = 0.76154458, grad/param norm = 2.0719e-01, time/batch = 16.2441s	
20034/29850 (epoch 33.558), train_loss = 0.78560961, grad/param norm = 2.0026e-01, time/batch = 15.3095s	
20035/29850 (epoch 33.559), train_loss = 0.82283125, grad/param norm = 2.2237e-01, time/batch = 15.6296s	
20036/29850 (epoch 33.561), train_loss = 0.89325899, grad/param norm = 2.2962e-01, time/batch = 15.8940s	
20037/29850 (epoch 33.563), train_loss = 0.91347521, grad/param norm = 2.2063e-01, time/batch = 15.1580s	
20038/29850 (epoch 33.564), train_loss = 0.83625985, grad/param norm = 2.1646e-01, time/batch = 16.2261s	
20039/29850 (epoch 33.566), train_loss = 0.86228713, grad/param norm = 2.0420e-01, time/batch = 15.0431s	
20040/29850 (epoch 33.568), train_loss = 0.99613221, grad/param norm = 2.3263e-01, time/batch = 16.2364s	
20041/29850 (epoch 33.570), train_loss = 0.90882577, grad/param norm = 2.1862e-01, time/batch = 16.2298s	
20042/29850 (epoch 33.571), train_loss = 0.96579206, grad/param norm = 2.1496e-01, time/batch = 16.2074s	
20043/29850 (epoch 33.573), train_loss = 1.03286631, grad/param norm = 2.5591e-01, time/batch = 16.1558s	
20044/29850 (epoch 33.575), train_loss = 1.05943964, grad/param norm = 2.4353e-01, time/batch = 16.3244s	
20045/29850 (epoch 33.576), train_loss = 0.99676642, grad/param norm = 2.7719e-01, time/batch = 15.0465s	
20046/29850 (epoch 33.578), train_loss = 0.83291810, grad/param norm = 2.2470e-01, time/batch = 15.4661s	
20047/29850 (epoch 33.580), train_loss = 0.97045151, grad/param norm = 1.9852e-01, time/batch = 15.4796s	
20048/29850 (epoch 33.581), train_loss = 0.79590279, grad/param norm = 2.1245e-01, time/batch = 15.5626s	
20049/29850 (epoch 33.583), train_loss = 0.85910840, grad/param norm = 2.3320e-01, time/batch = 15.9827s	
20050/29850 (epoch 33.585), train_loss = 0.90129344, grad/param norm = 1.9886e-01, time/batch = 16.3130s	
20051/29850 (epoch 33.586), train_loss = 0.91898349, grad/param norm = 2.5842e-01, time/batch = 16.0580s	
20052/29850 (epoch 33.588), train_loss = 0.82154595, grad/param norm = 2.1506e-01, time/batch = 15.3795s	
20053/29850 (epoch 33.590), train_loss = 0.83088756, grad/param norm = 2.0304e-01, time/batch = 15.3257s	
20054/29850 (epoch 33.591), train_loss = 0.85085316, grad/param norm = 2.3830e-01, time/batch = 15.3925s	
20055/29850 (epoch 33.593), train_loss = 0.80273636, grad/param norm = 2.0029e-01, time/batch = 16.0645s	
20056/29850 (epoch 33.595), train_loss = 0.75711558, grad/param norm = 1.7127e-01, time/batch = 16.5548s	
20057/29850 (epoch 33.596), train_loss = 0.76691400, grad/param norm = 2.0089e-01, time/batch = 14.8000s	
20058/29850 (epoch 33.598), train_loss = 0.87286199, grad/param norm = 2.1104e-01, time/batch = 15.5759s	
20059/29850 (epoch 33.600), train_loss = 0.90040371, grad/param norm = 2.3065e-01, time/batch = 15.9635s	
20060/29850 (epoch 33.601), train_loss = 0.75038903, grad/param norm = 1.8614e-01, time/batch = 16.7477s	
20061/29850 (epoch 33.603), train_loss = 0.80366134, grad/param norm = 1.9647e-01, time/batch = 16.1414s	
20062/29850 (epoch 33.605), train_loss = 0.84322983, grad/param norm = 2.0607e-01, time/batch = 17.1516s	
20063/29850 (epoch 33.606), train_loss = 0.60458867, grad/param norm = 1.6581e-01, time/batch = 16.3975s	
20064/29850 (epoch 33.608), train_loss = 0.77359191, grad/param norm = 1.8914e-01, time/batch = 18.1628s	
20065/29850 (epoch 33.610), train_loss = 0.83878803, grad/param norm = 2.1915e-01, time/batch = 30.2947s	
20066/29850 (epoch 33.611), train_loss = 0.76100708, grad/param norm = 1.9176e-01, time/batch = 21.1726s	
20067/29850 (epoch 33.613), train_loss = 0.64022049, grad/param norm = 1.6414e-01, time/batch = 17.8686s	
20068/29850 (epoch 33.615), train_loss = 0.75064235, grad/param norm = 1.9739e-01, time/batch = 16.2691s	
20069/29850 (epoch 33.616), train_loss = 0.74622191, grad/param norm = 2.2366e-01, time/batch = 16.0623s	
20070/29850 (epoch 33.618), train_loss = 0.81822466, grad/param norm = 1.9387e-01, time/batch = 14.5616s	
20071/29850 (epoch 33.620), train_loss = 0.88861040, grad/param norm = 2.5321e-01, time/batch = 17.4397s	
20072/29850 (epoch 33.621), train_loss = 1.00270158, grad/param norm = 2.6115e-01, time/batch = 17.6298s	
20073/29850 (epoch 33.623), train_loss = 0.91951099, grad/param norm = 1.9203e-01, time/batch = 18.3895s	
20074/29850 (epoch 33.625), train_loss = 0.86736671, grad/param norm = 2.1545e-01, time/batch = 17.5498s	
20075/29850 (epoch 33.626), train_loss = 0.88730661, grad/param norm = 2.3741e-01, time/batch = 17.8040s	
20076/29850 (epoch 33.628), train_loss = 0.84402930, grad/param norm = 2.1149e-01, time/batch = 17.9531s	
20077/29850 (epoch 33.630), train_loss = 0.89133168, grad/param norm = 2.2594e-01, time/batch = 15.1079s	
20078/29850 (epoch 33.631), train_loss = 0.85386620, grad/param norm = 2.1351e-01, time/batch = 18.6983s	
20079/29850 (epoch 33.633), train_loss = 0.91159168, grad/param norm = 2.7341e-01, time/batch = 19.0460s	
20080/29850 (epoch 33.635), train_loss = 0.81666113, grad/param norm = 2.3631e-01, time/batch = 18.8390s	
20081/29850 (epoch 33.637), train_loss = 0.78563429, grad/param norm = 2.1772e-01, time/batch = 16.7838s	
20082/29850 (epoch 33.638), train_loss = 0.88104927, grad/param norm = 2.1027e-01, time/batch = 19.5293s	
20083/29850 (epoch 33.640), train_loss = 1.02188821, grad/param norm = 2.5838e-01, time/batch = 18.0541s	
20084/29850 (epoch 33.642), train_loss = 0.81058724, grad/param norm = 2.1571e-01, time/batch = 17.9399s	
20085/29850 (epoch 33.643), train_loss = 0.79402773, grad/param norm = 2.4851e-01, time/batch = 16.4579s	
20086/29850 (epoch 33.645), train_loss = 0.85893632, grad/param norm = 2.0874e-01, time/batch = 18.7829s	
20087/29850 (epoch 33.647), train_loss = 1.00368898, grad/param norm = 2.3878e-01, time/batch = 17.3654s	
20088/29850 (epoch 33.648), train_loss = 0.77223721, grad/param norm = 1.9465e-01, time/batch = 16.8787s	
20089/29850 (epoch 33.650), train_loss = 0.89389556, grad/param norm = 2.2324e-01, time/batch = 18.6348s	
20090/29850 (epoch 33.652), train_loss = 0.87395554, grad/param norm = 2.4644e-01, time/batch = 17.0513s	
20091/29850 (epoch 33.653), train_loss = 0.97122432, grad/param norm = 2.4441e-01, time/batch = 17.2891s	
20092/29850 (epoch 33.655), train_loss = 0.88041999, grad/param norm = 1.9190e-01, time/batch = 18.5509s	
20093/29850 (epoch 33.657), train_loss = 0.86477255, grad/param norm = 2.2089e-01, time/batch = 17.4786s	
20094/29850 (epoch 33.658), train_loss = 0.96695771, grad/param norm = 2.1321e-01, time/batch = 15.9478s	
20095/29850 (epoch 33.660), train_loss = 0.82611783, grad/param norm = 2.2213e-01, time/batch = 17.0635s	
20096/29850 (epoch 33.662), train_loss = 0.97299766, grad/param norm = 2.3841e-01, time/batch = 19.1321s	
20097/29850 (epoch 33.663), train_loss = 1.06477098, grad/param norm = 2.2564e-01, time/batch = 17.0119s	
20098/29850 (epoch 33.665), train_loss = 0.99977728, grad/param norm = 2.3238e-01, time/batch = 17.1110s	
20099/29850 (epoch 33.667), train_loss = 0.94449807, grad/param norm = 2.7445e-01, time/batch = 16.7129s	
20100/29850 (epoch 33.668), train_loss = 0.83311060, grad/param norm = 2.0547e-01, time/batch = 17.7980s	
20101/29850 (epoch 33.670), train_loss = 0.99034848, grad/param norm = 2.7966e-01, time/batch = 17.3683s	
20102/29850 (epoch 33.672), train_loss = 0.96111290, grad/param norm = 2.5464e-01, time/batch = 19.6353s	
20103/29850 (epoch 33.673), train_loss = 0.89505528, grad/param norm = 2.2989e-01, time/batch = 17.6905s	
20104/29850 (epoch 33.675), train_loss = 0.77789402, grad/param norm = 1.9796e-01, time/batch = 15.9213s	
20105/29850 (epoch 33.677), train_loss = 0.84460070, grad/param norm = 2.4664e-01, time/batch = 18.9504s	
20106/29850 (epoch 33.678), train_loss = 0.87045559, grad/param norm = 2.2015e-01, time/batch = 19.2788s	
20107/29850 (epoch 33.680), train_loss = 0.86261189, grad/param norm = 2.4067e-01, time/batch = 17.2188s	
20108/29850 (epoch 33.682), train_loss = 0.87903147, grad/param norm = 2.2884e-01, time/batch = 18.1976s	
20109/29850 (epoch 33.683), train_loss = 0.98798366, grad/param norm = 2.3571e-01, time/batch = 18.1304s	
20110/29850 (epoch 33.685), train_loss = 1.07001580, grad/param norm = 2.4088e-01, time/batch = 18.6963s	
20111/29850 (epoch 33.687), train_loss = 0.91928142, grad/param norm = 2.1282e-01, time/batch = 17.3698s	
20112/29850 (epoch 33.688), train_loss = 0.77658289, grad/param norm = 2.0748e-01, time/batch = 18.0545s	
20113/29850 (epoch 33.690), train_loss = 0.75582132, grad/param norm = 1.7732e-01, time/batch = 18.8834s	
20114/29850 (epoch 33.692), train_loss = 0.97081756, grad/param norm = 2.1917e-01, time/batch = 15.8826s	
20115/29850 (epoch 33.693), train_loss = 0.86517329, grad/param norm = 1.9137e-01, time/batch = 18.8712s	
20116/29850 (epoch 33.695), train_loss = 0.76309342, grad/param norm = 1.7903e-01, time/batch = 18.3055s	
20117/29850 (epoch 33.697), train_loss = 0.87300430, grad/param norm = 2.0870e-01, time/batch = 18.2984s	
20118/29850 (epoch 33.698), train_loss = 0.99438451, grad/param norm = 2.1292e-01, time/batch = 17.3793s	
20119/29850 (epoch 33.700), train_loss = 0.95318931, grad/param norm = 2.5957e-01, time/batch = 16.3083s	
20120/29850 (epoch 33.702), train_loss = 0.89476359, grad/param norm = 2.3995e-01, time/batch = 17.1438s	
20121/29850 (epoch 33.704), train_loss = 0.75376700, grad/param norm = 1.8410e-01, time/batch = 15.7548s	
20122/29850 (epoch 33.705), train_loss = 0.89323535, grad/param norm = 2.2332e-01, time/batch = 17.5232s	
20123/29850 (epoch 33.707), train_loss = 0.80574067, grad/param norm = 2.1343e-01, time/batch = 16.6437s	
20124/29850 (epoch 33.709), train_loss = 0.86183503, grad/param norm = 2.3833e-01, time/batch = 18.4397s	
20125/29850 (epoch 33.710), train_loss = 0.81034109, grad/param norm = 2.0297e-01, time/batch = 20.1758s	
20126/29850 (epoch 33.712), train_loss = 0.90352663, grad/param norm = 2.0952e-01, time/batch = 18.4460s	
20127/29850 (epoch 33.714), train_loss = 0.96489276, grad/param norm = 2.5058e-01, time/batch = 18.0229s	
20128/29850 (epoch 33.715), train_loss = 0.89770466, grad/param norm = 2.2090e-01, time/batch = 17.9517s	
20129/29850 (epoch 33.717), train_loss = 0.66778035, grad/param norm = 2.1251e-01, time/batch = 19.6210s	
20130/29850 (epoch 33.719), train_loss = 0.84036789, grad/param norm = 2.1085e-01, time/batch = 19.0620s	
20131/29850 (epoch 33.720), train_loss = 0.87030524, grad/param norm = 1.8377e-01, time/batch = 17.5231s	
20132/29850 (epoch 33.722), train_loss = 0.79154551, grad/param norm = 1.8808e-01, time/batch = 19.5435s	
20133/29850 (epoch 33.724), train_loss = 0.90770669, grad/param norm = 2.3696e-01, time/batch = 17.2245s	
20134/29850 (epoch 33.725), train_loss = 0.76669520, grad/param norm = 2.0617e-01, time/batch = 16.2106s	
20135/29850 (epoch 33.727), train_loss = 0.78430554, grad/param norm = 2.5346e-01, time/batch = 17.2912s	
20136/29850 (epoch 33.729), train_loss = 0.72201563, grad/param norm = 1.7801e-01, time/batch = 16.7882s	
20137/29850 (epoch 33.730), train_loss = 0.70418499, grad/param norm = 1.9617e-01, time/batch = 17.9602s	
20138/29850 (epoch 33.732), train_loss = 0.98068734, grad/param norm = 2.1562e-01, time/batch = 16.2006s	
20139/29850 (epoch 33.734), train_loss = 1.02607469, grad/param norm = 2.4720e-01, time/batch = 18.8034s	
20140/29850 (epoch 33.735), train_loss = 0.79008578, grad/param norm = 2.2778e-01, time/batch = 18.0697s	
20141/29850 (epoch 33.737), train_loss = 0.76068980, grad/param norm = 1.9913e-01, time/batch = 16.3458s	
20142/29850 (epoch 33.739), train_loss = 0.69040685, grad/param norm = 2.6739e-01, time/batch = 19.0471s	
20143/29850 (epoch 33.740), train_loss = 0.73494303, grad/param norm = 2.0739e-01, time/batch = 19.2924s	
20144/29850 (epoch 33.742), train_loss = 0.64809218, grad/param norm = 1.6496e-01, time/batch = 17.2111s	
20145/29850 (epoch 33.744), train_loss = 0.79284192, grad/param norm = 2.6909e-01, time/batch = 17.5498s	
20146/29850 (epoch 33.745), train_loss = 0.84432900, grad/param norm = 2.9892e-01, time/batch = 20.0391s	
20147/29850 (epoch 33.747), train_loss = 0.84493077, grad/param norm = 2.0957e-01, time/batch = 17.2219s	
20148/29850 (epoch 33.749), train_loss = 0.73440448, grad/param norm = 2.1472e-01, time/batch = 16.2096s	
20149/29850 (epoch 33.750), train_loss = 0.69765352, grad/param norm = 1.8970e-01, time/batch = 18.7207s	
20150/29850 (epoch 33.752), train_loss = 0.61426591, grad/param norm = 1.8862e-01, time/batch = 18.2901s	
20151/29850 (epoch 33.754), train_loss = 0.68501532, grad/param norm = 2.1459e-01, time/batch = 16.6916s	
20152/29850 (epoch 33.755), train_loss = 0.71168463, grad/param norm = 1.9358e-01, time/batch = 17.8519s	
20153/29850 (epoch 33.757), train_loss = 0.73916177, grad/param norm = 1.7494e-01, time/batch = 19.9602s	
20154/29850 (epoch 33.759), train_loss = 0.75134714, grad/param norm = 2.0173e-01, time/batch = 16.5371s	
20155/29850 (epoch 33.760), train_loss = 0.77003965, grad/param norm = 2.6826e-01, time/batch = 18.6225s	
20156/29850 (epoch 33.762), train_loss = 0.72395749, grad/param norm = 2.5735e-01, time/batch = 18.4783s	
20157/29850 (epoch 33.764), train_loss = 0.65699583, grad/param norm = 2.1791e-01, time/batch = 17.6270s	
20158/29850 (epoch 33.765), train_loss = 0.80924306, grad/param norm = 2.4125e-01, time/batch = 18.0017s	
20159/29850 (epoch 33.767), train_loss = 0.80481889, grad/param norm = 1.9266e-01, time/batch = 18.7985s	
20160/29850 (epoch 33.769), train_loss = 0.82224280, grad/param norm = 2.1979e-01, time/batch = 15.7342s	
20161/29850 (epoch 33.771), train_loss = 0.88141059, grad/param norm = 2.1931e-01, time/batch = 17.1144s	
20162/29850 (epoch 33.772), train_loss = 0.84358515, grad/param norm = 2.0652e-01, time/batch = 15.6114s	
20163/29850 (epoch 33.774), train_loss = 0.78977016, grad/param norm = 1.9792e-01, time/batch = 18.4598s	
20164/29850 (epoch 33.776), train_loss = 0.80735225, grad/param norm = 1.9114e-01, time/batch = 16.3073s	
20165/29850 (epoch 33.777), train_loss = 0.91685967, grad/param norm = 2.3149e-01, time/batch = 16.1445s	
20166/29850 (epoch 33.779), train_loss = 0.75217001, grad/param norm = 1.8810e-01, time/batch = 16.8855s	
20167/29850 (epoch 33.781), train_loss = 0.86302062, grad/param norm = 2.0824e-01, time/batch = 17.2276s	
20168/29850 (epoch 33.782), train_loss = 0.86487507, grad/param norm = 2.0805e-01, time/batch = 16.6291s	
20169/29850 (epoch 33.784), train_loss = 0.72114866, grad/param norm = 2.1283e-01, time/batch = 18.3845s	
20170/29850 (epoch 33.786), train_loss = 0.77654291, grad/param norm = 2.1184e-01, time/batch = 16.1238s	
20171/29850 (epoch 33.787), train_loss = 0.68945045, grad/param norm = 2.4398e-01, time/batch = 16.5501s	
20172/29850 (epoch 33.789), train_loss = 0.68689304, grad/param norm = 1.9387e-01, time/batch = 17.7842s	
20173/29850 (epoch 33.791), train_loss = 0.77646381, grad/param norm = 2.3463e-01, time/batch = 16.9583s	
20174/29850 (epoch 33.792), train_loss = 0.88104148, grad/param norm = 2.6309e-01, time/batch = 19.5114s	
20175/29850 (epoch 33.794), train_loss = 0.85729945, grad/param norm = 2.1462e-01, time/batch = 18.0187s	
20176/29850 (epoch 33.796), train_loss = 0.71986319, grad/param norm = 1.7302e-01, time/batch = 17.6490s	
20177/29850 (epoch 33.797), train_loss = 0.65420010, grad/param norm = 2.0116e-01, time/batch = 16.7488s	
20178/29850 (epoch 33.799), train_loss = 0.69004695, grad/param norm = 1.8299e-01, time/batch = 15.8811s	
20179/29850 (epoch 33.801), train_loss = 0.72165683, grad/param norm = 1.8876e-01, time/batch = 18.7853s	
20180/29850 (epoch 33.802), train_loss = 0.67165364, grad/param norm = 1.9199e-01, time/batch = 17.3153s	
20181/29850 (epoch 33.804), train_loss = 0.71181655, grad/param norm = 1.7872e-01, time/batch = 18.6008s	
20182/29850 (epoch 33.806), train_loss = 0.66769241, grad/param norm = 1.8774e-01, time/batch = 18.7577s	
20183/29850 (epoch 33.807), train_loss = 0.69447044, grad/param norm = 1.8686e-01, time/batch = 17.9803s	
20184/29850 (epoch 33.809), train_loss = 0.71369787, grad/param norm = 2.2185e-01, time/batch = 16.5357s	
20185/29850 (epoch 33.811), train_loss = 0.87670140, grad/param norm = 2.5045e-01, time/batch = 15.3769s	
20186/29850 (epoch 33.812), train_loss = 0.84988849, grad/param norm = 2.2928e-01, time/batch = 16.5372s	
20187/29850 (epoch 33.814), train_loss = 0.89500431, grad/param norm = 2.1565e-01, time/batch = 19.9543s	
20188/29850 (epoch 33.816), train_loss = 0.93603066, grad/param norm = 2.2747e-01, time/batch = 17.5411s	
20189/29850 (epoch 33.817), train_loss = 0.86315834, grad/param norm = 2.7370e-01, time/batch = 16.8837s	
20190/29850 (epoch 33.819), train_loss = 0.68820215, grad/param norm = 1.8573e-01, time/batch = 18.2029s	
20191/29850 (epoch 33.821), train_loss = 0.94046463, grad/param norm = 2.8444e-01, time/batch = 19.0493s	
20192/29850 (epoch 33.822), train_loss = 0.95352935, grad/param norm = 2.6498e-01, time/batch = 18.6143s	
20193/29850 (epoch 33.824), train_loss = 0.83188100, grad/param norm = 2.1995e-01, time/batch = 17.4721s	
20194/29850 (epoch 33.826), train_loss = 0.73885244, grad/param norm = 1.8717e-01, time/batch = 19.5442s	
20195/29850 (epoch 33.827), train_loss = 0.68008333, grad/param norm = 2.0875e-01, time/batch = 17.3897s	
20196/29850 (epoch 33.829), train_loss = 0.82526110, grad/param norm = 2.6161e-01, time/batch = 18.7818s	
20197/29850 (epoch 33.831), train_loss = 0.94929156, grad/param norm = 2.4716e-01, time/batch = 19.2942s	
20198/29850 (epoch 33.832), train_loss = 0.85763421, grad/param norm = 2.0836e-01, time/batch = 16.1353s	
20199/29850 (epoch 33.834), train_loss = 0.64127082, grad/param norm = 1.8574e-01, time/batch = 17.0533s	
20200/29850 (epoch 33.836), train_loss = 0.67616074, grad/param norm = 1.9943e-01, time/batch = 17.0570s	
20201/29850 (epoch 33.838), train_loss = 0.76821523, grad/param norm = 2.7734e-01, time/batch = 18.3790s	
20202/29850 (epoch 33.839), train_loss = 0.68825311, grad/param norm = 2.1008e-01, time/batch = 18.1282s	
20203/29850 (epoch 33.841), train_loss = 0.73271746, grad/param norm = 1.8950e-01, time/batch = 18.7043s	
20204/29850 (epoch 33.843), train_loss = 0.66864092, grad/param norm = 2.0831e-01, time/batch = 17.5992s	
20205/29850 (epoch 33.844), train_loss = 0.73533547, grad/param norm = 2.1902e-01, time/batch = 15.5295s	
20206/29850 (epoch 33.846), train_loss = 0.79917237, grad/param norm = 2.1788e-01, time/batch = 19.1860s	
20207/29850 (epoch 33.848), train_loss = 0.88137389, grad/param norm = 2.4740e-01, time/batch = 18.5513s	
20208/29850 (epoch 33.849), train_loss = 0.75464702, grad/param norm = 2.0827e-01, time/batch = 17.0511s	
20209/29850 (epoch 33.851), train_loss = 0.96483052, grad/param norm = 2.2999e-01, time/batch = 16.6864s	
20210/29850 (epoch 33.853), train_loss = 0.77428474, grad/param norm = 2.2247e-01, time/batch = 19.6295s	
20211/29850 (epoch 33.854), train_loss = 0.96450539, grad/param norm = 2.5265e-01, time/batch = 17.9564s	
20212/29850 (epoch 33.856), train_loss = 0.93131053, grad/param norm = 2.8373e-01, time/batch = 18.9677s	
20213/29850 (epoch 33.858), train_loss = 0.82944170, grad/param norm = 2.2747e-01, time/batch = 17.2178s	
20214/29850 (epoch 33.859), train_loss = 0.73377717, grad/param norm = 2.4994e-01, time/batch = 18.4721s	
20215/29850 (epoch 33.861), train_loss = 0.93732307, grad/param norm = 2.4480e-01, time/batch = 16.2828s	
20216/29850 (epoch 33.863), train_loss = 0.96990282, grad/param norm = 2.5295e-01, time/batch = 16.1397s	
20217/29850 (epoch 33.864), train_loss = 0.94629336, grad/param norm = 2.6480e-01, time/batch = 16.8998s	
20218/29850 (epoch 33.866), train_loss = 0.86918562, grad/param norm = 2.6342e-01, time/batch = 17.2085s	
20219/29850 (epoch 33.868), train_loss = 0.99734788, grad/param norm = 2.4512e-01, time/batch = 19.6839s	
20220/29850 (epoch 33.869), train_loss = 0.90457387, grad/param norm = 2.6354e-01, time/batch = 17.8846s	
20221/29850 (epoch 33.871), train_loss = 0.93469752, grad/param norm = 2.2195e-01, time/batch = 17.0538s	
20222/29850 (epoch 33.873), train_loss = 0.86140327, grad/param norm = 2.1400e-01, time/batch = 15.2322s	
20223/29850 (epoch 33.874), train_loss = 0.86470562, grad/param norm = 2.2922e-01, time/batch = 17.3117s	
20224/29850 (epoch 33.876), train_loss = 0.87276257, grad/param norm = 3.7308e-01, time/batch = 18.7094s	
20225/29850 (epoch 33.878), train_loss = 0.85307725, grad/param norm = 2.0298e-01, time/batch = 16.4423s	
20226/29850 (epoch 33.879), train_loss = 0.88188104, grad/param norm = 2.2438e-01, time/batch = 16.8894s	
20227/29850 (epoch 33.881), train_loss = 0.96586341, grad/param norm = 2.6921e-01, time/batch = 18.3946s	
20228/29850 (epoch 33.883), train_loss = 0.92102599, grad/param norm = 2.4714e-01, time/batch = 18.8545s	
20229/29850 (epoch 33.884), train_loss = 0.74350484, grad/param norm = 2.0539e-01, time/batch = 16.8447s	
20230/29850 (epoch 33.886), train_loss = 0.96791601, grad/param norm = 3.2735e-01, time/batch = 17.7208s	
20231/29850 (epoch 33.888), train_loss = 0.84301043, grad/param norm = 2.2657e-01, time/batch = 19.5428s	
20232/29850 (epoch 33.889), train_loss = 0.79179921, grad/param norm = 2.0755e-01, time/batch = 15.8708s	
20233/29850 (epoch 33.891), train_loss = 0.74332767, grad/param norm = 1.9317e-01, time/batch = 18.3059s	
20234/29850 (epoch 33.893), train_loss = 0.80855548, grad/param norm = 2.0508e-01, time/batch = 18.7997s	
20235/29850 (epoch 33.894), train_loss = 0.82296129, grad/param norm = 2.2674e-01, time/batch = 16.8817s	
20236/29850 (epoch 33.896), train_loss = 0.84687178, grad/param norm = 2.3285e-01, time/batch = 18.9316s	
20237/29850 (epoch 33.898), train_loss = 0.99332126, grad/param norm = 2.4604e-01, time/batch = 18.9741s	
20238/29850 (epoch 33.899), train_loss = 0.77114235, grad/param norm = 2.6386e-01, time/batch = 18.1282s	
20239/29850 (epoch 33.901), train_loss = 1.05116981, grad/param norm = 3.3021e-01, time/batch = 16.1218s	
20240/29850 (epoch 33.903), train_loss = 0.90039516, grad/param norm = 3.9884e-01, time/batch = 16.7099s	
20241/29850 (epoch 33.905), train_loss = 1.14489137, grad/param norm = 2.4951e-01, time/batch = 19.7792s	
20242/29850 (epoch 33.906), train_loss = 0.88875367, grad/param norm = 2.3031e-01, time/batch = 17.1218s	
20243/29850 (epoch 33.908), train_loss = 1.02625015, grad/param norm = 2.4498e-01, time/batch = 18.9586s	
20244/29850 (epoch 33.910), train_loss = 0.93802120, grad/param norm = 2.3321e-01, time/batch = 16.1174s	
20245/29850 (epoch 33.911), train_loss = 1.08025582, grad/param norm = 2.2184e-01, time/batch = 18.1184s	
20246/29850 (epoch 33.913), train_loss = 1.01159163, grad/param norm = 2.5725e-01, time/batch = 18.9415s	
20247/29850 (epoch 33.915), train_loss = 1.00176604, grad/param norm = 2.3649e-01, time/batch = 18.9655s	
20248/29850 (epoch 33.916), train_loss = 0.92846063, grad/param norm = 2.1861e-01, time/batch = 18.2035s	
20249/29850 (epoch 33.918), train_loss = 0.80926479, grad/param norm = 2.0880e-01, time/batch = 17.0329s	
20250/29850 (epoch 33.920), train_loss = 0.99548394, grad/param norm = 2.1621e-01, time/batch = 18.9695s	
20251/29850 (epoch 33.921), train_loss = 0.86335417, grad/param norm = 2.5394e-01, time/batch = 15.3530s	
20252/29850 (epoch 33.923), train_loss = 0.88268328, grad/param norm = 2.1051e-01, time/batch = 17.4591s	
20253/29850 (epoch 33.925), train_loss = 1.00320706, grad/param norm = 2.6274e-01, time/batch = 18.5531s	
20254/29850 (epoch 33.926), train_loss = 1.01280810, grad/param norm = 2.4309e-01, time/batch = 19.6154s	
20255/29850 (epoch 33.928), train_loss = 0.86194877, grad/param norm = 2.0899e-01, time/batch = 17.4612s	
20256/29850 (epoch 33.930), train_loss = 0.91336717, grad/param norm = 2.3639e-01, time/batch = 16.0125s	
20257/29850 (epoch 33.931), train_loss = 0.87787115, grad/param norm = 2.1270e-01, time/batch = 17.7015s	
20258/29850 (epoch 33.933), train_loss = 1.00783806, grad/param norm = 2.1377e-01, time/batch = 19.6179s	
20259/29850 (epoch 33.935), train_loss = 0.93113262, grad/param norm = 2.5270e-01, time/batch = 17.6676s	
20260/29850 (epoch 33.936), train_loss = 0.91121776, grad/param norm = 2.3710e-01, time/batch = 17.6239s	
20261/29850 (epoch 33.938), train_loss = 0.79337124, grad/param norm = 2.1926e-01, time/batch = 18.4524s	
20262/29850 (epoch 33.940), train_loss = 0.77558930, grad/param norm = 2.0427e-01, time/batch = 16.7855s	
20263/29850 (epoch 33.941), train_loss = 0.79793963, grad/param norm = 2.7278e-01, time/batch = 17.8820s	
20264/29850 (epoch 33.943), train_loss = 0.81476631, grad/param norm = 2.1827e-01, time/batch = 19.0560s	
20265/29850 (epoch 33.945), train_loss = 0.77177204, grad/param norm = 2.1124e-01, time/batch = 15.3092s	
20266/29850 (epoch 33.946), train_loss = 0.78291335, grad/param norm = 2.0725e-01, time/batch = 30.2132s	
20267/29850 (epoch 33.948), train_loss = 0.87035182, grad/param norm = 2.0251e-01, time/batch = 16.2274s	
20268/29850 (epoch 33.950), train_loss = 0.81144339, grad/param norm = 1.7651e-01, time/batch = 16.4461s	
20269/29850 (epoch 33.951), train_loss = 0.70990180, grad/param norm = 1.9781e-01, time/batch = 17.7338s	
20270/29850 (epoch 33.953), train_loss = 0.83575437, grad/param norm = 2.2314e-01, time/batch = 18.2778s	
20271/29850 (epoch 33.955), train_loss = 0.74127983, grad/param norm = 1.9306e-01, time/batch = 16.9559s	
20272/29850 (epoch 33.956), train_loss = 0.76179682, grad/param norm = 2.2401e-01, time/batch = 16.0247s	
20273/29850 (epoch 33.958), train_loss = 0.65518492, grad/param norm = 1.6358e-01, time/batch = 18.3129s	
20274/29850 (epoch 33.960), train_loss = 0.94727991, grad/param norm = 2.5491e-01, time/batch = 17.0511s	
20275/29850 (epoch 33.961), train_loss = 0.76640919, grad/param norm = 3.5245e-01, time/batch = 17.6153s	
20276/29850 (epoch 33.963), train_loss = 0.71173346, grad/param norm = 1.9931e-01, time/batch = 18.2994s	
20277/29850 (epoch 33.965), train_loss = 0.76718924, grad/param norm = 2.0956e-01, time/batch = 16.8654s	
20278/29850 (epoch 33.966), train_loss = 0.73586794, grad/param norm = 2.1552e-01, time/batch = 17.0976s	
20279/29850 (epoch 33.968), train_loss = 0.78101241, grad/param norm = 2.8315e-01, time/batch = 16.3588s	
20280/29850 (epoch 33.970), train_loss = 0.77499799, grad/param norm = 2.5425e-01, time/batch = 17.8864s	
20281/29850 (epoch 33.972), train_loss = 0.76643967, grad/param norm = 1.8233e-01, time/batch = 18.8172s	
20282/29850 (epoch 33.973), train_loss = 0.76561944, grad/param norm = 1.9718e-01, time/batch = 16.8639s	
20283/29850 (epoch 33.975), train_loss = 0.64536813, grad/param norm = 1.7671e-01, time/batch = 18.8034s	
20284/29850 (epoch 33.977), train_loss = 0.79012721, grad/param norm = 1.8762e-01, time/batch = 17.6356s	
20285/29850 (epoch 33.978), train_loss = 0.69472700, grad/param norm = 1.9132e-01, time/batch = 16.3923s	
20286/29850 (epoch 33.980), train_loss = 0.76100350, grad/param norm = 1.8453e-01, time/batch = 18.5341s	
20287/29850 (epoch 33.982), train_loss = 0.75397336, grad/param norm = 2.0596e-01, time/batch = 17.9651s	
20288/29850 (epoch 33.983), train_loss = 0.78095702, grad/param norm = 1.8984e-01, time/batch = 18.3009s	
20289/29850 (epoch 33.985), train_loss = 0.87735229, grad/param norm = 2.1945e-01, time/batch = 16.2077s	
20290/29850 (epoch 33.987), train_loss = 0.84287778, grad/param norm = 2.1478e-01, time/batch = 16.1219s	
20291/29850 (epoch 33.988), train_loss = 0.79322939, grad/param norm = 1.9791e-01, time/batch = 17.7229s	
20292/29850 (epoch 33.990), train_loss = 0.84834620, grad/param norm = 1.8959e-01, time/batch = 16.7175s	
20293/29850 (epoch 33.992), train_loss = 0.86901925, grad/param norm = 1.8343e-01, time/batch = 14.9176s	
20294/29850 (epoch 33.993), train_loss = 0.86588299, grad/param norm = 2.3082e-01, time/batch = 16.9903s	
20295/29850 (epoch 33.995), train_loss = 0.83453683, grad/param norm = 1.9815e-01, time/batch = 18.2033s	
20296/29850 (epoch 33.997), train_loss = 0.88040320, grad/param norm = 2.0469e-01, time/batch = 17.2890s	
20297/29850 (epoch 33.998), train_loss = 0.87765957, grad/param norm = 2.0182e-01, time/batch = 19.1348s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
20298/29850 (epoch 34.000), train_loss = 0.71886908, grad/param norm = 1.9585e-01, time/batch = 19.2857s	
20299/29850 (epoch 34.002), train_loss = 0.97858744, grad/param norm = 2.3758e-01, time/batch = 15.3777s	
20300/29850 (epoch 34.003), train_loss = 0.72989163, grad/param norm = 2.3508e-01, time/batch = 16.0296s	
20301/29850 (epoch 34.005), train_loss = 0.88656046, grad/param norm = 2.1845e-01, time/batch = 17.8833s	
20302/29850 (epoch 34.007), train_loss = 0.92722478, grad/param norm = 2.3111e-01, time/batch = 17.7180s	
20303/29850 (epoch 34.008), train_loss = 1.06617879, grad/param norm = 2.6869e-01, time/batch = 18.2232s	
20304/29850 (epoch 34.010), train_loss = 0.76884065, grad/param norm = 2.2169e-01, time/batch = 18.6444s	
20305/29850 (epoch 34.012), train_loss = 0.81847240, grad/param norm = 2.0085e-01, time/batch = 18.3633s	
20306/29850 (epoch 34.013), train_loss = 0.88199657, grad/param norm = 2.2203e-01, time/batch = 15.9297s	
20307/29850 (epoch 34.015), train_loss = 0.92146882, grad/param norm = 2.1616e-01, time/batch = 19.7136s	
20308/29850 (epoch 34.017), train_loss = 0.88470614, grad/param norm = 2.3990e-01, time/batch = 19.0554s	
20309/29850 (epoch 34.018), train_loss = 0.98450289, grad/param norm = 2.2981e-01, time/batch = 16.3705s	
20310/29850 (epoch 34.020), train_loss = 0.85699309, grad/param norm = 2.1377e-01, time/batch = 17.7308s	
20311/29850 (epoch 34.022), train_loss = 0.94640079, grad/param norm = 2.4180e-01, time/batch = 18.3015s	
20312/29850 (epoch 34.023), train_loss = 0.91475328, grad/param norm = 1.9012e-01, time/batch = 18.5333s	
20313/29850 (epoch 34.025), train_loss = 0.83136806, grad/param norm = 1.8911e-01, time/batch = 17.8755s	
20314/29850 (epoch 34.027), train_loss = 0.65138651, grad/param norm = 2.2715e-01, time/batch = 18.3808s	
20315/29850 (epoch 34.028), train_loss = 0.78700569, grad/param norm = 1.9554e-01, time/batch = 18.7179s	
20316/29850 (epoch 34.030), train_loss = 0.80649432, grad/param norm = 2.4088e-01, time/batch = 18.1814s	
20317/29850 (epoch 34.032), train_loss = 0.88685370, grad/param norm = 2.0865e-01, time/batch = 17.0266s	
20318/29850 (epoch 34.034), train_loss = 0.78576576, grad/param norm = 2.0765e-01, time/batch = 16.2762s	
20319/29850 (epoch 34.035), train_loss = 0.68788402, grad/param norm = 1.9238e-01, time/batch = 15.4366s	
20320/29850 (epoch 34.037), train_loss = 0.85051854, grad/param norm = 2.0166e-01, time/batch = 15.2724s	
20321/29850 (epoch 34.039), train_loss = 0.75635435, grad/param norm = 1.7888e-01, time/batch = 15.9416s	
20322/29850 (epoch 34.040), train_loss = 0.75274319, grad/param norm = 2.1920e-01, time/batch = 15.0848s	
20323/29850 (epoch 34.042), train_loss = 0.76508865, grad/param norm = 2.1182e-01, time/batch = 15.0801s	
20324/29850 (epoch 34.044), train_loss = 0.81156357, grad/param norm = 1.8775e-01, time/batch = 14.5525s	
20325/29850 (epoch 34.045), train_loss = 0.90869903, grad/param norm = 2.2218e-01, time/batch = 15.3788s	
20326/29850 (epoch 34.047), train_loss = 0.75459439, grad/param norm = 1.9105e-01, time/batch = 18.2063s	
20327/29850 (epoch 34.049), train_loss = 0.88175469, grad/param norm = 2.2383e-01, time/batch = 16.2172s	
20328/29850 (epoch 34.050), train_loss = 0.76434364, grad/param norm = 1.9444e-01, time/batch = 17.9705s	
20329/29850 (epoch 34.052), train_loss = 0.97343337, grad/param norm = 2.6179e-01, time/batch = 18.3880s	
20330/29850 (epoch 34.054), train_loss = 0.83551727, grad/param norm = 2.1594e-01, time/batch = 16.1786s	
20331/29850 (epoch 34.055), train_loss = 0.80261691, grad/param norm = 2.0098e-01, time/batch = 17.9599s	
20332/29850 (epoch 34.057), train_loss = 0.89210332, grad/param norm = 2.0555e-01, time/batch = 19.6292s	
20333/29850 (epoch 34.059), train_loss = 0.89110480, grad/param norm = 2.2245e-01, time/batch = 18.5284s	
20334/29850 (epoch 34.060), train_loss = 0.85602533, grad/param norm = 2.4052e-01, time/batch = 18.1097s	
20335/29850 (epoch 34.062), train_loss = 0.92744886, grad/param norm = 2.3036e-01, time/batch = 18.6896s	
20336/29850 (epoch 34.064), train_loss = 0.91493689, grad/param norm = 2.2297e-01, time/batch = 16.8100s	
20337/29850 (epoch 34.065), train_loss = 0.73957813, grad/param norm = 1.8930e-01, time/batch = 15.3460s	
20338/29850 (epoch 34.067), train_loss = 0.88290747, grad/param norm = 1.9726e-01, time/batch = 19.4577s	
20339/29850 (epoch 34.069), train_loss = 0.89592526, grad/param norm = 2.0865e-01, time/batch = 16.7271s	
20340/29850 (epoch 34.070), train_loss = 0.88986933, grad/param norm = 2.0185e-01, time/batch = 16.9585s	
20341/29850 (epoch 34.072), train_loss = 0.87049745, grad/param norm = 2.2151e-01, time/batch = 17.8706s	
20342/29850 (epoch 34.074), train_loss = 0.93142136, grad/param norm = 2.0686e-01, time/batch = 19.2069s	
20343/29850 (epoch 34.075), train_loss = 0.78720396, grad/param norm = 2.1576e-01, time/batch = 18.8834s	
20344/29850 (epoch 34.077), train_loss = 0.91105899, grad/param norm = 2.1928e-01, time/batch = 18.3802s	
20345/29850 (epoch 34.079), train_loss = 1.08676357, grad/param norm = 3.1835e-01, time/batch = 18.2860s	
20346/29850 (epoch 34.080), train_loss = 1.02547574, grad/param norm = 2.3178e-01, time/batch = 19.1219s	
20347/29850 (epoch 34.082), train_loss = 0.92755915, grad/param norm = 2.1848e-01, time/batch = 17.4623s	
20348/29850 (epoch 34.084), train_loss = 1.02173112, grad/param norm = 2.3821e-01, time/batch = 18.7213s	
20349/29850 (epoch 34.085), train_loss = 1.02863787, grad/param norm = 2.3923e-01, time/batch = 19.0562s	
20350/29850 (epoch 34.087), train_loss = 0.99179235, grad/param norm = 2.3749e-01, time/batch = 15.9617s	
20351/29850 (epoch 34.089), train_loss = 0.91792017, grad/param norm = 2.1814e-01, time/batch = 0.6715s	
20352/29850 (epoch 34.090), train_loss = 0.92383721, grad/param norm = 2.0210e-01, time/batch = 0.6658s	
20353/29850 (epoch 34.092), train_loss = 0.79620352, grad/param norm = 2.0225e-01, time/batch = 0.6792s	
20354/29850 (epoch 34.094), train_loss = 1.00587876, grad/param norm = 2.1546e-01, time/batch = 0.6642s	
20355/29850 (epoch 34.095), train_loss = 0.89781345, grad/param norm = 2.3752e-01, time/batch = 0.6726s	
20356/29850 (epoch 34.097), train_loss = 0.69397655, grad/param norm = 2.0110e-01, time/batch = 0.6607s	
20357/29850 (epoch 34.099), train_loss = 0.72232803, grad/param norm = 2.0299e-01, time/batch = 0.6623s	
20358/29850 (epoch 34.101), train_loss = 0.95049925, grad/param norm = 2.2792e-01, time/batch = 0.8402s	
20359/29850 (epoch 34.102), train_loss = 0.91433236, grad/param norm = 2.1576e-01, time/batch = 0.9300s	
20360/29850 (epoch 34.104), train_loss = 0.84978446, grad/param norm = 2.4330e-01, time/batch = 0.9403s	
20361/29850 (epoch 34.106), train_loss = 0.96929641, grad/param norm = 2.3285e-01, time/batch = 0.9478s	
20362/29850 (epoch 34.107), train_loss = 0.80684145, grad/param norm = 1.7784e-01, time/batch = 0.9486s	
20363/29850 (epoch 34.109), train_loss = 0.89546309, grad/param norm = 2.4738e-01, time/batch = 1.2273s	
20364/29850 (epoch 34.111), train_loss = 0.91866922, grad/param norm = 2.1052e-01, time/batch = 1.7773s	
20365/29850 (epoch 34.112), train_loss = 0.77852750, grad/param norm = 1.9449e-01, time/batch = 1.7480s	
20366/29850 (epoch 34.114), train_loss = 0.82187119, grad/param norm = 2.2542e-01, time/batch = 9.7620s	
20367/29850 (epoch 34.116), train_loss = 0.79806752, grad/param norm = 2.1196e-01, time/batch = 17.9835s	
20368/29850 (epoch 34.117), train_loss = 0.83724557, grad/param norm = 2.0534e-01, time/batch = 16.9591s	
20369/29850 (epoch 34.119), train_loss = 0.80725790, grad/param norm = 1.9847e-01, time/batch = 17.9525s	
20370/29850 (epoch 34.121), train_loss = 0.69846916, grad/param norm = 2.0639e-01, time/batch = 19.0275s	
20371/29850 (epoch 34.122), train_loss = 0.71902844, grad/param norm = 1.5945e-01, time/batch = 19.1103s	
20372/29850 (epoch 34.124), train_loss = 0.76972430, grad/param norm = 1.9480e-01, time/batch = 16.8508s	
20373/29850 (epoch 34.126), train_loss = 0.81071560, grad/param norm = 1.9221e-01, time/batch = 18.3053s	
20374/29850 (epoch 34.127), train_loss = 0.91352914, grad/param norm = 2.5364e-01, time/batch = 15.3915s	
20375/29850 (epoch 34.129), train_loss = 0.82740640, grad/param norm = 2.1412e-01, time/batch = 16.1177s	
20376/29850 (epoch 34.131), train_loss = 0.86289972, grad/param norm = 2.0949e-01, time/batch = 19.0296s	
20377/29850 (epoch 34.132), train_loss = 0.72848142, grad/param norm = 2.1905e-01, time/batch = 17.5660s	
20378/29850 (epoch 34.134), train_loss = 0.81566711, grad/param norm = 2.1155e-01, time/batch = 18.5408s	
20379/29850 (epoch 34.136), train_loss = 0.90482490, grad/param norm = 2.0307e-01, time/batch = 17.0450s	
20380/29850 (epoch 34.137), train_loss = 0.71043065, grad/param norm = 2.0170e-01, time/batch = 19.1228s	
20381/29850 (epoch 34.139), train_loss = 0.84543753, grad/param norm = 2.2360e-01, time/batch = 18.6138s	
20382/29850 (epoch 34.141), train_loss = 0.77806552, grad/param norm = 2.1337e-01, time/batch = 16.3914s	
20383/29850 (epoch 34.142), train_loss = 0.98843194, grad/param norm = 2.5178e-01, time/batch = 17.5580s	
20384/29850 (epoch 34.144), train_loss = 1.07443949, grad/param norm = 2.4826e-01, time/batch = 17.7723s	
20385/29850 (epoch 34.146), train_loss = 1.09634568, grad/param norm = 2.4589e-01, time/batch = 14.9068s	
20386/29850 (epoch 34.147), train_loss = 0.95660780, grad/param norm = 2.4251e-01, time/batch = 19.8629s	
20387/29850 (epoch 34.149), train_loss = 0.89940657, grad/param norm = 2.2780e-01, time/batch = 17.7103s	
20388/29850 (epoch 34.151), train_loss = 0.91178511, grad/param norm = 2.4439e-01, time/batch = 17.3637s	
20389/29850 (epoch 34.152), train_loss = 0.84178778, grad/param norm = 2.0890e-01, time/batch = 15.8249s	
20390/29850 (epoch 34.154), train_loss = 0.79834130, grad/param norm = 2.0999e-01, time/batch = 18.8058s	
20391/29850 (epoch 34.156), train_loss = 0.79389441, grad/param norm = 2.1228e-01, time/batch = 19.2167s	
20392/29850 (epoch 34.157), train_loss = 0.92636105, grad/param norm = 2.3316e-01, time/batch = 16.1370s	
20393/29850 (epoch 34.159), train_loss = 0.83547009, grad/param norm = 2.2043e-01, time/batch = 19.5315s	
20394/29850 (epoch 34.161), train_loss = 0.84720558, grad/param norm = 1.9942e-01, time/batch = 18.2270s	
20395/29850 (epoch 34.162), train_loss = 0.98715323, grad/param norm = 2.3975e-01, time/batch = 16.2975s	
20396/29850 (epoch 34.164), train_loss = 0.89194066, grad/param norm = 2.1708e-01, time/batch = 18.6334s	
20397/29850 (epoch 34.166), train_loss = 0.84135477, grad/param norm = 2.2083e-01, time/batch = 17.5450s	
20398/29850 (epoch 34.168), train_loss = 0.74001968, grad/param norm = 1.7345e-01, time/batch = 18.1983s	
20399/29850 (epoch 34.169), train_loss = 0.99308964, grad/param norm = 2.5384e-01, time/batch = 16.8796s	
20400/29850 (epoch 34.171), train_loss = 0.90150002, grad/param norm = 2.1976e-01, time/batch = 17.7043s	
20401/29850 (epoch 34.173), train_loss = 0.77899443, grad/param norm = 2.2280e-01, time/batch = 19.3734s	
20402/29850 (epoch 34.174), train_loss = 0.89913619, grad/param norm = 2.3822e-01, time/batch = 15.8728s	
20403/29850 (epoch 34.176), train_loss = 0.88451579, grad/param norm = 2.1974e-01, time/batch = 18.7957s	
20404/29850 (epoch 34.178), train_loss = 0.88734786, grad/param norm = 2.2304e-01, time/batch = 17.5399s	
20405/29850 (epoch 34.179), train_loss = 0.74405649, grad/param norm = 2.3128e-01, time/batch = 17.8599s	
20406/29850 (epoch 34.181), train_loss = 0.88957310, grad/param norm = 2.5594e-01, time/batch = 17.0402s	
20407/29850 (epoch 34.183), train_loss = 0.87158990, grad/param norm = 1.8752e-01, time/batch = 19.7901s	
20408/29850 (epoch 34.184), train_loss = 0.93037808, grad/param norm = 2.2160e-01, time/batch = 18.0441s	
20409/29850 (epoch 34.186), train_loss = 0.88175491, grad/param norm = 2.1594e-01, time/batch = 16.2773s	
20410/29850 (epoch 34.188), train_loss = 0.99742211, grad/param norm = 2.2245e-01, time/batch = 18.8855s	
20411/29850 (epoch 34.189), train_loss = 0.97385912, grad/param norm = 2.4087e-01, time/batch = 16.8834s	
20412/29850 (epoch 34.191), train_loss = 0.96453646, grad/param norm = 2.1974e-01, time/batch = 16.2877s	
20413/29850 (epoch 34.193), train_loss = 0.85263769, grad/param norm = 2.0475e-01, time/batch = 19.2981s	
20414/29850 (epoch 34.194), train_loss = 0.95341592, grad/param norm = 2.3965e-01, time/batch = 19.2129s	
20415/29850 (epoch 34.196), train_loss = 0.86338805, grad/param norm = 2.2938e-01, time/batch = 16.5440s	
20416/29850 (epoch 34.198), train_loss = 0.83819768, grad/param norm = 2.2956e-01, time/batch = 18.3060s	
20417/29850 (epoch 34.199), train_loss = 1.06092545, grad/param norm = 2.4011e-01, time/batch = 18.3001s	
20418/29850 (epoch 34.201), train_loss = 0.79783415, grad/param norm = 1.9503e-01, time/batch = 17.9472s	
20419/29850 (epoch 34.203), train_loss = 0.64713928, grad/param norm = 2.2192e-01, time/batch = 18.5548s	
20420/29850 (epoch 34.204), train_loss = 0.85831951, grad/param norm = 2.1958e-01, time/batch = 18.0481s	
20421/29850 (epoch 34.206), train_loss = 0.75453193, grad/param norm = 2.0440e-01, time/batch = 17.4715s	
20422/29850 (epoch 34.208), train_loss = 1.00101120, grad/param norm = 2.4167e-01, time/batch = 15.5985s	
20423/29850 (epoch 34.209), train_loss = 0.76076184, grad/param norm = 2.0468e-01, time/batch = 19.3719s	
20424/29850 (epoch 34.211), train_loss = 0.82695436, grad/param norm = 2.1763e-01, time/batch = 17.1175s	
20425/29850 (epoch 34.213), train_loss = 0.93521092, grad/param norm = 2.4610e-01, time/batch = 17.0437s	
20426/29850 (epoch 34.214), train_loss = 0.74739250, grad/param norm = 1.7482e-01, time/batch = 17.2976s	
20427/29850 (epoch 34.216), train_loss = 0.77300017, grad/param norm = 1.9730e-01, time/batch = 18.3889s	
20428/29850 (epoch 34.218), train_loss = 0.89297645, grad/param norm = 2.1244e-01, time/batch = 18.4655s	
20429/29850 (epoch 34.219), train_loss = 0.93804778, grad/param norm = 2.6035e-01, time/batch = 18.4488s	
20430/29850 (epoch 34.221), train_loss = 0.86368063, grad/param norm = 2.2413e-01, time/batch = 18.8052s	
20431/29850 (epoch 34.223), train_loss = 0.73777551, grad/param norm = 2.2518e-01, time/batch = 17.3043s	
20432/29850 (epoch 34.224), train_loss = 0.73874719, grad/param norm = 1.9877e-01, time/batch = 16.6053s	
20433/29850 (epoch 34.226), train_loss = 0.77528882, grad/param norm = 1.8813e-01, time/batch = 17.8402s	
20434/29850 (epoch 34.228), train_loss = 0.81361246, grad/param norm = 1.9231e-01, time/batch = 15.7875s	
20435/29850 (epoch 34.229), train_loss = 0.68287592, grad/param norm = 1.5987e-01, time/batch = 17.2691s	
20436/29850 (epoch 34.231), train_loss = 0.86259723, grad/param norm = 2.2242e-01, time/batch = 19.1239s	
20437/29850 (epoch 34.233), train_loss = 0.82487867, grad/param norm = 1.9750e-01, time/batch = 18.5389s	
20438/29850 (epoch 34.235), train_loss = 0.78697195, grad/param norm = 1.8997e-01, time/batch = 19.2959s	
20439/29850 (epoch 34.236), train_loss = 0.99044156, grad/param norm = 2.4045e-01, time/batch = 16.1019s	
20440/29850 (epoch 34.238), train_loss = 0.72339019, grad/param norm = 2.0730e-01, time/batch = 20.3519s	
20441/29850 (epoch 34.240), train_loss = 0.73908848, grad/param norm = 2.0377e-01, time/batch = 18.4529s	
20442/29850 (epoch 34.241), train_loss = 0.90062274, grad/param norm = 2.4260e-01, time/batch = 16.3909s	
20443/29850 (epoch 34.243), train_loss = 0.89773690, grad/param norm = 2.0266e-01, time/batch = 15.2228s	
20444/29850 (epoch 34.245), train_loss = 0.80281173, grad/param norm = 2.1381e-01, time/batch = 18.7825s	
20445/29850 (epoch 34.246), train_loss = 0.72882620, grad/param norm = 1.7523e-01, time/batch = 18.0941s	
20446/29850 (epoch 34.248), train_loss = 0.71820637, grad/param norm = 1.9612e-01, time/batch = 18.1346s	
20447/29850 (epoch 34.250), train_loss = 0.80896102, grad/param norm = 1.8615e-01, time/batch = 18.0440s	
20448/29850 (epoch 34.251), train_loss = 0.69130586, grad/param norm = 1.9634e-01, time/batch = 18.5569s	
20449/29850 (epoch 34.253), train_loss = 0.69622077, grad/param norm = 1.9694e-01, time/batch = 15.1871s	
20450/29850 (epoch 34.255), train_loss = 0.76016689, grad/param norm = 2.0098e-01, time/batch = 18.5432s	
20451/29850 (epoch 34.256), train_loss = 0.90011458, grad/param norm = 2.3499e-01, time/batch = 16.4697s	
20452/29850 (epoch 34.258), train_loss = 0.88953294, grad/param norm = 2.3872e-01, time/batch = 17.1096s	
20453/29850 (epoch 34.260), train_loss = 0.82710209, grad/param norm = 2.0015e-01, time/batch = 18.2916s	
20454/29850 (epoch 34.261), train_loss = 0.77929149, grad/param norm = 2.3663e-01, time/batch = 15.4644s	
20455/29850 (epoch 34.263), train_loss = 0.76951655, grad/param norm = 1.9108e-01, time/batch = 18.2193s	
20456/29850 (epoch 34.265), train_loss = 0.83417138, grad/param norm = 2.1129e-01, time/batch = 16.2733s	
20457/29850 (epoch 34.266), train_loss = 0.84634082, grad/param norm = 2.2964e-01, time/batch = 18.1406s	
20458/29850 (epoch 34.268), train_loss = 0.81886371, grad/param norm = 2.0268e-01, time/batch = 18.1331s	
20459/29850 (epoch 34.270), train_loss = 0.78284108, grad/param norm = 1.8928e-01, time/batch = 17.6997s	
20460/29850 (epoch 34.271), train_loss = 0.90340608, grad/param norm = 2.3891e-01, time/batch = 19.0469s	
20461/29850 (epoch 34.273), train_loss = 0.74506253, grad/param norm = 2.3080e-01, time/batch = 17.5278s	
20462/29850 (epoch 34.275), train_loss = 0.72474407, grad/param norm = 1.8950e-01, time/batch = 16.7980s	
20463/29850 (epoch 34.276), train_loss = 0.72344500, grad/param norm = 1.9124e-01, time/batch = 17.7225s	
20464/29850 (epoch 34.278), train_loss = 0.80188801, grad/param norm = 2.0927e-01, time/batch = 18.5495s	
20465/29850 (epoch 34.280), train_loss = 1.00970692, grad/param norm = 2.3865e-01, time/batch = 17.9652s	
20466/29850 (epoch 34.281), train_loss = 0.88064596, grad/param norm = 2.2044e-01, time/batch = 16.5351s	
20467/29850 (epoch 34.283), train_loss = 0.97493802, grad/param norm = 3.2498e-01, time/batch = 18.1219s	
20468/29850 (epoch 34.285), train_loss = 0.93618573, grad/param norm = 2.3694e-01, time/batch = 16.8018s	
20469/29850 (epoch 34.286), train_loss = 0.94682139, grad/param norm = 2.3677e-01, time/batch = 17.5366s	
20470/29850 (epoch 34.288), train_loss = 0.95816239, grad/param norm = 3.0750e-01, time/batch = 17.5654s	
20471/29850 (epoch 34.290), train_loss = 0.88600571, grad/param norm = 2.6392e-01, time/batch = 20.0435s	
20472/29850 (epoch 34.291), train_loss = 1.07145725, grad/param norm = 2.4230e-01, time/batch = 15.6157s	
20473/29850 (epoch 34.293), train_loss = 0.98076959, grad/param norm = 3.5781e-01, time/batch = 14.9686s	
20474/29850 (epoch 34.295), train_loss = 1.04335093, grad/param norm = 2.6551e-01, time/batch = 18.7196s	
20475/29850 (epoch 34.296), train_loss = 0.77559197, grad/param norm = 2.0112e-01, time/batch = 19.0437s	
20476/29850 (epoch 34.298), train_loss = 0.64441010, grad/param norm = 1.7103e-01, time/batch = 17.5256s	
20477/29850 (epoch 34.300), train_loss = 0.76040294, grad/param norm = 2.1121e-01, time/batch = 17.2844s	
20478/29850 (epoch 34.302), train_loss = 0.72600492, grad/param norm = 2.0632e-01, time/batch = 18.0426s	
20479/29850 (epoch 34.303), train_loss = 0.79638402, grad/param norm = 2.3016e-01, time/batch = 17.0443s	
20480/29850 (epoch 34.305), train_loss = 0.91658990, grad/param norm = 2.0155e-01, time/batch = 18.9683s	
20481/29850 (epoch 34.307), train_loss = 0.91344946, grad/param norm = 1.9637e-01, time/batch = 19.6180s	
20482/29850 (epoch 34.308), train_loss = 0.75515026, grad/param norm = 2.0064e-01, time/batch = 19.1016s	
20483/29850 (epoch 34.310), train_loss = 0.87297446, grad/param norm = 2.2717e-01, time/batch = 30.5699s	
20484/29850 (epoch 34.312), train_loss = 0.91523023, grad/param norm = 2.1493e-01, time/batch = 17.7976s	
20485/29850 (epoch 34.313), train_loss = 0.88007022, grad/param norm = 2.2432e-01, time/batch = 16.3031s	
20486/29850 (epoch 34.315), train_loss = 0.87223606, grad/param norm = 2.3104e-01, time/batch = 18.9685s	
20487/29850 (epoch 34.317), train_loss = 0.86358185, grad/param norm = 2.5340e-01, time/batch = 16.7026s	
20488/29850 (epoch 34.318), train_loss = 0.85112086, grad/param norm = 2.2021e-01, time/batch = 18.1066s	
20489/29850 (epoch 34.320), train_loss = 0.78812301, grad/param norm = 2.1111e-01, time/batch = 15.0417s	
20490/29850 (epoch 34.322), train_loss = 0.98393170, grad/param norm = 2.3157e-01, time/batch = 18.1239s	
20491/29850 (epoch 34.323), train_loss = 0.91570270, grad/param norm = 2.4298e-01, time/batch = 18.9581s	
20492/29850 (epoch 34.325), train_loss = 0.95837777, grad/param norm = 2.2697e-01, time/batch = 15.9501s	
20493/29850 (epoch 34.327), train_loss = 1.07927830, grad/param norm = 2.4228e-01, time/batch = 17.9750s	
20494/29850 (epoch 34.328), train_loss = 0.98397960, grad/param norm = 3.0904e-01, time/batch = 16.4534s	
20495/29850 (epoch 34.330), train_loss = 0.92974492, grad/param norm = 2.0135e-01, time/batch = 16.5359s	
20496/29850 (epoch 34.332), train_loss = 0.82563759, grad/param norm = 2.3019e-01, time/batch = 17.0457s	
20497/29850 (epoch 34.333), train_loss = 0.90297683, grad/param norm = 2.2790e-01, time/batch = 16.2607s	
20498/29850 (epoch 34.335), train_loss = 0.96745828, grad/param norm = 2.0698e-01, time/batch = 19.2240s	
20499/29850 (epoch 34.337), train_loss = 0.87513952, grad/param norm = 2.2783e-01, time/batch = 16.5354s	
20500/29850 (epoch 34.338), train_loss = 0.89193320, grad/param norm = 2.1436e-01, time/batch = 18.0207s	
20501/29850 (epoch 34.340), train_loss = 0.75722722, grad/param norm = 2.0472e-01, time/batch = 18.4593s	
20502/29850 (epoch 34.342), train_loss = 0.90036016, grad/param norm = 2.8165e-01, time/batch = 18.1852s	
20503/29850 (epoch 34.343), train_loss = 0.85295345, grad/param norm = 2.3269e-01, time/batch = 17.2929s	
20504/29850 (epoch 34.345), train_loss = 0.95484598, grad/param norm = 2.6008e-01, time/batch = 17.0280s	
20505/29850 (epoch 34.347), train_loss = 0.95999664, grad/param norm = 2.6906e-01, time/batch = 19.2891s	
20506/29850 (epoch 34.348), train_loss = 0.81421939, grad/param norm = 2.0752e-01, time/batch = 17.0286s	
20507/29850 (epoch 34.350), train_loss = 0.93809060, grad/param norm = 2.4626e-01, time/batch = 18.9573s	
20508/29850 (epoch 34.352), train_loss = 0.82081835, grad/param norm = 2.0511e-01, time/batch = 17.6280s	
20509/29850 (epoch 34.353), train_loss = 0.92523584, grad/param norm = 2.3910e-01, time/batch = 17.4578s	
20510/29850 (epoch 34.355), train_loss = 0.82806909, grad/param norm = 2.1771e-01, time/batch = 18.1223s	
20511/29850 (epoch 34.357), train_loss = 0.94356329, grad/param norm = 2.2309e-01, time/batch = 18.8084s	
20512/29850 (epoch 34.358), train_loss = 0.80340476, grad/param norm = 2.0882e-01, time/batch = 17.7853s	
20513/29850 (epoch 34.360), train_loss = 0.83797804, grad/param norm = 2.1026e-01, time/batch = 18.7870s	
20514/29850 (epoch 34.362), train_loss = 0.87553389, grad/param norm = 2.5837e-01, time/batch = 16.8628s	
20515/29850 (epoch 34.363), train_loss = 0.90699384, grad/param norm = 2.2028e-01, time/batch = 18.3743s	
20516/29850 (epoch 34.365), train_loss = 1.01400037, grad/param norm = 2.6250e-01, time/batch = 17.6090s	
20517/29850 (epoch 34.367), train_loss = 0.80310604, grad/param norm = 1.9475e-01, time/batch = 17.7100s	
20518/29850 (epoch 34.369), train_loss = 0.74589849, grad/param norm = 2.2932e-01, time/batch = 19.0462s	
20519/29850 (epoch 34.370), train_loss = 0.69399037, grad/param norm = 1.9277e-01, time/batch = 16.7137s	
20520/29850 (epoch 34.372), train_loss = 0.95729797, grad/param norm = 2.2156e-01, time/batch = 19.1210s	
20521/29850 (epoch 34.374), train_loss = 0.94537642, grad/param norm = 2.1773e-01, time/batch = 18.4614s	
20522/29850 (epoch 34.375), train_loss = 0.87756225, grad/param norm = 2.0603e-01, time/batch = 17.8673s	
20523/29850 (epoch 34.377), train_loss = 0.80010724, grad/param norm = 2.2330e-01, time/batch = 18.6793s	
20524/29850 (epoch 34.379), train_loss = 0.99581650, grad/param norm = 2.5863e-01, time/batch = 18.6545s	
20525/29850 (epoch 34.380), train_loss = 0.91557098, grad/param norm = 2.1154e-01, time/batch = 17.4715s	
20526/29850 (epoch 34.382), train_loss = 0.90311354, grad/param norm = 3.1151e-01, time/batch = 18.9382s	
20527/29850 (epoch 34.384), train_loss = 0.94246697, grad/param norm = 2.1005e-01, time/batch = 19.4622s	
20528/29850 (epoch 34.385), train_loss = 0.92119949, grad/param norm = 2.5280e-01, time/batch = 17.5951s	
20529/29850 (epoch 34.387), train_loss = 0.92423398, grad/param norm = 2.5232e-01, time/batch = 16.7773s	
20530/29850 (epoch 34.389), train_loss = 1.01064535, grad/param norm = 2.3070e-01, time/batch = 18.9531s	
20531/29850 (epoch 34.390), train_loss = 0.93785707, grad/param norm = 2.0222e-01, time/batch = 17.6090s	
20532/29850 (epoch 34.392), train_loss = 0.85425109, grad/param norm = 2.5461e-01, time/batch = 17.2523s	
20533/29850 (epoch 34.394), train_loss = 0.96309016, grad/param norm = 2.3919e-01, time/batch = 18.1857s	
20534/29850 (epoch 34.395), train_loss = 0.82863694, grad/param norm = 2.3870e-01, time/batch = 17.2174s	
20535/29850 (epoch 34.397), train_loss = 0.76243106, grad/param norm = 2.2577e-01, time/batch = 17.1208s	
20536/29850 (epoch 34.399), train_loss = 0.79622514, grad/param norm = 2.2385e-01, time/batch = 19.6208s	
20537/29850 (epoch 34.400), train_loss = 1.14942448, grad/param norm = 2.8575e-01, time/batch = 17.2957s	
20538/29850 (epoch 34.402), train_loss = 1.04006556, grad/param norm = 2.4629e-01, time/batch = 18.4790s	
20539/29850 (epoch 34.404), train_loss = 0.92434646, grad/param norm = 2.4441e-01, time/batch = 16.8677s	
20540/29850 (epoch 34.405), train_loss = 0.81272861, grad/param norm = 2.2414e-01, time/batch = 16.1624s	
20541/29850 (epoch 34.407), train_loss = 0.80479235, grad/param norm = 2.0022e-01, time/batch = 17.6445s	
20542/29850 (epoch 34.409), train_loss = 0.90362127, grad/param norm = 2.3551e-01, time/batch = 16.6229s	
20543/29850 (epoch 34.410), train_loss = 0.98452177, grad/param norm = 2.4509e-01, time/batch = 16.2887s	
20544/29850 (epoch 34.412), train_loss = 0.99456431, grad/param norm = 2.5539e-01, time/batch = 18.3701s	
20545/29850 (epoch 34.414), train_loss = 0.90091785, grad/param norm = 2.3076e-01, time/batch = 17.8872s	
20546/29850 (epoch 34.415), train_loss = 0.88029106, grad/param norm = 2.0739e-01, time/batch = 18.6801s	
20547/29850 (epoch 34.417), train_loss = 1.01249780, grad/param norm = 2.4660e-01, time/batch = 17.0464s	
20548/29850 (epoch 34.419), train_loss = 0.86515519, grad/param norm = 2.3474e-01, time/batch = 20.0354s	
20549/29850 (epoch 34.420), train_loss = 0.87767023, grad/param norm = 2.3080e-01, time/batch = 15.9724s	
20550/29850 (epoch 34.422), train_loss = 0.87085557, grad/param norm = 2.1701e-01, time/batch = 18.8676s	
20551/29850 (epoch 34.424), train_loss = 0.81030612, grad/param norm = 2.2123e-01, time/batch = 17.6244s	
20552/29850 (epoch 34.425), train_loss = 0.96387866, grad/param norm = 2.4405e-01, time/batch = 17.6997s	
20553/29850 (epoch 34.427), train_loss = 0.68858408, grad/param norm = 1.9758e-01, time/batch = 18.9399s	
20554/29850 (epoch 34.429), train_loss = 0.79127838, grad/param norm = 2.2139e-01, time/batch = 17.0595s	
20555/29850 (epoch 34.430), train_loss = 0.72443587, grad/param norm = 1.9347e-01, time/batch = 18.2981s	
20556/29850 (epoch 34.432), train_loss = 0.81279985, grad/param norm = 2.5521e-01, time/batch = 15.8825s	
20557/29850 (epoch 34.434), train_loss = 0.79685574, grad/param norm = 1.9067e-01, time/batch = 18.6387s	
20558/29850 (epoch 34.436), train_loss = 0.84994316, grad/param norm = 2.4236e-01, time/batch = 18.1147s	
20559/29850 (epoch 34.437), train_loss = 0.91468915, grad/param norm = 2.2159e-01, time/batch = 16.8021s	
20560/29850 (epoch 34.439), train_loss = 0.93504428, grad/param norm = 2.2191e-01, time/batch = 18.3939s	
20561/29850 (epoch 34.441), train_loss = 0.89068175, grad/param norm = 2.5355e-01, time/batch = 18.7920s	
20562/29850 (epoch 34.442), train_loss = 0.84455095, grad/param norm = 2.0656e-01, time/batch = 16.6148s	
20563/29850 (epoch 34.444), train_loss = 0.89316006, grad/param norm = 2.5821e-01, time/batch = 17.2020s	
20564/29850 (epoch 34.446), train_loss = 0.94274423, grad/param norm = 2.4348e-01, time/batch = 19.0449s	
20565/29850 (epoch 34.447), train_loss = 0.93825462, grad/param norm = 2.3468e-01, time/batch = 18.3591s	
20566/29850 (epoch 34.449), train_loss = 0.89634278, grad/param norm = 2.3595e-01, time/batch = 18.7477s	
20567/29850 (epoch 34.451), train_loss = 0.69654697, grad/param norm = 1.9769e-01, time/batch = 17.4695s	
20568/29850 (epoch 34.452), train_loss = 0.61421541, grad/param norm = 1.8374e-01, time/batch = 19.0381s	
20569/29850 (epoch 34.454), train_loss = 0.73628269, grad/param norm = 1.8638e-01, time/batch = 16.2083s	
20570/29850 (epoch 34.456), train_loss = 0.92694875, grad/param norm = 2.2449e-01, time/batch = 19.4558s	
20571/29850 (epoch 34.457), train_loss = 0.92840302, grad/param norm = 3.3627e-01, time/batch = 19.4654s	
20572/29850 (epoch 34.459), train_loss = 1.03109661, grad/param norm = 2.4769e-01, time/batch = 18.1069s	
20573/29850 (epoch 34.461), train_loss = 0.99632019, grad/param norm = 2.3326e-01, time/batch = 18.3679s	
20574/29850 (epoch 34.462), train_loss = 1.02400591, grad/param norm = 2.4299e-01, time/batch = 17.5336s	
20575/29850 (epoch 34.464), train_loss = 0.89437211, grad/param norm = 2.0932e-01, time/batch = 16.4289s	
20576/29850 (epoch 34.466), train_loss = 0.75893934, grad/param norm = 2.1184e-01, time/batch = 16.4352s	
20577/29850 (epoch 34.467), train_loss = 0.80325456, grad/param norm = 2.2001e-01, time/batch = 18.7118s	
20578/29850 (epoch 34.469), train_loss = 0.83712397, grad/param norm = 2.0945e-01, time/batch = 18.8575s	
20579/29850 (epoch 34.471), train_loss = 0.84762767, grad/param norm = 2.4479e-01, time/batch = 17.8811s	
20580/29850 (epoch 34.472), train_loss = 0.80941500, grad/param norm = 1.9398e-01, time/batch = 17.7170s	
20581/29850 (epoch 34.474), train_loss = 0.96753970, grad/param norm = 2.3478e-01, time/batch = 18.5490s	
20582/29850 (epoch 34.476), train_loss = 0.87764357, grad/param norm = 1.9922e-01, time/batch = 17.4555s	
20583/29850 (epoch 34.477), train_loss = 0.89814395, grad/param norm = 2.3366e-01, time/batch = 17.8772s	
20584/29850 (epoch 34.479), train_loss = 1.06965206, grad/param norm = 2.6442e-01, time/batch = 15.1839s	
20585/29850 (epoch 34.481), train_loss = 0.86654260, grad/param norm = 2.6327e-01, time/batch = 17.9595s	
20586/29850 (epoch 34.482), train_loss = 0.80356976, grad/param norm = 1.8887e-01, time/batch = 17.1278s	
20587/29850 (epoch 34.484), train_loss = 0.82600605, grad/param norm = 2.1350e-01, time/batch = 17.0381s	
20588/29850 (epoch 34.486), train_loss = 0.89786620, grad/param norm = 2.7211e-01, time/batch = 18.6208s	
20589/29850 (epoch 34.487), train_loss = 0.88338972, grad/param norm = 2.1822e-01, time/batch = 17.7808s	
20590/29850 (epoch 34.489), train_loss = 0.89473329, grad/param norm = 2.5164e-01, time/batch = 18.3555s	
20591/29850 (epoch 34.491), train_loss = 0.77341804, grad/param norm = 1.9920e-01, time/batch = 17.6401s	
20592/29850 (epoch 34.492), train_loss = 0.87346700, grad/param norm = 2.2492e-01, time/batch = 18.4442s	
20593/29850 (epoch 34.494), train_loss = 0.94779296, grad/param norm = 2.1481e-01, time/batch = 17.7125s	
20594/29850 (epoch 34.496), train_loss = 1.00704194, grad/param norm = 2.3447e-01, time/batch = 17.2802s	
20595/29850 (epoch 34.497), train_loss = 0.92474948, grad/param norm = 2.2783e-01, time/batch = 18.7990s	
20596/29850 (epoch 34.499), train_loss = 0.89225289, grad/param norm = 2.2539e-01, time/batch = 18.6751s	
20597/29850 (epoch 34.501), train_loss = 0.79727819, grad/param norm = 2.4320e-01, time/batch = 17.7150s	
20598/29850 (epoch 34.503), train_loss = 0.94452882, grad/param norm = 2.3290e-01, time/batch = 18.3779s	
20599/29850 (epoch 34.504), train_loss = 1.08435942, grad/param norm = 2.1679e-01, time/batch = 15.8557s	
20600/29850 (epoch 34.506), train_loss = 1.03758972, grad/param norm = 2.3418e-01, time/batch = 18.1426s	
20601/29850 (epoch 34.508), train_loss = 0.89445243, grad/param norm = 2.0871e-01, time/batch = 18.5597s	
20602/29850 (epoch 34.509), train_loss = 0.70508571, grad/param norm = 2.0128e-01, time/batch = 17.1326s	
20603/29850 (epoch 34.511), train_loss = 0.91334902, grad/param norm = 2.2231e-01, time/batch = 19.0195s	
20604/29850 (epoch 34.513), train_loss = 0.87876879, grad/param norm = 2.4335e-01, time/batch = 20.2832s	
20605/29850 (epoch 34.514), train_loss = 0.79703318, grad/param norm = 2.1040e-01, time/batch = 16.8924s	
20606/29850 (epoch 34.516), train_loss = 0.83125873, grad/param norm = 1.8456e-01, time/batch = 16.7892s	
20607/29850 (epoch 34.518), train_loss = 0.71272198, grad/param norm = 1.7993e-01, time/batch = 16.3106s	
20608/29850 (epoch 34.519), train_loss = 0.70187650, grad/param norm = 1.8648e-01, time/batch = 20.1294s	
20609/29850 (epoch 34.521), train_loss = 0.64792819, grad/param norm = 1.6426e-01, time/batch = 16.1979s	
20610/29850 (epoch 34.523), train_loss = 0.71572797, grad/param norm = 1.8293e-01, time/batch = 14.7449s	
20611/29850 (epoch 34.524), train_loss = 0.78007651, grad/param norm = 2.1831e-01, time/batch = 19.6774s	
20612/29850 (epoch 34.526), train_loss = 0.83469088, grad/param norm = 2.2777e-01, time/batch = 17.5410s	
20613/29850 (epoch 34.528), train_loss = 0.94823608, grad/param norm = 2.5006e-01, time/batch = 18.3857s	
20614/29850 (epoch 34.529), train_loss = 0.91432058, grad/param norm = 2.4597e-01, time/batch = 17.8856s	
20615/29850 (epoch 34.531), train_loss = 0.85768879, grad/param norm = 2.5762e-01, time/batch = 19.6319s	
20616/29850 (epoch 34.533), train_loss = 0.87735268, grad/param norm = 2.3310e-01, time/batch = 16.6963s	
20617/29850 (epoch 34.534), train_loss = 0.92533969, grad/param norm = 2.3306e-01, time/batch = 18.3086s	
20618/29850 (epoch 34.536), train_loss = 0.80870895, grad/param norm = 2.2556e-01, time/batch = 19.6036s	
20619/29850 (epoch 34.538), train_loss = 0.98238795, grad/param norm = 2.4775e-01, time/batch = 17.2972s	
20620/29850 (epoch 34.539), train_loss = 1.03164940, grad/param norm = 2.5417e-01, time/batch = 18.2903s	
20621/29850 (epoch 34.541), train_loss = 0.64561264, grad/param norm = 1.8777e-01, time/batch = 18.4508s	
20622/29850 (epoch 34.543), train_loss = 0.82183410, grad/param norm = 2.3027e-01, time/batch = 16.0330s	
20623/29850 (epoch 34.544), train_loss = 0.94253829, grad/param norm = 2.3282e-01, time/batch = 16.6704s	
20624/29850 (epoch 34.546), train_loss = 0.94778711, grad/param norm = 2.5292e-01, time/batch = 16.3776s	
20625/29850 (epoch 34.548), train_loss = 0.73190789, grad/param norm = 1.8434e-01, time/batch = 18.4737s	
20626/29850 (epoch 34.549), train_loss = 0.81901149, grad/param norm = 2.0840e-01, time/batch = 16.1248s	
20627/29850 (epoch 34.551), train_loss = 0.77383926, grad/param norm = 2.0228e-01, time/batch = 17.3796s	
20628/29850 (epoch 34.553), train_loss = 0.87916562, grad/param norm = 2.3376e-01, time/batch = 17.8602s	
20629/29850 (epoch 34.554), train_loss = 0.73170755, grad/param norm = 2.1533e-01, time/batch = 17.9425s	
20630/29850 (epoch 34.556), train_loss = 0.75556845, grad/param norm = 2.1242e-01, time/batch = 19.8791s	
20631/29850 (epoch 34.558), train_loss = 0.77969443, grad/param norm = 2.0051e-01, time/batch = 18.1299s	
20632/29850 (epoch 34.559), train_loss = 0.79710220, grad/param norm = 2.0259e-01, time/batch = 18.4341s	
20633/29850 (epoch 34.561), train_loss = 0.87169628, grad/param norm = 2.1943e-01, time/batch = 17.7053s	
20634/29850 (epoch 34.563), train_loss = 0.91132338, grad/param norm = 2.3064e-01, time/batch = 17.6136s	
20635/29850 (epoch 34.564), train_loss = 0.83227428, grad/param norm = 2.3265e-01, time/batch = 19.2962s	
20636/29850 (epoch 34.566), train_loss = 0.87207426, grad/param norm = 2.2139e-01, time/batch = 17.4358s	
20637/29850 (epoch 34.568), train_loss = 0.99025632, grad/param norm = 2.5635e-01, time/batch = 17.9689s	
20638/29850 (epoch 34.570), train_loss = 0.91684030, grad/param norm = 2.6333e-01, time/batch = 18.3821s	
20639/29850 (epoch 34.571), train_loss = 0.97604572, grad/param norm = 2.3050e-01, time/batch = 16.7935s	
20640/29850 (epoch 34.573), train_loss = 1.00828769, grad/param norm = 2.3572e-01, time/batch = 14.4005s	
20641/29850 (epoch 34.575), train_loss = 1.04740762, grad/param norm = 2.4518e-01, time/batch = 15.3752s	
20642/29850 (epoch 34.576), train_loss = 0.96301541, grad/param norm = 2.5344e-01, time/batch = 15.6994s	
20643/29850 (epoch 34.578), train_loss = 0.82480548, grad/param norm = 2.3667e-01, time/batch = 15.8770s	
20644/29850 (epoch 34.580), train_loss = 0.96224222, grad/param norm = 2.4988e-01, time/batch = 16.9797s	
20645/29850 (epoch 34.581), train_loss = 0.79513339, grad/param norm = 1.9687e-01, time/batch = 18.8752s	
20646/29850 (epoch 34.583), train_loss = 0.85826074, grad/param norm = 2.2008e-01, time/batch = 17.9485s	
20647/29850 (epoch 34.585), train_loss = 0.91686971, grad/param norm = 2.2683e-01, time/batch = 18.7717s	
20648/29850 (epoch 34.586), train_loss = 0.90655721, grad/param norm = 2.7301e-01, time/batch = 17.0689s	
20649/29850 (epoch 34.588), train_loss = 0.80205242, grad/param norm = 2.2272e-01, time/batch = 19.1364s	
20650/29850 (epoch 34.590), train_loss = 0.82091568, grad/param norm = 1.9858e-01, time/batch = 17.5994s	
20651/29850 (epoch 34.591), train_loss = 0.86309116, grad/param norm = 2.5468e-01, time/batch = 18.9543s	
20652/29850 (epoch 34.593), train_loss = 0.79020983, grad/param norm = 1.9264e-01, time/batch = 17.2902s	
20653/29850 (epoch 34.595), train_loss = 0.73564483, grad/param norm = 1.7979e-01, time/batch = 16.7068s	
20654/29850 (epoch 34.596), train_loss = 0.76019296, grad/param norm = 2.1684e-01, time/batch = 19.1132s	
20655/29850 (epoch 34.598), train_loss = 0.85771895, grad/param norm = 2.2171e-01, time/batch = 18.5474s	
20656/29850 (epoch 34.600), train_loss = 0.88840781, grad/param norm = 2.6159e-01, time/batch = 18.0300s	
20657/29850 (epoch 34.601), train_loss = 0.75274487, grad/param norm = 1.9321e-01, time/batch = 17.4616s	
20658/29850 (epoch 34.603), train_loss = 0.82081029, grad/param norm = 2.2916e-01, time/batch = 17.0574s	
20659/29850 (epoch 34.605), train_loss = 0.84498107, grad/param norm = 2.2266e-01, time/batch = 17.8684s	
20660/29850 (epoch 34.606), train_loss = 0.61075281, grad/param norm = 1.7357e-01, time/batch = 17.8345s	
20661/29850 (epoch 34.608), train_loss = 0.76151505, grad/param norm = 2.1183e-01, time/batch = 18.8667s	
20662/29850 (epoch 34.610), train_loss = 0.81245602, grad/param norm = 2.0783e-01, time/batch = 18.9537s	
20663/29850 (epoch 34.611), train_loss = 0.75014252, grad/param norm = 2.0284e-01, time/batch = 17.4480s	
20664/29850 (epoch 34.613), train_loss = 0.64655151, grad/param norm = 1.7104e-01, time/batch = 15.2960s	
20665/29850 (epoch 34.615), train_loss = 0.73216800, grad/param norm = 1.8467e-01, time/batch = 18.2887s	
20666/29850 (epoch 34.616), train_loss = 0.73179903, grad/param norm = 2.1916e-01, time/batch = 18.1990s	
20667/29850 (epoch 34.618), train_loss = 0.81516698, grad/param norm = 2.1050e-01, time/batch = 16.4771s	
20668/29850 (epoch 34.620), train_loss = 0.89117891, grad/param norm = 2.4124e-01, time/batch = 17.5502s	
20669/29850 (epoch 34.621), train_loss = 0.97240671, grad/param norm = 2.3851e-01, time/batch = 17.4664s	
20670/29850 (epoch 34.623), train_loss = 0.93962510, grad/param norm = 2.4861e-01, time/batch = 15.9596s	
20671/29850 (epoch 34.625), train_loss = 0.86489935, grad/param norm = 2.5913e-01, time/batch = 19.2142s	
20672/29850 (epoch 34.626), train_loss = 0.88165403, grad/param norm = 2.5263e-01, time/batch = 19.0530s	
20673/29850 (epoch 34.628), train_loss = 0.84455150, grad/param norm = 2.3130e-01, time/batch = 17.4414s	
20674/29850 (epoch 34.630), train_loss = 0.87196229, grad/param norm = 2.3716e-01, time/batch = 18.6905s	
20675/29850 (epoch 34.631), train_loss = 0.85865154, grad/param norm = 2.1432e-01, time/batch = 19.0448s	
20676/29850 (epoch 34.633), train_loss = 0.90050886, grad/param norm = 2.4960e-01, time/batch = 17.3646s	
20677/29850 (epoch 34.635), train_loss = 0.81662629, grad/param norm = 2.2610e-01, time/batch = 16.6130s	
20678/29850 (epoch 34.637), train_loss = 0.76871810, grad/param norm = 1.9836e-01, time/batch = 17.7880s	
20679/29850 (epoch 34.638), train_loss = 0.87596491, grad/param norm = 2.2609e-01, time/batch = 18.6891s	
20680/29850 (epoch 34.640), train_loss = 0.98668247, grad/param norm = 2.5558e-01, time/batch = 18.3552s	
20681/29850 (epoch 34.642), train_loss = 0.78258386, grad/param norm = 1.8825e-01, time/batch = 18.2032s	
20682/29850 (epoch 34.643), train_loss = 0.78082040, grad/param norm = 2.3601e-01, time/batch = 17.5464s	
20683/29850 (epoch 34.645), train_loss = 0.84992279, grad/param norm = 2.1884e-01, time/batch = 24.5877s	
20684/29850 (epoch 34.647), train_loss = 0.98676701, grad/param norm = 2.4952e-01, time/batch = 22.9940s	
20685/29850 (epoch 34.648), train_loss = 0.74899278, grad/param norm = 1.8436e-01, time/batch = 16.6514s	
20686/29850 (epoch 34.650), train_loss = 0.87886802, grad/param norm = 2.3352e-01, time/batch = 18.1967s	
20687/29850 (epoch 34.652), train_loss = 0.85301268, grad/param norm = 2.3575e-01, time/batch = 18.8756s	
20688/29850 (epoch 34.653), train_loss = 0.94943807, grad/param norm = 2.4474e-01, time/batch = 19.9472s	
20689/29850 (epoch 34.655), train_loss = 0.85167569, grad/param norm = 1.9451e-01, time/batch = 15.8692s	
20690/29850 (epoch 34.657), train_loss = 0.84319633, grad/param norm = 2.1677e-01, time/batch = 16.6261s	
20691/29850 (epoch 34.658), train_loss = 0.96733722, grad/param norm = 2.3015e-01, time/batch = 16.4739s	
20692/29850 (epoch 34.660), train_loss = 0.81618263, grad/param norm = 2.2963e-01, time/batch = 17.7873s	
20693/29850 (epoch 34.662), train_loss = 0.95637454, grad/param norm = 2.3575e-01, time/batch = 17.7905s	
20694/29850 (epoch 34.663), train_loss = 1.05762668, grad/param norm = 2.3079e-01, time/batch = 17.6553s	
20695/29850 (epoch 34.665), train_loss = 0.99371739, grad/param norm = 2.4246e-01, time/batch = 18.5687s	
20696/29850 (epoch 34.667), train_loss = 0.92616005, grad/param norm = 2.9779e-01, time/batch = 15.6033s	
20697/29850 (epoch 34.668), train_loss = 0.82194543, grad/param norm = 2.5948e-01, time/batch = 19.5427s	
20698/29850 (epoch 34.670), train_loss = 0.98668323, grad/param norm = 3.1284e-01, time/batch = 17.4731s	
20699/29850 (epoch 34.672), train_loss = 0.94961982, grad/param norm = 2.4191e-01, time/batch = 17.2132s	
20700/29850 (epoch 34.673), train_loss = 0.90779549, grad/param norm = 2.3668e-01, time/batch = 18.0476s	
20701/29850 (epoch 34.675), train_loss = 0.78417979, grad/param norm = 2.0898e-01, time/batch = 17.1403s	
20702/29850 (epoch 34.677), train_loss = 0.81385024, grad/param norm = 2.0220e-01, time/batch = 17.9673s	
20703/29850 (epoch 34.678), train_loss = 0.86789442, grad/param norm = 2.1853e-01, time/batch = 16.4487s	
20704/29850 (epoch 34.680), train_loss = 0.85666668, grad/param norm = 2.3015e-01, time/batch = 18.6296s	
20705/29850 (epoch 34.682), train_loss = 0.86413378, grad/param norm = 2.3826e-01, time/batch = 19.7081s	
20706/29850 (epoch 34.683), train_loss = 0.98801060, grad/param norm = 2.4186e-01, time/batch = 16.3699s	
20707/29850 (epoch 34.685), train_loss = 1.04832346, grad/param norm = 2.1685e-01, time/batch = 17.1077s	
20708/29850 (epoch 34.687), train_loss = 0.88423671, grad/param norm = 2.1289e-01, time/batch = 15.5367s	
20709/29850 (epoch 34.688), train_loss = 0.76513446, grad/param norm = 2.2008e-01, time/batch = 18.4506s	
20710/29850 (epoch 34.690), train_loss = 0.76528044, grad/param norm = 1.9372e-01, time/batch = 16.6289s	
20711/29850 (epoch 34.692), train_loss = 0.98038311, grad/param norm = 2.1264e-01, time/batch = 19.1965s	
20712/29850 (epoch 34.693), train_loss = 0.86135911, grad/param norm = 2.1211e-01, time/batch = 18.4710s	
20713/29850 (epoch 34.695), train_loss = 0.75841809, grad/param norm = 1.9217e-01, time/batch = 18.1196s	
20714/29850 (epoch 34.697), train_loss = 0.87264428, grad/param norm = 2.2721e-01, time/batch = 19.2892s	
20715/29850 (epoch 34.698), train_loss = 0.98905279, grad/param norm = 2.0957e-01, time/batch = 18.5466s	
20716/29850 (epoch 34.700), train_loss = 0.94207428, grad/param norm = 2.8037e-01, time/batch = 16.1321s	
20717/29850 (epoch 34.702), train_loss = 0.89570319, grad/param norm = 2.5292e-01, time/batch = 18.7716s	
20718/29850 (epoch 34.704), train_loss = 0.73773922, grad/param norm = 1.9055e-01, time/batch = 17.0479s	
20719/29850 (epoch 34.705), train_loss = 0.89074522, grad/param norm = 2.5081e-01, time/batch = 18.3738s	
20720/29850 (epoch 34.707), train_loss = 0.80367509, grad/param norm = 2.6532e-01, time/batch = 19.0333s	
20721/29850 (epoch 34.709), train_loss = 0.86625930, grad/param norm = 2.2705e-01, time/batch = 19.7923s	
20722/29850 (epoch 34.710), train_loss = 0.80874603, grad/param norm = 2.6160e-01, time/batch = 17.4691s	
20723/29850 (epoch 34.712), train_loss = 0.89702815, grad/param norm = 2.1069e-01, time/batch = 15.8674s	
20724/29850 (epoch 34.714), train_loss = 0.96153352, grad/param norm = 2.6774e-01, time/batch = 16.8710s	
20725/29850 (epoch 34.715), train_loss = 0.87770291, grad/param norm = 2.1619e-01, time/batch = 15.9937s	
20726/29850 (epoch 34.717), train_loss = 0.66025302, grad/param norm = 2.1685e-01, time/batch = 15.3689s	
20727/29850 (epoch 34.719), train_loss = 0.82843845, grad/param norm = 2.1274e-01, time/batch = 15.4621s	
20728/29850 (epoch 34.720), train_loss = 0.85983622, grad/param norm = 2.0643e-01, time/batch = 18.9569s	
20729/29850 (epoch 34.722), train_loss = 0.78226061, grad/param norm = 1.8098e-01, time/batch = 16.7005s	
20730/29850 (epoch 34.724), train_loss = 0.90151230, grad/param norm = 2.5281e-01, time/batch = 16.3603s	
20731/29850 (epoch 34.725), train_loss = 0.76578433, grad/param norm = 1.8657e-01, time/batch = 18.3076s	
20732/29850 (epoch 34.727), train_loss = 0.77070377, grad/param norm = 2.2077e-01, time/batch = 18.1276s	
20733/29850 (epoch 34.729), train_loss = 0.71955168, grad/param norm = 1.6626e-01, time/batch = 16.7862s	
20734/29850 (epoch 34.730), train_loss = 0.68819107, grad/param norm = 1.8688e-01, time/batch = 18.5215s	
20735/29850 (epoch 34.732), train_loss = 0.97320533, grad/param norm = 2.0772e-01, time/batch = 17.1220s	
20736/29850 (epoch 34.734), train_loss = 1.03808589, grad/param norm = 2.4888e-01, time/batch = 17.8699s	
20737/29850 (epoch 34.735), train_loss = 0.75869404, grad/param norm = 2.1090e-01, time/batch = 16.4453s	
20738/29850 (epoch 34.737), train_loss = 0.74441709, grad/param norm = 1.9171e-01, time/batch = 19.1209s	
20739/29850 (epoch 34.739), train_loss = 0.67544312, grad/param norm = 2.2082e-01, time/batch = 15.7155s	
20740/29850 (epoch 34.740), train_loss = 0.73980045, grad/param norm = 2.2256e-01, time/batch = 17.5418s	
20741/29850 (epoch 34.742), train_loss = 0.64256581, grad/param norm = 1.6093e-01, time/batch = 16.9472s	
20742/29850 (epoch 34.744), train_loss = 0.77681233, grad/param norm = 2.5446e-01, time/batch = 18.2835s	
20743/29850 (epoch 34.745), train_loss = 0.82584939, grad/param norm = 2.3127e-01, time/batch = 16.4545s	
20744/29850 (epoch 34.747), train_loss = 0.83530888, grad/param norm = 2.1313e-01, time/batch = 18.7072s	
20745/29850 (epoch 34.749), train_loss = 0.73013790, grad/param norm = 2.1585e-01, time/batch = 17.6481s	
20746/29850 (epoch 34.750), train_loss = 0.70577782, grad/param norm = 2.2533e-01, time/batch = 17.1463s	
20747/29850 (epoch 34.752), train_loss = 0.60311849, grad/param norm = 1.8650e-01, time/batch = 16.5449s	
20748/29850 (epoch 34.754), train_loss = 0.67936864, grad/param norm = 1.9893e-01, time/batch = 18.3710s	
20749/29850 (epoch 34.755), train_loss = 0.69095640, grad/param norm = 1.9847e-01, time/batch = 17.8837s	
20750/29850 (epoch 34.757), train_loss = 0.73907100, grad/param norm = 1.9652e-01, time/batch = 17.1982s	
20751/29850 (epoch 34.759), train_loss = 0.74126440, grad/param norm = 2.0517e-01, time/batch = 14.7376s	
20752/29850 (epoch 34.760), train_loss = 0.77212969, grad/param norm = 2.1013e-01, time/batch = 17.9574s	
20753/29850 (epoch 34.762), train_loss = 0.69913074, grad/param norm = 2.0548e-01, time/batch = 18.0434s	
20754/29850 (epoch 34.764), train_loss = 0.63345356, grad/param norm = 1.9450e-01, time/batch = 15.5172s	
20755/29850 (epoch 34.765), train_loss = 0.80013358, grad/param norm = 2.2559e-01, time/batch = 18.9455s	
20756/29850 (epoch 34.767), train_loss = 0.78682614, grad/param norm = 1.9866e-01, time/batch = 19.1230s	
20757/29850 (epoch 34.769), train_loss = 0.80949229, grad/param norm = 2.0498e-01, time/batch = 17.3694s	
20758/29850 (epoch 34.771), train_loss = 0.86596755, grad/param norm = 2.1815e-01, time/batch = 18.3543s	
20759/29850 (epoch 34.772), train_loss = 0.85592267, grad/param norm = 2.4015e-01, time/batch = 18.5345s	
20760/29850 (epoch 34.774), train_loss = 0.77573580, grad/param norm = 2.0560e-01, time/batch = 16.4346s	
20761/29850 (epoch 34.776), train_loss = 0.79999866, grad/param norm = 2.0757e-01, time/batch = 19.8654s	
20762/29850 (epoch 34.777), train_loss = 0.91147101, grad/param norm = 2.1701e-01, time/batch = 18.3805s	
20763/29850 (epoch 34.779), train_loss = 0.73056591, grad/param norm = 2.0396e-01, time/batch = 17.9647s	
20764/29850 (epoch 34.781), train_loss = 0.85440748, grad/param norm = 2.2958e-01, time/batch = 17.7143s	
20765/29850 (epoch 34.782), train_loss = 0.84188161, grad/param norm = 1.9709e-01, time/batch = 18.3766s	
20766/29850 (epoch 34.784), train_loss = 0.68504683, grad/param norm = 2.2641e-01, time/batch = 18.7082s	
20767/29850 (epoch 34.786), train_loss = 0.76642646, grad/param norm = 2.0592e-01, time/batch = 16.0352s	
20768/29850 (epoch 34.787), train_loss = 0.67376354, grad/param norm = 2.6862e-01, time/batch = 18.3857s	
20769/29850 (epoch 34.789), train_loss = 0.67001852, grad/param norm = 1.8253e-01, time/batch = 17.8734s	
20770/29850 (epoch 34.791), train_loss = 0.76141503, grad/param norm = 2.5467e-01, time/batch = 15.4337s	
20771/29850 (epoch 34.792), train_loss = 0.88349691, grad/param norm = 3.0431e-01, time/batch = 19.4499s	
20772/29850 (epoch 34.794), train_loss = 0.82963254, grad/param norm = 2.0446e-01, time/batch = 18.1385s	
20773/29850 (epoch 34.796), train_loss = 0.72547804, grad/param norm = 1.8127e-01, time/batch = 16.1941s	
20774/29850 (epoch 34.797), train_loss = 0.63724332, grad/param norm = 1.7214e-01, time/batch = 15.5502s	
20775/29850 (epoch 34.799), train_loss = 0.68666026, grad/param norm = 1.8441e-01, time/batch = 18.8756s	
20776/29850 (epoch 34.801), train_loss = 0.70870381, grad/param norm = 1.7060e-01, time/batch = 18.3956s	
20777/29850 (epoch 34.802), train_loss = 0.66855412, grad/param norm = 2.1647e-01, time/batch = 17.2950s	
20778/29850 (epoch 34.804), train_loss = 0.70750532, grad/param norm = 1.7555e-01, time/batch = 18.1362s	
20779/29850 (epoch 34.806), train_loss = 0.66910000, grad/param norm = 1.9916e-01, time/batch = 18.7963s	
20780/29850 (epoch 34.807), train_loss = 0.68970542, grad/param norm = 1.9710e-01, time/batch = 18.5412s	
20781/29850 (epoch 34.809), train_loss = 0.69895458, grad/param norm = 2.6425e-01, time/batch = 15.9497s	
20782/29850 (epoch 34.811), train_loss = 0.85833181, grad/param norm = 2.3936e-01, time/batch = 18.1199s	
20783/29850 (epoch 34.812), train_loss = 0.85085858, grad/param norm = 2.2645e-01, time/batch = 18.8772s	
20784/29850 (epoch 34.814), train_loss = 0.90368849, grad/param norm = 2.5101e-01, time/batch = 17.5314s	
20785/29850 (epoch 34.816), train_loss = 0.90143420, grad/param norm = 2.0737e-01, time/batch = 18.9361s	
20786/29850 (epoch 34.817), train_loss = 0.84422181, grad/param norm = 2.3899e-01, time/batch = 16.1288s	
20787/29850 (epoch 34.819), train_loss = 0.69518386, grad/param norm = 2.3841e-01, time/batch = 18.4662s	
20788/29850 (epoch 34.821), train_loss = 0.92018583, grad/param norm = 2.7184e-01, time/batch = 18.6437s	
20789/29850 (epoch 34.822), train_loss = 0.92661596, grad/param norm = 2.3247e-01, time/batch = 18.2070s	
20790/29850 (epoch 34.824), train_loss = 0.82759360, grad/param norm = 2.1395e-01, time/batch = 15.6149s	
20791/29850 (epoch 34.826), train_loss = 0.72707450, grad/param norm = 1.9839e-01, time/batch = 17.5310s	
20792/29850 (epoch 34.827), train_loss = 0.66308180, grad/param norm = 2.2273e-01, time/batch = 18.2183s	
20793/29850 (epoch 34.829), train_loss = 0.82561108, grad/param norm = 2.5983e-01, time/batch = 17.8094s	
20794/29850 (epoch 34.831), train_loss = 0.92587539, grad/param norm = 2.2698e-01, time/batch = 16.8680s	
20795/29850 (epoch 34.832), train_loss = 0.84425533, grad/param norm = 2.0218e-01, time/batch = 17.9748s	
20796/29850 (epoch 34.834), train_loss = 0.63002358, grad/param norm = 1.9636e-01, time/batch = 17.5043s	
20797/29850 (epoch 34.836), train_loss = 0.65582104, grad/param norm = 1.8999e-01, time/batch = 17.4474s	
20798/29850 (epoch 34.838), train_loss = 0.75889495, grad/param norm = 2.2480e-01, time/batch = 17.3140s	
20799/29850 (epoch 34.839), train_loss = 0.67202604, grad/param norm = 2.1540e-01, time/batch = 18.5454s	
20800/29850 (epoch 34.841), train_loss = 0.71105384, grad/param norm = 1.8045e-01, time/batch = 18.7124s	
20801/29850 (epoch 34.843), train_loss = 0.66262003, grad/param norm = 2.1773e-01, time/batch = 17.9452s	
20802/29850 (epoch 34.844), train_loss = 0.72708868, grad/param norm = 2.4860e-01, time/batch = 16.9763s	
20803/29850 (epoch 34.846), train_loss = 0.78628460, grad/param norm = 2.0458e-01, time/batch = 17.9636s	
20804/29850 (epoch 34.848), train_loss = 0.87984092, grad/param norm = 2.6622e-01, time/batch = 17.1972s	
20805/29850 (epoch 34.849), train_loss = 0.76176486, grad/param norm = 2.1341e-01, time/batch = 17.2247s	
20806/29850 (epoch 34.851), train_loss = 0.96683736, grad/param norm = 2.5034e-01, time/batch = 19.7822s	
20807/29850 (epoch 34.853), train_loss = 0.74722179, grad/param norm = 2.1137e-01, time/batch = 16.1130s	
20808/29850 (epoch 34.854), train_loss = 0.92830929, grad/param norm = 2.3796e-01, time/batch = 17.1300s	
20809/29850 (epoch 34.856), train_loss = 0.91721228, grad/param norm = 2.4257e-01, time/batch = 16.4442s	
20810/29850 (epoch 34.858), train_loss = 0.83842298, grad/param norm = 2.7060e-01, time/batch = 19.5351s	
20811/29850 (epoch 34.859), train_loss = 0.74693931, grad/param norm = 2.4578e-01, time/batch = 18.7809s	
20812/29850 (epoch 34.861), train_loss = 0.91153518, grad/param norm = 2.2835e-01, time/batch = 18.6969s	
20813/29850 (epoch 34.863), train_loss = 0.95241443, grad/param norm = 2.4427e-01, time/batch = 19.7882s	
20814/29850 (epoch 34.864), train_loss = 0.93452445, grad/param norm = 2.6500e-01, time/batch = 16.1254s	
20815/29850 (epoch 34.866), train_loss = 0.86049016, grad/param norm = 2.6393e-01, time/batch = 19.4608s	
20816/29850 (epoch 34.868), train_loss = 0.98425000, grad/param norm = 2.4773e-01, time/batch = 19.2997s	
20817/29850 (epoch 34.869), train_loss = 0.89866190, grad/param norm = 2.5804e-01, time/batch = 17.7778s	
20818/29850 (epoch 34.871), train_loss = 0.92123145, grad/param norm = 2.3726e-01, time/batch = 18.5368s	
20819/29850 (epoch 34.873), train_loss = 0.84292956, grad/param norm = 2.4199e-01, time/batch = 16.8977s	
20820/29850 (epoch 34.874), train_loss = 0.85501158, grad/param norm = 2.3640e-01, time/batch = 18.5285s	
20821/29850 (epoch 34.876), train_loss = 0.82980622, grad/param norm = 2.9745e-01, time/batch = 18.0471s	
20822/29850 (epoch 34.878), train_loss = 0.85038465, grad/param norm = 2.0855e-01, time/batch = 18.4573s	
20823/29850 (epoch 34.879), train_loss = 0.87622005, grad/param norm = 2.1335e-01, time/batch = 19.3082s	
20824/29850 (epoch 34.881), train_loss = 0.93031188, grad/param norm = 2.1677e-01, time/batch = 17.2417s	
20825/29850 (epoch 34.883), train_loss = 0.89459936, grad/param norm = 2.2435e-01, time/batch = 17.3720s	
20826/29850 (epoch 34.884), train_loss = 0.73617920, grad/param norm = 2.0355e-01, time/batch = 18.9718s	
20827/29850 (epoch 34.886), train_loss = 0.95681487, grad/param norm = 2.9134e-01, time/batch = 16.2186s	
20828/29850 (epoch 34.888), train_loss = 0.83913309, grad/param norm = 2.2772e-01, time/batch = 16.2719s	
20829/29850 (epoch 34.889), train_loss = 0.76778830, grad/param norm = 1.9756e-01, time/batch = 19.3784s	
20830/29850 (epoch 34.891), train_loss = 0.74763139, grad/param norm = 1.9465e-01, time/batch = 17.9662s	
20831/29850 (epoch 34.893), train_loss = 0.80197158, grad/param norm = 2.0856e-01, time/batch = 16.6201s	
20832/29850 (epoch 34.894), train_loss = 0.82720338, grad/param norm = 2.2096e-01, time/batch = 19.2181s	
20833/29850 (epoch 34.896), train_loss = 0.84203241, grad/param norm = 2.5680e-01, time/batch = 15.8975s	
20834/29850 (epoch 34.898), train_loss = 0.97593155, grad/param norm = 2.4075e-01, time/batch = 15.7890s	
20835/29850 (epoch 34.899), train_loss = 0.73148859, grad/param norm = 2.2517e-01, time/batch = 19.5267s	
20836/29850 (epoch 34.901), train_loss = 1.01743165, grad/param norm = 2.9597e-01, time/batch = 16.2322s	
20837/29850 (epoch 34.903), train_loss = 0.90034077, grad/param norm = 3.2094e-01, time/batch = 18.5318s	
20838/29850 (epoch 34.905), train_loss = 1.11865308, grad/param norm = 2.6665e-01, time/batch = 17.8617s	
20839/29850 (epoch 34.906), train_loss = 0.87019310, grad/param norm = 2.3147e-01, time/batch = 19.3763s	
20840/29850 (epoch 34.908), train_loss = 0.99828858, grad/param norm = 2.4197e-01, time/batch = 18.3797s	
20841/29850 (epoch 34.910), train_loss = 0.90671714, grad/param norm = 2.0386e-01, time/batch = 16.5516s	
20842/29850 (epoch 34.911), train_loss = 1.06664951, grad/param norm = 2.2587e-01, time/batch = 16.9623s	
20843/29850 (epoch 34.913), train_loss = 0.97918253, grad/param norm = 2.5253e-01, time/batch = 18.1304s	
20844/29850 (epoch 34.915), train_loss = 0.98585951, grad/param norm = 2.4338e-01, time/batch = 16.3854s	
20845/29850 (epoch 34.916), train_loss = 0.94747266, grad/param norm = 2.4440e-01, time/batch = 18.1323s	
20846/29850 (epoch 34.918), train_loss = 0.80007377, grad/param norm = 2.0296e-01, time/batch = 15.3757s	
20847/29850 (epoch 34.920), train_loss = 0.98092009, grad/param norm = 2.2196e-01, time/batch = 16.6989s	
20848/29850 (epoch 34.921), train_loss = 0.85125671, grad/param norm = 2.2716e-01, time/batch = 18.4426s	
20849/29850 (epoch 34.923), train_loss = 0.86455924, grad/param norm = 2.0560e-01, time/batch = 19.1267s	
20850/29850 (epoch 34.925), train_loss = 1.00129653, grad/param norm = 2.4252e-01, time/batch = 18.2926s	
20851/29850 (epoch 34.926), train_loss = 1.00994214, grad/param norm = 2.5625e-01, time/batch = 16.9576s	
20852/29850 (epoch 34.928), train_loss = 0.84186435, grad/param norm = 2.1443e-01, time/batch = 18.3834s	
20853/29850 (epoch 34.930), train_loss = 0.89971322, grad/param norm = 2.4083e-01, time/batch = 17.2030s	
20854/29850 (epoch 34.931), train_loss = 0.86942758, grad/param norm = 2.2442e-01, time/batch = 17.3731s	
20855/29850 (epoch 34.933), train_loss = 1.00660612, grad/param norm = 2.5203e-01, time/batch = 19.8528s	
20856/29850 (epoch 34.935), train_loss = 0.93987722, grad/param norm = 2.3670e-01, time/batch = 17.9661s	
20857/29850 (epoch 34.936), train_loss = 0.89994158, grad/param norm = 2.4602e-01, time/batch = 18.2117s	
20858/29850 (epoch 34.938), train_loss = 0.77015374, grad/param norm = 2.0283e-01, time/batch = 15.4536s	
20859/29850 (epoch 34.940), train_loss = 0.77510613, grad/param norm = 2.0349e-01, time/batch = 17.1364s	
20860/29850 (epoch 34.941), train_loss = 0.78774581, grad/param norm = 2.4123e-01, time/batch = 17.9495s	
20861/29850 (epoch 34.943), train_loss = 0.79855307, grad/param norm = 2.4096e-01, time/batch = 16.1339s	
20862/29850 (epoch 34.945), train_loss = 0.77091069, grad/param norm = 2.1239e-01, time/batch = 17.3558s	
20863/29850 (epoch 34.946), train_loss = 0.75871314, grad/param norm = 2.1463e-01, time/batch = 19.7816s	
20864/29850 (epoch 34.948), train_loss = 0.88277686, grad/param norm = 2.2251e-01, time/batch = 18.4454s	
20865/29850 (epoch 34.950), train_loss = 0.81315011, grad/param norm = 1.9063e-01, time/batch = 17.7926s	
20866/29850 (epoch 34.951), train_loss = 0.72624051, grad/param norm = 2.1616e-01, time/batch = 19.6274s	
20867/29850 (epoch 34.953), train_loss = 0.81631400, grad/param norm = 2.1759e-01, time/batch = 17.9588s	
20868/29850 (epoch 34.955), train_loss = 0.73346774, grad/param norm = 2.0265e-01, time/batch = 16.3701s	
20869/29850 (epoch 34.956), train_loss = 0.75102478, grad/param norm = 2.0552e-01, time/batch = 17.4732s	
20870/29850 (epoch 34.958), train_loss = 0.66116450, grad/param norm = 1.7431e-01, time/batch = 17.9641s	
20871/29850 (epoch 34.960), train_loss = 0.94481546, grad/param norm = 2.4629e-01, time/batch = 17.3645s	
20872/29850 (epoch 34.961), train_loss = 0.71565778, grad/param norm = 2.0890e-01, time/batch = 17.9596s	
20873/29850 (epoch 34.963), train_loss = 0.72479530, grad/param norm = 2.0271e-01, time/batch = 15.1317s	
20874/29850 (epoch 34.965), train_loss = 0.75888519, grad/param norm = 2.0578e-01, time/batch = 17.2880s	
20875/29850 (epoch 34.966), train_loss = 0.72649095, grad/param norm = 2.1975e-01, time/batch = 17.3622s	
20876/29850 (epoch 34.968), train_loss = 0.76192966, grad/param norm = 2.3117e-01, time/batch = 17.3987s	
20877/29850 (epoch 34.970), train_loss = 0.76261597, grad/param norm = 2.5906e-01, time/batch = 18.8790s	
20878/29850 (epoch 34.972), train_loss = 0.76061100, grad/param norm = 2.0085e-01, time/batch = 18.1143s	
20879/29850 (epoch 34.973), train_loss = 0.76126679, grad/param norm = 2.0719e-01, time/batch = 18.9688s	
20880/29850 (epoch 34.975), train_loss = 0.64446629, grad/param norm = 2.1163e-01, time/batch = 16.1879s	
20881/29850 (epoch 34.977), train_loss = 0.79912928, grad/param norm = 2.1403e-01, time/batch = 17.1331s	
20882/29850 (epoch 34.978), train_loss = 0.68389465, grad/param norm = 2.0146e-01, time/batch = 16.2893s	
20883/29850 (epoch 34.980), train_loss = 0.76913043, grad/param norm = 1.8909e-01, time/batch = 16.8844s	
20884/29850 (epoch 34.982), train_loss = 0.73537328, grad/param norm = 1.9404e-01, time/batch = 18.1401s	
20885/29850 (epoch 34.983), train_loss = 0.76791610, grad/param norm = 1.8645e-01, time/batch = 31.0858s	
20886/29850 (epoch 34.985), train_loss = 0.86620840, grad/param norm = 2.1543e-01, time/batch = 17.6390s	
20887/29850 (epoch 34.987), train_loss = 0.83804488, grad/param norm = 2.3500e-01, time/batch = 16.2226s	
20888/29850 (epoch 34.988), train_loss = 0.78089382, grad/param norm = 1.9547e-01, time/batch = 18.3493s	
20889/29850 (epoch 34.990), train_loss = 0.83989224, grad/param norm = 1.8979e-01, time/batch = 18.6934s	
20890/29850 (epoch 34.992), train_loss = 0.86707745, grad/param norm = 2.0247e-01, time/batch = 18.5459s	
20891/29850 (epoch 34.993), train_loss = 0.83797176, grad/param norm = 2.1612e-01, time/batch = 16.2113s	
20892/29850 (epoch 34.995), train_loss = 0.83522849, grad/param norm = 2.4684e-01, time/batch = 18.7116s	
20893/29850 (epoch 34.997), train_loss = 0.85766193, grad/param norm = 2.2511e-01, time/batch = 19.1869s	
20894/29850 (epoch 34.998), train_loss = 0.88142317, grad/param norm = 2.2058e-01, time/batch = 15.7093s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
20895/29850 (epoch 35.000), train_loss = 0.71678321, grad/param norm = 1.8939e-01, time/batch = 18.2060s	
20896/29850 (epoch 35.002), train_loss = 0.95234649, grad/param norm = 2.3104e-01, time/batch = 19.5395s	
20897/29850 (epoch 35.003), train_loss = 0.71309455, grad/param norm = 2.2967e-01, time/batch = 17.1277s	
20898/29850 (epoch 35.005), train_loss = 0.88660630, grad/param norm = 2.1619e-01, time/batch = 17.6398s	
20899/29850 (epoch 35.007), train_loss = 0.92041366, grad/param norm = 2.4442e-01, time/batch = 17.4885s	
20900/29850 (epoch 35.008), train_loss = 1.05237136, grad/param norm = 2.7496e-01, time/batch = 19.0483s	
20901/29850 (epoch 35.010), train_loss = 0.76498825, grad/param norm = 2.0901e-01, time/batch = 16.0775s	
20902/29850 (epoch 35.012), train_loss = 0.80400833, grad/param norm = 2.1418e-01, time/batch = 18.2988s	
20903/29850 (epoch 35.013), train_loss = 0.88140859, grad/param norm = 2.5514e-01, time/batch = 17.8046s	
20904/29850 (epoch 35.015), train_loss = 0.91418986, grad/param norm = 2.2416e-01, time/batch = 16.3991s	
20905/29850 (epoch 35.017), train_loss = 0.87873295, grad/param norm = 2.3081e-01, time/batch = 18.0556s	
20906/29850 (epoch 35.018), train_loss = 0.97868213, grad/param norm = 2.3578e-01, time/batch = 16.5681s	
20907/29850 (epoch 35.020), train_loss = 0.84303357, grad/param norm = 1.9596e-01, time/batch = 18.2986s	
20908/29850 (epoch 35.022), train_loss = 0.91718228, grad/param norm = 2.4218e-01, time/batch = 17.2933s	
20909/29850 (epoch 35.023), train_loss = 0.92131823, grad/param norm = 2.1606e-01, time/batch = 18.9658s	
20910/29850 (epoch 35.025), train_loss = 0.82439392, grad/param norm = 1.9063e-01, time/batch = 19.2100s	
20911/29850 (epoch 35.027), train_loss = 0.65639777, grad/param norm = 1.9923e-01, time/batch = 17.9486s	
20912/29850 (epoch 35.028), train_loss = 0.76051630, grad/param norm = 1.8520e-01, time/batch = 17.6780s	
20913/29850 (epoch 35.030), train_loss = 0.80633641, grad/param norm = 2.0895e-01, time/batch = 19.2183s	
20914/29850 (epoch 35.032), train_loss = 0.90464320, grad/param norm = 2.2783e-01, time/batch = 17.7018s	
20915/29850 (epoch 35.034), train_loss = 0.76723350, grad/param norm = 2.1170e-01, time/batch = 18.7820s	
20916/29850 (epoch 35.035), train_loss = 0.66830899, grad/param norm = 1.8335e-01, time/batch = 19.4546s	
20917/29850 (epoch 35.037), train_loss = 0.84403586, grad/param norm = 2.0314e-01, time/batch = 16.6948s	
20918/29850 (epoch 35.039), train_loss = 0.74890793, grad/param norm = 1.7537e-01, time/batch = 17.6181s	
20919/29850 (epoch 35.040), train_loss = 0.73853822, grad/param norm = 2.2879e-01, time/batch = 16.3832s	
20920/29850 (epoch 35.042), train_loss = 0.75890314, grad/param norm = 2.1645e-01, time/batch = 15.1895s	
20921/29850 (epoch 35.044), train_loss = 0.81400484, grad/param norm = 2.0902e-01, time/batch = 17.8709s	
20922/29850 (epoch 35.045), train_loss = 0.90410023, grad/param norm = 2.1134e-01, time/batch = 18.3163s	
20923/29850 (epoch 35.047), train_loss = 0.73399232, grad/param norm = 1.9261e-01, time/batch = 17.8791s	
20924/29850 (epoch 35.049), train_loss = 0.87311769, grad/param norm = 2.1789e-01, time/batch = 16.7143s	
20925/29850 (epoch 35.050), train_loss = 0.75427215, grad/param norm = 2.0736e-01, time/batch = 16.4664s	
20926/29850 (epoch 35.052), train_loss = 0.93809848, grad/param norm = 2.1885e-01, time/batch = 17.0583s	
20927/29850 (epoch 35.054), train_loss = 0.82431329, grad/param norm = 2.0801e-01, time/batch = 18.2038s	
20928/29850 (epoch 35.055), train_loss = 0.78705946, grad/param norm = 1.9458e-01, time/batch = 17.2847s	
20929/29850 (epoch 35.057), train_loss = 0.88374176, grad/param norm = 2.0336e-01, time/batch = 17.3826s	
20930/29850 (epoch 35.059), train_loss = 0.86910525, grad/param norm = 2.0889e-01, time/batch = 19.2096s	
20931/29850 (epoch 35.060), train_loss = 0.84980876, grad/param norm = 2.2371e-01, time/batch = 17.6948s	
20932/29850 (epoch 35.062), train_loss = 0.92851077, grad/param norm = 2.7454e-01, time/batch = 17.7117s	
20933/29850 (epoch 35.064), train_loss = 0.92124950, grad/param norm = 2.4266e-01, time/batch = 18.6351s	
20934/29850 (epoch 35.065), train_loss = 0.71870039, grad/param norm = 2.1553e-01, time/batch = 16.7850s	
20935/29850 (epoch 35.067), train_loss = 0.86966626, grad/param norm = 1.9618e-01, time/batch = 16.5463s	
20936/29850 (epoch 35.069), train_loss = 0.89366822, grad/param norm = 2.0985e-01, time/batch = 17.8868s	
20937/29850 (epoch 35.070), train_loss = 0.89335696, grad/param norm = 2.1073e-01, time/batch = 17.2083s	
20938/29850 (epoch 35.072), train_loss = 0.85029388, grad/param norm = 2.6904e-01, time/batch = 15.0422s	
20939/29850 (epoch 35.074), train_loss = 0.92566276, grad/param norm = 2.0707e-01, time/batch = 18.7915s	
20940/29850 (epoch 35.075), train_loss = 0.77517150, grad/param norm = 2.1776e-01, time/batch = 19.4487s	
20941/29850 (epoch 35.077), train_loss = 0.89868308, grad/param norm = 2.2420e-01, time/batch = 16.6379s	
20942/29850 (epoch 35.079), train_loss = 1.04741800, grad/param norm = 3.2300e-01, time/batch = 15.9405s	
20943/29850 (epoch 35.080), train_loss = 1.02047959, grad/param norm = 2.7896e-01, time/batch = 18.1825s	
20944/29850 (epoch 35.082), train_loss = 0.91086754, grad/param norm = 2.2321e-01, time/batch = 19.3559s	
20945/29850 (epoch 35.084), train_loss = 0.99741893, grad/param norm = 2.4920e-01, time/batch = 17.2002s	
20946/29850 (epoch 35.085), train_loss = 1.03639026, grad/param norm = 2.6492e-01, time/batch = 18.4177s	
20947/29850 (epoch 35.087), train_loss = 0.97844177, grad/param norm = 2.7596e-01, time/batch = 19.6257s	
20948/29850 (epoch 35.089), train_loss = 0.89403182, grad/param norm = 2.0826e-01, time/batch = 16.5124s	
20949/29850 (epoch 35.090), train_loss = 0.92022823, grad/param norm = 2.1537e-01, time/batch = 17.3847s	
20950/29850 (epoch 35.092), train_loss = 0.79376802, grad/param norm = 2.2027e-01, time/batch = 18.8672s	
20951/29850 (epoch 35.094), train_loss = 0.98776202, grad/param norm = 2.2451e-01, time/batch = 17.0943s	
20952/29850 (epoch 35.095), train_loss = 0.91357414, grad/param norm = 2.4340e-01, time/batch = 17.9664s	
20953/29850 (epoch 35.097), train_loss = 0.66602825, grad/param norm = 1.6725e-01, time/batch = 16.5464s	
20954/29850 (epoch 35.099), train_loss = 0.70996895, grad/param norm = 1.9000e-01, time/batch = 17.8113s	
20955/29850 (epoch 35.101), train_loss = 0.92720536, grad/param norm = 2.3110e-01, time/batch = 15.7105s	
20956/29850 (epoch 35.102), train_loss = 0.91460622, grad/param norm = 2.3290e-01, time/batch = 19.5438s	
20957/29850 (epoch 35.104), train_loss = 0.82847985, grad/param norm = 2.3800e-01, time/batch = 19.6127s	
20958/29850 (epoch 35.106), train_loss = 0.93977576, grad/param norm = 2.1556e-01, time/batch = 17.2078s	
20959/29850 (epoch 35.107), train_loss = 0.79512338, grad/param norm = 2.0296e-01, time/batch = 17.5402s	
20960/29850 (epoch 35.109), train_loss = 0.87772710, grad/param norm = 2.1974e-01, time/batch = 16.6109s	
20961/29850 (epoch 35.111), train_loss = 0.91625935, grad/param norm = 2.2759e-01, time/batch = 16.8670s	
20962/29850 (epoch 35.112), train_loss = 0.76309364, grad/param norm = 1.8946e-01, time/batch = 19.7083s	
20963/29850 (epoch 35.114), train_loss = 0.81172155, grad/param norm = 2.1902e-01, time/batch = 17.6251s	
20964/29850 (epoch 35.116), train_loss = 0.78760071, grad/param norm = 2.2685e-01, time/batch = 17.6333s	
20965/29850 (epoch 35.117), train_loss = 0.84037453, grad/param norm = 2.3301e-01, time/batch = 18.5260s	
20966/29850 (epoch 35.119), train_loss = 0.81274979, grad/param norm = 2.0470e-01, time/batch = 19.0488s	
20967/29850 (epoch 35.121), train_loss = 0.66652922, grad/param norm = 1.8054e-01, time/batch = 17.2266s	
20968/29850 (epoch 35.122), train_loss = 0.71593404, grad/param norm = 1.6557e-01, time/batch = 16.7915s	
20969/29850 (epoch 35.124), train_loss = 0.75843311, grad/param norm = 1.9755e-01, time/batch = 19.1345s	
20970/29850 (epoch 35.126), train_loss = 0.80437967, grad/param norm = 2.2813e-01, time/batch = 16.7979s	
20971/29850 (epoch 35.127), train_loss = 0.89335666, grad/param norm = 2.6064e-01, time/batch = 17.8727s	
20972/29850 (epoch 35.129), train_loss = 0.82141810, grad/param norm = 2.0288e-01, time/batch = 15.0102s	
20973/29850 (epoch 35.131), train_loss = 0.84852709, grad/param norm = 1.9606e-01, time/batch = 17.6105s	
20974/29850 (epoch 35.132), train_loss = 0.71645358, grad/param norm = 2.1046e-01, time/batch = 18.3276s	
20975/29850 (epoch 35.134), train_loss = 0.81563008, grad/param norm = 2.2054e-01, time/batch = 16.2090s	
20976/29850 (epoch 35.136), train_loss = 0.91515697, grad/param norm = 2.2655e-01, time/batch = 16.0968s	
20977/29850 (epoch 35.137), train_loss = 0.69644492, grad/param norm = 1.8693e-01, time/batch = 19.1962s	
20978/29850 (epoch 35.139), train_loss = 0.82166332, grad/param norm = 1.9235e-01, time/batch = 17.8739s	
20979/29850 (epoch 35.141), train_loss = 0.76365788, grad/param norm = 2.1513e-01, time/batch = 19.5249s	
20980/29850 (epoch 35.142), train_loss = 0.97662281, grad/param norm = 2.3753e-01, time/batch = 18.4586s	
20981/29850 (epoch 35.144), train_loss = 1.06653995, grad/param norm = 2.6986e-01, time/batch = 18.3692s	
20982/29850 (epoch 35.146), train_loss = 1.07435157, grad/param norm = 2.2167e-01, time/batch = 17.8681s	
20983/29850 (epoch 35.147), train_loss = 0.95872484, grad/param norm = 2.6147e-01, time/batch = 19.9292s	
20984/29850 (epoch 35.149), train_loss = 0.89850320, grad/param norm = 2.3764e-01, time/batch = 19.0529s	
20985/29850 (epoch 35.151), train_loss = 0.89358046, grad/param norm = 2.1100e-01, time/batch = 15.6819s	
20986/29850 (epoch 35.152), train_loss = 0.85202060, grad/param norm = 2.3144e-01, time/batch = 18.7152s	
20987/29850 (epoch 35.154), train_loss = 0.78337509, grad/param norm = 2.2237e-01, time/batch = 18.2875s	
20988/29850 (epoch 35.156), train_loss = 0.79104217, grad/param norm = 2.1765e-01, time/batch = 15.5286s	
20989/29850 (epoch 35.157), train_loss = 0.91179309, grad/param norm = 2.3469e-01, time/batch = 18.1210s	
20990/29850 (epoch 35.159), train_loss = 0.82645343, grad/param norm = 2.4429e-01, time/batch = 15.4421s	
20991/29850 (epoch 35.161), train_loss = 0.85617309, grad/param norm = 2.2643e-01, time/batch = 16.8148s	
20992/29850 (epoch 35.162), train_loss = 0.96801287, grad/param norm = 2.3100e-01, time/batch = 17.1108s	
20993/29850 (epoch 35.164), train_loss = 0.89181086, grad/param norm = 2.2428e-01, time/batch = 17.3026s	
20994/29850 (epoch 35.166), train_loss = 0.80853668, grad/param norm = 2.0253e-01, time/batch = 18.8746s	
20995/29850 (epoch 35.168), train_loss = 0.72203227, grad/param norm = 1.7678e-01, time/batch = 16.8815s	
20996/29850 (epoch 35.169), train_loss = 0.97772883, grad/param norm = 2.5743e-01, time/batch = 17.3044s	
20997/29850 (epoch 35.171), train_loss = 0.91471585, grad/param norm = 2.2011e-01, time/batch = 17.9604s	
20998/29850 (epoch 35.173), train_loss = 0.77661415, grad/param norm = 2.4152e-01, time/batch = 17.6754s	
20999/29850 (epoch 35.174), train_loss = 0.87114722, grad/param norm = 2.4030e-01, time/batch = 16.7845s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch35.18_1.8298.t7	
21000/29850 (epoch 35.176), train_loss = 0.86090002, grad/param norm = 2.0729e-01, time/batch = 19.2950s	
21001/29850 (epoch 35.178), train_loss = 1.43623193, grad/param norm = 3.1803e-01, time/batch = 16.7782s	
21002/29850 (epoch 35.179), train_loss = 0.72290678, grad/param norm = 2.2596e-01, time/batch = 16.1334s	
21003/29850 (epoch 35.181), train_loss = 0.87568068, grad/param norm = 2.4372e-01, time/batch = 16.5291s	
21004/29850 (epoch 35.183), train_loss = 0.88073994, grad/param norm = 2.1890e-01, time/batch = 15.7152s	
21005/29850 (epoch 35.184), train_loss = 0.92032229, grad/param norm = 2.2295e-01, time/batch = 16.2205s	
21006/29850 (epoch 35.186), train_loss = 0.89337322, grad/param norm = 2.8489e-01, time/batch = 20.8698s	
21007/29850 (epoch 35.188), train_loss = 0.99103512, grad/param norm = 2.3258e-01, time/batch = 18.2751s	
21008/29850 (epoch 35.189), train_loss = 0.94219779, grad/param norm = 2.4412e-01, time/batch = 18.5398s	
21009/29850 (epoch 35.191), train_loss = 0.96794480, grad/param norm = 2.4696e-01, time/batch = 16.3874s	
21010/29850 (epoch 35.193), train_loss = 0.83994217, grad/param norm = 1.9757e-01, time/batch = 18.3701s	
21011/29850 (epoch 35.194), train_loss = 0.94232863, grad/param norm = 2.3003e-01, time/batch = 18.8611s	
21012/29850 (epoch 35.196), train_loss = 0.84094826, grad/param norm = 2.5226e-01, time/batch = 17.7918s	
21013/29850 (epoch 35.198), train_loss = 0.81363204, grad/param norm = 1.9613e-01, time/batch = 18.6244s	
21014/29850 (epoch 35.199), train_loss = 1.07073507, grad/param norm = 2.5197e-01, time/batch = 17.6305s	
21015/29850 (epoch 35.201), train_loss = 0.78182457, grad/param norm = 1.9494e-01, time/batch = 16.5550s	
21016/29850 (epoch 35.203), train_loss = 0.65568334, grad/param norm = 2.3225e-01, time/batch = 19.6261s	
21017/29850 (epoch 35.204), train_loss = 0.85121362, grad/param norm = 2.4035e-01, time/batch = 17.3925s	
21018/29850 (epoch 35.206), train_loss = 0.75549580, grad/param norm = 2.1812e-01, time/batch = 17.1093s	
21019/29850 (epoch 35.208), train_loss = 0.99114007, grad/param norm = 2.5499e-01, time/batch = 15.9694s	
21020/29850 (epoch 35.209), train_loss = 0.74968991, grad/param norm = 2.1698e-01, time/batch = 16.2048s	
21021/29850 (epoch 35.211), train_loss = 0.81346354, grad/param norm = 2.0375e-01, time/batch = 18.6228s	
21022/29850 (epoch 35.213), train_loss = 0.91187890, grad/param norm = 2.3607e-01, time/batch = 17.0940s	
21023/29850 (epoch 35.214), train_loss = 0.74710259, grad/param norm = 1.7590e-01, time/batch = 19.1261s	
21024/29850 (epoch 35.216), train_loss = 0.76992215, grad/param norm = 2.0327e-01, time/batch = 19.2709s	
21025/29850 (epoch 35.218), train_loss = 0.87244908, grad/param norm = 2.0981e-01, time/batch = 17.1897s	
21026/29850 (epoch 35.219), train_loss = 0.91157846, grad/param norm = 2.6945e-01, time/batch = 18.3495s	
21027/29850 (epoch 35.221), train_loss = 0.85221673, grad/param norm = 2.3890e-01, time/batch = 18.4676s	
21028/29850 (epoch 35.223), train_loss = 0.73320789, grad/param norm = 2.2103e-01, time/batch = 17.1984s	
21029/29850 (epoch 35.224), train_loss = 0.71302747, grad/param norm = 1.8475e-01, time/batch = 17.2134s	
21030/29850 (epoch 35.226), train_loss = 0.76886651, grad/param norm = 1.7373e-01, time/batch = 16.3990s	
21031/29850 (epoch 35.228), train_loss = 0.81460970, grad/param norm = 2.0602e-01, time/batch = 17.6426s	
21032/29850 (epoch 35.229), train_loss = 0.69014352, grad/param norm = 1.9317e-01, time/batch = 16.4621s	
21033/29850 (epoch 35.231), train_loss = 0.84271404, grad/param norm = 2.1371e-01, time/batch = 18.5324s	
21034/29850 (epoch 35.233), train_loss = 0.81611878, grad/param norm = 2.0508e-01, time/batch = 18.2966s	
21035/29850 (epoch 35.235), train_loss = 0.77684008, grad/param norm = 2.1218e-01, time/batch = 17.7856s	
21036/29850 (epoch 35.236), train_loss = 0.98551645, grad/param norm = 2.6106e-01, time/batch = 16.5248s	
21037/29850 (epoch 35.238), train_loss = 0.72120134, grad/param norm = 2.1605e-01, time/batch = 18.8008s	
21038/29850 (epoch 35.240), train_loss = 0.71810052, grad/param norm = 1.8493e-01, time/batch = 15.4455s	
21039/29850 (epoch 35.241), train_loss = 0.89554273, grad/param norm = 2.4102e-01, time/batch = 17.8662s	
21040/29850 (epoch 35.243), train_loss = 0.90191128, grad/param norm = 2.6340e-01, time/batch = 16.8643s	
21041/29850 (epoch 35.245), train_loss = 0.76913891, grad/param norm = 2.1648e-01, time/batch = 16.2027s	
21042/29850 (epoch 35.246), train_loss = 0.72707910, grad/param norm = 1.7516e-01, time/batch = 16.7832s	
21043/29850 (epoch 35.248), train_loss = 0.70656936, grad/param norm = 1.8960e-01, time/batch = 17.2982s	
21044/29850 (epoch 35.250), train_loss = 0.79298861, grad/param norm = 1.9634e-01, time/batch = 20.6041s	
21045/29850 (epoch 35.251), train_loss = 0.71951214, grad/param norm = 2.1185e-01, time/batch = 17.6884s	
21046/29850 (epoch 35.253), train_loss = 0.66981048, grad/param norm = 1.9470e-01, time/batch = 16.7872s	
21047/29850 (epoch 35.255), train_loss = 0.74759751, grad/param norm = 2.1328e-01, time/batch = 15.3217s	
21048/29850 (epoch 35.256), train_loss = 0.87294920, grad/param norm = 2.1005e-01, time/batch = 17.6379s	
21049/29850 (epoch 35.258), train_loss = 0.87570808, grad/param norm = 2.2573e-01, time/batch = 16.9521s	
21050/29850 (epoch 35.260), train_loss = 0.82003411, grad/param norm = 1.9715e-01, time/batch = 19.5456s	
21051/29850 (epoch 35.261), train_loss = 0.76084819, grad/param norm = 2.1664e-01, time/batch = 18.7829s	
21052/29850 (epoch 35.263), train_loss = 0.76170529, grad/param norm = 1.9339e-01, time/batch = 16.9577s	
21053/29850 (epoch 35.265), train_loss = 0.82726966, grad/param norm = 2.4328e-01, time/batch = 16.2897s	
21054/29850 (epoch 35.266), train_loss = 0.83424926, grad/param norm = 2.4608e-01, time/batch = 18.2801s	
21055/29850 (epoch 35.268), train_loss = 0.79449069, grad/param norm = 1.8804e-01, time/batch = 18.7054s	
21056/29850 (epoch 35.270), train_loss = 0.77408985, grad/param norm = 2.6130e-01, time/batch = 18.9607s	
21057/29850 (epoch 35.271), train_loss = 0.88579130, grad/param norm = 2.3959e-01, time/batch = 18.6389s	
21058/29850 (epoch 35.273), train_loss = 0.73020337, grad/param norm = 2.3228e-01, time/batch = 19.0337s	
21059/29850 (epoch 35.275), train_loss = 0.72504428, grad/param norm = 2.0748e-01, time/batch = 17.7653s	
21060/29850 (epoch 35.276), train_loss = 0.71850783, grad/param norm = 1.9608e-01, time/batch = 18.5398s	
21061/29850 (epoch 35.278), train_loss = 0.78267916, grad/param norm = 1.9530e-01, time/batch = 16.2067s	
21062/29850 (epoch 35.280), train_loss = 1.00337421, grad/param norm = 3.0776e-01, time/batch = 17.5967s	
21063/29850 (epoch 35.281), train_loss = 0.85551225, grad/param norm = 2.4843e-01, time/batch = 19.7813s	
21064/29850 (epoch 35.283), train_loss = 0.98066240, grad/param norm = 3.8289e-01, time/batch = 17.3885s	
21065/29850 (epoch 35.285), train_loss = 0.90568625, grad/param norm = 2.0204e-01, time/batch = 17.4646s	
21066/29850 (epoch 35.286), train_loss = 0.95893543, grad/param norm = 2.6780e-01, time/batch = 18.7909s	
21067/29850 (epoch 35.288), train_loss = 0.95473897, grad/param norm = 3.0356e-01, time/batch = 18.4483s	
21068/29850 (epoch 35.290), train_loss = 0.87246715, grad/param norm = 2.4993e-01, time/batch = 18.9529s	
21069/29850 (epoch 35.291), train_loss = 1.06694971, grad/param norm = 2.6039e-01, time/batch = 16.1107s	
21070/29850 (epoch 35.293), train_loss = 0.98040572, grad/param norm = 2.7051e-01, time/batch = 19.3684s	
21071/29850 (epoch 35.295), train_loss = 1.01281511, grad/param norm = 2.2910e-01, time/batch = 19.7143s	
21072/29850 (epoch 35.296), train_loss = 0.77424220, grad/param norm = 1.9311e-01, time/batch = 16.6230s	
21073/29850 (epoch 35.298), train_loss = 0.65231037, grad/param norm = 2.4015e-01, time/batch = 17.6503s	
21074/29850 (epoch 35.300), train_loss = 0.74635185, grad/param norm = 2.0646e-01, time/batch = 17.3029s	
21075/29850 (epoch 35.302), train_loss = 0.73271319, grad/param norm = 2.0738e-01, time/batch = 16.8399s	
21076/29850 (epoch 35.303), train_loss = 0.79078191, grad/param norm = 2.1011e-01, time/batch = 19.4401s	
21077/29850 (epoch 35.305), train_loss = 0.91044889, grad/param norm = 2.2009e-01, time/batch = 14.5835s	
21078/29850 (epoch 35.307), train_loss = 0.93691374, grad/param norm = 2.4749e-01, time/batch = 15.5495s	
21079/29850 (epoch 35.308), train_loss = 0.74161380, grad/param norm = 2.0824e-01, time/batch = 33.5483s	
21080/29850 (epoch 35.310), train_loss = 0.88747532, grad/param norm = 2.5418e-01, time/batch = 27.0035s	
21081/29850 (epoch 35.312), train_loss = 0.90684004, grad/param norm = 2.0867e-01, time/batch = 17.6195s	
21082/29850 (epoch 35.313), train_loss = 0.86627710, grad/param norm = 2.5701e-01, time/batch = 19.7153s	
21083/29850 (epoch 35.315), train_loss = 0.86263823, grad/param norm = 2.0580e-01, time/batch = 16.4806s	
21084/29850 (epoch 35.317), train_loss = 0.86038052, grad/param norm = 2.3272e-01, time/batch = 17.2043s	
21085/29850 (epoch 35.318), train_loss = 0.85090560, grad/param norm = 2.1720e-01, time/batch = 15.9614s	
21086/29850 (epoch 35.320), train_loss = 0.78599163, grad/param norm = 2.2553e-01, time/batch = 19.3726s	
21087/29850 (epoch 35.322), train_loss = 0.99257554, grad/param norm = 2.7091e-01, time/batch = 19.7641s	
21088/29850 (epoch 35.323), train_loss = 0.89059422, grad/param norm = 2.3119e-01, time/batch = 19.1193s	
21089/29850 (epoch 35.325), train_loss = 0.96224207, grad/param norm = 2.2104e-01, time/batch = 16.0510s	
21090/29850 (epoch 35.327), train_loss = 1.04887431, grad/param norm = 2.4068e-01, time/batch = 18.6826s	
21091/29850 (epoch 35.328), train_loss = 0.97795366, grad/param norm = 3.6710e-01, time/batch = 15.5174s	
21092/29850 (epoch 35.330), train_loss = 0.92656593, grad/param norm = 2.1827e-01, time/batch = 18.6223s	
21093/29850 (epoch 35.332), train_loss = 0.82862164, grad/param norm = 2.2167e-01, time/batch = 17.7813s	
21094/29850 (epoch 35.333), train_loss = 0.89903808, grad/param norm = 2.1781e-01, time/batch = 17.8551s	
21095/29850 (epoch 35.335), train_loss = 0.96674619, grad/param norm = 2.2413e-01, time/batch = 16.8971s	
21096/29850 (epoch 35.337), train_loss = 0.87356685, grad/param norm = 2.3181e-01, time/batch = 16.2293s	
21097/29850 (epoch 35.338), train_loss = 0.90428023, grad/param norm = 2.0823e-01, time/batch = 18.5453s	
21098/29850 (epoch 35.340), train_loss = 0.75916192, grad/param norm = 1.9829e-01, time/batch = 15.3661s	
21099/29850 (epoch 35.342), train_loss = 0.87396765, grad/param norm = 2.2335e-01, time/batch = 18.4732s	
21100/29850 (epoch 35.343), train_loss = 0.86607589, grad/param norm = 2.4522e-01, time/batch = 18.4651s	
21101/29850 (epoch 35.345), train_loss = 0.94612093, grad/param norm = 2.5240e-01, time/batch = 15.5888s	
21102/29850 (epoch 35.347), train_loss = 0.96353801, grad/param norm = 2.7590e-01, time/batch = 15.8751s	
21103/29850 (epoch 35.348), train_loss = 0.81204590, grad/param norm = 2.1279e-01, time/batch = 19.1334s	
21104/29850 (epoch 35.350), train_loss = 0.94000707, grad/param norm = 2.5837e-01, time/batch = 18.4667s	
21105/29850 (epoch 35.352), train_loss = 0.81189700, grad/param norm = 1.9712e-01, time/batch = 17.9318s	
21106/29850 (epoch 35.353), train_loss = 0.91669959, grad/param norm = 2.4160e-01, time/batch = 19.9477s	
21107/29850 (epoch 35.355), train_loss = 0.81825849, grad/param norm = 2.1905e-01, time/batch = 17.1440s	
21108/29850 (epoch 35.357), train_loss = 0.92331142, grad/param norm = 2.1124e-01, time/batch = 17.3756s	
21109/29850 (epoch 35.358), train_loss = 0.79879121, grad/param norm = 2.1802e-01, time/batch = 18.3707s	
21110/29850 (epoch 35.360), train_loss = 0.85254952, grad/param norm = 2.5632e-01, time/batch = 19.2211s	
21111/29850 (epoch 35.362), train_loss = 0.85309448, grad/param norm = 2.1596e-01, time/batch = 17.1943s	
21112/29850 (epoch 35.363), train_loss = 0.90793827, grad/param norm = 2.3331e-01, time/batch = 16.1037s	
21113/29850 (epoch 35.365), train_loss = 0.97079908, grad/param norm = 2.4975e-01, time/batch = 18.7056s	
21114/29850 (epoch 35.367), train_loss = 0.79104180, grad/param norm = 2.0669e-01, time/batch = 16.2134s	
21115/29850 (epoch 35.369), train_loss = 0.72437510, grad/param norm = 2.0612e-01, time/batch = 19.4180s	
21116/29850 (epoch 35.370), train_loss = 0.71180662, grad/param norm = 2.1847e-01, time/batch = 18.5348s	
21117/29850 (epoch 35.372), train_loss = 0.95042351, grad/param norm = 2.4072e-01, time/batch = 19.9517s	
21118/29850 (epoch 35.374), train_loss = 0.92848347, grad/param norm = 2.2246e-01, time/batch = 17.1961s	
21119/29850 (epoch 35.375), train_loss = 0.85204367, grad/param norm = 2.0841e-01, time/batch = 18.9261s	
21120/29850 (epoch 35.377), train_loss = 0.77520113, grad/param norm = 2.2856e-01, time/batch = 18.7958s	
21121/29850 (epoch 35.379), train_loss = 0.98455188, grad/param norm = 2.5299e-01, time/batch = 16.1297s	
21122/29850 (epoch 35.380), train_loss = 0.90913661, grad/param norm = 2.2351e-01, time/batch = 17.1308s	
21123/29850 (epoch 35.382), train_loss = 0.88830222, grad/param norm = 2.2727e-01, time/batch = 16.1974s	
21124/29850 (epoch 35.384), train_loss = 0.93508985, grad/param norm = 2.2078e-01, time/batch = 18.9467s	
21125/29850 (epoch 35.385), train_loss = 0.90788605, grad/param norm = 2.5012e-01, time/batch = 18.0365s	
21126/29850 (epoch 35.387), train_loss = 0.89615997, grad/param norm = 2.1887e-01, time/batch = 18.2025s	
21127/29850 (epoch 35.389), train_loss = 1.00491406, grad/param norm = 2.6462e-01, time/batch = 20.0140s	
21128/29850 (epoch 35.390), train_loss = 0.93474577, grad/param norm = 2.1810e-01, time/batch = 16.3710s	
21129/29850 (epoch 35.392), train_loss = 0.84229119, grad/param norm = 2.4186e-01, time/batch = 17.3071s	
21130/29850 (epoch 35.394), train_loss = 0.96390001, grad/param norm = 2.1734e-01, time/batch = 18.2959s	
21131/29850 (epoch 35.395), train_loss = 0.80360660, grad/param norm = 2.0449e-01, time/batch = 17.4665s	
21132/29850 (epoch 35.397), train_loss = 0.77236513, grad/param norm = 2.5247e-01, time/batch = 18.2979s	
21133/29850 (epoch 35.399), train_loss = 0.79323028, grad/param norm = 2.3113e-01, time/batch = 15.5942s	
21134/29850 (epoch 35.400), train_loss = 1.13584314, grad/param norm = 2.4048e-01, time/batch = 18.7802s	
21135/29850 (epoch 35.402), train_loss = 1.01758628, grad/param norm = 2.1532e-01, time/batch = 16.7004s	
21136/29850 (epoch 35.404), train_loss = 0.89016998, grad/param norm = 2.2283e-01, time/batch = 18.6085s	
21137/29850 (epoch 35.405), train_loss = 0.80946733, grad/param norm = 2.3876e-01, time/batch = 16.4571s	
21138/29850 (epoch 35.407), train_loss = 0.79873030, grad/param norm = 2.1566e-01, time/batch = 17.8685s	
21139/29850 (epoch 35.409), train_loss = 0.88526080, grad/param norm = 2.1264e-01, time/batch = 17.9608s	
21140/29850 (epoch 35.410), train_loss = 0.98749368, grad/param norm = 2.3699e-01, time/batch = 15.7931s	
21141/29850 (epoch 35.412), train_loss = 0.97972619, grad/param norm = 2.2778e-01, time/batch = 17.5367s	
21142/29850 (epoch 35.414), train_loss = 0.88168968, grad/param norm = 2.4222e-01, time/batch = 16.9548s	
21143/29850 (epoch 35.415), train_loss = 0.86671932, grad/param norm = 1.9889e-01, time/batch = 19.4558s	
21144/29850 (epoch 35.417), train_loss = 1.03246380, grad/param norm = 2.5519e-01, time/batch = 18.1229s	
21145/29850 (epoch 35.419), train_loss = 0.84601399, grad/param norm = 2.2473e-01, time/batch = 16.8553s	
21146/29850 (epoch 35.420), train_loss = 0.86275681, grad/param norm = 2.2347e-01, time/batch = 19.9658s	
21147/29850 (epoch 35.422), train_loss = 0.87553644, grad/param norm = 3.1807e-01, time/batch = 18.1357s	
21148/29850 (epoch 35.424), train_loss = 0.78178340, grad/param norm = 2.0648e-01, time/batch = 15.6728s	
21149/29850 (epoch 35.425), train_loss = 0.93282681, grad/param norm = 2.3923e-01, time/batch = 14.7509s	
21150/29850 (epoch 35.427), train_loss = 0.68009819, grad/param norm = 2.0820e-01, time/batch = 17.9680s	
21151/29850 (epoch 35.429), train_loss = 0.78272526, grad/param norm = 2.5279e-01, time/batch = 18.4651s	
21152/29850 (epoch 35.430), train_loss = 0.72468992, grad/param norm = 1.8351e-01, time/batch = 17.6891s	
21153/29850 (epoch 35.432), train_loss = 0.80329205, grad/param norm = 2.3219e-01, time/batch = 19.4500s	
21154/29850 (epoch 35.434), train_loss = 0.77127531, grad/param norm = 2.0461e-01, time/batch = 18.2921s	
21155/29850 (epoch 35.436), train_loss = 0.85024921, grad/param norm = 2.3221e-01, time/batch = 17.0558s	
21156/29850 (epoch 35.437), train_loss = 0.92116023, grad/param norm = 2.1282e-01, time/batch = 18.6334s	
21157/29850 (epoch 35.439), train_loss = 0.90969960, grad/param norm = 2.0045e-01, time/batch = 16.1948s	
21158/29850 (epoch 35.441), train_loss = 0.88526014, grad/param norm = 2.3693e-01, time/batch = 17.0412s	
21159/29850 (epoch 35.442), train_loss = 0.84098944, grad/param norm = 2.1067e-01, time/batch = 18.7848s	
21160/29850 (epoch 35.444), train_loss = 0.88660821, grad/param norm = 2.5559e-01, time/batch = 19.3765s	
21161/29850 (epoch 35.446), train_loss = 0.93505942, grad/param norm = 2.4560e-01, time/batch = 18.6093s	
21162/29850 (epoch 35.447), train_loss = 0.94198303, grad/param norm = 2.4288e-01, time/batch = 17.2017s	
21163/29850 (epoch 35.449), train_loss = 0.85660664, grad/param norm = 2.1541e-01, time/batch = 16.9618s	
21164/29850 (epoch 35.451), train_loss = 0.67949408, grad/param norm = 1.9379e-01, time/batch = 19.1969s	
21165/29850 (epoch 35.452), train_loss = 0.60291205, grad/param norm = 1.9204e-01, time/batch = 17.9455s	
21166/29850 (epoch 35.454), train_loss = 0.72619756, grad/param norm = 1.8754e-01, time/batch = 15.6445s	
21167/29850 (epoch 35.456), train_loss = 0.91872924, grad/param norm = 2.5221e-01, time/batch = 17.0524s	
21168/29850 (epoch 35.457), train_loss = 0.93515932, grad/param norm = 4.0508e-01, time/batch = 18.2060s	
21169/29850 (epoch 35.459), train_loss = 1.02004637, grad/param norm = 2.7338e-01, time/batch = 15.2927s	
21170/29850 (epoch 35.461), train_loss = 0.99812009, grad/param norm = 2.3272e-01, time/batch = 18.2802s	
21171/29850 (epoch 35.462), train_loss = 1.01588931, grad/param norm = 2.3624e-01, time/batch = 19.6292s	
21172/29850 (epoch 35.464), train_loss = 0.90399626, grad/param norm = 2.2503e-01, time/batch = 17.1897s	
21173/29850 (epoch 35.466), train_loss = 0.74688168, grad/param norm = 1.9394e-01, time/batch = 17.9802s	
21174/29850 (epoch 35.467), train_loss = 0.80854466, grad/param norm = 2.4104e-01, time/batch = 19.2943s	
21175/29850 (epoch 35.469), train_loss = 0.83555136, grad/param norm = 2.0522e-01, time/batch = 15.8663s	
21176/29850 (epoch 35.471), train_loss = 0.83225588, grad/param norm = 2.5800e-01, time/batch = 18.6188s	
21177/29850 (epoch 35.472), train_loss = 0.78856193, grad/param norm = 1.9787e-01, time/batch = 18.4646s	
21178/29850 (epoch 35.474), train_loss = 0.95348090, grad/param norm = 2.1200e-01, time/batch = 16.8643s	
21179/29850 (epoch 35.476), train_loss = 0.87310621, grad/param norm = 2.0255e-01, time/batch = 17.4534s	
21180/29850 (epoch 35.477), train_loss = 0.88822377, grad/param norm = 2.7358e-01, time/batch = 16.5363s	
21181/29850 (epoch 35.479), train_loss = 1.04097891, grad/param norm = 2.2393e-01, time/batch = 18.1067s	
21182/29850 (epoch 35.481), train_loss = 0.85113216, grad/param norm = 2.3327e-01, time/batch = 16.7046s	
21183/29850 (epoch 35.482), train_loss = 0.80048237, grad/param norm = 1.8671e-01, time/batch = 18.3779s	
21184/29850 (epoch 35.484), train_loss = 0.81135952, grad/param norm = 2.1674e-01, time/batch = 16.3912s	
21185/29850 (epoch 35.486), train_loss = 0.88833873, grad/param norm = 2.3220e-01, time/batch = 16.8902s	
21186/29850 (epoch 35.487), train_loss = 0.86281129, grad/param norm = 2.0947e-01, time/batch = 15.6268s	
21187/29850 (epoch 35.489), train_loss = 0.87041998, grad/param norm = 2.4192e-01, time/batch = 17.2927s	
21188/29850 (epoch 35.491), train_loss = 0.79018846, grad/param norm = 1.9724e-01, time/batch = 18.1369s	
21189/29850 (epoch 35.492), train_loss = 0.86321368, grad/param norm = 2.3199e-01, time/batch = 16.5505s	
21190/29850 (epoch 35.494), train_loss = 0.93562737, grad/param norm = 2.3341e-01, time/batch = 20.2082s	
21191/29850 (epoch 35.496), train_loss = 0.95543809, grad/param norm = 2.1283e-01, time/batch = 15.5409s	
21192/29850 (epoch 35.497), train_loss = 0.90422416, grad/param norm = 2.4939e-01, time/batch = 15.8444s	
21193/29850 (epoch 35.499), train_loss = 0.89209062, grad/param norm = 2.3875e-01, time/batch = 17.7228s	
21194/29850 (epoch 35.501), train_loss = 0.77033868, grad/param norm = 2.3443e-01, time/batch = 17.2870s	
21195/29850 (epoch 35.503), train_loss = 0.93257910, grad/param norm = 2.2844e-01, time/batch = 18.3831s	
21196/29850 (epoch 35.504), train_loss = 1.06852882, grad/param norm = 2.3608e-01, time/batch = 16.8815s	
21197/29850 (epoch 35.506), train_loss = 1.07000187, grad/param norm = 2.7441e-01, time/batch = 17.8753s	
21198/29850 (epoch 35.508), train_loss = 0.88734714, grad/param norm = 2.0414e-01, time/batch = 18.0507s	
21199/29850 (epoch 35.509), train_loss = 0.70211573, grad/param norm = 2.0694e-01, time/batch = 16.9541s	
21200/29850 (epoch 35.511), train_loss = 0.90012086, grad/param norm = 2.4568e-01, time/batch = 18.1249s	
21201/29850 (epoch 35.513), train_loss = 0.87587230, grad/param norm = 2.5760e-01, time/batch = 17.4631s	
21202/29850 (epoch 35.514), train_loss = 0.77631613, grad/param norm = 2.1619e-01, time/batch = 17.3637s	
21203/29850 (epoch 35.516), train_loss = 0.82216656, grad/param norm = 1.9227e-01, time/batch = 17.0227s	
21204/29850 (epoch 35.518), train_loss = 0.71004318, grad/param norm = 1.9708e-01, time/batch = 17.7795s	
21205/29850 (epoch 35.519), train_loss = 0.69708819, grad/param norm = 1.8635e-01, time/batch = 17.5255s	
21206/29850 (epoch 35.521), train_loss = 0.64614355, grad/param norm = 1.9496e-01, time/batch = 16.6263s	
21207/29850 (epoch 35.523), train_loss = 0.71960655, grad/param norm = 1.9109e-01, time/batch = 16.9720s	
21208/29850 (epoch 35.524), train_loss = 0.76675714, grad/param norm = 2.2345e-01, time/batch = 18.8754s	
21209/29850 (epoch 35.526), train_loss = 0.82193570, grad/param norm = 2.3536e-01, time/batch = 16.8381s	
21210/29850 (epoch 35.528), train_loss = 0.92251697, grad/param norm = 2.3971e-01, time/batch = 17.6959s	
21211/29850 (epoch 35.529), train_loss = 0.89765102, grad/param norm = 2.2094e-01, time/batch = 19.0344s	
21212/29850 (epoch 35.531), train_loss = 0.83639981, grad/param norm = 2.4631e-01, time/batch = 18.9499s	
21213/29850 (epoch 35.533), train_loss = 0.85603113, grad/param norm = 2.1920e-01, time/batch = 7.9632s	
21214/29850 (epoch 35.534), train_loss = 0.92021162, grad/param norm = 2.2589e-01, time/batch = 0.6747s	
21215/29850 (epoch 35.536), train_loss = 0.80613273, grad/param norm = 2.6968e-01, time/batch = 0.6704s	
21216/29850 (epoch 35.538), train_loss = 1.00213915, grad/param norm = 2.9720e-01, time/batch = 0.6607s	
21217/29850 (epoch 35.539), train_loss = 1.00443006, grad/param norm = 2.3300e-01, time/batch = 0.6673s	
21218/29850 (epoch 35.541), train_loss = 0.65583908, grad/param norm = 2.2906e-01, time/batch = 0.6716s	
21219/29850 (epoch 35.543), train_loss = 0.82012807, grad/param norm = 2.4082e-01, time/batch = 0.6614s	
21220/29850 (epoch 35.544), train_loss = 0.94929373, grad/param norm = 2.3265e-01, time/batch = 0.6615s	
21221/29850 (epoch 35.546), train_loss = 0.90793604, grad/param norm = 2.3120e-01, time/batch = 0.9658s	
21222/29850 (epoch 35.548), train_loss = 0.71475757, grad/param norm = 1.9088e-01, time/batch = 0.9707s	
21223/29850 (epoch 35.549), train_loss = 0.82531399, grad/param norm = 2.2402e-01, time/batch = 0.9968s	
21224/29850 (epoch 35.551), train_loss = 0.75408041, grad/param norm = 2.0162e-01, time/batch = 0.9984s	
21225/29850 (epoch 35.553), train_loss = 0.86694206, grad/param norm = 2.4753e-01, time/batch = 0.9997s	
21226/29850 (epoch 35.554), train_loss = 0.70190733, grad/param norm = 1.9456e-01, time/batch = 1.8521s	
21227/29850 (epoch 35.556), train_loss = 0.73814010, grad/param norm = 2.1504e-01, time/batch = 1.8147s	
21228/29850 (epoch 35.558), train_loss = 0.75404538, grad/param norm = 2.0869e-01, time/batch = 6.6109s	
21229/29850 (epoch 35.559), train_loss = 0.79633036, grad/param norm = 2.0209e-01, time/batch = 17.3718s	
21230/29850 (epoch 35.561), train_loss = 0.87266003, grad/param norm = 2.1866e-01, time/batch = 17.9509s	
21231/29850 (epoch 35.563), train_loss = 0.88146277, grad/param norm = 2.1248e-01, time/batch = 17.6333s	
21232/29850 (epoch 35.564), train_loss = 0.80216740, grad/param norm = 2.1883e-01, time/batch = 17.6348s	
21233/29850 (epoch 35.566), train_loss = 0.84690633, grad/param norm = 2.1115e-01, time/batch = 18.9622s	
21234/29850 (epoch 35.568), train_loss = 0.98523342, grad/param norm = 2.4430e-01, time/batch = 18.1941s	
21235/29850 (epoch 35.570), train_loss = 0.90097344, grad/param norm = 2.4306e-01, time/batch = 19.5274s	
21236/29850 (epoch 35.571), train_loss = 0.95537620, grad/param norm = 2.1252e-01, time/batch = 15.2989s	
21237/29850 (epoch 35.573), train_loss = 1.01211609, grad/param norm = 2.4967e-01, time/batch = 15.8898s	
21238/29850 (epoch 35.575), train_loss = 1.04626566, grad/param norm = 2.5142e-01, time/batch = 17.5399s	
21239/29850 (epoch 35.576), train_loss = 0.96337163, grad/param norm = 2.8621e-01, time/batch = 18.8001s	
21240/29850 (epoch 35.578), train_loss = 0.82085428, grad/param norm = 2.4676e-01, time/batch = 17.4553s	
21241/29850 (epoch 35.580), train_loss = 0.95465808, grad/param norm = 2.7213e-01, time/batch = 18.1197s	
21242/29850 (epoch 35.581), train_loss = 0.77668808, grad/param norm = 2.0224e-01, time/batch = 18.9374s	
21243/29850 (epoch 35.583), train_loss = 0.83757778, grad/param norm = 2.0362e-01, time/batch = 18.2126s	
21244/29850 (epoch 35.585), train_loss = 0.87088777, grad/param norm = 2.0309e-01, time/batch = 10.1715s	
21245/29850 (epoch 35.586), train_loss = 0.90018400, grad/param norm = 2.3399e-01, time/batch = 0.6757s	
21246/29850 (epoch 35.588), train_loss = 0.79268316, grad/param norm = 2.1047e-01, time/batch = 0.6703s	
21247/29850 (epoch 35.590), train_loss = 0.81542627, grad/param norm = 2.1024e-01, time/batch = 0.6633s	
21248/29850 (epoch 35.591), train_loss = 0.83781475, grad/param norm = 2.2797e-01, time/batch = 0.6525s	
21249/29850 (epoch 35.593), train_loss = 0.77670323, grad/param norm = 1.9051e-01, time/batch = 0.6692s	
21250/29850 (epoch 35.595), train_loss = 0.72776822, grad/param norm = 1.7383e-01, time/batch = 0.6629s	
21251/29850 (epoch 35.596), train_loss = 0.75548157, grad/param norm = 2.0993e-01, time/batch = 0.6616s	
21252/29850 (epoch 35.598), train_loss = 0.83062589, grad/param norm = 2.1323e-01, time/batch = 0.9592s	
21253/29850 (epoch 35.600), train_loss = 0.86909000, grad/param norm = 2.0492e-01, time/batch = 0.9816s	
21254/29850 (epoch 35.601), train_loss = 0.73834827, grad/param norm = 1.8433e-01, time/batch = 0.9711s	
21255/29850 (epoch 35.603), train_loss = 0.78653049, grad/param norm = 2.4810e-01, time/batch = 0.9694s	
21256/29850 (epoch 35.605), train_loss = 0.83910446, grad/param norm = 2.3375e-01, time/batch = 0.9519s	
21257/29850 (epoch 35.606), train_loss = 0.59509894, grad/param norm = 2.0379e-01, time/batch = 1.6455s	
21258/29850 (epoch 35.608), train_loss = 0.75384023, grad/param norm = 2.1109e-01, time/batch = 1.7927s	
21259/29850 (epoch 35.610), train_loss = 0.80863284, grad/param norm = 2.1489e-01, time/batch = 2.0432s	
21260/29850 (epoch 35.611), train_loss = 0.75094368, grad/param norm = 2.0414e-01, time/batch = 17.5556s	
21261/29850 (epoch 35.613), train_loss = 0.62731907, grad/param norm = 1.6380e-01, time/batch = 16.8828s	
21262/29850 (epoch 35.615), train_loss = 0.72262835, grad/param norm = 1.9831e-01, time/batch = 17.6139s	
21263/29850 (epoch 35.616), train_loss = 0.71933034, grad/param norm = 2.0658e-01, time/batch = 18.1481s	
21264/29850 (epoch 35.618), train_loss = 0.79268012, grad/param norm = 2.2252e-01, time/batch = 15.1138s	
21265/29850 (epoch 35.620), train_loss = 0.87306959, grad/param norm = 2.2744e-01, time/batch = 16.2138s	
21266/29850 (epoch 35.621), train_loss = 0.97552959, grad/param norm = 2.5427e-01, time/batch = 15.9531s	
21267/29850 (epoch 35.623), train_loss = 0.91314985, grad/param norm = 2.0660e-01, time/batch = 18.9722s	
21268/29850 (epoch 35.625), train_loss = 0.84001499, grad/param norm = 2.1988e-01, time/batch = 18.4671s	
21269/29850 (epoch 35.626), train_loss = 0.87511296, grad/param norm = 2.5573e-01, time/batch = 16.8488s	
21270/29850 (epoch 35.628), train_loss = 0.82959280, grad/param norm = 2.2122e-01, time/batch = 18.8626s	
21271/29850 (epoch 35.630), train_loss = 0.85706395, grad/param norm = 2.1249e-01, time/batch = 17.8738s	
21272/29850 (epoch 35.631), train_loss = 0.85361382, grad/param norm = 2.2204e-01, time/batch = 16.7938s	
21273/29850 (epoch 35.633), train_loss = 0.90006912, grad/param norm = 2.7851e-01, time/batch = 17.2208s	
21274/29850 (epoch 35.635), train_loss = 0.81708473, grad/param norm = 3.0862e-01, time/batch = 19.2141s	
21275/29850 (epoch 35.637), train_loss = 0.77339642, grad/param norm = 2.2710e-01, time/batch = 17.0242s	
21276/29850 (epoch 35.638), train_loss = 0.86219506, grad/param norm = 2.4344e-01, time/batch = 16.6118s	
21277/29850 (epoch 35.640), train_loss = 1.02197681, grad/param norm = 2.8853e-01, time/batch = 17.5633s	
21278/29850 (epoch 35.642), train_loss = 0.79166064, grad/param norm = 1.9629e-01, time/batch = 18.3722s	
21279/29850 (epoch 35.643), train_loss = 0.78312945, grad/param norm = 2.3949e-01, time/batch = 16.7136s	
21280/29850 (epoch 35.645), train_loss = 0.85064350, grad/param norm = 2.3914e-01, time/batch = 18.4737s	
21281/29850 (epoch 35.647), train_loss = 0.96953522, grad/param norm = 2.2933e-01, time/batch = 17.9708s	
21282/29850 (epoch 35.648), train_loss = 0.76025436, grad/param norm = 1.9867e-01, time/batch = 15.8700s	
21283/29850 (epoch 35.650), train_loss = 0.87224639, grad/param norm = 2.3945e-01, time/batch = 16.1950s	
21284/29850 (epoch 35.652), train_loss = 0.85154200, grad/param norm = 2.2968e-01, time/batch = 17.0663s	
21285/29850 (epoch 35.653), train_loss = 0.94169883, grad/param norm = 2.3295e-01, time/batch = 19.5102s	
21286/29850 (epoch 35.655), train_loss = 0.86977382, grad/param norm = 1.9472e-01, time/batch = 17.1879s	
21287/29850 (epoch 35.657), train_loss = 0.84794419, grad/param norm = 2.1482e-01, time/batch = 17.7867s	
21288/29850 (epoch 35.658), train_loss = 0.94952832, grad/param norm = 2.6158e-01, time/batch = 14.9147s	
21289/29850 (epoch 35.660), train_loss = 0.78868066, grad/param norm = 2.1937e-01, time/batch = 17.9546s	
21290/29850 (epoch 35.662), train_loss = 0.94375718, grad/param norm = 2.4890e-01, time/batch = 18.2863s	
21291/29850 (epoch 35.663), train_loss = 1.04500215, grad/param norm = 2.3714e-01, time/batch = 18.9696s	
21292/29850 (epoch 35.665), train_loss = 0.97286967, grad/param norm = 2.4876e-01, time/batch = 17.5368s	
21293/29850 (epoch 35.667), train_loss = 0.93024165, grad/param norm = 2.6401e-01, time/batch = 16.0411s	
21294/29850 (epoch 35.668), train_loss = 0.84186001, grad/param norm = 2.4861e-01, time/batch = 17.9034s	
21295/29850 (epoch 35.670), train_loss = 0.98289068, grad/param norm = 3.3576e-01, time/batch = 17.2208s	
21296/29850 (epoch 35.672), train_loss = 0.93900819, grad/param norm = 2.5090e-01, time/batch = 17.4435s	
21297/29850 (epoch 35.673), train_loss = 0.88326883, grad/param norm = 2.5208e-01, time/batch = 18.0560s	
21298/29850 (epoch 35.675), train_loss = 0.76858729, grad/param norm = 2.1374e-01, time/batch = 18.9585s	
21299/29850 (epoch 35.677), train_loss = 0.81630264, grad/param norm = 2.1707e-01, time/batch = 16.8678s	
21300/29850 (epoch 35.678), train_loss = 0.84723178, grad/param norm = 2.2435e-01, time/batch = 16.1303s	
21301/29850 (epoch 35.680), train_loss = 0.83192752, grad/param norm = 1.9640e-01, time/batch = 18.0419s	
21302/29850 (epoch 35.682), train_loss = 0.85653911, grad/param norm = 2.3089e-01, time/batch = 18.2913s	
21303/29850 (epoch 35.683), train_loss = 0.98899517, grad/param norm = 2.7245e-01, time/batch = 17.9575s	
21304/29850 (epoch 35.685), train_loss = 1.05780632, grad/param norm = 2.4146e-01, time/batch = 16.6885s	
21305/29850 (epoch 35.687), train_loss = 0.89760815, grad/param norm = 2.1564e-01, time/batch = 18.1201s	
21306/29850 (epoch 35.688), train_loss = 0.77099885, grad/param norm = 2.1614e-01, time/batch = 17.7948s	
21307/29850 (epoch 35.690), train_loss = 0.75260344, grad/param norm = 2.1443e-01, time/batch = 18.1385s	
21308/29850 (epoch 35.692), train_loss = 0.94781561, grad/param norm = 2.1368e-01, time/batch = 16.9638s	
21309/29850 (epoch 35.693), train_loss = 0.84234448, grad/param norm = 2.0032e-01, time/batch = 18.1616s	
21310/29850 (epoch 35.695), train_loss = 0.74327874, grad/param norm = 1.8858e-01, time/batch = 29.9735s	
21311/29850 (epoch 35.697), train_loss = 0.84016780, grad/param norm = 1.9782e-01, time/batch = 17.3017s	
21312/29850 (epoch 35.698), train_loss = 0.97832083, grad/param norm = 2.2875e-01, time/batch = 16.8622s	
21313/29850 (epoch 35.700), train_loss = 0.96972762, grad/param norm = 2.7672e-01, time/batch = 16.8040s	
21314/29850 (epoch 35.702), train_loss = 0.86450534, grad/param norm = 2.1931e-01, time/batch = 19.0434s	
21315/29850 (epoch 35.704), train_loss = 0.73127187, grad/param norm = 1.9621e-01, time/batch = 17.6886s	
21316/29850 (epoch 35.705), train_loss = 0.85282494, grad/param norm = 2.1486e-01, time/batch = 17.4441s	
21317/29850 (epoch 35.707), train_loss = 0.78983525, grad/param norm = 2.1109e-01, time/batch = 16.1982s	
21318/29850 (epoch 35.709), train_loss = 0.84465625, grad/param norm = 2.1902e-01, time/batch = 18.7902s	
21319/29850 (epoch 35.710), train_loss = 0.78617973, grad/param norm = 2.1314e-01, time/batch = 18.1236s	
21320/29850 (epoch 35.712), train_loss = 0.88189459, grad/param norm = 1.9975e-01, time/batch = 18.0534s	
21321/29850 (epoch 35.714), train_loss = 0.95048023, grad/param norm = 2.6349e-01, time/batch = 17.8819s	
21322/29850 (epoch 35.715), train_loss = 0.88794166, grad/param norm = 2.2627e-01, time/batch = 15.7051s	
21323/29850 (epoch 35.717), train_loss = 0.63456395, grad/param norm = 1.8722e-01, time/batch = 16.1294s	
21324/29850 (epoch 35.719), train_loss = 0.81356127, grad/param norm = 2.1513e-01, time/batch = 19.1128s	
21325/29850 (epoch 35.720), train_loss = 0.83788112, grad/param norm = 1.7945e-01, time/batch = 16.0567s	
21326/29850 (epoch 35.722), train_loss = 0.76340230, grad/param norm = 1.8414e-01, time/batch = 15.7099s	
21327/29850 (epoch 35.724), train_loss = 0.88579119, grad/param norm = 2.3317e-01, time/batch = 18.3764s	
21328/29850 (epoch 35.725), train_loss = 0.74928261, grad/param norm = 2.1994e-01, time/batch = 18.5486s	
21329/29850 (epoch 35.727), train_loss = 0.75556324, grad/param norm = 2.4361e-01, time/batch = 17.0331s	
21330/29850 (epoch 35.729), train_loss = 0.70307911, grad/param norm = 1.7848e-01, time/batch = 18.3774s	
21331/29850 (epoch 35.730), train_loss = 0.68152861, grad/param norm = 1.9905e-01, time/batch = 18.4526s	
21332/29850 (epoch 35.732), train_loss = 0.96312829, grad/param norm = 2.2584e-01, time/batch = 15.7084s	
21333/29850 (epoch 35.734), train_loss = 1.03470353, grad/param norm = 2.4432e-01, time/batch = 16.7208s	
21334/29850 (epoch 35.735), train_loss = 0.76562172, grad/param norm = 2.1511e-01, time/batch = 17.7907s	
21335/29850 (epoch 35.737), train_loss = 0.74612430, grad/param norm = 2.0216e-01, time/batch = 16.8494s	
21336/29850 (epoch 35.739), train_loss = 0.66111980, grad/param norm = 1.8859e-01, time/batch = 17.4595s	
21337/29850 (epoch 35.740), train_loss = 0.71954179, grad/param norm = 2.1517e-01, time/batch = 19.1890s	
21338/29850 (epoch 35.742), train_loss = 0.63502747, grad/param norm = 1.6467e-01, time/batch = 19.2813s	
21339/29850 (epoch 35.744), train_loss = 0.76929640, grad/param norm = 2.5208e-01, time/batch = 18.2071s	
21340/29850 (epoch 35.745), train_loss = 0.79208483, grad/param norm = 2.2252e-01, time/batch = 16.8626s	
21341/29850 (epoch 35.747), train_loss = 0.83275448, grad/param norm = 2.1550e-01, time/batch = 18.6346s	
21342/29850 (epoch 35.749), train_loss = 0.71607414, grad/param norm = 2.1675e-01, time/batch = 16.9689s	
21343/29850 (epoch 35.750), train_loss = 0.66697584, grad/param norm = 1.8845e-01, time/batch = 17.5195s	
21344/29850 (epoch 35.752), train_loss = 0.58782301, grad/param norm = 1.8505e-01, time/batch = 17.4335s	
21345/29850 (epoch 35.754), train_loss = 0.65769867, grad/param norm = 2.0723e-01, time/batch = 18.4350s	
21346/29850 (epoch 35.755), train_loss = 0.68624563, grad/param norm = 2.0233e-01, time/batch = 16.0268s	
21347/29850 (epoch 35.757), train_loss = 0.71679785, grad/param norm = 1.8386e-01, time/batch = 16.8687s	
21348/29850 (epoch 35.759), train_loss = 0.74977200, grad/param norm = 2.0512e-01, time/batch = 16.9599s	
21349/29850 (epoch 35.760), train_loss = 0.74059158, grad/param norm = 1.9772e-01, time/batch = 18.9551s	
21350/29850 (epoch 35.762), train_loss = 0.68649803, grad/param norm = 2.0201e-01, time/batch = 16.8950s	
21351/29850 (epoch 35.764), train_loss = 0.61619604, grad/param norm = 2.2825e-01, time/batch = 17.6069s	
21352/29850 (epoch 35.765), train_loss = 0.78339830, grad/param norm = 2.1529e-01, time/batch = 19.6191s	
21353/29850 (epoch 35.767), train_loss = 0.79458947, grad/param norm = 2.1428e-01, time/batch = 15.8852s	
21354/29850 (epoch 35.769), train_loss = 0.80903671, grad/param norm = 1.9700e-01, time/batch = 18.6286s	
21355/29850 (epoch 35.771), train_loss = 0.86917080, grad/param norm = 2.2673e-01, time/batch = 18.7127s	
21356/29850 (epoch 35.772), train_loss = 0.81986833, grad/param norm = 2.1564e-01, time/batch = 18.9370s	
21357/29850 (epoch 35.774), train_loss = 0.77712174, grad/param norm = 2.2613e-01, time/batch = 17.5442s	
21358/29850 (epoch 35.776), train_loss = 0.80344715, grad/param norm = 2.1837e-01, time/batch = 19.0472s	
21359/29850 (epoch 35.777), train_loss = 0.89135008, grad/param norm = 2.4510e-01, time/batch = 18.1926s	
21360/29850 (epoch 35.779), train_loss = 0.71662418, grad/param norm = 2.0322e-01, time/batch = 15.9590s	
21361/29850 (epoch 35.781), train_loss = 0.84536985, grad/param norm = 2.2029e-01, time/batch = 17.3100s	
21362/29850 (epoch 35.782), train_loss = 0.84754824, grad/param norm = 2.1025e-01, time/batch = 18.3138s	
21363/29850 (epoch 35.784), train_loss = 0.68970671, grad/param norm = 2.3521e-01, time/batch = 16.1179s	
21364/29850 (epoch 35.786), train_loss = 0.76306080, grad/param norm = 2.1956e-01, time/batch = 18.0386s	
21365/29850 (epoch 35.787), train_loss = 0.65648159, grad/param norm = 2.1787e-01, time/batch = 18.5507s	
21366/29850 (epoch 35.789), train_loss = 0.66269794, grad/param norm = 1.8679e-01, time/batch = 17.5349s	
21367/29850 (epoch 35.791), train_loss = 0.73792878, grad/param norm = 2.0946e-01, time/batch = 15.4402s	
21368/29850 (epoch 35.792), train_loss = 0.85116708, grad/param norm = 2.4421e-01, time/batch = 19.2903s	
21369/29850 (epoch 35.794), train_loss = 0.81901690, grad/param norm = 2.0225e-01, time/batch = 18.3800s	
21370/29850 (epoch 35.796), train_loss = 0.70956183, grad/param norm = 1.8090e-01, time/batch = 17.0061s	
21371/29850 (epoch 35.797), train_loss = 0.62972895, grad/param norm = 1.8570e-01, time/batch = 18.1315s	
21372/29850 (epoch 35.799), train_loss = 0.66617013, grad/param norm = 2.0231e-01, time/batch = 19.2025s	
21373/29850 (epoch 35.801), train_loss = 0.68322126, grad/param norm = 1.8889e-01, time/batch = 16.0314s	
21374/29850 (epoch 35.802), train_loss = 0.64842359, grad/param norm = 2.0817e-01, time/batch = 17.9743s	
21375/29850 (epoch 35.804), train_loss = 0.71160867, grad/param norm = 1.8599e-01, time/batch = 16.4593s	
21376/29850 (epoch 35.806), train_loss = 0.65138535, grad/param norm = 1.7534e-01, time/batch = 17.9558s	
21377/29850 (epoch 35.807), train_loss = 0.68182362, grad/param norm = 1.7937e-01, time/batch = 16.4516s	
21378/29850 (epoch 35.809), train_loss = 0.68009381, grad/param norm = 1.9411e-01, time/batch = 18.8694s	
21379/29850 (epoch 35.811), train_loss = 0.87048344, grad/param norm = 2.8551e-01, time/batch = 17.6358s	
21380/29850 (epoch 35.812), train_loss = 0.85233740, grad/param norm = 2.2746e-01, time/batch = 16.2468s	
21381/29850 (epoch 35.814), train_loss = 0.87414891, grad/param norm = 2.3866e-01, time/batch = 19.2896s	
21382/29850 (epoch 35.816), train_loss = 0.89792539, grad/param norm = 2.1329e-01, time/batch = 19.5341s	
21383/29850 (epoch 35.817), train_loss = 0.84111960, grad/param norm = 2.3764e-01, time/batch = 17.3824s	
21384/29850 (epoch 35.819), train_loss = 0.67551365, grad/param norm = 2.4111e-01, time/batch = 16.2869s	
21385/29850 (epoch 35.821), train_loss = 0.90625395, grad/param norm = 2.3688e-01, time/batch = 19.6016s	
21386/29850 (epoch 35.822), train_loss = 0.91896848, grad/param norm = 2.2634e-01, time/batch = 16.6288s	
21387/29850 (epoch 35.824), train_loss = 0.80331605, grad/param norm = 2.1590e-01, time/batch = 18.2071s	
21388/29850 (epoch 35.826), train_loss = 0.70348301, grad/param norm = 1.8914e-01, time/batch = 18.3976s	
21389/29850 (epoch 35.827), train_loss = 0.64898521, grad/param norm = 2.1349e-01, time/batch = 15.4580s	
21390/29850 (epoch 35.829), train_loss = 0.80624992, grad/param norm = 2.5296e-01, time/batch = 16.7124s	
21391/29850 (epoch 35.831), train_loss = 0.92170116, grad/param norm = 2.5137e-01, time/batch = 18.4554s	
21392/29850 (epoch 35.832), train_loss = 0.83779445, grad/param norm = 2.2618e-01, time/batch = 18.7897s	
21393/29850 (epoch 35.834), train_loss = 0.63250301, grad/param norm = 2.0223e-01, time/batch = 16.7219s	
21394/29850 (epoch 35.836), train_loss = 0.64940759, grad/param norm = 1.9867e-01, time/batch = 18.2021s	
21395/29850 (epoch 35.838), train_loss = 0.74675120, grad/param norm = 2.7008e-01, time/batch = 17.2996s	
21396/29850 (epoch 35.839), train_loss = 0.66146659, grad/param norm = 2.0223e-01, time/batch = 15.9117s	
21397/29850 (epoch 35.841), train_loss = 0.71777040, grad/param norm = 1.9211e-01, time/batch = 15.4739s	
21398/29850 (epoch 35.843), train_loss = 0.65494821, grad/param norm = 2.0866e-01, time/batch = 18.7825s	
21399/29850 (epoch 35.844), train_loss = 0.71754678, grad/param norm = 2.1945e-01, time/batch = 16.1250s	
21400/29850 (epoch 35.846), train_loss = 0.76382601, grad/param norm = 2.1023e-01, time/batch = 16.7188s	
21401/29850 (epoch 35.848), train_loss = 0.86116190, grad/param norm = 2.5057e-01, time/batch = 16.8592s	
21402/29850 (epoch 35.849), train_loss = 0.76314059, grad/param norm = 2.4094e-01, time/batch = 19.1397s	
21403/29850 (epoch 35.851), train_loss = 0.96199355, grad/param norm = 2.6392e-01, time/batch = 18.4675s	
21404/29850 (epoch 35.853), train_loss = 0.75998766, grad/param norm = 2.4405e-01, time/batch = 18.9388s	
21405/29850 (epoch 35.854), train_loss = 0.94641208, grad/param norm = 2.7733e-01, time/batch = 16.1080s	
21406/29850 (epoch 35.856), train_loss = 0.88479927, grad/param norm = 2.4280e-01, time/batch = 17.1410s	
21407/29850 (epoch 35.858), train_loss = 0.80529611, grad/param norm = 2.4108e-01, time/batch = 16.8805s	
21408/29850 (epoch 35.859), train_loss = 0.73194944, grad/param norm = 2.5963e-01, time/batch = 16.8907s	
21409/29850 (epoch 35.861), train_loss = 0.91584812, grad/param norm = 3.1239e-01, time/batch = 18.7236s	
21410/29850 (epoch 35.863), train_loss = 0.94254160, grad/param norm = 2.4296e-01, time/batch = 17.9575s	
21411/29850 (epoch 35.864), train_loss = 0.92106788, grad/param norm = 2.5917e-01, time/batch = 16.7141s	
21412/29850 (epoch 35.866), train_loss = 0.84097288, grad/param norm = 2.7605e-01, time/batch = 17.0525s	
21413/29850 (epoch 35.868), train_loss = 0.97589860, grad/param norm = 2.4895e-01, time/batch = 18.6207s	
21414/29850 (epoch 35.869), train_loss = 0.88294163, grad/param norm = 2.5537e-01, time/batch = 17.3514s	
21415/29850 (epoch 35.871), train_loss = 0.91702827, grad/param norm = 2.4623e-01, time/batch = 15.1612s	
21416/29850 (epoch 35.873), train_loss = 0.84762746, grad/param norm = 2.6831e-01, time/batch = 17.2151s	
21417/29850 (epoch 35.874), train_loss = 0.85152193, grad/param norm = 2.2458e-01, time/batch = 16.9635s	
21418/29850 (epoch 35.876), train_loss = 0.82238195, grad/param norm = 2.9617e-01, time/batch = 17.2117s	
21419/29850 (epoch 35.878), train_loss = 0.83687082, grad/param norm = 2.0005e-01, time/batch = 15.9656s	
21420/29850 (epoch 35.879), train_loss = 0.86592709, grad/param norm = 2.2380e-01, time/batch = 18.2025s	
21421/29850 (epoch 35.881), train_loss = 0.94764850, grad/param norm = 2.6194e-01, time/batch = 16.7020s	
21422/29850 (epoch 35.883), train_loss = 0.88337016, grad/param norm = 2.3346e-01, time/batch = 19.9322s	
21423/29850 (epoch 35.884), train_loss = 0.73540132, grad/param norm = 2.0275e-01, time/batch = 17.5603s	
21424/29850 (epoch 35.886), train_loss = 0.90524685, grad/param norm = 2.3545e-01, time/batch = 17.8651s	
21425/29850 (epoch 35.888), train_loss = 0.84551360, grad/param norm = 2.4578e-01, time/batch = 17.6907s	
21426/29850 (epoch 35.889), train_loss = 0.77387806, grad/param norm = 1.9595e-01, time/batch = 19.2895s	
21427/29850 (epoch 35.891), train_loss = 0.73455201, grad/param norm = 1.9949e-01, time/batch = 17.9474s	
21428/29850 (epoch 35.893), train_loss = 0.80405141, grad/param norm = 2.3568e-01, time/batch = 17.3723s	
21429/29850 (epoch 35.894), train_loss = 0.80296351, grad/param norm = 2.2994e-01, time/batch = 18.1242s	
21430/29850 (epoch 35.896), train_loss = 0.84839215, grad/param norm = 2.8725e-01, time/batch = 17.2970s	
21431/29850 (epoch 35.898), train_loss = 1.00024492, grad/param norm = 2.6049e-01, time/batch = 16.7666s	
21432/29850 (epoch 35.899), train_loss = 0.72131827, grad/param norm = 2.7843e-01, time/batch = 16.8744s	
21433/29850 (epoch 35.901), train_loss = 1.00459464, grad/param norm = 2.9090e-01, time/batch = 18.3031s	
21434/29850 (epoch 35.903), train_loss = 0.87507971, grad/param norm = 3.1954e-01, time/batch = 15.7719s	
21435/29850 (epoch 35.905), train_loss = 1.09994571, grad/param norm = 2.4413e-01, time/batch = 17.9441s	
21436/29850 (epoch 35.906), train_loss = 0.85258149, grad/param norm = 2.3440e-01, time/batch = 19.1181s	
21437/29850 (epoch 35.908), train_loss = 0.99240925, grad/param norm = 2.5754e-01, time/batch = 19.2887s	
21438/29850 (epoch 35.910), train_loss = 0.91282808, grad/param norm = 2.0833e-01, time/batch = 17.6064s	
21439/29850 (epoch 35.911), train_loss = 1.04710060, grad/param norm = 2.5019e-01, time/batch = 16.7267s	
21440/29850 (epoch 35.913), train_loss = 0.98058325, grad/param norm = 2.3699e-01, time/batch = 17.6400s	
21441/29850 (epoch 35.915), train_loss = 0.98527906, grad/param norm = 2.5016e-01, time/batch = 17.3730s	
21442/29850 (epoch 35.916), train_loss = 0.93631501, grad/param norm = 2.7080e-01, time/batch = 16.1990s	
21443/29850 (epoch 35.918), train_loss = 0.78778758, grad/param norm = 2.2787e-01, time/batch = 15.9580s	
21444/29850 (epoch 35.920), train_loss = 0.97676769, grad/param norm = 2.2183e-01, time/batch = 17.8890s	
21445/29850 (epoch 35.921), train_loss = 0.85143018, grad/param norm = 2.5135e-01, time/batch = 16.5391s	
21446/29850 (epoch 35.923), train_loss = 0.85833537, grad/param norm = 2.2207e-01, time/batch = 18.1461s	
21447/29850 (epoch 35.925), train_loss = 1.00321918, grad/param norm = 2.6920e-01, time/batch = 17.6280s	
21448/29850 (epoch 35.926), train_loss = 0.99256987, grad/param norm = 2.4828e-01, time/batch = 15.8679s	
21449/29850 (epoch 35.928), train_loss = 0.84213885, grad/param norm = 2.2176e-01, time/batch = 17.9537s	
21450/29850 (epoch 35.930), train_loss = 0.88644532, grad/param norm = 2.3623e-01, time/batch = 18.8517s	
21451/29850 (epoch 35.931), train_loss = 0.85466534, grad/param norm = 2.3363e-01, time/batch = 17.4454s	
21452/29850 (epoch 35.933), train_loss = 1.00617611, grad/param norm = 2.6478e-01, time/batch = 17.8485s	
21453/29850 (epoch 35.935), train_loss = 0.92369297, grad/param norm = 2.6245e-01, time/batch = 17.9557s	
21454/29850 (epoch 35.936), train_loss = 0.89011719, grad/param norm = 2.3030e-01, time/batch = 16.0435s	
21455/29850 (epoch 35.938), train_loss = 0.76301394, grad/param norm = 2.2594e-01, time/batch = 15.5904s	
21456/29850 (epoch 35.940), train_loss = 0.78706077, grad/param norm = 2.2534e-01, time/batch = 18.2150s	
21457/29850 (epoch 35.941), train_loss = 0.79213653, grad/param norm = 2.3929e-01, time/batch = 19.3732s	
21458/29850 (epoch 35.943), train_loss = 0.77915255, grad/param norm = 2.0333e-01, time/batch = 17.5377s	
21459/29850 (epoch 35.945), train_loss = 0.76175924, grad/param norm = 2.5374e-01, time/batch = 17.7856s	
21460/29850 (epoch 35.946), train_loss = 0.75283915, grad/param norm = 2.2053e-01, time/batch = 18.0544s	
21461/29850 (epoch 35.948), train_loss = 0.84735895, grad/param norm = 2.1932e-01, time/batch = 18.6141s	
21462/29850 (epoch 35.950), train_loss = 0.79164798, grad/param norm = 2.0603e-01, time/batch = 17.5398s	
21463/29850 (epoch 35.951), train_loss = 0.71228826, grad/param norm = 2.0804e-01, time/batch = 18.3876s	
21464/29850 (epoch 35.953), train_loss = 0.80871221, grad/param norm = 2.4840e-01, time/batch = 18.0202s	
21465/29850 (epoch 35.955), train_loss = 0.71988904, grad/param norm = 1.9744e-01, time/batch = 18.2676s	
21466/29850 (epoch 35.956), train_loss = 0.74782916, grad/param norm = 2.4374e-01, time/batch = 17.0486s	
21467/29850 (epoch 35.958), train_loss = 0.65309414, grad/param norm = 1.7535e-01, time/batch = 17.8982s	
21468/29850 (epoch 35.960), train_loss = 0.92713628, grad/param norm = 2.8072e-01, time/batch = 17.3640s	
21469/29850 (epoch 35.961), train_loss = 0.71712581, grad/param norm = 2.5251e-01, time/batch = 16.5447s	
21470/29850 (epoch 35.963), train_loss = 0.70395872, grad/param norm = 2.2273e-01, time/batch = 18.2939s	
21471/29850 (epoch 35.965), train_loss = 0.75092433, grad/param norm = 2.1583e-01, time/batch = 16.5214s	
21472/29850 (epoch 35.966), train_loss = 0.73135452, grad/param norm = 2.1920e-01, time/batch = 15.2680s	
21473/29850 (epoch 35.968), train_loss = 0.75689054, grad/param norm = 2.2750e-01, time/batch = 19.7778s	
21474/29850 (epoch 35.970), train_loss = 0.73126589, grad/param norm = 2.4231e-01, time/batch = 19.4397s	
21475/29850 (epoch 35.972), train_loss = 0.74133071, grad/param norm = 1.8435e-01, time/batch = 17.1256s	
21476/29850 (epoch 35.973), train_loss = 0.74154896, grad/param norm = 2.0228e-01, time/batch = 17.5453s	
21477/29850 (epoch 35.975), train_loss = 0.64374467, grad/param norm = 1.8285e-01, time/batch = 17.8817s	
21478/29850 (epoch 35.977), train_loss = 0.77604176, grad/param norm = 1.9791e-01, time/batch = 17.9303s	
21479/29850 (epoch 35.978), train_loss = 0.67923992, grad/param norm = 1.8311e-01, time/batch = 17.1431s	
21480/29850 (epoch 35.980), train_loss = 0.74194898, grad/param norm = 1.9079e-01, time/batch = 17.2974s	
21481/29850 (epoch 35.982), train_loss = 0.74692069, grad/param norm = 2.1357e-01, time/batch = 17.9681s	
21482/29850 (epoch 35.983), train_loss = 0.75491415, grad/param norm = 1.7591e-01, time/batch = 16.3866s	
21483/29850 (epoch 35.985), train_loss = 0.88374888, grad/param norm = 2.8147e-01, time/batch = 19.7974s	
21484/29850 (epoch 35.987), train_loss = 0.83703254, grad/param norm = 2.1770e-01, time/batch = 18.1277s	
21485/29850 (epoch 35.988), train_loss = 0.77213689, grad/param norm = 1.9225e-01, time/batch = 17.7200s	
21486/29850 (epoch 35.990), train_loss = 0.83866419, grad/param norm = 1.9955e-01, time/batch = 16.2423s	
21487/29850 (epoch 35.992), train_loss = 0.85771377, grad/param norm = 2.0834e-01, time/batch = 16.0437s	
21488/29850 (epoch 35.993), train_loss = 0.84519674, grad/param norm = 2.5290e-01, time/batch = 16.5241s	
21489/29850 (epoch 35.995), train_loss = 0.81844027, grad/param norm = 1.9599e-01, time/batch = 16.2173s	
21490/29850 (epoch 35.997), train_loss = 0.86434612, grad/param norm = 2.2113e-01, time/batch = 19.2072s	
21491/29850 (epoch 35.998), train_loss = 0.87650096, grad/param norm = 2.3032e-01, time/batch = 17.8723s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
21492/29850 (epoch 36.000), train_loss = 0.71825304, grad/param norm = 2.0320e-01, time/batch = 17.6982s	
21493/29850 (epoch 36.002), train_loss = 0.96490983, grad/param norm = 2.4017e-01, time/batch = 17.5579s	
21494/29850 (epoch 36.003), train_loss = 0.70291163, grad/param norm = 2.5415e-01, time/batch = 18.4658s	
21495/29850 (epoch 36.005), train_loss = 0.88187714, grad/param norm = 2.3044e-01, time/batch = 18.0309s	
21496/29850 (epoch 36.007), train_loss = 0.91896839, grad/param norm = 2.6893e-01, time/batch = 17.6969s	
21497/29850 (epoch 36.008), train_loss = 1.06343654, grad/param norm = 2.7987e-01, time/batch = 17.9565s	
21498/29850 (epoch 36.010), train_loss = 0.75547371, grad/param norm = 2.1340e-01, time/batch = 17.3691s	
21499/29850 (epoch 36.012), train_loss = 0.78172312, grad/param norm = 1.8521e-01, time/batch = 18.2688s	
21500/29850 (epoch 36.013), train_loss = 0.87059840, grad/param norm = 2.3491e-01, time/batch = 17.1248s	
21501/29850 (epoch 36.015), train_loss = 0.91153977, grad/param norm = 2.2599e-01, time/batch = 16.9740s	
21502/29850 (epoch 36.017), train_loss = 0.86548421, grad/param norm = 2.5044e-01, time/batch = 16.3910s	
21503/29850 (epoch 36.018), train_loss = 0.96788450, grad/param norm = 2.1696e-01, time/batch = 16.8603s	
21504/29850 (epoch 36.020), train_loss = 0.83507429, grad/param norm = 2.1661e-01, time/batch = 18.9701s	
21505/29850 (epoch 36.022), train_loss = 0.91152235, grad/param norm = 2.2089e-01, time/batch = 18.2818s	
21506/29850 (epoch 36.023), train_loss = 0.91346272, grad/param norm = 2.2581e-01, time/batch = 19.2039s	
21507/29850 (epoch 36.025), train_loss = 0.84232737, grad/param norm = 2.0208e-01, time/batch = 15.9421s	
21508/29850 (epoch 36.027), train_loss = 0.63636674, grad/param norm = 1.8926e-01, time/batch = 16.4570s	
21509/29850 (epoch 36.028), train_loss = 0.76040557, grad/param norm = 2.0240e-01, time/batch = 16.6976s	
21510/29850 (epoch 36.030), train_loss = 0.79103574, grad/param norm = 2.0932e-01, time/batch = 18.0554s	
21511/29850 (epoch 36.032), train_loss = 0.87799864, grad/param norm = 2.0790e-01, time/batch = 17.1194s	
21512/29850 (epoch 36.034), train_loss = 0.76026322, grad/param norm = 2.0366e-01, time/batch = 19.6572s	
21513/29850 (epoch 36.035), train_loss = 0.66576313, grad/param norm = 1.9317e-01, time/batch = 25.5455s	
21514/29850 (epoch 36.037), train_loss = 0.82986378, grad/param norm = 2.0320e-01, time/batch = 15.2194s	
21515/29850 (epoch 36.039), train_loss = 0.73328788, grad/param norm = 1.7316e-01, time/batch = 15.8484s	
21516/29850 (epoch 36.040), train_loss = 0.72214725, grad/param norm = 2.1529e-01, time/batch = 15.8139s	
21517/29850 (epoch 36.042), train_loss = 0.74123220, grad/param norm = 2.1146e-01, time/batch = 17.1240s	
21518/29850 (epoch 36.044), train_loss = 0.79164210, grad/param norm = 1.9650e-01, time/batch = 18.4583s	
21519/29850 (epoch 36.045), train_loss = 0.90759926, grad/param norm = 2.3775e-01, time/batch = 16.8808s	
21520/29850 (epoch 36.047), train_loss = 0.72394912, grad/param norm = 2.0102e-01, time/batch = 16.7934s	
21521/29850 (epoch 36.049), train_loss = 0.85815992, grad/param norm = 2.1877e-01, time/batch = 19.7782s	
21522/29850 (epoch 36.050), train_loss = 0.77857319, grad/param norm = 2.3295e-01, time/batch = 17.5518s	
21523/29850 (epoch 36.052), train_loss = 0.94198534, grad/param norm = 2.1468e-01, time/batch = 18.7917s	
21524/29850 (epoch 36.054), train_loss = 0.81257607, grad/param norm = 1.9665e-01, time/batch = 17.1433s	
21525/29850 (epoch 36.055), train_loss = 0.77869723, grad/param norm = 2.2961e-01, time/batch = 18.2188s	
21526/29850 (epoch 36.057), train_loss = 0.86879048, grad/param norm = 2.1182e-01, time/batch = 18.3613s	
21527/29850 (epoch 36.059), train_loss = 0.87894081, grad/param norm = 2.1453e-01, time/batch = 17.7068s	
21528/29850 (epoch 36.060), train_loss = 0.83981927, grad/param norm = 2.1911e-01, time/batch = 15.4543s	
21529/29850 (epoch 36.062), train_loss = 0.91449713, grad/param norm = 2.5714e-01, time/batch = 15.5896s	
21530/29850 (epoch 36.064), train_loss = 0.92748688, grad/param norm = 2.8237e-01, time/batch = 15.3662s	
21531/29850 (epoch 36.065), train_loss = 0.71643918, grad/param norm = 2.0751e-01, time/batch = 15.2585s	
21532/29850 (epoch 36.067), train_loss = 0.87212765, grad/param norm = 2.1477e-01, time/batch = 14.9738s	
21533/29850 (epoch 36.069), train_loss = 0.87850180, grad/param norm = 1.9588e-01, time/batch = 14.8730s	
21534/29850 (epoch 36.070), train_loss = 0.87770528, grad/param norm = 2.0154e-01, time/batch = 15.2652s	
21535/29850 (epoch 36.072), train_loss = 0.83731656, grad/param norm = 2.1945e-01, time/batch = 15.0880s	
21536/29850 (epoch 36.074), train_loss = 0.91521865, grad/param norm = 2.1184e-01, time/batch = 18.7004s	
21537/29850 (epoch 36.075), train_loss = 0.78900362, grad/param norm = 2.5280e-01, time/batch = 16.8683s	
21538/29850 (epoch 36.077), train_loss = 0.90757789, grad/param norm = 2.2457e-01, time/batch = 18.0293s	
21539/29850 (epoch 36.079), train_loss = 1.03061657, grad/param norm = 2.8586e-01, time/batch = 17.7144s	
21540/29850 (epoch 36.080), train_loss = 1.02029669, grad/param norm = 2.6564e-01, time/batch = 17.2214s	
21541/29850 (epoch 36.082), train_loss = 0.91310071, grad/param norm = 2.3097e-01, time/batch = 18.1084s	
21542/29850 (epoch 36.084), train_loss = 1.01034746, grad/param norm = 2.4498e-01, time/batch = 16.9786s	
21543/29850 (epoch 36.085), train_loss = 1.03105790, grad/param norm = 2.6721e-01, time/batch = 17.1313s	
21544/29850 (epoch 36.087), train_loss = 0.97072154, grad/param norm = 2.3178e-01, time/batch = 16.8823s	
21545/29850 (epoch 36.089), train_loss = 0.88966540, grad/param norm = 2.3079e-01, time/batch = 19.4633s	
21546/29850 (epoch 36.090), train_loss = 0.89516395, grad/param norm = 2.1192e-01, time/batch = 18.3909s	
21547/29850 (epoch 36.092), train_loss = 0.79243390, grad/param norm = 2.3493e-01, time/batch = 15.1931s	
21548/29850 (epoch 36.094), train_loss = 0.99347430, grad/param norm = 2.4409e-01, time/batch = 19.3595s	
21549/29850 (epoch 36.095), train_loss = 0.88670816, grad/param norm = 2.9025e-01, time/batch = 14.7968s	
21550/29850 (epoch 36.097), train_loss = 0.66850154, grad/param norm = 1.8940e-01, time/batch = 14.4101s	
21551/29850 (epoch 36.099), train_loss = 0.69486950, grad/param norm = 1.9622e-01, time/batch = 16.4589s	
21552/29850 (epoch 36.101), train_loss = 0.91252637, grad/param norm = 2.0894e-01, time/batch = 19.7815s	
21553/29850 (epoch 36.102), train_loss = 0.90431240, grad/param norm = 2.1882e-01, time/batch = 17.8910s	
21554/29850 (epoch 36.104), train_loss = 0.83872862, grad/param norm = 2.5968e-01, time/batch = 15.1943s	
21555/29850 (epoch 36.106), train_loss = 0.92693627, grad/param norm = 2.2192e-01, time/batch = 16.2607s	
21556/29850 (epoch 36.107), train_loss = 0.79035785, grad/param norm = 1.9871e-01, time/batch = 18.0607s	
21557/29850 (epoch 36.109), train_loss = 0.85801905, grad/param norm = 2.3284e-01, time/batch = 18.1085s	
21558/29850 (epoch 36.111), train_loss = 0.89794198, grad/param norm = 2.2101e-01, time/batch = 17.6949s	
21559/29850 (epoch 36.112), train_loss = 0.75037327, grad/param norm = 2.0807e-01, time/batch = 17.2827s	
21560/29850 (epoch 36.114), train_loss = 0.81201462, grad/param norm = 2.3108e-01, time/batch = 18.3862s	
21561/29850 (epoch 36.116), train_loss = 0.76275199, grad/param norm = 2.0081e-01, time/batch = 16.0200s	
21562/29850 (epoch 36.117), train_loss = 0.83446030, grad/param norm = 2.5105e-01, time/batch = 18.9603s	
21563/29850 (epoch 36.119), train_loss = 0.81702977, grad/param norm = 2.1725e-01, time/batch = 18.9546s	
21564/29850 (epoch 36.121), train_loss = 0.67634573, grad/param norm = 2.0757e-01, time/batch = 16.5348s	
21565/29850 (epoch 36.122), train_loss = 0.71029918, grad/param norm = 1.6204e-01, time/batch = 17.1400s	
21566/29850 (epoch 36.124), train_loss = 0.74335577, grad/param norm = 1.9678e-01, time/batch = 15.9767s	
21567/29850 (epoch 36.126), train_loss = 0.80161537, grad/param norm = 2.1231e-01, time/batch = 15.9588s	
21568/29850 (epoch 36.127), train_loss = 0.87509365, grad/param norm = 2.5587e-01, time/batch = 16.8782s	
21569/29850 (epoch 36.129), train_loss = 0.80001318, grad/param norm = 2.0373e-01, time/batch = 15.9656s	
21570/29850 (epoch 36.131), train_loss = 0.83652718, grad/param norm = 1.9901e-01, time/batch = 19.1855s	
21571/29850 (epoch 36.132), train_loss = 0.69639080, grad/param norm = 1.9817e-01, time/batch = 18.1088s	
21572/29850 (epoch 36.134), train_loss = 0.80436298, grad/param norm = 2.1091e-01, time/batch = 15.3649s	
21573/29850 (epoch 36.136), train_loss = 0.89249153, grad/param norm = 2.0839e-01, time/batch = 17.3013s	
21574/29850 (epoch 36.137), train_loss = 0.69592500, grad/param norm = 1.8607e-01, time/batch = 18.8061s	
21575/29850 (epoch 36.139), train_loss = 0.81608539, grad/param norm = 2.0281e-01, time/batch = 17.7844s	
21576/29850 (epoch 36.141), train_loss = 0.73968425, grad/param norm = 2.2728e-01, time/batch = 19.5436s	
21577/29850 (epoch 36.142), train_loss = 0.96656449, grad/param norm = 2.4286e-01, time/batch = 15.4724s	
21578/29850 (epoch 36.144), train_loss = 1.05399489, grad/param norm = 2.3686e-01, time/batch = 16.2852s	
21579/29850 (epoch 36.146), train_loss = 1.07560992, grad/param norm = 2.4597e-01, time/batch = 18.7184s	
21580/29850 (epoch 36.147), train_loss = 0.94300796, grad/param norm = 2.5265e-01, time/batch = 15.8740s	
21581/29850 (epoch 36.149), train_loss = 0.89350593, grad/param norm = 2.3681e-01, time/batch = 18.5191s	
21582/29850 (epoch 36.151), train_loss = 0.89290584, grad/param norm = 2.2760e-01, time/batch = 17.7069s	
21583/29850 (epoch 36.152), train_loss = 0.80911340, grad/param norm = 2.0154e-01, time/batch = 18.0613s	
21584/29850 (epoch 36.154), train_loss = 0.78104414, grad/param norm = 2.2386e-01, time/batch = 15.6221s	
21585/29850 (epoch 36.156), train_loss = 0.78019683, grad/param norm = 2.1609e-01, time/batch = 16.4531s	
21586/29850 (epoch 36.157), train_loss = 0.89632203, grad/param norm = 2.2165e-01, time/batch = 17.7916s	
21587/29850 (epoch 36.159), train_loss = 0.80480927, grad/param norm = 1.9133e-01, time/batch = 18.2214s	
21588/29850 (epoch 36.161), train_loss = 0.83638134, grad/param norm = 2.3795e-01, time/batch = 17.4676s	
21589/29850 (epoch 36.162), train_loss = 0.95440346, grad/param norm = 2.3480e-01, time/batch = 17.9518s	
21590/29850 (epoch 36.164), train_loss = 0.89890969, grad/param norm = 2.5068e-01, time/batch = 16.5221s	
21591/29850 (epoch 36.166), train_loss = 0.80829516, grad/param norm = 2.1274e-01, time/batch = 19.1142s	
21592/29850 (epoch 36.168), train_loss = 0.73107306, grad/param norm = 1.9012e-01, time/batch = 17.3626s	
21593/29850 (epoch 36.169), train_loss = 0.97099474, grad/param norm = 2.4643e-01, time/batch = 18.5546s	
21594/29850 (epoch 36.171), train_loss = 0.89308688, grad/param norm = 2.0859e-01, time/batch = 17.1264s	
21595/29850 (epoch 36.173), train_loss = 0.74796240, grad/param norm = 2.0715e-01, time/batch = 17.1268s	
21596/29850 (epoch 36.174), train_loss = 0.86710918, grad/param norm = 2.4548e-01, time/batch = 16.0393s	
21597/29850 (epoch 36.176), train_loss = 0.84893749, grad/param norm = 2.2024e-01, time/batch = 17.4567s	
21598/29850 (epoch 36.178), train_loss = 0.88792667, grad/param norm = 2.4346e-01, time/batch = 19.1194s	
21599/29850 (epoch 36.179), train_loss = 0.71262056, grad/param norm = 2.2382e-01, time/batch = 16.1180s	
21600/29850 (epoch 36.181), train_loss = 0.86051557, grad/param norm = 2.1383e-01, time/batch = 18.3764s	
21601/29850 (epoch 36.183), train_loss = 0.85661169, grad/param norm = 1.9800e-01, time/batch = 19.4566s	
21602/29850 (epoch 36.184), train_loss = 0.88756862, grad/param norm = 2.2429e-01, time/batch = 17.8704s	
21603/29850 (epoch 36.186), train_loss = 0.87142856, grad/param norm = 2.3233e-01, time/batch = 18.8797s	
21604/29850 (epoch 36.188), train_loss = 0.98317041, grad/param norm = 2.4149e-01, time/batch = 16.6918s	
21605/29850 (epoch 36.189), train_loss = 0.93406167, grad/param norm = 2.5194e-01, time/batch = 16.4699s	
21606/29850 (epoch 36.191), train_loss = 0.94011931, grad/param norm = 2.3297e-01, time/batch = 16.1295s	
21607/29850 (epoch 36.193), train_loss = 0.83743975, grad/param norm = 2.0952e-01, time/batch = 19.4529s	
21608/29850 (epoch 36.194), train_loss = 0.92789903, grad/param norm = 2.1928e-01, time/batch = 19.2047s	
21609/29850 (epoch 36.196), train_loss = 0.83897251, grad/param norm = 2.3734e-01, time/batch = 18.9273s	
21610/29850 (epoch 36.198), train_loss = 0.81417376, grad/param norm = 2.4007e-01, time/batch = 17.4523s	
21611/29850 (epoch 36.199), train_loss = 1.04494042, grad/param norm = 2.4226e-01, time/batch = 18.3723s	
21612/29850 (epoch 36.201), train_loss = 0.78076217, grad/param norm = 2.1101e-01, time/batch = 17.5318s	
21613/29850 (epoch 36.203), train_loss = 0.64308924, grad/param norm = 2.1846e-01, time/batch = 17.4681s	
21614/29850 (epoch 36.204), train_loss = 0.82365857, grad/param norm = 2.3810e-01, time/batch = 18.3957s	
21615/29850 (epoch 36.206), train_loss = 0.75161480, grad/param norm = 2.6243e-01, time/batch = 17.6944s	
21616/29850 (epoch 36.208), train_loss = 0.99794330, grad/param norm = 2.5549e-01, time/batch = 16.8737s	
21617/29850 (epoch 36.209), train_loss = 0.73953313, grad/param norm = 1.8344e-01, time/batch = 16.5662s	
21618/29850 (epoch 36.211), train_loss = 0.81455957, grad/param norm = 2.2554e-01, time/batch = 18.6131s	
21619/29850 (epoch 36.213), train_loss = 0.90227676, grad/param norm = 2.3893e-01, time/batch = 17.3648s	
21620/29850 (epoch 36.214), train_loss = 0.73284702, grad/param norm = 1.8032e-01, time/batch = 16.2523s	
21621/29850 (epoch 36.216), train_loss = 0.76951981, grad/param norm = 2.1166e-01, time/batch = 18.8002s	
21622/29850 (epoch 36.218), train_loss = 0.87170913, grad/param norm = 2.0948e-01, time/batch = 17.0382s	
21623/29850 (epoch 36.219), train_loss = 0.89007459, grad/param norm = 2.6202e-01, time/batch = 15.4606s	
21624/29850 (epoch 36.221), train_loss = 0.84650900, grad/param norm = 2.5598e-01, time/batch = 18.7042s	
21625/29850 (epoch 36.223), train_loss = 0.71839177, grad/param norm = 2.1888e-01, time/batch = 17.6033s	
21626/29850 (epoch 36.224), train_loss = 0.70572362, grad/param norm = 1.9936e-01, time/batch = 17.2961s	
21627/29850 (epoch 36.226), train_loss = 0.75822023, grad/param norm = 1.8715e-01, time/batch = 18.2192s	
21628/29850 (epoch 36.228), train_loss = 0.80960609, grad/param norm = 2.3544e-01, time/batch = 16.8875s	
21629/29850 (epoch 36.229), train_loss = 0.66974519, grad/param norm = 1.8031e-01, time/batch = 16.4505s	
21630/29850 (epoch 36.231), train_loss = 0.83600181, grad/param norm = 2.0764e-01, time/batch = 17.3883s	
21631/29850 (epoch 36.233), train_loss = 0.81667617, grad/param norm = 2.0627e-01, time/batch = 14.9867s	
21632/29850 (epoch 36.235), train_loss = 0.77690020, grad/param norm = 1.9232e-01, time/batch = 17.0601s	
21633/29850 (epoch 36.236), train_loss = 0.98879147, grad/param norm = 3.2165e-01, time/batch = 16.2925s	
21634/29850 (epoch 36.238), train_loss = 0.72921209, grad/param norm = 2.1671e-01, time/batch = 19.3798s	
21635/29850 (epoch 36.240), train_loss = 0.72125881, grad/param norm = 2.1039e-01, time/batch = 17.3827s	
21636/29850 (epoch 36.241), train_loss = 0.87800617, grad/param norm = 2.3801e-01, time/batch = 16.3714s	
21637/29850 (epoch 36.243), train_loss = 0.87615542, grad/param norm = 2.1377e-01, time/batch = 19.2079s	
21638/29850 (epoch 36.245), train_loss = 0.76501402, grad/param norm = 2.1517e-01, time/batch = 18.5405s	
21639/29850 (epoch 36.246), train_loss = 0.72305145, grad/param norm = 1.7134e-01, time/batch = 17.8440s	
21640/29850 (epoch 36.248), train_loss = 0.70963141, grad/param norm = 1.9081e-01, time/batch = 16.4500s	
21641/29850 (epoch 36.250), train_loss = 0.79301568, grad/param norm = 1.9707e-01, time/batch = 19.0393s	
21642/29850 (epoch 36.251), train_loss = 0.69025392, grad/param norm = 2.1515e-01, time/batch = 16.3677s	
21643/29850 (epoch 36.253), train_loss = 0.68216068, grad/param norm = 2.0147e-01, time/batch = 17.2776s	
21644/29850 (epoch 36.255), train_loss = 0.72778338, grad/param norm = 2.0143e-01, time/batch = 18.5442s	
21645/29850 (epoch 36.256), train_loss = 0.87617268, grad/param norm = 2.5145e-01, time/batch = 18.3676s	
21646/29850 (epoch 36.258), train_loss = 0.87986583, grad/param norm = 2.1926e-01, time/batch = 16.9449s	
21647/29850 (epoch 36.260), train_loss = 0.80914887, grad/param norm = 1.9881e-01, time/batch = 18.3031s	
21648/29850 (epoch 36.261), train_loss = 0.74626888, grad/param norm = 2.1387e-01, time/batch = 17.4411s	
21649/29850 (epoch 36.263), train_loss = 0.75797967, grad/param norm = 1.9802e-01, time/batch = 17.2898s	
21650/29850 (epoch 36.265), train_loss = 0.81799257, grad/param norm = 2.2361e-01, time/batch = 16.6217s	
21651/29850 (epoch 36.266), train_loss = 0.81997277, grad/param norm = 2.3793e-01, time/batch = 17.3033s	
21652/29850 (epoch 36.268), train_loss = 0.79726467, grad/param norm = 2.0654e-01, time/batch = 17.5504s	
21653/29850 (epoch 36.270), train_loss = 0.78440137, grad/param norm = 2.6840e-01, time/batch = 17.4639s	
21654/29850 (epoch 36.271), train_loss = 0.86229023, grad/param norm = 2.6719e-01, time/batch = 17.1454s	
21655/29850 (epoch 36.273), train_loss = 0.73685205, grad/param norm = 2.4084e-01, time/batch = 17.3590s	
21656/29850 (epoch 36.275), train_loss = 0.71508855, grad/param norm = 2.1014e-01, time/batch = 18.3509s	
21657/29850 (epoch 36.276), train_loss = 0.71555841, grad/param norm = 1.9635e-01, time/batch = 16.1939s	
21658/29850 (epoch 36.278), train_loss = 0.79832140, grad/param norm = 2.3085e-01, time/batch = 15.5307s	
21659/29850 (epoch 36.280), train_loss = 1.00766615, grad/param norm = 2.9960e-01, time/batch = 19.2880s	
21660/29850 (epoch 36.281), train_loss = 0.85904917, grad/param norm = 2.2223e-01, time/batch = 16.3602s	
21661/29850 (epoch 36.283), train_loss = 0.93159978, grad/param norm = 2.7682e-01, time/batch = 17.6191s	
21662/29850 (epoch 36.285), train_loss = 0.91238462, grad/param norm = 2.1550e-01, time/batch = 19.3696s	
21663/29850 (epoch 36.286), train_loss = 0.91615987, grad/param norm = 2.4845e-01, time/batch = 14.5828s	
21664/29850 (epoch 36.288), train_loss = 0.91342231, grad/param norm = 2.8629e-01, time/batch = 17.9595s	
21665/29850 (epoch 36.290), train_loss = 0.86292326, grad/param norm = 2.5639e-01, time/batch = 18.0504s	
21666/29850 (epoch 36.291), train_loss = 1.06604410, grad/param norm = 2.5734e-01, time/batch = 18.6290s	
21667/29850 (epoch 36.293), train_loss = 0.96164386, grad/param norm = 2.6092e-01, time/batch = 17.9437s	
21668/29850 (epoch 36.295), train_loss = 1.01162888, grad/param norm = 2.0820e-01, time/batch = 16.4666s	
21669/29850 (epoch 36.296), train_loss = 0.76151913, grad/param norm = 1.9513e-01, time/batch = 19.1305s	
21670/29850 (epoch 36.298), train_loss = 0.65617450, grad/param norm = 1.8886e-01, time/batch = 16.8676s	
21671/29850 (epoch 36.300), train_loss = 0.73506185, grad/param norm = 1.9460e-01, time/batch = 19.7111s	
21672/29850 (epoch 36.302), train_loss = 0.72062546, grad/param norm = 2.1049e-01, time/batch = 16.9678s	
21673/29850 (epoch 36.303), train_loss = 0.79046959, grad/param norm = 2.4914e-01, time/batch = 18.2774s	
21674/29850 (epoch 36.305), train_loss = 0.90863546, grad/param norm = 2.1136e-01, time/batch = 16.6946s	
21675/29850 (epoch 36.307), train_loss = 0.91396386, grad/param norm = 2.1282e-01, time/batch = 16.7777s	
21676/29850 (epoch 36.308), train_loss = 0.73771052, grad/param norm = 2.2510e-01, time/batch = 18.8001s	
21677/29850 (epoch 36.310), train_loss = 0.87750701, grad/param norm = 2.3119e-01, time/batch = 16.5140s	
21678/29850 (epoch 36.312), train_loss = 0.91625066, grad/param norm = 2.1128e-01, time/batch = 18.1190s	
21679/29850 (epoch 36.313), train_loss = 0.85933823, grad/param norm = 2.4867e-01, time/batch = 19.2900s	
21680/29850 (epoch 36.315), train_loss = 0.85199319, grad/param norm = 2.0182e-01, time/batch = 16.1949s	
21681/29850 (epoch 36.317), train_loss = 0.84306761, grad/param norm = 2.1602e-01, time/batch = 18.0523s	
21682/29850 (epoch 36.318), train_loss = 0.82877357, grad/param norm = 2.2683e-01, time/batch = 17.5406s	
21683/29850 (epoch 36.320), train_loss = 0.76024983, grad/param norm = 1.9573e-01, time/batch = 18.0286s	
21684/29850 (epoch 36.322), train_loss = 0.97070611, grad/param norm = 2.4598e-01, time/batch = 16.0394s	
21685/29850 (epoch 36.323), train_loss = 0.88388362, grad/param norm = 2.4270e-01, time/batch = 17.6235s	
21686/29850 (epoch 36.325), train_loss = 0.93216325, grad/param norm = 2.0693e-01, time/batch = 18.4695s	
21687/29850 (epoch 36.327), train_loss = 1.05012922, grad/param norm = 2.4110e-01, time/batch = 16.9564s	
21688/29850 (epoch 36.328), train_loss = 0.96703581, grad/param norm = 2.9151e-01, time/batch = 19.1245s	
21689/29850 (epoch 36.330), train_loss = 0.92586052, grad/param norm = 2.1692e-01, time/batch = 17.9419s	
21690/29850 (epoch 36.332), train_loss = 0.81085778, grad/param norm = 2.1159e-01, time/batch = 17.6228s	
21691/29850 (epoch 36.333), train_loss = 0.88209172, grad/param norm = 2.1450e-01, time/batch = 17.1104s	
21692/29850 (epoch 36.335), train_loss = 0.95989861, grad/param norm = 2.3758e-01, time/batch = 18.1314s	
21693/29850 (epoch 36.337), train_loss = 0.86087456, grad/param norm = 2.6834e-01, time/batch = 17.7001s	
21694/29850 (epoch 36.338), train_loss = 0.89964860, grad/param norm = 2.3645e-01, time/batch = 16.4559s	
21695/29850 (epoch 36.340), train_loss = 0.73220947, grad/param norm = 1.9714e-01, time/batch = 19.1926s	
21696/29850 (epoch 36.342), train_loss = 0.87681453, grad/param norm = 2.4187e-01, time/batch = 17.6400s	
21697/29850 (epoch 36.343), train_loss = 0.85989988, grad/param norm = 2.8675e-01, time/batch = 17.6219s	
21698/29850 (epoch 36.345), train_loss = 0.92568612, grad/param norm = 2.4922e-01, time/batch = 17.3706s	
21699/29850 (epoch 36.347), train_loss = 0.94261208, grad/param norm = 2.5494e-01, time/batch = 19.3849s	
21700/29850 (epoch 36.348), train_loss = 0.80293010, grad/param norm = 2.4405e-01, time/batch = 16.2061s	
21701/29850 (epoch 36.350), train_loss = 0.91690970, grad/param norm = 2.4718e-01, time/batch = 16.7333s	
21702/29850 (epoch 36.352), train_loss = 0.80611521, grad/param norm = 2.1102e-01, time/batch = 17.7835s	
21703/29850 (epoch 36.353), train_loss = 0.89092771, grad/param norm = 2.2891e-01, time/batch = 17.9848s	
21704/29850 (epoch 36.355), train_loss = 0.82115396, grad/param norm = 2.2321e-01, time/batch = 18.4452s	
21705/29850 (epoch 36.357), train_loss = 0.93256964, grad/param norm = 2.2877e-01, time/batch = 17.8892s	
21706/29850 (epoch 36.358), train_loss = 0.77873857, grad/param norm = 2.2744e-01, time/batch = 19.5496s	
21707/29850 (epoch 36.360), train_loss = 0.82815978, grad/param norm = 2.1073e-01, time/batch = 16.7060s	
21708/29850 (epoch 36.362), train_loss = 0.83570559, grad/param norm = 2.5933e-01, time/batch = 15.8509s	
21709/29850 (epoch 36.363), train_loss = 0.89561635, grad/param norm = 2.4240e-01, time/batch = 19.5474s	
21710/29850 (epoch 36.365), train_loss = 0.98000750, grad/param norm = 2.7570e-01, time/batch = 17.0466s	
21711/29850 (epoch 36.367), train_loss = 0.75979868, grad/param norm = 1.9374e-01, time/batch = 16.1092s	
21712/29850 (epoch 36.369), train_loss = 0.71578163, grad/param norm = 2.1788e-01, time/batch = 15.8670s	
21713/29850 (epoch 36.370), train_loss = 0.69982963, grad/param norm = 2.0940e-01, time/batch = 18.8811s	
21714/29850 (epoch 36.372), train_loss = 0.94240359, grad/param norm = 2.2672e-01, time/batch = 17.7013s	
21715/29850 (epoch 36.374), train_loss = 0.91494848, grad/param norm = 2.1313e-01, time/batch = 18.8820s	
21716/29850 (epoch 36.375), train_loss = 0.85988505, grad/param norm = 2.0102e-01, time/batch = 19.3729s	
21717/29850 (epoch 36.377), train_loss = 0.78188362, grad/param norm = 2.3429e-01, time/batch = 28.1500s	
21718/29850 (epoch 36.379), train_loss = 0.97912605, grad/param norm = 2.9275e-01, time/batch = 21.7970s	
21719/29850 (epoch 36.380), train_loss = 0.89603125, grad/param norm = 2.5490e-01, time/batch = 17.0648s	
21720/29850 (epoch 36.382), train_loss = 0.85929149, grad/param norm = 2.3683e-01, time/batch = 16.6220s	
21721/29850 (epoch 36.384), train_loss = 0.91815899, grad/param norm = 2.2197e-01, time/batch = 17.4618s	
21722/29850 (epoch 36.385), train_loss = 0.89367224, grad/param norm = 2.2538e-01, time/batch = 17.3029s	
21723/29850 (epoch 36.387), train_loss = 0.90084462, grad/param norm = 2.7546e-01, time/batch = 16.7975s	
21724/29850 (epoch 36.389), train_loss = 0.98152839, grad/param norm = 2.5050e-01, time/batch = 17.1221s	
21725/29850 (epoch 36.390), train_loss = 0.93236219, grad/param norm = 2.2176e-01, time/batch = 17.7000s	
21726/29850 (epoch 36.392), train_loss = 0.84431360, grad/param norm = 2.6752e-01, time/batch = 18.6896s	
21727/29850 (epoch 36.394), train_loss = 0.92268614, grad/param norm = 2.1756e-01, time/batch = 19.0315s	
21728/29850 (epoch 36.395), train_loss = 0.80994576, grad/param norm = 3.1457e-01, time/batch = 18.4369s	
21729/29850 (epoch 36.397), train_loss = 0.77062214, grad/param norm = 2.5064e-01, time/batch = 19.7046s	
21730/29850 (epoch 36.399), train_loss = 0.79528171, grad/param norm = 2.7318e-01, time/batch = 16.2232s	
21731/29850 (epoch 36.400), train_loss = 1.13707132, grad/param norm = 2.6675e-01, time/batch = 19.5246s	
21732/29850 (epoch 36.402), train_loss = 1.01781558, grad/param norm = 2.4465e-01, time/batch = 16.4535s	
21733/29850 (epoch 36.404), train_loss = 0.88098380, grad/param norm = 2.3386e-01, time/batch = 16.4577s	
21734/29850 (epoch 36.405), train_loss = 0.80642332, grad/param norm = 2.6027e-01, time/batch = 16.3735s	
21735/29850 (epoch 36.407), train_loss = 0.77647940, grad/param norm = 1.9256e-01, time/batch = 18.7894s	
21736/29850 (epoch 36.409), train_loss = 0.87996051, grad/param norm = 2.2525e-01, time/batch = 19.0971s	
21737/29850 (epoch 36.410), train_loss = 0.96662449, grad/param norm = 2.3986e-01, time/batch = 18.2030s	
21738/29850 (epoch 36.412), train_loss = 0.96940483, grad/param norm = 2.4565e-01, time/batch = 16.9699s	
21739/29850 (epoch 36.414), train_loss = 0.90718047, grad/param norm = 2.5927e-01, time/batch = 17.9646s	
21740/29850 (epoch 36.415), train_loss = 0.85127879, grad/param norm = 2.2022e-01, time/batch = 18.8609s	
21741/29850 (epoch 36.417), train_loss = 0.99132441, grad/param norm = 2.4636e-01, time/batch = 15.2845s	
21742/29850 (epoch 36.419), train_loss = 0.84565237, grad/param norm = 2.3544e-01, time/batch = 17.6954s	
21743/29850 (epoch 36.420), train_loss = 0.86937475, grad/param norm = 2.5112e-01, time/batch = 16.7091s	
21744/29850 (epoch 36.422), train_loss = 0.85682547, grad/param norm = 2.2502e-01, time/batch = 18.6270s	
21745/29850 (epoch 36.424), train_loss = 0.78888725, grad/param norm = 2.0540e-01, time/batch = 16.0606s	
21746/29850 (epoch 36.425), train_loss = 0.94941396, grad/param norm = 2.7229e-01, time/batch = 18.9680s	
21747/29850 (epoch 36.427), train_loss = 0.67386949, grad/param norm = 1.9429e-01, time/batch = 17.7738s	
21748/29850 (epoch 36.429), train_loss = 0.75989564, grad/param norm = 2.2484e-01, time/batch = 17.2994s	
21749/29850 (epoch 36.430), train_loss = 0.70884155, grad/param norm = 1.8342e-01, time/batch = 19.2941s	
21750/29850 (epoch 36.432), train_loss = 0.79282962, grad/param norm = 2.3778e-01, time/batch = 16.1224s	
21751/29850 (epoch 36.434), train_loss = 0.79453349, grad/param norm = 1.9999e-01, time/batch = 15.8912s	
21752/29850 (epoch 36.436), train_loss = 0.83344487, grad/param norm = 2.4505e-01, time/batch = 17.4742s	
21753/29850 (epoch 36.437), train_loss = 0.91475818, grad/param norm = 2.2077e-01, time/batch = 17.6075s	
21754/29850 (epoch 36.439), train_loss = 0.89765739, grad/param norm = 2.1063e-01, time/batch = 17.2861s	
21755/29850 (epoch 36.441), train_loss = 0.87342945, grad/param norm = 2.3902e-01, time/batch = 15.2267s	
21756/29850 (epoch 36.442), train_loss = 0.82281014, grad/param norm = 2.2533e-01, time/batch = 18.2824s	
21757/29850 (epoch 36.444), train_loss = 0.88114573, grad/param norm = 2.3047e-01, time/batch = 16.2613s	
21758/29850 (epoch 36.446), train_loss = 0.92430775, grad/param norm = 2.1622e-01, time/batch = 16.5621s	
21759/29850 (epoch 36.447), train_loss = 0.92066101, grad/param norm = 2.3690e-01, time/batch = 16.7949s	
21760/29850 (epoch 36.449), train_loss = 0.89023440, grad/param norm = 2.6164e-01, time/batch = 18.3036s	
21761/29850 (epoch 36.451), train_loss = 0.67913417, grad/param norm = 2.0420e-01, time/batch = 15.7177s	
21762/29850 (epoch 36.452), train_loss = 0.58631811, grad/param norm = 1.7498e-01, time/batch = 18.0605s	
21763/29850 (epoch 36.454), train_loss = 0.71485437, grad/param norm = 1.8297e-01, time/batch = 18.8908s	
21764/29850 (epoch 36.456), train_loss = 0.92786424, grad/param norm = 2.4622e-01, time/batch = 17.5388s	
21765/29850 (epoch 36.457), train_loss = 0.94996254, grad/param norm = 4.0150e-01, time/batch = 18.5464s	
21766/29850 (epoch 36.459), train_loss = 1.01711878, grad/param norm = 2.4436e-01, time/batch = 17.4766s	
21767/29850 (epoch 36.461), train_loss = 0.99306046, grad/param norm = 2.5116e-01, time/batch = 17.2589s	
21768/29850 (epoch 36.462), train_loss = 1.01087502, grad/param norm = 2.5777e-01, time/batch = 18.2769s	
21769/29850 (epoch 36.464), train_loss = 0.89415921, grad/param norm = 2.1212e-01, time/batch = 17.2293s	
21770/29850 (epoch 36.466), train_loss = 0.74152389, grad/param norm = 2.2764e-01, time/batch = 18.9525s	
21771/29850 (epoch 36.467), train_loss = 0.78633559, grad/param norm = 2.3221e-01, time/batch = 16.7013s	
21772/29850 (epoch 36.469), train_loss = 0.81940935, grad/param norm = 2.1596e-01, time/batch = 18.5385s	
21773/29850 (epoch 36.471), train_loss = 0.84101739, grad/param norm = 2.3878e-01, time/batch = 14.4939s	
21774/29850 (epoch 36.472), train_loss = 0.78123202, grad/param norm = 2.1135e-01, time/batch = 17.2997s	
21775/29850 (epoch 36.474), train_loss = 0.93842661, grad/param norm = 2.3203e-01, time/batch = 16.5081s	
21776/29850 (epoch 36.476), train_loss = 0.86570843, grad/param norm = 2.1466e-01, time/batch = 18.2117s	
21777/29850 (epoch 36.477), train_loss = 0.86843115, grad/param norm = 2.2034e-01, time/batch = 16.3733s	
21778/29850 (epoch 36.479), train_loss = 1.03541266, grad/param norm = 2.5026e-01, time/batch = 17.0313s	
21779/29850 (epoch 36.481), train_loss = 0.85471873, grad/param norm = 2.3745e-01, time/batch = 19.8681s	
21780/29850 (epoch 36.482), train_loss = 0.78522419, grad/param norm = 1.8653e-01, time/batch = 19.0481s	
21781/29850 (epoch 36.484), train_loss = 0.82425971, grad/param norm = 2.6423e-01, time/batch = 16.2920s	
21782/29850 (epoch 36.486), train_loss = 0.89149903, grad/param norm = 2.5965e-01, time/batch = 19.7118s	
21783/29850 (epoch 36.487), train_loss = 0.85702344, grad/param norm = 2.0763e-01, time/batch = 19.1305s	
21784/29850 (epoch 36.489), train_loss = 0.87244483, grad/param norm = 2.2311e-01, time/batch = 15.5356s	
21785/29850 (epoch 36.491), train_loss = 0.77829503, grad/param norm = 2.2208e-01, time/batch = 17.1311s	
21786/29850 (epoch 36.492), train_loss = 0.86535794, grad/param norm = 2.2065e-01, time/batch = 15.9832s	
21787/29850 (epoch 36.494), train_loss = 0.91677951, grad/param norm = 2.0431e-01, time/batch = 18.7376s	
21788/29850 (epoch 36.496), train_loss = 0.96051089, grad/param norm = 2.2751e-01, time/batch = 16.2741s	
21789/29850 (epoch 36.497), train_loss = 0.89627332, grad/param norm = 2.1167e-01, time/batch = 18.2206s	
21790/29850 (epoch 36.499), train_loss = 0.86209122, grad/param norm = 2.0833e-01, time/batch = 19.0467s	
21791/29850 (epoch 36.501), train_loss = 0.76305322, grad/param norm = 2.3856e-01, time/batch = 16.1182s	
21792/29850 (epoch 36.503), train_loss = 0.91201754, grad/param norm = 2.1035e-01, time/batch = 16.9593s	
21793/29850 (epoch 36.504), train_loss = 1.05857961, grad/param norm = 2.3265e-01, time/batch = 16.9683s	
21794/29850 (epoch 36.506), train_loss = 1.04409482, grad/param norm = 2.7681e-01, time/batch = 18.1244s	
21795/29850 (epoch 36.508), train_loss = 0.89607179, grad/param norm = 2.4526e-01, time/batch = 17.9509s	
21796/29850 (epoch 36.509), train_loss = 0.69148933, grad/param norm = 1.9832e-01, time/batch = 17.5271s	
21797/29850 (epoch 36.511), train_loss = 0.89559522, grad/param norm = 2.3383e-01, time/batch = 19.3816s	
21798/29850 (epoch 36.513), train_loss = 0.85640724, grad/param norm = 2.6171e-01, time/batch = 16.7827s	
21799/29850 (epoch 36.514), train_loss = 0.76343790, grad/param norm = 2.4735e-01, time/batch = 17.3855s	
21800/29850 (epoch 36.516), train_loss = 0.81797266, grad/param norm = 1.8189e-01, time/batch = 15.1192s	
21801/29850 (epoch 36.518), train_loss = 0.69347525, grad/param norm = 1.8894e-01, time/batch = 18.2055s	
21802/29850 (epoch 36.519), train_loss = 0.68499371, grad/param norm = 1.8562e-01, time/batch = 16.1877s	
21803/29850 (epoch 36.521), train_loss = 0.63812039, grad/param norm = 1.7490e-01, time/batch = 18.3708s	
21804/29850 (epoch 36.523), train_loss = 0.71356917, grad/param norm = 1.8452e-01, time/batch = 17.8749s	
21805/29850 (epoch 36.524), train_loss = 0.74390803, grad/param norm = 2.2312e-01, time/batch = 16.7942s	
21806/29850 (epoch 36.526), train_loss = 0.81968029, grad/param norm = 2.6861e-01, time/batch = 16.2826s	
21807/29850 (epoch 36.528), train_loss = 0.90507256, grad/param norm = 2.3077e-01, time/batch = 17.6397s	
21808/29850 (epoch 36.529), train_loss = 0.88780116, grad/param norm = 2.5484e-01, time/batch = 19.0312s	
21809/29850 (epoch 36.531), train_loss = 0.83493211, grad/param norm = 2.5871e-01, time/batch = 16.9772s	
21810/29850 (epoch 36.533), train_loss = 0.85197695, grad/param norm = 2.3091e-01, time/batch = 18.7702s	
21811/29850 (epoch 36.534), train_loss = 0.90343260, grad/param norm = 2.2852e-01, time/batch = 18.9389s	
21812/29850 (epoch 36.536), train_loss = 0.79748569, grad/param norm = 2.3402e-01, time/batch = 17.3043s	
21813/29850 (epoch 36.538), train_loss = 0.96210469, grad/param norm = 2.6304e-01, time/batch = 18.7151s	
21814/29850 (epoch 36.539), train_loss = 0.99996024, grad/param norm = 2.7416e-01, time/batch = 17.3077s	
21815/29850 (epoch 36.541), train_loss = 0.62791049, grad/param norm = 1.9166e-01, time/batch = 16.2997s	
21816/29850 (epoch 36.543), train_loss = 0.80872977, grad/param norm = 2.2728e-01, time/batch = 19.2126s	
21817/29850 (epoch 36.544), train_loss = 0.92519700, grad/param norm = 2.1436e-01, time/batch = 17.0643s	
21818/29850 (epoch 36.546), train_loss = 0.91168782, grad/param norm = 2.2700e-01, time/batch = 16.6438s	
21819/29850 (epoch 36.548), train_loss = 0.71275349, grad/param norm = 1.9011e-01, time/batch = 17.2849s	
21820/29850 (epoch 36.549), train_loss = 0.79415991, grad/param norm = 2.0642e-01, time/batch = 17.9552s	
21821/29850 (epoch 36.551), train_loss = 0.76342860, grad/param norm = 2.2598e-01, time/batch = 17.8734s	
21822/29850 (epoch 36.553), train_loss = 0.85275469, grad/param norm = 2.3321e-01, time/batch = 15.6811s	
21823/29850 (epoch 36.554), train_loss = 0.70320539, grad/param norm = 1.8672e-01, time/batch = 19.1209s	
21824/29850 (epoch 36.556), train_loss = 0.73121990, grad/param norm = 2.0583e-01, time/batch = 15.7909s	
21825/29850 (epoch 36.558), train_loss = 0.75811411, grad/param norm = 2.0292e-01, time/batch = 16.2042s	
21826/29850 (epoch 36.559), train_loss = 0.78432567, grad/param norm = 2.3076e-01, time/batch = 16.3802s	
21827/29850 (epoch 36.561), train_loss = 0.85407394, grad/param norm = 2.2830e-01, time/batch = 18.2188s	
21828/29850 (epoch 36.563), train_loss = 0.86928243, grad/param norm = 2.2865e-01, time/batch = 19.3543s	
21829/29850 (epoch 36.564), train_loss = 0.80609930, grad/param norm = 2.6640e-01, time/batch = 18.0520s	
21830/29850 (epoch 36.566), train_loss = 0.83551229, grad/param norm = 2.1088e-01, time/batch = 17.4620s	
21831/29850 (epoch 36.568), train_loss = 0.96336312, grad/param norm = 2.5607e-01, time/batch = 18.1326s	
21832/29850 (epoch 36.570), train_loss = 0.89475024, grad/param norm = 2.6416e-01, time/batch = 16.9545s	
21833/29850 (epoch 36.571), train_loss = 0.93342239, grad/param norm = 2.1531e-01, time/batch = 18.7756s	
21834/29850 (epoch 36.573), train_loss = 0.99861638, grad/param norm = 2.2445e-01, time/batch = 17.9413s	
21835/29850 (epoch 36.575), train_loss = 1.03204316, grad/param norm = 2.3029e-01, time/batch = 17.3298s	
21836/29850 (epoch 36.576), train_loss = 0.92240168, grad/param norm = 2.3703e-01, time/batch = 18.1086s	
21837/29850 (epoch 36.578), train_loss = 0.78501052, grad/param norm = 1.9697e-01, time/batch = 19.1085s	
21838/29850 (epoch 36.580), train_loss = 0.95393010, grad/param norm = 2.8213e-01, time/batch = 17.4659s	
21839/29850 (epoch 36.581), train_loss = 0.76970176, grad/param norm = 2.1723e-01, time/batch = 17.9473s	
21840/29850 (epoch 36.583), train_loss = 0.83578918, grad/param norm = 2.1686e-01, time/batch = 18.2012s	
21841/29850 (epoch 36.585), train_loss = 0.85980984, grad/param norm = 2.1810e-01, time/batch = 16.7854s	
21842/29850 (epoch 36.586), train_loss = 0.88944721, grad/param norm = 2.2381e-01, time/batch = 17.7941s	
21843/29850 (epoch 36.588), train_loss = 0.78377674, grad/param norm = 2.1522e-01, time/batch = 16.1304s	
21844/29850 (epoch 36.590), train_loss = 0.79299846, grad/param norm = 2.0191e-01, time/batch = 19.3002s	
21845/29850 (epoch 36.591), train_loss = 0.83537155, grad/param norm = 2.3383e-01, time/batch = 17.7935s	
21846/29850 (epoch 36.593), train_loss = 0.75943860, grad/param norm = 1.9055e-01, time/batch = 18.3705s	
21847/29850 (epoch 36.595), train_loss = 0.72097192, grad/param norm = 1.8625e-01, time/batch = 19.3627s	
21848/29850 (epoch 36.596), train_loss = 0.73082096, grad/param norm = 2.0578e-01, time/batch = 16.2951s	
21849/29850 (epoch 36.598), train_loss = 0.82275787, grad/param norm = 1.9695e-01, time/batch = 17.9331s	
21850/29850 (epoch 36.600), train_loss = 0.87401575, grad/param norm = 2.1820e-01, time/batch = 18.3001s	
21851/29850 (epoch 36.601), train_loss = 0.73583593, grad/param norm = 1.8189e-01, time/batch = 15.8674s	
21852/29850 (epoch 36.603), train_loss = 0.78271011, grad/param norm = 2.0274e-01, time/batch = 15.7984s	
21853/29850 (epoch 36.605), train_loss = 0.82832946, grad/param norm = 2.0494e-01, time/batch = 17.2309s	
21854/29850 (epoch 36.606), train_loss = 0.59080096, grad/param norm = 2.0740e-01, time/batch = 17.3827s	
21855/29850 (epoch 36.608), train_loss = 0.74650065, grad/param norm = 2.0970e-01, time/batch = 18.6962s	
21856/29850 (epoch 36.610), train_loss = 0.80483687, grad/param norm = 2.1616e-01, time/batch = 19.0230s	
21857/29850 (epoch 36.611), train_loss = 0.72855889, grad/param norm = 1.8811e-01, time/batch = 19.1174s	
21858/29850 (epoch 36.613), train_loss = 0.62560087, grad/param norm = 1.6429e-01, time/batch = 19.2876s	
21859/29850 (epoch 36.615), train_loss = 0.69966260, grad/param norm = 1.8486e-01, time/batch = 18.4332s	
21860/29850 (epoch 36.616), train_loss = 0.73682748, grad/param norm = 2.8235e-01, time/batch = 16.8778s	
21861/29850 (epoch 36.618), train_loss = 0.81107748, grad/param norm = 2.1536e-01, time/batch = 19.2072s	
21862/29850 (epoch 36.620), train_loss = 0.87508779, grad/param norm = 2.4178e-01, time/batch = 15.5478s	
21863/29850 (epoch 36.621), train_loss = 0.95622748, grad/param norm = 2.5971e-01, time/batch = 18.0175s	
21864/29850 (epoch 36.623), train_loss = 0.90389734, grad/param norm = 2.1216e-01, time/batch = 19.1992s	
21865/29850 (epoch 36.625), train_loss = 0.82985830, grad/param norm = 2.4100e-01, time/batch = 17.0950s	
21866/29850 (epoch 36.626), train_loss = 0.86932687, grad/param norm = 2.7689e-01, time/batch = 18.1253s	
21867/29850 (epoch 36.628), train_loss = 0.82440587, grad/param norm = 2.1955e-01, time/batch = 18.5377s	
21868/29850 (epoch 36.630), train_loss = 0.84710101, grad/param norm = 2.4197e-01, time/batch = 18.2994s	
21869/29850 (epoch 36.631), train_loss = 0.87239152, grad/param norm = 2.5623e-01, time/batch = 17.0917s	
21870/29850 (epoch 36.633), train_loss = 0.87960938, grad/param norm = 2.5351e-01, time/batch = 17.2722s	
21871/29850 (epoch 36.635), train_loss = 0.80181721, grad/param norm = 2.4719e-01, time/batch = 18.1353s	
21872/29850 (epoch 36.637), train_loss = 0.74732086, grad/param norm = 1.9967e-01, time/batch = 17.5250s	
21873/29850 (epoch 36.638), train_loss = 0.87264516, grad/param norm = 2.4727e-01, time/batch = 15.6241s	
21874/29850 (epoch 36.640), train_loss = 0.96617029, grad/param norm = 2.5751e-01, time/batch = 18.6768s	
21875/29850 (epoch 36.642), train_loss = 0.79088413, grad/param norm = 2.2398e-01, time/batch = 18.5062s	
21876/29850 (epoch 36.643), train_loss = 0.77467484, grad/param norm = 2.2922e-01, time/batch = 18.0425s	
21877/29850 (epoch 36.645), train_loss = 0.84894313, grad/param norm = 2.2258e-01, time/batch = 18.2076s	
21878/29850 (epoch 36.647), train_loss = 0.95845294, grad/param norm = 2.3203e-01, time/batch = 17.3822s	
21879/29850 (epoch 36.648), train_loss = 0.74922705, grad/param norm = 2.0208e-01, time/batch = 16.6151s	
21880/29850 (epoch 36.650), train_loss = 0.86096654, grad/param norm = 2.3593e-01, time/batch = 19.2927s	
21881/29850 (epoch 36.652), train_loss = 0.84344273, grad/param norm = 2.3327e-01, time/batch = 18.5605s	
21882/29850 (epoch 36.653), train_loss = 0.93665019, grad/param norm = 2.3781e-01, time/batch = 15.2531s	
21883/29850 (epoch 36.655), train_loss = 0.85440097, grad/param norm = 2.0473e-01, time/batch = 17.8022s	
21884/29850 (epoch 36.657), train_loss = 0.85336108, grad/param norm = 2.2956e-01, time/batch = 20.0350s	
21885/29850 (epoch 36.658), train_loss = 0.96343368, grad/param norm = 2.2815e-01, time/batch = 18.1627s	
21886/29850 (epoch 36.660), train_loss = 0.79350491, grad/param norm = 2.3401e-01, time/batch = 15.4962s	
21887/29850 (epoch 36.662), train_loss = 0.95920357, grad/param norm = 2.8600e-01, time/batch = 18.8937s	
21888/29850 (epoch 36.663), train_loss = 1.03133558, grad/param norm = 2.4773e-01, time/batch = 18.7049s	
21889/29850 (epoch 36.665), train_loss = 0.97528340, grad/param norm = 2.8478e-01, time/batch = 16.8497s	
21890/29850 (epoch 36.667), train_loss = 0.89758259, grad/param norm = 2.4203e-01, time/batch = 17.4733s	
21891/29850 (epoch 36.668), train_loss = 0.82171441, grad/param norm = 2.5090e-01, time/batch = 19.6948s	
21892/29850 (epoch 36.670), train_loss = 0.94096131, grad/param norm = 2.6109e-01, time/batch = 17.7189s	
21893/29850 (epoch 36.672), train_loss = 0.93886994, grad/param norm = 2.6779e-01, time/batch = 16.8768s	
21894/29850 (epoch 36.673), train_loss = 0.87145750, grad/param norm = 2.2273e-01, time/batch = 16.7960s	
21895/29850 (epoch 36.675), train_loss = 0.76008703, grad/param norm = 2.0058e-01, time/batch = 16.7832s	
21896/29850 (epoch 36.677), train_loss = 0.81240658, grad/param norm = 2.5741e-01, time/batch = 19.4454s	
21897/29850 (epoch 36.678), train_loss = 0.82530070, grad/param norm = 2.1605e-01, time/batch = 17.4786s	
21898/29850 (epoch 36.680), train_loss = 0.83452161, grad/param norm = 2.5297e-01, time/batch = 18.3772s	
21899/29850 (epoch 36.682), train_loss = 0.85101507, grad/param norm = 2.2498e-01, time/batch = 17.4526s	
21900/29850 (epoch 36.683), train_loss = 0.97249173, grad/param norm = 2.7515e-01, time/batch = 17.7092s	
21901/29850 (epoch 36.685), train_loss = 1.04799618, grad/param norm = 2.7476e-01, time/batch = 18.7116s	
21902/29850 (epoch 36.687), train_loss = 0.87980700, grad/param norm = 2.2686e-01, time/batch = 16.6174s	
21903/29850 (epoch 36.688), train_loss = 0.75569691, grad/param norm = 2.3424e-01, time/batch = 18.9380s	
21904/29850 (epoch 36.690), train_loss = 0.75220714, grad/param norm = 1.9990e-01, time/batch = 18.7837s	
21905/29850 (epoch 36.692), train_loss = 0.95839774, grad/param norm = 2.8394e-01, time/batch = 17.0386s	
21906/29850 (epoch 36.693), train_loss = 0.84258813, grad/param norm = 2.2073e-01, time/batch = 17.1471s	
21907/29850 (epoch 36.695), train_loss = 0.75278911, grad/param norm = 1.8511e-01, time/batch = 18.3018s	
21908/29850 (epoch 36.697), train_loss = 0.83895005, grad/param norm = 2.2511e-01, time/batch = 18.9601s	
21909/29850 (epoch 36.698), train_loss = 0.95434679, grad/param norm = 2.1208e-01, time/batch = 17.1315s	
21910/29850 (epoch 36.700), train_loss = 0.92623893, grad/param norm = 2.8185e-01, time/batch = 16.5414s	
21911/29850 (epoch 36.702), train_loss = 0.86025401, grad/param norm = 2.1668e-01, time/batch = 17.6899s	
21912/29850 (epoch 36.704), train_loss = 0.71630802, grad/param norm = 1.7542e-01, time/batch = 17.8686s	
21913/29850 (epoch 36.705), train_loss = 0.86906968, grad/param norm = 2.4874e-01, time/batch = 16.9734s	
21914/29850 (epoch 36.707), train_loss = 0.77691476, grad/param norm = 2.2158e-01, time/batch = 18.6379s	
21915/29850 (epoch 36.709), train_loss = 0.84240613, grad/param norm = 2.5397e-01, time/batch = 18.9498s	
21916/29850 (epoch 36.710), train_loss = 0.77934495, grad/param norm = 2.3162e-01, time/batch = 17.6139s	
21917/29850 (epoch 36.712), train_loss = 0.87242080, grad/param norm = 2.0149e-01, time/batch = 16.4588s	
21918/29850 (epoch 36.714), train_loss = 0.94393220, grad/param norm = 2.4660e-01, time/batch = 18.5434s	
21919/29850 (epoch 36.715), train_loss = 0.85885976, grad/param norm = 2.3095e-01, time/batch = 26.0852s	
21920/29850 (epoch 36.717), train_loss = 0.62703761, grad/param norm = 2.1271e-01, time/batch = 20.3189s	
21921/29850 (epoch 36.719), train_loss = 0.80909656, grad/param norm = 2.1968e-01, time/batch = 17.6427s	
21922/29850 (epoch 36.720), train_loss = 0.82760570, grad/param norm = 2.0510e-01, time/batch = 18.3645s	
21923/29850 (epoch 36.722), train_loss = 0.77276635, grad/param norm = 1.9030e-01, time/batch = 19.4420s	
21924/29850 (epoch 36.724), train_loss = 0.87116144, grad/param norm = 2.4422e-01, time/batch = 18.6864s	
21925/29850 (epoch 36.725), train_loss = 0.75159218, grad/param norm = 1.9611e-01, time/batch = 15.3892s	
21926/29850 (epoch 36.727), train_loss = 0.75139109, grad/param norm = 2.2168e-01, time/batch = 16.6298s	
21927/29850 (epoch 36.729), train_loss = 0.69927681, grad/param norm = 1.6957e-01, time/batch = 19.3629s	
21928/29850 (epoch 36.730), train_loss = 0.67423378, grad/param norm = 1.9274e-01, time/batch = 18.0326s	
21929/29850 (epoch 36.732), train_loss = 0.93806498, grad/param norm = 2.0320e-01, time/batch = 19.2172s	
21930/29850 (epoch 36.734), train_loss = 1.01300125, grad/param norm = 2.5648e-01, time/batch = 16.0415s	
21931/29850 (epoch 36.735), train_loss = 0.76924628, grad/param norm = 2.3545e-01, time/batch = 19.1268s	
21932/29850 (epoch 36.737), train_loss = 0.73792618, grad/param norm = 2.2820e-01, time/batch = 17.8719s	
21933/29850 (epoch 36.739), train_loss = 0.66976140, grad/param norm = 2.3964e-01, time/batch = 17.0447s	
21934/29850 (epoch 36.740), train_loss = 0.71031146, grad/param norm = 2.2614e-01, time/batch = 16.1075s	
21935/29850 (epoch 36.742), train_loss = 0.64028708, grad/param norm = 1.6553e-01, time/batch = 16.5108s	
21936/29850 (epoch 36.744), train_loss = 0.76325655, grad/param norm = 2.4774e-01, time/batch = 15.8447s	
21937/29850 (epoch 36.745), train_loss = 0.78476708, grad/param norm = 2.0816e-01, time/batch = 18.2567s	
21938/29850 (epoch 36.747), train_loss = 0.81562950, grad/param norm = 2.2094e-01, time/batch = 18.0477s	
21939/29850 (epoch 36.749), train_loss = 0.71597874, grad/param norm = 2.1448e-01, time/batch = 17.7538s	
21940/29850 (epoch 36.750), train_loss = 0.66670595, grad/param norm = 2.1560e-01, time/batch = 18.2093s	
21941/29850 (epoch 36.752), train_loss = 0.58963607, grad/param norm = 1.9353e-01, time/batch = 18.4574s	
21942/29850 (epoch 36.754), train_loss = 0.64989423, grad/param norm = 2.2024e-01, time/batch = 15.0582s	
21943/29850 (epoch 36.755), train_loss = 0.66535689, grad/param norm = 2.2174e-01, time/batch = 16.2200s	
21944/29850 (epoch 36.757), train_loss = 0.71469486, grad/param norm = 1.8155e-01, time/batch = 18.3824s	
21945/29850 (epoch 36.759), train_loss = 0.72616383, grad/param norm = 1.9639e-01, time/batch = 18.1087s	
21946/29850 (epoch 36.760), train_loss = 0.74779776, grad/param norm = 2.1523e-01, time/batch = 16.4908s	
21947/29850 (epoch 36.762), train_loss = 0.68189626, grad/param norm = 2.5591e-01, time/batch = 18.5505s	
21948/29850 (epoch 36.764), train_loss = 0.60981736, grad/param norm = 2.2723e-01, time/batch = 17.6292s	
21949/29850 (epoch 36.765), train_loss = 0.77012912, grad/param norm = 2.2957e-01, time/batch = 15.7925s	
21950/29850 (epoch 36.767), train_loss = 0.76922625, grad/param norm = 2.0953e-01, time/batch = 17.5657s	
21951/29850 (epoch 36.769), train_loss = 0.79794093, grad/param norm = 2.2796e-01, time/batch = 19.3823s	
21952/29850 (epoch 36.771), train_loss = 0.84870131, grad/param norm = 2.1441e-01, time/batch = 16.1123s	
21953/29850 (epoch 36.772), train_loss = 0.81783571, grad/param norm = 2.2550e-01, time/batch = 17.7971s	
21954/29850 (epoch 36.774), train_loss = 0.75540963, grad/param norm = 2.2746e-01, time/batch = 17.8791s	
21955/29850 (epoch 36.776), train_loss = 0.77707604, grad/param norm = 2.2614e-01, time/batch = 18.6335s	
21956/29850 (epoch 36.777), train_loss = 0.87731415, grad/param norm = 2.2435e-01, time/batch = 18.5446s	
21957/29850 (epoch 36.779), train_loss = 0.69966136, grad/param norm = 1.8646e-01, time/batch = 18.4772s	
21958/29850 (epoch 36.781), train_loss = 0.84015996, grad/param norm = 2.5377e-01, time/batch = 16.2956s	
21959/29850 (epoch 36.782), train_loss = 0.84347932, grad/param norm = 2.2070e-01, time/batch = 16.7693s	
21960/29850 (epoch 36.784), train_loss = 0.67363668, grad/param norm = 2.0163e-01, time/batch = 15.5467s	
21961/29850 (epoch 36.786), train_loss = 0.75977824, grad/param norm = 2.2340e-01, time/batch = 19.4526s	
21962/29850 (epoch 36.787), train_loss = 0.63021100, grad/param norm = 2.3574e-01, time/batch = 17.5190s	
21963/29850 (epoch 36.789), train_loss = 0.65604522, grad/param norm = 1.8729e-01, time/batch = 18.5160s	
21964/29850 (epoch 36.791), train_loss = 0.74103891, grad/param norm = 2.5015e-01, time/batch = 18.8836s	
21965/29850 (epoch 36.792), train_loss = 0.83353452, grad/param norm = 2.6664e-01, time/batch = 16.1520s	
21966/29850 (epoch 36.794), train_loss = 0.81267906, grad/param norm = 1.9994e-01, time/batch = 17.6143s	
21967/29850 (epoch 36.796), train_loss = 0.69810889, grad/param norm = 1.9310e-01, time/batch = 18.4649s	
21968/29850 (epoch 36.797), train_loss = 0.60541701, grad/param norm = 1.8197e-01, time/batch = 17.7877s	
21969/29850 (epoch 36.799), train_loss = 0.66280452, grad/param norm = 1.8532e-01, time/batch = 15.8521s	
21970/29850 (epoch 36.801), train_loss = 0.69487954, grad/param norm = 2.4173e-01, time/batch = 17.5357s	
21971/29850 (epoch 36.802), train_loss = 0.63292782, grad/param norm = 1.8571e-01, time/batch = 18.1338s	
21972/29850 (epoch 36.804), train_loss = 0.68116219, grad/param norm = 1.8259e-01, time/batch = 18.2018s	
21973/29850 (epoch 36.806), train_loss = 0.63412727, grad/param norm = 2.1886e-01, time/batch = 18.1989s	
21974/29850 (epoch 36.807), train_loss = 0.67453854, grad/param norm = 1.9293e-01, time/batch = 18.3875s	
21975/29850 (epoch 36.809), train_loss = 0.67489427, grad/param norm = 2.2453e-01, time/batch = 20.0346s	
21976/29850 (epoch 36.811), train_loss = 0.85338135, grad/param norm = 2.5710e-01, time/batch = 18.6905s	
21977/29850 (epoch 36.812), train_loss = 0.82939348, grad/param norm = 2.3140e-01, time/batch = 17.4537s	
21978/29850 (epoch 36.814), train_loss = 0.88320580, grad/param norm = 2.6212e-01, time/batch = 20.2014s	
21979/29850 (epoch 36.816), train_loss = 0.89101587, grad/param norm = 2.0972e-01, time/batch = 15.8589s	
21980/29850 (epoch 36.817), train_loss = 0.82258610, grad/param norm = 2.7451e-01, time/batch = 19.1888s	
21981/29850 (epoch 36.819), train_loss = 0.65786366, grad/param norm = 2.3170e-01, time/batch = 16.4800s	
21982/29850 (epoch 36.821), train_loss = 0.88578126, grad/param norm = 2.4644e-01, time/batch = 16.1765s	
21983/29850 (epoch 36.822), train_loss = 0.91156508, grad/param norm = 2.2218e-01, time/batch = 17.3849s	
21984/29850 (epoch 36.824), train_loss = 0.80248690, grad/param norm = 2.0806e-01, time/batch = 19.3738s	
21985/29850 (epoch 36.826), train_loss = 0.69525193, grad/param norm = 2.3095e-01, time/batch = 18.7899s	
21986/29850 (epoch 36.827), train_loss = 0.62544769, grad/param norm = 2.2253e-01, time/batch = 16.2140s	
21987/29850 (epoch 36.829), train_loss = 0.80540375, grad/param norm = 2.6846e-01, time/batch = 16.2123s	
21988/29850 (epoch 36.831), train_loss = 0.89281061, grad/param norm = 2.1348e-01, time/batch = 18.4553s	
21989/29850 (epoch 36.832), train_loss = 0.82550310, grad/param norm = 2.2717e-01, time/batch = 17.2867s	
21990/29850 (epoch 36.834), train_loss = 0.59807345, grad/param norm = 1.8663e-01, time/batch = 18.2578s	
21991/29850 (epoch 36.836), train_loss = 0.64674702, grad/param norm = 2.4082e-01, time/batch = 17.7109s	
21992/29850 (epoch 36.838), train_loss = 0.73833374, grad/param norm = 2.7783e-01, time/batch = 18.1116s	
21993/29850 (epoch 36.839), train_loss = 0.64927261, grad/param norm = 2.2271e-01, time/batch = 17.9482s	
21994/29850 (epoch 36.841), train_loss = 0.70879904, grad/param norm = 2.1428e-01, time/batch = 16.7740s	
21995/29850 (epoch 36.843), train_loss = 0.64886458, grad/param norm = 2.1059e-01, time/batch = 19.1340s	
21996/29850 (epoch 36.844), train_loss = 0.70006641, grad/param norm = 2.1225e-01, time/batch = 16.0548s	
21997/29850 (epoch 36.846), train_loss = 0.76515568, grad/param norm = 2.0504e-01, time/batch = 16.2192s	
21998/29850 (epoch 36.848), train_loss = 0.84614908, grad/param norm = 2.3560e-01, time/batch = 18.8177s	
21999/29850 (epoch 36.849), train_loss = 0.74831468, grad/param norm = 2.0895e-01, time/batch = 17.9478s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch36.85_1.8540.t7	
22000/29850 (epoch 36.851), train_loss = 0.94308503, grad/param norm = 2.4058e-01, time/batch = 19.3691s	
22001/29850 (epoch 36.853), train_loss = 1.50715934, grad/param norm = 3.3963e-01, time/batch = 17.1767s	
22002/29850 (epoch 36.854), train_loss = 0.94528652, grad/param norm = 2.6198e-01, time/batch = 17.9518s	
22003/29850 (epoch 36.856), train_loss = 0.89938311, grad/param norm = 2.7142e-01, time/batch = 16.7849s	
22004/29850 (epoch 36.858), train_loss = 0.81702985, grad/param norm = 2.4896e-01, time/batch = 20.2882s	
22005/29850 (epoch 36.859), train_loss = 0.71755176, grad/param norm = 2.4641e-01, time/batch = 17.1753s	
22006/29850 (epoch 36.861), train_loss = 0.90509487, grad/param norm = 2.7590e-01, time/batch = 18.3767s	
22007/29850 (epoch 36.863), train_loss = 0.93030292, grad/param norm = 2.6702e-01, time/batch = 18.2064s	
22008/29850 (epoch 36.864), train_loss = 0.91363381, grad/param norm = 2.5245e-01, time/batch = 18.3738s	
22009/29850 (epoch 36.866), train_loss = 0.81452694, grad/param norm = 2.4070e-01, time/batch = 18.4529s	
22010/29850 (epoch 36.868), train_loss = 0.96442777, grad/param norm = 2.7758e-01, time/batch = 17.8912s	
22011/29850 (epoch 36.869), train_loss = 0.88025728, grad/param norm = 2.7278e-01, time/batch = 18.6431s	
22012/29850 (epoch 36.871), train_loss = 0.89893434, grad/param norm = 2.5997e-01, time/batch = 17.1146s	
22013/29850 (epoch 36.873), train_loss = 0.83116227, grad/param norm = 2.2537e-01, time/batch = 17.4600s	
22014/29850 (epoch 36.874), train_loss = 0.85292129, grad/param norm = 2.1788e-01, time/batch = 18.5442s	
22015/29850 (epoch 36.876), train_loss = 0.83609668, grad/param norm = 3.3592e-01, time/batch = 16.7754s	
22016/29850 (epoch 36.878), train_loss = 0.83547375, grad/param norm = 2.1045e-01, time/batch = 17.7841s	
22017/29850 (epoch 36.879), train_loss = 0.86017670, grad/param norm = 2.2697e-01, time/batch = 17.5979s	
22018/29850 (epoch 36.881), train_loss = 0.92803982, grad/param norm = 2.5480e-01, time/batch = 18.7083s	
22019/29850 (epoch 36.883), train_loss = 0.85455802, grad/param norm = 2.1783e-01, time/batch = 18.1227s	
22020/29850 (epoch 36.884), train_loss = 0.73200519, grad/param norm = 2.3416e-01, time/batch = 17.2091s	
22021/29850 (epoch 36.886), train_loss = 0.90687723, grad/param norm = 2.5280e-01, time/batch = 18.9698s	
22022/29850 (epoch 36.888), train_loss = 0.82326205, grad/param norm = 2.3366e-01, time/batch = 18.0998s	
22023/29850 (epoch 36.889), train_loss = 0.76417729, grad/param norm = 2.1242e-01, time/batch = 17.6348s	
22024/29850 (epoch 36.891), train_loss = 0.73334846, grad/param norm = 1.9076e-01, time/batch = 18.7944s	
22025/29850 (epoch 36.893), train_loss = 0.79772067, grad/param norm = 2.1699e-01, time/batch = 16.3770s	
22026/29850 (epoch 36.894), train_loss = 0.79894941, grad/param norm = 2.3784e-01, time/batch = 17.4734s	
22027/29850 (epoch 36.896), train_loss = 0.81550806, grad/param norm = 2.1673e-01, time/batch = 16.5872s	
22028/29850 (epoch 36.898), train_loss = 0.96227976, grad/param norm = 2.6755e-01, time/batch = 19.3506s	
22029/29850 (epoch 36.899), train_loss = 0.71590023, grad/param norm = 2.1954e-01, time/batch = 16.0088s	
22030/29850 (epoch 36.901), train_loss = 1.01412283, grad/param norm = 3.1675e-01, time/batch = 16.6085s	
22031/29850 (epoch 36.903), train_loss = 0.88298548, grad/param norm = 3.0718e-01, time/batch = 19.0360s	
22032/29850 (epoch 36.905), train_loss = 1.06407466, grad/param norm = 2.3763e-01, time/batch = 16.8732s	
22033/29850 (epoch 36.906), train_loss = 0.85034173, grad/param norm = 2.6696e-01, time/batch = 17.9537s	
22034/29850 (epoch 36.908), train_loss = 0.98407845, grad/param norm = 2.2240e-01, time/batch = 19.3781s	
22035/29850 (epoch 36.910), train_loss = 0.90657609, grad/param norm = 2.1353e-01, time/batch = 17.7762s	
22036/29850 (epoch 36.911), train_loss = 1.03795551, grad/param norm = 2.1527e-01, time/batch = 16.7085s	
22037/29850 (epoch 36.913), train_loss = 0.98210402, grad/param norm = 2.4883e-01, time/batch = 17.3056s	
22038/29850 (epoch 36.915), train_loss = 0.97930795, grad/param norm = 2.6491e-01, time/batch = 19.6265s	
22039/29850 (epoch 36.916), train_loss = 0.93343181, grad/param norm = 2.5004e-01, time/batch = 18.5325s	
22040/29850 (epoch 36.918), train_loss = 0.79568056, grad/param norm = 2.3751e-01, time/batch = 15.4526s	
22041/29850 (epoch 36.920), train_loss = 0.95939283, grad/param norm = 2.1520e-01, time/batch = 17.2228s	
22042/29850 (epoch 36.921), train_loss = 0.84597986, grad/param norm = 2.3626e-01, time/batch = 17.1383s	
22043/29850 (epoch 36.923), train_loss = 0.84853581, grad/param norm = 2.1973e-01, time/batch = 18.7911s	
22044/29850 (epoch 36.925), train_loss = 0.98960037, grad/param norm = 2.5815e-01, time/batch = 18.9667s	
22045/29850 (epoch 36.926), train_loss = 0.98000423, grad/param norm = 2.7947e-01, time/batch = 17.9393s	
22046/29850 (epoch 36.928), train_loss = 0.84242731, grad/param norm = 2.3042e-01, time/batch = 16.8046s	
22047/29850 (epoch 36.930), train_loss = 0.87263503, grad/param norm = 2.2751e-01, time/batch = 17.2156s	
22048/29850 (epoch 36.931), train_loss = 0.85206767, grad/param norm = 2.1411e-01, time/batch = 17.8888s	
22049/29850 (epoch 36.933), train_loss = 1.01704591, grad/param norm = 4.3782e-01, time/batch = 16.2531s	
22050/29850 (epoch 36.935), train_loss = 0.94349385, grad/param norm = 2.8995e-01, time/batch = 19.2862s	
22051/29850 (epoch 36.936), train_loss = 0.90301989, grad/param norm = 2.5853e-01, time/batch = 19.2994s	
22052/29850 (epoch 36.938), train_loss = 0.77001907, grad/param norm = 2.2007e-01, time/batch = 17.6289s	
22053/29850 (epoch 36.940), train_loss = 0.79596073, grad/param norm = 2.3309e-01, time/batch = 16.7934s	
22054/29850 (epoch 36.941), train_loss = 0.76506031, grad/param norm = 2.2896e-01, time/batch = 16.7901s	
22055/29850 (epoch 36.943), train_loss = 0.80032425, grad/param norm = 2.1892e-01, time/batch = 17.5488s	
22056/29850 (epoch 36.945), train_loss = 0.72973983, grad/param norm = 2.1345e-01, time/batch = 16.5528s	
22057/29850 (epoch 36.946), train_loss = 0.75613200, grad/param norm = 2.2073e-01, time/batch = 16.8075s	
22058/29850 (epoch 36.948), train_loss = 0.86073842, grad/param norm = 2.3107e-01, time/batch = 18.6173s	
22059/29850 (epoch 36.950), train_loss = 0.79173397, grad/param norm = 1.9927e-01, time/batch = 18.2769s	
22060/29850 (epoch 36.951), train_loss = 0.70732392, grad/param norm = 2.1433e-01, time/batch = 16.9682s	
22061/29850 (epoch 36.953), train_loss = 0.79907452, grad/param norm = 2.4637e-01, time/batch = 15.6263s	
22062/29850 (epoch 36.955), train_loss = 0.72599162, grad/param norm = 2.0027e-01, time/batch = 17.2041s	
22063/29850 (epoch 36.956), train_loss = 0.73980210, grad/param norm = 1.9742e-01, time/batch = 18.0150s	
22064/29850 (epoch 36.958), train_loss = 0.65171877, grad/param norm = 1.7913e-01, time/batch = 18.6294s	
22065/29850 (epoch 36.960), train_loss = 0.93478977, grad/param norm = 2.4626e-01, time/batch = 18.8786s	
22066/29850 (epoch 36.961), train_loss = 0.69861980, grad/param norm = 2.1404e-01, time/batch = 15.0466s	
22067/29850 (epoch 36.963), train_loss = 0.69286238, grad/param norm = 2.0958e-01, time/batch = 18.1383s	
22068/29850 (epoch 36.965), train_loss = 0.76212904, grad/param norm = 2.6173e-01, time/batch = 17.5501s	
22069/29850 (epoch 36.966), train_loss = 0.72122601, grad/param norm = 2.0903e-01, time/batch = 16.6152s	
22070/29850 (epoch 36.968), train_loss = 0.75300487, grad/param norm = 2.4279e-01, time/batch = 17.6942s	
22071/29850 (epoch 36.970), train_loss = 0.75810700, grad/param norm = 2.2616e-01, time/batch = 17.9657s	
22072/29850 (epoch 36.972), train_loss = 0.74157652, grad/param norm = 1.9364e-01, time/batch = 18.5606s	
22073/29850 (epoch 36.973), train_loss = 0.74189946, grad/param norm = 1.9337e-01, time/batch = 19.0356s	
22074/29850 (epoch 36.975), train_loss = 0.63817078, grad/param norm = 1.8922e-01, time/batch = 18.2179s	
22075/29850 (epoch 36.977), train_loss = 0.76786804, grad/param norm = 1.9138e-01, time/batch = 17.9685s	
22076/29850 (epoch 36.978), train_loss = 0.66658591, grad/param norm = 1.8669e-01, time/batch = 16.7857s	
22077/29850 (epoch 36.980), train_loss = 0.74050628, grad/param norm = 1.8554e-01, time/batch = 19.2002s	
22078/29850 (epoch 36.982), train_loss = 0.71951320, grad/param norm = 2.0615e-01, time/batch = 19.3647s	
22079/29850 (epoch 36.983), train_loss = 0.75874613, grad/param norm = 2.0773e-01, time/batch = 16.6874s	
22080/29850 (epoch 36.985), train_loss = 0.85714363, grad/param norm = 2.4473e-01, time/batch = 17.7964s	
22081/29850 (epoch 36.987), train_loss = 0.83966166, grad/param norm = 2.7182e-01, time/batch = 16.6551s	
22082/29850 (epoch 36.988), train_loss = 0.75882126, grad/param norm = 2.1080e-01, time/batch = 17.8747s	
22083/29850 (epoch 36.990), train_loss = 0.83330078, grad/param norm = 2.0511e-01, time/batch = 16.0426s	
22084/29850 (epoch 36.992), train_loss = 0.85346577, grad/param norm = 2.3027e-01, time/batch = 16.3702s	
22085/29850 (epoch 36.993), train_loss = 0.82833517, grad/param norm = 2.3570e-01, time/batch = 17.6151s	
22086/29850 (epoch 36.995), train_loss = 0.81746559, grad/param norm = 2.1603e-01, time/batch = 17.2960s	
22087/29850 (epoch 36.997), train_loss = 0.84869463, grad/param norm = 2.1241e-01, time/batch = 17.8620s	
22088/29850 (epoch 36.998), train_loss = 0.85501895, grad/param norm = 2.1040e-01, time/batch = 16.9779s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
22089/29850 (epoch 37.000), train_loss = 0.69735319, grad/param norm = 2.0175e-01, time/batch = 18.5255s	
22090/29850 (epoch 37.002), train_loss = 0.91793613, grad/param norm = 2.2349e-01, time/batch = 18.1218s	
22091/29850 (epoch 37.003), train_loss = 0.69917929, grad/param norm = 2.2771e-01, time/batch = 17.2343s	
22092/29850 (epoch 37.005), train_loss = 0.86922828, grad/param norm = 2.3437e-01, time/batch = 18.7081s	
22093/29850 (epoch 37.007), train_loss = 0.89761501, grad/param norm = 2.4227e-01, time/batch = 16.6188s	
22094/29850 (epoch 37.008), train_loss = 1.03430983, grad/param norm = 2.7060e-01, time/batch = 19.2060s	
22095/29850 (epoch 37.010), train_loss = 0.76375639, grad/param norm = 2.2768e-01, time/batch = 18.3038s	
22096/29850 (epoch 37.012), train_loss = 0.79077405, grad/param norm = 2.1060e-01, time/batch = 16.5216s	
22097/29850 (epoch 37.013), train_loss = 0.86310394, grad/param norm = 2.6349e-01, time/batch = 18.6365s	
22098/29850 (epoch 37.015), train_loss = 0.92088917, grad/param norm = 2.5266e-01, time/batch = 16.9669s	
22099/29850 (epoch 37.017), train_loss = 0.85198836, grad/param norm = 2.4634e-01, time/batch = 14.7460s	
22100/29850 (epoch 37.018), train_loss = 0.95555684, grad/param norm = 2.3609e-01, time/batch = 17.2996s	
22101/29850 (epoch 37.020), train_loss = 0.84361113, grad/param norm = 2.3022e-01, time/batch = 19.2940s	
22102/29850 (epoch 37.022), train_loss = 0.91295004, grad/param norm = 2.3623e-01, time/batch = 16.2692s	
22103/29850 (epoch 37.023), train_loss = 0.89170469, grad/param norm = 2.2009e-01, time/batch = 16.1907s	
22104/29850 (epoch 37.025), train_loss = 0.79883837, grad/param norm = 1.8134e-01, time/batch = 16.3837s	
22105/29850 (epoch 37.027), train_loss = 0.61751365, grad/param norm = 1.9387e-01, time/batch = 18.2280s	
22106/29850 (epoch 37.028), train_loss = 0.74307019, grad/param norm = 1.8289e-01, time/batch = 17.7092s	
22107/29850 (epoch 37.030), train_loss = 0.77630748, grad/param norm = 2.3820e-01, time/batch = 18.3655s	
22108/29850 (epoch 37.032), train_loss = 0.88171796, grad/param norm = 2.3593e-01, time/batch = 18.2878s	
22109/29850 (epoch 37.034), train_loss = 0.73811881, grad/param norm = 2.0290e-01, time/batch = 18.9541s	
22110/29850 (epoch 37.035), train_loss = 0.66382921, grad/param norm = 2.0282e-01, time/batch = 17.7855s	
22111/29850 (epoch 37.037), train_loss = 0.83386881, grad/param norm = 2.3771e-01, time/batch = 18.0415s	
22112/29850 (epoch 37.039), train_loss = 0.72311454, grad/param norm = 1.7377e-01, time/batch = 18.7127s	
22113/29850 (epoch 37.040), train_loss = 0.71870175, grad/param norm = 2.0053e-01, time/batch = 24.3675s	
22114/29850 (epoch 37.042), train_loss = 0.74290799, grad/param norm = 2.0757e-01, time/batch = 23.3950s	
22115/29850 (epoch 37.044), train_loss = 0.79836582, grad/param norm = 2.0797e-01, time/batch = 16.8838s	
22116/29850 (epoch 37.045), train_loss = 0.87234430, grad/param norm = 2.0673e-01, time/batch = 15.7997s	
22117/29850 (epoch 37.047), train_loss = 0.72146705, grad/param norm = 1.9483e-01, time/batch = 17.7211s	
22118/29850 (epoch 37.049), train_loss = 0.84982208, grad/param norm = 2.0877e-01, time/batch = 16.5259s	
22119/29850 (epoch 37.050), train_loss = 0.75461747, grad/param norm = 2.0782e-01, time/batch = 17.3018s	
22120/29850 (epoch 37.052), train_loss = 0.94910827, grad/param norm = 2.8023e-01, time/batch = 16.8688s	
22121/29850 (epoch 37.054), train_loss = 0.81146068, grad/param norm = 2.4958e-01, time/batch = 17.6811s	
22122/29850 (epoch 37.055), train_loss = 0.79237023, grad/param norm = 2.2484e-01, time/batch = 18.3911s	
22123/29850 (epoch 37.057), train_loss = 0.86388908, grad/param norm = 1.9368e-01, time/batch = 17.1743s	
22124/29850 (epoch 37.059), train_loss = 0.87771217, grad/param norm = 2.4620e-01, time/batch = 17.7141s	
22125/29850 (epoch 37.060), train_loss = 0.81433282, grad/param norm = 2.2606e-01, time/batch = 19.2137s	
22126/29850 (epoch 37.062), train_loss = 0.92075757, grad/param norm = 3.0140e-01, time/batch = 16.2790s	
22127/29850 (epoch 37.064), train_loss = 0.89802441, grad/param norm = 2.5154e-01, time/batch = 19.7729s	
22128/29850 (epoch 37.065), train_loss = 0.70817602, grad/param norm = 2.0841e-01, time/batch = 19.7831s	
22129/29850 (epoch 37.067), train_loss = 0.87760144, grad/param norm = 2.0701e-01, time/batch = 17.7012s	
22130/29850 (epoch 37.069), train_loss = 0.87247407, grad/param norm = 1.9456e-01, time/batch = 19.8707s	
22131/29850 (epoch 37.070), train_loss = 0.88277052, grad/param norm = 2.1039e-01, time/batch = 15.8024s	
22132/29850 (epoch 37.072), train_loss = 0.82505808, grad/param norm = 2.1224e-01, time/batch = 17.9558s	
22133/29850 (epoch 37.074), train_loss = 0.90550202, grad/param norm = 2.0761e-01, time/batch = 19.5240s	
22134/29850 (epoch 37.075), train_loss = 0.76663338, grad/param norm = 2.2441e-01, time/batch = 17.2126s	
22135/29850 (epoch 37.077), train_loss = 0.91262200, grad/param norm = 2.4596e-01, time/batch = 18.8091s	
22136/29850 (epoch 37.079), train_loss = 1.03655830, grad/param norm = 2.9493e-01, time/batch = 17.2075s	
22137/29850 (epoch 37.080), train_loss = 1.00144480, grad/param norm = 2.3084e-01, time/batch = 15.9677s	
22138/29850 (epoch 37.082), train_loss = 0.89233025, grad/param norm = 2.1845e-01, time/batch = 18.5448s	
22139/29850 (epoch 37.084), train_loss = 0.97961479, grad/param norm = 2.3474e-01, time/batch = 16.2794s	
22140/29850 (epoch 37.085), train_loss = 1.02126220, grad/param norm = 2.6007e-01, time/batch = 18.7241s	
22141/29850 (epoch 37.087), train_loss = 0.95236830, grad/param norm = 2.2945e-01, time/batch = 18.2179s	
22142/29850 (epoch 37.089), train_loss = 0.88622462, grad/param norm = 2.2620e-01, time/batch = 15.7652s	
22143/29850 (epoch 37.090), train_loss = 0.88592626, grad/param norm = 2.1398e-01, time/batch = 16.6168s	
22144/29850 (epoch 37.092), train_loss = 0.76576509, grad/param norm = 2.0993e-01, time/batch = 20.1095s	
22145/29850 (epoch 37.094), train_loss = 0.98306344, grad/param norm = 2.3603e-01, time/batch = 17.6172s	
22146/29850 (epoch 37.095), train_loss = 0.92250313, grad/param norm = 4.6864e-01, time/batch = 16.4368s	
22147/29850 (epoch 37.097), train_loss = 0.65865547, grad/param norm = 1.9960e-01, time/batch = 18.0462s	
22148/29850 (epoch 37.099), train_loss = 0.70562930, grad/param norm = 1.9852e-01, time/batch = 17.4728s	
22149/29850 (epoch 37.101), train_loss = 0.92285412, grad/param norm = 2.3225e-01, time/batch = 17.6961s	
22150/29850 (epoch 37.102), train_loss = 0.90548055, grad/param norm = 2.7133e-01, time/batch = 17.8809s	
22151/29850 (epoch 37.104), train_loss = 0.79361442, grad/param norm = 2.2043e-01, time/batch = 18.1297s	
22152/29850 (epoch 37.106), train_loss = 0.92850488, grad/param norm = 2.4628e-01, time/batch = 17.0259s	
22153/29850 (epoch 37.107), train_loss = 0.78115239, grad/param norm = 2.0532e-01, time/batch = 16.8593s	
22154/29850 (epoch 37.109), train_loss = 0.84363365, grad/param norm = 2.1137e-01, time/batch = 15.4450s	
22155/29850 (epoch 37.111), train_loss = 0.91116608, grad/param norm = 2.3353e-01, time/batch = 17.7108s	
22156/29850 (epoch 37.112), train_loss = 0.73915417, grad/param norm = 1.8732e-01, time/batch = 18.0364s	
22157/29850 (epoch 37.114), train_loss = 0.79028365, grad/param norm = 2.4481e-01, time/batch = 18.5337s	
22158/29850 (epoch 37.116), train_loss = 0.75962165, grad/param norm = 2.2662e-01, time/batch = 18.5442s	
22159/29850 (epoch 37.117), train_loss = 0.83166069, grad/param norm = 2.2759e-01, time/batch = 18.5438s	
22160/29850 (epoch 37.119), train_loss = 0.78957114, grad/param norm = 2.1479e-01, time/batch = 17.6961s	
22161/29850 (epoch 37.121), train_loss = 0.67486523, grad/param norm = 2.3106e-01, time/batch = 17.2187s	
22162/29850 (epoch 37.122), train_loss = 0.70594869, grad/param norm = 1.6099e-01, time/batch = 18.8792s	
22163/29850 (epoch 37.124), train_loss = 0.76315015, grad/param norm = 2.1266e-01, time/batch = 16.1217s	
22164/29850 (epoch 37.126), train_loss = 0.79289816, grad/param norm = 2.1242e-01, time/batch = 17.1162s	
22165/29850 (epoch 37.127), train_loss = 0.88251484, grad/param norm = 2.7049e-01, time/batch = 16.6919s	
22166/29850 (epoch 37.129), train_loss = 0.82396207, grad/param norm = 2.2515e-01, time/batch = 18.5264s	
22167/29850 (epoch 37.131), train_loss = 0.83138895, grad/param norm = 2.1252e-01, time/batch = 15.6160s	
22168/29850 (epoch 37.132), train_loss = 0.69898560, grad/param norm = 2.3106e-01, time/batch = 17.3770s	
22169/29850 (epoch 37.134), train_loss = 0.80320276, grad/param norm = 2.3261e-01, time/batch = 17.8799s	
22170/29850 (epoch 37.136), train_loss = 0.87222567, grad/param norm = 1.9789e-01, time/batch = 17.1272s	
22171/29850 (epoch 37.137), train_loss = 0.68476437, grad/param norm = 2.1711e-01, time/batch = 17.0241s	
22172/29850 (epoch 37.139), train_loss = 0.82008498, grad/param norm = 2.1216e-01, time/batch = 19.4470s	
22173/29850 (epoch 37.141), train_loss = 0.75194797, grad/param norm = 2.1459e-01, time/batch = 14.6460s	
22174/29850 (epoch 37.142), train_loss = 0.94632792, grad/param norm = 2.4031e-01, time/batch = 19.0264s	
22175/29850 (epoch 37.144), train_loss = 1.03860649, grad/param norm = 2.4572e-01, time/batch = 18.8597s	
22176/29850 (epoch 37.146), train_loss = 1.05886130, grad/param norm = 2.3974e-01, time/batch = 18.9614s	
22177/29850 (epoch 37.147), train_loss = 0.94297288, grad/param norm = 2.6130e-01, time/batch = 16.7812s	
22178/29850 (epoch 37.149), train_loss = 0.87641231, grad/param norm = 2.0853e-01, time/batch = 17.6334s	
22179/29850 (epoch 37.151), train_loss = 0.89967931, grad/param norm = 2.4887e-01, time/batch = 17.8964s	
22180/29850 (epoch 37.152), train_loss = 0.81957568, grad/param norm = 2.2712e-01, time/batch = 16.0255s	
22181/29850 (epoch 37.154), train_loss = 0.77925705, grad/param norm = 2.3588e-01, time/batch = 19.5558s	
22182/29850 (epoch 37.156), train_loss = 0.77696106, grad/param norm = 2.1089e-01, time/batch = 17.5375s	
22183/29850 (epoch 37.157), train_loss = 0.87801483, grad/param norm = 2.2605e-01, time/batch = 17.3681s	
22184/29850 (epoch 37.159), train_loss = 0.79352049, grad/param norm = 2.0774e-01, time/batch = 16.8795s	
22185/29850 (epoch 37.161), train_loss = 0.81240030, grad/param norm = 2.0277e-01, time/batch = 19.0376s	
22186/29850 (epoch 37.162), train_loss = 0.96243433, grad/param norm = 2.4508e-01, time/batch = 15.3631s	
22187/29850 (epoch 37.164), train_loss = 0.87495818, grad/param norm = 2.3137e-01, time/batch = 17.1852s	
22188/29850 (epoch 37.166), train_loss = 0.80336576, grad/param norm = 2.1076e-01, time/batch = 17.5299s	
22189/29850 (epoch 37.168), train_loss = 0.72507239, grad/param norm = 1.9762e-01, time/batch = 19.2027s	
22190/29850 (epoch 37.169), train_loss = 0.94901101, grad/param norm = 2.5904e-01, time/batch = 17.1147s	
22191/29850 (epoch 37.171), train_loss = 0.90930100, grad/param norm = 2.3729e-01, time/batch = 19.5435s	
22192/29850 (epoch 37.173), train_loss = 0.74634506, grad/param norm = 2.1775e-01, time/batch = 18.3800s	
22193/29850 (epoch 37.174), train_loss = 0.82643409, grad/param norm = 2.3936e-01, time/batch = 18.2841s	
22194/29850 (epoch 37.176), train_loss = 0.86609988, grad/param norm = 2.3908e-01, time/batch = 20.3580s	
22195/29850 (epoch 37.178), train_loss = 0.87856763, grad/param norm = 2.6798e-01, time/batch = 18.0206s	
22196/29850 (epoch 37.179), train_loss = 0.70470303, grad/param norm = 2.7014e-01, time/batch = 19.4483s	
22197/29850 (epoch 37.181), train_loss = 0.85893484, grad/param norm = 2.5461e-01, time/batch = 16.5278s	
22198/29850 (epoch 37.183), train_loss = 0.83690424, grad/param norm = 2.0441e-01, time/batch = 19.0455s	
22199/29850 (epoch 37.184), train_loss = 0.91632875, grad/param norm = 2.6237e-01, time/batch = 19.1129s	
22200/29850 (epoch 37.186), train_loss = 0.87617264, grad/param norm = 2.6461e-01, time/batch = 16.7031s	
22201/29850 (epoch 37.188), train_loss = 0.96381730, grad/param norm = 2.2984e-01, time/batch = 18.6295s	
22202/29850 (epoch 37.189), train_loss = 0.94913477, grad/param norm = 2.7348e-01, time/batch = 14.8670s	
22203/29850 (epoch 37.191), train_loss = 0.94464596, grad/param norm = 2.4256e-01, time/batch = 14.7914s	
22204/29850 (epoch 37.193), train_loss = 0.80448419, grad/param norm = 1.9777e-01, time/batch = 16.5150s	
22205/29850 (epoch 37.194), train_loss = 0.94282634, grad/param norm = 2.3213e-01, time/batch = 14.7676s	
22206/29850 (epoch 37.196), train_loss = 0.81113836, grad/param norm = 2.0293e-01, time/batch = 15.2477s	
22207/29850 (epoch 37.198), train_loss = 0.78161775, grad/param norm = 1.9885e-01, time/batch = 14.7914s	
22208/29850 (epoch 37.199), train_loss = 1.03793914, grad/param norm = 2.5428e-01, time/batch = 15.2736s	
22209/29850 (epoch 37.201), train_loss = 0.77075680, grad/param norm = 1.9329e-01, time/batch = 17.6947s	
22210/29850 (epoch 37.203), train_loss = 0.61056894, grad/param norm = 2.3859e-01, time/batch = 17.2154s	
22211/29850 (epoch 37.204), train_loss = 0.83645363, grad/param norm = 2.3162e-01, time/batch = 17.4595s	
22212/29850 (epoch 37.206), train_loss = 0.72900927, grad/param norm = 2.2241e-01, time/batch = 18.2885s	
22213/29850 (epoch 37.208), train_loss = 0.98827981, grad/param norm = 2.7039e-01, time/batch = 19.6112s	
22214/29850 (epoch 37.209), train_loss = 0.72853599, grad/param norm = 2.4563e-01, time/batch = 17.2163s	
22215/29850 (epoch 37.211), train_loss = 0.78870761, grad/param norm = 2.0246e-01, time/batch = 18.0335s	
22216/29850 (epoch 37.213), train_loss = 0.87931918, grad/param norm = 2.4215e-01, time/batch = 16.3736s	
22217/29850 (epoch 37.214), train_loss = 0.71029021, grad/param norm = 1.9466e-01, time/batch = 18.4541s	
22218/29850 (epoch 37.216), train_loss = 0.75504301, grad/param norm = 2.3217e-01, time/batch = 18.1910s	
22219/29850 (epoch 37.218), train_loss = 0.86905663, grad/param norm = 2.1475e-01, time/batch = 17.8892s	
22220/29850 (epoch 37.219), train_loss = 0.87265106, grad/param norm = 2.7087e-01, time/batch = 16.4503s	
22221/29850 (epoch 37.221), train_loss = 0.83888460, grad/param norm = 2.3483e-01, time/batch = 17.2174s	
22222/29850 (epoch 37.223), train_loss = 0.69328110, grad/param norm = 2.1314e-01, time/batch = 17.6931s	
22223/29850 (epoch 37.224), train_loss = 0.69832863, grad/param norm = 1.8607e-01, time/batch = 16.9787s	
22224/29850 (epoch 37.226), train_loss = 0.75443216, grad/param norm = 1.9181e-01, time/batch = 17.8063s	
22225/29850 (epoch 37.228), train_loss = 0.79089574, grad/param norm = 2.0447e-01, time/batch = 18.0554s	
22226/29850 (epoch 37.229), train_loss = 0.66953243, grad/param norm = 1.7726e-01, time/batch = 15.6945s	
22227/29850 (epoch 37.231), train_loss = 0.82519748, grad/param norm = 2.0350e-01, time/batch = 18.1289s	
22228/29850 (epoch 37.233), train_loss = 0.79903025, grad/param norm = 2.0392e-01, time/batch = 15.8758s	
22229/29850 (epoch 37.235), train_loss = 0.76713263, grad/param norm = 2.0128e-01, time/batch = 18.8864s	
22230/29850 (epoch 37.236), train_loss = 0.96597667, grad/param norm = 2.5506e-01, time/batch = 15.5494s	
22231/29850 (epoch 37.238), train_loss = 0.70243153, grad/param norm = 1.9390e-01, time/batch = 17.0338s	
22232/29850 (epoch 37.240), train_loss = 0.70094646, grad/param norm = 1.9138e-01, time/batch = 16.9740s	
22233/29850 (epoch 37.241), train_loss = 0.86950964, grad/param norm = 2.5438e-01, time/batch = 17.9498s	
22234/29850 (epoch 37.243), train_loss = 0.88001968, grad/param norm = 2.0584e-01, time/batch = 17.0468s	
22235/29850 (epoch 37.245), train_loss = 0.74135537, grad/param norm = 2.1531e-01, time/batch = 16.3628s	
22236/29850 (epoch 37.246), train_loss = 0.71767564, grad/param norm = 1.7108e-01, time/batch = 18.5592s	
22237/29850 (epoch 37.248), train_loss = 0.71117129, grad/param norm = 2.2601e-01, time/batch = 17.8672s	
22238/29850 (epoch 37.250), train_loss = 0.78358925, grad/param norm = 1.9484e-01, time/batch = 16.5491s	
22239/29850 (epoch 37.251), train_loss = 0.68075576, grad/param norm = 1.9885e-01, time/batch = 18.2928s	
22240/29850 (epoch 37.253), train_loss = 0.67084671, grad/param norm = 2.1783e-01, time/batch = 17.5354s	
22241/29850 (epoch 37.255), train_loss = 0.71820607, grad/param norm = 2.1021e-01, time/batch = 16.9539s	
22242/29850 (epoch 37.256), train_loss = 0.85380453, grad/param norm = 2.1369e-01, time/batch = 16.6984s	
22243/29850 (epoch 37.258), train_loss = 0.85297967, grad/param norm = 2.1764e-01, time/batch = 19.6329s	
22244/29850 (epoch 37.260), train_loss = 0.78816400, grad/param norm = 1.9025e-01, time/batch = 18.8829s	
22245/29850 (epoch 37.261), train_loss = 0.73325304, grad/param norm = 2.3065e-01, time/batch = 18.2919s	
22246/29850 (epoch 37.263), train_loss = 0.74951983, grad/param norm = 2.0605e-01, time/batch = 18.0297s	
22247/29850 (epoch 37.265), train_loss = 0.80702177, grad/param norm = 2.3202e-01, time/batch = 19.9418s	
22248/29850 (epoch 37.266), train_loss = 0.80242047, grad/param norm = 2.0862e-01, time/batch = 17.3581s	
22249/29850 (epoch 37.268), train_loss = 0.78174130, grad/param norm = 2.1883e-01, time/batch = 18.3549s	
22250/29850 (epoch 37.270), train_loss = 0.76313545, grad/param norm = 2.2182e-01, time/batch = 16.8600s	
22251/29850 (epoch 37.271), train_loss = 0.86337608, grad/param norm = 2.2412e-01, time/batch = 18.1072s	
22252/29850 (epoch 37.273), train_loss = 0.71426019, grad/param norm = 2.1896e-01, time/batch = 17.7900s	
22253/29850 (epoch 37.275), train_loss = 0.69667493, grad/param norm = 1.9866e-01, time/batch = 17.6497s	
22254/29850 (epoch 37.276), train_loss = 0.69318464, grad/param norm = 1.9472e-01, time/batch = 18.6335s	
22255/29850 (epoch 37.278), train_loss = 0.77207541, grad/param norm = 2.2574e-01, time/batch = 17.3751s	
22256/29850 (epoch 37.280), train_loss = 0.97691999, grad/param norm = 2.7652e-01, time/batch = 16.7038s	
22257/29850 (epoch 37.281), train_loss = 0.85263743, grad/param norm = 2.4535e-01, time/batch = 18.2268s	
22258/29850 (epoch 37.283), train_loss = 0.95386983, grad/param norm = 3.4307e-01, time/batch = 17.9551s	
22259/29850 (epoch 37.285), train_loss = 0.90684942, grad/param norm = 2.3082e-01, time/batch = 18.8021s	
22260/29850 (epoch 37.286), train_loss = 0.94031764, grad/param norm = 2.9916e-01, time/batch = 18.2163s	
22261/29850 (epoch 37.288), train_loss = 0.89717656, grad/param norm = 2.9127e-01, time/batch = 18.0368s	
22262/29850 (epoch 37.290), train_loss = 0.86190757, grad/param norm = 2.6854e-01, time/batch = 18.9411s	
22263/29850 (epoch 37.291), train_loss = 1.03887344, grad/param norm = 2.9093e-01, time/batch = 17.7903s	
22264/29850 (epoch 37.293), train_loss = 0.96779331, grad/param norm = 2.6121e-01, time/batch = 19.2138s	
22265/29850 (epoch 37.295), train_loss = 1.00375168, grad/param norm = 2.5521e-01, time/batch = 16.2714s	
22266/29850 (epoch 37.296), train_loss = 0.74464708, grad/param norm = 1.8392e-01, time/batch = 19.0491s	
22267/29850 (epoch 37.298), train_loss = 0.64116346, grad/param norm = 1.7171e-01, time/batch = 17.1167s	
22268/29850 (epoch 37.300), train_loss = 0.73254287, grad/param norm = 2.1450e-01, time/batch = 17.1831s	
22269/29850 (epoch 37.302), train_loss = 0.71760650, grad/param norm = 2.3773e-01, time/batch = 17.8832s	
22270/29850 (epoch 37.303), train_loss = 0.77832216, grad/param norm = 2.6638e-01, time/batch = 18.7027s	
22271/29850 (epoch 37.305), train_loss = 0.89077278, grad/param norm = 2.0879e-01, time/batch = 17.3826s	
22272/29850 (epoch 37.307), train_loss = 0.90980363, grad/param norm = 2.2982e-01, time/batch = 18.2234s	
22273/29850 (epoch 37.308), train_loss = 0.73635696, grad/param norm = 2.1798e-01, time/batch = 17.1933s	
22274/29850 (epoch 37.310), train_loss = 0.88502929, grad/param norm = 2.4804e-01, time/batch = 17.8143s	
22275/29850 (epoch 37.312), train_loss = 0.88922646, grad/param norm = 2.1267e-01, time/batch = 16.2259s	
22276/29850 (epoch 37.313), train_loss = 0.85603840, grad/param norm = 2.5712e-01, time/batch = 17.2735s	
22277/29850 (epoch 37.315), train_loss = 0.86085092, grad/param norm = 2.2766e-01, time/batch = 18.0449s	
22278/29850 (epoch 37.317), train_loss = 0.83967261, grad/param norm = 2.2910e-01, time/batch = 16.7969s	
22279/29850 (epoch 37.318), train_loss = 0.82698158, grad/param norm = 2.1567e-01, time/batch = 16.3791s	
22280/29850 (epoch 37.320), train_loss = 0.77733397, grad/param norm = 2.1447e-01, time/batch = 18.6292s	
22281/29850 (epoch 37.322), train_loss = 0.96936973, grad/param norm = 2.7269e-01, time/batch = 18.2075s	
22282/29850 (epoch 37.323), train_loss = 0.86426357, grad/param norm = 2.2744e-01, time/batch = 16.0170s	
22283/29850 (epoch 37.325), train_loss = 0.93654211, grad/param norm = 2.1970e-01, time/batch = 18.8699s	
22284/29850 (epoch 37.327), train_loss = 1.03387034, grad/param norm = 2.4726e-01, time/batch = 16.6440s	
22285/29850 (epoch 37.328), train_loss = 0.94070039, grad/param norm = 2.3954e-01, time/batch = 16.7836s	
22286/29850 (epoch 37.330), train_loss = 0.90345647, grad/param norm = 2.0391e-01, time/batch = 17.7819s	
22287/29850 (epoch 37.332), train_loss = 0.80398616, grad/param norm = 2.2031e-01, time/batch = 18.7916s	
22288/29850 (epoch 37.333), train_loss = 0.88521918, grad/param norm = 2.2291e-01, time/batch = 18.1228s	
22289/29850 (epoch 37.335), train_loss = 0.93432658, grad/param norm = 2.3420e-01, time/batch = 15.3235s	
22290/29850 (epoch 37.337), train_loss = 0.85011734, grad/param norm = 2.4775e-01, time/batch = 16.3824s	
22291/29850 (epoch 37.338), train_loss = 0.88716980, grad/param norm = 2.1867e-01, time/batch = 17.3875s	
22292/29850 (epoch 37.340), train_loss = 0.73114623, grad/param norm = 2.0917e-01, time/batch = 17.0391s	
22293/29850 (epoch 37.342), train_loss = 0.85998260, grad/param norm = 2.8390e-01, time/batch = 17.3777s	
22294/29850 (epoch 37.343), train_loss = 0.86032133, grad/param norm = 2.5368e-01, time/batch = 19.8674s	
22295/29850 (epoch 37.345), train_loss = 0.92765937, grad/param norm = 2.5078e-01, time/batch = 17.7059s	
22296/29850 (epoch 37.347), train_loss = 0.93756100, grad/param norm = 2.5013e-01, time/batch = 17.7069s	
22297/29850 (epoch 37.348), train_loss = 0.79986363, grad/param norm = 2.1729e-01, time/batch = 19.2866s	
22298/29850 (epoch 37.350), train_loss = 0.89554995, grad/param norm = 2.1842e-01, time/batch = 18.4726s	
22299/29850 (epoch 37.352), train_loss = 0.78066405, grad/param norm = 1.9263e-01, time/batch = 16.3560s	
22300/29850 (epoch 37.353), train_loss = 0.89222427, grad/param norm = 2.4782e-01, time/batch = 17.7981s	
22301/29850 (epoch 37.355), train_loss = 0.80517251, grad/param norm = 2.1121e-01, time/batch = 18.3095s	
22302/29850 (epoch 37.357), train_loss = 0.92883919, grad/param norm = 2.3007e-01, time/batch = 17.6918s	
22303/29850 (epoch 37.358), train_loss = 0.77134178, grad/param norm = 2.1938e-01, time/batch = 18.0415s	
22304/29850 (epoch 37.360), train_loss = 0.84415557, grad/param norm = 2.3851e-01, time/batch = 19.2093s	
22305/29850 (epoch 37.362), train_loss = 0.83639164, grad/param norm = 2.2647e-01, time/batch = 17.3790s	
22306/29850 (epoch 37.363), train_loss = 0.88441138, grad/param norm = 2.4116e-01, time/batch = 18.1163s	
22307/29850 (epoch 37.365), train_loss = 0.96218055, grad/param norm = 2.5907e-01, time/batch = 16.0151s	
22308/29850 (epoch 37.367), train_loss = 0.76353434, grad/param norm = 2.0531e-01, time/batch = 17.3898s	
22309/29850 (epoch 37.369), train_loss = 0.71077125, grad/param norm = 2.6830e-01, time/batch = 16.8620s	
22310/29850 (epoch 37.370), train_loss = 0.69523371, grad/param norm = 2.1468e-01, time/batch = 18.1116s	
22311/29850 (epoch 37.372), train_loss = 0.94732231, grad/param norm = 2.4358e-01, time/batch = 18.2206s	
22312/29850 (epoch 37.374), train_loss = 0.90078604, grad/param norm = 2.1252e-01, time/batch = 17.7791s	
22313/29850 (epoch 37.375), train_loss = 0.84419232, grad/param norm = 2.2003e-01, time/batch = 17.5575s	
22314/29850 (epoch 37.377), train_loss = 0.76355473, grad/param norm = 2.3515e-01, time/batch = 18.9666s	
22315/29850 (epoch 37.379), train_loss = 0.94281664, grad/param norm = 2.8469e-01, time/batch = 16.3061s	
22316/29850 (epoch 37.380), train_loss = 0.88952948, grad/param norm = 2.3684e-01, time/batch = 32.4378s	
22317/29850 (epoch 37.382), train_loss = 0.85735916, grad/param norm = 2.2020e-01, time/batch = 16.9128s	
22318/29850 (epoch 37.384), train_loss = 0.92241402, grad/param norm = 2.5465e-01, time/batch = 16.0265s	
22319/29850 (epoch 37.385), train_loss = 0.89376652, grad/param norm = 2.3517e-01, time/batch = 19.4589s	
22320/29850 (epoch 37.387), train_loss = 0.88702472, grad/param norm = 2.4186e-01, time/batch = 18.2684s	
22321/29850 (epoch 37.389), train_loss = 0.98399364, grad/param norm = 2.6235e-01, time/batch = 17.8714s	
22322/29850 (epoch 37.390), train_loss = 0.91982503, grad/param norm = 2.2362e-01, time/batch = 19.0364s	
22323/29850 (epoch 37.392), train_loss = 0.83333727, grad/param norm = 2.2952e-01, time/batch = 16.2779s	
22324/29850 (epoch 37.394), train_loss = 0.93497168, grad/param norm = 2.3556e-01, time/batch = 19.1896s	
22325/29850 (epoch 37.395), train_loss = 0.78520338, grad/param norm = 2.0430e-01, time/batch = 16.6163s	
22326/29850 (epoch 37.397), train_loss = 0.73333629, grad/param norm = 2.4805e-01, time/batch = 17.4586s	
22327/29850 (epoch 37.399), train_loss = 0.77909391, grad/param norm = 2.4222e-01, time/batch = 17.9510s	
22328/29850 (epoch 37.400), train_loss = 1.11249988, grad/param norm = 2.5816e-01, time/batch = 16.4542s	
22329/29850 (epoch 37.402), train_loss = 1.00090658, grad/param norm = 2.3673e-01, time/batch = 17.2215s	
22330/29850 (epoch 37.404), train_loss = 0.85869686, grad/param norm = 2.1186e-01, time/batch = 18.7094s	
22331/29850 (epoch 37.405), train_loss = 0.79233965, grad/param norm = 2.6548e-01, time/batch = 18.8664s	
22332/29850 (epoch 37.407), train_loss = 0.78906005, grad/param norm = 2.2491e-01, time/batch = 16.4690s	
22333/29850 (epoch 37.409), train_loss = 0.86291782, grad/param norm = 2.2013e-01, time/batch = 16.4828s	
22334/29850 (epoch 37.410), train_loss = 0.97121953, grad/param norm = 2.4183e-01, time/batch = 19.0389s	
22335/29850 (epoch 37.412), train_loss = 0.95022444, grad/param norm = 2.3832e-01, time/batch = 16.3587s	
22336/29850 (epoch 37.414), train_loss = 0.87718218, grad/param norm = 2.3300e-01, time/batch = 18.7198s	
22337/29850 (epoch 37.415), train_loss = 0.82852622, grad/param norm = 1.9206e-01, time/batch = 17.1282s	
22338/29850 (epoch 37.417), train_loss = 0.98905768, grad/param norm = 2.7719e-01, time/batch = 17.7929s	
22339/29850 (epoch 37.419), train_loss = 0.82616869, grad/param norm = 2.3000e-01, time/batch = 17.3116s	
22340/29850 (epoch 37.420), train_loss = 0.85143766, grad/param norm = 2.3486e-01, time/batch = 17.7781s	
22341/29850 (epoch 37.422), train_loss = 0.84288983, grad/param norm = 2.2096e-01, time/batch = 19.3530s	
22342/29850 (epoch 37.424), train_loss = 0.78659379, grad/param norm = 2.1341e-01, time/batch = 18.1940s	
22343/29850 (epoch 37.425), train_loss = 0.91085564, grad/param norm = 2.2648e-01, time/batch = 18.8665s	
22344/29850 (epoch 37.427), train_loss = 0.65891250, grad/param norm = 2.2623e-01, time/batch = 16.7725s	
22345/29850 (epoch 37.429), train_loss = 0.75782214, grad/param norm = 2.2870e-01, time/batch = 15.7659s	
22346/29850 (epoch 37.430), train_loss = 0.70717905, grad/param norm = 2.0254e-01, time/batch = 17.7108s	
22347/29850 (epoch 37.432), train_loss = 0.78302795, grad/param norm = 2.1815e-01, time/batch = 19.3734s	
22348/29850 (epoch 37.434), train_loss = 0.78383371, grad/param norm = 2.2251e-01, time/batch = 17.8682s	
22349/29850 (epoch 37.436), train_loss = 0.81940524, grad/param norm = 2.3310e-01, time/batch = 1.1595s	
22350/29850 (epoch 37.437), train_loss = 0.90475505, grad/param norm = 2.1721e-01, time/batch = 0.6724s	
22351/29850 (epoch 37.439), train_loss = 0.90751562, grad/param norm = 2.2784e-01, time/batch = 0.6709s	
22352/29850 (epoch 37.441), train_loss = 0.86150112, grad/param norm = 2.4168e-01, time/batch = 0.6743s	
22353/29850 (epoch 37.442), train_loss = 0.81759246, grad/param norm = 2.2930e-01, time/batch = 0.6636s	
22354/29850 (epoch 37.444), train_loss = 0.86758549, grad/param norm = 2.1988e-01, time/batch = 0.6631s	
22355/29850 (epoch 37.446), train_loss = 0.92384770, grad/param norm = 2.3316e-01, time/batch = 0.6783s	
22356/29850 (epoch 37.447), train_loss = 0.91982687, grad/param norm = 2.4292e-01, time/batch = 0.8438s	
22357/29850 (epoch 37.449), train_loss = 0.84756986, grad/param norm = 2.1700e-01, time/batch = 0.9705s	
22358/29850 (epoch 37.451), train_loss = 0.66190106, grad/param norm = 1.8975e-01, time/batch = 0.9727s	
22359/29850 (epoch 37.452), train_loss = 0.60458444, grad/param norm = 2.0947e-01, time/batch = 0.9778s	
22360/29850 (epoch 37.454), train_loss = 0.71323549, grad/param norm = 1.9950e-01, time/batch = 0.9663s	
22361/29850 (epoch 37.456), train_loss = 0.91562799, grad/param norm = 2.2711e-01, time/batch = 1.4150s	
22362/29850 (epoch 37.457), train_loss = 0.94479646, grad/param norm = 4.9838e-01, time/batch = 1.8296s	
22363/29850 (epoch 37.459), train_loss = 1.01707490, grad/param norm = 2.8505e-01, time/batch = 1.8274s	
22364/29850 (epoch 37.461), train_loss = 0.98779552, grad/param norm = 2.3207e-01, time/batch = 15.2679s	
22365/29850 (epoch 37.462), train_loss = 1.00513527, grad/param norm = 2.5551e-01, time/batch = 17.7773s	
22366/29850 (epoch 37.464), train_loss = 0.88711879, grad/param norm = 2.3957e-01, time/batch = 17.7904s	
22367/29850 (epoch 37.466), train_loss = 0.73502680, grad/param norm = 2.2033e-01, time/batch = 20.3646s	
22368/29850 (epoch 37.467), train_loss = 0.79592960, grad/param norm = 2.5670e-01, time/batch = 15.8820s	
22369/29850 (epoch 37.469), train_loss = 0.82563099, grad/param norm = 2.0966e-01, time/batch = 17.4603s	
22370/29850 (epoch 37.471), train_loss = 0.81753888, grad/param norm = 2.4605e-01, time/batch = 18.4434s	
22371/29850 (epoch 37.472), train_loss = 0.78377921, grad/param norm = 2.1603e-01, time/batch = 18.1131s	
22372/29850 (epoch 37.474), train_loss = 0.91304669, grad/param norm = 2.0146e-01, time/batch = 16.2092s	
22373/29850 (epoch 37.476), train_loss = 0.86337265, grad/param norm = 2.1389e-01, time/batch = 16.1061s	
22374/29850 (epoch 37.477), train_loss = 0.87218525, grad/param norm = 2.4702e-01, time/batch = 19.6305s	
22375/29850 (epoch 37.479), train_loss = 1.01762162, grad/param norm = 2.4559e-01, time/batch = 19.1978s	
22376/29850 (epoch 37.481), train_loss = 0.86947193, grad/param norm = 2.5545e-01, time/batch = 17.5231s	
22377/29850 (epoch 37.482), train_loss = 0.77638113, grad/param norm = 1.9053e-01, time/batch = 17.9618s	
22378/29850 (epoch 37.484), train_loss = 0.80988856, grad/param norm = 2.2268e-01, time/batch = 20.4408s	
22379/29850 (epoch 37.486), train_loss = 0.88824942, grad/param norm = 2.7114e-01, time/batch = 17.4574s	
22380/29850 (epoch 37.487), train_loss = 0.84255510, grad/param norm = 1.9929e-01, time/batch = 17.1241s	
22381/29850 (epoch 37.489), train_loss = 0.84890608, grad/param norm = 2.3062e-01, time/batch = 18.3860s	
22382/29850 (epoch 37.491), train_loss = 0.76092856, grad/param norm = 2.0913e-01, time/batch = 17.8749s	
22383/29850 (epoch 37.492), train_loss = 0.85438085, grad/param norm = 2.2531e-01, time/batch = 18.5356s	
22384/29850 (epoch 37.494), train_loss = 0.92605223, grad/param norm = 2.3980e-01, time/batch = 18.6350s	
22385/29850 (epoch 37.496), train_loss = 0.95586539, grad/param norm = 2.3999e-01, time/batch = 16.8917s	
22386/29850 (epoch 37.497), train_loss = 0.90236423, grad/param norm = 2.4989e-01, time/batch = 18.2808s	
22387/29850 (epoch 37.499), train_loss = 0.85790697, grad/param norm = 2.2407e-01, time/batch = 16.6360s	
22388/29850 (epoch 37.501), train_loss = 0.74850369, grad/param norm = 2.2524e-01, time/batch = 17.2548s	
22389/29850 (epoch 37.503), train_loss = 0.91076795, grad/param norm = 2.2288e-01, time/batch = 17.8659s	
22390/29850 (epoch 37.504), train_loss = 1.06289427, grad/param norm = 2.3112e-01, time/batch = 17.3841s	
22391/29850 (epoch 37.506), train_loss = 1.03315660, grad/param norm = 2.5390e-01, time/batch = 19.2798s	
22392/29850 (epoch 37.508), train_loss = 0.88217141, grad/param norm = 2.2262e-01, time/batch = 18.4504s	
22393/29850 (epoch 37.509), train_loss = 0.69234453, grad/param norm = 2.0001e-01, time/batch = 18.8040s	
22394/29850 (epoch 37.511), train_loss = 0.89053669, grad/param norm = 2.5112e-01, time/batch = 17.5537s	
22395/29850 (epoch 37.513), train_loss = 0.86400719, grad/param norm = 2.9270e-01, time/batch = 19.3764s	
22396/29850 (epoch 37.514), train_loss = 0.75930505, grad/param norm = 2.2106e-01, time/batch = 15.3526s	
22397/29850 (epoch 37.516), train_loss = 0.79686973, grad/param norm = 1.9173e-01, time/batch = 18.9477s	
22398/29850 (epoch 37.518), train_loss = 0.69557645, grad/param norm = 1.9924e-01, time/batch = 17.9536s	
22399/29850 (epoch 37.519), train_loss = 0.67230515, grad/param norm = 1.9055e-01, time/batch = 17.7879s	
22400/29850 (epoch 37.521), train_loss = 0.63040613, grad/param norm = 1.8187e-01, time/batch = 17.1995s	
22401/29850 (epoch 37.523), train_loss = 0.69092342, grad/param norm = 1.9465e-01, time/batch = 16.8140s	
22402/29850 (epoch 37.524), train_loss = 0.75286139, grad/param norm = 2.4375e-01, time/batch = 16.6271s	
22403/29850 (epoch 37.526), train_loss = 0.80587722, grad/param norm = 2.4468e-01, time/batch = 17.1180s	
22404/29850 (epoch 37.528), train_loss = 0.90621040, grad/param norm = 2.4758e-01, time/batch = 16.2634s	
22405/29850 (epoch 37.529), train_loss = 0.86215640, grad/param norm = 2.1874e-01, time/batch = 16.8958s	
22406/29850 (epoch 37.531), train_loss = 0.82925406, grad/param norm = 2.7467e-01, time/batch = 17.4537s	
22407/29850 (epoch 37.533), train_loss = 0.83289941, grad/param norm = 2.1596e-01, time/batch = 16.9603s	
22408/29850 (epoch 37.534), train_loss = 0.91698035, grad/param norm = 2.5566e-01, time/batch = 17.9597s	
22409/29850 (epoch 37.536), train_loss = 0.77836553, grad/param norm = 2.3829e-01, time/batch = 18.7985s	
22410/29850 (epoch 37.538), train_loss = 0.98115276, grad/param norm = 3.1226e-01, time/batch = 17.4591s	
22411/29850 (epoch 37.539), train_loss = 0.97390562, grad/param norm = 2.2921e-01, time/batch = 19.0624s	
22412/29850 (epoch 37.541), train_loss = 0.61399594, grad/param norm = 2.1029e-01, time/batch = 18.2127s	
22413/29850 (epoch 37.543), train_loss = 0.79521443, grad/param norm = 2.1941e-01, time/batch = 15.3489s	
22414/29850 (epoch 37.544), train_loss = 0.94351532, grad/param norm = 2.6178e-01, time/batch = 19.6208s	
22415/29850 (epoch 37.546), train_loss = 0.90977797, grad/param norm = 2.4516e-01, time/batch = 18.5193s	
22416/29850 (epoch 37.548), train_loss = 0.70169528, grad/param norm = 1.7727e-01, time/batch = 17.3700s	
22417/29850 (epoch 37.549), train_loss = 0.79388967, grad/param norm = 2.3245e-01, time/batch = 18.4624s	
22418/29850 (epoch 37.551), train_loss = 0.75298707, grad/param norm = 2.1660e-01, time/batch = 16.7065s	
22419/29850 (epoch 37.553), train_loss = 0.83857458, grad/param norm = 2.4797e-01, time/batch = 18.2195s	
22420/29850 (epoch 37.554), train_loss = 0.71721584, grad/param norm = 2.4273e-01, time/batch = 18.4523s	
22421/29850 (epoch 37.556), train_loss = 0.73317818, grad/param norm = 2.4751e-01, time/batch = 16.4582s	
22422/29850 (epoch 37.558), train_loss = 0.74534766, grad/param norm = 2.7660e-01, time/batch = 18.8052s	
22423/29850 (epoch 37.559), train_loss = 0.79456239, grad/param norm = 2.3558e-01, time/batch = 15.6936s	
22424/29850 (epoch 37.561), train_loss = 0.85484458, grad/param norm = 2.2254e-01, time/batch = 17.3867s	
22425/29850 (epoch 37.563), train_loss = 0.86016766, grad/param norm = 2.0837e-01, time/batch = 19.6211s	
22426/29850 (epoch 37.564), train_loss = 0.78878736, grad/param norm = 2.3833e-01, time/batch = 17.9574s	
22427/29850 (epoch 37.566), train_loss = 0.83982654, grad/param norm = 2.1777e-01, time/batch = 17.7754s	
22428/29850 (epoch 37.568), train_loss = 0.96873038, grad/param norm = 2.3710e-01, time/batch = 16.6316s	
22429/29850 (epoch 37.570), train_loss = 0.85408364, grad/param norm = 2.4677e-01, time/batch = 18.9421s	
22430/29850 (epoch 37.571), train_loss = 0.94442882, grad/param norm = 2.5355e-01, time/batch = 16.2842s	
22431/29850 (epoch 37.573), train_loss = 0.98565488, grad/param norm = 2.3231e-01, time/batch = 15.5488s	
22432/29850 (epoch 37.575), train_loss = 1.00324775, grad/param norm = 2.3095e-01, time/batch = 17.3808s	
22433/29850 (epoch 37.576), train_loss = 0.91935232, grad/param norm = 2.3407e-01, time/batch = 16.6980s	
22434/29850 (epoch 37.578), train_loss = 0.78849735, grad/param norm = 2.4197e-01, time/batch = 18.8794s	
22435/29850 (epoch 37.580), train_loss = 0.93354051, grad/param norm = 3.4698e-01, time/batch = 18.1364s	
22436/29850 (epoch 37.581), train_loss = 0.76627614, grad/param norm = 2.4082e-01, time/batch = 16.9788s	
22437/29850 (epoch 37.583), train_loss = 0.81518271, grad/param norm = 2.0360e-01, time/batch = 16.1390s	
22438/29850 (epoch 37.585), train_loss = 0.85881994, grad/param norm = 2.0787e-01, time/batch = 15.7064s	
22439/29850 (epoch 37.586), train_loss = 0.89110023, grad/param norm = 2.6226e-01, time/batch = 17.6368s	
22440/29850 (epoch 37.588), train_loss = 0.78216881, grad/param norm = 2.5070e-01, time/batch = 16.4454s	
22441/29850 (epoch 37.590), train_loss = 0.79204223, grad/param norm = 1.9445e-01, time/batch = 18.6997s	
22442/29850 (epoch 37.591), train_loss = 0.81979880, grad/param norm = 2.4301e-01, time/batch = 18.9676s	
22443/29850 (epoch 37.593), train_loss = 0.74935660, grad/param norm = 1.9572e-01, time/batch = 17.2862s	
22444/29850 (epoch 37.595), train_loss = 0.71116380, grad/param norm = 1.7655e-01, time/batch = 19.6116s	
22445/29850 (epoch 37.596), train_loss = 0.74361424, grad/param norm = 2.4749e-01, time/batch = 19.4511s	
22446/29850 (epoch 37.598), train_loss = 0.83167630, grad/param norm = 2.2909e-01, time/batch = 17.3832s	
22447/29850 (epoch 37.600), train_loss = 0.83838433, grad/param norm = 2.0715e-01, time/batch = 18.1930s	
22448/29850 (epoch 37.601), train_loss = 0.72173305, grad/param norm = 1.7931e-01, time/batch = 15.8645s	
22449/29850 (epoch 37.603), train_loss = 0.77967130, grad/param norm = 2.4110e-01, time/batch = 18.6989s	
22450/29850 (epoch 37.605), train_loss = 0.81272961, grad/param norm = 2.1802e-01, time/batch = 18.1088s	
22451/29850 (epoch 37.606), train_loss = 0.57598288, grad/param norm = 1.9140e-01, time/batch = 15.7793s	
22452/29850 (epoch 37.608), train_loss = 0.73041787, grad/param norm = 1.8579e-01, time/batch = 19.2849s	
22453/29850 (epoch 37.610), train_loss = 0.78560079, grad/param norm = 2.1597e-01, time/batch = 17.9605s	
22454/29850 (epoch 37.611), train_loss = 0.72479594, grad/param norm = 2.0230e-01, time/batch = 19.5372s	
22455/29850 (epoch 37.613), train_loss = 0.61089677, grad/param norm = 1.7758e-01, time/batch = 16.3844s	
22456/29850 (epoch 37.615), train_loss = 0.68628674, grad/param norm = 1.8954e-01, time/batch = 18.8016s	
22457/29850 (epoch 37.616), train_loss = 0.71176527, grad/param norm = 2.2200e-01, time/batch = 18.2798s	
22458/29850 (epoch 37.618), train_loss = 0.77421664, grad/param norm = 2.1182e-01, time/batch = 17.9623s	
22459/29850 (epoch 37.620), train_loss = 0.88146908, grad/param norm = 2.6681e-01, time/batch = 18.2967s	
22460/29850 (epoch 37.621), train_loss = 0.95891077, grad/param norm = 2.6980e-01, time/batch = 16.9683s	
22461/29850 (epoch 37.623), train_loss = 0.91075702, grad/param norm = 2.1167e-01, time/batch = 17.7144s	
22462/29850 (epoch 37.625), train_loss = 0.82663863, grad/param norm = 2.1484e-01, time/batch = 19.2078s	
22463/29850 (epoch 37.626), train_loss = 0.85683363, grad/param norm = 2.5009e-01, time/batch = 17.8416s	
22464/29850 (epoch 37.628), train_loss = 0.81344622, grad/param norm = 2.4047e-01, time/batch = 18.4705s	
22465/29850 (epoch 37.630), train_loss = 0.85617009, grad/param norm = 2.4620e-01, time/batch = 18.5463s	
22466/29850 (epoch 37.631), train_loss = 0.85217463, grad/param norm = 2.2765e-01, time/batch = 18.0395s	
22467/29850 (epoch 37.633), train_loss = 0.86640470, grad/param norm = 2.4574e-01, time/batch = 16.8530s	
22468/29850 (epoch 37.635), train_loss = 0.79379692, grad/param norm = 2.7126e-01, time/batch = 18.1979s	
22469/29850 (epoch 37.637), train_loss = 0.72586524, grad/param norm = 1.8810e-01, time/batch = 19.2869s	
22470/29850 (epoch 37.638), train_loss = 0.86219477, grad/param norm = 2.3045e-01, time/batch = 16.8026s	
22471/29850 (epoch 37.640), train_loss = 0.99355576, grad/param norm = 3.0433e-01, time/batch = 16.1221s	
22472/29850 (epoch 37.642), train_loss = 0.80555313, grad/param norm = 2.1639e-01, time/batch = 19.2112s	
22473/29850 (epoch 37.643), train_loss = 0.76040342, grad/param norm = 2.2627e-01, time/batch = 17.1123s	
22474/29850 (epoch 37.645), train_loss = 0.81599891, grad/param norm = 2.2452e-01, time/batch = 19.6132s	
22475/29850 (epoch 37.647), train_loss = 0.95147136, grad/param norm = 2.1624e-01, time/batch = 17.2955s	
22476/29850 (epoch 37.648), train_loss = 0.73689785, grad/param norm = 2.0058e-01, time/batch = 18.4641s	
22477/29850 (epoch 37.650), train_loss = 0.83216635, grad/param norm = 2.2962e-01, time/batch = 17.2062s	
22478/29850 (epoch 37.652), train_loss = 0.84709443, grad/param norm = 2.8442e-01, time/batch = 18.9533s	
22479/29850 (epoch 37.653), train_loss = 0.91430711, grad/param norm = 2.9239e-01, time/batch = 18.1360s	
22480/29850 (epoch 37.655), train_loss = 0.83590887, grad/param norm = 1.9125e-01, time/batch = 16.9514s	
22481/29850 (epoch 37.657), train_loss = 0.82806967, grad/param norm = 2.1286e-01, time/batch = 19.3642s	
22482/29850 (epoch 37.658), train_loss = 0.93839694, grad/param norm = 2.3070e-01, time/batch = 16.2166s	
22483/29850 (epoch 37.660), train_loss = 0.80300937, grad/param norm = 2.5089e-01, time/batch = 17.7160s	
22484/29850 (epoch 37.662), train_loss = 0.94202778, grad/param norm = 2.9913e-01, time/batch = 16.2305s	
22485/29850 (epoch 37.663), train_loss = 1.03320175, grad/param norm = 2.2629e-01, time/batch = 19.5506s	
22486/29850 (epoch 37.665), train_loss = 0.98126519, grad/param norm = 2.5475e-01, time/batch = 19.1175s	
22487/29850 (epoch 37.667), train_loss = 0.91661789, grad/param norm = 2.8849e-01, time/batch = 18.1311s	
22488/29850 (epoch 37.668), train_loss = 0.79989840, grad/param norm = 2.2592e-01, time/batch = 17.2745s	
22489/29850 (epoch 37.670), train_loss = 0.92989283, grad/param norm = 2.7451e-01, time/batch = 18.6171s	
22490/29850 (epoch 37.672), train_loss = 0.95922401, grad/param norm = 2.8466e-01, time/batch = 15.8096s	
22491/29850 (epoch 37.673), train_loss = 0.89398931, grad/param norm = 2.7201e-01, time/batch = 16.5276s	
22492/29850 (epoch 37.675), train_loss = 0.75034097, grad/param norm = 2.0150e-01, time/batch = 19.4678s	
22493/29850 (epoch 37.677), train_loss = 0.80196485, grad/param norm = 2.3887e-01, time/batch = 16.7891s	
22494/29850 (epoch 37.678), train_loss = 0.83877431, grad/param norm = 2.3305e-01, time/batch = 18.2051s	
22495/29850 (epoch 37.680), train_loss = 0.82785106, grad/param norm = 2.4099e-01, time/batch = 15.5266s	
22496/29850 (epoch 37.682), train_loss = 0.84330854, grad/param norm = 2.2329e-01, time/batch = 18.2981s	
22497/29850 (epoch 37.683), train_loss = 0.95171454, grad/param norm = 2.5826e-01, time/batch = 15.6933s	
22498/29850 (epoch 37.685), train_loss = 1.05100532, grad/param norm = 2.5190e-01, time/batch = 18.3626s	
22499/29850 (epoch 37.687), train_loss = 0.87660519, grad/param norm = 2.1271e-01, time/batch = 18.5499s	
22500/29850 (epoch 37.688), train_loss = 0.76809284, grad/param norm = 2.2474e-01, time/batch = 18.1225s	
22501/29850 (epoch 37.690), train_loss = 0.76241210, grad/param norm = 2.4805e-01, time/batch = 18.3571s	
22502/29850 (epoch 37.692), train_loss = 0.94250170, grad/param norm = 2.4130e-01, time/batch = 19.2039s	
22503/29850 (epoch 37.693), train_loss = 0.83764461, grad/param norm = 2.1051e-01, time/batch = 18.2099s	
22504/29850 (epoch 37.695), train_loss = 0.73843900, grad/param norm = 2.3346e-01, time/batch = 17.6239s	
22505/29850 (epoch 37.697), train_loss = 0.83902073, grad/param norm = 2.2266e-01, time/batch = 16.8655s	
22506/29850 (epoch 37.698), train_loss = 0.95340123, grad/param norm = 2.1830e-01, time/batch = 19.2770s	
22507/29850 (epoch 37.700), train_loss = 0.91428616, grad/param norm = 3.0264e-01, time/batch = 18.8657s	
22508/29850 (epoch 37.702), train_loss = 0.87082670, grad/param norm = 2.6161e-01, time/batch = 17.2198s	
22509/29850 (epoch 37.704), train_loss = 0.72447124, grad/param norm = 2.0784e-01, time/batch = 18.8737s	
22510/29850 (epoch 37.705), train_loss = 0.83224277, grad/param norm = 2.1164e-01, time/batch = 16.8006s	
22511/29850 (epoch 37.707), train_loss = 0.77336001, grad/param norm = 2.2083e-01, time/batch = 18.9572s	
22512/29850 (epoch 37.709), train_loss = 0.83509267, grad/param norm = 2.3587e-01, time/batch = 17.7145s	
22513/29850 (epoch 37.710), train_loss = 0.76688766, grad/param norm = 2.2464e-01, time/batch = 17.1299s	
22514/29850 (epoch 37.712), train_loss = 0.86318915, grad/param norm = 2.0094e-01, time/batch = 18.0387s	
22515/29850 (epoch 37.714), train_loss = 0.94051839, grad/param norm = 2.7866e-01, time/batch = 17.3049s	
22516/29850 (epoch 37.715), train_loss = 0.86085244, grad/param norm = 2.3836e-01, time/batch = 19.3731s	
22517/29850 (epoch 37.717), train_loss = 0.64181755, grad/param norm = 2.1350e-01, time/batch = 18.7717s	
22518/29850 (epoch 37.719), train_loss = 0.78978988, grad/param norm = 2.1537e-01, time/batch = 15.3749s	
22519/29850 (epoch 37.720), train_loss = 0.81648587, grad/param norm = 1.9294e-01, time/batch = 18.7823s	
22520/29850 (epoch 37.722), train_loss = 0.76499948, grad/param norm = 1.9740e-01, time/batch = 17.2594s	
22521/29850 (epoch 37.724), train_loss = 0.88110763, grad/param norm = 2.8605e-01, time/batch = 17.6163s	
22522/29850 (epoch 37.725), train_loss = 0.72090450, grad/param norm = 1.7942e-01, time/batch = 15.4897s	
22523/29850 (epoch 37.727), train_loss = 0.73236493, grad/param norm = 2.2529e-01, time/batch = 19.1874s	
22524/29850 (epoch 37.729), train_loss = 0.68904957, grad/param norm = 1.7345e-01, time/batch = 19.8483s	
22525/29850 (epoch 37.730), train_loss = 0.65914974, grad/param norm = 2.0216e-01, time/batch = 17.6049s	
22526/29850 (epoch 37.732), train_loss = 0.92476243, grad/param norm = 2.0307e-01, time/batch = 19.5492s	
22527/29850 (epoch 37.734), train_loss = 1.00838949, grad/param norm = 2.8189e-01, time/batch = 17.3689s	
22528/29850 (epoch 37.735), train_loss = 0.76105381, grad/param norm = 2.4552e-01, time/batch = 19.6201s	
22529/29850 (epoch 37.737), train_loss = 0.73567428, grad/param norm = 2.1344e-01, time/batch = 17.2888s	
22530/29850 (epoch 37.739), train_loss = 0.66006162, grad/param norm = 2.1009e-01, time/batch = 28.6341s	
22531/29850 (epoch 37.740), train_loss = 0.70661575, grad/param norm = 2.5478e-01, time/batch = 20.1998s	
22532/29850 (epoch 37.742), train_loss = 0.62926866, grad/param norm = 1.7576e-01, time/batch = 16.6205s	
22533/29850 (epoch 37.744), train_loss = 0.76394167, grad/param norm = 2.4045e-01, time/batch = 17.6341s	
22534/29850 (epoch 37.745), train_loss = 0.77354088, grad/param norm = 2.1437e-01, time/batch = 17.7066s	
22535/29850 (epoch 37.747), train_loss = 0.82500483, grad/param norm = 2.2486e-01, time/batch = 18.2770s	
22536/29850 (epoch 37.749), train_loss = 0.71006541, grad/param norm = 2.1333e-01, time/batch = 17.2641s	
22537/29850 (epoch 37.750), train_loss = 0.64935279, grad/param norm = 2.0875e-01, time/batch = 16.7944s	
22538/29850 (epoch 37.752), train_loss = 0.57633070, grad/param norm = 1.9875e-01, time/batch = 17.2097s	
22539/29850 (epoch 37.754), train_loss = 0.64170584, grad/param norm = 2.0561e-01, time/batch = 17.3075s	
22540/29850 (epoch 37.755), train_loss = 0.67097062, grad/param norm = 2.0506e-01, time/batch = 18.1293s	
22541/29850 (epoch 37.757), train_loss = 0.70983150, grad/param norm = 1.8885e-01, time/batch = 18.6298s	
22542/29850 (epoch 37.759), train_loss = 0.72413408, grad/param norm = 2.1597e-01, time/batch = 15.3832s	
22543/29850 (epoch 37.760), train_loss = 0.75037672, grad/param norm = 2.2830e-01, time/batch = 17.1814s	
22544/29850 (epoch 37.762), train_loss = 0.68116234, grad/param norm = 2.4040e-01, time/batch = 16.9459s	
22545/29850 (epoch 37.764), train_loss = 0.59958923, grad/param norm = 2.0617e-01, time/batch = 18.2925s	
22546/29850 (epoch 37.765), train_loss = 0.76474551, grad/param norm = 2.3564e-01, time/batch = 16.8785s	
22547/29850 (epoch 37.767), train_loss = 0.76411513, grad/param norm = 2.1146e-01, time/batch = 17.8034s	
22548/29850 (epoch 37.769), train_loss = 0.79593305, grad/param norm = 2.1161e-01, time/batch = 17.6851s	
22549/29850 (epoch 37.771), train_loss = 0.82025496, grad/param norm = 2.0502e-01, time/batch = 16.9528s	
22550/29850 (epoch 37.772), train_loss = 0.79907276, grad/param norm = 2.3161e-01, time/batch = 16.4383s	
22551/29850 (epoch 37.774), train_loss = 0.73765727, grad/param norm = 2.2168e-01, time/batch = 18.4301s	
22552/29850 (epoch 37.776), train_loss = 0.77466906, grad/param norm = 2.2362e-01, time/batch = 18.8712s	
22553/29850 (epoch 37.777), train_loss = 0.87928024, grad/param norm = 2.4219e-01, time/batch = 16.8852s	
22554/29850 (epoch 37.779), train_loss = 0.71934233, grad/param norm = 2.3583e-01, time/batch = 16.3909s	
22555/29850 (epoch 37.781), train_loss = 0.84106032, grad/param norm = 2.3411e-01, time/batch = 17.4764s	
22556/29850 (epoch 37.782), train_loss = 0.83404656, grad/param norm = 2.0915e-01, time/batch = 17.0425s	
22557/29850 (epoch 37.784), train_loss = 0.65659706, grad/param norm = 2.1638e-01, time/batch = 18.1352s	
22558/29850 (epoch 37.786), train_loss = 0.74406721, grad/param norm = 2.0995e-01, time/batch = 17.7967s	
22559/29850 (epoch 37.787), train_loss = 0.61336955, grad/param norm = 2.0494e-01, time/batch = 18.3812s	
22560/29850 (epoch 37.789), train_loss = 0.64873563, grad/param norm = 1.9978e-01, time/batch = 15.1181s	
22561/29850 (epoch 37.791), train_loss = 0.72788380, grad/param norm = 2.4922e-01, time/batch = 18.2931s	
22562/29850 (epoch 37.792), train_loss = 0.82957363, grad/param norm = 2.3867e-01, time/batch = 19.0483s	
22563/29850 (epoch 37.794), train_loss = 0.79180273, grad/param norm = 2.0685e-01, time/batch = 16.3764s	
22564/29850 (epoch 37.796), train_loss = 0.70813011, grad/param norm = 1.9680e-01, time/batch = 17.0384s	
22565/29850 (epoch 37.797), train_loss = 0.59546235, grad/param norm = 1.8948e-01, time/batch = 18.5484s	
22566/29850 (epoch 37.799), train_loss = 0.65495863, grad/param norm = 1.8521e-01, time/batch = 18.1353s	
22567/29850 (epoch 37.801), train_loss = 0.66592123, grad/param norm = 1.9699e-01, time/batch = 17.9618s	
22568/29850 (epoch 37.802), train_loss = 0.63221367, grad/param norm = 2.0962e-01, time/batch = 18.2833s	
22569/29850 (epoch 37.804), train_loss = 0.68335347, grad/param norm = 1.8698e-01, time/batch = 18.5447s	
22570/29850 (epoch 37.806), train_loss = 0.63212041, grad/param norm = 2.1361e-01, time/batch = 16.8587s	
22571/29850 (epoch 37.807), train_loss = 0.66297534, grad/param norm = 1.7250e-01, time/batch = 16.9342s	
22572/29850 (epoch 37.809), train_loss = 0.67486691, grad/param norm = 2.4301e-01, time/batch = 16.6820s	
22573/29850 (epoch 37.811), train_loss = 0.82458231, grad/param norm = 2.4155e-01, time/batch = 16.8840s	
22574/29850 (epoch 37.812), train_loss = 0.81232831, grad/param norm = 2.5398e-01, time/batch = 17.4590s	
22575/29850 (epoch 37.814), train_loss = 0.84076332, grad/param norm = 2.5006e-01, time/batch = 19.0994s	
22576/29850 (epoch 37.816), train_loss = 0.89705194, grad/param norm = 2.1304e-01, time/batch = 18.1062s	
22577/29850 (epoch 37.817), train_loss = 0.82010727, grad/param norm = 2.6891e-01, time/batch = 18.5191s	
22578/29850 (epoch 37.819), train_loss = 0.64496576, grad/param norm = 2.0652e-01, time/batch = 17.3660s	
22579/29850 (epoch 37.821), train_loss = 0.88864529, grad/param norm = 2.5977e-01, time/batch = 18.9557s	
22580/29850 (epoch 37.822), train_loss = 0.89747900, grad/param norm = 2.1211e-01, time/batch = 17.6887s	
22581/29850 (epoch 37.824), train_loss = 0.77589143, grad/param norm = 2.0844e-01, time/batch = 17.7121s	
22582/29850 (epoch 37.826), train_loss = 0.68328406, grad/param norm = 1.8361e-01, time/batch = 18.1352s	
22583/29850 (epoch 37.827), train_loss = 0.62383638, grad/param norm = 2.3925e-01, time/batch = 17.6905s	
22584/29850 (epoch 37.829), train_loss = 0.80174329, grad/param norm = 2.8514e-01, time/batch = 18.5406s	
22585/29850 (epoch 37.831), train_loss = 0.90927637, grad/param norm = 2.5137e-01, time/batch = 17.8856s	
22586/29850 (epoch 37.832), train_loss = 0.80598780, grad/param norm = 1.9754e-01, time/batch = 16.8694s	
22587/29850 (epoch 37.834), train_loss = 0.60650586, grad/param norm = 1.8705e-01, time/batch = 17.1094s	
22588/29850 (epoch 37.836), train_loss = 0.62965215, grad/param norm = 2.1789e-01, time/batch = 16.7210s	
22589/29850 (epoch 37.838), train_loss = 0.72958248, grad/param norm = 2.9001e-01, time/batch = 16.0968s	
22590/29850 (epoch 37.839), train_loss = 0.64372390, grad/param norm = 2.2841e-01, time/batch = 16.8856s	
22591/29850 (epoch 37.841), train_loss = 0.69541565, grad/param norm = 2.1737e-01, time/batch = 18.1450s	
22592/29850 (epoch 37.843), train_loss = 0.64848493, grad/param norm = 2.3993e-01, time/batch = 17.3070s	
22593/29850 (epoch 37.844), train_loss = 0.70259401, grad/param norm = 2.0664e-01, time/batch = 18.3901s	
22594/29850 (epoch 37.846), train_loss = 0.74473296, grad/param norm = 2.0812e-01, time/batch = 17.3784s	
22595/29850 (epoch 37.848), train_loss = 0.82852109, grad/param norm = 2.3699e-01, time/batch = 17.9568s	
22596/29850 (epoch 37.849), train_loss = 0.74243038, grad/param norm = 2.1164e-01, time/batch = 18.9533s	
22597/29850 (epoch 37.851), train_loss = 0.93373938, grad/param norm = 2.3630e-01, time/batch = 15.7182s	
22598/29850 (epoch 37.853), train_loss = 0.76874239, grad/param norm = 2.6020e-01, time/batch = 18.6255s	
22599/29850 (epoch 37.854), train_loss = 0.92195707, grad/param norm = 2.4366e-01, time/batch = 16.6942s	
22600/29850 (epoch 37.856), train_loss = 0.86806761, grad/param norm = 2.3596e-01, time/batch = 17.0291s	
22601/29850 (epoch 37.858), train_loss = 0.81464331, grad/param norm = 2.6774e-01, time/batch = 17.4572s	
22602/29850 (epoch 37.859), train_loss = 0.72894244, grad/param norm = 3.3053e-01, time/batch = 17.5540s	
22603/29850 (epoch 37.861), train_loss = 0.94675055, grad/param norm = 3.0095e-01, time/batch = 17.8705s	
22604/29850 (epoch 37.863), train_loss = 0.92867960, grad/param norm = 2.5620e-01, time/batch = 17.4540s	
22605/29850 (epoch 37.864), train_loss = 0.88489371, grad/param norm = 2.3383e-01, time/batch = 16.8670s	
22606/29850 (epoch 37.866), train_loss = 0.82143311, grad/param norm = 2.4814e-01, time/batch = 17.7858s	
22607/29850 (epoch 37.868), train_loss = 0.93209179, grad/param norm = 2.3919e-01, time/batch = 18.2963s	
22608/29850 (epoch 37.869), train_loss = 0.88270776, grad/param norm = 3.2436e-01, time/batch = 17.5515s	
22609/29850 (epoch 37.871), train_loss = 0.88810342, grad/param norm = 2.3280e-01, time/batch = 16.4400s	
22610/29850 (epoch 37.873), train_loss = 0.84295943, grad/param norm = 2.5512e-01, time/batch = 18.0587s	
22611/29850 (epoch 37.874), train_loss = 0.84550403, grad/param norm = 2.1123e-01, time/batch = 17.3786s	
22612/29850 (epoch 37.876), train_loss = 0.81871263, grad/param norm = 2.6546e-01, time/batch = 19.5423s	
22613/29850 (epoch 37.878), train_loss = 0.80893944, grad/param norm = 2.0555e-01, time/batch = 18.4647s	
22614/29850 (epoch 37.879), train_loss = 0.83236194, grad/param norm = 2.0945e-01, time/batch = 15.9545s	
22615/29850 (epoch 37.881), train_loss = 0.92334504, grad/param norm = 2.5568e-01, time/batch = 18.6314s	
22616/29850 (epoch 37.883), train_loss = 0.85936512, grad/param norm = 2.3699e-01, time/batch = 17.8059s	
22617/29850 (epoch 37.884), train_loss = 0.71771890, grad/param norm = 2.4100e-01, time/batch = 17.5540s	
22618/29850 (epoch 37.886), train_loss = 0.88361035, grad/param norm = 2.3742e-01, time/batch = 18.5307s	
22619/29850 (epoch 37.888), train_loss = 0.83564628, grad/param norm = 2.3953e-01, time/batch = 15.7838s	
22620/29850 (epoch 37.889), train_loss = 0.76147488, grad/param norm = 2.1347e-01, time/batch = 18.7976s	
22621/29850 (epoch 37.891), train_loss = 0.72131924, grad/param norm = 1.7851e-01, time/batch = 18.1271s	
22622/29850 (epoch 37.893), train_loss = 0.77959998, grad/param norm = 2.2984e-01, time/batch = 16.1977s	
22623/29850 (epoch 37.894), train_loss = 0.77587519, grad/param norm = 2.2431e-01, time/batch = 16.2316s	
22624/29850 (epoch 37.896), train_loss = 0.82792325, grad/param norm = 3.0217e-01, time/batch = 17.2166s	
22625/29850 (epoch 37.898), train_loss = 0.96173863, grad/param norm = 2.8403e-01, time/batch = 18.1210s	
22626/29850 (epoch 37.899), train_loss = 0.71797585, grad/param norm = 2.4318e-01, time/batch = 18.1126s	
22627/29850 (epoch 37.901), train_loss = 1.01177543, grad/param norm = 3.6705e-01, time/batch = 14.7411s	
22628/29850 (epoch 37.903), train_loss = 0.87642279, grad/param norm = 4.5911e-01, time/batch = 17.7082s	
22629/29850 (epoch 37.905), train_loss = 1.11729431, grad/param norm = 2.7191e-01, time/batch = 18.8707s	
22630/29850 (epoch 37.906), train_loss = 0.85519326, grad/param norm = 2.6282e-01, time/batch = 17.5500s	
22631/29850 (epoch 37.908), train_loss = 1.00596413, grad/param norm = 2.6044e-01, time/batch = 15.5134s	
22632/29850 (epoch 37.910), train_loss = 0.90008772, grad/param norm = 2.3233e-01, time/batch = 16.8157s	
22633/29850 (epoch 37.911), train_loss = 1.02633168, grad/param norm = 2.3116e-01, time/batch = 15.9958s	
22634/29850 (epoch 37.913), train_loss = 0.98449606, grad/param norm = 2.7760e-01, time/batch = 17.6444s	
22635/29850 (epoch 37.915), train_loss = 0.94897737, grad/param norm = 2.3647e-01, time/batch = 18.1030s	
22636/29850 (epoch 37.916), train_loss = 0.92023432, grad/param norm = 2.4328e-01, time/batch = 17.7766s	
22637/29850 (epoch 37.918), train_loss = 0.77038626, grad/param norm = 2.0069e-01, time/batch = 17.9688s	
22638/29850 (epoch 37.920), train_loss = 0.93146885, grad/param norm = 2.0935e-01, time/batch = 16.4535s	
22639/29850 (epoch 37.921), train_loss = 0.82571820, grad/param norm = 2.4818e-01, time/batch = 17.4597s	
22640/29850 (epoch 37.923), train_loss = 0.83917232, grad/param norm = 2.5270e-01, time/batch = 16.5390s	
22641/29850 (epoch 37.925), train_loss = 0.97621290, grad/param norm = 2.6060e-01, time/batch = 16.1864s	
22642/29850 (epoch 37.926), train_loss = 1.01144483, grad/param norm = 3.3007e-01, time/batch = 18.6145s	
22643/29850 (epoch 37.928), train_loss = 0.83809512, grad/param norm = 2.4021e-01, time/batch = 16.8951s	
22644/29850 (epoch 37.930), train_loss = 0.86493552, grad/param norm = 2.2271e-01, time/batch = 19.9514s	
22645/29850 (epoch 37.931), train_loss = 0.85230904, grad/param norm = 2.3238e-01, time/batch = 15.9717s	
22646/29850 (epoch 37.933), train_loss = 0.99183323, grad/param norm = 2.6189e-01, time/batch = 17.0697s	
22647/29850 (epoch 37.935), train_loss = 0.90653582, grad/param norm = 2.5057e-01, time/batch = 14.8222s	
22648/29850 (epoch 37.936), train_loss = 0.87693354, grad/param norm = 2.5918e-01, time/batch = 14.8301s	
22649/29850 (epoch 37.938), train_loss = 0.74083163, grad/param norm = 1.9613e-01, time/batch = 15.3416s	
22650/29850 (epoch 37.940), train_loss = 0.76456584, grad/param norm = 2.1736e-01, time/batch = 15.0449s	
22651/29850 (epoch 37.941), train_loss = 0.76937981, grad/param norm = 2.5206e-01, time/batch = 15.7727s	
22652/29850 (epoch 37.943), train_loss = 0.78674822, grad/param norm = 2.3188e-01, time/batch = 16.8035s	
22653/29850 (epoch 37.945), train_loss = 0.72901561, grad/param norm = 2.3133e-01, time/batch = 15.9610s	
22654/29850 (epoch 37.946), train_loss = 0.72881684, grad/param norm = 2.1123e-01, time/batch = 18.7136s	
22655/29850 (epoch 37.948), train_loss = 0.83920374, grad/param norm = 2.2567e-01, time/batch = 16.2858s	
22656/29850 (epoch 37.950), train_loss = 0.78310009, grad/param norm = 1.8774e-01, time/batch = 16.2987s	
22657/29850 (epoch 37.951), train_loss = 0.69625219, grad/param norm = 1.9501e-01, time/batch = 16.7123s	
22658/29850 (epoch 37.953), train_loss = 0.80010199, grad/param norm = 2.4838e-01, time/batch = 17.6309s	
22659/29850 (epoch 37.955), train_loss = 0.71162750, grad/param norm = 2.1452e-01, time/batch = 17.2990s	
22660/29850 (epoch 37.956), train_loss = 0.72563283, grad/param norm = 2.2586e-01, time/batch = 16.9673s	
22661/29850 (epoch 37.958), train_loss = 0.64201077, grad/param norm = 1.6843e-01, time/batch = 17.8659s	
22662/29850 (epoch 37.960), train_loss = 0.92829230, grad/param norm = 2.8478e-01, time/batch = 18.3912s	
22663/29850 (epoch 37.961), train_loss = 0.68419623, grad/param norm = 2.1504e-01, time/batch = 16.4574s	
22664/29850 (epoch 37.963), train_loss = 0.68362321, grad/param norm = 2.1039e-01, time/batch = 18.1686s	
22665/29850 (epoch 37.965), train_loss = 0.73485637, grad/param norm = 2.1726e-01, time/batch = 18.3913s	
22666/29850 (epoch 37.966), train_loss = 0.70578770, grad/param norm = 1.9649e-01, time/batch = 16.3805s	
22667/29850 (epoch 37.968), train_loss = 0.73485628, grad/param norm = 2.2043e-01, time/batch = 17.8023s	
22668/29850 (epoch 37.970), train_loss = 0.74980035, grad/param norm = 2.7813e-01, time/batch = 15.3703s	
22669/29850 (epoch 37.972), train_loss = 0.74538315, grad/param norm = 2.0384e-01, time/batch = 17.1891s	
22670/29850 (epoch 37.973), train_loss = 0.71967112, grad/param norm = 1.8927e-01, time/batch = 16.5779s	
22671/29850 (epoch 37.975), train_loss = 0.62993861, grad/param norm = 1.9366e-01, time/batch = 18.1434s	
22672/29850 (epoch 37.977), train_loss = 0.75217001, grad/param norm = 1.8359e-01, time/batch = 19.6979s	
22673/29850 (epoch 37.978), train_loss = 0.66666923, grad/param norm = 1.9609e-01, time/batch = 18.0413s	
22674/29850 (epoch 37.980), train_loss = 0.72616773, grad/param norm = 1.9227e-01, time/batch = 17.1333s	
22675/29850 (epoch 37.982), train_loss = 0.71107352, grad/param norm = 2.1246e-01, time/batch = 18.0234s	
22676/29850 (epoch 37.983), train_loss = 0.74537380, grad/param norm = 1.8504e-01, time/batch = 17.3036s	
22677/29850 (epoch 37.985), train_loss = 0.85563748, grad/param norm = 2.2687e-01, time/batch = 17.5499s	
22678/29850 (epoch 37.987), train_loss = 0.81194971, grad/param norm = 2.1336e-01, time/batch = 16.5509s	
22679/29850 (epoch 37.988), train_loss = 0.75501932, grad/param norm = 2.0048e-01, time/batch = 18.7119s	
22680/29850 (epoch 37.990), train_loss = 0.82888073, grad/param norm = 2.0649e-01, time/batch = 15.5177s	
22681/29850 (epoch 37.992), train_loss = 0.82866579, grad/param norm = 2.0192e-01, time/batch = 19.2116s	
22682/29850 (epoch 37.993), train_loss = 0.81211301, grad/param norm = 2.1268e-01, time/batch = 17.6291s	
22683/29850 (epoch 37.995), train_loss = 0.79719268, grad/param norm = 2.3385e-01, time/batch = 17.6115s	
22684/29850 (epoch 37.997), train_loss = 0.82143053, grad/param norm = 2.0062e-01, time/batch = 17.4462s	
22685/29850 (epoch 37.998), train_loss = 0.84975791, grad/param norm = 2.2761e-01, time/batch = 17.4666s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
22686/29850 (epoch 38.000), train_loss = 0.68203822, grad/param norm = 1.9306e-01, time/batch = 19.1247s	
22687/29850 (epoch 38.002), train_loss = 0.93645594, grad/param norm = 2.3977e-01, time/batch = 18.3645s	
22688/29850 (epoch 38.003), train_loss = 0.68567650, grad/param norm = 2.0111e-01, time/batch = 18.5528s	
22689/29850 (epoch 38.005), train_loss = 0.86163626, grad/param norm = 2.2368e-01, time/batch = 17.8939s	
22690/29850 (epoch 38.007), train_loss = 0.90272754, grad/param norm = 2.5188e-01, time/batch = 16.9503s	
22691/29850 (epoch 38.008), train_loss = 1.03103274, grad/param norm = 2.7506e-01, time/batch = 16.9619s	
22692/29850 (epoch 38.010), train_loss = 0.75062932, grad/param norm = 2.3544e-01, time/batch = 18.2066s	
22693/29850 (epoch 38.012), train_loss = 0.78185918, grad/param norm = 2.0828e-01, time/batch = 17.4660s	
22694/29850 (epoch 38.013), train_loss = 0.85123094, grad/param norm = 2.6293e-01, time/batch = 19.3585s	
22695/29850 (epoch 38.015), train_loss = 0.90794825, grad/param norm = 2.4145e-01, time/batch = 18.8701s	
22696/29850 (epoch 38.017), train_loss = 0.84963018, grad/param norm = 2.6859e-01, time/batch = 18.3580s	
22697/29850 (epoch 38.018), train_loss = 0.96018566, grad/param norm = 2.5806e-01, time/batch = 18.3779s	
22698/29850 (epoch 38.020), train_loss = 0.82216957, grad/param norm = 2.0098e-01, time/batch = 16.2001s	
22699/29850 (epoch 38.022), train_loss = 0.91232145, grad/param norm = 2.4515e-01, time/batch = 19.1779s	
22700/29850 (epoch 38.023), train_loss = 0.87235572, grad/param norm = 2.0347e-01, time/batch = 16.0157s	
22701/29850 (epoch 38.025), train_loss = 0.80566355, grad/param norm = 1.9649e-01, time/batch = 19.0161s	
22702/29850 (epoch 38.027), train_loss = 0.61055245, grad/param norm = 1.8234e-01, time/batch = 18.1123s	
22703/29850 (epoch 38.028), train_loss = 0.75187822, grad/param norm = 2.1639e-01, time/batch = 17.7769s	
22704/29850 (epoch 38.030), train_loss = 0.77170089, grad/param norm = 2.1754e-01, time/batch = 18.5423s	
22705/29850 (epoch 38.032), train_loss = 0.85368837, grad/param norm = 2.0124e-01, time/batch = 18.0461s	
22706/29850 (epoch 38.034), train_loss = 0.74967020, grad/param norm = 2.6728e-01, time/batch = 16.7965s	
22707/29850 (epoch 38.035), train_loss = 0.64688760, grad/param norm = 2.0325e-01, time/batch = 18.1154s	
22708/29850 (epoch 38.037), train_loss = 0.82509142, grad/param norm = 2.3617e-01, time/batch = 15.8832s	
22709/29850 (epoch 38.039), train_loss = 0.71850952, grad/param norm = 1.8372e-01, time/batch = 18.7113s	
22710/29850 (epoch 38.040), train_loss = 0.69763303, grad/param norm = 2.0057e-01, time/batch = 17.7112s	
22711/29850 (epoch 38.042), train_loss = 0.72883944, grad/param norm = 2.1770e-01, time/batch = 17.5488s	
22712/29850 (epoch 38.044), train_loss = 0.78923146, grad/param norm = 2.0263e-01, time/batch = 17.4321s	
22713/29850 (epoch 38.045), train_loss = 0.87682085, grad/param norm = 2.1471e-01, time/batch = 18.0386s	
22714/29850 (epoch 38.047), train_loss = 0.70745625, grad/param norm = 2.0888e-01, time/batch = 19.1277s	
22715/29850 (epoch 38.049), train_loss = 0.85270693, grad/param norm = 2.0665e-01, time/batch = 19.3484s	
22716/29850 (epoch 38.050), train_loss = 0.75879124, grad/param norm = 2.2576e-01, time/batch = 18.2776s	
22717/29850 (epoch 38.052), train_loss = 0.92376211, grad/param norm = 2.1174e-01, time/batch = 15.7730s	
22718/29850 (epoch 38.054), train_loss = 0.79019607, grad/param norm = 2.2883e-01, time/batch = 17.3666s	
22719/29850 (epoch 38.055), train_loss = 0.76346361, grad/param norm = 2.2419e-01, time/batch = 19.1367s	
22720/29850 (epoch 38.057), train_loss = 0.84780554, grad/param norm = 2.0102e-01, time/batch = 17.0211s	
22721/29850 (epoch 38.059), train_loss = 0.85358866, grad/param norm = 2.1489e-01, time/batch = 17.1802s	
22722/29850 (epoch 38.060), train_loss = 0.82873221, grad/param norm = 2.4379e-01, time/batch = 19.5310s	
22723/29850 (epoch 38.062), train_loss = 0.89217406, grad/param norm = 2.1808e-01, time/batch = 17.6975s	
22724/29850 (epoch 38.064), train_loss = 0.89384447, grad/param norm = 2.6286e-01, time/batch = 18.4349s	
22725/29850 (epoch 38.065), train_loss = 0.70545902, grad/param norm = 2.2446e-01, time/batch = 18.7859s	
22726/29850 (epoch 38.067), train_loss = 0.84577320, grad/param norm = 1.9962e-01, time/batch = 17.6986s	
22727/29850 (epoch 38.069), train_loss = 0.83690339, grad/param norm = 1.9365e-01, time/batch = 16.6415s	
22728/29850 (epoch 38.070), train_loss = 0.86461075, grad/param norm = 2.0456e-01, time/batch = 17.5592s	
22729/29850 (epoch 38.072), train_loss = 0.82608950, grad/param norm = 2.3693e-01, time/batch = 16.0461s	
22730/29850 (epoch 38.074), train_loss = 0.89926759, grad/param norm = 2.0348e-01, time/batch = 18.1938s	
22731/29850 (epoch 38.075), train_loss = 0.76825765, grad/param norm = 2.3238e-01, time/batch = 18.2181s	
22732/29850 (epoch 38.077), train_loss = 0.89199582, grad/param norm = 2.4173e-01, time/batch = 17.2852s	
22733/29850 (epoch 38.079), train_loss = 1.03641050, grad/param norm = 3.0358e-01, time/batch = 20.1616s	
22734/29850 (epoch 38.080), train_loss = 0.99324690, grad/param norm = 2.8049e-01, time/batch = 25.0317s	
22735/29850 (epoch 38.082), train_loss = 0.89824424, grad/param norm = 2.3187e-01, time/batch = 17.6372s	
22736/29850 (epoch 38.084), train_loss = 0.96550478, grad/param norm = 2.5336e-01, time/batch = 17.2863s	
22737/29850 (epoch 38.085), train_loss = 1.01186623, grad/param norm = 2.4859e-01, time/batch = 17.0053s	
22738/29850 (epoch 38.087), train_loss = 0.94797103, grad/param norm = 2.3385e-01, time/batch = 17.6386s	
22739/29850 (epoch 38.089), train_loss = 0.86534120, grad/param norm = 2.1111e-01, time/batch = 17.7108s	
22740/29850 (epoch 38.090), train_loss = 0.88400256, grad/param norm = 2.1178e-01, time/batch = 17.5393s	
22741/29850 (epoch 38.092), train_loss = 0.76645706, grad/param norm = 1.9877e-01, time/batch = 16.8784s	
22742/29850 (epoch 38.094), train_loss = 0.97017511, grad/param norm = 2.4476e-01, time/batch = 18.7762s	
22743/29850 (epoch 38.095), train_loss = 0.90161490, grad/param norm = 3.0455e-01, time/batch = 16.2008s	
22744/29850 (epoch 38.097), train_loss = 0.65340690, grad/param norm = 1.9484e-01, time/batch = 16.6869s	
22745/29850 (epoch 38.099), train_loss = 0.68281658, grad/param norm = 1.9247e-01, time/batch = 19.7026s	
22746/29850 (epoch 38.101), train_loss = 0.90420336, grad/param norm = 2.6139e-01, time/batch = 17.2193s	
22747/29850 (epoch 38.102), train_loss = 0.88683357, grad/param norm = 2.5556e-01, time/batch = 19.3709s	
22748/29850 (epoch 38.104), train_loss = 0.80267470, grad/param norm = 2.3370e-01, time/batch = 17.8760s	
22749/29850 (epoch 38.106), train_loss = 0.90439998, grad/param norm = 2.1537e-01, time/batch = 18.8748s	
22750/29850 (epoch 38.107), train_loss = 0.78296978, grad/param norm = 2.0414e-01, time/batch = 16.8660s	
22751/29850 (epoch 38.109), train_loss = 0.83521129, grad/param norm = 2.2065e-01, time/batch = 17.3386s	
22752/29850 (epoch 38.111), train_loss = 0.87757280, grad/param norm = 2.1504e-01, time/batch = 19.2106s	
22753/29850 (epoch 38.112), train_loss = 0.74128193, grad/param norm = 2.1241e-01, time/batch = 16.7818s	
22754/29850 (epoch 38.114), train_loss = 0.78701418, grad/param norm = 2.3893e-01, time/batch = 18.7920s	
22755/29850 (epoch 38.116), train_loss = 0.75774263, grad/param norm = 2.0446e-01, time/batch = 19.3721s	
22756/29850 (epoch 38.117), train_loss = 0.81145063, grad/param norm = 2.2048e-01, time/batch = 17.4412s	
22757/29850 (epoch 38.119), train_loss = 0.76601723, grad/param norm = 1.9483e-01, time/batch = 14.5850s	
22758/29850 (epoch 38.121), train_loss = 0.66569363, grad/param norm = 2.1853e-01, time/batch = 17.2142s	
22759/29850 (epoch 38.122), train_loss = 0.70216042, grad/param norm = 1.6886e-01, time/batch = 18.4536s	
22760/29850 (epoch 38.124), train_loss = 0.75908968, grad/param norm = 2.5065e-01, time/batch = 15.9232s	
22761/29850 (epoch 38.126), train_loss = 0.78587206, grad/param norm = 2.2694e-01, time/batch = 18.2865s	
22762/29850 (epoch 38.127), train_loss = 0.86282321, grad/param norm = 2.6373e-01, time/batch = 19.8589s	
22763/29850 (epoch 38.129), train_loss = 0.82150308, grad/param norm = 2.2905e-01, time/batch = 17.4548s	
22764/29850 (epoch 38.131), train_loss = 0.82518208, grad/param norm = 2.0487e-01, time/batch = 19.0462s	
22765/29850 (epoch 38.132), train_loss = 0.68754799, grad/param norm = 2.1301e-01, time/batch = 17.5332s	
22766/29850 (epoch 38.134), train_loss = 0.79402712, grad/param norm = 2.3241e-01, time/batch = 17.6101s	
22767/29850 (epoch 38.136), train_loss = 0.86485277, grad/param norm = 1.9518e-01, time/batch = 16.8078s	
22768/29850 (epoch 38.137), train_loss = 0.68126800, grad/param norm = 2.1238e-01, time/batch = 17.8055s	
22769/29850 (epoch 38.139), train_loss = 0.79285013, grad/param norm = 2.0337e-01, time/batch = 17.8702s	
22770/29850 (epoch 38.141), train_loss = 0.72353662, grad/param norm = 2.1456e-01, time/batch = 17.2806s	
22771/29850 (epoch 38.142), train_loss = 0.93916735, grad/param norm = 2.3615e-01, time/batch = 18.0903s	
22772/29850 (epoch 38.144), train_loss = 1.04939620, grad/param norm = 2.6821e-01, time/batch = 17.6070s	
22773/29850 (epoch 38.146), train_loss = 1.04383678, grad/param norm = 2.2972e-01, time/batch = 17.4543s	
22774/29850 (epoch 38.147), train_loss = 0.93238933, grad/param norm = 2.5071e-01, time/batch = 17.7666s	
22775/29850 (epoch 38.149), train_loss = 0.87366481, grad/param norm = 2.3578e-01, time/batch = 17.3545s	
22776/29850 (epoch 38.151), train_loss = 0.88032975, grad/param norm = 2.6281e-01, time/batch = 18.4386s	
22777/29850 (epoch 38.152), train_loss = 0.80252808, grad/param norm = 2.1591e-01, time/batch = 16.0345s	
22778/29850 (epoch 38.154), train_loss = 0.76102864, grad/param norm = 2.2088e-01, time/batch = 18.1314s	
22779/29850 (epoch 38.156), train_loss = 0.76620663, grad/param norm = 2.1582e-01, time/batch = 18.2975s	
22780/29850 (epoch 38.157), train_loss = 0.87541660, grad/param norm = 2.4331e-01, time/batch = 16.7808s	
22781/29850 (epoch 38.159), train_loss = 0.78482097, grad/param norm = 2.0106e-01, time/batch = 18.4751s	
22782/29850 (epoch 38.161), train_loss = 0.81293979, grad/param norm = 2.4929e-01, time/batch = 19.3828s	
22783/29850 (epoch 38.162), train_loss = 0.95572465, grad/param norm = 2.5460e-01, time/batch = 16.6980s	
22784/29850 (epoch 38.164), train_loss = 0.87980823, grad/param norm = 2.3684e-01, time/batch = 18.8010s	
22785/29850 (epoch 38.166), train_loss = 0.78525367, grad/param norm = 2.1011e-01, time/batch = 16.7212s	
22786/29850 (epoch 38.168), train_loss = 0.70969130, grad/param norm = 1.8762e-01, time/batch = 15.0370s	
22787/29850 (epoch 38.169), train_loss = 0.95303007, grad/param norm = 2.9682e-01, time/batch = 16.8685s	
22788/29850 (epoch 38.171), train_loss = 0.88156501, grad/param norm = 2.1841e-01, time/batch = 19.2032s	
22789/29850 (epoch 38.173), train_loss = 0.73871848, grad/param norm = 2.1949e-01, time/batch = 17.8804s	
22790/29850 (epoch 38.174), train_loss = 0.83769968, grad/param norm = 2.3932e-01, time/batch = 17.4638s	
22791/29850 (epoch 38.176), train_loss = 0.84657481, grad/param norm = 2.3835e-01, time/batch = 17.1796s	
22792/29850 (epoch 38.178), train_loss = 0.87412241, grad/param norm = 2.7697e-01, time/batch = 18.6111s	
22793/29850 (epoch 38.179), train_loss = 0.71021029, grad/param norm = 2.6360e-01, time/batch = 17.1290s	
22794/29850 (epoch 38.181), train_loss = 0.84221932, grad/param norm = 2.2644e-01, time/batch = 17.9574s	
22795/29850 (epoch 38.183), train_loss = 0.82975223, grad/param norm = 2.0041e-01, time/batch = 17.3836s	
22796/29850 (epoch 38.184), train_loss = 0.88687138, grad/param norm = 2.5599e-01, time/batch = 18.7934s	
22797/29850 (epoch 38.186), train_loss = 0.87462246, grad/param norm = 2.7718e-01, time/batch = 16.1186s	
22798/29850 (epoch 38.188), train_loss = 0.94885640, grad/param norm = 2.3468e-01, time/batch = 16.3710s	
22799/29850 (epoch 38.189), train_loss = 0.89715626, grad/param norm = 2.3445e-01, time/batch = 19.1079s	
22800/29850 (epoch 38.191), train_loss = 0.94631652, grad/param norm = 2.4181e-01, time/batch = 16.9592s	
22801/29850 (epoch 38.193), train_loss = 0.80148451, grad/param norm = 1.9730e-01, time/batch = 17.5382s	
22802/29850 (epoch 38.194), train_loss = 0.93494769, grad/param norm = 2.7585e-01, time/batch = 16.9670s	
22803/29850 (epoch 38.196), train_loss = 0.81685398, grad/param norm = 2.1544e-01, time/batch = 17.7751s	
22804/29850 (epoch 38.198), train_loss = 0.77505637, grad/param norm = 2.0467e-01, time/batch = 17.1930s	
22805/29850 (epoch 38.199), train_loss = 1.02241471, grad/param norm = 2.6899e-01, time/batch = 18.2919s	
22806/29850 (epoch 38.201), train_loss = 0.76595653, grad/param norm = 2.1182e-01, time/batch = 20.5310s	
22807/29850 (epoch 38.203), train_loss = 0.61967052, grad/param norm = 2.2188e-01, time/batch = 16.1227s	
22808/29850 (epoch 38.204), train_loss = 0.81360490, grad/param norm = 2.2639e-01, time/batch = 17.8663s	
22809/29850 (epoch 38.206), train_loss = 0.71278041, grad/param norm = 2.0620e-01, time/batch = 15.4379s	
22810/29850 (epoch 38.208), train_loss = 0.96382428, grad/param norm = 2.6231e-01, time/batch = 18.0459s	
22811/29850 (epoch 38.209), train_loss = 0.71681778, grad/param norm = 1.9177e-01, time/batch = 16.6159s	
22812/29850 (epoch 38.211), train_loss = 0.77856655, grad/param norm = 2.0922e-01, time/batch = 17.4708s	
22813/29850 (epoch 38.213), train_loss = 0.88422402, grad/param norm = 2.6488e-01, time/batch = 19.9596s	
22814/29850 (epoch 38.214), train_loss = 0.71365251, grad/param norm = 1.9337e-01, time/batch = 16.7969s	
22815/29850 (epoch 38.216), train_loss = 0.74166371, grad/param norm = 2.1938e-01, time/batch = 19.2855s	
22816/29850 (epoch 38.218), train_loss = 0.86510262, grad/param norm = 2.2915e-01, time/batch = 18.7143s	
22817/29850 (epoch 38.219), train_loss = 0.86602529, grad/param norm = 3.0323e-01, time/batch = 16.7094s	
22818/29850 (epoch 38.221), train_loss = 0.82300292, grad/param norm = 2.3542e-01, time/batch = 19.1278s	
22819/29850 (epoch 38.223), train_loss = 0.69859217, grad/param norm = 2.1441e-01, time/batch = 18.3785s	
22820/29850 (epoch 38.224), train_loss = 0.68212283, grad/param norm = 1.9839e-01, time/batch = 17.6919s	
22821/29850 (epoch 38.226), train_loss = 0.74181743, grad/param norm = 2.0673e-01, time/batch = 16.9708s	
22822/29850 (epoch 38.228), train_loss = 0.77521855, grad/param norm = 1.9295e-01, time/batch = 18.3882s	
22823/29850 (epoch 38.229), train_loss = 0.66130435, grad/param norm = 1.7440e-01, time/batch = 18.7226s	
22824/29850 (epoch 38.231), train_loss = 0.82697623, grad/param norm = 2.0755e-01, time/batch = 18.5154s	
22825/29850 (epoch 38.233), train_loss = 0.80085605, grad/param norm = 2.3709e-01, time/batch = 16.5310s	
22826/29850 (epoch 38.235), train_loss = 0.76088336, grad/param norm = 2.1619e-01, time/batch = 19.6260s	
22827/29850 (epoch 38.236), train_loss = 0.96411114, grad/param norm = 2.8378e-01, time/batch = 15.6214s	
22828/29850 (epoch 38.238), train_loss = 0.69823026, grad/param norm = 2.1466e-01, time/batch = 18.1050s	
22829/29850 (epoch 38.240), train_loss = 0.71671955, grad/param norm = 2.0206e-01, time/batch = 18.9545s	
22830/29850 (epoch 38.241), train_loss = 0.84386498, grad/param norm = 2.3363e-01, time/batch = 15.7655s	
22831/29850 (epoch 38.243), train_loss = 0.86482017, grad/param norm = 2.1190e-01, time/batch = 18.1248s	
22832/29850 (epoch 38.245), train_loss = 0.72849953, grad/param norm = 2.2526e-01, time/batch = 18.1322s	
22833/29850 (epoch 38.246), train_loss = 0.72271339, grad/param norm = 1.8784e-01, time/batch = 19.1355s	
22834/29850 (epoch 38.248), train_loss = 0.68690965, grad/param norm = 1.8710e-01, time/batch = 16.1884s	
22835/29850 (epoch 38.250), train_loss = 0.76354496, grad/param norm = 1.8703e-01, time/batch = 18.4620s	
22836/29850 (epoch 38.251), train_loss = 0.67018826, grad/param norm = 2.0525e-01, time/batch = 17.7207s	
22837/29850 (epoch 38.253), train_loss = 0.66424404, grad/param norm = 2.0772e-01, time/batch = 17.4563s	
22838/29850 (epoch 38.255), train_loss = 0.71749733, grad/param norm = 2.3214e-01, time/batch = 17.7171s	
22839/29850 (epoch 38.256), train_loss = 0.84851589, grad/param norm = 2.2851e-01, time/batch = 18.9597s	
22840/29850 (epoch 38.258), train_loss = 0.86666025, grad/param norm = 2.2767e-01, time/batch = 18.1389s	
22841/29850 (epoch 38.260), train_loss = 0.77641114, grad/param norm = 1.9570e-01, time/batch = 18.7692s	
22842/29850 (epoch 38.261), train_loss = 0.72563196, grad/param norm = 2.0652e-01, time/batch = 18.0365s	
22843/29850 (epoch 38.263), train_loss = 0.74832981, grad/param norm = 2.0098e-01, time/batch = 18.9203s	
22844/29850 (epoch 38.265), train_loss = 0.79456477, grad/param norm = 2.3865e-01, time/batch = 19.3566s	
22845/29850 (epoch 38.266), train_loss = 0.80549011, grad/param norm = 2.3549e-01, time/batch = 17.2215s	
22846/29850 (epoch 38.268), train_loss = 0.77335331, grad/param norm = 2.0110e-01, time/batch = 18.8717s	
22847/29850 (epoch 38.270), train_loss = 0.74009832, grad/param norm = 1.9893e-01, time/batch = 16.4495s	
22848/29850 (epoch 38.271), train_loss = 0.85110930, grad/param norm = 2.0855e-01, time/batch = 19.6253s	
22849/29850 (epoch 38.273), train_loss = 0.70430424, grad/param norm = 2.1576e-01, time/batch = 17.6951s	
22850/29850 (epoch 38.275), train_loss = 0.69037431, grad/param norm = 1.9498e-01, time/batch = 15.1271s	
22851/29850 (epoch 38.276), train_loss = 0.68357581, grad/param norm = 1.8833e-01, time/batch = 15.6901s	
22852/29850 (epoch 38.278), train_loss = 0.77000699, grad/param norm = 2.2419e-01, time/batch = 16.4753s	
22853/29850 (epoch 38.280), train_loss = 0.98576369, grad/param norm = 3.0990e-01, time/batch = 19.3816s	
22854/29850 (epoch 38.281), train_loss = 0.83345586, grad/param norm = 2.4789e-01, time/batch = 16.7106s	
22855/29850 (epoch 38.283), train_loss = 0.91804610, grad/param norm = 3.0496e-01, time/batch = 18.3845s	
22856/29850 (epoch 38.285), train_loss = 0.89352077, grad/param norm = 2.1789e-01, time/batch = 18.0427s	
22857/29850 (epoch 38.286), train_loss = 0.91400297, grad/param norm = 2.4385e-01, time/batch = 17.3693s	
22858/29850 (epoch 38.288), train_loss = 0.87044470, grad/param norm = 3.3017e-01, time/batch = 17.3637s	
22859/29850 (epoch 38.290), train_loss = 0.83012710, grad/param norm = 2.3315e-01, time/batch = 18.1056s	
22860/29850 (epoch 38.291), train_loss = 1.04268526, grad/param norm = 2.8018e-01, time/batch = 15.4862s	
22861/29850 (epoch 38.293), train_loss = 0.94930947, grad/param norm = 2.8804e-01, time/batch = 18.6825s	
22862/29850 (epoch 38.295), train_loss = 1.00685484, grad/param norm = 2.5392e-01, time/batch = 18.2138s	
22863/29850 (epoch 38.296), train_loss = 0.75061179, grad/param norm = 2.1561e-01, time/batch = 16.8516s	
22864/29850 (epoch 38.298), train_loss = 0.64498439, grad/param norm = 2.0818e-01, time/batch = 18.0231s	
22865/29850 (epoch 38.300), train_loss = 0.70575809, grad/param norm = 2.0193e-01, time/batch = 18.3758s	
22866/29850 (epoch 38.302), train_loss = 0.71037300, grad/param norm = 1.9584e-01, time/batch = 19.4593s	
22867/29850 (epoch 38.303), train_loss = 0.75395422, grad/param norm = 2.0875e-01, time/batch = 17.2179s	
22868/29850 (epoch 38.305), train_loss = 0.88942442, grad/param norm = 2.0840e-01, time/batch = 17.8697s	
22869/29850 (epoch 38.307), train_loss = 0.89113004, grad/param norm = 2.2298e-01, time/batch = 16.8072s	
22870/29850 (epoch 38.308), train_loss = 0.73159605, grad/param norm = 2.4760e-01, time/batch = 18.1349s	
22871/29850 (epoch 38.310), train_loss = 0.87887858, grad/param norm = 2.2384e-01, time/batch = 16.4397s	
22872/29850 (epoch 38.312), train_loss = 0.89828583, grad/param norm = 2.1627e-01, time/batch = 19.6952s	
22873/29850 (epoch 38.313), train_loss = 0.84534347, grad/param norm = 2.7147e-01, time/batch = 19.6314s	
22874/29850 (epoch 38.315), train_loss = 0.84340016, grad/param norm = 2.1096e-01, time/batch = 17.6933s	
22875/29850 (epoch 38.317), train_loss = 0.82560665, grad/param norm = 2.1698e-01, time/batch = 18.2695s	
22876/29850 (epoch 38.318), train_loss = 0.82465007, grad/param norm = 2.3762e-01, time/batch = 17.3767s	
22877/29850 (epoch 38.320), train_loss = 0.75670637, grad/param norm = 2.1709e-01, time/batch = 16.4204s	
22878/29850 (epoch 38.322), train_loss = 0.93015572, grad/param norm = 2.3804e-01, time/batch = 17.3080s	
22879/29850 (epoch 38.323), train_loss = 0.88506468, grad/param norm = 2.4961e-01, time/batch = 17.7106s	
22880/29850 (epoch 38.325), train_loss = 0.92613829, grad/param norm = 2.2193e-01, time/batch = 20.1121s	
22881/29850 (epoch 38.327), train_loss = 1.02537946, grad/param norm = 2.3157e-01, time/batch = 16.6125s	
22882/29850 (epoch 38.328), train_loss = 0.94382001, grad/param norm = 2.5472e-01, time/batch = 19.7866s	
22883/29850 (epoch 38.330), train_loss = 0.89737039, grad/param norm = 2.1193e-01, time/batch = 19.2125s	
22884/29850 (epoch 38.332), train_loss = 0.80269712, grad/param norm = 2.2128e-01, time/batch = 16.5235s	
22885/29850 (epoch 38.333), train_loss = 0.88236741, grad/param norm = 2.2363e-01, time/batch = 18.7569s	
22886/29850 (epoch 38.335), train_loss = 0.92538689, grad/param norm = 2.3129e-01, time/batch = 17.3524s	
22887/29850 (epoch 38.337), train_loss = 0.84450134, grad/param norm = 2.4563e-01, time/batch = 17.9503s	
22888/29850 (epoch 38.338), train_loss = 0.86485061, grad/param norm = 1.9702e-01, time/batch = 17.0597s	
22889/29850 (epoch 38.340), train_loss = 0.70841639, grad/param norm = 2.0629e-01, time/batch = 18.3802s	
22890/29850 (epoch 38.342), train_loss = 0.84445757, grad/param norm = 2.6898e-01, time/batch = 17.8808s	
22891/29850 (epoch 38.343), train_loss = 0.83089359, grad/param norm = 2.4158e-01, time/batch = 16.7140s	
22892/29850 (epoch 38.345), train_loss = 0.90602311, grad/param norm = 2.5819e-01, time/batch = 16.6239s	
22893/29850 (epoch 38.347), train_loss = 0.94041913, grad/param norm = 2.5616e-01, time/batch = 19.8724s	
22894/29850 (epoch 38.348), train_loss = 0.79334500, grad/param norm = 2.4089e-01, time/batch = 16.8509s	
22895/29850 (epoch 38.350), train_loss = 0.89025750, grad/param norm = 2.5261e-01, time/batch = 18.4494s	
22896/29850 (epoch 38.352), train_loss = 0.77148843, grad/param norm = 1.9180e-01, time/batch = 18.7176s	
22897/29850 (epoch 38.353), train_loss = 0.87234853, grad/param norm = 2.3371e-01, time/batch = 15.9458s	
22898/29850 (epoch 38.355), train_loss = 0.81732598, grad/param norm = 2.6181e-01, time/batch = 17.7890s	
22899/29850 (epoch 38.357), train_loss = 0.90933024, grad/param norm = 2.2039e-01, time/batch = 18.6342s	
22900/29850 (epoch 38.358), train_loss = 0.76430122, grad/param norm = 2.2122e-01, time/batch = 17.8868s	
22901/29850 (epoch 38.360), train_loss = 0.82357895, grad/param norm = 2.2187e-01, time/batch = 17.8551s	
22902/29850 (epoch 38.362), train_loss = 0.83418670, grad/param norm = 2.3906e-01, time/batch = 18.1435s	
22903/29850 (epoch 38.363), train_loss = 0.86729042, grad/param norm = 2.4455e-01, time/batch = 16.3928s	
22904/29850 (epoch 38.365), train_loss = 0.95220702, grad/param norm = 3.0347e-01, time/batch = 16.6239s	
22905/29850 (epoch 38.367), train_loss = 0.76752379, grad/param norm = 2.0601e-01, time/batch = 18.7845s	
22906/29850 (epoch 38.369), train_loss = 0.69692385, grad/param norm = 2.4232e-01, time/batch = 17.9544s	
22907/29850 (epoch 38.370), train_loss = 0.67200038, grad/param norm = 1.8995e-01, time/batch = 17.2964s	
22908/29850 (epoch 38.372), train_loss = 0.93743010, grad/param norm = 2.3507e-01, time/batch = 18.2806s	
22909/29850 (epoch 38.374), train_loss = 0.89791359, grad/param norm = 2.0381e-01, time/batch = 16.0283s	
22910/29850 (epoch 38.375), train_loss = 0.84914840, grad/param norm = 2.2294e-01, time/batch = 16.6975s	
22911/29850 (epoch 38.377), train_loss = 0.74422621, grad/param norm = 2.2462e-01, time/batch = 15.9639s	
22912/29850 (epoch 38.379), train_loss = 0.95403586, grad/param norm = 2.7188e-01, time/batch = 15.3754s	
22913/29850 (epoch 38.380), train_loss = 0.87742338, grad/param norm = 2.2888e-01, time/batch = 19.3036s	
22914/29850 (epoch 38.382), train_loss = 0.83102033, grad/param norm = 2.2669e-01, time/batch = 17.9556s	
22915/29850 (epoch 38.384), train_loss = 0.91275103, grad/param norm = 2.4023e-01, time/batch = 18.2073s	
22916/29850 (epoch 38.385), train_loss = 0.88566591, grad/param norm = 2.2787e-01, time/batch = 18.7092s	
22917/29850 (epoch 38.387), train_loss = 0.87060626, grad/param norm = 2.3957e-01, time/batch = 19.3677s	
22918/29850 (epoch 38.389), train_loss = 0.97980458, grad/param norm = 2.7729e-01, time/batch = 16.6484s	
22919/29850 (epoch 38.390), train_loss = 0.92673264, grad/param norm = 2.7551e-01, time/batch = 18.6284s	
22920/29850 (epoch 38.392), train_loss = 0.84065223, grad/param norm = 3.0323e-01, time/batch = 17.7177s	
22921/29850 (epoch 38.394), train_loss = 0.91204096, grad/param norm = 2.1631e-01, time/batch = 18.1213s	
22922/29850 (epoch 38.395), train_loss = 0.79518637, grad/param norm = 2.3939e-01, time/batch = 19.6101s	
22923/29850 (epoch 38.397), train_loss = 0.73939396, grad/param norm = 3.2610e-01, time/batch = 18.1280s	
22924/29850 (epoch 38.399), train_loss = 0.77907056, grad/param norm = 2.2252e-01, time/batch = 17.9524s	
22925/29850 (epoch 38.400), train_loss = 1.11834953, grad/param norm = 2.6924e-01, time/batch = 20.0298s	
22926/29850 (epoch 38.402), train_loss = 0.95923167, grad/param norm = 2.1972e-01, time/batch = 16.8594s	
22927/29850 (epoch 38.404), train_loss = 0.85722212, grad/param norm = 2.0020e-01, time/batch = 18.2753s	
22928/29850 (epoch 38.405), train_loss = 0.78553962, grad/param norm = 2.3511e-01, time/batch = 18.9661s	
22929/29850 (epoch 38.407), train_loss = 0.76886759, grad/param norm = 1.9158e-01, time/batch = 17.2967s	
22930/29850 (epoch 38.409), train_loss = 0.85496054, grad/param norm = 2.2955e-01, time/batch = 18.6423s	
22931/29850 (epoch 38.410), train_loss = 0.93750798, grad/param norm = 2.3223e-01, time/batch = 16.8730s	
22932/29850 (epoch 38.412), train_loss = 0.94553580, grad/param norm = 2.4602e-01, time/batch = 19.7049s	
22933/29850 (epoch 38.414), train_loss = 0.85665802, grad/param norm = 2.3507e-01, time/batch = 18.3887s	
22934/29850 (epoch 38.415), train_loss = 0.83210486, grad/param norm = 1.9646e-01, time/batch = 26.4219s	
22935/29850 (epoch 38.417), train_loss = 0.97943015, grad/param norm = 2.6805e-01, time/batch = 22.1691s	
22936/29850 (epoch 38.419), train_loss = 0.82349251, grad/param norm = 2.1386e-01, time/batch = 17.2010s	
22937/29850 (epoch 38.420), train_loss = 0.85183133, grad/param norm = 2.2999e-01, time/batch = 16.7843s	
22938/29850 (epoch 38.422), train_loss = 0.82920272, grad/param norm = 2.2893e-01, time/batch = 19.6172s	
22939/29850 (epoch 38.424), train_loss = 0.75944445, grad/param norm = 2.1197e-01, time/batch = 15.5543s	
22940/29850 (epoch 38.425), train_loss = 0.91223262, grad/param norm = 2.7037e-01, time/batch = 17.9569s	
22941/29850 (epoch 38.427), train_loss = 0.65010038, grad/param norm = 1.9243e-01, time/batch = 18.2088s	
22942/29850 (epoch 38.429), train_loss = 0.74063773, grad/param norm = 2.3389e-01, time/batch = 15.5219s	
22943/29850 (epoch 38.430), train_loss = 0.69272860, grad/param norm = 1.8858e-01, time/batch = 18.4499s	
22944/29850 (epoch 38.432), train_loss = 0.77202414, grad/param norm = 2.1566e-01, time/batch = 17.1194s	
22945/29850 (epoch 38.434), train_loss = 0.77687354, grad/param norm = 2.1837e-01, time/batch = 19.4623s	
22946/29850 (epoch 38.436), train_loss = 0.81150433, grad/param norm = 2.2626e-01, time/batch = 15.9822s	
22947/29850 (epoch 38.437), train_loss = 0.89948035, grad/param norm = 2.2338e-01, time/batch = 16.3836s	
22948/29850 (epoch 38.439), train_loss = 0.89013966, grad/param norm = 2.2433e-01, time/batch = 18.4565s	
22949/29850 (epoch 38.441), train_loss = 0.83525355, grad/param norm = 2.1131e-01, time/batch = 19.3661s	
22950/29850 (epoch 38.442), train_loss = 0.79388285, grad/param norm = 1.9070e-01, time/batch = 15.5920s	
22951/29850 (epoch 38.444), train_loss = 0.85456291, grad/param norm = 2.2759e-01, time/batch = 14.8962s	
22952/29850 (epoch 38.446), train_loss = 0.91113254, grad/param norm = 2.3503e-01, time/batch = 14.4782s	
22953/29850 (epoch 38.447), train_loss = 0.91362849, grad/param norm = 2.4686e-01, time/batch = 14.6350s	
22954/29850 (epoch 38.449), train_loss = 0.83786444, grad/param norm = 2.2612e-01, time/batch = 14.8087s	
22955/29850 (epoch 38.451), train_loss = 0.65601638, grad/param norm = 2.0835e-01, time/batch = 15.8274s	
22956/29850 (epoch 38.452), train_loss = 0.57330486, grad/param norm = 1.7817e-01, time/batch = 17.9186s	
22957/29850 (epoch 38.454), train_loss = 0.70680546, grad/param norm = 1.9868e-01, time/batch = 16.0139s	
22958/29850 (epoch 38.456), train_loss = 0.89810931, grad/param norm = 2.3888e-01, time/batch = 15.7047s	
22959/29850 (epoch 38.457), train_loss = 0.93098820, grad/param norm = 3.3377e-01, time/batch = 18.1034s	
22960/29850 (epoch 38.459), train_loss = 0.96616602, grad/param norm = 2.6201e-01, time/batch = 18.9549s	
22961/29850 (epoch 38.461), train_loss = 0.97969671, grad/param norm = 2.5349e-01, time/batch = 17.5432s	
22962/29850 (epoch 38.462), train_loss = 0.98418129, grad/param norm = 2.4680e-01, time/batch = 15.5168s	
22963/29850 (epoch 38.464), train_loss = 0.88786637, grad/param norm = 2.4899e-01, time/batch = 18.7227s	
22964/29850 (epoch 38.466), train_loss = 0.72628156, grad/param norm = 2.0018e-01, time/batch = 16.6861s	
22965/29850 (epoch 38.467), train_loss = 0.76957105, grad/param norm = 2.0379e-01, time/batch = 17.7869s	
22966/29850 (epoch 38.469), train_loss = 0.79738082, grad/param norm = 2.0759e-01, time/batch = 19.1227s	
22967/29850 (epoch 38.471), train_loss = 0.80694351, grad/param norm = 2.3587e-01, time/batch = 16.8844s	
22968/29850 (epoch 38.472), train_loss = 0.76871456, grad/param norm = 2.1197e-01, time/batch = 14.8889s	
22969/29850 (epoch 38.474), train_loss = 0.90949891, grad/param norm = 2.2380e-01, time/batch = 18.2882s	
22970/29850 (epoch 38.476), train_loss = 0.84099474, grad/param norm = 2.0309e-01, time/batch = 15.7949s	
22971/29850 (epoch 38.477), train_loss = 0.87552258, grad/param norm = 2.6581e-01, time/batch = 18.0267s	
22972/29850 (epoch 38.479), train_loss = 1.01243884, grad/param norm = 2.2615e-01, time/batch = 16.8610s	
22973/29850 (epoch 38.481), train_loss = 0.84877393, grad/param norm = 2.3152e-01, time/batch = 18.1035s	
22974/29850 (epoch 38.482), train_loss = 0.77203806, grad/param norm = 1.8652e-01, time/batch = 16.6195s	
22975/29850 (epoch 38.484), train_loss = 0.78865201, grad/param norm = 2.0954e-01, time/batch = 17.1937s	
22976/29850 (epoch 38.486), train_loss = 0.85882062, grad/param norm = 2.5384e-01, time/batch = 18.9507s	
22977/29850 (epoch 38.487), train_loss = 0.83401111, grad/param norm = 2.1130e-01, time/batch = 16.8602s	
22978/29850 (epoch 38.489), train_loss = 0.83072227, grad/param norm = 2.0722e-01, time/batch = 17.6354s	
22979/29850 (epoch 38.491), train_loss = 0.76543855, grad/param norm = 2.2381e-01, time/batch = 17.2894s	
22980/29850 (epoch 38.492), train_loss = 0.82705705, grad/param norm = 2.0969e-01, time/batch = 16.7792s	
22981/29850 (epoch 38.494), train_loss = 0.89574867, grad/param norm = 2.1888e-01, time/batch = 18.5505s	
22982/29850 (epoch 38.496), train_loss = 0.94293321, grad/param norm = 2.4093e-01, time/batch = 17.0368s	
22983/29850 (epoch 38.497), train_loss = 0.86920064, grad/param norm = 2.2325e-01, time/batch = 19.2716s	
22984/29850 (epoch 38.499), train_loss = 0.86129758, grad/param norm = 2.5044e-01, time/batch = 18.1418s	
22985/29850 (epoch 38.501), train_loss = 0.73805979, grad/param norm = 3.1511e-01, time/batch = 17.0288s	
22986/29850 (epoch 38.503), train_loss = 0.92095138, grad/param norm = 2.4580e-01, time/batch = 15.6926s	
22987/29850 (epoch 38.504), train_loss = 1.05973107, grad/param norm = 2.1968e-01, time/batch = 18.0620s	
22988/29850 (epoch 38.506), train_loss = 1.05615240, grad/param norm = 2.9687e-01, time/batch = 18.3016s	
22989/29850 (epoch 38.508), train_loss = 0.86934096, grad/param norm = 2.2090e-01, time/batch = 17.0307s	
22990/29850 (epoch 38.509), train_loss = 0.67240865, grad/param norm = 2.0009e-01, time/batch = 19.8606s	
22991/29850 (epoch 38.511), train_loss = 0.87896140, grad/param norm = 2.4233e-01, time/batch = 18.1927s	
22992/29850 (epoch 38.513), train_loss = 0.83755142, grad/param norm = 2.5100e-01, time/batch = 16.8797s	
22993/29850 (epoch 38.514), train_loss = 0.75037856, grad/param norm = 2.0328e-01, time/batch = 17.0467s	
22994/29850 (epoch 38.516), train_loss = 0.79164102, grad/param norm = 1.9064e-01, time/batch = 18.1032s	
22995/29850 (epoch 38.518), train_loss = 0.67532143, grad/param norm = 2.0608e-01, time/batch = 17.8723s	
22996/29850 (epoch 38.519), train_loss = 0.64912040, grad/param norm = 1.8679e-01, time/batch = 18.9524s	
22997/29850 (epoch 38.521), train_loss = 0.62284591, grad/param norm = 1.6761e-01, time/batch = 17.9660s	
22998/29850 (epoch 38.523), train_loss = 0.69406920, grad/param norm = 1.7957e-01, time/batch = 19.2882s	
22999/29850 (epoch 38.524), train_loss = 0.73814696, grad/param norm = 2.0604e-01, time/batch = 16.9526s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch38.53_1.8715.t7	
23000/29850 (epoch 38.526), train_loss = 0.79595895, grad/param norm = 3.5624e-01, time/batch = 19.3004s	
23001/29850 (epoch 38.528), train_loss = 1.46897952, grad/param norm = 3.4140e-01, time/batch = 0.7921s	
23002/29850 (epoch 38.529), train_loss = 0.87516030, grad/param norm = 2.2668e-01, time/batch = 0.9764s	
23003/29850 (epoch 38.531), train_loss = 0.81275575, grad/param norm = 2.5505e-01, time/batch = 1.0068s	
23004/29850 (epoch 38.533), train_loss = 0.83465961, grad/param norm = 2.3062e-01, time/batch = 1.0105s	
23005/29850 (epoch 38.534), train_loss = 0.89596250, grad/param norm = 2.2745e-01, time/batch = 0.9874s	
23006/29850 (epoch 38.536), train_loss = 0.77703201, grad/param norm = 2.5108e-01, time/batch = 1.3019s	
23007/29850 (epoch 38.538), train_loss = 0.94424831, grad/param norm = 2.4884e-01, time/batch = 1.8905s	
23008/29850 (epoch 38.539), train_loss = 0.97784032, grad/param norm = 2.7401e-01, time/batch = 1.8356s	
23009/29850 (epoch 38.541), train_loss = 0.61394158, grad/param norm = 2.1198e-01, time/batch = 13.7456s	
23010/29850 (epoch 38.543), train_loss = 0.80239508, grad/param norm = 2.5000e-01, time/batch = 17.9794s	
23011/29850 (epoch 38.544), train_loss = 0.91148641, grad/param norm = 2.6044e-01, time/batch = 18.5314s	
23012/29850 (epoch 38.546), train_loss = 0.90182704, grad/param norm = 2.2411e-01, time/batch = 18.8453s	
23013/29850 (epoch 38.548), train_loss = 0.69356686, grad/param norm = 2.0922e-01, time/batch = 19.1879s	
23014/29850 (epoch 38.549), train_loss = 0.79683042, grad/param norm = 2.0923e-01, time/batch = 17.5362s	
23015/29850 (epoch 38.551), train_loss = 0.74971391, grad/param norm = 1.9965e-01, time/batch = 15.3579s	
23016/29850 (epoch 38.553), train_loss = 0.82023166, grad/param norm = 2.0367e-01, time/batch = 14.7893s	
23017/29850 (epoch 38.554), train_loss = 0.68547629, grad/param norm = 1.9789e-01, time/batch = 17.2212s	
23018/29850 (epoch 38.556), train_loss = 0.71276783, grad/param norm = 1.8138e-01, time/batch = 15.5368s	
23019/29850 (epoch 38.558), train_loss = 0.72733322, grad/param norm = 1.8962e-01, time/batch = 19.1271s	
23020/29850 (epoch 38.559), train_loss = 0.76874652, grad/param norm = 2.3079e-01, time/batch = 18.7869s	
23021/29850 (epoch 38.561), train_loss = 0.83063590, grad/param norm = 2.2371e-01, time/batch = 17.0491s	
23022/29850 (epoch 38.563), train_loss = 0.85518262, grad/param norm = 2.2467e-01, time/batch = 19.3768s	
23023/29850 (epoch 38.564), train_loss = 0.79122473, grad/param norm = 2.5517e-01, time/batch = 18.0398s	
23024/29850 (epoch 38.566), train_loss = 0.83436485, grad/param norm = 2.3763e-01, time/batch = 18.1420s	
23025/29850 (epoch 38.568), train_loss = 0.96027014, grad/param norm = 2.6941e-01, time/batch = 16.8086s	
23026/29850 (epoch 38.570), train_loss = 0.86252482, grad/param norm = 2.3318e-01, time/batch = 18.0325s	
23027/29850 (epoch 38.571), train_loss = 0.91649287, grad/param norm = 2.1565e-01, time/batch = 18.6291s	
23028/29850 (epoch 38.573), train_loss = 0.97326799, grad/param norm = 2.4960e-01, time/batch = 16.0567s	
23029/29850 (epoch 38.575), train_loss = 1.03095185, grad/param norm = 2.2494e-01, time/batch = 18.2536s	
23030/29850 (epoch 38.576), train_loss = 0.90096311, grad/param norm = 2.3408e-01, time/batch = 19.1423s	
23031/29850 (epoch 38.578), train_loss = 0.78623310, grad/param norm = 2.4897e-01, time/batch = 18.1212s	
23032/29850 (epoch 38.580), train_loss = 0.94893108, grad/param norm = 2.8500e-01, time/batch = 19.1184s	
23033/29850 (epoch 38.581), train_loss = 0.75204003, grad/param norm = 1.9033e-01, time/batch = 17.1833s	
23034/29850 (epoch 38.583), train_loss = 0.83192302, grad/param norm = 2.3654e-01, time/batch = 16.4439s	
23035/29850 (epoch 38.585), train_loss = 0.85539899, grad/param norm = 2.1687e-01, time/batch = 20.0806s	
23036/29850 (epoch 38.586), train_loss = 0.87243842, grad/param norm = 2.4151e-01, time/batch = 17.9611s	
23037/29850 (epoch 38.588), train_loss = 0.75688312, grad/param norm = 2.2738e-01, time/batch = 19.0402s	
23038/29850 (epoch 38.590), train_loss = 0.77427537, grad/param norm = 2.1317e-01, time/batch = 17.6114s	
23039/29850 (epoch 38.591), train_loss = 0.82249672, grad/param norm = 2.5477e-01, time/batch = 19.2798s	
23040/29850 (epoch 38.593), train_loss = 0.74853597, grad/param norm = 1.9792e-01, time/batch = 19.0322s	
23041/29850 (epoch 38.595), train_loss = 0.68912979, grad/param norm = 1.6041e-01, time/batch = 16.6128s	
23042/29850 (epoch 38.596), train_loss = 0.74107547, grad/param norm = 2.2455e-01, time/batch = 19.0238s	
23043/29850 (epoch 38.598), train_loss = 0.81005297, grad/param norm = 2.2036e-01, time/batch = 17.7949s	
23044/29850 (epoch 38.600), train_loss = 0.83907283, grad/param norm = 2.1078e-01, time/batch = 17.8702s	
23045/29850 (epoch 38.601), train_loss = 0.72272898, grad/param norm = 1.9036e-01, time/batch = 18.3484s	
23046/29850 (epoch 38.603), train_loss = 0.75703572, grad/param norm = 2.0415e-01, time/batch = 18.0509s	
23047/29850 (epoch 38.605), train_loss = 0.78897267, grad/param norm = 2.1642e-01, time/batch = 18.7919s	
23048/29850 (epoch 38.606), train_loss = 0.56678786, grad/param norm = 1.9460e-01, time/batch = 17.6258s	
23049/29850 (epoch 38.608), train_loss = 0.71301684, grad/param norm = 1.9773e-01, time/batch = 16.9488s	
23050/29850 (epoch 38.610), train_loss = 0.76472744, grad/param norm = 2.1658e-01, time/batch = 17.5488s	
23051/29850 (epoch 38.611), train_loss = 0.72874958, grad/param norm = 2.1870e-01, time/batch = 17.9540s	
23052/29850 (epoch 38.613), train_loss = 0.59900733, grad/param norm = 1.6347e-01, time/batch = 17.5492s	
23053/29850 (epoch 38.615), train_loss = 0.68810752, grad/param norm = 1.9689e-01, time/batch = 16.9375s	
23054/29850 (epoch 38.616), train_loss = 0.71549867, grad/param norm = 2.2732e-01, time/batch = 17.2110s	
23055/29850 (epoch 38.618), train_loss = 0.76853459, grad/param norm = 2.1038e-01, time/batch = 16.6314s	
23056/29850 (epoch 38.620), train_loss = 0.87267690, grad/param norm = 2.6617e-01, time/batch = 16.4471s	
23057/29850 (epoch 38.621), train_loss = 0.94481893, grad/param norm = 2.6183e-01, time/batch = 17.9774s	
23058/29850 (epoch 38.623), train_loss = 0.89848813, grad/param norm = 2.2646e-01, time/batch = 16.6079s	
23059/29850 (epoch 38.625), train_loss = 0.81139006, grad/param norm = 2.3153e-01, time/batch = 18.2136s	
23060/29850 (epoch 38.626), train_loss = 0.83376078, grad/param norm = 2.3682e-01, time/batch = 15.7974s	
23061/29850 (epoch 38.628), train_loss = 0.81817212, grad/param norm = 2.3091e-01, time/batch = 17.1268s	
23062/29850 (epoch 38.630), train_loss = 0.81202363, grad/param norm = 2.2793e-01, time/batch = 18.7870s	
23063/29850 (epoch 38.631), train_loss = 0.83654044, grad/param norm = 2.3149e-01, time/batch = 17.6267s	
23064/29850 (epoch 38.633), train_loss = 0.85305455, grad/param norm = 2.6932e-01, time/batch = 18.3815s	
23065/29850 (epoch 38.635), train_loss = 0.77602615, grad/param norm = 2.5017e-01, time/batch = 16.3490s	
23066/29850 (epoch 38.637), train_loss = 0.72202009, grad/param norm = 2.0179e-01, time/batch = 17.2899s	
23067/29850 (epoch 38.638), train_loss = 0.83891411, grad/param norm = 2.6770e-01, time/batch = 17.3677s	
23068/29850 (epoch 38.640), train_loss = 0.99385646, grad/param norm = 2.9696e-01, time/batch = 17.6261s	
23069/29850 (epoch 38.642), train_loss = 0.78505311, grad/param norm = 2.1031e-01, time/batch = 17.5489s	
23070/29850 (epoch 38.643), train_loss = 0.74307676, grad/param norm = 2.3392e-01, time/batch = 19.2198s	
23071/29850 (epoch 38.645), train_loss = 0.80634346, grad/param norm = 2.1118e-01, time/batch = 17.3875s	
23072/29850 (epoch 38.647), train_loss = 0.95043652, grad/param norm = 2.5083e-01, time/batch = 18.2902s	
23073/29850 (epoch 38.648), train_loss = 0.74959886, grad/param norm = 2.2660e-01, time/batch = 19.7122s	
23074/29850 (epoch 38.650), train_loss = 0.83885940, grad/param norm = 2.2711e-01, time/batch = 16.4044s	
23075/29850 (epoch 38.652), train_loss = 0.83180417, grad/param norm = 2.2147e-01, time/batch = 16.1278s	
23076/29850 (epoch 38.653), train_loss = 0.91642773, grad/param norm = 3.1934e-01, time/batch = 17.5358s	
23077/29850 (epoch 38.655), train_loss = 0.84036136, grad/param norm = 2.1946e-01, time/batch = 17.7036s	
23078/29850 (epoch 38.657), train_loss = 0.82226388, grad/param norm = 2.1404e-01, time/batch = 16.3917s	
23079/29850 (epoch 38.658), train_loss = 0.94186969, grad/param norm = 3.0740e-01, time/batch = 16.2744s	
23080/29850 (epoch 38.660), train_loss = 0.79724925, grad/param norm = 2.3359e-01, time/batch = 18.2910s	
23081/29850 (epoch 38.662), train_loss = 0.93668224, grad/param norm = 2.5888e-01, time/batch = 19.0487s	
23082/29850 (epoch 38.663), train_loss = 1.03880535, grad/param norm = 2.6859e-01, time/batch = 17.0164s	
23083/29850 (epoch 38.665), train_loss = 0.96632896, grad/param norm = 3.0759e-01, time/batch = 15.0332s	
23084/29850 (epoch 38.667), train_loss = 0.91398295, grad/param norm = 3.8750e-01, time/batch = 18.2055s	
23085/29850 (epoch 38.668), train_loss = 0.79981476, grad/param norm = 2.7114e-01, time/batch = 15.8039s	
23086/29850 (epoch 38.670), train_loss = 0.92895815, grad/param norm = 2.7996e-01, time/batch = 18.1251s	
23087/29850 (epoch 38.672), train_loss = 0.93092684, grad/param norm = 2.5603e-01, time/batch = 18.5455s	
23088/29850 (epoch 38.673), train_loss = 0.85379737, grad/param norm = 2.4229e-01, time/batch = 17.3874s	
23089/29850 (epoch 38.675), train_loss = 0.74669924, grad/param norm = 2.2116e-01, time/batch = 14.9576s	
23090/29850 (epoch 38.677), train_loss = 0.79260204, grad/param norm = 2.5041e-01, time/batch = 17.9793s	
23091/29850 (epoch 38.678), train_loss = 0.82892054, grad/param norm = 2.3066e-01, time/batch = 19.1757s	
23092/29850 (epoch 38.680), train_loss = 0.81282719, grad/param norm = 2.3508e-01, time/batch = 16.4554s	
23093/29850 (epoch 38.682), train_loss = 0.82348227, grad/param norm = 2.1549e-01, time/batch = 18.0414s	
23094/29850 (epoch 38.683), train_loss = 0.94495902, grad/param norm = 2.9359e-01, time/batch = 16.7389s	
23095/29850 (epoch 38.685), train_loss = 1.04202137, grad/param norm = 2.6951e-01, time/batch = 15.9554s	
23096/29850 (epoch 38.687), train_loss = 0.87424122, grad/param norm = 2.1458e-01, time/batch = 16.1035s	
23097/29850 (epoch 38.688), train_loss = 0.75201853, grad/param norm = 2.4195e-01, time/batch = 18.2151s	
23098/29850 (epoch 38.690), train_loss = 0.74714231, grad/param norm = 2.2008e-01, time/batch = 19.1273s	
23099/29850 (epoch 38.692), train_loss = 0.94193097, grad/param norm = 2.5154e-01, time/batch = 18.4425s	
23100/29850 (epoch 38.693), train_loss = 0.83569359, grad/param norm = 2.0367e-01, time/batch = 16.8623s	
23101/29850 (epoch 38.695), train_loss = 0.73345236, grad/param norm = 1.8710e-01, time/batch = 19.4372s	
23102/29850 (epoch 38.697), train_loss = 0.82172718, grad/param norm = 2.0730e-01, time/batch = 16.9657s	
23103/29850 (epoch 38.698), train_loss = 0.95946304, grad/param norm = 2.2266e-01, time/batch = 18.8472s	
23104/29850 (epoch 38.700), train_loss = 0.89172657, grad/param norm = 2.7905e-01, time/batch = 17.2127s	
23105/29850 (epoch 38.702), train_loss = 0.85626401, grad/param norm = 2.4895e-01, time/batch = 19.2822s	
23106/29850 (epoch 38.704), train_loss = 0.72018786, grad/param norm = 1.8702e-01, time/batch = 18.8635s	
23107/29850 (epoch 38.705), train_loss = 0.83142780, grad/param norm = 2.1503e-01, time/batch = 19.2950s	
23108/29850 (epoch 38.707), train_loss = 0.78055580, grad/param norm = 2.6735e-01, time/batch = 18.0432s	
23109/29850 (epoch 38.709), train_loss = 0.82119063, grad/param norm = 2.3869e-01, time/batch = 15.5112s	
23110/29850 (epoch 38.710), train_loss = 0.75469364, grad/param norm = 2.2691e-01, time/batch = 18.4576s	
23111/29850 (epoch 38.712), train_loss = 0.86512412, grad/param norm = 2.0668e-01, time/batch = 17.3944s	
23112/29850 (epoch 38.714), train_loss = 0.93237750, grad/param norm = 2.4926e-01, time/batch = 17.7899s	
23113/29850 (epoch 38.715), train_loss = 0.85461224, grad/param norm = 2.3679e-01, time/batch = 19.0345s	
23114/29850 (epoch 38.717), train_loss = 0.62513525, grad/param norm = 2.0233e-01, time/batch = 17.7000s	
23115/29850 (epoch 38.719), train_loss = 0.78632226, grad/param norm = 2.2399e-01, time/batch = 17.7934s	
23116/29850 (epoch 38.720), train_loss = 0.80603388, grad/param norm = 2.0811e-01, time/batch = 18.0421s	
23117/29850 (epoch 38.722), train_loss = 0.74221921, grad/param norm = 1.7876e-01, time/batch = 17.0420s	
23118/29850 (epoch 38.724), train_loss = 0.83676813, grad/param norm = 2.6057e-01, time/batch = 15.9418s	
23119/29850 (epoch 38.725), train_loss = 0.72747026, grad/param norm = 2.2378e-01, time/batch = 18.0357s	
23120/29850 (epoch 38.727), train_loss = 0.71913414, grad/param norm = 2.2218e-01, time/batch = 17.6988s	
23121/29850 (epoch 38.729), train_loss = 0.69031173, grad/param norm = 1.7997e-01, time/batch = 19.2099s	
23122/29850 (epoch 38.730), train_loss = 0.65798726, grad/param norm = 2.0371e-01, time/batch = 16.7826s	
23123/29850 (epoch 38.732), train_loss = 0.91660613, grad/param norm = 2.1192e-01, time/batch = 18.6357s	
23124/29850 (epoch 38.734), train_loss = 1.00761133, grad/param norm = 2.9171e-01, time/batch = 17.3750s	
23125/29850 (epoch 38.735), train_loss = 0.74204442, grad/param norm = 2.1260e-01, time/batch = 18.7854s	
23126/29850 (epoch 38.737), train_loss = 0.71846472, grad/param norm = 2.1210e-01, time/batch = 17.5076s	
23127/29850 (epoch 38.739), train_loss = 0.63200202, grad/param norm = 1.8403e-01, time/batch = 16.4750s	
23128/29850 (epoch 38.740), train_loss = 0.68687366, grad/param norm = 2.3571e-01, time/batch = 18.3698s	
23129/29850 (epoch 38.742), train_loss = 0.61853217, grad/param norm = 1.7187e-01, time/batch = 16.5447s	
23130/29850 (epoch 38.744), train_loss = 0.73605469, grad/param norm = 2.1143e-01, time/batch = 17.3051s	
23131/29850 (epoch 38.745), train_loss = 0.75986384, grad/param norm = 2.2551e-01, time/batch = 19.6270s	
23132/29850 (epoch 38.747), train_loss = 0.80118620, grad/param norm = 2.3264e-01, time/batch = 17.8867s	
23133/29850 (epoch 38.749), train_loss = 0.69494190, grad/param norm = 2.1306e-01, time/batch = 17.3031s	
23134/29850 (epoch 38.750), train_loss = 0.64280021, grad/param norm = 2.1801e-01, time/batch = 16.9529s	
23135/29850 (epoch 38.752), train_loss = 0.56154571, grad/param norm = 1.9065e-01, time/batch = 18.4343s	
23136/29850 (epoch 38.754), train_loss = 0.64316713, grad/param norm = 2.4091e-01, time/batch = 17.6960s	
23137/29850 (epoch 38.755), train_loss = 0.64971686, grad/param norm = 2.1776e-01, time/batch = 18.7169s	
23138/29850 (epoch 38.757), train_loss = 0.70646588, grad/param norm = 1.9556e-01, time/batch = 17.1339s	
23139/29850 (epoch 38.759), train_loss = 0.72154779, grad/param norm = 2.1970e-01, time/batch = 17.1227s	
23140/29850 (epoch 38.760), train_loss = 0.71899347, grad/param norm = 2.0379e-01, time/batch = 17.5480s	
23141/29850 (epoch 38.762), train_loss = 0.65890572, grad/param norm = 2.1142e-01, time/batch = 19.4562s	
23142/29850 (epoch 38.764), train_loss = 0.60825227, grad/param norm = 2.3432e-01, time/batch = 22.0558s	
23143/29850 (epoch 38.765), train_loss = 0.75752573, grad/param norm = 2.4543e-01, time/batch = 28.7738s	
23144/29850 (epoch 38.767), train_loss = 0.73994623, grad/param norm = 2.0536e-01, time/batch = 17.0510s	
23145/29850 (epoch 38.769), train_loss = 0.77947491, grad/param norm = 2.0970e-01, time/batch = 16.1868s	
23146/29850 (epoch 38.771), train_loss = 0.82255589, grad/param norm = 2.2820e-01, time/batch = 19.5572s	
23147/29850 (epoch 38.772), train_loss = 0.78198504, grad/param norm = 2.3436e-01, time/batch = 16.8856s	
23148/29850 (epoch 38.774), train_loss = 0.72858470, grad/param norm = 2.2337e-01, time/batch = 17.8724s	
23149/29850 (epoch 38.776), train_loss = 0.77401446, grad/param norm = 2.3023e-01, time/batch = 18.2162s	
23150/29850 (epoch 38.777), train_loss = 0.86620220, grad/param norm = 2.5591e-01, time/batch = 16.2955s	
23151/29850 (epoch 38.779), train_loss = 0.69971494, grad/param norm = 1.9815e-01, time/batch = 18.1331s	
23152/29850 (epoch 38.781), train_loss = 0.81596748, grad/param norm = 2.2176e-01, time/batch = 17.3870s	
23153/29850 (epoch 38.782), train_loss = 0.81882427, grad/param norm = 2.1970e-01, time/batch = 19.0385s	
23154/29850 (epoch 38.784), train_loss = 0.64835858, grad/param norm = 2.2087e-01, time/batch = 15.2102s	
23155/29850 (epoch 38.786), train_loss = 0.72749644, grad/param norm = 2.2161e-01, time/batch = 16.9557s	
23156/29850 (epoch 38.787), train_loss = 0.61075803, grad/param norm = 2.1930e-01, time/batch = 17.7962s	
23157/29850 (epoch 38.789), train_loss = 0.64066528, grad/param norm = 1.8539e-01, time/batch = 17.9566s	
23158/29850 (epoch 38.791), train_loss = 0.71132385, grad/param norm = 2.2044e-01, time/batch = 16.9377s	
23159/29850 (epoch 38.792), train_loss = 0.83017905, grad/param norm = 2.3564e-01, time/batch = 16.6916s	
23160/29850 (epoch 38.794), train_loss = 0.78906120, grad/param norm = 2.1972e-01, time/batch = 18.3734s	
23161/29850 (epoch 38.796), train_loss = 0.67979614, grad/param norm = 2.0848e-01, time/batch = 18.0595s	
23162/29850 (epoch 38.797), train_loss = 0.59263131, grad/param norm = 2.0846e-01, time/batch = 16.8837s	
23163/29850 (epoch 38.799), train_loss = 0.65089942, grad/param norm = 1.8496e-01, time/batch = 17.1098s	
23164/29850 (epoch 38.801), train_loss = 0.65019710, grad/param norm = 1.6672e-01, time/batch = 19.9553s	
23165/29850 (epoch 38.802), train_loss = 0.64070730, grad/param norm = 2.2190e-01, time/batch = 18.0355s	
23166/29850 (epoch 38.804), train_loss = 0.67754673, grad/param norm = 1.7769e-01, time/batch = 19.5314s	
23167/29850 (epoch 38.806), train_loss = 0.62454807, grad/param norm = 2.0918e-01, time/batch = 15.2726s	
23168/29850 (epoch 38.807), train_loss = 0.66498205, grad/param norm = 1.8491e-01, time/batch = 16.8700s	
23169/29850 (epoch 38.809), train_loss = 0.65226364, grad/param norm = 2.0300e-01, time/batch = 17.2166s	
23170/29850 (epoch 38.811), train_loss = 0.83112711, grad/param norm = 2.2696e-01, time/batch = 17.5409s	
23171/29850 (epoch 38.812), train_loss = 0.81191313, grad/param norm = 2.4530e-01, time/batch = 18.7969s	
23172/29850 (epoch 38.814), train_loss = 0.83647149, grad/param norm = 2.5769e-01, time/batch = 18.0275s	
23173/29850 (epoch 38.816), train_loss = 0.88492209, grad/param norm = 2.2911e-01, time/batch = 19.6982s	
23174/29850 (epoch 38.817), train_loss = 0.80285088, grad/param norm = 2.6157e-01, time/batch = 18.0319s	
23175/29850 (epoch 38.819), train_loss = 0.63391147, grad/param norm = 1.9767e-01, time/batch = 17.3763s	
23176/29850 (epoch 38.821), train_loss = 0.87751246, grad/param norm = 2.5471e-01, time/batch = 17.4489s	
23177/29850 (epoch 38.822), train_loss = 0.90084024, grad/param norm = 2.5571e-01, time/batch = 17.3177s	
23178/29850 (epoch 38.824), train_loss = 0.77302005, grad/param norm = 2.1687e-01, time/batch = 18.0420s	
23179/29850 (epoch 38.826), train_loss = 0.68616742, grad/param norm = 1.9599e-01, time/batch = 16.9374s	
23180/29850 (epoch 38.827), train_loss = 0.62049336, grad/param norm = 2.6577e-01, time/batch = 19.7202s	
23181/29850 (epoch 38.829), train_loss = 0.78068551, grad/param norm = 2.3711e-01, time/batch = 18.7311s	
23182/29850 (epoch 38.831), train_loss = 0.88539540, grad/param norm = 2.4607e-01, time/batch = 17.5386s	
23183/29850 (epoch 38.832), train_loss = 0.79576199, grad/param norm = 2.0980e-01, time/batch = 17.5305s	
23184/29850 (epoch 38.834), train_loss = 0.59521473, grad/param norm = 1.7829e-01, time/batch = 16.6992s	
23185/29850 (epoch 38.836), train_loss = 0.62308380, grad/param norm = 1.8912e-01, time/batch = 18.0397s	
23186/29850 (epoch 38.838), train_loss = 0.72301171, grad/param norm = 2.4419e-01, time/batch = 17.0514s	
23187/29850 (epoch 38.839), train_loss = 0.62159535, grad/param norm = 2.3917e-01, time/batch = 17.1423s	
23188/29850 (epoch 38.841), train_loss = 0.68282096, grad/param norm = 1.7158e-01, time/batch = 18.0533s	
23189/29850 (epoch 38.843), train_loss = 0.61024213, grad/param norm = 1.9111e-01, time/batch = 17.7883s	
23190/29850 (epoch 38.844), train_loss = 0.67697301, grad/param norm = 2.4157e-01, time/batch = 18.3706s	
23191/29850 (epoch 38.846), train_loss = 0.76034499, grad/param norm = 2.4763e-01, time/batch = 18.0650s	
23192/29850 (epoch 38.848), train_loss = 0.82307144, grad/param norm = 2.3574e-01, time/batch = 16.2163s	
23193/29850 (epoch 38.849), train_loss = 0.74328663, grad/param norm = 2.4361e-01, time/batch = 17.3894s	
23194/29850 (epoch 38.851), train_loss = 0.91719866, grad/param norm = 2.3896e-01, time/batch = 17.6401s	
23195/29850 (epoch 38.853), train_loss = 0.76956893, grad/param norm = 2.5553e-01, time/batch = 18.6201s	
23196/29850 (epoch 38.854), train_loss = 0.92393658, grad/param norm = 2.6936e-01, time/batch = 19.8539s	
23197/29850 (epoch 38.856), train_loss = 0.87282960, grad/param norm = 2.7755e-01, time/batch = 17.0541s	
23198/29850 (epoch 38.858), train_loss = 0.78048969, grad/param norm = 2.9092e-01, time/batch = 18.3069s	
23199/29850 (epoch 38.859), train_loss = 0.71283283, grad/param norm = 2.3986e-01, time/batch = 18.2139s	
23200/29850 (epoch 38.861), train_loss = 0.87309331, grad/param norm = 2.4642e-01, time/batch = 16.2332s	
23201/29850 (epoch 38.863), train_loss = 0.90465163, grad/param norm = 2.7748e-01, time/batch = 18.3727s	
23202/29850 (epoch 38.864), train_loss = 0.88868732, grad/param norm = 2.5610e-01, time/batch = 16.4532s	
23203/29850 (epoch 38.866), train_loss = 0.82352610, grad/param norm = 3.0158e-01, time/batch = 15.2142s	
23204/29850 (epoch 38.868), train_loss = 0.94072530, grad/param norm = 2.4952e-01, time/batch = 15.1995s	
23205/29850 (epoch 38.869), train_loss = 0.86531995, grad/param norm = 2.5894e-01, time/batch = 18.7845s	
23206/29850 (epoch 38.871), train_loss = 0.89278950, grad/param norm = 2.5755e-01, time/batch = 17.1272s	
23207/29850 (epoch 38.873), train_loss = 0.82359716, grad/param norm = 2.3833e-01, time/batch = 18.7204s	
23208/29850 (epoch 38.874), train_loss = 0.82616755, grad/param norm = 2.3385e-01, time/batch = 18.3029s	
23209/29850 (epoch 38.876), train_loss = 0.80291835, grad/param norm = 3.8297e-01, time/batch = 16.7062s	
23210/29850 (epoch 38.878), train_loss = 0.80318695, grad/param norm = 2.0437e-01, time/batch = 19.2775s	
23211/29850 (epoch 38.879), train_loss = 0.82348065, grad/param norm = 2.1529e-01, time/batch = 17.3983s	
23212/29850 (epoch 38.881), train_loss = 0.89899526, grad/param norm = 2.4670e-01, time/batch = 17.1225s	
23213/29850 (epoch 38.883), train_loss = 0.82431671, grad/param norm = 2.2415e-01, time/batch = 16.8782s	
23214/29850 (epoch 38.884), train_loss = 0.71742460, grad/param norm = 2.4046e-01, time/batch = 18.0568s	
23215/29850 (epoch 38.886), train_loss = 0.87244629, grad/param norm = 2.8241e-01, time/batch = 19.0418s	
23216/29850 (epoch 38.888), train_loss = 0.79214841, grad/param norm = 2.2325e-01, time/batch = 17.1924s	
23217/29850 (epoch 38.889), train_loss = 0.74480437, grad/param norm = 2.0654e-01, time/batch = 16.3800s	
23218/29850 (epoch 38.891), train_loss = 0.72099352, grad/param norm = 2.0430e-01, time/batch = 19.0195s	
23219/29850 (epoch 38.893), train_loss = 0.77506267, grad/param norm = 2.2122e-01, time/batch = 16.7935s	
23220/29850 (epoch 38.894), train_loss = 0.78460523, grad/param norm = 2.6817e-01, time/batch = 17.7854s	
23221/29850 (epoch 38.896), train_loss = 0.82072057, grad/param norm = 2.8791e-01, time/batch = 18.8768s	
23222/29850 (epoch 38.898), train_loss = 0.93996888, grad/param norm = 2.2941e-01, time/batch = 18.4437s	
23223/29850 (epoch 38.899), train_loss = 0.70905070, grad/param norm = 2.5207e-01, time/batch = 18.0528s	
23224/29850 (epoch 38.901), train_loss = 0.98557452, grad/param norm = 2.5882e-01, time/batch = 19.0425s	
23225/29850 (epoch 38.903), train_loss = 0.84875418, grad/param norm = 3.2104e-01, time/batch = 15.7667s	
23226/29850 (epoch 38.905), train_loss = 1.07094188, grad/param norm = 2.6545e-01, time/batch = 16.2661s	
23227/29850 (epoch 38.906), train_loss = 0.83160247, grad/param norm = 2.7624e-01, time/batch = 16.3891s	
23228/29850 (epoch 38.908), train_loss = 0.97578324, grad/param norm = 2.7397e-01, time/batch = 17.1518s	
23229/29850 (epoch 38.910), train_loss = 0.88438438, grad/param norm = 2.2143e-01, time/batch = 18.4570s	
23230/29850 (epoch 38.911), train_loss = 0.99631875, grad/param norm = 2.1765e-01, time/batch = 18.2903s	
23231/29850 (epoch 38.913), train_loss = 0.96890444, grad/param norm = 2.6849e-01, time/batch = 17.6301s	
23232/29850 (epoch 38.915), train_loss = 0.94630876, grad/param norm = 2.3709e-01, time/batch = 19.6165s	
23233/29850 (epoch 38.916), train_loss = 0.91349902, grad/param norm = 2.5662e-01, time/batch = 17.9541s	
23234/29850 (epoch 38.918), train_loss = 0.76192901, grad/param norm = 2.1204e-01, time/batch = 16.7812s	
23235/29850 (epoch 38.920), train_loss = 0.93335795, grad/param norm = 2.3406e-01, time/batch = 17.6288s	
23236/29850 (epoch 38.921), train_loss = 0.82589315, grad/param norm = 2.6526e-01, time/batch = 15.9809s	
23237/29850 (epoch 38.923), train_loss = 0.82749084, grad/param norm = 2.4210e-01, time/batch = 17.3411s	
23238/29850 (epoch 38.925), train_loss = 0.96850060, grad/param norm = 2.3905e-01, time/batch = 18.4609s	
23239/29850 (epoch 38.926), train_loss = 0.97601508, grad/param norm = 2.6395e-01, time/batch = 18.1028s	
23240/29850 (epoch 38.928), train_loss = 0.84384305, grad/param norm = 2.3004e-01, time/batch = 19.0307s	
23241/29850 (epoch 38.930), train_loss = 0.84655050, grad/param norm = 2.2767e-01, time/batch = 17.7941s	
23242/29850 (epoch 38.931), train_loss = 0.84038484, grad/param norm = 2.2934e-01, time/batch = 16.3686s	
23243/29850 (epoch 38.933), train_loss = 0.98469513, grad/param norm = 2.4092e-01, time/batch = 16.1149s	
23244/29850 (epoch 38.935), train_loss = 0.90547130, grad/param norm = 2.5152e-01, time/batch = 18.1376s	
23245/29850 (epoch 38.936), train_loss = 0.88514368, grad/param norm = 2.5524e-01, time/batch = 17.8141s	
23246/29850 (epoch 38.938), train_loss = 0.73062762, grad/param norm = 1.9828e-01, time/batch = 17.2180s	
23247/29850 (epoch 38.940), train_loss = 0.75778538, grad/param norm = 2.0163e-01, time/batch = 19.3730s	
23248/29850 (epoch 38.941), train_loss = 0.75305488, grad/param norm = 2.5095e-01, time/batch = 17.6179s	
23249/29850 (epoch 38.943), train_loss = 0.77447932, grad/param norm = 2.1474e-01, time/batch = 16.7117s	
23250/29850 (epoch 38.945), train_loss = 0.72517874, grad/param norm = 3.0546e-01, time/batch = 18.0376s	
23251/29850 (epoch 38.946), train_loss = 0.74340115, grad/param norm = 2.3463e-01, time/batch = 16.6099s	
23252/29850 (epoch 38.948), train_loss = 0.83339429, grad/param norm = 2.4789e-01, time/batch = 18.0442s	
23253/29850 (epoch 38.950), train_loss = 0.77510862, grad/param norm = 1.8515e-01, time/batch = 17.3873s	
23254/29850 (epoch 38.951), train_loss = 0.69332237, grad/param norm = 2.1077e-01, time/batch = 16.8899s	
23255/29850 (epoch 38.953), train_loss = 0.78033424, grad/param norm = 2.4360e-01, time/batch = 18.7085s	
23256/29850 (epoch 38.955), train_loss = 0.69659358, grad/param norm = 2.0298e-01, time/batch = 17.7773s	
23257/29850 (epoch 38.956), train_loss = 0.71032901, grad/param norm = 2.1166e-01, time/batch = 18.4716s	
23258/29850 (epoch 38.958), train_loss = 0.65272082, grad/param norm = 1.8830e-01, time/batch = 18.3723s	
23259/29850 (epoch 38.960), train_loss = 0.89833632, grad/param norm = 2.3974e-01, time/batch = 19.1371s	
23260/29850 (epoch 38.961), train_loss = 0.66711121, grad/param norm = 2.1712e-01, time/batch = 17.0432s	
23261/29850 (epoch 38.963), train_loss = 0.66282488, grad/param norm = 2.0719e-01, time/batch = 17.8813s	
23262/29850 (epoch 38.965), train_loss = 0.72603900, grad/param norm = 2.1246e-01, time/batch = 18.0465s	
23263/29850 (epoch 38.966), train_loss = 0.70821472, grad/param norm = 2.2971e-01, time/batch = 16.8690s	
23264/29850 (epoch 38.968), train_loss = 0.72782467, grad/param norm = 2.6033e-01, time/batch = 16.8076s	
23265/29850 (epoch 38.970), train_loss = 0.74412134, grad/param norm = 2.4312e-01, time/batch = 15.4563s	
23266/29850 (epoch 38.972), train_loss = 0.72115365, grad/param norm = 1.9717e-01, time/batch = 17.3664s	
23267/29850 (epoch 38.973), train_loss = 0.72093612, grad/param norm = 1.9505e-01, time/batch = 18.6217s	
23268/29850 (epoch 38.975), train_loss = 0.61579960, grad/param norm = 1.7295e-01, time/batch = 16.6333s	
23269/29850 (epoch 38.977), train_loss = 0.75034726, grad/param norm = 2.0750e-01, time/batch = 17.5338s	
23270/29850 (epoch 38.978), train_loss = 0.65241476, grad/param norm = 1.7725e-01, time/batch = 16.1294s	
23271/29850 (epoch 38.980), train_loss = 0.71369315, grad/param norm = 1.8556e-01, time/batch = 18.8007s	
23272/29850 (epoch 38.982), train_loss = 0.70416466, grad/param norm = 1.9746e-01, time/batch = 18.2102s	
23273/29850 (epoch 38.983), train_loss = 0.73829818, grad/param norm = 1.9743e-01, time/batch = 17.8009s	
23274/29850 (epoch 38.985), train_loss = 0.84902543, grad/param norm = 2.4607e-01, time/batch = 18.7030s	
23275/29850 (epoch 38.987), train_loss = 0.80593958, grad/param norm = 2.3646e-01, time/batch = 18.0446s	
23276/29850 (epoch 38.988), train_loss = 0.77180782, grad/param norm = 2.5106e-01, time/batch = 16.6133s	
23277/29850 (epoch 38.990), train_loss = 0.81864377, grad/param norm = 2.1080e-01, time/batch = 16.1493s	
23278/29850 (epoch 38.992), train_loss = 0.82202934, grad/param norm = 2.1690e-01, time/batch = 17.8026s	
23279/29850 (epoch 38.993), train_loss = 0.81071756, grad/param norm = 2.2403e-01, time/batch = 18.2201s	
23280/29850 (epoch 38.995), train_loss = 0.78840448, grad/param norm = 2.0972e-01, time/batch = 17.1352s	
23281/29850 (epoch 38.997), train_loss = 0.81846437, grad/param norm = 2.2429e-01, time/batch = 18.8817s	
23282/29850 (epoch 38.998), train_loss = 0.83232526, grad/param norm = 2.2269e-01, time/batch = 18.6089s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
23283/29850 (epoch 39.000), train_loss = 0.66395566, grad/param norm = 1.9689e-01, time/batch = 17.2176s	
23284/29850 (epoch 39.002), train_loss = 0.92117346, grad/param norm = 2.3351e-01, time/batch = 17.6383s	
23285/29850 (epoch 39.003), train_loss = 0.65824002, grad/param norm = 2.4027e-01, time/batch = 16.8822s	
23286/29850 (epoch 39.005), train_loss = 0.85749508, grad/param norm = 2.2037e-01, time/batch = 18.6382s	
23287/29850 (epoch 39.007), train_loss = 0.86412904, grad/param norm = 2.3606e-01, time/batch = 15.5562s	
23288/29850 (epoch 39.008), train_loss = 1.01806254, grad/param norm = 2.8694e-01, time/batch = 18.7966s	
23289/29850 (epoch 39.010), train_loss = 0.72916348, grad/param norm = 2.0949e-01, time/batch = 16.6119s	
23290/29850 (epoch 39.012), train_loss = 0.76892644, grad/param norm = 1.9868e-01, time/batch = 17.3481s	
23291/29850 (epoch 39.013), train_loss = 0.85162605, grad/param norm = 2.5663e-01, time/batch = 18.7074s	
23292/29850 (epoch 39.015), train_loss = 0.90332880, grad/param norm = 2.4372e-01, time/batch = 17.9622s	
23293/29850 (epoch 39.017), train_loss = 0.85165996, grad/param norm = 2.6277e-01, time/batch = 18.2111s	
23294/29850 (epoch 39.018), train_loss = 0.92348366, grad/param norm = 2.4753e-01, time/batch = 17.9329s	
23295/29850 (epoch 39.020), train_loss = 0.81664686, grad/param norm = 2.2000e-01, time/batch = 19.1271s	
23296/29850 (epoch 39.022), train_loss = 0.91197815, grad/param norm = 2.5674e-01, time/batch = 15.3542s	
23297/29850 (epoch 39.023), train_loss = 0.86958590, grad/param norm = 2.0477e-01, time/batch = 16.8619s	
23298/29850 (epoch 39.025), train_loss = 0.79628195, grad/param norm = 2.0239e-01, time/batch = 18.7018s	
23299/29850 (epoch 39.027), train_loss = 0.60248442, grad/param norm = 2.1358e-01, time/batch = 16.6826s	
23300/29850 (epoch 39.028), train_loss = 0.73584374, grad/param norm = 1.9453e-01, time/batch = 18.5135s	
23301/29850 (epoch 39.030), train_loss = 0.75073644, grad/param norm = 2.1236e-01, time/batch = 17.2266s	
23302/29850 (epoch 39.032), train_loss = 0.86403347, grad/param norm = 2.5627e-01, time/batch = 17.1923s	
23303/29850 (epoch 39.034), train_loss = 0.74501841, grad/param norm = 2.3584e-01, time/batch = 19.2935s	
23304/29850 (epoch 39.035), train_loss = 0.64206975, grad/param norm = 2.1328e-01, time/batch = 16.9613s	
23305/29850 (epoch 39.037), train_loss = 0.80149524, grad/param norm = 2.0786e-01, time/batch = 17.5491s	
23306/29850 (epoch 39.039), train_loss = 0.71348327, grad/param norm = 1.7459e-01, time/batch = 18.2784s	
23307/29850 (epoch 39.040), train_loss = 0.67840530, grad/param norm = 1.8619e-01, time/batch = 16.5516s	
23308/29850 (epoch 39.042), train_loss = 0.73514934, grad/param norm = 2.3383e-01, time/batch = 16.9060s	
23309/29850 (epoch 39.044), train_loss = 0.76838772, grad/param norm = 2.0872e-01, time/batch = 16.0667s	
23310/29850 (epoch 39.045), train_loss = 0.86106703, grad/param norm = 2.2397e-01, time/batch = 18.4767s	
23311/29850 (epoch 39.047), train_loss = 0.70542773, grad/param norm = 2.0267e-01, time/batch = 16.6889s	
23312/29850 (epoch 39.049), train_loss = 0.84160174, grad/param norm = 2.2864e-01, time/batch = 18.8858s	
23313/29850 (epoch 39.050), train_loss = 0.76359697, grad/param norm = 2.2871e-01, time/batch = 17.5639s	
23314/29850 (epoch 39.052), train_loss = 0.90716226, grad/param norm = 2.4980e-01, time/batch = 16.6264s	
23315/29850 (epoch 39.054), train_loss = 0.78279968, grad/param norm = 2.1106e-01, time/batch = 19.1808s	
23316/29850 (epoch 39.055), train_loss = 0.75879498, grad/param norm = 2.1084e-01, time/batch = 17.3782s	
23317/29850 (epoch 39.057), train_loss = 0.84680756, grad/param norm = 1.9907e-01, time/batch = 17.5935s	
23318/29850 (epoch 39.059), train_loss = 0.84985395, grad/param norm = 2.1820e-01, time/batch = 15.0416s	
23319/29850 (epoch 39.060), train_loss = 0.82920194, grad/param norm = 2.7177e-01, time/batch = 14.8701s	
23320/29850 (epoch 39.062), train_loss = 0.87216577, grad/param norm = 2.2112e-01, time/batch = 15.2813s	
23321/29850 (epoch 39.064), train_loss = 0.89716082, grad/param norm = 2.3983e-01, time/batch = 15.0869s	
23322/29850 (epoch 39.065), train_loss = 0.69193021, grad/param norm = 2.3107e-01, time/batch = 15.0152s	
23323/29850 (epoch 39.067), train_loss = 0.86043111, grad/param norm = 2.1471e-01, time/batch = 15.0630s	
23324/29850 (epoch 39.069), train_loss = 0.84569166, grad/param norm = 2.2067e-01, time/batch = 15.4579s	
23325/29850 (epoch 39.070), train_loss = 0.85525138, grad/param norm = 2.0593e-01, time/batch = 16.7896s	
23326/29850 (epoch 39.072), train_loss = 0.81751255, grad/param norm = 2.8540e-01, time/batch = 18.5490s	
23327/29850 (epoch 39.074), train_loss = 0.88662642, grad/param norm = 2.1105e-01, time/batch = 18.8672s	
23328/29850 (epoch 39.075), train_loss = 0.76948798, grad/param norm = 2.4212e-01, time/batch = 17.8688s	
23329/29850 (epoch 39.077), train_loss = 0.87852964, grad/param norm = 2.3854e-01, time/batch = 16.5359s	
23330/29850 (epoch 39.079), train_loss = 1.01970503, grad/param norm = 3.2712e-01, time/batch = 17.2972s	
23331/29850 (epoch 39.080), train_loss = 0.98595339, grad/param norm = 2.6614e-01, time/batch = 19.1334s	
23332/29850 (epoch 39.082), train_loss = 0.88610165, grad/param norm = 2.3615e-01, time/batch = 16.2119s	
23333/29850 (epoch 39.084), train_loss = 0.97117502, grad/param norm = 2.5329e-01, time/batch = 18.4676s	
23334/29850 (epoch 39.085), train_loss = 1.00095678, grad/param norm = 2.6383e-01, time/batch = 18.9582s	
23335/29850 (epoch 39.087), train_loss = 0.95121669, grad/param norm = 2.8969e-01, time/batch = 16.6391s	
23336/29850 (epoch 39.089), train_loss = 0.85458092, grad/param norm = 2.5045e-01, time/batch = 18.7916s	
23337/29850 (epoch 39.090), train_loss = 0.85680278, grad/param norm = 2.1636e-01, time/batch = 15.8477s	
23338/29850 (epoch 39.092), train_loss = 0.76381463, grad/param norm = 2.0978e-01, time/batch = 18.5395s	
23339/29850 (epoch 39.094), train_loss = 0.96371370, grad/param norm = 2.3458e-01, time/batch = 16.6272s	
23340/29850 (epoch 39.095), train_loss = 0.89845881, grad/param norm = 3.3555e-01, time/batch = 18.0553s	
23341/29850 (epoch 39.097), train_loss = 0.65088220, grad/param norm = 1.9089e-01, time/batch = 16.2815s	
23342/29850 (epoch 39.099), train_loss = 0.67505961, grad/param norm = 2.0968e-01, time/batch = 16.0466s	
23343/29850 (epoch 39.101), train_loss = 0.90460148, grad/param norm = 2.2901e-01, time/batch = 18.7142s	
23344/29850 (epoch 39.102), train_loss = 0.89935484, grad/param norm = 2.6792e-01, time/batch = 18.5293s	
23345/29850 (epoch 39.104), train_loss = 0.76905448, grad/param norm = 2.1351e-01, time/batch = 19.4370s	
23346/29850 (epoch 39.106), train_loss = 0.92104387, grad/param norm = 2.2253e-01, time/batch = 29.7929s	
23347/29850 (epoch 39.107), train_loss = 0.77622376, grad/param norm = 2.0204e-01, time/batch = 18.1257s	
23348/29850 (epoch 39.109), train_loss = 0.81793557, grad/param norm = 2.1437e-01, time/batch = 15.8708s	
23349/29850 (epoch 39.111), train_loss = 0.84749464, grad/param norm = 2.0489e-01, time/batch = 18.6990s	
23350/29850 (epoch 39.112), train_loss = 0.73775334, grad/param norm = 2.4963e-01, time/batch = 18.6328s	
23351/29850 (epoch 39.114), train_loss = 0.77038664, grad/param norm = 2.3170e-01, time/batch = 18.0390s	
23352/29850 (epoch 39.116), train_loss = 0.74590095, grad/param norm = 2.2956e-01, time/batch = 18.5316s	
23353/29850 (epoch 39.117), train_loss = 0.79776416, grad/param norm = 2.2366e-01, time/batch = 16.6079s	
23354/29850 (epoch 39.119), train_loss = 0.76926642, grad/param norm = 2.0788e-01, time/batch = 18.1330s	
23355/29850 (epoch 39.121), train_loss = 0.66679046, grad/param norm = 2.3718e-01, time/batch = 17.0308s	
23356/29850 (epoch 39.122), train_loss = 0.70335276, grad/param norm = 1.6839e-01, time/batch = 18.8054s	
23357/29850 (epoch 39.124), train_loss = 0.75146627, grad/param norm = 2.2474e-01, time/batch = 16.5921s	
23358/29850 (epoch 39.126), train_loss = 0.78689314, grad/param norm = 2.1897e-01, time/batch = 16.4671s	
23359/29850 (epoch 39.127), train_loss = 0.85953253, grad/param norm = 2.7601e-01, time/batch = 18.9638s	
23360/29850 (epoch 39.129), train_loss = 0.81663783, grad/param norm = 2.3195e-01, time/batch = 18.0560s	
23361/29850 (epoch 39.131), train_loss = 0.81362626, grad/param norm = 1.9703e-01, time/batch = 17.7937s	
23362/29850 (epoch 39.132), train_loss = 0.67942619, grad/param norm = 2.2723e-01, time/batch = 16.4785s	
23363/29850 (epoch 39.134), train_loss = 0.79045836, grad/param norm = 2.2280e-01, time/batch = 17.1381s	
23364/29850 (epoch 39.136), train_loss = 0.86925946, grad/param norm = 2.0950e-01, time/batch = 18.6990s	
23365/29850 (epoch 39.137), train_loss = 0.67048586, grad/param norm = 2.0671e-01, time/batch = 17.4431s	
23366/29850 (epoch 39.139), train_loss = 0.78842906, grad/param norm = 1.9990e-01, time/batch = 18.0583s	
23367/29850 (epoch 39.141), train_loss = 0.70573862, grad/param norm = 2.1073e-01, time/batch = 18.8807s	
23368/29850 (epoch 39.142), train_loss = 0.94120518, grad/param norm = 2.4641e-01, time/batch = 17.6989s	
23369/29850 (epoch 39.144), train_loss = 1.02571317, grad/param norm = 2.5041e-01, time/batch = 15.9505s	
23370/29850 (epoch 39.146), train_loss = 1.04510321, grad/param norm = 2.5884e-01, time/batch = 17.6926s	
23371/29850 (epoch 39.147), train_loss = 0.91365599, grad/param norm = 2.3396e-01, time/batch = 18.4512s	
23372/29850 (epoch 39.149), train_loss = 0.86706379, grad/param norm = 2.3492e-01, time/batch = 17.9628s	
23373/29850 (epoch 39.151), train_loss = 0.87862584, grad/param norm = 2.4877e-01, time/batch = 16.8825s	
23374/29850 (epoch 39.152), train_loss = 0.81410476, grad/param norm = 2.1959e-01, time/batch = 18.6426s	
23375/29850 (epoch 39.154), train_loss = 0.77093260, grad/param norm = 2.4915e-01, time/batch = 16.2516s	
23376/29850 (epoch 39.156), train_loss = 0.75637186, grad/param norm = 2.2056e-01, time/batch = 18.7113s	
23377/29850 (epoch 39.157), train_loss = 0.88003208, grad/param norm = 2.4226e-01, time/batch = 18.7994s	
23378/29850 (epoch 39.159), train_loss = 0.78574205, grad/param norm = 2.0002e-01, time/batch = 17.0445s	
23379/29850 (epoch 39.161), train_loss = 0.80540347, grad/param norm = 2.1633e-01, time/batch = 17.0362s	
23380/29850 (epoch 39.162), train_loss = 0.93006512, grad/param norm = 2.3250e-01, time/batch = 17.6218s	
23381/29850 (epoch 39.164), train_loss = 0.87149707, grad/param norm = 2.3521e-01, time/batch = 18.3859s	
23382/29850 (epoch 39.166), train_loss = 0.77532702, grad/param norm = 2.0585e-01, time/batch = 17.7802s	
23383/29850 (epoch 39.168), train_loss = 0.70956567, grad/param norm = 1.8638e-01, time/batch = 16.6222s	
23384/29850 (epoch 39.169), train_loss = 0.95238286, grad/param norm = 3.0045e-01, time/batch = 17.9657s	
23385/29850 (epoch 39.171), train_loss = 0.87227797, grad/param norm = 2.2640e-01, time/batch = 17.6281s	
23386/29850 (epoch 39.173), train_loss = 0.72273539, grad/param norm = 1.9892e-01, time/batch = 16.4726s	
23387/29850 (epoch 39.174), train_loss = 0.81318227, grad/param norm = 2.5291e-01, time/batch = 17.1839s	
23388/29850 (epoch 39.176), train_loss = 0.83051437, grad/param norm = 2.0873e-01, time/batch = 15.4465s	
23389/29850 (epoch 39.178), train_loss = 0.87509658, grad/param norm = 2.4137e-01, time/batch = 16.1353s	
23390/29850 (epoch 39.179), train_loss = 0.68191849, grad/param norm = 2.2655e-01, time/batch = 18.4583s	
23391/29850 (epoch 39.181), train_loss = 0.84053382, grad/param norm = 2.9349e-01, time/batch = 17.7889s	
23392/29850 (epoch 39.183), train_loss = 0.83534460, grad/param norm = 2.2657e-01, time/batch = 17.8552s	
23393/29850 (epoch 39.184), train_loss = 0.89760506, grad/param norm = 2.4265e-01, time/batch = 19.5421s	
23394/29850 (epoch 39.186), train_loss = 0.85135107, grad/param norm = 2.3881e-01, time/batch = 17.4662s	
23395/29850 (epoch 39.188), train_loss = 0.95889561, grad/param norm = 2.6044e-01, time/batch = 17.5293s	
23396/29850 (epoch 39.189), train_loss = 0.90356919, grad/param norm = 2.7819e-01, time/batch = 16.5419s	
23397/29850 (epoch 39.191), train_loss = 0.92134816, grad/param norm = 2.4697e-01, time/batch = 17.1514s	
23398/29850 (epoch 39.193), train_loss = 0.79857974, grad/param norm = 1.9358e-01, time/batch = 18.3922s	
23399/29850 (epoch 39.194), train_loss = 0.90524626, grad/param norm = 2.2372e-01, time/batch = 15.5481s	
23400/29850 (epoch 39.196), train_loss = 0.79437824, grad/param norm = 2.0961e-01, time/batch = 16.7855s	
23401/29850 (epoch 39.198), train_loss = 0.76374414, grad/param norm = 2.1838e-01, time/batch = 17.1293s	
23402/29850 (epoch 39.199), train_loss = 1.05118810, grad/param norm = 2.6720e-01, time/batch = 17.7040s	
23403/29850 (epoch 39.201), train_loss = 0.76694395, grad/param norm = 2.1348e-01, time/batch = 18.0421s	
23404/29850 (epoch 39.203), train_loss = 0.59476881, grad/param norm = 2.1060e-01, time/batch = 15.4833s	
23405/29850 (epoch 39.204), train_loss = 0.79830631, grad/param norm = 2.3588e-01, time/batch = 17.2137s	
23406/29850 (epoch 39.206), train_loss = 0.72868234, grad/param norm = 2.4456e-01, time/batch = 17.1203s	
23407/29850 (epoch 39.208), train_loss = 0.96174951, grad/param norm = 2.6802e-01, time/batch = 18.4502s	
23408/29850 (epoch 39.209), train_loss = 0.72098486, grad/param norm = 2.1522e-01, time/batch = 18.1348s	
23409/29850 (epoch 39.211), train_loss = 0.78936754, grad/param norm = 2.3540e-01, time/batch = 17.3550s	
23410/29850 (epoch 39.213), train_loss = 0.86675972, grad/param norm = 2.1677e-01, time/batch = 18.5434s	
23411/29850 (epoch 39.214), train_loss = 0.71044788, grad/param norm = 1.8665e-01, time/batch = 18.8632s	
23412/29850 (epoch 39.216), train_loss = 0.72821665, grad/param norm = 2.2463e-01, time/batch = 18.0200s	
23413/29850 (epoch 39.218), train_loss = 0.84305061, grad/param norm = 2.1567e-01, time/batch = 17.3789s	
23414/29850 (epoch 39.219), train_loss = 0.86499855, grad/param norm = 2.7780e-01, time/batch = 17.4699s	
23415/29850 (epoch 39.221), train_loss = 0.82757061, grad/param norm = 2.5002e-01, time/batch = 18.2914s	
23416/29850 (epoch 39.223), train_loss = 0.67986347, grad/param norm = 2.0906e-01, time/batch = 16.4612s	
23417/29850 (epoch 39.224), train_loss = 0.68428261, grad/param norm = 2.0978e-01, time/batch = 17.7904s	
23418/29850 (epoch 39.226), train_loss = 0.75089902, grad/param norm = 2.3107e-01, time/batch = 19.3002s	
23419/29850 (epoch 39.228), train_loss = 0.76888425, grad/param norm = 1.9307e-01, time/batch = 17.3729s	
23420/29850 (epoch 39.229), train_loss = 0.66608189, grad/param norm = 1.7618e-01, time/batch = 18.1247s	
23421/29850 (epoch 39.231), train_loss = 0.82154171, grad/param norm = 2.0995e-01, time/batch = 17.2952s	
23422/29850 (epoch 39.233), train_loss = 0.78553110, grad/param norm = 2.2344e-01, time/batch = 17.7943s	
23423/29850 (epoch 39.235), train_loss = 0.75322020, grad/param norm = 2.1740e-01, time/batch = 16.5182s	
23424/29850 (epoch 39.236), train_loss = 0.95597851, grad/param norm = 2.9810e-01, time/batch = 14.8037s	
23425/29850 (epoch 39.238), train_loss = 0.70165393, grad/param norm = 2.1279e-01, time/batch = 18.2954s	
23426/29850 (epoch 39.240), train_loss = 0.69054059, grad/param norm = 1.7457e-01, time/batch = 17.6187s	
23427/29850 (epoch 39.241), train_loss = 0.84981623, grad/param norm = 2.4858e-01, time/batch = 18.4758s	
23428/29850 (epoch 39.243), train_loss = 0.86538312, grad/param norm = 2.4926e-01, time/batch = 17.9691s	
23429/29850 (epoch 39.245), train_loss = 0.73064776, grad/param norm = 2.0223e-01, time/batch = 18.2905s	
23430/29850 (epoch 39.246), train_loss = 0.70249863, grad/param norm = 1.7755e-01, time/batch = 17.3003s	
23431/29850 (epoch 39.248), train_loss = 0.69816065, grad/param norm = 2.4315e-01, time/batch = 16.1588s	
23432/29850 (epoch 39.250), train_loss = 0.74385290, grad/param norm = 1.7985e-01, time/batch = 17.9606s	
23433/29850 (epoch 39.251), train_loss = 0.66167423, grad/param norm = 2.0627e-01, time/batch = 17.0447s	
23434/29850 (epoch 39.253), train_loss = 0.65261558, grad/param norm = 2.4438e-01, time/batch = 18.1222s	
23435/29850 (epoch 39.255), train_loss = 0.70184669, grad/param norm = 2.0195e-01, time/batch = 17.6270s	
23436/29850 (epoch 39.256), train_loss = 0.84210057, grad/param norm = 2.1960e-01, time/batch = 15.7020s	
23437/29850 (epoch 39.258), train_loss = 0.84765164, grad/param norm = 2.3062e-01, time/batch = 15.9864s	
23438/29850 (epoch 39.260), train_loss = 0.78338614, grad/param norm = 2.0694e-01, time/batch = 16.4606s	
23439/29850 (epoch 39.261), train_loss = 0.72805664, grad/param norm = 2.1451e-01, time/batch = 19.0419s	
23440/29850 (epoch 39.263), train_loss = 0.72977826, grad/param norm = 2.0016e-01, time/batch = 17.0352s	
23441/29850 (epoch 39.265), train_loss = 0.78904572, grad/param norm = 2.5607e-01, time/batch = 18.9627s	
23442/29850 (epoch 39.266), train_loss = 0.79681647, grad/param norm = 2.4484e-01, time/batch = 15.9448s	
23443/29850 (epoch 39.268), train_loss = 0.77387342, grad/param norm = 2.1676e-01, time/batch = 17.0290s	
23444/29850 (epoch 39.270), train_loss = 0.73794007, grad/param norm = 2.1465e-01, time/batch = 18.1808s	
23445/29850 (epoch 39.271), train_loss = 0.84244648, grad/param norm = 2.4659e-01, time/batch = 19.2949s	
23446/29850 (epoch 39.273), train_loss = 0.68619315, grad/param norm = 1.8451e-01, time/batch = 18.3574s	
23447/29850 (epoch 39.275), train_loss = 0.68889788, grad/param norm = 2.1878e-01, time/batch = 17.9524s	
23448/29850 (epoch 39.276), train_loss = 0.67793008, grad/param norm = 2.0223e-01, time/batch = 18.3690s	
23449/29850 (epoch 39.278), train_loss = 0.74950061, grad/param norm = 2.2543e-01, time/batch = 16.8134s	
23450/29850 (epoch 39.280), train_loss = 0.95714384, grad/param norm = 2.9218e-01, time/batch = 16.9534s	
23451/29850 (epoch 39.281), train_loss = 0.82373201, grad/param norm = 2.6546e-01, time/batch = 17.9185s	
23452/29850 (epoch 39.283), train_loss = 0.91782365, grad/param norm = 2.9148e-01, time/batch = 19.1232s	
23453/29850 (epoch 39.285), train_loss = 0.87536441, grad/param norm = 2.3354e-01, time/batch = 17.6974s	
23454/29850 (epoch 39.286), train_loss = 0.88023857, grad/param norm = 2.3150e-01, time/batch = 18.6984s	
23455/29850 (epoch 39.288), train_loss = 0.86532913, grad/param norm = 2.8062e-01, time/batch = 17.9649s	
23456/29850 (epoch 39.290), train_loss = 0.83629619, grad/param norm = 2.7872e-01, time/batch = 16.9690s	
23457/29850 (epoch 39.291), train_loss = 1.04361093, grad/param norm = 2.9259e-01, time/batch = 17.8725s	
23458/29850 (epoch 39.293), train_loss = 0.95600296, grad/param norm = 2.5445e-01, time/batch = 18.5514s	
23459/29850 (epoch 39.295), train_loss = 1.00960787, grad/param norm = 2.6397e-01, time/batch = 19.9639s	
23460/29850 (epoch 39.296), train_loss = 0.74659681, grad/param norm = 1.9498e-01, time/batch = 17.6194s	
23461/29850 (epoch 39.298), train_loss = 0.62099344, grad/param norm = 2.1801e-01, time/batch = 16.8804s	
23462/29850 (epoch 39.300), train_loss = 0.71352279, grad/param norm = 2.1531e-01, time/batch = 19.6951s	
23463/29850 (epoch 39.302), train_loss = 0.68817369, grad/param norm = 2.1020e-01, time/batch = 16.6018s	
23464/29850 (epoch 39.303), train_loss = 0.75103258, grad/param norm = 2.1967e-01, time/batch = 15.0270s	
23465/29850 (epoch 39.305), train_loss = 0.88928280, grad/param norm = 2.2779e-01, time/batch = 14.9522s	
23466/29850 (epoch 39.307), train_loss = 0.88954934, grad/param norm = 2.2287e-01, time/batch = 16.4360s	
23467/29850 (epoch 39.308), train_loss = 0.69275232, grad/param norm = 2.2046e-01, time/batch = 15.4725s	
23468/29850 (epoch 39.310), train_loss = 0.84480297, grad/param norm = 2.2488e-01, time/batch = 18.9501s	
23469/29850 (epoch 39.312), train_loss = 0.88374801, grad/param norm = 2.2556e-01, time/batch = 18.5464s	
23470/29850 (epoch 39.313), train_loss = 0.80458323, grad/param norm = 2.3427e-01, time/batch = 17.5509s	
23471/29850 (epoch 39.315), train_loss = 0.83270419, grad/param norm = 2.1741e-01, time/batch = 19.0428s	
23472/29850 (epoch 39.317), train_loss = 0.84655774, grad/param norm = 2.5654e-01, time/batch = 17.6875s	
23473/29850 (epoch 39.318), train_loss = 0.81081523, grad/param norm = 2.3144e-01, time/batch = 19.0962s	
23474/29850 (epoch 39.320), train_loss = 0.74162505, grad/param norm = 2.0173e-01, time/batch = 17.7230s	
23475/29850 (epoch 39.322), train_loss = 0.93523820, grad/param norm = 2.6588e-01, time/batch = 15.8187s	
23476/29850 (epoch 39.323), train_loss = 0.85314347, grad/param norm = 2.2720e-01, time/batch = 18.2680s	
23477/29850 (epoch 39.325), train_loss = 0.91223319, grad/param norm = 2.2959e-01, time/batch = 16.6163s	
23478/29850 (epoch 39.327), train_loss = 1.02138254, grad/param norm = 2.4362e-01, time/batch = 17.6209s	
23479/29850 (epoch 39.328), train_loss = 0.93209363, grad/param norm = 2.4296e-01, time/batch = 18.4616s	
23480/29850 (epoch 39.330), train_loss = 0.88656660, grad/param norm = 2.0677e-01, time/batch = 17.3658s	
23481/29850 (epoch 39.332), train_loss = 0.76034531, grad/param norm = 1.9595e-01, time/batch = 17.9435s	
23482/29850 (epoch 39.333), train_loss = 0.86848064, grad/param norm = 2.2393e-01, time/batch = 17.8009s	
23483/29850 (epoch 39.335), train_loss = 0.90931626, grad/param norm = 2.2510e-01, time/batch = 18.7920s	
23484/29850 (epoch 39.337), train_loss = 0.81445740, grad/param norm = 2.1871e-01, time/batch = 18.3762s	
23485/29850 (epoch 39.338), train_loss = 0.85952296, grad/param norm = 2.1296e-01, time/batch = 18.3046s	
23486/29850 (epoch 39.340), train_loss = 0.70601299, grad/param norm = 2.1584e-01, time/batch = 17.8986s	
23487/29850 (epoch 39.342), train_loss = 0.83859125, grad/param norm = 2.9038e-01, time/batch = 17.4485s	
23488/29850 (epoch 39.343), train_loss = 0.80652813, grad/param norm = 2.2241e-01, time/batch = 17.0531s	
23489/29850 (epoch 39.345), train_loss = 0.90265828, grad/param norm = 2.8662e-01, time/batch = 18.2147s	
23490/29850 (epoch 39.347), train_loss = 0.91658116, grad/param norm = 2.7212e-01, time/batch = 15.5943s	
23491/29850 (epoch 39.348), train_loss = 0.78021935, grad/param norm = 2.3916e-01, time/batch = 17.5204s	
23492/29850 (epoch 39.350), train_loss = 0.86578528, grad/param norm = 2.3616e-01, time/batch = 19.7018s	
23493/29850 (epoch 39.352), train_loss = 0.78667209, grad/param norm = 2.2015e-01, time/batch = 17.9611s	
23494/29850 (epoch 39.353), train_loss = 0.86736186, grad/param norm = 2.3455e-01, time/batch = 16.2949s	
23495/29850 (epoch 39.355), train_loss = 0.79303958, grad/param norm = 2.3381e-01, time/batch = 18.4575s	
23496/29850 (epoch 39.357), train_loss = 0.90082969, grad/param norm = 2.0523e-01, time/batch = 18.3945s	
23497/29850 (epoch 39.358), train_loss = 0.74119599, grad/param norm = 2.1627e-01, time/batch = 16.7932s	
23498/29850 (epoch 39.360), train_loss = 0.81131892, grad/param norm = 2.1149e-01, time/batch = 17.1353s	
23499/29850 (epoch 39.362), train_loss = 0.82002561, grad/param norm = 2.4857e-01, time/batch = 18.5618s	
23500/29850 (epoch 39.363), train_loss = 0.87193999, grad/param norm = 2.4240e-01, time/batch = 17.9706s	
23501/29850 (epoch 39.365), train_loss = 0.95093192, grad/param norm = 2.4604e-01, time/batch = 18.6301s	
23502/29850 (epoch 39.367), train_loss = 0.75232356, grad/param norm = 1.9840e-01, time/batch = 18.3764s	
23503/29850 (epoch 39.369), train_loss = 0.67268059, grad/param norm = 2.1677e-01, time/batch = 17.1964s	
23504/29850 (epoch 39.370), train_loss = 0.69258851, grad/param norm = 2.4647e-01, time/batch = 17.2880s	
23505/29850 (epoch 39.372), train_loss = 0.92233188, grad/param norm = 2.3108e-01, time/batch = 16.6867s	
23506/29850 (epoch 39.374), train_loss = 0.89293890, grad/param norm = 2.1112e-01, time/batch = 15.0881s	
23507/29850 (epoch 39.375), train_loss = 0.82899690, grad/param norm = 2.4786e-01, time/batch = 15.9558s	
23508/29850 (epoch 39.377), train_loss = 0.72900827, grad/param norm = 2.1878e-01, time/batch = 15.7871s	
23509/29850 (epoch 39.379), train_loss = 0.92651288, grad/param norm = 2.2941e-01, time/batch = 16.2306s	
23510/29850 (epoch 39.380), train_loss = 0.87184545, grad/param norm = 2.3640e-01, time/batch = 15.3859s	
23511/29850 (epoch 39.382), train_loss = 0.83686414, grad/param norm = 2.3303e-01, time/batch = 15.8865s	
23512/29850 (epoch 39.384), train_loss = 0.88161460, grad/param norm = 2.1801e-01, time/batch = 15.6579s	
23513/29850 (epoch 39.385), train_loss = 0.87462028, grad/param norm = 2.3444e-01, time/batch = 15.8252s	
23514/29850 (epoch 39.387), train_loss = 0.86206670, grad/param norm = 2.3863e-01, time/batch = 18.2154s	
23515/29850 (epoch 39.389), train_loss = 0.96464517, grad/param norm = 2.4545e-01, time/batch = 15.2936s	
23516/29850 (epoch 39.390), train_loss = 0.90034416, grad/param norm = 2.1280e-01, time/batch = 17.7866s	
23517/29850 (epoch 39.392), train_loss = 0.80925642, grad/param norm = 2.5229e-01, time/batch = 17.6406s	
23518/29850 (epoch 39.394), train_loss = 0.90391345, grad/param norm = 2.1915e-01, time/batch = 18.1941s	
23519/29850 (epoch 39.395), train_loss = 0.76048796, grad/param norm = 2.2141e-01, time/batch = 16.9513s	
23520/29850 (epoch 39.397), train_loss = 0.72370978, grad/param norm = 2.5719e-01, time/batch = 18.6294s	
23521/29850 (epoch 39.399), train_loss = 0.77141505, grad/param norm = 2.4379e-01, time/batch = 18.7786s	
23522/29850 (epoch 39.400), train_loss = 1.08853286, grad/param norm = 2.4220e-01, time/batch = 14.8540s	
23523/29850 (epoch 39.402), train_loss = 0.95771714, grad/param norm = 2.2398e-01, time/batch = 14.8593s	
23524/29850 (epoch 39.404), train_loss = 0.84212742, grad/param norm = 2.2101e-01, time/batch = 15.5707s	
23525/29850 (epoch 39.405), train_loss = 0.78890491, grad/param norm = 2.7034e-01, time/batch = 16.7961s	
23526/29850 (epoch 39.407), train_loss = 0.75465125, grad/param norm = 2.0294e-01, time/batch = 19.0336s	
23527/29850 (epoch 39.409), train_loss = 0.85279176, grad/param norm = 2.2836e-01, time/batch = 16.8735s	
23528/29850 (epoch 39.410), train_loss = 0.94632351, grad/param norm = 2.3871e-01, time/batch = 17.6331s	
23529/29850 (epoch 39.412), train_loss = 0.93510183, grad/param norm = 2.7927e-01, time/batch = 15.1128s	
23530/29850 (epoch 39.414), train_loss = 0.85252849, grad/param norm = 2.4724e-01, time/batch = 17.4071s	
23531/29850 (epoch 39.415), train_loss = 0.82162602, grad/param norm = 2.1989e-01, time/batch = 17.6285s	
23532/29850 (epoch 39.417), train_loss = 0.95510993, grad/param norm = 2.4691e-01, time/batch = 17.2086s	
23533/29850 (epoch 39.419), train_loss = 0.80032936, grad/param norm = 2.0726e-01, time/batch = 17.8701s	
23534/29850 (epoch 39.420), train_loss = 0.83655077, grad/param norm = 2.3401e-01, time/batch = 16.8009s	
23535/29850 (epoch 39.422), train_loss = 0.84600349, grad/param norm = 2.3987e-01, time/batch = 18.7066s	
23536/29850 (epoch 39.424), train_loss = 0.74028721, grad/param norm = 2.0624e-01, time/batch = 16.6301s	
23537/29850 (epoch 39.425), train_loss = 0.88368727, grad/param norm = 2.4147e-01, time/batch = 16.1547s	
23538/29850 (epoch 39.427), train_loss = 0.63517662, grad/param norm = 2.2922e-01, time/batch = 15.5367s	
23539/29850 (epoch 39.429), train_loss = 0.73157251, grad/param norm = 2.2214e-01, time/batch = 18.4474s	
23540/29850 (epoch 39.430), train_loss = 0.68247684, grad/param norm = 2.0182e-01, time/batch = 18.6116s	
23541/29850 (epoch 39.432), train_loss = 0.78308294, grad/param norm = 2.3115e-01, time/batch = 17.5173s	
23542/29850 (epoch 39.434), train_loss = 0.76583247, grad/param norm = 2.3863e-01, time/batch = 14.0938s	
23543/29850 (epoch 39.436), train_loss = 0.82884777, grad/param norm = 2.5704e-01, time/batch = 15.2367s	
23544/29850 (epoch 39.437), train_loss = 0.88147220, grad/param norm = 2.3856e-01, time/batch = 15.1922s	
23545/29850 (epoch 39.439), train_loss = 0.88359774, grad/param norm = 2.3137e-01, time/batch = 15.3942s	
23546/29850 (epoch 39.441), train_loss = 0.82761157, grad/param norm = 2.1942e-01, time/batch = 16.1193s	
23547/29850 (epoch 39.442), train_loss = 0.80565055, grad/param norm = 2.2083e-01, time/batch = 16.2355s	
23548/29850 (epoch 39.444), train_loss = 0.86654001, grad/param norm = 2.3533e-01, time/batch = 17.3037s	
23549/29850 (epoch 39.446), train_loss = 0.90392059, grad/param norm = 2.2470e-01, time/batch = 18.0537s	
23550/29850 (epoch 39.447), train_loss = 0.91150514, grad/param norm = 2.8297e-01, time/batch = 21.5598s	
23551/29850 (epoch 39.449), train_loss = 0.82885653, grad/param norm = 2.3135e-01, time/batch = 22.0581s	
23552/29850 (epoch 39.451), train_loss = 0.65304202, grad/param norm = 2.1376e-01, time/batch = 16.5263s	
23553/29850 (epoch 39.452), train_loss = 0.56871632, grad/param norm = 1.9516e-01, time/batch = 16.2910s	
23554/29850 (epoch 39.454), train_loss = 0.69691953, grad/param norm = 2.0129e-01, time/batch = 17.1353s	
23555/29850 (epoch 39.456), train_loss = 0.90693718, grad/param norm = 2.5357e-01, time/batch = 18.5586s	
23556/29850 (epoch 39.457), train_loss = 0.92075581, grad/param norm = 3.2263e-01, time/batch = 16.0666s	
23557/29850 (epoch 39.459), train_loss = 0.96554472, grad/param norm = 2.7043e-01, time/batch = 16.9625s	
23558/29850 (epoch 39.461), train_loss = 0.94002947, grad/param norm = 2.3426e-01, time/batch = 16.1954s	
23559/29850 (epoch 39.462), train_loss = 0.98729052, grad/param norm = 2.7472e-01, time/batch = 18.6921s	
23560/29850 (epoch 39.464), train_loss = 0.86998954, grad/param norm = 2.2147e-01, time/batch = 17.1268s	
23561/29850 (epoch 39.466), train_loss = 0.70332693, grad/param norm = 1.9386e-01, time/batch = 18.6225s	
23562/29850 (epoch 39.467), train_loss = 0.76286888, grad/param norm = 2.3022e-01, time/batch = 18.8753s	
23563/29850 (epoch 39.469), train_loss = 0.79773792, grad/param norm = 2.1168e-01, time/batch = 17.2862s	
23564/29850 (epoch 39.471), train_loss = 0.78271888, grad/param norm = 2.3831e-01, time/batch = 17.5477s	
23565/29850 (epoch 39.472), train_loss = 0.77447759, grad/param norm = 2.0532e-01, time/batch = 17.8046s	
23566/29850 (epoch 39.474), train_loss = 0.91357273, grad/param norm = 2.4818e-01, time/batch = 16.2077s	
23567/29850 (epoch 39.476), train_loss = 0.83404672, grad/param norm = 2.0392e-01, time/batch = 16.8255s	
23568/29850 (epoch 39.477), train_loss = 0.84617364, grad/param norm = 2.6900e-01, time/batch = 18.2197s	
23569/29850 (epoch 39.479), train_loss = 0.99948904, grad/param norm = 2.2095e-01, time/batch = 17.3131s	
23570/29850 (epoch 39.481), train_loss = 0.84689490, grad/param norm = 2.4730e-01, time/batch = 15.4034s	
23571/29850 (epoch 39.482), train_loss = 0.77317166, grad/param norm = 2.0228e-01, time/batch = 15.8771s	
23572/29850 (epoch 39.484), train_loss = 0.77256300, grad/param norm = 2.1110e-01, time/batch = 17.3791s	
23573/29850 (epoch 39.486), train_loss = 0.87653281, grad/param norm = 2.3983e-01, time/batch = 18.9656s	
23574/29850 (epoch 39.487), train_loss = 0.83832919, grad/param norm = 2.3080e-01, time/batch = 16.4655s	
23575/29850 (epoch 39.489), train_loss = 0.84401119, grad/param norm = 2.3303e-01, time/batch = 17.0448s	
23576/29850 (epoch 39.491), train_loss = 0.75161286, grad/param norm = 2.0579e-01, time/batch = 19.1924s	
23577/29850 (epoch 39.492), train_loss = 0.84088036, grad/param norm = 2.2454e-01, time/batch = 17.0548s	
23578/29850 (epoch 39.494), train_loss = 0.88998315, grad/param norm = 2.2521e-01, time/batch = 18.2015s	
23579/29850 (epoch 39.496), train_loss = 0.92489190, grad/param norm = 2.1613e-01, time/batch = 17.6777s	
23580/29850 (epoch 39.497), train_loss = 0.86413209, grad/param norm = 2.3918e-01, time/batch = 17.7109s	
23581/29850 (epoch 39.499), train_loss = 0.83919098, grad/param norm = 2.6970e-01, time/batch = 16.7975s	
23582/29850 (epoch 39.501), train_loss = 0.75866321, grad/param norm = 3.1824e-01, time/batch = 19.2784s	
23583/29850 (epoch 39.503), train_loss = 0.89422407, grad/param norm = 2.3464e-01, time/batch = 16.5485s	
23584/29850 (epoch 39.504), train_loss = 1.05157068, grad/param norm = 2.3362e-01, time/batch = 16.5450s	
23585/29850 (epoch 39.506), train_loss = 1.03108515, grad/param norm = 2.7468e-01, time/batch = 18.9529s	
23586/29850 (epoch 39.508), train_loss = 0.86942028, grad/param norm = 2.3326e-01, time/batch = 16.5509s	
23587/29850 (epoch 39.509), train_loss = 0.67463750, grad/param norm = 2.6396e-01, time/batch = 18.3695s	
23588/29850 (epoch 39.511), train_loss = 0.89461000, grad/param norm = 2.5930e-01, time/batch = 15.5009s	
23589/29850 (epoch 39.513), train_loss = 0.83515530, grad/param norm = 2.4742e-01, time/batch = 15.3774s	
23590/29850 (epoch 39.514), train_loss = 0.73089561, grad/param norm = 2.1707e-01, time/batch = 15.3757s	
23591/29850 (epoch 39.516), train_loss = 0.78832994, grad/param norm = 1.9740e-01, time/batch = 16.0307s	
23592/29850 (epoch 39.518), train_loss = 0.66620512, grad/param norm = 2.0144e-01, time/batch = 16.1921s	
23593/29850 (epoch 39.519), train_loss = 0.67234897, grad/param norm = 1.8164e-01, time/batch = 16.3608s	
23594/29850 (epoch 39.521), train_loss = 0.62560317, grad/param norm = 1.7859e-01, time/batch = 17.7247s	
23595/29850 (epoch 39.523), train_loss = 0.68194342, grad/param norm = 1.8467e-01, time/batch = 15.4959s	
23596/29850 (epoch 39.524), train_loss = 0.72824557, grad/param norm = 2.2920e-01, time/batch = 17.6938s	
23597/29850 (epoch 39.526), train_loss = 0.78392585, grad/param norm = 2.5317e-01, time/batch = 18.7178s	
23598/29850 (epoch 39.528), train_loss = 0.90650672, grad/param norm = 2.2731e-01, time/batch = 17.4543s	
23599/29850 (epoch 39.529), train_loss = 0.85414653, grad/param norm = 2.4590e-01, time/batch = 18.1181s	
23600/29850 (epoch 39.531), train_loss = 0.80596214, grad/param norm = 2.8163e-01, time/batch = 16.8021s	
23601/29850 (epoch 39.533), train_loss = 0.83296739, grad/param norm = 2.1473e-01, time/batch = 17.3792s	
23602/29850 (epoch 39.534), train_loss = 0.88511184, grad/param norm = 2.3983e-01, time/batch = 16.6898s	
23603/29850 (epoch 39.536), train_loss = 0.78765125, grad/param norm = 2.3274e-01, time/batch = 17.5642s	
23604/29850 (epoch 39.538), train_loss = 0.94731522, grad/param norm = 2.8189e-01, time/batch = 17.2850s	
23605/29850 (epoch 39.539), train_loss = 0.95580449, grad/param norm = 2.4967e-01, time/batch = 15.7211s	
23606/29850 (epoch 39.541), train_loss = 0.60915126, grad/param norm = 1.9662e-01, time/batch = 15.1912s	
23607/29850 (epoch 39.543), train_loss = 0.78465957, grad/param norm = 2.1582e-01, time/batch = 16.5594s	
23608/29850 (epoch 39.544), train_loss = 0.93517956, grad/param norm = 2.4446e-01, time/batch = 16.3814s	
23609/29850 (epoch 39.546), train_loss = 0.89781744, grad/param norm = 2.1942e-01, time/batch = 17.4577s	
23610/29850 (epoch 39.548), train_loss = 0.68934925, grad/param norm = 1.9492e-01, time/batch = 16.8766s	
23611/29850 (epoch 39.549), train_loss = 0.77880814, grad/param norm = 2.0149e-01, time/batch = 18.5339s	
23612/29850 (epoch 39.551), train_loss = 0.72991420, grad/param norm = 2.0503e-01, time/batch = 15.5574s	
23613/29850 (epoch 39.553), train_loss = 0.80970444, grad/param norm = 2.2421e-01, time/batch = 16.2951s	
23614/29850 (epoch 39.554), train_loss = 0.66457656, grad/param norm = 1.9008e-01, time/batch = 16.1191s	
23615/29850 (epoch 39.556), train_loss = 0.70884120, grad/param norm = 1.9909e-01, time/batch = 15.5483s	
23616/29850 (epoch 39.558), train_loss = 0.71418529, grad/param norm = 2.1410e-01, time/batch = 15.9664s	
23617/29850 (epoch 39.559), train_loss = 0.74820929, grad/param norm = 2.1174e-01, time/batch = 17.3694s	
23618/29850 (epoch 39.561), train_loss = 0.83288561, grad/param norm = 2.3137e-01, time/batch = 19.1969s	
23619/29850 (epoch 39.563), train_loss = 0.84413256, grad/param norm = 2.1252e-01, time/batch = 17.1996s	
23620/29850 (epoch 39.564), train_loss = 0.77193934, grad/param norm = 2.1814e-01, time/batch = 18.1270s	
23621/29850 (epoch 39.566), train_loss = 0.81309065, grad/param norm = 2.3430e-01, time/batch = 16.3756s	
23622/29850 (epoch 39.568), train_loss = 0.94960027, grad/param norm = 2.4439e-01, time/batch = 17.5541s	
23623/29850 (epoch 39.570), train_loss = 0.83109089, grad/param norm = 2.3223e-01, time/batch = 15.5550s	
23624/29850 (epoch 39.571), train_loss = 0.89530168, grad/param norm = 2.1399e-01, time/batch = 18.1123s	
23625/29850 (epoch 39.573), train_loss = 0.95938632, grad/param norm = 2.6253e-01, time/batch = 18.7983s	
23626/29850 (epoch 39.575), train_loss = 0.99950783, grad/param norm = 2.3256e-01, time/batch = 17.6220s	
23627/29850 (epoch 39.576), train_loss = 0.90484056, grad/param norm = 2.3539e-01, time/batch = 17.5394s	
23628/29850 (epoch 39.578), train_loss = 0.77365287, grad/param norm = 2.2745e-01, time/batch = 16.7820s	
23629/29850 (epoch 39.580), train_loss = 0.92538881, grad/param norm = 2.4581e-01, time/batch = 17.5530s	
23630/29850 (epoch 39.581), train_loss = 0.73411055, grad/param norm = 1.9729e-01, time/batch = 16.5298s	
23631/29850 (epoch 39.583), train_loss = 0.81009714, grad/param norm = 2.2386e-01, time/batch = 18.3835s	
23632/29850 (epoch 39.585), train_loss = 0.83576055, grad/param norm = 2.1258e-01, time/batch = 16.7800s	
23633/29850 (epoch 39.586), train_loss = 0.87652847, grad/param norm = 3.0219e-01, time/batch = 16.9300s	
23634/29850 (epoch 39.588), train_loss = 0.76090716, grad/param norm = 2.1229e-01, time/batch = 17.4591s	
23635/29850 (epoch 39.590), train_loss = 0.76078445, grad/param norm = 1.9063e-01, time/batch = 18.2996s	
23636/29850 (epoch 39.591), train_loss = 0.81037856, grad/param norm = 2.2788e-01, time/batch = 17.7016s	
23637/29850 (epoch 39.593), train_loss = 0.72412689, grad/param norm = 1.8840e-01, time/batch = 15.9635s	
23638/29850 (epoch 39.595), train_loss = 0.67926810, grad/param norm = 1.6302e-01, time/batch = 16.8794s	
23639/29850 (epoch 39.596), train_loss = 0.73914807, grad/param norm = 2.2868e-01, time/batch = 16.6195s	
23640/29850 (epoch 39.598), train_loss = 0.79829010, grad/param norm = 2.1558e-01, time/batch = 17.2044s	
23641/29850 (epoch 39.600), train_loss = 0.82038822, grad/param norm = 1.9304e-01, time/batch = 15.9878s	
23642/29850 (epoch 39.601), train_loss = 0.70779360, grad/param norm = 1.8056e-01, time/batch = 18.1438s	
23643/29850 (epoch 39.603), train_loss = 0.74536956, grad/param norm = 2.2128e-01, time/batch = 17.5517s	
23644/29850 (epoch 39.605), train_loss = 0.79789862, grad/param norm = 2.2997e-01, time/batch = 18.4450s	
23645/29850 (epoch 39.606), train_loss = 0.55554522, grad/param norm = 1.8004e-01, time/batch = 15.3063s	
23646/29850 (epoch 39.608), train_loss = 0.68918922, grad/param norm = 1.7698e-01, time/batch = 17.0523s	
23647/29850 (epoch 39.610), train_loss = 0.76090544, grad/param norm = 2.0687e-01, time/batch = 17.5353s	
23648/29850 (epoch 39.611), train_loss = 0.70351951, grad/param norm = 1.9395e-01, time/batch = 17.3728s	
23649/29850 (epoch 39.613), train_loss = 0.59591894, grad/param norm = 1.7190e-01, time/batch = 18.0508s	
23650/29850 (epoch 39.615), train_loss = 0.67102836, grad/param norm = 1.9512e-01, time/batch = 16.8716s	
23651/29850 (epoch 39.616), train_loss = 0.68559150, grad/param norm = 2.0079e-01, time/batch = 17.3654s	
23652/29850 (epoch 39.618), train_loss = 0.75608695, grad/param norm = 2.2368e-01, time/batch = 16.1050s	
23653/29850 (epoch 39.620), train_loss = 0.84776042, grad/param norm = 2.4347e-01, time/batch = 17.7875s	
23654/29850 (epoch 39.621), train_loss = 0.92311619, grad/param norm = 2.3947e-01, time/batch = 10.9573s	
23655/29850 (epoch 39.623), train_loss = 0.89194278, grad/param norm = 2.1703e-01, time/batch = 0.6535s	
23656/29850 (epoch 39.625), train_loss = 0.81156788, grad/param norm = 2.1845e-01, time/batch = 0.6431s	
23657/29850 (epoch 39.626), train_loss = 0.82727279, grad/param norm = 2.5410e-01, time/batch = 0.6517s	
23658/29850 (epoch 39.628), train_loss = 0.79951283, grad/param norm = 2.2762e-01, time/batch = 0.6438s	
23659/29850 (epoch 39.630), train_loss = 0.81465043, grad/param norm = 2.3656e-01, time/batch = 0.6616s	
23660/29850 (epoch 39.631), train_loss = 0.82756272, grad/param norm = 2.2738e-01, time/batch = 0.6642s	
23661/29850 (epoch 39.633), train_loss = 0.85084822, grad/param norm = 2.4221e-01, time/batch = 0.6435s	
23662/29850 (epoch 39.635), train_loss = 0.76997669, grad/param norm = 3.4145e-01, time/batch = 0.8476s	
23663/29850 (epoch 39.637), train_loss = 0.72278703, grad/param norm = 2.1473e-01, time/batch = 0.9458s	
23664/29850 (epoch 39.638), train_loss = 0.84423541, grad/param norm = 2.5288e-01, time/batch = 0.9524s	
23665/29850 (epoch 39.640), train_loss = 0.93709917, grad/param norm = 2.4497e-01, time/batch = 0.9459s	
23666/29850 (epoch 39.642), train_loss = 0.78484756, grad/param norm = 2.1688e-01, time/batch = 0.9444s	
23667/29850 (epoch 39.643), train_loss = 0.74859040, grad/param norm = 2.5040e-01, time/batch = 1.2813s	
23668/29850 (epoch 39.645), train_loss = 0.79156131, grad/param norm = 2.0087e-01, time/batch = 1.7515s	
23669/29850 (epoch 39.647), train_loss = 0.93775396, grad/param norm = 2.3487e-01, time/batch = 1.7547s	
23670/29850 (epoch 39.648), train_loss = 0.71951239, grad/param norm = 1.9892e-01, time/batch = 12.4081s	
23671/29850 (epoch 39.650), train_loss = 0.83548816, grad/param norm = 2.4420e-01, time/batch = 16.3046s	
23672/29850 (epoch 39.652), train_loss = 0.83263761, grad/param norm = 2.5523e-01, time/batch = 18.8654s	
23673/29850 (epoch 39.653), train_loss = 0.90903126, grad/param norm = 2.6211e-01, time/batch = 14.5526s	
23674/29850 (epoch 39.655), train_loss = 0.82747773, grad/param norm = 1.9906e-01, time/batch = 18.6336s	
23675/29850 (epoch 39.657), train_loss = 0.81258277, grad/param norm = 2.1765e-01, time/batch = 17.3066s	
23676/29850 (epoch 39.658), train_loss = 0.91908642, grad/param norm = 2.4973e-01, time/batch = 15.4597s	
23677/29850 (epoch 39.660), train_loss = 0.77949220, grad/param norm = 2.5011e-01, time/batch = 16.0973s	
23678/29850 (epoch 39.662), train_loss = 0.91659818, grad/param norm = 2.6005e-01, time/batch = 18.7825s	
23679/29850 (epoch 39.663), train_loss = 1.01654869, grad/param norm = 2.3674e-01, time/batch = 16.4544s	
23680/29850 (epoch 39.665), train_loss = 0.94831785, grad/param norm = 2.4343e-01, time/batch = 17.2063s	
23681/29850 (epoch 39.667), train_loss = 0.89423521, grad/param norm = 3.0148e-01, time/batch = 19.4536s	
23682/29850 (epoch 39.668), train_loss = 0.78177521, grad/param norm = 2.2737e-01, time/batch = 17.5450s	
23683/29850 (epoch 39.670), train_loss = 0.89862747, grad/param norm = 3.0600e-01, time/batch = 18.2130s	
23684/29850 (epoch 39.672), train_loss = 0.89746401, grad/param norm = 2.6247e-01, time/batch = 17.7236s	
23685/29850 (epoch 39.673), train_loss = 0.84738404, grad/param norm = 2.4953e-01, time/batch = 17.4747s	
23686/29850 (epoch 39.675), train_loss = 0.73254399, grad/param norm = 2.1166e-01, time/batch = 16.0384s	
23687/29850 (epoch 39.677), train_loss = 0.78297050, grad/param norm = 2.3411e-01, time/batch = 18.1386s	
23688/29850 (epoch 39.678), train_loss = 0.82653041, grad/param norm = 2.3957e-01, time/batch = 17.0537s	
23689/29850 (epoch 39.680), train_loss = 0.79961251, grad/param norm = 2.1348e-01, time/batch = 17.2757s	
23690/29850 (epoch 39.682), train_loss = 0.81652805, grad/param norm = 2.1794e-01, time/batch = 15.8563s	
23691/29850 (epoch 39.683), train_loss = 0.91566638, grad/param norm = 2.4436e-01, time/batch = 17.9542s	
23692/29850 (epoch 39.685), train_loss = 1.01166300, grad/param norm = 2.2721e-01, time/batch = 16.5145s	
23693/29850 (epoch 39.687), train_loss = 0.86300313, grad/param norm = 2.0593e-01, time/batch = 17.4583s	
23694/29850 (epoch 39.688), train_loss = 0.74385841, grad/param norm = 2.3654e-01, time/batch = 18.4249s	
23695/29850 (epoch 39.690), train_loss = 0.73260338, grad/param norm = 2.2536e-01, time/batch = 18.6136s	
23696/29850 (epoch 39.692), train_loss = 0.92138877, grad/param norm = 2.2307e-01, time/batch = 17.2220s	
23697/29850 (epoch 39.693), train_loss = 0.82635410, grad/param norm = 2.0833e-01, time/batch = 18.2917s	
23698/29850 (epoch 39.695), train_loss = 0.73393463, grad/param norm = 2.0611e-01, time/batch = 17.3018s	
23699/29850 (epoch 39.697), train_loss = 0.83050732, grad/param norm = 2.4229e-01, time/batch = 18.5498s	
23700/29850 (epoch 39.698), train_loss = 0.95492984, grad/param norm = 2.3838e-01, time/batch = 18.2991s	
23701/29850 (epoch 39.700), train_loss = 0.88865853, grad/param norm = 2.9976e-01, time/batch = 17.2193s	
23702/29850 (epoch 39.702), train_loss = 0.83025612, grad/param norm = 2.3496e-01, time/batch = 19.8671s	
23703/29850 (epoch 39.704), train_loss = 0.70344317, grad/param norm = 2.1678e-01, time/batch = 15.9437s	
23704/29850 (epoch 39.705), train_loss = 0.82926013, grad/param norm = 2.3580e-01, time/batch = 17.6262s	
23705/29850 (epoch 39.707), train_loss = 0.75732096, grad/param norm = 2.5497e-01, time/batch = 18.2021s	
23706/29850 (epoch 39.709), train_loss = 0.81769152, grad/param norm = 2.2945e-01, time/batch = 17.2493s	
23707/29850 (epoch 39.710), train_loss = 0.75296526, grad/param norm = 2.3176e-01, time/batch = 15.4880s	
23708/29850 (epoch 39.712), train_loss = 0.84883829, grad/param norm = 2.0356e-01, time/batch = 16.8004s	
23709/29850 (epoch 39.714), train_loss = 0.92199647, grad/param norm = 2.8397e-01, time/batch = 15.2049s	
23710/29850 (epoch 39.715), train_loss = 0.84611432, grad/param norm = 2.1540e-01, time/batch = 15.6157s	
23711/29850 (epoch 39.717), train_loss = 0.62421384, grad/param norm = 2.3570e-01, time/batch = 18.0384s	
23712/29850 (epoch 39.719), train_loss = 0.77003324, grad/param norm = 2.0337e-01, time/batch = 17.1014s	
23713/29850 (epoch 39.720), train_loss = 0.79712891, grad/param norm = 1.9687e-01, time/batch = 17.2066s	
23714/29850 (epoch 39.722), train_loss = 0.74507238, grad/param norm = 1.9024e-01, time/batch = 15.6323s	
23715/29850 (epoch 39.724), train_loss = 0.83899973, grad/param norm = 2.3917e-01, time/batch = 16.4517s	
23716/29850 (epoch 39.725), train_loss = 0.71774384, grad/param norm = 2.0176e-01, time/batch = 17.7972s	
23717/29850 (epoch 39.727), train_loss = 0.69118170, grad/param norm = 1.9485e-01, time/batch = 16.4331s	
23718/29850 (epoch 39.729), train_loss = 0.68277427, grad/param norm = 1.7580e-01, time/batch = 16.7945s	
23719/29850 (epoch 39.730), train_loss = 0.65423921, grad/param norm = 2.1606e-01, time/batch = 18.8820s	
23720/29850 (epoch 39.732), train_loss = 0.90808772, grad/param norm = 2.2171e-01, time/batch = 17.2079s	
23721/29850 (epoch 39.734), train_loss = 0.98414676, grad/param norm = 2.5319e-01, time/batch = 17.1729s	
23722/29850 (epoch 39.735), train_loss = 0.73531632, grad/param norm = 2.0068e-01, time/batch = 18.1362s	
23723/29850 (epoch 39.737), train_loss = 0.71042562, grad/param norm = 1.8013e-01, time/batch = 17.0275s	
23724/29850 (epoch 39.739), train_loss = 0.61953243, grad/param norm = 1.9523e-01, time/batch = 17.5382s	
23725/29850 (epoch 39.740), train_loss = 0.67489798, grad/param norm = 2.1888e-01, time/batch = 17.2180s	
23726/29850 (epoch 39.742), train_loss = 0.60397800, grad/param norm = 1.7396e-01, time/batch = 18.5456s	
23727/29850 (epoch 39.744), train_loss = 0.73294061, grad/param norm = 2.2861e-01, time/batch = 16.4629s	
23728/29850 (epoch 39.745), train_loss = 0.75978561, grad/param norm = 2.4486e-01, time/batch = 19.5410s	
23729/29850 (epoch 39.747), train_loss = 0.80328540, grad/param norm = 2.1191e-01, time/batch = 16.4432s	
23730/29850 (epoch 39.749), train_loss = 0.67782216, grad/param norm = 2.3739e-01, time/batch = 17.8729s	
23731/29850 (epoch 39.750), train_loss = 0.62894439, grad/param norm = 2.1623e-01, time/batch = 15.7250s	
23732/29850 (epoch 39.752), train_loss = 0.56352779, grad/param norm = 1.9394e-01, time/batch = 15.3262s	
23733/29850 (epoch 39.754), train_loss = 0.61907792, grad/param norm = 1.9964e-01, time/batch = 16.4891s	
23734/29850 (epoch 39.755), train_loss = 0.64329043, grad/param norm = 2.1954e-01, time/batch = 16.8759s	
23735/29850 (epoch 39.757), train_loss = 0.69366756, grad/param norm = 1.9226e-01, time/batch = 16.9446s	
23736/29850 (epoch 39.759), train_loss = 0.70137026, grad/param norm = 2.1716e-01, time/batch = 18.8017s	
23737/29850 (epoch 39.760), train_loss = 0.71941251, grad/param norm = 2.4237e-01, time/batch = 17.5712s	
23738/29850 (epoch 39.762), train_loss = 0.67187675, grad/param norm = 2.7644e-01, time/batch = 15.7021s	
23739/29850 (epoch 39.764), train_loss = 0.58902843, grad/param norm = 2.6095e-01, time/batch = 16.2252s	
23740/29850 (epoch 39.765), train_loss = 0.73599116, grad/param norm = 2.2911e-01, time/batch = 19.1867s	
23741/29850 (epoch 39.767), train_loss = 0.74990814, grad/param norm = 2.2343e-01, time/batch = 16.7081s	
23742/29850 (epoch 39.769), train_loss = 0.77638923, grad/param norm = 2.1538e-01, time/batch = 15.4452s	
23743/29850 (epoch 39.771), train_loss = 0.79879734, grad/param norm = 2.4243e-01, time/batch = 15.4368s	
23744/29850 (epoch 39.772), train_loss = 0.78810490, grad/param norm = 2.5792e-01, time/batch = 16.2880s	
23745/29850 (epoch 39.774), train_loss = 0.73048267, grad/param norm = 2.3191e-01, time/batch = 16.8843s	
23746/29850 (epoch 39.776), train_loss = 0.76682705, grad/param norm = 2.2776e-01, time/batch = 17.1231s	
23747/29850 (epoch 39.777), train_loss = 0.85088632, grad/param norm = 2.4575e-01, time/batch = 16.0280s	
23748/29850 (epoch 39.779), train_loss = 0.69559477, grad/param norm = 2.1355e-01, time/batch = 17.6992s	
23749/29850 (epoch 39.781), train_loss = 0.81458809, grad/param norm = 2.0745e-01, time/batch = 17.2033s	
23750/29850 (epoch 39.782), train_loss = 0.81744801, grad/param norm = 2.1626e-01, time/batch = 18.7155s	
23751/29850 (epoch 39.784), train_loss = 0.62870864, grad/param norm = 2.4466e-01, time/batch = 19.8827s	
23752/29850 (epoch 39.786), train_loss = 0.72429249, grad/param norm = 1.9919e-01, time/batch = 16.6188s	
23753/29850 (epoch 39.787), train_loss = 0.61434191, grad/param norm = 2.2764e-01, time/batch = 19.2087s	
23754/29850 (epoch 39.789), train_loss = 0.62951964, grad/param norm = 1.8006e-01, time/batch = 19.3584s	
23755/29850 (epoch 39.791), train_loss = 0.69347242, grad/param norm = 2.1650e-01, time/batch = 16.9509s	
23756/29850 (epoch 39.792), train_loss = 0.81529594, grad/param norm = 2.5808e-01, time/batch = 19.7227s	
23757/29850 (epoch 39.794), train_loss = 0.78478007, grad/param norm = 2.3479e-01, time/batch = 16.7316s	
23758/29850 (epoch 39.796), train_loss = 0.68535655, grad/param norm = 2.2501e-01, time/batch = 18.5429s	
23759/29850 (epoch 39.797), train_loss = 0.58555946, grad/param norm = 1.9806e-01, time/batch = 16.9806s	
23760/29850 (epoch 39.799), train_loss = 0.63463653, grad/param norm = 1.8415e-01, time/batch = 16.1381s	
23761/29850 (epoch 39.801), train_loss = 0.64133448, grad/param norm = 1.9380e-01, time/batch = 18.4365s	
23762/29850 (epoch 39.802), train_loss = 0.61511534, grad/param norm = 2.1619e-01, time/batch = 17.3559s	
23763/29850 (epoch 39.804), train_loss = 0.66547052, grad/param norm = 1.9105e-01, time/batch = 17.6860s	
23764/29850 (epoch 39.806), train_loss = 0.61504290, grad/param norm = 2.0266e-01, time/batch = 15.2668s	
23765/29850 (epoch 39.807), train_loss = 0.65901015, grad/param norm = 2.0097e-01, time/batch = 16.3611s	
23766/29850 (epoch 39.809), train_loss = 0.65589102, grad/param norm = 2.2989e-01, time/batch = 16.6467s	
23767/29850 (epoch 39.811), train_loss = 0.80509576, grad/param norm = 2.2669e-01, time/batch = 18.7771s	
23768/29850 (epoch 39.812), train_loss = 0.79127901, grad/param norm = 2.3577e-01, time/batch = 19.7848s	
23769/29850 (epoch 39.814), train_loss = 0.82548035, grad/param norm = 2.5192e-01, time/batch = 16.1331s	
23770/29850 (epoch 39.816), train_loss = 0.87804447, grad/param norm = 2.1219e-01, time/batch = 18.3902s	
23771/29850 (epoch 39.817), train_loss = 0.77627912, grad/param norm = 2.7851e-01, time/batch = 19.9669s	
23772/29850 (epoch 39.819), train_loss = 0.63428672, grad/param norm = 2.3771e-01, time/batch = 28.5408s	
23773/29850 (epoch 39.821), train_loss = 0.85345484, grad/param norm = 2.4122e-01, time/batch = 20.9469s	
23774/29850 (epoch 39.822), train_loss = 0.88684515, grad/param norm = 2.1303e-01, time/batch = 15.7201s	
23775/29850 (epoch 39.824), train_loss = 0.77359612, grad/param norm = 2.4215e-01, time/batch = 16.4226s	
23776/29850 (epoch 39.826), train_loss = 0.66232709, grad/param norm = 1.9856e-01, time/batch = 16.4533s	
23777/29850 (epoch 39.827), train_loss = 0.60400645, grad/param norm = 2.1065e-01, time/batch = 16.9445s	
23778/29850 (epoch 39.829), train_loss = 0.81130685, grad/param norm = 2.9252e-01, time/batch = 16.9469s	
23779/29850 (epoch 39.831), train_loss = 0.88435089, grad/param norm = 2.3003e-01, time/batch = 14.8907s	
23780/29850 (epoch 39.832), train_loss = 0.80221770, grad/param norm = 2.2709e-01, time/batch = 16.7062s	
23781/29850 (epoch 39.834), train_loss = 0.59817531, grad/param norm = 2.0817e-01, time/batch = 17.5447s	
23782/29850 (epoch 39.836), train_loss = 0.63656541, grad/param norm = 2.2244e-01, time/batch = 17.3554s	
23783/29850 (epoch 39.838), train_loss = 0.69637154, grad/param norm = 2.1229e-01, time/batch = 16.6885s	
23784/29850 (epoch 39.839), train_loss = 0.60523482, grad/param norm = 2.0649e-01, time/batch = 19.8699s	
23785/29850 (epoch 39.841), train_loss = 0.67824341, grad/param norm = 1.9908e-01, time/batch = 16.2588s	
23786/29850 (epoch 39.843), train_loss = 0.61981867, grad/param norm = 2.2128e-01, time/batch = 18.2236s	
23787/29850 (epoch 39.844), train_loss = 0.67002748, grad/param norm = 2.2914e-01, time/batch = 17.1160s	
23788/29850 (epoch 39.846), train_loss = 0.73603033, grad/param norm = 2.1545e-01, time/batch = 15.4859s	
23789/29850 (epoch 39.848), train_loss = 0.82578360, grad/param norm = 2.4753e-01, time/batch = 15.5787s	
23790/29850 (epoch 39.849), train_loss = 0.73737217, grad/param norm = 2.2417e-01, time/batch = 16.1198s	
23791/29850 (epoch 39.851), train_loss = 0.91949837, grad/param norm = 2.5924e-01, time/batch = 18.0397s	
23792/29850 (epoch 39.853), train_loss = 0.74049769, grad/param norm = 2.3891e-01, time/batch = 16.6222s	
23793/29850 (epoch 39.854), train_loss = 0.90660384, grad/param norm = 2.6830e-01, time/batch = 14.8067s	
23794/29850 (epoch 39.856), train_loss = 0.84559280, grad/param norm = 2.6251e-01, time/batch = 16.1010s	
23795/29850 (epoch 39.858), train_loss = 0.77628496, grad/param norm = 3.0997e-01, time/batch = 15.7427s	
23796/29850 (epoch 39.859), train_loss = 0.70171094, grad/param norm = 2.4404e-01, time/batch = 16.9521s	
23797/29850 (epoch 39.861), train_loss = 0.87708848, grad/param norm = 2.9308e-01, time/batch = 19.4789s	
23798/29850 (epoch 39.863), train_loss = 0.90141866, grad/param norm = 2.4261e-01, time/batch = 15.7602s	
23799/29850 (epoch 39.864), train_loss = 0.87638638, grad/param norm = 2.4222e-01, time/batch = 17.5263s	
23800/29850 (epoch 39.866), train_loss = 0.79850249, grad/param norm = 2.6132e-01, time/batch = 17.4585s	
23801/29850 (epoch 39.868), train_loss = 0.93862055, grad/param norm = 2.8691e-01, time/batch = 18.3900s	
23802/29850 (epoch 39.869), train_loss = 0.88302053, grad/param norm = 2.9955e-01, time/batch = 18.7198s	
23803/29850 (epoch 39.871), train_loss = 0.87496724, grad/param norm = 2.4597e-01, time/batch = 16.5550s	
23804/29850 (epoch 39.873), train_loss = 0.80620265, grad/param norm = 2.2550e-01, time/batch = 19.5471s	
23805/29850 (epoch 39.874), train_loss = 0.83168653, grad/param norm = 2.3663e-01, time/batch = 19.1248s	
23806/29850 (epoch 39.876), train_loss = 0.81269308, grad/param norm = 3.6747e-01, time/batch = 16.7039s	
23807/29850 (epoch 39.878), train_loss = 0.79545004, grad/param norm = 2.1767e-01, time/batch = 16.3016s	
23808/29850 (epoch 39.879), train_loss = 0.83171139, grad/param norm = 2.5035e-01, time/batch = 17.2239s	
23809/29850 (epoch 39.881), train_loss = 0.87314356, grad/param norm = 2.3369e-01, time/batch = 16.1862s	
23810/29850 (epoch 39.883), train_loss = 0.82761838, grad/param norm = 2.3517e-01, time/batch = 15.3320s	
23811/29850 (epoch 39.884), train_loss = 0.70774257, grad/param norm = 2.1427e-01, time/batch = 15.6096s	
23812/29850 (epoch 39.886), train_loss = 0.85445704, grad/param norm = 2.6941e-01, time/batch = 18.0434s	
23813/29850 (epoch 39.888), train_loss = 0.81045699, grad/param norm = 2.3007e-01, time/batch = 17.2892s	
23814/29850 (epoch 39.889), train_loss = 0.73430704, grad/param norm = 2.0713e-01, time/batch = 19.2956s	
23815/29850 (epoch 39.891), train_loss = 0.69768248, grad/param norm = 1.7952e-01, time/batch = 16.1279s	
23816/29850 (epoch 39.893), train_loss = 0.77067445, grad/param norm = 2.5280e-01, time/batch = 17.4589s	
23817/29850 (epoch 39.894), train_loss = 0.76925044, grad/param norm = 2.4438e-01, time/batch = 15.9819s	
23818/29850 (epoch 39.896), train_loss = 0.80570179, grad/param norm = 2.3343e-01, time/batch = 15.3374s	
23819/29850 (epoch 39.898), train_loss = 0.97253919, grad/param norm = 2.8364e-01, time/batch = 14.9476s	
23820/29850 (epoch 39.899), train_loss = 0.70042381, grad/param norm = 2.2067e-01, time/batch = 15.9204s	
23821/29850 (epoch 39.901), train_loss = 0.98737907, grad/param norm = 3.4189e-01, time/batch = 16.0808s	
23822/29850 (epoch 39.903), train_loss = 0.83025584, grad/param norm = 3.1158e-01, time/batch = 18.3035s	
23823/29850 (epoch 39.905), train_loss = 1.04797862, grad/param norm = 2.3414e-01, time/batch = 15.6821s	
23824/29850 (epoch 39.906), train_loss = 0.81798098, grad/param norm = 2.5815e-01, time/batch = 15.8817s	
23825/29850 (epoch 39.908), train_loss = 0.95322725, grad/param norm = 2.4215e-01, time/batch = 15.4084s	
23826/29850 (epoch 39.910), train_loss = 0.86587585, grad/param norm = 2.2610e-01, time/batch = 15.2094s	
23827/29850 (epoch 39.911), train_loss = 1.01256643, grad/param norm = 2.1549e-01, time/batch = 15.7294s	
23828/29850 (epoch 39.913), train_loss = 0.95127712, grad/param norm = 2.5652e-01, time/batch = 15.8895s	
23829/29850 (epoch 39.915), train_loss = 0.93660045, grad/param norm = 2.2110e-01, time/batch = 16.5412s	
23830/29850 (epoch 39.916), train_loss = 0.90381099, grad/param norm = 2.4790e-01, time/batch = 16.0529s	
23831/29850 (epoch 39.918), train_loss = 0.76214337, grad/param norm = 2.0873e-01, time/batch = 16.7047s	
23832/29850 (epoch 39.920), train_loss = 0.92100096, grad/param norm = 2.1983e-01, time/batch = 15.9579s	
23833/29850 (epoch 39.921), train_loss = 0.81715307, grad/param norm = 2.7890e-01, time/batch = 15.6890s	
23834/29850 (epoch 39.923), train_loss = 0.82863206, grad/param norm = 2.3012e-01, time/batch = 15.5486s	
23835/29850 (epoch 39.925), train_loss = 0.97589823, grad/param norm = 3.2976e-01, time/batch = 15.0263s	
23836/29850 (epoch 39.926), train_loss = 0.97492779, grad/param norm = 2.7748e-01, time/batch = 15.4393s	
23837/29850 (epoch 39.928), train_loss = 0.84729900, grad/param norm = 2.4518e-01, time/batch = 14.7176s	
23838/29850 (epoch 39.930), train_loss = 0.82889137, grad/param norm = 2.4849e-01, time/batch = 14.4657s	
23839/29850 (epoch 39.931), train_loss = 0.82638563, grad/param norm = 2.2289e-01, time/batch = 15.1832s	
23840/29850 (epoch 39.933), train_loss = 0.96558791, grad/param norm = 2.5219e-01, time/batch = 16.1313s	
23841/29850 (epoch 39.935), train_loss = 0.90243913, grad/param norm = 2.6373e-01, time/batch = 16.1420s	
23842/29850 (epoch 39.936), train_loss = 0.86141228, grad/param norm = 2.4700e-01, time/batch = 14.9432s	
23843/29850 (epoch 39.938), train_loss = 0.72209376, grad/param norm = 2.0529e-01, time/batch = 15.3255s	
23844/29850 (epoch 39.940), train_loss = 0.75925035, grad/param norm = 2.3037e-01, time/batch = 15.0367s	
23845/29850 (epoch 39.941), train_loss = 0.74673254, grad/param norm = 2.3624e-01, time/batch = 15.4301s	
23846/29850 (epoch 39.943), train_loss = 0.76416577, grad/param norm = 2.3392e-01, time/batch = 16.2905s	
23847/29850 (epoch 39.945), train_loss = 0.71273470, grad/param norm = 2.2076e-01, time/batch = 16.7848s	
23848/29850 (epoch 39.946), train_loss = 0.71084448, grad/param norm = 2.5123e-01, time/batch = 15.2659s	
23849/29850 (epoch 39.948), train_loss = 0.84910034, grad/param norm = 2.2420e-01, time/batch = 15.3979s	
23850/29850 (epoch 39.950), train_loss = 0.76879982, grad/param norm = 1.8166e-01, time/batch = 15.4054s	
23851/29850 (epoch 39.951), train_loss = 0.69167756, grad/param norm = 2.1654e-01, time/batch = 15.6972s	
23852/29850 (epoch 39.953), train_loss = 0.79151202, grad/param norm = 2.6027e-01, time/batch = 15.1843s	
23853/29850 (epoch 39.955), train_loss = 0.69659884, grad/param norm = 1.9654e-01, time/batch = 15.0599s	
23854/29850 (epoch 39.956), train_loss = 0.69437691, grad/param norm = 2.1191e-01, time/batch = 15.7196s	
23855/29850 (epoch 39.958), train_loss = 0.64223308, grad/param norm = 1.8214e-01, time/batch = 17.1243s	
23856/29850 (epoch 39.960), train_loss = 0.90227502, grad/param norm = 2.4811e-01, time/batch = 17.5629s	
23857/29850 (epoch 39.961), train_loss = 0.66077337, grad/param norm = 2.5306e-01, time/batch = 16.7121s	
23858/29850 (epoch 39.963), train_loss = 0.65451027, grad/param norm = 1.9787e-01, time/batch = 16.0365s	
23859/29850 (epoch 39.965), train_loss = 0.71335517, grad/param norm = 2.4365e-01, time/batch = 16.9709s	
23860/29850 (epoch 39.966), train_loss = 0.71677837, grad/param norm = 2.1121e-01, time/batch = 17.2221s	
23861/29850 (epoch 39.968), train_loss = 0.74242408, grad/param norm = 2.7579e-01, time/batch = 16.1510s	
23862/29850 (epoch 39.970), train_loss = 0.73923302, grad/param norm = 2.3374e-01, time/batch = 15.5927s	
23863/29850 (epoch 39.972), train_loss = 0.72399775, grad/param norm = 1.9329e-01, time/batch = 15.4279s	
23864/29850 (epoch 39.973), train_loss = 0.71917886, grad/param norm = 1.8907e-01, time/batch = 15.4079s	
23865/29850 (epoch 39.975), train_loss = 0.61345395, grad/param norm = 2.0829e-01, time/batch = 17.4531s	
23866/29850 (epoch 39.977), train_loss = 0.73432083, grad/param norm = 2.0418e-01, time/batch = 16.2804s	
23867/29850 (epoch 39.978), train_loss = 0.64852663, grad/param norm = 2.0557e-01, time/batch = 18.5436s	
23868/29850 (epoch 39.980), train_loss = 0.70999749, grad/param norm = 1.8446e-01, time/batch = 18.2027s	
23869/29850 (epoch 39.982), train_loss = 0.68906107, grad/param norm = 2.0689e-01, time/batch = 16.1245s	
23870/29850 (epoch 39.983), train_loss = 0.71641361, grad/param norm = 1.7549e-01, time/batch = 15.3826s	
23871/29850 (epoch 39.985), train_loss = 0.83968553, grad/param norm = 2.4621e-01, time/batch = 15.4978s	
23872/29850 (epoch 39.987), train_loss = 0.80631452, grad/param norm = 2.0890e-01, time/batch = 17.8812s	
23873/29850 (epoch 39.988), train_loss = 0.73723320, grad/param norm = 1.9322e-01, time/batch = 16.5371s	
23874/29850 (epoch 39.990), train_loss = 0.80513783, grad/param norm = 1.9348e-01, time/batch = 17.9677s	
23875/29850 (epoch 39.992), train_loss = 0.81367541, grad/param norm = 2.1853e-01, time/batch = 15.1762s	
23876/29850 (epoch 39.993), train_loss = 0.79360825, grad/param norm = 2.2222e-01, time/batch = 15.5960s	
23877/29850 (epoch 39.995), train_loss = 0.75805011, grad/param norm = 1.9279e-01, time/batch = 16.2434s	
23878/29850 (epoch 39.997), train_loss = 0.81496248, grad/param norm = 2.1859e-01, time/batch = 14.9815s	
23879/29850 (epoch 39.998), train_loss = 0.83197171, grad/param norm = 2.2365e-01, time/batch = 14.9494s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
23880/29850 (epoch 40.000), train_loss = 0.66416045, grad/param norm = 1.8618e-01, time/batch = 14.7928s	
23881/29850 (epoch 40.002), train_loss = 0.91666482, grad/param norm = 2.3293e-01, time/batch = 14.8191s	
23882/29850 (epoch 40.003), train_loss = 0.66580584, grad/param norm = 2.2644e-01, time/batch = 14.4093s	
23883/29850 (epoch 40.005), train_loss = 0.84178014, grad/param norm = 2.1426e-01, time/batch = 14.3344s	
23884/29850 (epoch 40.007), train_loss = 0.87846121, grad/param norm = 2.2967e-01, time/batch = 14.6502s	
23885/29850 (epoch 40.008), train_loss = 1.01377147, grad/param norm = 2.8524e-01, time/batch = 14.6528s	
23886/29850 (epoch 40.010), train_loss = 0.71823511, grad/param norm = 2.1085e-01, time/batch = 14.7227s	
23887/29850 (epoch 40.012), train_loss = 0.76243399, grad/param norm = 2.1332e-01, time/batch = 15.1569s	
23888/29850 (epoch 40.013), train_loss = 0.82072784, grad/param norm = 2.5993e-01, time/batch = 14.7816s	
23889/29850 (epoch 40.015), train_loss = 0.89865191, grad/param norm = 2.3534e-01, time/batch = 14.7894s	
23890/29850 (epoch 40.017), train_loss = 0.81587868, grad/param norm = 2.2199e-01, time/batch = 15.2676s	
23891/29850 (epoch 40.018), train_loss = 0.91677662, grad/param norm = 2.4963e-01, time/batch = 15.0335s	
23892/29850 (epoch 40.020), train_loss = 0.82619942, grad/param norm = 2.2635e-01, time/batch = 15.4177s	
23893/29850 (epoch 40.022), train_loss = 0.88790187, grad/param norm = 2.4849e-01, time/batch = 15.5329s	
23894/29850 (epoch 40.023), train_loss = 0.86245902, grad/param norm = 1.9294e-01, time/batch = 15.5874s	
23895/29850 (epoch 40.025), train_loss = 0.79755212, grad/param norm = 2.2021e-01, time/batch = 15.1391s	
23896/29850 (epoch 40.027), train_loss = 0.59568432, grad/param norm = 1.8848e-01, time/batch = 14.4837s	
23897/29850 (epoch 40.028), train_loss = 0.73856935, grad/param norm = 2.1016e-01, time/batch = 14.4025s	
23898/29850 (epoch 40.030), train_loss = 0.76391773, grad/param norm = 2.6359e-01, time/batch = 14.9663s	
23899/29850 (epoch 40.032), train_loss = 0.84153678, grad/param norm = 2.2907e-01, time/batch = 15.4010s	
23900/29850 (epoch 40.034), train_loss = 0.72973068, grad/param norm = 2.1820e-01, time/batch = 15.1301s	
23901/29850 (epoch 40.035), train_loss = 0.62644279, grad/param norm = 1.9393e-01, time/batch = 15.1941s	
23902/29850 (epoch 40.037), train_loss = 0.81319848, grad/param norm = 2.4408e-01, time/batch = 14.7394s	
23903/29850 (epoch 40.039), train_loss = 0.70659467, grad/param norm = 1.7583e-01, time/batch = 14.5085s	
23904/29850 (epoch 40.040), train_loss = 0.66277172, grad/param norm = 1.9907e-01, time/batch = 14.4808s	
23905/29850 (epoch 40.042), train_loss = 0.73580525, grad/param norm = 2.2945e-01, time/batch = 14.8067s	
23906/29850 (epoch 40.044), train_loss = 0.76892897, grad/param norm = 2.0374e-01, time/batch = 14.5771s	
23907/29850 (epoch 40.045), train_loss = 0.85536894, grad/param norm = 2.2411e-01, time/batch = 14.2563s	
23908/29850 (epoch 40.047), train_loss = 0.69396064, grad/param norm = 2.1598e-01, time/batch = 14.8808s	
23909/29850 (epoch 40.049), train_loss = 0.82443948, grad/param norm = 2.1480e-01, time/batch = 14.8104s	
23910/29850 (epoch 40.050), train_loss = 0.74927658, grad/param norm = 2.2426e-01, time/batch = 14.6727s	
23911/29850 (epoch 40.052), train_loss = 0.92575828, grad/param norm = 2.5612e-01, time/batch = 14.8167s	
23912/29850 (epoch 40.054), train_loss = 0.78960943, grad/param norm = 2.2836e-01, time/batch = 15.1079s	
23913/29850 (epoch 40.055), train_loss = 0.76104349, grad/param norm = 2.2981e-01, time/batch = 14.2444s	
23914/29850 (epoch 40.057), train_loss = 0.84903053, grad/param norm = 2.0611e-01, time/batch = 14.8219s	
23915/29850 (epoch 40.059), train_loss = 0.84440666, grad/param norm = 2.2209e-01, time/batch = 14.7282s	
23916/29850 (epoch 40.060), train_loss = 0.80593118, grad/param norm = 2.3649e-01, time/batch = 14.8068s	
23917/29850 (epoch 40.062), train_loss = 0.88464443, grad/param norm = 2.7308e-01, time/batch = 14.6576s	
23918/29850 (epoch 40.064), train_loss = 0.87638547, grad/param norm = 2.8049e-01, time/batch = 14.2665s	
23919/29850 (epoch 40.065), train_loss = 0.69236931, grad/param norm = 2.0474e-01, time/batch = 14.8060s	
23920/29850 (epoch 40.067), train_loss = 0.83619172, grad/param norm = 1.8657e-01, time/batch = 14.7192s	
23921/29850 (epoch 40.069), train_loss = 0.83041326, grad/param norm = 1.9626e-01, time/batch = 15.0458s	
23922/29850 (epoch 40.070), train_loss = 0.84666450, grad/param norm = 2.0050e-01, time/batch = 14.5010s	
23923/29850 (epoch 40.072), train_loss = 0.80650911, grad/param norm = 2.4628e-01, time/batch = 14.8135s	
23924/29850 (epoch 40.074), train_loss = 0.89010266, grad/param norm = 2.0873e-01, time/batch = 14.5664s	
23925/29850 (epoch 40.075), train_loss = 0.75194864, grad/param norm = 2.5157e-01, time/batch = 14.7350s	
23926/29850 (epoch 40.077), train_loss = 0.87529368, grad/param norm = 2.3986e-01, time/batch = 14.4948s	
23927/29850 (epoch 40.079), train_loss = 1.01083764, grad/param norm = 2.6783e-01, time/batch = 14.3348s	
23928/29850 (epoch 40.080), train_loss = 0.97449803, grad/param norm = 2.6454e-01, time/batch = 14.4149s	
23929/29850 (epoch 40.082), train_loss = 0.87506987, grad/param norm = 2.4135e-01, time/batch = 14.9604s	
23930/29850 (epoch 40.084), train_loss = 0.96852826, grad/param norm = 2.5006e-01, time/batch = 14.8060s	
23931/29850 (epoch 40.085), train_loss = 1.00586738, grad/param norm = 2.6742e-01, time/batch = 15.0357s	
23932/29850 (epoch 40.087), train_loss = 0.93298363, grad/param norm = 2.4556e-01, time/batch = 14.6456s	
23933/29850 (epoch 40.089), train_loss = 0.84515709, grad/param norm = 2.1200e-01, time/batch = 14.6878s	
23934/29850 (epoch 40.090), train_loss = 0.85221083, grad/param norm = 2.0675e-01, time/batch = 14.3237s	
23935/29850 (epoch 40.092), train_loss = 0.74277147, grad/param norm = 2.2938e-01, time/batch = 14.0893s	
23936/29850 (epoch 40.094), train_loss = 0.95443394, grad/param norm = 2.6187e-01, time/batch = 14.0959s	
23937/29850 (epoch 40.095), train_loss = 0.90686466, grad/param norm = 3.5065e-01, time/batch = 14.4726s	
23938/29850 (epoch 40.097), train_loss = 0.62477178, grad/param norm = 1.6551e-01, time/batch = 14.3995s	
23939/29850 (epoch 40.099), train_loss = 0.66542771, grad/param norm = 2.0595e-01, time/batch = 14.0136s	
23940/29850 (epoch 40.101), train_loss = 0.87230606, grad/param norm = 2.1466e-01, time/batch = 14.0036s	
23941/29850 (epoch 40.102), train_loss = 0.86719007, grad/param norm = 2.4573e-01, time/batch = 15.1840s	
23942/29850 (epoch 40.104), train_loss = 0.78994415, grad/param norm = 2.7236e-01, time/batch = 13.9305s	
23943/29850 (epoch 40.106), train_loss = 0.90655192, grad/param norm = 2.2449e-01, time/batch = 14.3230s	
23944/29850 (epoch 40.107), train_loss = 0.75371806, grad/param norm = 1.8872e-01, time/batch = 14.0073s	
23945/29850 (epoch 40.109), train_loss = 0.80693550, grad/param norm = 2.2536e-01, time/batch = 14.6371s	
23946/29850 (epoch 40.111), train_loss = 0.85048501, grad/param norm = 2.1072e-01, time/batch = 14.7460s	
23947/29850 (epoch 40.112), train_loss = 0.72254511, grad/param norm = 2.2538e-01, time/batch = 14.4280s	
23948/29850 (epoch 40.114), train_loss = 0.77407696, grad/param norm = 2.3431e-01, time/batch = 14.3426s	
23949/29850 (epoch 40.116), train_loss = 0.73539527, grad/param norm = 2.1256e-01, time/batch = 14.7329s	
23950/29850 (epoch 40.117), train_loss = 0.80796929, grad/param norm = 2.4959e-01, time/batch = 14.6538s	
23951/29850 (epoch 40.119), train_loss = 0.77265340, grad/param norm = 2.4169e-01, time/batch = 15.1160s	
23952/29850 (epoch 40.121), train_loss = 0.65853572, grad/param norm = 2.1737e-01, time/batch = 14.6482s	
23953/29850 (epoch 40.122), train_loss = 0.69833234, grad/param norm = 1.8439e-01, time/batch = 14.3263s	
23954/29850 (epoch 40.124), train_loss = 0.72500060, grad/param norm = 2.0703e-01, time/batch = 14.3287s	
23955/29850 (epoch 40.126), train_loss = 0.78157463, grad/param norm = 2.1526e-01, time/batch = 14.9595s	
23956/29850 (epoch 40.127), train_loss = 0.84233114, grad/param norm = 2.4043e-01, time/batch = 14.4114s	
23957/29850 (epoch 40.129), train_loss = 0.81019086, grad/param norm = 2.3424e-01, time/batch = 14.7164s	
23958/29850 (epoch 40.131), train_loss = 0.80560308, grad/param norm = 2.0664e-01, time/batch = 14.5833s	
23959/29850 (epoch 40.132), train_loss = 0.67592885, grad/param norm = 2.0494e-01, time/batch = 14.5718s	
23960/29850 (epoch 40.134), train_loss = 0.76081858, grad/param norm = 2.1960e-01, time/batch = 14.5737s	
23961/29850 (epoch 40.136), train_loss = 0.87101863, grad/param norm = 2.2902e-01, time/batch = 14.9597s	
23962/29850 (epoch 40.137), train_loss = 0.66438086, grad/param norm = 2.1111e-01, time/batch = 14.8671s	
23963/29850 (epoch 40.139), train_loss = 0.78842987, grad/param norm = 2.0224e-01, time/batch = 14.6548s	
23964/29850 (epoch 40.141), train_loss = 0.71978560, grad/param norm = 2.2098e-01, time/batch = 14.5012s	
23965/29850 (epoch 40.142), train_loss = 0.90862695, grad/param norm = 2.2924e-01, time/batch = 14.5622s	
23966/29850 (epoch 40.144), train_loss = 1.01791772, grad/param norm = 2.6069e-01, time/batch = 14.6463s	
23967/29850 (epoch 40.146), train_loss = 1.00868482, grad/param norm = 2.5437e-01, time/batch = 14.2550s	
23968/29850 (epoch 40.147), train_loss = 0.91646533, grad/param norm = 2.5761e-01, time/batch = 14.1706s	
23969/29850 (epoch 40.149), train_loss = 0.86100103, grad/param norm = 2.3232e-01, time/batch = 14.4928s	
23970/29850 (epoch 40.151), train_loss = 0.87362687, grad/param norm = 2.6366e-01, time/batch = 14.8041s	
23971/29850 (epoch 40.152), train_loss = 0.79680281, grad/param norm = 2.0461e-01, time/batch = 14.4896s	
23972/29850 (epoch 40.154), train_loss = 0.76558620, grad/param norm = 2.5659e-01, time/batch = 15.0394s	
23973/29850 (epoch 40.156), train_loss = 0.76811132, grad/param norm = 2.7312e-01, time/batch = 14.6379s	
23974/29850 (epoch 40.157), train_loss = 0.86173534, grad/param norm = 2.1205e-01, time/batch = 15.7152s	
23975/29850 (epoch 40.159), train_loss = 0.78479910, grad/param norm = 2.4801e-01, time/batch = 16.3129s	
23976/29850 (epoch 40.161), train_loss = 0.79267075, grad/param norm = 2.1271e-01, time/batch = 17.4329s	
23977/29850 (epoch 40.162), train_loss = 0.93662078, grad/param norm = 2.5515e-01, time/batch = 17.7769s	
23978/29850 (epoch 40.164), train_loss = 0.88060882, grad/param norm = 2.3378e-01, time/batch = 17.7795s	
23979/29850 (epoch 40.166), train_loss = 0.77031900, grad/param norm = 2.1658e-01, time/batch = 17.8040s	
23980/29850 (epoch 40.168), train_loss = 0.69945693, grad/param norm = 1.8625e-01, time/batch = 18.3751s	
23981/29850 (epoch 40.169), train_loss = 0.92492836, grad/param norm = 2.8241e-01, time/batch = 15.9594s	
23982/29850 (epoch 40.171), train_loss = 0.86950009, grad/param norm = 2.3242e-01, time/batch = 17.9644s	
23983/29850 (epoch 40.173), train_loss = 0.71947291, grad/param norm = 2.2091e-01, time/batch = 15.6828s	
23984/29850 (epoch 40.174), train_loss = 0.81915915, grad/param norm = 2.8120e-01, time/batch = 16.8559s	
23985/29850 (epoch 40.176), train_loss = 0.82374011, grad/param norm = 2.1970e-01, time/batch = 18.2793s	
23986/29850 (epoch 40.178), train_loss = 0.85879980, grad/param norm = 2.2314e-01, time/batch = 17.8119s	
23987/29850 (epoch 40.179), train_loss = 0.65617138, grad/param norm = 1.9891e-01, time/batch = 18.3577s	
23988/29850 (epoch 40.181), train_loss = 0.83816070, grad/param norm = 2.6657e-01, time/batch = 16.8338s	
23989/29850 (epoch 40.183), train_loss = 0.82433247, grad/param norm = 2.0930e-01, time/batch = 17.6190s	
23990/29850 (epoch 40.184), train_loss = 0.88901603, grad/param norm = 2.4713e-01, time/batch = 16.1130s	
23991/29850 (epoch 40.186), train_loss = 0.86386377, grad/param norm = 2.3842e-01, time/batch = 16.1344s	
23992/29850 (epoch 40.188), train_loss = 0.95064793, grad/param norm = 2.3588e-01, time/batch = 18.6390s	
23993/29850 (epoch 40.189), train_loss = 0.89349163, grad/param norm = 2.6352e-01, time/batch = 17.0335s	
23994/29850 (epoch 40.191), train_loss = 0.93371667, grad/param norm = 2.5244e-01, time/batch = 16.9582s	
23995/29850 (epoch 40.193), train_loss = 0.81779777, grad/param norm = 2.2565e-01, time/batch = 17.8797s	
23996/29850 (epoch 40.194), train_loss = 0.91341770, grad/param norm = 2.3449e-01, time/batch = 15.7897s	
23997/29850 (epoch 40.196), train_loss = 0.79284397, grad/param norm = 2.1657e-01, time/batch = 16.7090s	
23998/29850 (epoch 40.198), train_loss = 0.75425184, grad/param norm = 2.0924e-01, time/batch = 26.0240s	
23999/29850 (epoch 40.199), train_loss = 1.01488708, grad/param norm = 2.5251e-01, time/batch = 20.1423s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch40.20_1.8806.t7	
24000/29850 (epoch 40.201), train_loss = 0.74368902, grad/param norm = 1.9175e-01, time/batch = 16.2246s	
24001/29850 (epoch 40.203), train_loss = 1.21135165, grad/param norm = 3.1537e-01, time/batch = 16.8095s	
24002/29850 (epoch 40.204), train_loss = 0.79699971, grad/param norm = 2.3331e-01, time/batch = 17.5210s	
24003/29850 (epoch 40.206), train_loss = 0.72026173, grad/param norm = 2.6046e-01, time/batch = 18.2189s	
24004/29850 (epoch 40.208), train_loss = 0.94287624, grad/param norm = 2.6735e-01, time/batch = 16.2711s	
24005/29850 (epoch 40.209), train_loss = 0.71812088, grad/param norm = 2.2827e-01, time/batch = 18.2061s	
24006/29850 (epoch 40.211), train_loss = 0.76638852, grad/param norm = 2.2874e-01, time/batch = 19.0382s	
24007/29850 (epoch 40.213), train_loss = 0.84778114, grad/param norm = 2.2948e-01, time/batch = 16.2875s	
24008/29850 (epoch 40.214), train_loss = 0.69102979, grad/param norm = 1.8765e-01, time/batch = 17.4558s	
24009/29850 (epoch 40.216), train_loss = 0.71936768, grad/param norm = 2.2599e-01, time/batch = 19.0344s	
24010/29850 (epoch 40.218), train_loss = 0.83869229, grad/param norm = 2.2828e-01, time/batch = 17.5994s	
24011/29850 (epoch 40.219), train_loss = 0.84265544, grad/param norm = 3.0341e-01, time/batch = 16.7380s	
24012/29850 (epoch 40.221), train_loss = 0.80742944, grad/param norm = 2.3173e-01, time/batch = 16.6354s	
24013/29850 (epoch 40.223), train_loss = 0.67159735, grad/param norm = 2.0416e-01, time/batch = 17.7063s	
24014/29850 (epoch 40.224), train_loss = 0.68350575, grad/param norm = 2.3426e-01, time/batch = 17.2797s	
24015/29850 (epoch 40.226), train_loss = 0.72855983, grad/param norm = 1.9951e-01, time/batch = 16.8022s	
24016/29850 (epoch 40.228), train_loss = 0.76135512, grad/param norm = 1.9733e-01, time/batch = 15.5428s	
24017/29850 (epoch 40.229), train_loss = 0.65827198, grad/param norm = 1.8416e-01, time/batch = 18.6225s	
24018/29850 (epoch 40.231), train_loss = 0.80743139, grad/param norm = 2.0226e-01, time/batch = 17.2178s	
24019/29850 (epoch 40.233), train_loss = 0.77964319, grad/param norm = 2.3116e-01, time/batch = 17.3806s	
24020/29850 (epoch 40.235), train_loss = 0.73079529, grad/param norm = 2.0110e-01, time/batch = 16.6481s	
24021/29850 (epoch 40.236), train_loss = 0.95177647, grad/param norm = 2.5627e-01, time/batch = 18.4410s	
24022/29850 (epoch 40.238), train_loss = 0.68990660, grad/param norm = 2.2424e-01, time/batch = 16.8067s	
24023/29850 (epoch 40.240), train_loss = 0.68826584, grad/param norm = 1.9849e-01, time/batch = 18.5370s	
24024/29850 (epoch 40.241), train_loss = 0.81523851, grad/param norm = 2.4643e-01, time/batch = 16.4549s	
24025/29850 (epoch 40.243), train_loss = 0.85010905, grad/param norm = 2.3261e-01, time/batch = 19.2098s	
24026/29850 (epoch 40.245), train_loss = 0.71248784, grad/param norm = 2.1418e-01, time/batch = 17.3961s	
24027/29850 (epoch 40.246), train_loss = 0.71882569, grad/param norm = 2.0236e-01, time/batch = 17.5273s	
24028/29850 (epoch 40.248), train_loss = 0.68758697, grad/param norm = 1.9957e-01, time/batch = 18.4462s	
24029/29850 (epoch 40.250), train_loss = 0.73748043, grad/param norm = 1.8556e-01, time/batch = 17.3019s	
24030/29850 (epoch 40.251), train_loss = 0.65920873, grad/param norm = 2.1214e-01, time/batch = 17.2959s	
24031/29850 (epoch 40.253), train_loss = 0.63941000, grad/param norm = 2.2169e-01, time/batch = 16.5170s	
24032/29850 (epoch 40.255), train_loss = 0.70044515, grad/param norm = 2.2511e-01, time/batch = 19.6456s	
24033/29850 (epoch 40.256), train_loss = 0.84211340, grad/param norm = 2.2020e-01, time/batch = 17.0279s	
24034/29850 (epoch 40.258), train_loss = 0.84666930, grad/param norm = 2.3649e-01, time/batch = 17.2705s	
24035/29850 (epoch 40.260), train_loss = 0.77131940, grad/param norm = 1.8937e-01, time/batch = 17.0759s	
24036/29850 (epoch 40.261), train_loss = 0.71190785, grad/param norm = 2.1340e-01, time/batch = 18.2901s	
24037/29850 (epoch 40.263), train_loss = 0.71218226, grad/param norm = 2.3225e-01, time/batch = 18.5381s	
24038/29850 (epoch 40.265), train_loss = 0.78336086, grad/param norm = 2.3905e-01, time/batch = 16.6426s	
24039/29850 (epoch 40.266), train_loss = 0.80066348, grad/param norm = 2.1870e-01, time/batch = 16.8544s	
24040/29850 (epoch 40.268), train_loss = 0.76836908, grad/param norm = 2.0982e-01, time/batch = 18.6704s	
24041/29850 (epoch 40.270), train_loss = 0.72237543, grad/param norm = 2.0867e-01, time/batch = 16.6232s	
24042/29850 (epoch 40.271), train_loss = 0.81514553, grad/param norm = 2.2182e-01, time/batch = 16.6810s	
24043/29850 (epoch 40.273), train_loss = 0.66809302, grad/param norm = 1.9807e-01, time/batch = 16.8827s	
24044/29850 (epoch 40.275), train_loss = 0.67676780, grad/param norm = 2.0938e-01, time/batch = 17.8598s	
24045/29850 (epoch 40.276), train_loss = 0.67444254, grad/param norm = 1.9945e-01, time/batch = 16.4016s	
24046/29850 (epoch 40.278), train_loss = 0.75330552, grad/param norm = 2.5219e-01, time/batch = 19.2684s	
24047/29850 (epoch 40.280), train_loss = 0.93252143, grad/param norm = 2.5723e-01, time/batch = 17.6167s	
24048/29850 (epoch 40.281), train_loss = 0.81974392, grad/param norm = 2.4983e-01, time/batch = 16.3598s	
24049/29850 (epoch 40.283), train_loss = 0.88807195, grad/param norm = 2.8513e-01, time/batch = 19.0525s	
24050/29850 (epoch 40.285), train_loss = 0.87135844, grad/param norm = 2.1068e-01, time/batch = 15.5393s	
24051/29850 (epoch 40.286), train_loss = 0.87981638, grad/param norm = 2.1623e-01, time/batch = 17.6699s	
24052/29850 (epoch 40.288), train_loss = 0.83262441, grad/param norm = 2.9445e-01, time/batch = 17.3759s	
24053/29850 (epoch 40.290), train_loss = 0.80738839, grad/param norm = 2.1550e-01, time/batch = 18.7179s	
24054/29850 (epoch 40.291), train_loss = 1.02459437, grad/param norm = 2.7516e-01, time/batch = 18.2209s	
24055/29850 (epoch 40.293), train_loss = 0.96734838, grad/param norm = 2.7207e-01, time/batch = 15.3369s	
24056/29850 (epoch 40.295), train_loss = 0.97257623, grad/param norm = 2.1434e-01, time/batch = 18.9463s	
24057/29850 (epoch 40.296), train_loss = 0.74008561, grad/param norm = 1.8943e-01, time/batch = 19.2942s	
24058/29850 (epoch 40.298), train_loss = 0.62009358, grad/param norm = 1.9005e-01, time/batch = 16.1203s	
24059/29850 (epoch 40.300), train_loss = 0.68715186, grad/param norm = 2.0012e-01, time/batch = 17.3732s	
24060/29850 (epoch 40.302), train_loss = 0.69310483, grad/param norm = 2.1163e-01, time/batch = 17.6327s	
24061/29850 (epoch 40.303), train_loss = 0.74022106, grad/param norm = 2.2009e-01, time/batch = 16.8441s	
24062/29850 (epoch 40.305), train_loss = 0.87582122, grad/param norm = 2.2938e-01, time/batch = 17.8355s	
24063/29850 (epoch 40.307), train_loss = 0.88499156, grad/param norm = 2.2597e-01, time/batch = 18.2840s	
24064/29850 (epoch 40.308), train_loss = 0.69009765, grad/param norm = 2.7511e-01, time/batch = 18.7100s	
24065/29850 (epoch 40.310), train_loss = 0.86023798, grad/param norm = 2.4488e-01, time/batch = 17.0316s	
24066/29850 (epoch 40.312), train_loss = 0.88683913, grad/param norm = 2.0417e-01, time/batch = 18.4712s	
24067/29850 (epoch 40.313), train_loss = 0.83010555, grad/param norm = 2.6535e-01, time/batch = 17.1794s	
24068/29850 (epoch 40.315), train_loss = 0.84340058, grad/param norm = 2.3076e-01, time/batch = 16.9526s	
24069/29850 (epoch 40.317), train_loss = 0.83142276, grad/param norm = 3.0917e-01, time/batch = 19.5360s	
24070/29850 (epoch 40.318), train_loss = 0.79499185, grad/param norm = 2.3224e-01, time/batch = 17.5573s	
24071/29850 (epoch 40.320), train_loss = 0.74417230, grad/param norm = 2.0774e-01, time/batch = 17.4400s	
24072/29850 (epoch 40.322), train_loss = 0.91338079, grad/param norm = 2.6775e-01, time/batch = 16.2193s	
24073/29850 (epoch 40.323), train_loss = 0.84237078, grad/param norm = 2.3191e-01, time/batch = 15.6197s	
24074/29850 (epoch 40.325), train_loss = 0.89506779, grad/param norm = 2.3690e-01, time/batch = 19.5475s	
24075/29850 (epoch 40.327), train_loss = 1.01288295, grad/param norm = 2.5397e-01, time/batch = 16.6143s	
24076/29850 (epoch 40.328), train_loss = 0.93480087, grad/param norm = 3.1315e-01, time/batch = 18.6904s	
24077/29850 (epoch 40.330), train_loss = 0.87171527, grad/param norm = 2.0077e-01, time/batch = 17.3066s	
24078/29850 (epoch 40.332), train_loss = 0.77060616, grad/param norm = 2.2522e-01, time/batch = 18.1091s	
24079/29850 (epoch 40.333), train_loss = 0.85367523, grad/param norm = 2.4364e-01, time/batch = 17.4545s	
24080/29850 (epoch 40.335), train_loss = 0.89907585, grad/param norm = 2.2598e-01, time/batch = 16.3036s	
24081/29850 (epoch 40.337), train_loss = 0.81858081, grad/param norm = 2.4658e-01, time/batch = 19.6141s	
24082/29850 (epoch 40.338), train_loss = 0.85147006, grad/param norm = 2.0867e-01, time/batch = 16.7884s	
24083/29850 (epoch 40.340), train_loss = 0.68637208, grad/param norm = 1.9474e-01, time/batch = 18.5447s	
24084/29850 (epoch 40.342), train_loss = 0.82138255, grad/param norm = 2.8306e-01, time/batch = 16.0301s	
24085/29850 (epoch 40.343), train_loss = 0.82330120, grad/param norm = 2.7388e-01, time/batch = 17.6235s	
24086/29850 (epoch 40.345), train_loss = 0.88504410, grad/param norm = 2.4517e-01, time/batch = 16.7153s	
24087/29850 (epoch 40.347), train_loss = 0.92285021, grad/param norm = 3.0120e-01, time/batch = 15.2621s	
24088/29850 (epoch 40.348), train_loss = 0.78077960, grad/param norm = 2.2262e-01, time/batch = 18.0351s	
24089/29850 (epoch 40.350), train_loss = 0.86709478, grad/param norm = 2.5974e-01, time/batch = 17.4374s	
24090/29850 (epoch 40.352), train_loss = 0.78275863, grad/param norm = 2.2754e-01, time/batch = 17.0394s	
24091/29850 (epoch 40.353), train_loss = 0.84821380, grad/param norm = 2.1822e-01, time/batch = 16.3967s	
24092/29850 (epoch 40.355), train_loss = 0.77015843, grad/param norm = 2.2031e-01, time/batch = 17.8544s	
24093/29850 (epoch 40.357), train_loss = 0.90653814, grad/param norm = 2.0972e-01, time/batch = 17.8743s	
24094/29850 (epoch 40.358), train_loss = 0.73418392, grad/param norm = 2.1524e-01, time/batch = 16.8753s	
24095/29850 (epoch 40.360), train_loss = 0.80632201, grad/param norm = 2.1146e-01, time/batch = 18.6159s	
24096/29850 (epoch 40.362), train_loss = 0.81088461, grad/param norm = 2.4115e-01, time/batch = 16.6864s	
24097/29850 (epoch 40.363), train_loss = 0.83727205, grad/param norm = 2.2265e-01, time/batch = 15.8461s	
24098/29850 (epoch 40.365), train_loss = 0.92399464, grad/param norm = 2.4085e-01, time/batch = 18.8779s	
24099/29850 (epoch 40.367), train_loss = 0.74149753, grad/param norm = 2.0532e-01, time/batch = 17.4389s	
24100/29850 (epoch 40.369), train_loss = 0.67510213, grad/param norm = 2.3972e-01, time/batch = 17.7141s	
24101/29850 (epoch 40.370), train_loss = 0.67475937, grad/param norm = 2.0053e-01, time/batch = 16.1327s	
24102/29850 (epoch 40.372), train_loss = 0.92477827, grad/param norm = 2.5289e-01, time/batch = 17.7650s	
24103/29850 (epoch 40.374), train_loss = 0.87778247, grad/param norm = 2.3368e-01, time/batch = 18.2919s	
24104/29850 (epoch 40.375), train_loss = 0.82101551, grad/param norm = 2.1939e-01, time/batch = 19.0390s	
24105/29850 (epoch 40.377), train_loss = 0.71816369, grad/param norm = 2.1053e-01, time/batch = 18.3658s	
24106/29850 (epoch 40.379), train_loss = 0.91444083, grad/param norm = 2.6791e-01, time/batch = 15.6619s	
24107/29850 (epoch 40.380), train_loss = 0.86380646, grad/param norm = 2.4918e-01, time/batch = 18.3855s	
24108/29850 (epoch 40.382), train_loss = 0.82823290, grad/param norm = 2.8762e-01, time/batch = 18.7975s	
24109/29850 (epoch 40.384), train_loss = 0.87910995, grad/param norm = 2.4162e-01, time/batch = 16.5351s	
24110/29850 (epoch 40.385), train_loss = 0.87281184, grad/param norm = 2.3869e-01, time/batch = 17.8945s	
24111/29850 (epoch 40.387), train_loss = 0.86168939, grad/param norm = 2.7955e-01, time/batch = 17.7967s	
24112/29850 (epoch 40.389), train_loss = 0.93841082, grad/param norm = 2.3116e-01, time/batch = 17.3842s	
24113/29850 (epoch 40.390), train_loss = 0.89760703, grad/param norm = 2.2206e-01, time/batch = 16.2006s	
24114/29850 (epoch 40.392), train_loss = 0.82489164, grad/param norm = 2.6396e-01, time/batch = 16.9540s	
24115/29850 (epoch 40.394), train_loss = 0.89515178, grad/param norm = 2.2948e-01, time/batch = 19.6195s	
24116/29850 (epoch 40.395), train_loss = 0.78623629, grad/param norm = 2.5178e-01, time/batch = 16.8863s	
24117/29850 (epoch 40.397), train_loss = 0.70777489, grad/param norm = 2.2720e-01, time/batch = 16.1176s	
24118/29850 (epoch 40.399), train_loss = 0.75625270, grad/param norm = 2.4845e-01, time/batch = 15.5279s	
24119/29850 (epoch 40.400), train_loss = 1.09855226, grad/param norm = 3.1187e-01, time/batch = 19.1102s	
24120/29850 (epoch 40.402), train_loss = 0.95427207, grad/param norm = 2.3058e-01, time/batch = 17.7022s	
24121/29850 (epoch 40.404), train_loss = 0.84474060, grad/param norm = 2.3953e-01, time/batch = 15.7224s	
24122/29850 (epoch 40.405), train_loss = 0.76827458, grad/param norm = 2.4198e-01, time/batch = 16.5218s	
24123/29850 (epoch 40.407), train_loss = 0.73415745, grad/param norm = 1.8416e-01, time/batch = 16.4589s	
24124/29850 (epoch 40.409), train_loss = 0.84428456, grad/param norm = 2.5018e-01, time/batch = 14.6622s	
24125/29850 (epoch 40.410), train_loss = 0.93428384, grad/param norm = 3.2402e-01, time/batch = 18.2231s	
24126/29850 (epoch 40.412), train_loss = 0.93499324, grad/param norm = 2.3723e-01, time/batch = 18.8904s	
24127/29850 (epoch 40.414), train_loss = 0.85680652, grad/param norm = 2.6032e-01, time/batch = 18.0087s	
24128/29850 (epoch 40.415), train_loss = 0.81270509, grad/param norm = 1.9638e-01, time/batch = 17.9706s	
24129/29850 (epoch 40.417), train_loss = 0.94237506, grad/param norm = 2.5364e-01, time/batch = 17.7001s	
24130/29850 (epoch 40.419), train_loss = 0.79902155, grad/param norm = 2.0804e-01, time/batch = 16.3838s	
24131/29850 (epoch 40.420), train_loss = 0.82560514, grad/param norm = 2.4610e-01, time/batch = 17.5333s	
24132/29850 (epoch 40.422), train_loss = 0.81714545, grad/param norm = 2.2843e-01, time/batch = 16.8828s	
24133/29850 (epoch 40.424), train_loss = 0.75369882, grad/param norm = 2.4116e-01, time/batch = 15.5522s	
24134/29850 (epoch 40.425), train_loss = 0.89121012, grad/param norm = 2.9811e-01, time/batch = 16.2781s	
24135/29850 (epoch 40.427), train_loss = 0.63107382, grad/param norm = 2.2808e-01, time/batch = 17.7102s	
24136/29850 (epoch 40.429), train_loss = 0.73396734, grad/param norm = 2.3436e-01, time/batch = 19.1924s	
24137/29850 (epoch 40.430), train_loss = 0.67914135, grad/param norm = 1.8903e-01, time/batch = 16.0751s	
24138/29850 (epoch 40.432), train_loss = 0.77829350, grad/param norm = 2.4955e-01, time/batch = 18.5328s	
24139/29850 (epoch 40.434), train_loss = 0.77244767, grad/param norm = 2.2025e-01, time/batch = 16.6281s	
24140/29850 (epoch 40.436), train_loss = 0.79413401, grad/param norm = 2.3075e-01, time/batch = 18.3655s	
24141/29850 (epoch 40.437), train_loss = 0.87547269, grad/param norm = 2.3212e-01, time/batch = 17.7878s	
24142/29850 (epoch 40.439), train_loss = 0.87471067, grad/param norm = 2.2070e-01, time/batch = 19.1208s	
24143/29850 (epoch 40.441), train_loss = 0.82351896, grad/param norm = 2.1687e-01, time/batch = 16.7269s	
24144/29850 (epoch 40.442), train_loss = 0.78933348, grad/param norm = 2.1628e-01, time/batch = 16.1842s	
24145/29850 (epoch 40.444), train_loss = 0.84846069, grad/param norm = 2.5201e-01, time/batch = 16.9269s	
24146/29850 (epoch 40.446), train_loss = 0.90709176, grad/param norm = 2.3514e-01, time/batch = 17.0441s	
24147/29850 (epoch 40.447), train_loss = 0.92181482, grad/param norm = 2.7722e-01, time/batch = 17.5391s	
24148/29850 (epoch 40.449), train_loss = 0.82630981, grad/param norm = 2.4233e-01, time/batch = 14.2255s	
24149/29850 (epoch 40.451), train_loss = 0.66484214, grad/param norm = 2.1362e-01, time/batch = 14.5639s	
24150/29850 (epoch 40.452), train_loss = 0.57279942, grad/param norm = 2.2459e-01, time/batch = 17.8639s	
24151/29850 (epoch 40.454), train_loss = 0.69461720, grad/param norm = 1.9940e-01, time/batch = 17.0429s	
24152/29850 (epoch 40.456), train_loss = 0.88426108, grad/param norm = 2.3341e-01, time/batch = 17.3881s	
24153/29850 (epoch 40.457), train_loss = 0.92530431, grad/param norm = 3.4271e-01, time/batch = 15.8799s	
24154/29850 (epoch 40.459), train_loss = 0.97074910, grad/param norm = 2.4559e-01, time/batch = 17.6317s	
24155/29850 (epoch 40.461), train_loss = 0.95033499, grad/param norm = 2.5083e-01, time/batch = 18.4609s	
24156/29850 (epoch 40.462), train_loss = 0.98110348, grad/param norm = 2.4867e-01, time/batch = 18.3001s	
24157/29850 (epoch 40.464), train_loss = 0.88660439, grad/param norm = 2.4574e-01, time/batch = 16.0221s	
24158/29850 (epoch 40.466), train_loss = 0.70113146, grad/param norm = 2.5216e-01, time/batch = 15.8715s	
24159/29850 (epoch 40.467), train_loss = 0.75165592, grad/param norm = 2.5468e-01, time/batch = 17.2704s	
24160/29850 (epoch 40.469), train_loss = 0.77874764, grad/param norm = 2.1988e-01, time/batch = 19.2002s	
24161/29850 (epoch 40.471), train_loss = 0.79607464, grad/param norm = 2.4352e-01, time/batch = 17.3558s	
24162/29850 (epoch 40.472), train_loss = 0.75903244, grad/param norm = 2.1494e-01, time/batch = 16.1322s	
24163/29850 (epoch 40.474), train_loss = 0.89452630, grad/param norm = 2.3176e-01, time/batch = 18.1203s	
24164/29850 (epoch 40.476), train_loss = 0.81988088, grad/param norm = 1.9339e-01, time/batch = 17.0657s	
24165/29850 (epoch 40.477), train_loss = 0.85545548, grad/param norm = 2.8221e-01, time/batch = 16.0426s	
24166/29850 (epoch 40.479), train_loss = 0.99290204, grad/param norm = 2.7071e-01, time/batch = 18.4578s	
24167/29850 (epoch 40.481), train_loss = 0.80625331, grad/param norm = 2.0958e-01, time/batch = 17.6934s	
24168/29850 (epoch 40.482), train_loss = 0.75520456, grad/param norm = 1.8866e-01, time/batch = 18.2124s	
24169/29850 (epoch 40.484), train_loss = 0.79254558, grad/param norm = 2.3973e-01, time/batch = 18.6946s	
24170/29850 (epoch 40.486), train_loss = 0.83409891, grad/param norm = 2.2322e-01, time/batch = 15.9413s	
24171/29850 (epoch 40.487), train_loss = 0.82711570, grad/param norm = 2.0613e-01, time/batch = 16.1023s	
24172/29850 (epoch 40.489), train_loss = 0.81576894, grad/param norm = 2.3523e-01, time/batch = 17.8517s	
24173/29850 (epoch 40.491), train_loss = 0.73354890, grad/param norm = 2.0717e-01, time/batch = 17.8095s	
24174/29850 (epoch 40.492), train_loss = 0.82341172, grad/param norm = 2.3323e-01, time/batch = 17.4686s	
24175/29850 (epoch 40.494), train_loss = 0.89185962, grad/param norm = 2.6987e-01, time/batch = 17.6213s	
24176/29850 (epoch 40.496), train_loss = 0.92803925, grad/param norm = 2.2671e-01, time/batch = 17.4512s	
24177/29850 (epoch 40.497), train_loss = 0.85640487, grad/param norm = 2.2907e-01, time/batch = 17.9631s	
24178/29850 (epoch 40.499), train_loss = 0.85086318, grad/param norm = 2.5098e-01, time/batch = 18.4407s	
24179/29850 (epoch 40.501), train_loss = 0.72729828, grad/param norm = 2.4545e-01, time/batch = 18.9286s	
24180/29850 (epoch 40.503), train_loss = 0.90983919, grad/param norm = 2.3444e-01, time/batch = 15.9729s	
24181/29850 (epoch 40.504), train_loss = 1.04148878, grad/param norm = 2.3138e-01, time/batch = 15.3725s	
24182/29850 (epoch 40.506), train_loss = 1.00624732, grad/param norm = 2.3912e-01, time/batch = 16.3656s	
24183/29850 (epoch 40.508), train_loss = 0.86628154, grad/param norm = 2.1760e-01, time/batch = 18.6361s	
24184/29850 (epoch 40.509), train_loss = 0.67824902, grad/param norm = 2.6387e-01, time/batch = 16.6402s	
24185/29850 (epoch 40.511), train_loss = 0.87876499, grad/param norm = 2.3511e-01, time/batch = 18.3702s	
24186/29850 (epoch 40.513), train_loss = 0.79989608, grad/param norm = 2.3617e-01, time/batch = 18.7069s	
24187/29850 (epoch 40.514), train_loss = 0.72057387, grad/param norm = 2.1317e-01, time/batch = 15.9432s	
24188/29850 (epoch 40.516), train_loss = 0.77817519, grad/param norm = 1.9514e-01, time/batch = 17.0124s	
24189/29850 (epoch 40.518), train_loss = 0.65645096, grad/param norm = 2.0243e-01, time/batch = 16.1035s	
24190/29850 (epoch 40.519), train_loss = 0.66878714, grad/param norm = 2.1498e-01, time/batch = 17.8858s	
24191/29850 (epoch 40.521), train_loss = 0.62116084, grad/param norm = 1.8519e-01, time/batch = 18.1314s	
24192/29850 (epoch 40.523), train_loss = 0.67245403, grad/param norm = 1.8665e-01, time/batch = 18.0282s	
24193/29850 (epoch 40.524), train_loss = 0.72118317, grad/param norm = 2.3481e-01, time/batch = 18.4487s	
24194/29850 (epoch 40.526), train_loss = 0.76354118, grad/param norm = 2.3222e-01, time/batch = 18.5396s	
24195/29850 (epoch 40.528), train_loss = 0.88093429, grad/param norm = 2.3980e-01, time/batch = 17.1813s	
24196/29850 (epoch 40.529), train_loss = 0.83054310, grad/param norm = 2.3257e-01, time/batch = 30.6645s	
24197/29850 (epoch 40.531), train_loss = 0.80230235, grad/param norm = 2.4737e-01, time/batch = 18.7062s	
24198/29850 (epoch 40.533), train_loss = 0.81568098, grad/param norm = 2.3202e-01, time/batch = 17.6797s	
24199/29850 (epoch 40.534), train_loss = 0.88279784, grad/param norm = 2.3516e-01, time/batch = 19.1877s	
24200/29850 (epoch 40.536), train_loss = 0.76131993, grad/param norm = 2.6188e-01, time/batch = 18.9416s	
24201/29850 (epoch 40.538), train_loss = 0.93117283, grad/param norm = 2.7105e-01, time/batch = 16.6215s	
24202/29850 (epoch 40.539), train_loss = 0.95710417, grad/param norm = 2.3157e-01, time/batch = 18.4637s	
24203/29850 (epoch 40.541), train_loss = 0.60012860, grad/param norm = 2.0841e-01, time/batch = 16.4416s	
24204/29850 (epoch 40.543), train_loss = 0.76996198, grad/param norm = 2.4638e-01, time/batch = 15.9355s	
24205/29850 (epoch 40.544), train_loss = 0.92156711, grad/param norm = 2.7505e-01, time/batch = 15.3578s	
24206/29850 (epoch 40.546), train_loss = 0.88890137, grad/param norm = 2.4298e-01, time/batch = 16.4346s	
24207/29850 (epoch 40.548), train_loss = 0.68748783, grad/param norm = 2.0064e-01, time/batch = 17.5520s	
24208/29850 (epoch 40.549), train_loss = 0.78008110, grad/param norm = 2.3112e-01, time/batch = 16.2910s	
24209/29850 (epoch 40.551), train_loss = 0.73962593, grad/param norm = 1.9977e-01, time/batch = 16.8825s	
24210/29850 (epoch 40.553), train_loss = 0.78387011, grad/param norm = 2.1942e-01, time/batch = 16.3801s	
24211/29850 (epoch 40.554), train_loss = 0.68129054, grad/param norm = 1.9878e-01, time/batch = 18.2852s	
24212/29850 (epoch 40.556), train_loss = 0.70811996, grad/param norm = 2.1244e-01, time/batch = 16.3563s	
24213/29850 (epoch 40.558), train_loss = 0.71124095, grad/param norm = 2.0766e-01, time/batch = 17.8821s	
24214/29850 (epoch 40.559), train_loss = 0.74763273, grad/param norm = 2.3434e-01, time/batch = 17.1155s	
24215/29850 (epoch 40.561), train_loss = 0.80974012, grad/param norm = 2.1231e-01, time/batch = 16.6298s	
24216/29850 (epoch 40.563), train_loss = 0.85358172, grad/param norm = 2.6082e-01, time/batch = 15.9633s	
24217/29850 (epoch 40.564), train_loss = 0.77106171, grad/param norm = 2.5430e-01, time/batch = 16.3606s	
24218/29850 (epoch 40.566), train_loss = 0.78950504, grad/param norm = 1.9772e-01, time/batch = 15.1638s	
24219/29850 (epoch 40.568), train_loss = 0.95080244, grad/param norm = 2.6857e-01, time/batch = 16.9612s	
24220/29850 (epoch 40.570), train_loss = 0.83326022, grad/param norm = 2.1805e-01, time/batch = 17.8984s	
24221/29850 (epoch 40.571), train_loss = 0.87449443, grad/param norm = 2.1650e-01, time/batch = 16.1374s	
24222/29850 (epoch 40.573), train_loss = 0.96876624, grad/param norm = 3.0007e-01, time/batch = 16.3033s	
24223/29850 (epoch 40.575), train_loss = 0.99191697, grad/param norm = 2.3742e-01, time/batch = 17.5222s	
24224/29850 (epoch 40.576), train_loss = 0.89559963, grad/param norm = 2.5918e-01, time/batch = 18.6930s	
24225/29850 (epoch 40.578), train_loss = 0.75500111, grad/param norm = 2.1155e-01, time/batch = 19.1302s	
24226/29850 (epoch 40.580), train_loss = 0.90709362, grad/param norm = 2.6391e-01, time/batch = 15.8492s	
24227/29850 (epoch 40.581), train_loss = 0.73355838, grad/param norm = 2.0328e-01, time/batch = 18.4912s	
24228/29850 (epoch 40.583), train_loss = 0.80845584, grad/param norm = 2.3745e-01, time/batch = 15.6819s	
24229/29850 (epoch 40.585), train_loss = 0.83085582, grad/param norm = 2.3948e-01, time/batch = 18.6164s	
24230/29850 (epoch 40.586), train_loss = 0.84520829, grad/param norm = 2.2696e-01, time/batch = 16.6202s	
24231/29850 (epoch 40.588), train_loss = 0.74794435, grad/param norm = 2.3359e-01, time/batch = 15.0402s	
24232/29850 (epoch 40.590), train_loss = 0.76513536, grad/param norm = 2.0510e-01, time/batch = 15.5530s	
24233/29850 (epoch 40.591), train_loss = 0.80226997, grad/param norm = 2.3754e-01, time/batch = 16.1100s	
24234/29850 (epoch 40.593), train_loss = 0.72000530, grad/param norm = 1.9236e-01, time/batch = 16.4848s	
24235/29850 (epoch 40.595), train_loss = 0.67622727, grad/param norm = 1.9671e-01, time/batch = 15.7751s	
24236/29850 (epoch 40.596), train_loss = 0.72684455, grad/param norm = 2.6612e-01, time/batch = 16.1862s	
24237/29850 (epoch 40.598), train_loss = 0.77752768, grad/param norm = 1.9578e-01, time/batch = 17.0333s	
24238/29850 (epoch 40.600), train_loss = 0.80692177, grad/param norm = 1.9947e-01, time/batch = 19.9478s	
24239/29850 (epoch 40.601), train_loss = 0.69039502, grad/param norm = 1.7897e-01, time/batch = 15.8535s	
24240/29850 (epoch 40.603), train_loss = 0.75038861, grad/param norm = 2.1601e-01, time/batch = 16.7919s	
24241/29850 (epoch 40.605), train_loss = 0.78702426, grad/param norm = 2.3173e-01, time/batch = 16.7691s	
24242/29850 (epoch 40.606), train_loss = 0.55365734, grad/param norm = 1.8555e-01, time/batch = 19.1994s	
24243/29850 (epoch 40.608), train_loss = 0.68860018, grad/param norm = 1.8718e-01, time/batch = 17.5451s	
24244/29850 (epoch 40.610), train_loss = 0.75497790, grad/param norm = 2.0400e-01, time/batch = 16.9428s	
24245/29850 (epoch 40.611), train_loss = 0.70218132, grad/param norm = 1.9795e-01, time/batch = 15.6371s	
24246/29850 (epoch 40.613), train_loss = 0.60027251, grad/param norm = 1.9933e-01, time/batch = 17.0146s	
24247/29850 (epoch 40.615), train_loss = 0.65422807, grad/param norm = 1.9088e-01, time/batch = 17.1150s	
24248/29850 (epoch 40.616), train_loss = 0.70894573, grad/param norm = 2.7133e-01, time/batch = 15.7730s	
24249/29850 (epoch 40.618), train_loss = 0.75801150, grad/param norm = 2.4128e-01, time/batch = 16.9918s	
24250/29850 (epoch 40.620), train_loss = 0.84724133, grad/param norm = 2.3616e-01, time/batch = 16.3851s	
24251/29850 (epoch 40.621), train_loss = 0.90011709, grad/param norm = 2.6997e-01, time/batch = 16.9647s	
24252/29850 (epoch 40.623), train_loss = 0.87447173, grad/param norm = 2.1819e-01, time/batch = 18.1269s	
24253/29850 (epoch 40.625), train_loss = 0.80223930, grad/param norm = 2.1634e-01, time/batch = 15.6808s	
24254/29850 (epoch 40.626), train_loss = 0.81420973, grad/param norm = 2.6100e-01, time/batch = 16.0860s	
24255/29850 (epoch 40.628), train_loss = 0.80968620, grad/param norm = 2.4701e-01, time/batch = 18.5466s	
24256/29850 (epoch 40.630), train_loss = 0.82102436, grad/param norm = 2.4622e-01, time/batch = 17.6173s	
24257/29850 (epoch 40.631), train_loss = 0.82291583, grad/param norm = 2.5342e-01, time/batch = 18.9483s	
24258/29850 (epoch 40.633), train_loss = 0.82855117, grad/param norm = 2.7360e-01, time/batch = 18.5324s	
24259/29850 (epoch 40.635), train_loss = 0.74946931, grad/param norm = 2.6560e-01, time/batch = 18.5475s	
24260/29850 (epoch 40.637), train_loss = 0.70804892, grad/param norm = 2.4168e-01, time/batch = 17.2989s	
24261/29850 (epoch 40.638), train_loss = 0.83225192, grad/param norm = 2.4723e-01, time/batch = 16.0541s	
24262/29850 (epoch 40.640), train_loss = 0.93659954, grad/param norm = 2.6174e-01, time/batch = 16.3468s	
24263/29850 (epoch 40.642), train_loss = 0.78228189, grad/param norm = 2.1942e-01, time/batch = 15.7036s	
24264/29850 (epoch 40.643), train_loss = 0.75076077, grad/param norm = 2.4040e-01, time/batch = 16.0497s	
24265/29850 (epoch 40.645), train_loss = 0.79114071, grad/param norm = 2.0712e-01, time/batch = 16.2854s	
24266/29850 (epoch 40.647), train_loss = 0.91820562, grad/param norm = 2.4016e-01, time/batch = 14.9361s	
24267/29850 (epoch 40.648), train_loss = 0.72803156, grad/param norm = 2.0829e-01, time/batch = 15.2730s	
24268/29850 (epoch 40.650), train_loss = 0.83061355, grad/param norm = 2.4589e-01, time/batch = 17.9523s	
24269/29850 (epoch 40.652), train_loss = 0.81858485, grad/param norm = 2.6453e-01, time/batch = 17.0474s	
24270/29850 (epoch 40.653), train_loss = 0.89002430, grad/param norm = 2.3321e-01, time/batch = 18.2116s	
24271/29850 (epoch 40.655), train_loss = 0.83261012, grad/param norm = 2.2397e-01, time/batch = 19.8767s	
24272/29850 (epoch 40.657), train_loss = 0.82063408, grad/param norm = 2.1476e-01, time/batch = 17.0529s	
24273/29850 (epoch 40.658), train_loss = 0.89370514, grad/param norm = 2.2792e-01, time/batch = 17.0418s	
24274/29850 (epoch 40.660), train_loss = 0.76988563, grad/param norm = 2.5435e-01, time/batch = 17.0322s	
24275/29850 (epoch 40.662), train_loss = 0.92599385, grad/param norm = 2.9103e-01, time/batch = 16.7676s	
24276/29850 (epoch 40.663), train_loss = 1.01855881, grad/param norm = 2.6173e-01, time/batch = 18.6223s	
24277/29850 (epoch 40.665), train_loss = 0.93915485, grad/param norm = 2.3073e-01, time/batch = 16.0498s	
24278/29850 (epoch 40.667), train_loss = 0.88115201, grad/param norm = 3.2304e-01, time/batch = 18.5387s	
24279/29850 (epoch 40.668), train_loss = 0.77009798, grad/param norm = 2.6737e-01, time/batch = 16.8449s	
24280/29850 (epoch 40.670), train_loss = 0.91763837, grad/param norm = 2.8757e-01, time/batch = 17.5458s	
24281/29850 (epoch 40.672), train_loss = 0.91646740, grad/param norm = 2.7518e-01, time/batch = 15.3523s	
24282/29850 (epoch 40.673), train_loss = 0.84771186, grad/param norm = 2.7143e-01, time/batch = 16.6071s	
24283/29850 (epoch 40.675), train_loss = 0.73311633, grad/param norm = 2.1076e-01, time/batch = 17.3731s	
24284/29850 (epoch 40.677), train_loss = 0.77348448, grad/param norm = 2.2657e-01, time/batch = 16.3733s	
24285/29850 (epoch 40.678), train_loss = 0.81040360, grad/param norm = 2.2542e-01, time/batch = 17.7838s	
24286/29850 (epoch 40.680), train_loss = 0.79922095, grad/param norm = 2.2603e-01, time/batch = 16.9472s	
24287/29850 (epoch 40.682), train_loss = 0.80190431, grad/param norm = 2.3776e-01, time/batch = 15.3548s	
24288/29850 (epoch 40.683), train_loss = 0.91218331, grad/param norm = 2.9149e-01, time/batch = 15.5705s	
24289/29850 (epoch 40.685), train_loss = 1.00209119, grad/param norm = 2.1535e-01, time/batch = 15.5030s	
24290/29850 (epoch 40.687), train_loss = 0.85934345, grad/param norm = 2.1207e-01, time/batch = 15.3967s	
24291/29850 (epoch 40.688), train_loss = 0.71125486, grad/param norm = 2.3115e-01, time/batch = 15.0625s	
24292/29850 (epoch 40.690), train_loss = 0.73586788, grad/param norm = 2.0754e-01, time/batch = 15.7776s	
24293/29850 (epoch 40.692), train_loss = 0.93485810, grad/param norm = 2.4333e-01, time/batch = 15.5911s	
24294/29850 (epoch 40.693), train_loss = 0.81778982, grad/param norm = 2.0101e-01, time/batch = 17.9431s	
24295/29850 (epoch 40.695), train_loss = 0.72854954, grad/param norm = 2.1624e-01, time/batch = 16.8112s	
24296/29850 (epoch 40.697), train_loss = 0.80857896, grad/param norm = 2.2158e-01, time/batch = 18.8762s	
24297/29850 (epoch 40.698), train_loss = 0.93427389, grad/param norm = 2.3079e-01, time/batch = 15.0049s	
24298/29850 (epoch 40.700), train_loss = 0.86774427, grad/param norm = 2.8115e-01, time/batch = 14.9273s	
24299/29850 (epoch 40.702), train_loss = 0.83544023, grad/param norm = 2.4304e-01, time/batch = 15.0130s	
24300/29850 (epoch 40.704), train_loss = 0.69631624, grad/param norm = 2.0173e-01, time/batch = 16.4265s	
24301/29850 (epoch 40.705), train_loss = 0.81432444, grad/param norm = 2.2559e-01, time/batch = 15.8219s	
24302/29850 (epoch 40.707), train_loss = 0.74161887, grad/param norm = 2.2134e-01, time/batch = 18.0526s	
24303/29850 (epoch 40.709), train_loss = 0.80880330, grad/param norm = 2.2076e-01, time/batch = 18.4682s	
24304/29850 (epoch 40.710), train_loss = 0.76127382, grad/param norm = 2.5248e-01, time/batch = 17.7869s	
24305/29850 (epoch 40.712), train_loss = 0.86423399, grad/param norm = 2.3296e-01, time/batch = 17.8547s	
24306/29850 (epoch 40.714), train_loss = 0.89470573, grad/param norm = 2.4832e-01, time/batch = 17.3145s	
24307/29850 (epoch 40.715), train_loss = 0.83619178, grad/param norm = 2.2861e-01, time/batch = 17.2057s	
24308/29850 (epoch 40.717), train_loss = 0.63839773, grad/param norm = 2.1718e-01, time/batch = 18.5461s	
24309/29850 (epoch 40.719), train_loss = 0.77509162, grad/param norm = 2.3120e-01, time/batch = 16.6163s	
24310/29850 (epoch 40.720), train_loss = 0.78106218, grad/param norm = 1.9791e-01, time/batch = 18.8903s	
24311/29850 (epoch 40.722), train_loss = 0.72428499, grad/param norm = 1.8590e-01, time/batch = 18.9380s	
24312/29850 (epoch 40.724), train_loss = 0.84476790, grad/param norm = 2.5009e-01, time/batch = 18.1241s	
24313/29850 (epoch 40.725), train_loss = 0.71305099, grad/param norm = 1.9075e-01, time/batch = 16.0526s	
24314/29850 (epoch 40.727), train_loss = 0.69894464, grad/param norm = 2.2962e-01, time/batch = 16.6942s	
24315/29850 (epoch 40.729), train_loss = 0.67237563, grad/param norm = 1.8282e-01, time/batch = 19.8700s	
24316/29850 (epoch 40.730), train_loss = 0.65204096, grad/param norm = 2.1112e-01, time/batch = 17.5581s	
24317/29850 (epoch 40.732), train_loss = 0.89771088, grad/param norm = 2.5204e-01, time/batch = 16.7192s	
24318/29850 (epoch 40.734), train_loss = 0.96937495, grad/param norm = 2.5755e-01, time/batch = 17.8824s	
24319/29850 (epoch 40.735), train_loss = 0.74303106, grad/param norm = 2.3249e-01, time/batch = 16.4616s	
24320/29850 (epoch 40.737), train_loss = 0.69006968, grad/param norm = 2.1299e-01, time/batch = 18.6998s	
24321/29850 (epoch 40.739), train_loss = 0.62177219, grad/param norm = 1.8960e-01, time/batch = 17.8536s	
24322/29850 (epoch 40.740), train_loss = 0.66313005, grad/param norm = 2.1920e-01, time/batch = 16.5678s	
24323/29850 (epoch 40.742), train_loss = 0.61305879, grad/param norm = 1.7916e-01, time/batch = 17.8105s	
24324/29850 (epoch 40.744), train_loss = 0.73148150, grad/param norm = 2.0852e-01, time/batch = 16.7166s	
24325/29850 (epoch 40.745), train_loss = 0.75477679, grad/param norm = 2.6404e-01, time/batch = 17.6480s	
24326/29850 (epoch 40.747), train_loss = 0.80392584, grad/param norm = 2.3455e-01, time/batch = 16.7998s	
24327/29850 (epoch 40.749), train_loss = 0.67925423, grad/param norm = 2.2720e-01, time/batch = 17.8684s	
24328/29850 (epoch 40.750), train_loss = 0.61929374, grad/param norm = 2.1202e-01, time/batch = 17.7054s	
24329/29850 (epoch 40.752), train_loss = 0.54445862, grad/param norm = 1.7230e-01, time/batch = 15.9007s	
24330/29850 (epoch 40.754), train_loss = 0.60291654, grad/param norm = 1.9666e-01, time/batch = 16.3809s	
24331/29850 (epoch 40.755), train_loss = 0.62698866, grad/param norm = 1.9547e-01, time/batch = 16.3066s	
24332/29850 (epoch 40.757), train_loss = 0.68227816, grad/param norm = 1.8523e-01, time/batch = 17.9612s	
24333/29850 (epoch 40.759), train_loss = 0.69734438, grad/param norm = 2.0834e-01, time/batch = 18.3093s	
24334/29850 (epoch 40.760), train_loss = 0.72062935, grad/param norm = 2.2925e-01, time/batch = 19.5315s	
24335/29850 (epoch 40.762), train_loss = 0.64676718, grad/param norm = 2.4854e-01, time/batch = 6.2975s	
24336/29850 (epoch 40.764), train_loss = 0.59457484, grad/param norm = 2.8505e-01, time/batch = 0.6729s	
24337/29850 (epoch 40.765), train_loss = 0.73112792, grad/param norm = 2.5359e-01, time/batch = 0.6729s	
24338/29850 (epoch 40.767), train_loss = 0.72297398, grad/param norm = 2.2426e-01, time/batch = 0.6841s	
24339/29850 (epoch 40.769), train_loss = 0.78277125, grad/param norm = 2.2620e-01, time/batch = 0.6803s	
24340/29850 (epoch 40.771), train_loss = 0.77664042, grad/param norm = 2.0062e-01, time/batch = 0.6649s	
24341/29850 (epoch 40.772), train_loss = 0.78030077, grad/param norm = 2.4731e-01, time/batch = 0.6638s	
24342/29850 (epoch 40.774), train_loss = 0.71709193, grad/param norm = 2.2028e-01, time/batch = 0.7535s	
24343/29850 (epoch 40.776), train_loss = 0.73903998, grad/param norm = 2.1465e-01, time/batch = 1.0080s	
24344/29850 (epoch 40.777), train_loss = 0.83815720, grad/param norm = 2.3344e-01, time/batch = 0.9580s	
24345/29850 (epoch 40.779), train_loss = 0.68575117, grad/param norm = 2.0255e-01, time/batch = 0.9879s	
24346/29850 (epoch 40.781), train_loss = 0.79327290, grad/param norm = 2.2756e-01, time/batch = 0.9802s	
24347/29850 (epoch 40.782), train_loss = 0.81425990, grad/param norm = 2.3153e-01, time/batch = 1.1632s	
24348/29850 (epoch 40.784), train_loss = 0.63588243, grad/param norm = 2.5730e-01, time/batch = 1.8353s	
24349/29850 (epoch 40.786), train_loss = 0.70889877, grad/param norm = 2.0780e-01, time/batch = 1.8135s	
24350/29850 (epoch 40.787), train_loss = 0.59855194, grad/param norm = 2.2672e-01, time/batch = 10.4192s	
24351/29850 (epoch 40.789), train_loss = 0.63035765, grad/param norm = 1.9884e-01, time/batch = 18.6348s	
24352/29850 (epoch 40.791), train_loss = 0.71297164, grad/param norm = 2.4566e-01, time/batch = 17.2021s	
24353/29850 (epoch 40.792), train_loss = 0.79185478, grad/param norm = 2.3817e-01, time/batch = 17.9392s	
24354/29850 (epoch 40.794), train_loss = 0.75833422, grad/param norm = 1.9163e-01, time/batch = 18.1950s	
24355/29850 (epoch 40.796), train_loss = 0.65688411, grad/param norm = 1.9680e-01, time/batch = 17.0311s	
24356/29850 (epoch 40.797), train_loss = 0.56968196, grad/param norm = 1.8081e-01, time/batch = 16.4417s	
24357/29850 (epoch 40.799), train_loss = 0.63001142, grad/param norm = 1.7954e-01, time/batch = 19.0225s	
24358/29850 (epoch 40.801), train_loss = 0.64665620, grad/param norm = 2.0227e-01, time/batch = 20.0034s	
24359/29850 (epoch 40.802), train_loss = 0.62822319, grad/param norm = 2.2849e-01, time/batch = 15.2237s	
24360/29850 (epoch 40.804), train_loss = 0.65987805, grad/param norm = 1.9613e-01, time/batch = 17.4563s	
24361/29850 (epoch 40.806), train_loss = 0.59440702, grad/param norm = 2.1305e-01, time/batch = 17.7269s	
24362/29850 (epoch 40.807), train_loss = 0.64952550, grad/param norm = 1.8269e-01, time/batch = 18.2807s	
24363/29850 (epoch 40.809), train_loss = 0.64290905, grad/param norm = 2.5601e-01, time/batch = 18.8763s	
24364/29850 (epoch 40.811), train_loss = 0.79903823, grad/param norm = 2.2377e-01, time/batch = 15.5753s	
24365/29850 (epoch 40.812), train_loss = 0.77921109, grad/param norm = 2.1641e-01, time/batch = 15.5639s	
24366/29850 (epoch 40.814), train_loss = 0.81732704, grad/param norm = 2.6740e-01, time/batch = 15.2946s	
24367/29850 (epoch 40.816), train_loss = 0.87561673, grad/param norm = 2.1411e-01, time/batch = 16.8876s	
24368/29850 (epoch 40.817), train_loss = 0.78583548, grad/param norm = 2.8190e-01, time/batch = 17.5616s	
24369/29850 (epoch 40.819), train_loss = 0.60913731, grad/param norm = 2.3287e-01, time/batch = 18.6061s	
24370/29850 (epoch 40.821), train_loss = 0.85647550, grad/param norm = 2.8546e-01, time/batch = 16.4519s	
24371/29850 (epoch 40.822), train_loss = 0.87904455, grad/param norm = 2.3730e-01, time/batch = 18.5296s	
24372/29850 (epoch 40.824), train_loss = 0.76137683, grad/param norm = 2.2218e-01, time/batch = 19.1397s	
24373/29850 (epoch 40.826), train_loss = 0.66646517, grad/param norm = 2.1021e-01, time/batch = 18.4510s	
24374/29850 (epoch 40.827), train_loss = 0.60319670, grad/param norm = 2.3000e-01, time/batch = 17.6286s	
24375/29850 (epoch 40.829), train_loss = 0.77582843, grad/param norm = 2.8131e-01, time/batch = 15.8748s	
24376/29850 (epoch 40.831), train_loss = 0.87216017, grad/param norm = 2.3950e-01, time/batch = 16.4521s	
24377/29850 (epoch 40.832), train_loss = 0.78834188, grad/param norm = 2.2912e-01, time/batch = 18.3822s	
24378/29850 (epoch 40.834), train_loss = 0.58326219, grad/param norm = 1.7572e-01, time/batch = 16.4619s	
24379/29850 (epoch 40.836), train_loss = 0.60445513, grad/param norm = 2.0550e-01, time/batch = 17.9586s	
24380/29850 (epoch 40.838), train_loss = 0.69523915, grad/param norm = 2.0098e-01, time/batch = 18.0411s	
24381/29850 (epoch 40.839), train_loss = 0.59923831, grad/param norm = 2.1486e-01, time/batch = 19.1150s	
24382/29850 (epoch 40.841), train_loss = 0.68388422, grad/param norm = 1.8983e-01, time/batch = 18.2313s	
24383/29850 (epoch 40.843), train_loss = 0.59621063, grad/param norm = 1.9935e-01, time/batch = 16.4588s	
24384/29850 (epoch 40.844), train_loss = 0.65861939, grad/param norm = 2.2972e-01, time/batch = 18.4430s	
24385/29850 (epoch 40.846), train_loss = 0.73028672, grad/param norm = 2.2602e-01, time/batch = 16.7997s	
24386/29850 (epoch 40.848), train_loss = 0.79196756, grad/param norm = 2.1778e-01, time/batch = 18.5366s	
24387/29850 (epoch 40.849), train_loss = 0.73105603, grad/param norm = 2.1973e-01, time/batch = 18.3027s	
24388/29850 (epoch 40.851), train_loss = 0.90240635, grad/param norm = 2.3715e-01, time/batch = 17.5534s	
24389/29850 (epoch 40.853), train_loss = 0.72005446, grad/param norm = 2.4086e-01, time/batch = 17.6347s	
24390/29850 (epoch 40.854), train_loss = 0.90213215, grad/param norm = 2.5114e-01, time/batch = 16.7770s	
24391/29850 (epoch 40.856), train_loss = 0.85105306, grad/param norm = 2.8529e-01, time/batch = 17.3738s	
24392/29850 (epoch 40.858), train_loss = 0.77633521, grad/param norm = 2.2602e-01, time/batch = 18.7859s	
24393/29850 (epoch 40.859), train_loss = 0.68426025, grad/param norm = 2.5793e-01, time/batch = 16.2866s	
24394/29850 (epoch 40.861), train_loss = 0.86681689, grad/param norm = 2.7114e-01, time/batch = 18.6251s	
24395/29850 (epoch 40.863), train_loss = 0.85406562, grad/param norm = 2.3201e-01, time/batch = 15.8851s	
24396/29850 (epoch 40.864), train_loss = 0.88465241, grad/param norm = 2.5029e-01, time/batch = 17.3996s	
24397/29850 (epoch 40.866), train_loss = 0.78347060, grad/param norm = 2.7206e-01, time/batch = 17.9768s	
24398/29850 (epoch 40.868), train_loss = 0.94301511, grad/param norm = 2.9044e-01, time/batch = 17.1474s	
24399/29850 (epoch 40.869), train_loss = 0.86690435, grad/param norm = 2.8692e-01, time/batch = 16.4685s	
24400/29850 (epoch 40.871), train_loss = 0.85892643, grad/param norm = 2.3935e-01, time/batch = 15.2810s	
24401/29850 (epoch 40.873), train_loss = 0.82804332, grad/param norm = 2.6997e-01, time/batch = 17.3698s	
24402/29850 (epoch 40.874), train_loss = 0.80261704, grad/param norm = 2.2012e-01, time/batch = 17.5559s	
24403/29850 (epoch 40.876), train_loss = 0.80142526, grad/param norm = 2.6453e-01, time/batch = 17.6386s	
24404/29850 (epoch 40.878), train_loss = 0.78449125, grad/param norm = 2.0980e-01, time/batch = 16.9628s	
24405/29850 (epoch 40.879), train_loss = 0.83976142, grad/param norm = 2.3253e-01, time/batch = 18.1449s	
24406/29850 (epoch 40.881), train_loss = 0.89551870, grad/param norm = 2.9775e-01, time/batch = 18.7137s	
24407/29850 (epoch 40.883), train_loss = 0.81198153, grad/param norm = 2.3338e-01, time/batch = 17.7806s	
24408/29850 (epoch 40.884), train_loss = 0.69765197, grad/param norm = 2.2187e-01, time/batch = 15.1097s	
24409/29850 (epoch 40.886), train_loss = 0.84647302, grad/param norm = 2.8749e-01, time/batch = 16.5497s	
24410/29850 (epoch 40.888), train_loss = 0.80040101, grad/param norm = 2.4655e-01, time/batch = 17.8753s	
24411/29850 (epoch 40.889), train_loss = 0.73485475, grad/param norm = 2.0547e-01, time/batch = 19.0351s	
24412/29850 (epoch 40.891), train_loss = 0.70935569, grad/param norm = 1.8764e-01, time/batch = 18.0458s	
24413/29850 (epoch 40.893), train_loss = 0.75746275, grad/param norm = 2.1402e-01, time/batch = 18.7790s	
24414/29850 (epoch 40.894), train_loss = 0.74199772, grad/param norm = 2.2632e-01, time/batch = 18.0350s	
24415/29850 (epoch 40.896), train_loss = 0.80307470, grad/param norm = 2.4730e-01, time/batch = 19.0395s	
24416/29850 (epoch 40.898), train_loss = 0.92432930, grad/param norm = 2.4297e-01, time/batch = 19.1225s	
24417/29850 (epoch 40.899), train_loss = 0.68875935, grad/param norm = 2.2061e-01, time/batch = 29.9495s	
24418/29850 (epoch 40.901), train_loss = 0.98488914, grad/param norm = 3.7084e-01, time/batch = 16.1374s	
24419/29850 (epoch 40.903), train_loss = 0.80878730, grad/param norm = 2.6969e-01, time/batch = 17.1099s	
24420/29850 (epoch 40.905), train_loss = 1.04932837, grad/param norm = 2.4776e-01, time/batch = 16.7648s	
24421/29850 (epoch 40.906), train_loss = 0.81782951, grad/param norm = 3.1441e-01, time/batch = 15.7785s	
24422/29850 (epoch 40.908), train_loss = 0.93946045, grad/param norm = 2.2577e-01, time/batch = 18.4656s	
24423/29850 (epoch 40.910), train_loss = 0.86852898, grad/param norm = 2.2705e-01, time/batch = 17.1314s	
24424/29850 (epoch 40.911), train_loss = 1.00664843, grad/param norm = 2.7456e-01, time/batch = 15.4433s	
24425/29850 (epoch 40.913), train_loss = 0.95923847, grad/param norm = 2.6039e-01, time/batch = 16.9535s	
24426/29850 (epoch 40.915), train_loss = 0.93553853, grad/param norm = 2.3477e-01, time/batch = 19.0314s	
24427/29850 (epoch 40.916), train_loss = 0.89339429, grad/param norm = 2.6838e-01, time/batch = 17.3057s	
24428/29850 (epoch 40.918), train_loss = 0.75986043, grad/param norm = 2.2335e-01, time/batch = 18.4591s	
24429/29850 (epoch 40.920), train_loss = 0.91580370, grad/param norm = 2.1179e-01, time/batch = 18.6368s	
24430/29850 (epoch 40.921), train_loss = 0.79902691, grad/param norm = 2.4709e-01, time/batch = 15.4590s	
24431/29850 (epoch 40.923), train_loss = 0.81976963, grad/param norm = 2.2868e-01, time/batch = 17.7904s	
24432/29850 (epoch 40.925), train_loss = 0.95675373, grad/param norm = 2.5098e-01, time/batch = 17.5248s	
24433/29850 (epoch 40.926), train_loss = 0.96514441, grad/param norm = 2.7845e-01, time/batch = 18.2749s	
24434/29850 (epoch 40.928), train_loss = 0.83119525, grad/param norm = 2.2786e-01, time/batch = 16.1429s	
24435/29850 (epoch 40.930), train_loss = 0.82804416, grad/param norm = 2.4708e-01, time/batch = 18.9555s	
24436/29850 (epoch 40.931), train_loss = 0.82274016, grad/param norm = 2.3034e-01, time/batch = 18.2197s	
24437/29850 (epoch 40.933), train_loss = 0.96704765, grad/param norm = 2.3992e-01, time/batch = 17.5337s	
24438/29850 (epoch 40.935), train_loss = 0.88538320, grad/param norm = 2.5276e-01, time/batch = 19.7086s	
24439/29850 (epoch 40.936), train_loss = 0.85752506, grad/param norm = 2.4906e-01, time/batch = 17.6366s	
24440/29850 (epoch 40.938), train_loss = 0.72526505, grad/param norm = 2.1399e-01, time/batch = 16.8050s	
24441/29850 (epoch 40.940), train_loss = 0.74144834, grad/param norm = 2.1259e-01, time/batch = 18.7082s	
24442/29850 (epoch 40.941), train_loss = 0.71887160, grad/param norm = 2.5056e-01, time/batch = 15.4096s	
24443/29850 (epoch 40.943), train_loss = 0.76558874, grad/param norm = 2.2382e-01, time/batch = 17.3031s	
24444/29850 (epoch 40.945), train_loss = 0.72033103, grad/param norm = 2.8264e-01, time/batch = 17.7909s	
24445/29850 (epoch 40.946), train_loss = 0.72684736, grad/param norm = 2.3625e-01, time/batch = 18.5514s	
24446/29850 (epoch 40.948), train_loss = 0.81640280, grad/param norm = 2.3861e-01, time/batch = 18.7161s	
24447/29850 (epoch 40.950), train_loss = 0.76052582, grad/param norm = 1.9355e-01, time/batch = 18.5351s	
24448/29850 (epoch 40.951), train_loss = 0.68297303, grad/param norm = 2.3309e-01, time/batch = 18.6264s	
24449/29850 (epoch 40.953), train_loss = 0.76534726, grad/param norm = 2.5664e-01, time/batch = 18.1217s	
24450/29850 (epoch 40.955), train_loss = 0.68592208, grad/param norm = 2.4289e-01, time/batch = 16.4539s	
24451/29850 (epoch 40.956), train_loss = 0.69198384, grad/param norm = 2.2849e-01, time/batch = 17.3861s	
24452/29850 (epoch 40.958), train_loss = 0.62970153, grad/param norm = 1.7749e-01, time/batch = 17.8707s	
24453/29850 (epoch 40.960), train_loss = 0.89297152, grad/param norm = 2.8066e-01, time/batch = 17.7861s	
24454/29850 (epoch 40.961), train_loss = 0.65737462, grad/param norm = 2.8983e-01, time/batch = 16.9554s	
24455/29850 (epoch 40.963), train_loss = 0.64372022, grad/param norm = 1.8326e-01, time/batch = 17.2635s	
24456/29850 (epoch 40.965), train_loss = 0.70741303, grad/param norm = 2.1644e-01, time/batch = 17.3879s	
24457/29850 (epoch 40.966), train_loss = 0.66983509, grad/param norm = 2.2860e-01, time/batch = 16.3933s	
24458/29850 (epoch 40.968), train_loss = 0.73614042, grad/param norm = 2.9441e-01, time/batch = 19.2199s	
24459/29850 (epoch 40.970), train_loss = 0.71981172, grad/param norm = 2.6770e-01, time/batch = 16.4633s	
24460/29850 (epoch 40.972), train_loss = 0.69954667, grad/param norm = 1.8545e-01, time/batch = 17.2972s	
24461/29850 (epoch 40.973), train_loss = 0.71234388, grad/param norm = 2.0773e-01, time/batch = 17.5490s	
24462/29850 (epoch 40.975), train_loss = 0.61669206, grad/param norm = 1.9476e-01, time/batch = 18.2232s	
24463/29850 (epoch 40.977), train_loss = 0.72187439, grad/param norm = 2.1943e-01, time/batch = 16.4436s	
24464/29850 (epoch 40.978), train_loss = 0.64059880, grad/param norm = 1.9034e-01, time/batch = 18.0965s	
24465/29850 (epoch 40.980), train_loss = 0.71057750, grad/param norm = 1.9669e-01, time/batch = 18.7063s	
24466/29850 (epoch 40.982), train_loss = 0.67934634, grad/param norm = 2.0911e-01, time/batch = 19.5416s	
24467/29850 (epoch 40.983), train_loss = 0.72322904, grad/param norm = 1.8734e-01, time/batch = 15.9528s	
24468/29850 (epoch 40.985), train_loss = 0.83254858, grad/param norm = 2.8501e-01, time/batch = 18.5349s	
24469/29850 (epoch 40.987), train_loss = 0.79615857, grad/param norm = 2.0795e-01, time/batch = 17.4611s	
24470/29850 (epoch 40.988), train_loss = 0.73007342, grad/param norm = 1.9084e-01, time/batch = 18.0528s	
24471/29850 (epoch 40.990), train_loss = 0.79288371, grad/param norm = 2.1000e-01, time/batch = 19.2090s	
24472/29850 (epoch 40.992), train_loss = 0.78957740, grad/param norm = 1.9792e-01, time/batch = 18.1234s	
24473/29850 (epoch 40.993), train_loss = 0.79649563, grad/param norm = 2.1560e-01, time/batch = 14.7426s	
24474/29850 (epoch 40.995), train_loss = 0.77813156, grad/param norm = 2.3471e-01, time/batch = 17.4660s	
24475/29850 (epoch 40.997), train_loss = 0.81009395, grad/param norm = 2.1758e-01, time/batch = 19.3803s	
24476/29850 (epoch 40.998), train_loss = 0.80744853, grad/param norm = 2.0833e-01, time/batch = 15.6316s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
24477/29850 (epoch 41.000), train_loss = 0.64780764, grad/param norm = 1.7387e-01, time/batch = 17.1347s	
24478/29850 (epoch 41.002), train_loss = 0.89964600, grad/param norm = 2.1660e-01, time/batch = 14.9157s	
24479/29850 (epoch 41.003), train_loss = 0.66081740, grad/param norm = 2.3970e-01, time/batch = 19.2090s	
24480/29850 (epoch 41.005), train_loss = 0.83984233, grad/param norm = 2.4738e-01, time/batch = 18.3796s	
24481/29850 (epoch 41.007), train_loss = 0.86494002, grad/param norm = 2.4623e-01, time/batch = 16.9347s	
24482/29850 (epoch 41.008), train_loss = 0.99217684, grad/param norm = 2.6270e-01, time/batch = 17.1441s	
24483/29850 (epoch 41.010), train_loss = 0.71877704, grad/param norm = 2.0772e-01, time/batch = 18.3895s	
24484/29850 (epoch 41.012), train_loss = 0.75673573, grad/param norm = 2.0680e-01, time/batch = 15.7938s	
24485/29850 (epoch 41.013), train_loss = 0.81477431, grad/param norm = 2.5844e-01, time/batch = 17.7932s	
24486/29850 (epoch 41.015), train_loss = 0.88015125, grad/param norm = 2.3161e-01, time/batch = 17.3451s	
24487/29850 (epoch 41.017), train_loss = 0.82353440, grad/param norm = 2.4120e-01, time/batch = 17.6012s	
24488/29850 (epoch 41.018), train_loss = 0.91661255, grad/param norm = 2.5112e-01, time/batch = 17.1146s	
24489/29850 (epoch 41.020), train_loss = 0.80440750, grad/param norm = 2.2521e-01, time/batch = 16.8535s	
24490/29850 (epoch 41.022), train_loss = 0.86659783, grad/param norm = 2.4540e-01, time/batch = 17.7315s	
24491/29850 (epoch 41.023), train_loss = 0.86209701, grad/param norm = 2.4449e-01, time/batch = 17.8694s	
24492/29850 (epoch 41.025), train_loss = 0.77394087, grad/param norm = 1.8536e-01, time/batch = 18.3788s	
24493/29850 (epoch 41.027), train_loss = 0.58861491, grad/param norm = 2.0526e-01, time/batch = 16.7991s	
24494/29850 (epoch 41.028), train_loss = 0.73760958, grad/param norm = 2.0725e-01, time/batch = 18.1210s	
24495/29850 (epoch 41.030), train_loss = 0.75082854, grad/param norm = 2.2907e-01, time/batch = 19.3754s	
24496/29850 (epoch 41.032), train_loss = 0.82397109, grad/param norm = 2.1185e-01, time/batch = 18.2094s	
24497/29850 (epoch 41.034), train_loss = 0.72226157, grad/param norm = 2.3310e-01, time/batch = 18.2148s	
24498/29850 (epoch 41.035), train_loss = 0.62736286, grad/param norm = 2.0733e-01, time/batch = 17.9489s	
24499/29850 (epoch 41.037), train_loss = 0.79467831, grad/param norm = 2.1143e-01, time/batch = 16.0402s	
24500/29850 (epoch 41.039), train_loss = 0.70066998, grad/param norm = 1.9346e-01, time/batch = 18.9765s	
24501/29850 (epoch 41.040), train_loss = 0.65507469, grad/param norm = 1.7678e-01, time/batch = 16.7123s	
24502/29850 (epoch 41.042), train_loss = 0.72140088, grad/param norm = 2.2997e-01, time/batch = 18.2295s	
24503/29850 (epoch 41.044), train_loss = 0.73949688, grad/param norm = 1.9691e-01, time/batch = 17.2955s	
24504/29850 (epoch 41.045), train_loss = 0.85036124, grad/param norm = 2.1617e-01, time/batch = 16.7924s	
24505/29850 (epoch 41.047), train_loss = 0.68831032, grad/param norm = 2.0262e-01, time/batch = 18.7255s	
24506/29850 (epoch 41.049), train_loss = 0.82384624, grad/param norm = 2.1020e-01, time/batch = 16.8526s	
24507/29850 (epoch 41.050), train_loss = 0.73672551, grad/param norm = 2.1095e-01, time/batch = 19.1416s	
24508/29850 (epoch 41.052), train_loss = 0.89045429, grad/param norm = 2.4274e-01, time/batch = 16.8579s	
24509/29850 (epoch 41.054), train_loss = 0.77385646, grad/param norm = 2.2190e-01, time/batch = 19.2936s	
24510/29850 (epoch 41.055), train_loss = 0.72941684, grad/param norm = 1.8526e-01, time/batch = 16.9600s	
24511/29850 (epoch 41.057), train_loss = 0.83394277, grad/param norm = 2.0317e-01, time/batch = 16.2933s	
24512/29850 (epoch 41.059), train_loss = 0.81515150, grad/param norm = 2.0534e-01, time/batch = 19.0454s	
24513/29850 (epoch 41.060), train_loss = 0.81118625, grad/param norm = 2.7583e-01, time/batch = 19.6185s	
24514/29850 (epoch 41.062), train_loss = 0.86991075, grad/param norm = 2.4722e-01, time/batch = 17.6303s	
24515/29850 (epoch 41.064), train_loss = 0.88229424, grad/param norm = 2.2885e-01, time/batch = 19.8619s	
24516/29850 (epoch 41.065), train_loss = 0.67447165, grad/param norm = 1.9874e-01, time/batch = 17.5485s	
24517/29850 (epoch 41.067), train_loss = 0.84810034, grad/param norm = 2.1863e-01, time/batch = 18.6941s	
24518/29850 (epoch 41.069), train_loss = 0.82810701, grad/param norm = 1.9935e-01, time/batch = 17.2146s	
24519/29850 (epoch 41.070), train_loss = 0.85627174, grad/param norm = 2.1268e-01, time/batch = 16.7830s	
24520/29850 (epoch 41.072), train_loss = 0.79547329, grad/param norm = 2.5711e-01, time/batch = 17.8809s	
24521/29850 (epoch 41.074), train_loss = 0.86112716, grad/param norm = 1.9142e-01, time/batch = 16.5321s	
24522/29850 (epoch 41.075), train_loss = 0.74593931, grad/param norm = 2.8363e-01, time/batch = 16.9649s	
24523/29850 (epoch 41.077), train_loss = 0.84597918, grad/param norm = 2.1886e-01, time/batch = 18.2044s	
24524/29850 (epoch 41.079), train_loss = 1.00219438, grad/param norm = 2.8798e-01, time/batch = 17.9466s	
24525/29850 (epoch 41.080), train_loss = 0.96516683, grad/param norm = 2.6243e-01, time/batch = 17.7135s	
24526/29850 (epoch 41.082), train_loss = 0.85310503, grad/param norm = 2.1666e-01, time/batch = 17.9518s	
24527/29850 (epoch 41.084), train_loss = 0.93739016, grad/param norm = 2.4722e-01, time/batch = 19.4466s	
24528/29850 (epoch 41.085), train_loss = 0.99063802, grad/param norm = 2.5197e-01, time/batch = 17.3662s	
24529/29850 (epoch 41.087), train_loss = 0.91833194, grad/param norm = 2.4173e-01, time/batch = 17.9649s	
24530/29850 (epoch 41.089), train_loss = 0.84213961, grad/param norm = 2.1200e-01, time/batch = 16.0340s	
24531/29850 (epoch 41.090), train_loss = 0.84376394, grad/param norm = 2.3095e-01, time/batch = 16.5522s	
24532/29850 (epoch 41.092), train_loss = 0.74484753, grad/param norm = 2.1992e-01, time/batch = 17.3720s	
24533/29850 (epoch 41.094), train_loss = 0.93559993, grad/param norm = 2.2647e-01, time/batch = 18.6265s	
24534/29850 (epoch 41.095), train_loss = 0.88319173, grad/param norm = 3.0319e-01, time/batch = 18.2975s	
24535/29850 (epoch 41.097), train_loss = 0.62203105, grad/param norm = 1.8707e-01, time/batch = 16.1277s	
24536/29850 (epoch 41.099), train_loss = 0.64761412, grad/param norm = 1.9008e-01, time/batch = 18.7904s	
24537/29850 (epoch 41.101), train_loss = 0.86153963, grad/param norm = 2.4276e-01, time/batch = 16.9551s	
24538/29850 (epoch 41.102), train_loss = 0.86096122, grad/param norm = 2.2889e-01, time/batch = 16.5294s	
24539/29850 (epoch 41.104), train_loss = 0.78718516, grad/param norm = 2.3922e-01, time/batch = 19.1906s	
24540/29850 (epoch 41.106), train_loss = 0.87201084, grad/param norm = 2.1071e-01, time/batch = 17.8014s	
24541/29850 (epoch 41.107), train_loss = 0.74469277, grad/param norm = 1.9681e-01, time/batch = 17.6226s	
24542/29850 (epoch 41.109), train_loss = 0.79655271, grad/param norm = 2.1220e-01, time/batch = 15.7872s	
24543/29850 (epoch 41.111), train_loss = 0.84508026, grad/param norm = 2.3151e-01, time/batch = 18.0359s	
24544/29850 (epoch 41.112), train_loss = 0.70319057, grad/param norm = 2.0469e-01, time/batch = 16.5100s	
24545/29850 (epoch 41.114), train_loss = 0.74842885, grad/param norm = 2.7509e-01, time/batch = 16.3779s	
24546/29850 (epoch 41.116), train_loss = 0.73382521, grad/param norm = 2.2956e-01, time/batch = 19.3761s	
24547/29850 (epoch 41.117), train_loss = 0.77547627, grad/param norm = 2.2231e-01, time/batch = 19.2120s	
24548/29850 (epoch 41.119), train_loss = 0.77774967, grad/param norm = 2.1839e-01, time/batch = 17.2055s	
24549/29850 (epoch 41.121), train_loss = 0.65373859, grad/param norm = 2.0930e-01, time/batch = 19.2241s	
24550/29850 (epoch 41.122), train_loss = 0.68099227, grad/param norm = 1.5976e-01, time/batch = 16.9589s	
24551/29850 (epoch 41.124), train_loss = 0.73036901, grad/param norm = 2.2648e-01, time/batch = 17.7059s	
24552/29850 (epoch 41.126), train_loss = 0.77859895, grad/param norm = 2.2451e-01, time/batch = 17.4550s	
24553/29850 (epoch 41.127), train_loss = 0.82682918, grad/param norm = 2.5614e-01, time/batch = 18.2187s	
24554/29850 (epoch 41.129), train_loss = 0.79974989, grad/param norm = 2.3111e-01, time/batch = 18.3856s	
24555/29850 (epoch 41.131), train_loss = 0.81285611, grad/param norm = 2.0620e-01, time/batch = 16.2086s	
24556/29850 (epoch 41.132), train_loss = 0.67934243, grad/param norm = 2.2378e-01, time/batch = 18.1318s	
24557/29850 (epoch 41.134), train_loss = 0.77350401, grad/param norm = 2.6217e-01, time/batch = 16.8772s	
24558/29850 (epoch 41.136), train_loss = 0.85584054, grad/param norm = 2.1608e-01, time/batch = 17.3668s	
24559/29850 (epoch 41.137), train_loss = 0.66673946, grad/param norm = 2.4369e-01, time/batch = 19.3637s	
24560/29850 (epoch 41.139), train_loss = 0.79152957, grad/param norm = 2.2522e-01, time/batch = 16.9025s	
24561/29850 (epoch 41.141), train_loss = 0.70534501, grad/param norm = 2.2238e-01, time/batch = 18.5338s	
24562/29850 (epoch 41.142), train_loss = 0.91462481, grad/param norm = 2.8243e-01, time/batch = 16.0571s	
24563/29850 (epoch 41.144), train_loss = 1.01825329, grad/param norm = 2.9862e-01, time/batch = 18.0544s	
24564/29850 (epoch 41.146), train_loss = 1.01111636, grad/param norm = 2.5904e-01, time/batch = 17.3787s	
24565/29850 (epoch 41.147), train_loss = 0.89706371, grad/param norm = 2.3760e-01, time/batch = 16.3086s	
24566/29850 (epoch 41.149), train_loss = 0.84429793, grad/param norm = 2.2776e-01, time/batch = 17.6321s	
24567/29850 (epoch 41.151), train_loss = 0.84542522, grad/param norm = 2.3000e-01, time/batch = 15.7150s	
24568/29850 (epoch 41.152), train_loss = 0.79779413, grad/param norm = 2.3541e-01, time/batch = 18.8628s	
24569/29850 (epoch 41.154), train_loss = 0.74614122, grad/param norm = 2.3316e-01, time/batch = 17.2503s	
24570/29850 (epoch 41.156), train_loss = 0.74817854, grad/param norm = 2.2001e-01, time/batch = 18.1206s	
24571/29850 (epoch 41.157), train_loss = 0.85077842, grad/param norm = 2.2874e-01, time/batch = 17.8587s	
24572/29850 (epoch 41.159), train_loss = 0.76581353, grad/param norm = 2.0360e-01, time/batch = 17.4453s	
24573/29850 (epoch 41.161), train_loss = 0.78564271, grad/param norm = 2.2669e-01, time/batch = 16.7704s	
24574/29850 (epoch 41.162), train_loss = 0.92989978, grad/param norm = 2.7031e-01, time/batch = 18.8835s	
24575/29850 (epoch 41.164), train_loss = 0.86621396, grad/param norm = 2.5446e-01, time/batch = 18.0387s	
24576/29850 (epoch 41.166), train_loss = 0.77881220, grad/param norm = 2.4007e-01, time/batch = 19.3021s	
24577/29850 (epoch 41.168), train_loss = 0.70368298, grad/param norm = 2.1548e-01, time/batch = 16.2686s	
24578/29850 (epoch 41.169), train_loss = 0.91800722, grad/param norm = 2.6348e-01, time/batch = 18.6931s	
24579/29850 (epoch 41.171), train_loss = 0.87276032, grad/param norm = 2.4308e-01, time/batch = 16.8832s	
24580/29850 (epoch 41.173), train_loss = 0.70074470, grad/param norm = 2.1677e-01, time/batch = 19.4685s	
24581/29850 (epoch 41.174), train_loss = 0.79200025, grad/param norm = 2.4374e-01, time/batch = 15.9785s	
24582/29850 (epoch 41.176), train_loss = 0.84157428, grad/param norm = 2.1630e-01, time/batch = 15.6394s	
24583/29850 (epoch 41.178), train_loss = 0.86474845, grad/param norm = 3.4000e-01, time/batch = 19.2261s	
24584/29850 (epoch 41.179), train_loss = 0.67001844, grad/param norm = 2.2472e-01, time/batch = 16.3975s	
24585/29850 (epoch 41.181), train_loss = 0.83132168, grad/param norm = 2.6913e-01, time/batch = 17.9475s	
24586/29850 (epoch 41.183), train_loss = 0.81673961, grad/param norm = 2.0485e-01, time/batch = 16.6186s	
24587/29850 (epoch 41.184), train_loss = 0.88405504, grad/param norm = 2.1933e-01, time/batch = 18.7084s	
24588/29850 (epoch 41.186), train_loss = 0.84997401, grad/param norm = 2.3357e-01, time/batch = 14.7407s	
24589/29850 (epoch 41.188), train_loss = 0.96766068, grad/param norm = 2.7067e-01, time/batch = 16.6120s	
24590/29850 (epoch 41.189), train_loss = 0.87649859, grad/param norm = 2.5598e-01, time/batch = 17.7611s	
24591/29850 (epoch 41.191), train_loss = 0.90351267, grad/param norm = 2.2005e-01, time/batch = 17.0569s	
24592/29850 (epoch 41.193), train_loss = 0.79317123, grad/param norm = 2.1640e-01, time/batch = 17.1369s	
24593/29850 (epoch 41.194), train_loss = 0.90324205, grad/param norm = 2.5841e-01, time/batch = 16.8842s	
24594/29850 (epoch 41.196), train_loss = 0.79662141, grad/param norm = 2.3004e-01, time/batch = 17.8036s	
24595/29850 (epoch 41.198), train_loss = 0.71913352, grad/param norm = 2.0262e-01, time/batch = 18.0460s	
24596/29850 (epoch 41.199), train_loss = 1.00986610, grad/param norm = 2.7050e-01, time/batch = 15.8781s	
24597/29850 (epoch 41.201), train_loss = 0.74691922, grad/param norm = 2.0134e-01, time/batch = 17.5513s	
24598/29850 (epoch 41.203), train_loss = 0.60780377, grad/param norm = 2.5005e-01, time/batch = 18.3891s	
24599/29850 (epoch 41.204), train_loss = 0.79700970, grad/param norm = 2.6096e-01, time/batch = 18.2912s	
24600/29850 (epoch 41.206), train_loss = 0.70905654, grad/param norm = 2.8379e-01, time/batch = 19.6399s	
24601/29850 (epoch 41.208), train_loss = 0.93667866, grad/param norm = 2.8113e-01, time/batch = 18.6090s	
24602/29850 (epoch 41.209), train_loss = 0.70151355, grad/param norm = 2.0819e-01, time/batch = 18.1135s	
24603/29850 (epoch 41.211), train_loss = 0.76269076, grad/param norm = 2.0819e-01, time/batch = 16.1557s	
24604/29850 (epoch 41.213), train_loss = 0.85139985, grad/param norm = 2.3535e-01, time/batch = 17.7047s	
24605/29850 (epoch 41.214), train_loss = 0.67734385, grad/param norm = 1.8148e-01, time/batch = 19.4566s	
24606/29850 (epoch 41.216), train_loss = 0.71161120, grad/param norm = 2.0302e-01, time/batch = 17.5303s	
24607/29850 (epoch 41.218), train_loss = 0.82301227, grad/param norm = 2.1315e-01, time/batch = 18.3904s	
24608/29850 (epoch 41.219), train_loss = 0.84065471, grad/param norm = 3.0024e-01, time/batch = 17.6363s	
24609/29850 (epoch 41.221), train_loss = 0.79750492, grad/param norm = 2.5322e-01, time/batch = 17.4612s	
24610/29850 (epoch 41.223), train_loss = 0.66581844, grad/param norm = 2.6528e-01, time/batch = 16.6215s	
24611/29850 (epoch 41.224), train_loss = 0.66651147, grad/param norm = 2.2910e-01, time/batch = 16.3067s	
24612/29850 (epoch 41.226), train_loss = 0.70746779, grad/param norm = 1.8717e-01, time/batch = 18.8621s	
24613/29850 (epoch 41.228), train_loss = 0.75690202, grad/param norm = 1.9373e-01, time/batch = 20.3723s	
24614/29850 (epoch 41.229), train_loss = 0.65721851, grad/param norm = 1.9602e-01, time/batch = 18.2935s	
24615/29850 (epoch 41.231), train_loss = 0.81867457, grad/param norm = 2.1671e-01, time/batch = 18.0475s	
24616/29850 (epoch 41.233), train_loss = 0.76312663, grad/param norm = 2.2138e-01, time/batch = 18.9490s	
24617/29850 (epoch 41.235), train_loss = 0.73698868, grad/param norm = 2.0680e-01, time/batch = 18.5440s	
24618/29850 (epoch 41.236), train_loss = 0.93437415, grad/param norm = 2.5173e-01, time/batch = 20.2817s	
24619/29850 (epoch 41.238), train_loss = 0.68395237, grad/param norm = 2.1705e-01, time/batch = 28.8652s	
24620/29850 (epoch 41.240), train_loss = 0.68278184, grad/param norm = 1.9683e-01, time/batch = 19.9536s	
24621/29850 (epoch 41.241), train_loss = 0.80050471, grad/param norm = 2.2858e-01, time/batch = 15.8811s	
24622/29850 (epoch 41.243), train_loss = 0.84082352, grad/param norm = 2.2003e-01, time/batch = 18.7023s	
24623/29850 (epoch 41.245), train_loss = 0.70774971, grad/param norm = 2.1347e-01, time/batch = 17.9561s	
24624/29850 (epoch 41.246), train_loss = 0.71255947, grad/param norm = 1.7898e-01, time/batch = 15.6981s	
24625/29850 (epoch 41.248), train_loss = 0.67853701, grad/param norm = 1.9669e-01, time/batch = 16.3068s	
24626/29850 (epoch 41.250), train_loss = 0.74022516, grad/param norm = 1.9416e-01, time/batch = 17.7871s	
24627/29850 (epoch 41.251), train_loss = 0.65743500, grad/param norm = 2.4043e-01, time/batch = 17.5261s	
24628/29850 (epoch 41.253), train_loss = 0.64711819, grad/param norm = 2.5981e-01, time/batch = 18.2030s	
24629/29850 (epoch 41.255), train_loss = 0.68677605, grad/param norm = 2.0405e-01, time/batch = 18.8663s	
24630/29850 (epoch 41.256), train_loss = 0.82805851, grad/param norm = 2.1835e-01, time/batch = 19.2906s	
24631/29850 (epoch 41.258), train_loss = 0.84648024, grad/param norm = 2.5788e-01, time/batch = 17.4684s	
24632/29850 (epoch 41.260), train_loss = 0.75827767, grad/param norm = 1.9854e-01, time/batch = 19.4121s	
24633/29850 (epoch 41.261), train_loss = 0.68794108, grad/param norm = 2.0728e-01, time/batch = 16.8913s	
24634/29850 (epoch 41.263), train_loss = 0.71412111, grad/param norm = 1.8986e-01, time/batch = 19.0397s	
24635/29850 (epoch 41.265), train_loss = 0.76322840, grad/param norm = 2.4233e-01, time/batch = 16.5355s	
24636/29850 (epoch 41.266), train_loss = 0.77928783, grad/param norm = 2.0378e-01, time/batch = 17.1163s	
24637/29850 (epoch 41.268), train_loss = 0.75651070, grad/param norm = 1.9974e-01, time/batch = 16.3957s	
24638/29850 (epoch 41.270), train_loss = 0.71197562, grad/param norm = 2.3669e-01, time/batch = 18.1194s	
24639/29850 (epoch 41.271), train_loss = 0.81082110, grad/param norm = 2.1033e-01, time/batch = 19.1221s	
24640/29850 (epoch 41.273), train_loss = 0.68443502, grad/param norm = 2.2523e-01, time/batch = 16.0483s	
24641/29850 (epoch 41.275), train_loss = 0.68142654, grad/param norm = 2.1305e-01, time/batch = 17.7891s	
24642/29850 (epoch 41.276), train_loss = 0.66304097, grad/param norm = 1.8339e-01, time/batch = 17.3672s	
24643/29850 (epoch 41.278), train_loss = 0.72670489, grad/param norm = 2.2004e-01, time/batch = 19.7040s	
24644/29850 (epoch 41.280), train_loss = 0.95306034, grad/param norm = 3.1937e-01, time/batch = 17.2750s	
24645/29850 (epoch 41.281), train_loss = 0.80180681, grad/param norm = 2.8404e-01, time/batch = 17.5501s	
24646/29850 (epoch 41.283), train_loss = 0.87162149, grad/param norm = 2.5432e-01, time/batch = 16.9460s	
24647/29850 (epoch 41.285), train_loss = 0.87498377, grad/param norm = 2.3196e-01, time/batch = 16.7345s	
24648/29850 (epoch 41.286), train_loss = 0.87259514, grad/param norm = 2.1757e-01, time/batch = 19.0358s	
24649/29850 (epoch 41.288), train_loss = 0.82884520, grad/param norm = 3.1157e-01, time/batch = 18.2144s	
24650/29850 (epoch 41.290), train_loss = 0.82183703, grad/param norm = 2.6887e-01, time/batch = 19.6079s	
24651/29850 (epoch 41.291), train_loss = 1.02774161, grad/param norm = 2.5620e-01, time/batch = 19.4444s	
24652/29850 (epoch 41.293), train_loss = 0.93342513, grad/param norm = 2.5497e-01, time/batch = 17.3564s	
24653/29850 (epoch 41.295), train_loss = 0.97894473, grad/param norm = 2.4968e-01, time/batch = 18.5353s	
24654/29850 (epoch 41.296), train_loss = 0.73302063, grad/param norm = 2.0200e-01, time/batch = 16.9727s	
24655/29850 (epoch 41.298), train_loss = 0.61912206, grad/param norm = 2.3449e-01, time/batch = 17.4737s	
24656/29850 (epoch 41.300), train_loss = 0.69670855, grad/param norm = 2.1051e-01, time/batch = 16.8561s	
24657/29850 (epoch 41.302), train_loss = 0.67075621, grad/param norm = 2.0091e-01, time/batch = 17.2184s	
24658/29850 (epoch 41.303), train_loss = 0.71679676, grad/param norm = 2.0704e-01, time/batch = 15.3705s	
24659/29850 (epoch 41.305), train_loss = 0.87534712, grad/param norm = 2.1829e-01, time/batch = 18.6830s	
24660/29850 (epoch 41.307), train_loss = 0.87432961, grad/param norm = 2.3488e-01, time/batch = 17.7936s	
24661/29850 (epoch 41.308), train_loss = 0.69115191, grad/param norm = 2.5139e-01, time/batch = 17.8730s	
24662/29850 (epoch 41.310), train_loss = 0.86404738, grad/param norm = 2.4769e-01, time/batch = 15.8720s	
24663/29850 (epoch 41.312), train_loss = 0.87808288, grad/param norm = 2.1874e-01, time/batch = 17.1445s	
24664/29850 (epoch 41.313), train_loss = 0.80594495, grad/param norm = 2.4685e-01, time/batch = 18.1369s	
24665/29850 (epoch 41.315), train_loss = 0.81951751, grad/param norm = 2.0323e-01, time/batch = 17.7833s	
24666/29850 (epoch 41.317), train_loss = 0.79774508, grad/param norm = 2.2462e-01, time/batch = 18.4617s	
24667/29850 (epoch 41.318), train_loss = 0.77930420, grad/param norm = 2.2982e-01, time/batch = 17.3957s	
24668/29850 (epoch 41.320), train_loss = 0.73351245, grad/param norm = 2.0663e-01, time/batch = 17.5600s	
24669/29850 (epoch 41.322), train_loss = 0.90790488, grad/param norm = 2.6297e-01, time/batch = 17.6063s	
24670/29850 (epoch 41.323), train_loss = 0.83109529, grad/param norm = 2.2384e-01, time/batch = 17.7811s	
24671/29850 (epoch 41.325), train_loss = 0.88569751, grad/param norm = 2.4721e-01, time/batch = 17.8697s	
24672/29850 (epoch 41.327), train_loss = 0.99622069, grad/param norm = 2.5504e-01, time/batch = 16.4151s	
24673/29850 (epoch 41.328), train_loss = 0.91867630, grad/param norm = 3.0155e-01, time/batch = 18.2058s	
24674/29850 (epoch 41.330), train_loss = 0.86774581, grad/param norm = 2.1484e-01, time/batch = 18.3853s	
24675/29850 (epoch 41.332), train_loss = 0.77541821, grad/param norm = 2.3354e-01, time/batch = 17.2858s	
24676/29850 (epoch 41.333), train_loss = 0.83352709, grad/param norm = 2.1753e-01, time/batch = 17.7197s	
24677/29850 (epoch 41.335), train_loss = 0.89209382, grad/param norm = 2.2425e-01, time/batch = 18.4497s	
24678/29850 (epoch 41.337), train_loss = 0.80886652, grad/param norm = 2.3787e-01, time/batch = 17.1961s	
24679/29850 (epoch 41.338), train_loss = 0.85767142, grad/param norm = 2.2819e-01, time/batch = 17.1089s	
24680/29850 (epoch 41.340), train_loss = 0.70311909, grad/param norm = 2.1054e-01, time/batch = 18.9697s	
24681/29850 (epoch 41.342), train_loss = 0.82870601, grad/param norm = 2.7709e-01, time/batch = 19.5411s	
24682/29850 (epoch 41.343), train_loss = 0.82286706, grad/param norm = 2.7430e-01, time/batch = 16.5488s	
24683/29850 (epoch 41.345), train_loss = 0.87500158, grad/param norm = 2.5188e-01, time/batch = 16.2660s	
24684/29850 (epoch 41.347), train_loss = 0.90670840, grad/param norm = 2.6640e-01, time/batch = 17.3022s	
24685/29850 (epoch 41.348), train_loss = 0.76827464, grad/param norm = 2.3831e-01, time/batch = 18.5534s	
24686/29850 (epoch 41.350), train_loss = 0.85201224, grad/param norm = 2.2907e-01, time/batch = 15.9209s	
24687/29850 (epoch 41.352), train_loss = 0.77293018, grad/param norm = 2.2358e-01, time/batch = 18.2009s	
24688/29850 (epoch 41.353), train_loss = 0.83802315, grad/param norm = 2.3348e-01, time/batch = 18.5503s	
24689/29850 (epoch 41.355), train_loss = 0.74313804, grad/param norm = 2.2036e-01, time/batch = 17.0432s	
24690/29850 (epoch 41.357), train_loss = 0.89474941, grad/param norm = 2.4480e-01, time/batch = 19.2875s	
24691/29850 (epoch 41.358), train_loss = 0.73188297, grad/param norm = 2.0187e-01, time/batch = 19.2736s	
24692/29850 (epoch 41.360), train_loss = 0.80189352, grad/param norm = 2.3453e-01, time/batch = 16.8743s	
24693/29850 (epoch 41.362), train_loss = 0.81658680, grad/param norm = 2.5197e-01, time/batch = 15.0649s	
24694/29850 (epoch 41.363), train_loss = 0.83979956, grad/param norm = 2.4857e-01, time/batch = 16.8777s	
24695/29850 (epoch 41.365), train_loss = 0.92898034, grad/param norm = 2.6822e-01, time/batch = 18.0038s	
24696/29850 (epoch 41.367), train_loss = 0.72868146, grad/param norm = 2.0355e-01, time/batch = 16.7674s	
24697/29850 (epoch 41.369), train_loss = 0.65850870, grad/param norm = 2.2872e-01, time/batch = 19.6313s	
24698/29850 (epoch 41.370), train_loss = 0.69073619, grad/param norm = 2.3008e-01, time/batch = 16.6403s	
24699/29850 (epoch 41.372), train_loss = 0.91270059, grad/param norm = 2.4736e-01, time/batch = 18.3645s	
24700/29850 (epoch 41.374), train_loss = 0.88916524, grad/param norm = 2.2928e-01, time/batch = 18.3709s	
24701/29850 (epoch 41.375), train_loss = 0.81624641, grad/param norm = 2.0186e-01, time/batch = 18.2983s	
24702/29850 (epoch 41.377), train_loss = 0.69130052, grad/param norm = 2.0553e-01, time/batch = 17.9602s	
24703/29850 (epoch 41.379), train_loss = 0.92203809, grad/param norm = 2.5916e-01, time/batch = 18.2936s	
24704/29850 (epoch 41.380), train_loss = 0.86495856, grad/param norm = 2.8343e-01, time/batch = 16.8811s	
24705/29850 (epoch 41.382), train_loss = 0.83014438, grad/param norm = 2.5917e-01, time/batch = 14.6326s	
24706/29850 (epoch 41.384), train_loss = 0.86918846, grad/param norm = 2.2625e-01, time/batch = 16.1439s	
24707/29850 (epoch 41.385), train_loss = 0.85035436, grad/param norm = 2.4626e-01, time/batch = 18.2994s	
24708/29850 (epoch 41.387), train_loss = 0.84067578, grad/param norm = 2.5250e-01, time/batch = 18.4672s	
24709/29850 (epoch 41.389), train_loss = 0.93107255, grad/param norm = 2.5480e-01, time/batch = 16.4438s	
24710/29850 (epoch 41.390), train_loss = 0.87481763, grad/param norm = 2.1144e-01, time/batch = 18.3732s	
24711/29850 (epoch 41.392), train_loss = 0.80304118, grad/param norm = 2.3851e-01, time/batch = 16.9539s	
24712/29850 (epoch 41.394), train_loss = 0.86656316, grad/param norm = 2.0669e-01, time/batch = 18.1279s	
24713/29850 (epoch 41.395), train_loss = 0.74156711, grad/param norm = 2.4928e-01, time/batch = 18.2013s	
24714/29850 (epoch 41.397), train_loss = 0.68954960, grad/param norm = 2.4719e-01, time/batch = 18.8881s	
24715/29850 (epoch 41.399), train_loss = 0.75819189, grad/param norm = 2.5746e-01, time/batch = 17.1253s	
24716/29850 (epoch 41.400), train_loss = 1.06759161, grad/param norm = 2.5158e-01, time/batch = 17.6928s	
24717/29850 (epoch 41.402), train_loss = 0.95030722, grad/param norm = 2.4467e-01, time/batch = 18.1226s	
24718/29850 (epoch 41.404), train_loss = 0.83352913, grad/param norm = 2.3131e-01, time/batch = 19.4607s	
24719/29850 (epoch 41.405), train_loss = 0.75521882, grad/param norm = 2.3467e-01, time/batch = 17.9332s	
24720/29850 (epoch 41.407), train_loss = 0.74561064, grad/param norm = 2.1900e-01, time/batch = 17.5488s	
24721/29850 (epoch 41.409), train_loss = 0.84428251, grad/param norm = 2.6276e-01, time/batch = 14.5770s	
24722/29850 (epoch 41.410), train_loss = 0.91959246, grad/param norm = 2.5203e-01, time/batch = 17.3132s	
24723/29850 (epoch 41.412), train_loss = 0.91451322, grad/param norm = 2.3100e-01, time/batch = 16.0489s	
24724/29850 (epoch 41.414), train_loss = 0.85901529, grad/param norm = 2.5152e-01, time/batch = 17.5532s	
24725/29850 (epoch 41.415), train_loss = 0.81034450, grad/param norm = 1.9853e-01, time/batch = 18.9564s	
24726/29850 (epoch 41.417), train_loss = 0.94683017, grad/param norm = 2.5063e-01, time/batch = 17.2924s	
24727/29850 (epoch 41.419), train_loss = 0.78770459, grad/param norm = 2.1046e-01, time/batch = 19.1119s	
24728/29850 (epoch 41.420), train_loss = 0.81292665, grad/param norm = 2.3217e-01, time/batch = 17.2820s	
24729/29850 (epoch 41.422), train_loss = 0.81697605, grad/param norm = 2.2501e-01, time/batch = 15.3490s	
24730/29850 (epoch 41.424), train_loss = 0.73261219, grad/param norm = 2.1796e-01, time/batch = 17.3719s	
24731/29850 (epoch 41.425), train_loss = 0.88659375, grad/param norm = 2.6180e-01, time/batch = 19.2857s	
24732/29850 (epoch 41.427), train_loss = 0.61974781, grad/param norm = 2.1521e-01, time/batch = 18.5398s	
24733/29850 (epoch 41.429), train_loss = 0.72988274, grad/param norm = 2.5094e-01, time/batch = 17.1229s	
24734/29850 (epoch 41.430), train_loss = 0.66143578, grad/param norm = 1.8161e-01, time/batch = 18.2262s	
24735/29850 (epoch 41.432), train_loss = 0.79575492, grad/param norm = 2.8530e-01, time/batch = 19.2943s	
24736/29850 (epoch 41.434), train_loss = 0.76130565, grad/param norm = 2.2809e-01, time/batch = 18.1208s	
24737/29850 (epoch 41.436), train_loss = 0.78498762, grad/param norm = 2.5051e-01, time/batch = 17.9343s	
24738/29850 (epoch 41.437), train_loss = 0.86618685, grad/param norm = 2.3629e-01, time/batch = 17.1554s	
24739/29850 (epoch 41.439), train_loss = 0.86548229, grad/param norm = 2.1635e-01, time/batch = 17.6165s	
24740/29850 (epoch 41.441), train_loss = 0.82326369, grad/param norm = 2.4819e-01, time/batch = 17.1930s	
24741/29850 (epoch 41.442), train_loss = 0.76798122, grad/param norm = 2.3187e-01, time/batch = 17.5308s	
24742/29850 (epoch 41.444), train_loss = 0.83537265, grad/param norm = 2.8709e-01, time/batch = 16.7814s	
24743/29850 (epoch 41.446), train_loss = 0.89860207, grad/param norm = 2.4939e-01, time/batch = 16.6377s	
24744/29850 (epoch 41.447), train_loss = 0.88890149, grad/param norm = 2.3729e-01, time/batch = 17.9648s	
24745/29850 (epoch 41.449), train_loss = 0.82689882, grad/param norm = 2.3967e-01, time/batch = 16.3534s	
24746/29850 (epoch 41.451), train_loss = 0.65278576, grad/param norm = 2.0783e-01, time/batch = 18.7596s	
24747/29850 (epoch 41.452), train_loss = 0.56258063, grad/param norm = 1.9351e-01, time/batch = 17.4662s	
24748/29850 (epoch 41.454), train_loss = 0.67843559, grad/param norm = 2.0362e-01, time/batch = 18.9652s	
24749/29850 (epoch 41.456), train_loss = 0.87471933, grad/param norm = 2.7559e-01, time/batch = 18.1292s	
24750/29850 (epoch 41.457), train_loss = 0.91450707, grad/param norm = 3.7898e-01, time/batch = 16.3088s	
24751/29850 (epoch 41.459), train_loss = 0.94794723, grad/param norm = 2.8748e-01, time/batch = 18.0508s	
24752/29850 (epoch 41.461), train_loss = 0.95186707, grad/param norm = 2.6226e-01, time/batch = 18.3847s	
24753/29850 (epoch 41.462), train_loss = 0.95654117, grad/param norm = 2.4056e-01, time/batch = 17.5223s	
24754/29850 (epoch 41.464), train_loss = 0.83579439, grad/param norm = 2.2919e-01, time/batch = 16.3923s	
24755/29850 (epoch 41.466), train_loss = 0.70804611, grad/param norm = 2.1081e-01, time/batch = 17.7933s	
24756/29850 (epoch 41.467), train_loss = 0.72861395, grad/param norm = 2.1253e-01, time/batch = 18.2181s	
24757/29850 (epoch 41.469), train_loss = 0.79825191, grad/param norm = 2.2423e-01, time/batch = 17.0400s	
24758/29850 (epoch 41.471), train_loss = 0.78401481, grad/param norm = 2.4041e-01, time/batch = 19.8646s	
24759/29850 (epoch 41.472), train_loss = 0.75005154, grad/param norm = 2.1879e-01, time/batch = 17.5291s	
24760/29850 (epoch 41.474), train_loss = 0.88917145, grad/param norm = 2.2870e-01, time/batch = 16.2992s	
24761/29850 (epoch 41.476), train_loss = 0.81522380, grad/param norm = 1.9538e-01, time/batch = 16.8875s	
24762/29850 (epoch 41.477), train_loss = 0.84227371, grad/param norm = 2.6291e-01, time/batch = 15.3495s	
24763/29850 (epoch 41.479), train_loss = 0.97352858, grad/param norm = 2.3120e-01, time/batch = 18.6243s	
24764/29850 (epoch 41.481), train_loss = 0.81105191, grad/param norm = 2.1679e-01, time/batch = 16.2123s	
24765/29850 (epoch 41.482), train_loss = 0.76484389, grad/param norm = 2.0899e-01, time/batch = 17.7966s	
24766/29850 (epoch 41.484), train_loss = 0.76097193, grad/param norm = 1.9913e-01, time/batch = 18.7139s	
24767/29850 (epoch 41.486), train_loss = 0.87137497, grad/param norm = 2.7344e-01, time/batch = 16.7047s	
24768/29850 (epoch 41.487), train_loss = 0.82276167, grad/param norm = 2.1286e-01, time/batch = 18.4722s	
24769/29850 (epoch 41.489), train_loss = 0.81434649, grad/param norm = 2.2761e-01, time/batch = 19.3824s	
24770/29850 (epoch 41.491), train_loss = 0.73889388, grad/param norm = 2.3234e-01, time/batch = 17.9609s	
24771/29850 (epoch 41.492), train_loss = 0.81323034, grad/param norm = 2.3218e-01, time/batch = 15.5199s	
24772/29850 (epoch 41.494), train_loss = 0.88645282, grad/param norm = 2.6045e-01, time/batch = 17.0648s	
24773/29850 (epoch 41.496), train_loss = 0.94205846, grad/param norm = 2.4994e-01, time/batch = 18.0549s	
24774/29850 (epoch 41.497), train_loss = 0.84809352, grad/param norm = 2.8352e-01, time/batch = 15.1312s	
24775/29850 (epoch 41.499), train_loss = 0.81550367, grad/param norm = 2.2221e-01, time/batch = 16.2841s	
24776/29850 (epoch 41.501), train_loss = 0.71225050, grad/param norm = 2.4514e-01, time/batch = 17.2150s	
24777/29850 (epoch 41.503), train_loss = 0.87557104, grad/param norm = 2.1544e-01, time/batch = 17.6202s	
24778/29850 (epoch 41.504), train_loss = 1.04070250, grad/param norm = 2.3720e-01, time/batch = 17.8042s	
24779/29850 (epoch 41.506), train_loss = 1.02372788, grad/param norm = 2.6400e-01, time/batch = 16.8059s	
24780/29850 (epoch 41.508), train_loss = 0.85305186, grad/param norm = 2.3052e-01, time/batch = 19.2817s	
24781/29850 (epoch 41.509), train_loss = 0.66464402, grad/param norm = 2.0181e-01, time/batch = 18.2779s	
24782/29850 (epoch 41.511), train_loss = 0.88073917, grad/param norm = 2.5103e-01, time/batch = 18.6386s	
24783/29850 (epoch 41.513), train_loss = 0.82412210, grad/param norm = 3.0385e-01, time/batch = 18.6369s	
24784/29850 (epoch 41.514), train_loss = 0.71974731, grad/param norm = 2.2369e-01, time/batch = 15.6808s	
24785/29850 (epoch 41.516), train_loss = 0.77316050, grad/param norm = 1.9438e-01, time/batch = 18.7895s	
24786/29850 (epoch 41.518), train_loss = 0.64586872, grad/param norm = 1.9285e-01, time/batch = 18.5533s	
24787/29850 (epoch 41.519), train_loss = 0.66838522, grad/param norm = 2.0252e-01, time/batch = 17.1957s	
24788/29850 (epoch 41.521), train_loss = 0.61464164, grad/param norm = 1.7996e-01, time/batch = 18.3867s	
24789/29850 (epoch 41.523), train_loss = 0.67645007, grad/param norm = 1.9520e-01, time/batch = 17.0552s	
24790/29850 (epoch 41.524), train_loss = 0.70029941, grad/param norm = 2.0898e-01, time/batch = 17.8182s	
24791/29850 (epoch 41.526), train_loss = 0.76128359, grad/param norm = 2.5227e-01, time/batch = 19.3492s	
24792/29850 (epoch 41.528), train_loss = 0.84764844, grad/param norm = 1.9600e-01, time/batch = 18.2854s	
24793/29850 (epoch 41.529), train_loss = 0.81957317, grad/param norm = 2.3211e-01, time/batch = 18.3795s	
24794/29850 (epoch 41.531), train_loss = 0.80385783, grad/param norm = 2.8645e-01, time/batch = 16.6932s	
24795/29850 (epoch 41.533), train_loss = 0.82463249, grad/param norm = 2.4912e-01, time/batch = 18.4515s	
24796/29850 (epoch 41.534), train_loss = 0.87631164, grad/param norm = 2.4713e-01, time/batch = 16.3768s	
24797/29850 (epoch 41.536), train_loss = 0.76126629, grad/param norm = 2.9767e-01, time/batch = 16.5422s	
24798/29850 (epoch 41.538), train_loss = 0.93253932, grad/param norm = 2.7369e-01, time/batch = 14.4114s	
24799/29850 (epoch 41.539), train_loss = 0.94809014, grad/param norm = 2.6549e-01, time/batch = 18.3030s	
24800/29850 (epoch 41.541), train_loss = 0.59611127, grad/param norm = 1.9925e-01, time/batch = 19.0596s	
24801/29850 (epoch 41.543), train_loss = 0.76769814, grad/param norm = 2.3491e-01, time/batch = 16.6274s	
24802/29850 (epoch 41.544), train_loss = 0.91238367, grad/param norm = 2.7529e-01, time/batch = 18.9545s	
24803/29850 (epoch 41.546), train_loss = 0.86736423, grad/param norm = 2.4029e-01, time/batch = 19.4611s	
24804/29850 (epoch 41.548), train_loss = 0.69702730, grad/param norm = 2.1362e-01, time/batch = 16.3757s	
24805/29850 (epoch 41.549), train_loss = 0.78238325, grad/param norm = 2.1331e-01, time/batch = 17.5398s	
24806/29850 (epoch 41.551), train_loss = 0.72535375, grad/param norm = 2.2624e-01, time/batch = 15.6025s	
24807/29850 (epoch 41.553), train_loss = 0.79678891, grad/param norm = 2.4455e-01, time/batch = 17.6180s	
24808/29850 (epoch 41.554), train_loss = 0.65546987, grad/param norm = 1.9520e-01, time/batch = 15.7905s	
24809/29850 (epoch 41.556), train_loss = 0.69508732, grad/param norm = 2.2822e-01, time/batch = 19.7933s	
24810/29850 (epoch 41.558), train_loss = 0.71979850, grad/param norm = 2.2319e-01, time/batch = 18.9542s	
24811/29850 (epoch 41.559), train_loss = 0.71779451, grad/param norm = 2.1132e-01, time/batch = 16.6435s	
24812/29850 (epoch 41.561), train_loss = 0.82250817, grad/param norm = 2.3534e-01, time/batch = 18.5574s	
24813/29850 (epoch 41.563), train_loss = 0.82615470, grad/param norm = 2.2951e-01, time/batch = 15.4697s	
24814/29850 (epoch 41.564), train_loss = 0.77138841, grad/param norm = 2.3501e-01, time/batch = 17.5370s	
24815/29850 (epoch 41.566), train_loss = 0.78627452, grad/param norm = 2.1920e-01, time/batch = 16.3635s	
24816/29850 (epoch 41.568), train_loss = 0.93298558, grad/param norm = 2.4875e-01, time/batch = 19.0455s	
24817/29850 (epoch 41.570), train_loss = 0.82253659, grad/param norm = 2.1137e-01, time/batch = 18.1289s	
24818/29850 (epoch 41.571), train_loss = 0.88204622, grad/param norm = 2.1876e-01, time/batch = 17.3677s	
24819/29850 (epoch 41.573), train_loss = 0.93722857, grad/param norm = 2.4366e-01, time/batch = 17.3744s	
24820/29850 (epoch 41.575), train_loss = 0.99653247, grad/param norm = 2.3560e-01, time/batch = 18.3044s	
24821/29850 (epoch 41.576), train_loss = 0.87777109, grad/param norm = 2.2768e-01, time/batch = 24.8550s	
24822/29850 (epoch 41.578), train_loss = 0.75304310, grad/param norm = 2.1766e-01, time/batch = 23.8205s	
24823/29850 (epoch 41.580), train_loss = 0.89752588, grad/param norm = 2.2330e-01, time/batch = 16.0486s	
24824/29850 (epoch 41.581), train_loss = 0.73279136, grad/param norm = 1.8766e-01, time/batch = 15.5108s	
24825/29850 (epoch 41.583), train_loss = 0.80691325, grad/param norm = 2.4151e-01, time/batch = 18.2097s	
24826/29850 (epoch 41.585), train_loss = 0.81863592, grad/param norm = 2.2918e-01, time/batch = 16.6407s	
24827/29850 (epoch 41.586), train_loss = 0.86113881, grad/param norm = 2.9651e-01, time/batch = 16.1087s	
24828/29850 (epoch 41.588), train_loss = 0.74498383, grad/param norm = 2.0861e-01, time/batch = 15.1993s	
24829/29850 (epoch 41.590), train_loss = 0.74926979, grad/param norm = 2.0745e-01, time/batch = 16.4018s	
24830/29850 (epoch 41.591), train_loss = 0.79127791, grad/param norm = 2.5063e-01, time/batch = 15.1318s	
24831/29850 (epoch 41.593), train_loss = 0.70723532, grad/param norm = 2.1466e-01, time/batch = 16.2906s	
24832/29850 (epoch 41.595), train_loss = 0.68124753, grad/param norm = 2.0855e-01, time/batch = 15.7210s	
24833/29850 (epoch 41.596), train_loss = 0.70869327, grad/param norm = 2.3324e-01, time/batch = 19.8604s	
24834/29850 (epoch 41.598), train_loss = 0.77749417, grad/param norm = 2.1884e-01, time/batch = 17.7154s	
24835/29850 (epoch 41.600), train_loss = 0.82172257, grad/param norm = 2.1689e-01, time/batch = 16.2737s	
24836/29850 (epoch 41.601), train_loss = 0.68211289, grad/param norm = 2.0175e-01, time/batch = 16.6419s	
24837/29850 (epoch 41.603), train_loss = 0.74296405, grad/param norm = 2.0556e-01, time/batch = 19.3724s	
24838/29850 (epoch 41.605), train_loss = 0.77118848, grad/param norm = 2.1765e-01, time/batch = 16.1150s	
24839/29850 (epoch 41.606), train_loss = 0.53712837, grad/param norm = 1.8115e-01, time/batch = 17.4703s	
24840/29850 (epoch 41.608), train_loss = 0.67926346, grad/param norm = 2.1424e-01, time/batch = 17.5587s	
24841/29850 (epoch 41.610), train_loss = 0.74925468, grad/param norm = 2.0597e-01, time/batch = 17.7907s	
24842/29850 (epoch 41.611), train_loss = 0.68255309, grad/param norm = 1.9901e-01, time/batch = 15.4360s	
24843/29850 (epoch 41.613), train_loss = 0.59275060, grad/param norm = 1.7667e-01, time/batch = 16.5656s	
24844/29850 (epoch 41.615), train_loss = 0.65606961, grad/param norm = 2.1024e-01, time/batch = 18.7997s	
24845/29850 (epoch 41.616), train_loss = 0.68938597, grad/param norm = 2.2792e-01, time/batch = 15.9558s	
24846/29850 (epoch 41.618), train_loss = 0.74264986, grad/param norm = 2.1227e-01, time/batch = 17.5533s	
24847/29850 (epoch 41.620), train_loss = 0.83243320, grad/param norm = 2.4964e-01, time/batch = 15.3634s	
24848/29850 (epoch 41.621), train_loss = 0.90233534, grad/param norm = 2.5865e-01, time/batch = 19.0429s	
24849/29850 (epoch 41.623), train_loss = 0.86865580, grad/param norm = 2.1176e-01, time/batch = 17.3639s	
24850/29850 (epoch 41.625), train_loss = 0.81002887, grad/param norm = 2.4640e-01, time/batch = 19.3050s	
24851/29850 (epoch 41.626), train_loss = 0.80664052, grad/param norm = 2.4975e-01, time/batch = 18.5137s	
24852/29850 (epoch 41.628), train_loss = 0.78726797, grad/param norm = 2.6101e-01, time/batch = 15.0119s	
24853/29850 (epoch 41.630), train_loss = 0.80971292, grad/param norm = 2.4634e-01, time/batch = 16.6239s	
24854/29850 (epoch 41.631), train_loss = 0.82286342, grad/param norm = 2.4754e-01, time/batch = 15.3038s	
24855/29850 (epoch 41.633), train_loss = 0.82313250, grad/param norm = 2.5119e-01, time/batch = 15.8341s	
24856/29850 (epoch 41.635), train_loss = 0.74704863, grad/param norm = 2.2915e-01, time/batch = 15.6193s	
24857/29850 (epoch 41.637), train_loss = 0.69762179, grad/param norm = 2.0438e-01, time/batch = 17.7147s	
24858/29850 (epoch 41.638), train_loss = 0.84297994, grad/param norm = 2.8906e-01, time/batch = 17.6406s	
24859/29850 (epoch 41.640), train_loss = 0.95168684, grad/param norm = 2.8952e-01, time/batch = 15.7870s	
24860/29850 (epoch 41.642), train_loss = 0.76261468, grad/param norm = 2.1826e-01, time/batch = 16.8860s	
24861/29850 (epoch 41.643), train_loss = 0.72006090, grad/param norm = 2.2944e-01, time/batch = 17.8876s	
24862/29850 (epoch 41.645), train_loss = 0.77877520, grad/param norm = 2.0783e-01, time/batch = 18.4557s	
24863/29850 (epoch 41.647), train_loss = 0.91338961, grad/param norm = 2.4707e-01, time/batch = 18.4560s	
24864/29850 (epoch 41.648), train_loss = 0.70374692, grad/param norm = 2.1161e-01, time/batch = 16.3067s	
24865/29850 (epoch 41.650), train_loss = 0.84039453, grad/param norm = 2.2458e-01, time/batch = 15.6329s	
24866/29850 (epoch 41.652), train_loss = 0.81205895, grad/param norm = 2.4688e-01, time/batch = 15.9623s	
24867/29850 (epoch 41.653), train_loss = 0.88600999, grad/param norm = 4.0745e-01, time/batch = 15.9326s	
24868/29850 (epoch 41.655), train_loss = 0.82037731, grad/param norm = 2.1881e-01, time/batch = 15.4728s	
24869/29850 (epoch 41.657), train_loss = 0.80701799, grad/param norm = 2.1052e-01, time/batch = 19.3839s	
24870/29850 (epoch 41.658), train_loss = 0.90261436, grad/param norm = 2.4753e-01, time/batch = 15.4844s	
24871/29850 (epoch 41.660), train_loss = 0.77814238, grad/param norm = 2.8656e-01, time/batch = 15.4902s	
24872/29850 (epoch 41.662), train_loss = 0.91210973, grad/param norm = 2.7553e-01, time/batch = 15.2047s	
24873/29850 (epoch 41.663), train_loss = 1.00635698, grad/param norm = 2.4726e-01, time/batch = 17.7649s	
24874/29850 (epoch 41.665), train_loss = 0.92814486, grad/param norm = 2.8091e-01, time/batch = 18.1939s	
24875/29850 (epoch 41.667), train_loss = 0.86857686, grad/param norm = 2.4675e-01, time/batch = 16.7227s	
24876/29850 (epoch 41.668), train_loss = 0.76448550, grad/param norm = 2.2650e-01, time/batch = 18.4610s	
24877/29850 (epoch 41.670), train_loss = 0.86996162, grad/param norm = 2.9146e-01, time/batch = 17.1368s	
24878/29850 (epoch 41.672), train_loss = 0.90589709, grad/param norm = 2.7355e-01, time/batch = 18.7165s	
24879/29850 (epoch 41.673), train_loss = 0.83583092, grad/param norm = 2.6516e-01, time/batch = 17.6331s	
24880/29850 (epoch 41.675), train_loss = 0.71333968, grad/param norm = 1.9748e-01, time/batch = 17.8874s	
24881/29850 (epoch 41.677), train_loss = 0.75710440, grad/param norm = 2.3946e-01, time/batch = 18.4596s	
24882/29850 (epoch 41.678), train_loss = 0.79467491, grad/param norm = 2.1562e-01, time/batch = 16.2563s	
24883/29850 (epoch 41.680), train_loss = 0.79397155, grad/param norm = 2.3817e-01, time/batch = 18.3731s	
24884/29850 (epoch 41.682), train_loss = 0.79999606, grad/param norm = 2.6995e-01, time/batch = 17.2897s	
24885/29850 (epoch 41.683), train_loss = 0.92175597, grad/param norm = 3.3525e-01, time/batch = 18.5381s	
24886/29850 (epoch 41.685), train_loss = 1.00875010, grad/param norm = 2.9830e-01, time/batch = 15.2557s	
24887/29850 (epoch 41.687), train_loss = 0.86297398, grad/param norm = 2.5218e-01, time/batch = 14.6431s	
24888/29850 (epoch 41.688), train_loss = 0.73006947, grad/param norm = 2.3705e-01, time/batch = 15.2830s	
24889/29850 (epoch 41.690), train_loss = 0.73170575, grad/param norm = 2.4178e-01, time/batch = 15.4047s	
24890/29850 (epoch 41.692), train_loss = 0.91060212, grad/param norm = 2.3941e-01, time/batch = 14.4870s	
24891/29850 (epoch 41.693), train_loss = 0.82074736, grad/param norm = 2.1067e-01, time/batch = 15.4173s	
24892/29850 (epoch 41.695), train_loss = 0.71157185, grad/param norm = 1.7903e-01, time/batch = 14.2608s	
24893/29850 (epoch 41.697), train_loss = 0.81077071, grad/param norm = 2.3996e-01, time/batch = 14.1631s	
24894/29850 (epoch 41.698), train_loss = 0.91557841, grad/param norm = 2.2050e-01, time/batch = 14.5536s	
24895/29850 (epoch 41.700), train_loss = 0.86082546, grad/param norm = 2.7638e-01, time/batch = 14.3209s	
24896/29850 (epoch 41.702), train_loss = 0.81797263, grad/param norm = 2.5317e-01, time/batch = 14.4952s	
24897/29850 (epoch 41.704), train_loss = 0.69791723, grad/param norm = 1.9422e-01, time/batch = 14.4955s	
24898/29850 (epoch 41.705), train_loss = 0.80999242, grad/param norm = 2.4071e-01, time/batch = 14.0922s	
24899/29850 (epoch 41.707), train_loss = 0.74373811, grad/param norm = 2.2049e-01, time/batch = 14.3292s	
24900/29850 (epoch 41.709), train_loss = 0.79878548, grad/param norm = 2.6176e-01, time/batch = 14.2447s	
24901/29850 (epoch 41.710), train_loss = 0.73036732, grad/param norm = 2.1241e-01, time/batch = 14.1707s	
24902/29850 (epoch 41.712), train_loss = 0.84250802, grad/param norm = 2.0113e-01, time/batch = 14.7048s	
24903/29850 (epoch 41.714), train_loss = 0.90230234, grad/param norm = 3.0029e-01, time/batch = 13.9132s	
24904/29850 (epoch 41.715), train_loss = 0.83079985, grad/param norm = 2.1968e-01, time/batch = 14.5568s	
24905/29850 (epoch 41.717), train_loss = 0.61674283, grad/param norm = 2.1385e-01, time/batch = 14.0096s	
24906/29850 (epoch 41.719), train_loss = 0.76645300, grad/param norm = 2.2105e-01, time/batch = 14.6866s	
24907/29850 (epoch 41.720), train_loss = 0.78757152, grad/param norm = 2.0509e-01, time/batch = 14.6791s	
24908/29850 (epoch 41.722), train_loss = 0.72207786, grad/param norm = 1.8146e-01, time/batch = 14.7771s	
24909/29850 (epoch 41.724), train_loss = 0.83635075, grad/param norm = 2.6016e-01, time/batch = 15.2369s	
24910/29850 (epoch 41.725), train_loss = 0.70093155, grad/param norm = 2.0503e-01, time/batch = 14.8004s	
24911/29850 (epoch 41.727), train_loss = 0.68892781, grad/param norm = 2.4615e-01, time/batch = 14.2491s	
24912/29850 (epoch 41.729), train_loss = 0.66607193, grad/param norm = 1.8118e-01, time/batch = 20.3235s	
24913/29850 (epoch 41.730), train_loss = 0.63842419, grad/param norm = 1.9077e-01, time/batch = 20.9142s	
24914/29850 (epoch 41.732), train_loss = 0.89336908, grad/param norm = 2.2857e-01, time/batch = 20.4349s	
24915/29850 (epoch 41.734), train_loss = 0.98033823, grad/param norm = 2.9752e-01, time/batch = 22.1510s	
24916/29850 (epoch 41.735), train_loss = 0.73993634, grad/param norm = 2.4119e-01, time/batch = 21.7476s	
24917/29850 (epoch 41.737), train_loss = 0.69859240, grad/param norm = 2.3824e-01, time/batch = 21.1056s	
24918/29850 (epoch 41.739), train_loss = 0.61388098, grad/param norm = 2.0290e-01, time/batch = 21.2637s	
24919/29850 (epoch 41.740), train_loss = 0.65462205, grad/param norm = 2.1245e-01, time/batch = 19.1192s	
24920/29850 (epoch 41.742), train_loss = 0.59550942, grad/param norm = 1.7995e-01, time/batch = 19.7169s	
24921/29850 (epoch 41.744), train_loss = 0.71928082, grad/param norm = 2.4039e-01, time/batch = 20.2099s	
24922/29850 (epoch 41.745), train_loss = 0.74494771, grad/param norm = 2.6631e-01, time/batch = 20.7478s	
24923/29850 (epoch 41.747), train_loss = 0.78347055, grad/param norm = 2.0673e-01, time/batch = 20.9557s	
24924/29850 (epoch 41.749), train_loss = 0.66292471, grad/param norm = 2.1280e-01, time/batch = 21.9621s	
24925/29850 (epoch 41.750), train_loss = 0.60599594, grad/param norm = 2.0047e-01, time/batch = 20.3727s	
24926/29850 (epoch 41.752), train_loss = 0.54707530, grad/param norm = 1.8765e-01, time/batch = 21.0102s	
24927/29850 (epoch 41.754), train_loss = 0.59169511, grad/param norm = 1.9819e-01, time/batch = 21.8204s	
24928/29850 (epoch 41.755), train_loss = 0.63175377, grad/param norm = 2.2803e-01, time/batch = 21.0206s	
24929/29850 (epoch 41.757), train_loss = 0.67902739, grad/param norm = 1.9421e-01, time/batch = 20.2010s	
24930/29850 (epoch 41.759), train_loss = 0.67694258, grad/param norm = 2.3388e-01, time/batch = 21.9789s	
24931/29850 (epoch 41.760), train_loss = 0.70351278, grad/param norm = 2.5585e-01, time/batch = 22.2791s	
24932/29850 (epoch 41.762), train_loss = 0.63235916, grad/param norm = 2.2815e-01, time/batch = 22.3621s	
24933/29850 (epoch 41.764), train_loss = 0.56744943, grad/param norm = 2.2532e-01, time/batch = 28.3112s	
24934/29850 (epoch 41.765), train_loss = 0.71437878, grad/param norm = 2.2201e-01, time/batch = 18.2283s	
24935/29850 (epoch 41.767), train_loss = 0.70701845, grad/param norm = 2.0406e-01, time/batch = 15.4736s	
24936/29850 (epoch 41.769), train_loss = 0.75379904, grad/param norm = 2.1189e-01, time/batch = 15.1354s	
24937/29850 (epoch 41.771), train_loss = 0.76226530, grad/param norm = 2.0814e-01, time/batch = 15.1575s	
24938/29850 (epoch 41.772), train_loss = 0.75909838, grad/param norm = 2.4288e-01, time/batch = 15.4895s	
24939/29850 (epoch 41.774), train_loss = 0.70251257, grad/param norm = 2.0852e-01, time/batch = 15.4838s	
24940/29850 (epoch 41.776), train_loss = 0.74082431, grad/param norm = 2.3108e-01, time/batch = 15.3508s	
24941/29850 (epoch 41.777), train_loss = 0.83859402, grad/param norm = 2.4680e-01, time/batch = 15.6863s	
24942/29850 (epoch 41.779), train_loss = 0.67968767, grad/param norm = 1.9954e-01, time/batch = 15.9146s	
24943/29850 (epoch 41.781), train_loss = 0.80082463, grad/param norm = 2.3370e-01, time/batch = 15.1430s	
24944/29850 (epoch 41.782), train_loss = 0.79632937, grad/param norm = 2.1584e-01, time/batch = 15.4444s	
24945/29850 (epoch 41.784), train_loss = 0.61148636, grad/param norm = 2.5258e-01, time/batch = 15.4459s	
24946/29850 (epoch 41.786), train_loss = 0.70193334, grad/param norm = 2.0997e-01, time/batch = 15.6062s	
24947/29850 (epoch 41.787), train_loss = 0.59738799, grad/param norm = 2.3404e-01, time/batch = 15.4955s	
24948/29850 (epoch 41.789), train_loss = 0.61385525, grad/param norm = 1.7913e-01, time/batch = 15.6170s	
24949/29850 (epoch 41.791), train_loss = 0.69791211, grad/param norm = 2.2687e-01, time/batch = 15.3010s	
24950/29850 (epoch 41.792), train_loss = 0.78899241, grad/param norm = 2.4212e-01, time/batch = 15.2044s	
24951/29850 (epoch 41.794), train_loss = 0.75666597, grad/param norm = 2.1748e-01, time/batch = 15.4566s	
24952/29850 (epoch 41.796), train_loss = 0.66590032, grad/param norm = 2.1312e-01, time/batch = 15.2937s	
24953/29850 (epoch 41.797), train_loss = 0.57650458, grad/param norm = 2.2560e-01, time/batch = 15.5952s	
24954/29850 (epoch 41.799), train_loss = 0.61239770, grad/param norm = 1.6924e-01, time/batch = 15.1423s	
24955/29850 (epoch 41.801), train_loss = 0.63296427, grad/param norm = 2.0883e-01, time/batch = 14.8935s	
24956/29850 (epoch 41.802), train_loss = 0.60778592, grad/param norm = 1.9949e-01, time/batch = 15.1184s	
24957/29850 (epoch 41.804), train_loss = 0.64680113, grad/param norm = 1.8680e-01, time/batch = 15.3458s	
24958/29850 (epoch 41.806), train_loss = 0.59329537, grad/param norm = 2.3578e-01, time/batch = 15.7508s	
24959/29850 (epoch 41.807), train_loss = 0.64388777, grad/param norm = 1.8922e-01, time/batch = 15.9003s	
24960/29850 (epoch 41.809), train_loss = 0.64651060, grad/param norm = 2.4202e-01, time/batch = 15.5244s	
24961/29850 (epoch 41.811), train_loss = 0.79178830, grad/param norm = 2.4797e-01, time/batch = 15.8351s	
24962/29850 (epoch 41.812), train_loss = 0.77744097, grad/param norm = 2.3963e-01, time/batch = 15.1423s	
24963/29850 (epoch 41.814), train_loss = 0.80914111, grad/param norm = 2.8897e-01, time/batch = 15.4388s	
24964/29850 (epoch 41.816), train_loss = 0.86959718, grad/param norm = 2.2541e-01, time/batch = 15.3041s	
24965/29850 (epoch 41.817), train_loss = 0.77469662, grad/param norm = 2.6105e-01, time/batch = 15.6070s	
24966/29850 (epoch 41.819), train_loss = 0.61619151, grad/param norm = 2.6029e-01, time/batch = 15.1611s	
24967/29850 (epoch 41.821), train_loss = 0.86180435, grad/param norm = 3.0040e-01, time/batch = 15.5610s	
24968/29850 (epoch 41.822), train_loss = 0.89293843, grad/param norm = 2.7181e-01, time/batch = 15.1452s	
24969/29850 (epoch 41.824), train_loss = 0.75412774, grad/param norm = 2.1545e-01, time/batch = 15.2908s	
24970/29850 (epoch 41.826), train_loss = 0.66830174, grad/param norm = 2.4809e-01, time/batch = 14.9052s	
24971/29850 (epoch 41.827), train_loss = 0.59070516, grad/param norm = 2.1386e-01, time/batch = 15.4586s	
24972/29850 (epoch 41.829), train_loss = 0.76955900, grad/param norm = 2.7672e-01, time/batch = 15.1395s	
24973/29850 (epoch 41.831), train_loss = 0.87924774, grad/param norm = 2.5758e-01, time/batch = 15.3554s	
24974/29850 (epoch 41.832), train_loss = 0.76800191, grad/param norm = 2.1645e-01, time/batch = 14.9107s	
24975/29850 (epoch 41.834), train_loss = 0.57656829, grad/param norm = 1.8609e-01, time/batch = 15.2233s	
24976/29850 (epoch 41.836), train_loss = 0.60367932, grad/param norm = 2.2691e-01, time/batch = 15.5257s	
24977/29850 (epoch 41.838), train_loss = 0.70048402, grad/param norm = 2.5384e-01, time/batch = 15.8788s	
24978/29850 (epoch 41.839), train_loss = 0.58887365, grad/param norm = 2.1834e-01, time/batch = 15.9843s	
24979/29850 (epoch 41.841), train_loss = 0.66970483, grad/param norm = 1.8791e-01, time/batch = 15.9775s	
24980/29850 (epoch 41.843), train_loss = 0.59794782, grad/param norm = 2.1145e-01, time/batch = 15.8300s	
24981/29850 (epoch 41.844), train_loss = 0.66288773, grad/param norm = 2.3874e-01, time/batch = 16.0082s	
24982/29850 (epoch 41.846), train_loss = 0.71049863, grad/param norm = 2.1090e-01, time/batch = 15.5238s	
24983/29850 (epoch 41.848), train_loss = 0.78730739, grad/param norm = 2.2948e-01, time/batch = 15.3975s	
24984/29850 (epoch 41.849), train_loss = 0.72469468, grad/param norm = 2.6282e-01, time/batch = 15.6194s	
24985/29850 (epoch 41.851), train_loss = 0.88630233, grad/param norm = 2.4225e-01, time/batch = 15.6285s	
24986/29850 (epoch 41.853), train_loss = 0.72342214, grad/param norm = 2.4457e-01, time/batch = 15.4660s	
24987/29850 (epoch 41.854), train_loss = 0.88763466, grad/param norm = 2.5033e-01, time/batch = 15.5494s	
24988/29850 (epoch 41.856), train_loss = 0.84405712, grad/param norm = 2.6670e-01, time/batch = 15.6926s	
24989/29850 (epoch 41.858), train_loss = 0.75193674, grad/param norm = 2.4113e-01, time/batch = 15.4711s	
24990/29850 (epoch 41.859), train_loss = 0.68078700, grad/param norm = 3.2149e-01, time/batch = 15.5500s	
24991/29850 (epoch 41.861), train_loss = 0.86348373, grad/param norm = 3.3239e-01, time/batch = 15.1296s	
24992/29850 (epoch 41.863), train_loss = 0.87208660, grad/param norm = 2.5006e-01, time/batch = 15.5214s	
24993/29850 (epoch 41.864), train_loss = 0.86319004, grad/param norm = 2.5975e-01, time/batch = 15.3111s	
24994/29850 (epoch 41.866), train_loss = 0.78410690, grad/param norm = 2.6634e-01, time/batch = 15.2361s	
24995/29850 (epoch 41.868), train_loss = 0.93363238, grad/param norm = 2.6389e-01, time/batch = 15.5921s	
24996/29850 (epoch 41.869), train_loss = 0.85008693, grad/param norm = 2.7929e-01, time/batch = 15.2864s	
24997/29850 (epoch 41.871), train_loss = 0.84998964, grad/param norm = 2.6598e-01, time/batch = 15.6269s	
24998/29850 (epoch 41.873), train_loss = 0.80315548, grad/param norm = 2.6177e-01, time/batch = 15.9788s	
24999/29850 (epoch 41.874), train_loss = 0.81272235, grad/param norm = 2.2075e-01, time/batch = 15.6812s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch41.88_1.8970.t7	
25000/29850 (epoch 41.876), train_loss = 0.81975360, grad/param norm = 3.5171e-01, time/batch = 6.9295s	
25001/29850 (epoch 41.878), train_loss = 1.41848549, grad/param norm = 2.6608e-01, time/batch = 1.0296s	
25002/29850 (epoch 41.879), train_loss = 0.81771877, grad/param norm = 2.1956e-01, time/batch = 1.0199s	
25003/29850 (epoch 41.881), train_loss = 0.86655543, grad/param norm = 2.3584e-01, time/batch = 1.3385s	
25004/29850 (epoch 41.883), train_loss = 0.81082193, grad/param norm = 3.0615e-01, time/batch = 1.9054s	
25005/29850 (epoch 41.884), train_loss = 0.68813714, grad/param norm = 2.3386e-01, time/batch = 1.8988s	
25006/29850 (epoch 41.886), train_loss = 0.86210564, grad/param norm = 3.1046e-01, time/batch = 11.6638s	
25007/29850 (epoch 41.888), train_loss = 0.79887681, grad/param norm = 2.8377e-01, time/batch = 15.6643s	
25008/29850 (epoch 41.889), train_loss = 0.71952955, grad/param norm = 2.0647e-01, time/batch = 15.2146s	
25009/29850 (epoch 41.891), train_loss = 0.69910628, grad/param norm = 2.0103e-01, time/batch = 15.7766s	
25010/29850 (epoch 41.893), train_loss = 0.76457469, grad/param norm = 2.4467e-01, time/batch = 15.6482s	
25011/29850 (epoch 41.894), train_loss = 0.75090809, grad/param norm = 2.5467e-01, time/batch = 15.5382s	
25012/29850 (epoch 41.896), train_loss = 0.78508146, grad/param norm = 2.6419e-01, time/batch = 15.2884s	
25013/29850 (epoch 41.898), train_loss = 0.91101495, grad/param norm = 2.2854e-01, time/batch = 15.2138s	
25014/29850 (epoch 41.899), train_loss = 0.68596642, grad/param norm = 2.1642e-01, time/batch = 15.2283s	
25015/29850 (epoch 41.901), train_loss = 0.96799053, grad/param norm = 3.2548e-01, time/batch = 15.6662s	
25016/29850 (epoch 41.903), train_loss = 0.83963367, grad/param norm = 5.1079e-01, time/batch = 15.4503s	
25017/29850 (epoch 41.905), train_loss = 1.03423488, grad/param norm = 2.8551e-01, time/batch = 15.2188s	
25018/29850 (epoch 41.906), train_loss = 0.79210384, grad/param norm = 2.5478e-01, time/batch = 16.1335s	
25019/29850 (epoch 41.908), train_loss = 0.94600664, grad/param norm = 2.7490e-01, time/batch = 18.0546s	
25020/29850 (epoch 41.910), train_loss = 0.85952910, grad/param norm = 2.2681e-01, time/batch = 15.9562s	
25021/29850 (epoch 41.911), train_loss = 0.99375304, grad/param norm = 2.4980e-01, time/batch = 18.8394s	
25022/29850 (epoch 41.913), train_loss = 0.93110039, grad/param norm = 2.5585e-01, time/batch = 19.2898s	
25023/29850 (epoch 41.915), train_loss = 0.92964865, grad/param norm = 2.4575e-01, time/batch = 16.1227s	
25024/29850 (epoch 41.916), train_loss = 0.91888235, grad/param norm = 2.7596e-01, time/batch = 15.4338s	
25025/29850 (epoch 41.918), train_loss = 0.74166871, grad/param norm = 2.5014e-01, time/batch = 15.3153s	
25026/29850 (epoch 41.920), train_loss = 0.91078803, grad/param norm = 2.2587e-01, time/batch = 15.9832s	
25027/29850 (epoch 41.921), train_loss = 0.80547726, grad/param norm = 2.6523e-01, time/batch = 15.7086s	
25028/29850 (epoch 41.923), train_loss = 0.81849486, grad/param norm = 2.2257e-01, time/batch = 16.5925s	
25029/29850 (epoch 41.925), train_loss = 0.96815361, grad/param norm = 3.2999e-01, time/batch = 17.2150s	
25030/29850 (epoch 41.926), train_loss = 0.97823457, grad/param norm = 2.7675e-01, time/batch = 17.6158s	
25031/29850 (epoch 41.928), train_loss = 0.82176666, grad/param norm = 2.4238e-01, time/batch = 19.8498s	
25032/29850 (epoch 41.930), train_loss = 0.82392853, grad/param norm = 2.5807e-01, time/batch = 16.2245s	
25033/29850 (epoch 41.931), train_loss = 0.81804563, grad/param norm = 2.2475e-01, time/batch = 18.2134s	
25034/29850 (epoch 41.933), train_loss = 0.95768552, grad/param norm = 2.5911e-01, time/batch = 17.7688s	
25035/29850 (epoch 41.935), train_loss = 0.86786617, grad/param norm = 2.5401e-01, time/batch = 17.5387s	
25036/29850 (epoch 41.936), train_loss = 0.84875252, grad/param norm = 2.6096e-01, time/batch = 19.3595s	
25037/29850 (epoch 41.938), train_loss = 0.71618457, grad/param norm = 2.1329e-01, time/batch = 16.4467s	
25038/29850 (epoch 41.940), train_loss = 0.72138118, grad/param norm = 2.1973e-01, time/batch = 17.0492s	
25039/29850 (epoch 41.941), train_loss = 0.72207583, grad/param norm = 2.3732e-01, time/batch = 16.0431s	
25040/29850 (epoch 41.943), train_loss = 0.75485043, grad/param norm = 2.2608e-01, time/batch = 16.5390s	
25041/29850 (epoch 41.945), train_loss = 0.70877663, grad/param norm = 3.2825e-01, time/batch = 24.0021s	
25042/29850 (epoch 41.946), train_loss = 0.70553191, grad/param norm = 2.2239e-01, time/batch = 24.0741s	
25043/29850 (epoch 41.948), train_loss = 0.80399465, grad/param norm = 2.2265e-01, time/batch = 15.3503s	
25044/29850 (epoch 41.950), train_loss = 0.74507413, grad/param norm = 1.9331e-01, time/batch = 18.3551s	
25045/29850 (epoch 41.951), train_loss = 0.66880245, grad/param norm = 2.0183e-01, time/batch = 16.6275s	
25046/29850 (epoch 41.953), train_loss = 0.75279678, grad/param norm = 2.3673e-01, time/batch = 15.4981s	
25047/29850 (epoch 41.955), train_loss = 0.68361398, grad/param norm = 1.9887e-01, time/batch = 15.4412s	
25048/29850 (epoch 41.956), train_loss = 0.64885201, grad/param norm = 1.8070e-01, time/batch = 16.4468s	
25049/29850 (epoch 41.958), train_loss = 0.63416998, grad/param norm = 1.9179e-01, time/batch = 16.1895s	
25050/29850 (epoch 41.960), train_loss = 0.89049507, grad/param norm = 2.9046e-01, time/batch = 14.5414s	
25051/29850 (epoch 41.961), train_loss = 0.63102128, grad/param norm = 1.8166e-01, time/batch = 16.6098s	
25052/29850 (epoch 41.963), train_loss = 0.63378742, grad/param norm = 2.0983e-01, time/batch = 17.5460s	
25053/29850 (epoch 41.965), train_loss = 0.69243071, grad/param norm = 2.2617e-01, time/batch = 16.9492s	
25054/29850 (epoch 41.966), train_loss = 0.69360095, grad/param norm = 2.3863e-01, time/batch = 16.6345s	
25055/29850 (epoch 41.968), train_loss = 0.69285435, grad/param norm = 2.1773e-01, time/batch = 17.6870s	
25056/29850 (epoch 41.970), train_loss = 0.73383259, grad/param norm = 2.5488e-01, time/batch = 18.2864s	
25057/29850 (epoch 41.972), train_loss = 0.71163954, grad/param norm = 2.1513e-01, time/batch = 17.0613s	
25058/29850 (epoch 41.973), train_loss = 0.68619281, grad/param norm = 1.8575e-01, time/batch = 17.5107s	
25059/29850 (epoch 41.975), train_loss = 0.61811061, grad/param norm = 2.2305e-01, time/batch = 18.7955s	
25060/29850 (epoch 41.977), train_loss = 0.71701075, grad/param norm = 1.9676e-01, time/batch = 16.5448s	
25061/29850 (epoch 41.978), train_loss = 0.61806725, grad/param norm = 1.6887e-01, time/batch = 15.8182s	
25062/29850 (epoch 41.980), train_loss = 0.68586393, grad/param norm = 1.8929e-01, time/batch = 15.2768s	
25063/29850 (epoch 41.982), train_loss = 0.67430923, grad/param norm = 2.0750e-01, time/batch = 15.5534s	
25064/29850 (epoch 41.983), train_loss = 0.72454095, grad/param norm = 1.9623e-01, time/batch = 16.2009s	
25065/29850 (epoch 41.985), train_loss = 0.82573345, grad/param norm = 2.5996e-01, time/batch = 17.0386s	
25066/29850 (epoch 41.987), train_loss = 0.78262822, grad/param norm = 2.1509e-01, time/batch = 19.6029s	
25067/29850 (epoch 41.988), train_loss = 0.74900583, grad/param norm = 2.2830e-01, time/batch = 16.1075s	
25068/29850 (epoch 41.990), train_loss = 0.80521936, grad/param norm = 2.2152e-01, time/batch = 16.8738s	
25069/29850 (epoch 41.992), train_loss = 0.79707340, grad/param norm = 2.1253e-01, time/batch = 18.4572s	
25070/29850 (epoch 41.993), train_loss = 0.80105532, grad/param norm = 2.3157e-01, time/batch = 16.6955s	
25071/29850 (epoch 41.995), train_loss = 0.78274800, grad/param norm = 2.2069e-01, time/batch = 17.7090s	
25072/29850 (epoch 41.997), train_loss = 0.80531378, grad/param norm = 2.0411e-01, time/batch = 18.0218s	
25073/29850 (epoch 41.998), train_loss = 0.81583650, grad/param norm = 2.2809e-01, time/batch = 18.0362s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
25074/29850 (epoch 42.000), train_loss = 0.64984688, grad/param norm = 2.0930e-01, time/batch = 17.5242s	
25075/29850 (epoch 42.002), train_loss = 0.88120840, grad/param norm = 2.1965e-01, time/batch = 17.3595s	
25076/29850 (epoch 42.003), train_loss = 0.64228361, grad/param norm = 2.0787e-01, time/batch = 18.1121s	
25077/29850 (epoch 42.005), train_loss = 0.82955649, grad/param norm = 2.1818e-01, time/batch = 15.9575s	
25078/29850 (epoch 42.007), train_loss = 0.85919788, grad/param norm = 2.5774e-01, time/batch = 15.2516s	
25079/29850 (epoch 42.008), train_loss = 0.98032034, grad/param norm = 2.6768e-01, time/batch = 15.3511s	
25080/29850 (epoch 42.010), train_loss = 0.69920871, grad/param norm = 2.1547e-01, time/batch = 16.9515s	
25081/29850 (epoch 42.012), train_loss = 0.73967390, grad/param norm = 2.2169e-01, time/batch = 16.7718s	
25082/29850 (epoch 42.013), train_loss = 0.79767598, grad/param norm = 2.5085e-01, time/batch = 17.2047s	
25083/29850 (epoch 42.015), train_loss = 0.87218016, grad/param norm = 2.2843e-01, time/batch = 17.9670s	
25084/29850 (epoch 42.017), train_loss = 0.81680189, grad/param norm = 2.3845e-01, time/batch = 16.7092s	
25085/29850 (epoch 42.018), train_loss = 0.89882670, grad/param norm = 2.1113e-01, time/batch = 16.4748s	
25086/29850 (epoch 42.020), train_loss = 0.80585510, grad/param norm = 2.3769e-01, time/batch = 15.0882s	
25087/29850 (epoch 42.022), train_loss = 0.87987695, grad/param norm = 2.5439e-01, time/batch = 16.3131s	
25088/29850 (epoch 42.023), train_loss = 0.84449777, grad/param norm = 1.9771e-01, time/batch = 19.4586s	
25089/29850 (epoch 42.025), train_loss = 0.77368910, grad/param norm = 1.9437e-01, time/batch = 18.2842s	
25090/29850 (epoch 42.027), train_loss = 0.56808739, grad/param norm = 1.9142e-01, time/batch = 18.5292s	
25091/29850 (epoch 42.028), train_loss = 0.71889819, grad/param norm = 1.9782e-01, time/batch = 16.0918s	
25092/29850 (epoch 42.030), train_loss = 0.74212663, grad/param norm = 2.3763e-01, time/batch = 16.2140s	
25093/29850 (epoch 42.032), train_loss = 0.82278604, grad/param norm = 2.3520e-01, time/batch = 15.2844s	
25094/29850 (epoch 42.034), train_loss = 0.70760452, grad/param norm = 1.9862e-01, time/batch = 15.3631s	
25095/29850 (epoch 42.035), train_loss = 0.62997352, grad/param norm = 2.0256e-01, time/batch = 16.4383s	
25096/29850 (epoch 42.037), train_loss = 0.78061799, grad/param norm = 2.2101e-01, time/batch = 17.6213s	
25097/29850 (epoch 42.039), train_loss = 0.69281280, grad/param norm = 1.9196e-01, time/batch = 19.7083s	
25098/29850 (epoch 42.040), train_loss = 0.66285912, grad/param norm = 2.2039e-01, time/batch = 16.0647s	
25099/29850 (epoch 42.042), train_loss = 0.72638497, grad/param norm = 2.4668e-01, time/batch = 15.2382s	
25100/29850 (epoch 42.044), train_loss = 0.75584061, grad/param norm = 2.1081e-01, time/batch = 15.7789s	
25101/29850 (epoch 42.045), train_loss = 0.84720109, grad/param norm = 2.3847e-01, time/batch = 19.6886s	
25102/29850 (epoch 42.047), train_loss = 0.69083406, grad/param norm = 2.1752e-01, time/batch = 16.8529s	
25103/29850 (epoch 42.049), train_loss = 0.81302921, grad/param norm = 2.2205e-01, time/batch = 17.5385s	
25104/29850 (epoch 42.050), train_loss = 0.73605015, grad/param norm = 2.1599e-01, time/batch = 19.5215s	
25105/29850 (epoch 42.052), train_loss = 0.90065145, grad/param norm = 2.4586e-01, time/batch = 16.7350s	
25106/29850 (epoch 42.054), train_loss = 0.74655271, grad/param norm = 2.1333e-01, time/batch = 15.3707s	
25107/29850 (epoch 42.055), train_loss = 0.74034133, grad/param norm = 2.1942e-01, time/batch = 15.4350s	
25108/29850 (epoch 42.057), train_loss = 0.83958937, grad/param norm = 2.1301e-01, time/batch = 15.4233s	
25109/29850 (epoch 42.059), train_loss = 0.82309658, grad/param norm = 2.2479e-01, time/batch = 15.2817s	
25110/29850 (epoch 42.060), train_loss = 0.80426596, grad/param norm = 2.6328e-01, time/batch = 15.2085s	
25111/29850 (epoch 42.062), train_loss = 0.87144138, grad/param norm = 3.4647e-01, time/batch = 15.2634s	
25112/29850 (epoch 42.064), train_loss = 0.86045938, grad/param norm = 3.4940e-01, time/batch = 14.1242s	
25113/29850 (epoch 42.065), train_loss = 0.67374171, grad/param norm = 2.1882e-01, time/batch = 15.7683s	
25114/29850 (epoch 42.067), train_loss = 0.84248519, grad/param norm = 2.8059e-01, time/batch = 17.7070s	
25115/29850 (epoch 42.069), train_loss = 0.81479835, grad/param norm = 2.1367e-01, time/batch = 18.1219s	
25116/29850 (epoch 42.070), train_loss = 0.84606777, grad/param norm = 2.1850e-01, time/batch = 19.1287s	
25117/29850 (epoch 42.072), train_loss = 0.77462321, grad/param norm = 2.4630e-01, time/batch = 18.2065s	
25118/29850 (epoch 42.074), train_loss = 0.87008546, grad/param norm = 2.2995e-01, time/batch = 17.7012s	
25119/29850 (epoch 42.075), train_loss = 0.74708466, grad/param norm = 2.5653e-01, time/batch = 19.8013s	
25120/29850 (epoch 42.077), train_loss = 0.84746174, grad/param norm = 2.4830e-01, time/batch = 15.7727s	
25121/29850 (epoch 42.079), train_loss = 0.97806448, grad/param norm = 2.9648e-01, time/batch = 16.6246s	
25122/29850 (epoch 42.080), train_loss = 0.95042930, grad/param norm = 2.5859e-01, time/batch = 15.8565s	
25123/29850 (epoch 42.082), train_loss = 0.85047933, grad/param norm = 2.1895e-01, time/batch = 18.8666s	
25124/29850 (epoch 42.084), train_loss = 0.94698550, grad/param norm = 2.7263e-01, time/batch = 17.4594s	
25125/29850 (epoch 42.085), train_loss = 0.98480634, grad/param norm = 2.6422e-01, time/batch = 16.3026s	
25126/29850 (epoch 42.087), train_loss = 0.93838807, grad/param norm = 2.6939e-01, time/batch = 16.3049s	
25127/29850 (epoch 42.089), train_loss = 0.83097673, grad/param norm = 2.1960e-01, time/batch = 16.5907s	
25128/29850 (epoch 42.090), train_loss = 0.83506327, grad/param norm = 2.3614e-01, time/batch = 16.2644s	
25129/29850 (epoch 42.092), train_loss = 0.72061840, grad/param norm = 2.0404e-01, time/batch = 16.2928s	
25130/29850 (epoch 42.094), train_loss = 0.93780257, grad/param norm = 2.7824e-01, time/batch = 17.7249s	
25131/29850 (epoch 42.095), train_loss = 0.90249116, grad/param norm = 4.3939e-01, time/batch = 15.7080s	
25132/29850 (epoch 42.097), train_loss = 0.62129437, grad/param norm = 1.9064e-01, time/batch = 16.7551s	
25133/29850 (epoch 42.099), train_loss = 0.65425095, grad/param norm = 2.1111e-01, time/batch = 14.8709s	
25134/29850 (epoch 42.101), train_loss = 0.86443800, grad/param norm = 2.4345e-01, time/batch = 15.0451s	
25135/29850 (epoch 42.102), train_loss = 0.87187841, grad/param norm = 2.4078e-01, time/batch = 15.8984s	
25136/29850 (epoch 42.104), train_loss = 0.76484178, grad/param norm = 2.3547e-01, time/batch = 15.6427s	
25137/29850 (epoch 42.106), train_loss = 0.89057470, grad/param norm = 2.2938e-01, time/batch = 17.7819s	
25138/29850 (epoch 42.107), train_loss = 0.75460187, grad/param norm = 1.9918e-01, time/batch = 16.5892s	
25139/29850 (epoch 42.109), train_loss = 0.78914633, grad/param norm = 2.4118e-01, time/batch = 16.5598s	
25140/29850 (epoch 42.111), train_loss = 0.83681110, grad/param norm = 2.1604e-01, time/batch = 17.4613s	
25141/29850 (epoch 42.112), train_loss = 0.71044148, grad/param norm = 1.9490e-01, time/batch = 15.5415s	
25142/29850 (epoch 42.114), train_loss = 0.75166860, grad/param norm = 2.3507e-01, time/batch = 16.7167s	
25143/29850 (epoch 42.116), train_loss = 0.71989002, grad/param norm = 2.0783e-01, time/batch = 16.9410s	
25144/29850 (epoch 42.117), train_loss = 0.77700651, grad/param norm = 2.3821e-01, time/batch = 18.4552s	
25145/29850 (epoch 42.119), train_loss = 0.75042110, grad/param norm = 2.2362e-01, time/batch = 18.3051s	
25146/29850 (epoch 42.121), train_loss = 0.66880932, grad/param norm = 2.7667e-01, time/batch = 16.2849s	
25147/29850 (epoch 42.122), train_loss = 0.68743878, grad/param norm = 1.6542e-01, time/batch = 17.3073s	
25148/29850 (epoch 42.124), train_loss = 0.70452813, grad/param norm = 2.1473e-01, time/batch = 15.3990s	
25149/29850 (epoch 42.126), train_loss = 0.75763119, grad/param norm = 2.4380e-01, time/batch = 17.7234s	
25150/29850 (epoch 42.127), train_loss = 0.82499829, grad/param norm = 2.5213e-01, time/batch = 15.4078s	
25151/29850 (epoch 42.129), train_loss = 0.80549539, grad/param norm = 2.4579e-01, time/batch = 15.5904s	
25152/29850 (epoch 42.131), train_loss = 0.80312665, grad/param norm = 2.1735e-01, time/batch = 15.3055s	
25153/29850 (epoch 42.132), train_loss = 0.66748112, grad/param norm = 1.9907e-01, time/batch = 14.8940s	
25154/29850 (epoch 42.134), train_loss = 0.75276026, grad/param norm = 2.7463e-01, time/batch = 17.4253s	
25155/29850 (epoch 42.136), train_loss = 0.88039742, grad/param norm = 2.4193e-01, time/batch = 19.2983s	
25156/29850 (epoch 42.137), train_loss = 0.65715289, grad/param norm = 2.0529e-01, time/batch = 18.5294s	
25157/29850 (epoch 42.139), train_loss = 0.78085829, grad/param norm = 2.1688e-01, time/batch = 16.1390s	
25158/29850 (epoch 42.141), train_loss = 0.70413759, grad/param norm = 2.2051e-01, time/batch = 19.2903s	
25159/29850 (epoch 42.142), train_loss = 0.89276704, grad/param norm = 2.3751e-01, time/batch = 18.2795s	
25160/29850 (epoch 42.144), train_loss = 0.99608934, grad/param norm = 2.5753e-01, time/batch = 17.4212s	
25161/29850 (epoch 42.146), train_loss = 1.00812549, grad/param norm = 2.5367e-01, time/batch = 19.5241s	
25162/29850 (epoch 42.147), train_loss = 0.90166210, grad/param norm = 2.9220e-01, time/batch = 18.0356s	
25163/29850 (epoch 42.149), train_loss = 0.84445183, grad/param norm = 2.3537e-01, time/batch = 17.2867s	
25164/29850 (epoch 42.151), train_loss = 0.83606760, grad/param norm = 2.7583e-01, time/batch = 15.1853s	
25165/29850 (epoch 42.152), train_loss = 0.78100170, grad/param norm = 2.1264e-01, time/batch = 16.2571s	
25166/29850 (epoch 42.154), train_loss = 0.73278098, grad/param norm = 2.4038e-01, time/batch = 16.1226s	
25167/29850 (epoch 42.156), train_loss = 0.73704646, grad/param norm = 2.1584e-01, time/batch = 16.8454s	
25168/29850 (epoch 42.157), train_loss = 0.86389055, grad/param norm = 2.4931e-01, time/batch = 14.4841s	
25169/29850 (epoch 42.159), train_loss = 0.75108819, grad/param norm = 1.8854e-01, time/batch = 17.3900s	
25170/29850 (epoch 42.161), train_loss = 0.78334822, grad/param norm = 2.7382e-01, time/batch = 15.5200s	
25171/29850 (epoch 42.162), train_loss = 0.92111564, grad/param norm = 2.7743e-01, time/batch = 17.1203s	
25172/29850 (epoch 42.164), train_loss = 0.87305705, grad/param norm = 2.7023e-01, time/batch = 15.8716s	
25173/29850 (epoch 42.166), train_loss = 0.75686713, grad/param norm = 2.3535e-01, time/batch = 16.2783s	
25174/29850 (epoch 42.168), train_loss = 0.70496693, grad/param norm = 1.9860e-01, time/batch = 16.7710s	
25175/29850 (epoch 42.169), train_loss = 0.91677895, grad/param norm = 2.7688e-01, time/batch = 17.4222s	
25176/29850 (epoch 42.171), train_loss = 0.86561481, grad/param norm = 2.3130e-01, time/batch = 15.4643s	
25177/29850 (epoch 42.173), train_loss = 0.70055850, grad/param norm = 2.4043e-01, time/batch = 15.2060s	
25178/29850 (epoch 42.174), train_loss = 0.79478202, grad/param norm = 2.4494e-01, time/batch = 16.7871s	
25179/29850 (epoch 42.176), train_loss = 0.82932733, grad/param norm = 2.0306e-01, time/batch = 19.6328s	
25180/29850 (epoch 42.178), train_loss = 0.86018886, grad/param norm = 2.7050e-01, time/batch = 15.9725s	
25181/29850 (epoch 42.179), train_loss = 0.67174808, grad/param norm = 2.2060e-01, time/batch = 17.3156s	
25182/29850 (epoch 42.181), train_loss = 0.80820478, grad/param norm = 2.3219e-01, time/batch = 15.0201s	
25183/29850 (epoch 42.183), train_loss = 0.83188387, grad/param norm = 3.0944e-01, time/batch = 16.8683s	
25184/29850 (epoch 42.184), train_loss = 0.89251114, grad/param norm = 2.5872e-01, time/batch = 17.0424s	
25185/29850 (epoch 42.186), train_loss = 0.86089742, grad/param norm = 2.6002e-01, time/batch = 17.0418s	
25186/29850 (epoch 42.188), train_loss = 0.95075861, grad/param norm = 2.6994e-01, time/batch = 18.0475s	
25187/29850 (epoch 42.189), train_loss = 0.87770640, grad/param norm = 2.5392e-01, time/batch = 18.4761s	
25188/29850 (epoch 42.191), train_loss = 0.92040143, grad/param norm = 3.0690e-01, time/batch = 15.5499s	
25189/29850 (epoch 42.193), train_loss = 0.78954041, grad/param norm = 2.1625e-01, time/batch = 15.4319s	
25190/29850 (epoch 42.194), train_loss = 0.90051540, grad/param norm = 2.3134e-01, time/batch = 17.9545s	
25191/29850 (epoch 42.196), train_loss = 0.79072489, grad/param norm = 2.2719e-01, time/batch = 16.5222s	
25192/29850 (epoch 42.198), train_loss = 0.74288964, grad/param norm = 2.4104e-01, time/batch = 17.3744s	
25193/29850 (epoch 42.199), train_loss = 1.01135581, grad/param norm = 2.6118e-01, time/batch = 16.7561s	
25194/29850 (epoch 42.201), train_loss = 0.74080293, grad/param norm = 2.0808e-01, time/batch = 18.5544s	
25195/29850 (epoch 42.203), train_loss = 0.58534263, grad/param norm = 1.9935e-01, time/batch = 16.7066s	
25196/29850 (epoch 42.204), train_loss = 0.80331709, grad/param norm = 2.9574e-01, time/batch = 19.7715s	
25197/29850 (epoch 42.206), train_loss = 0.70029171, grad/param norm = 2.2803e-01, time/batch = 17.7816s	
25198/29850 (epoch 42.208), train_loss = 0.91583527, grad/param norm = 2.7367e-01, time/batch = 19.5386s	
25199/29850 (epoch 42.209), train_loss = 0.71938555, grad/param norm = 2.2068e-01, time/batch = 15.8609s	
25200/29850 (epoch 42.211), train_loss = 0.76665298, grad/param norm = 2.3009e-01, time/batch = 15.5896s	
25201/29850 (epoch 42.213), train_loss = 0.83915154, grad/param norm = 2.6028e-01, time/batch = 15.3055s	
25202/29850 (epoch 42.214), train_loss = 0.67653236, grad/param norm = 2.0602e-01, time/batch = 15.6094s	
25203/29850 (epoch 42.216), train_loss = 0.70685683, grad/param norm = 2.2626e-01, time/batch = 15.4567s	
25204/29850 (epoch 42.218), train_loss = 0.82387092, grad/param norm = 2.2392e-01, time/batch = 15.0667s	
25205/29850 (epoch 42.219), train_loss = 0.84054576, grad/param norm = 2.7064e-01, time/batch = 15.3010s	
25206/29850 (epoch 42.221), train_loss = 0.78531197, grad/param norm = 2.3418e-01, time/batch = 15.2272s	
25207/29850 (epoch 42.223), train_loss = 0.65346354, grad/param norm = 2.1747e-01, time/batch = 15.3049s	
25208/29850 (epoch 42.224), train_loss = 0.64691477, grad/param norm = 1.9623e-01, time/batch = 15.1434s	
25209/29850 (epoch 42.226), train_loss = 0.71845908, grad/param norm = 2.2620e-01, time/batch = 15.1061s	
25210/29850 (epoch 42.228), train_loss = 0.74798625, grad/param norm = 2.2001e-01, time/batch = 14.9001s	
25211/29850 (epoch 42.229), train_loss = 0.64660729, grad/param norm = 1.8618e-01, time/batch = 15.6738s	
25212/29850 (epoch 42.231), train_loss = 0.80081544, grad/param norm = 2.1384e-01, time/batch = 15.5200s	
25213/29850 (epoch 42.233), train_loss = 0.76010270, grad/param norm = 2.1954e-01, time/batch = 15.3814s	
25214/29850 (epoch 42.235), train_loss = 0.72668750, grad/param norm = 2.4290e-01, time/batch = 15.1400s	
25215/29850 (epoch 42.236), train_loss = 0.94747940, grad/param norm = 2.9150e-01, time/batch = 15.3115s	
25216/29850 (epoch 42.238), train_loss = 0.67233133, grad/param norm = 2.3120e-01, time/batch = 14.9834s	
25217/29850 (epoch 42.240), train_loss = 0.67983449, grad/param norm = 2.0121e-01, time/batch = 14.9649s	
25218/29850 (epoch 42.241), train_loss = 0.79017226, grad/param norm = 2.1625e-01, time/batch = 15.2185s	
25219/29850 (epoch 42.243), train_loss = 0.82056310, grad/param norm = 1.9776e-01, time/batch = 15.3072s	
25220/29850 (epoch 42.245), train_loss = 0.69923194, grad/param norm = 2.0879e-01, time/batch = 15.1499s	
25221/29850 (epoch 42.246), train_loss = 0.71418820, grad/param norm = 1.9889e-01, time/batch = 15.3842s	
25222/29850 (epoch 42.248), train_loss = 0.67097753, grad/param norm = 2.1854e-01, time/batch = 15.5875s	
25223/29850 (epoch 42.250), train_loss = 0.73269606, grad/param norm = 1.9810e-01, time/batch = 15.3852s	
25224/29850 (epoch 42.251), train_loss = 0.64433898, grad/param norm = 2.2052e-01, time/batch = 15.3152s	
25225/29850 (epoch 42.253), train_loss = 0.63965939, grad/param norm = 2.2499e-01, time/batch = 15.3043s	
25226/29850 (epoch 42.255), train_loss = 0.68489501, grad/param norm = 2.0790e-01, time/batch = 15.2211s	
25227/29850 (epoch 42.256), train_loss = 0.82490024, grad/param norm = 2.2245e-01, time/batch = 15.1457s	
25228/29850 (epoch 42.258), train_loss = 0.82889771, grad/param norm = 2.4759e-01, time/batch = 15.0683s	
25229/29850 (epoch 42.260), train_loss = 0.75449397, grad/param norm = 2.1241e-01, time/batch = 15.1858s	
25230/29850 (epoch 42.261), train_loss = 0.69109201, grad/param norm = 2.0029e-01, time/batch = 15.5312s	
25231/29850 (epoch 42.263), train_loss = 0.69400938, grad/param norm = 1.9152e-01, time/batch = 15.3784s	
25232/29850 (epoch 42.265), train_loss = 0.75199092, grad/param norm = 2.1861e-01, time/batch = 15.6030s	
25233/29850 (epoch 42.266), train_loss = 0.76534446, grad/param norm = 2.2260e-01, time/batch = 15.0787s	
25234/29850 (epoch 42.268), train_loss = 0.73300416, grad/param norm = 1.9197e-01, time/batch = 15.0500s	
25235/29850 (epoch 42.270), train_loss = 0.70395409, grad/param norm = 2.4333e-01, time/batch = 15.0068s	
25236/29850 (epoch 42.271), train_loss = 0.81606480, grad/param norm = 2.2147e-01, time/batch = 15.4795s	
25237/29850 (epoch 42.273), train_loss = 0.65948249, grad/param norm = 1.8736e-01, time/batch = 14.8845s	
25238/29850 (epoch 42.275), train_loss = 0.65943527, grad/param norm = 2.2199e-01, time/batch = 15.5125s	
25239/29850 (epoch 42.276), train_loss = 0.66514459, grad/param norm = 1.9762e-01, time/batch = 15.2151s	
25240/29850 (epoch 42.278), train_loss = 0.72480973, grad/param norm = 2.1260e-01, time/batch = 15.1526s	
25241/29850 (epoch 42.280), train_loss = 0.94837066, grad/param norm = 3.8471e-01, time/batch = 15.1479s	
25242/29850 (epoch 42.281), train_loss = 0.81069491, grad/param norm = 2.6948e-01, time/batch = 15.2646s	
25243/29850 (epoch 42.283), train_loss = 0.85889026, grad/param norm = 2.4709e-01, time/batch = 14.8179s	
25244/29850 (epoch 42.285), train_loss = 0.84675324, grad/param norm = 2.3416e-01, time/batch = 14.9667s	
25245/29850 (epoch 42.286), train_loss = 0.87064310, grad/param norm = 2.4178e-01, time/batch = 14.9613s	
25246/29850 (epoch 42.288), train_loss = 0.81775563, grad/param norm = 2.6843e-01, time/batch = 15.3856s	
25247/29850 (epoch 42.290), train_loss = 0.79188026, grad/param norm = 2.7015e-01, time/batch = 14.8165s	
25248/29850 (epoch 42.291), train_loss = 1.00064274, grad/param norm = 2.6853e-01, time/batch = 15.4246s	
25249/29850 (epoch 42.293), train_loss = 0.92630398, grad/param norm = 2.5710e-01, time/batch = 14.9006s	
25250/29850 (epoch 42.295), train_loss = 0.97377453, grad/param norm = 2.3442e-01, time/batch = 15.1079s	
25251/29850 (epoch 42.296), train_loss = 0.72115022, grad/param norm = 1.9598e-01, time/batch = 15.1575s	
25252/29850 (epoch 42.298), train_loss = 0.61179296, grad/param norm = 1.7998e-01, time/batch = 15.3096s	
25253/29850 (epoch 42.300), train_loss = 0.68846924, grad/param norm = 2.1881e-01, time/batch = 14.9062s	
25254/29850 (epoch 42.302), train_loss = 0.68222362, grad/param norm = 2.8961e-01, time/batch = 15.3553s	
25255/29850 (epoch 42.303), train_loss = 0.73501705, grad/param norm = 2.3104e-01, time/batch = 15.1421s	
25256/29850 (epoch 42.305), train_loss = 0.86354294, grad/param norm = 2.1256e-01, time/batch = 15.2972s	
25257/29850 (epoch 42.307), train_loss = 0.85734465, grad/param norm = 2.3009e-01, time/batch = 15.2237s	
25258/29850 (epoch 42.308), train_loss = 0.66734118, grad/param norm = 1.9294e-01, time/batch = 28.9190s	
25259/29850 (epoch 42.310), train_loss = 0.85000527, grad/param norm = 2.3843e-01, time/batch = 15.3067s	
25260/29850 (epoch 42.312), train_loss = 0.89620175, grad/param norm = 2.3725e-01, time/batch = 15.7345s	
25261/29850 (epoch 42.313), train_loss = 0.81051227, grad/param norm = 2.4965e-01, time/batch = 15.8251s	
25262/29850 (epoch 42.315), train_loss = 0.83611090, grad/param norm = 2.3211e-01, time/batch = 15.3558s	
25263/29850 (epoch 42.317), train_loss = 0.79581469, grad/param norm = 2.3806e-01, time/batch = 15.7860s	
25264/29850 (epoch 42.318), train_loss = 0.75236123, grad/param norm = 2.1073e-01, time/batch = 15.7681s	
25265/29850 (epoch 42.320), train_loss = 0.73272541, grad/param norm = 2.0256e-01, time/batch = 15.8006s	
25266/29850 (epoch 42.322), train_loss = 0.88432075, grad/param norm = 2.6742e-01, time/batch = 15.8966s	
25267/29850 (epoch 42.323), train_loss = 0.81768593, grad/param norm = 2.3192e-01, time/batch = 16.1032s	
25268/29850 (epoch 42.325), train_loss = 0.87745979, grad/param norm = 2.4295e-01, time/batch = 16.0227s	
25269/29850 (epoch 42.327), train_loss = 0.99159159, grad/param norm = 2.5227e-01, time/batch = 16.0236s	
25270/29850 (epoch 42.328), train_loss = 0.90365210, grad/param norm = 2.6917e-01, time/batch = 15.8204s	
25271/29850 (epoch 42.330), train_loss = 0.87331543, grad/param norm = 2.1737e-01, time/batch = 15.9780s	
25272/29850 (epoch 42.332), train_loss = 0.76724534, grad/param norm = 2.2255e-01, time/batch = 16.0331s	
25273/29850 (epoch 42.333), train_loss = 0.82664245, grad/param norm = 2.5629e-01, time/batch = 15.7230s	
25274/29850 (epoch 42.335), train_loss = 0.88438378, grad/param norm = 2.2933e-01, time/batch = 15.6389s	
25275/29850 (epoch 42.337), train_loss = 0.81510906, grad/param norm = 3.1633e-01, time/batch = 15.9691s	
25276/29850 (epoch 42.338), train_loss = 0.85970355, grad/param norm = 2.2342e-01, time/batch = 16.0663s	
25277/29850 (epoch 42.340), train_loss = 0.68585987, grad/param norm = 2.0766e-01, time/batch = 15.7952s	
25278/29850 (epoch 42.342), train_loss = 0.80575868, grad/param norm = 2.5475e-01, time/batch = 15.8875s	
25279/29850 (epoch 42.343), train_loss = 0.80817714, grad/param norm = 2.2669e-01, time/batch = 16.0556s	
25280/29850 (epoch 42.345), train_loss = 0.88074284, grad/param norm = 2.8714e-01, time/batch = 15.8119s	
25281/29850 (epoch 42.347), train_loss = 0.89000354, grad/param norm = 2.6520e-01, time/batch = 15.8626s	
25282/29850 (epoch 42.348), train_loss = 0.75191413, grad/param norm = 2.1721e-01, time/batch = 15.7254s	
25283/29850 (epoch 42.350), train_loss = 0.85142205, grad/param norm = 2.4861e-01, time/batch = 15.7171s	
25284/29850 (epoch 42.352), train_loss = 0.75954800, grad/param norm = 2.0934e-01, time/batch = 16.0516s	
25285/29850 (epoch 42.353), train_loss = 0.83225203, grad/param norm = 2.2076e-01, time/batch = 15.7780s	
25286/29850 (epoch 42.355), train_loss = 0.73698780, grad/param norm = 2.1210e-01, time/batch = 15.7080s	
25287/29850 (epoch 42.357), train_loss = 0.89257549, grad/param norm = 2.1264e-01, time/batch = 15.8724s	
25288/29850 (epoch 42.358), train_loss = 0.72636691, grad/param norm = 2.0280e-01, time/batch = 15.9804s	
25289/29850 (epoch 42.360), train_loss = 0.79774063, grad/param norm = 2.2326e-01, time/batch = 15.9498s	
25290/29850 (epoch 42.362), train_loss = 0.80401124, grad/param norm = 2.3047e-01, time/batch = 15.7814s	
25291/29850 (epoch 42.363), train_loss = 0.83406406, grad/param norm = 2.6514e-01, time/batch = 16.2182s	
25292/29850 (epoch 42.365), train_loss = 0.92272092, grad/param norm = 2.7784e-01, time/batch = 15.6450s	
25293/29850 (epoch 42.367), train_loss = 0.72842888, grad/param norm = 2.1460e-01, time/batch = 15.4792s	
25294/29850 (epoch 42.369), train_loss = 0.64418073, grad/param norm = 2.4758e-01, time/batch = 15.6831s	
25295/29850 (epoch 42.370), train_loss = 0.67251121, grad/param norm = 2.5022e-01, time/batch = 15.8134s	
25296/29850 (epoch 42.372), train_loss = 0.88765453, grad/param norm = 2.2485e-01, time/batch = 15.4506s	
25297/29850 (epoch 42.374), train_loss = 0.88340104, grad/param norm = 3.1434e-01, time/batch = 15.6181s	
25298/29850 (epoch 42.375), train_loss = 0.83269171, grad/param norm = 2.8265e-01, time/batch = 15.3741s	
25299/29850 (epoch 42.377), train_loss = 0.68453290, grad/param norm = 2.0303e-01, time/batch = 14.9168s	
25300/29850 (epoch 42.379), train_loss = 0.89337865, grad/param norm = 2.8910e-01, time/batch = 15.5349s	
25301/29850 (epoch 42.380), train_loss = 0.85379592, grad/param norm = 2.4672e-01, time/batch = 15.3084s	
25302/29850 (epoch 42.382), train_loss = 0.81826486, grad/param norm = 3.5074e-01, time/batch = 15.4474s	
25303/29850 (epoch 42.384), train_loss = 0.87742997, grad/param norm = 2.5548e-01, time/batch = 15.3510s	
25304/29850 (epoch 42.385), train_loss = 0.86790226, grad/param norm = 2.7164e-01, time/batch = 15.1593s	
25305/29850 (epoch 42.387), train_loss = 0.83318089, grad/param norm = 2.8280e-01, time/batch = 15.2960s	
25306/29850 (epoch 42.389), train_loss = 0.92672043, grad/param norm = 2.8378e-01, time/batch = 15.1907s	
25307/29850 (epoch 42.390), train_loss = 0.88085321, grad/param norm = 2.2438e-01, time/batch = 15.2909s	
25308/29850 (epoch 42.392), train_loss = 0.81417410, grad/param norm = 2.5551e-01, time/batch = 15.2215s	
25309/29850 (epoch 42.394), train_loss = 0.86120410, grad/param norm = 2.4565e-01, time/batch = 15.1514s	
25310/29850 (epoch 42.395), train_loss = 0.77935652, grad/param norm = 3.0731e-01, time/batch = 15.6038s	
25311/29850 (epoch 42.397), train_loss = 0.68868367, grad/param norm = 2.2311e-01, time/batch = 15.3215s	
25312/29850 (epoch 42.399), train_loss = 0.76114331, grad/param norm = 2.9198e-01, time/batch = 15.2126s	
25313/29850 (epoch 42.400), train_loss = 1.08852734, grad/param norm = 2.8717e-01, time/batch = 15.2328s	
25314/29850 (epoch 42.402), train_loss = 0.93836764, grad/param norm = 2.7097e-01, time/batch = 15.7642s	
25315/29850 (epoch 42.404), train_loss = 0.82426096, grad/param norm = 2.4594e-01, time/batch = 15.3863s	
25316/29850 (epoch 42.405), train_loss = 0.76778287, grad/param norm = 2.6613e-01, time/batch = 15.0699s	
25317/29850 (epoch 42.407), train_loss = 0.71914874, grad/param norm = 1.8914e-01, time/batch = 15.3685s	
25318/29850 (epoch 42.409), train_loss = 0.83519690, grad/param norm = 2.8223e-01, time/batch = 15.3683s	
25319/29850 (epoch 42.410), train_loss = 0.91121893, grad/param norm = 2.4235e-01, time/batch = 14.9609s	
25320/29850 (epoch 42.412), train_loss = 0.90732219, grad/param norm = 2.3500e-01, time/batch = 15.2817s	
25321/29850 (epoch 42.414), train_loss = 0.83498341, grad/param norm = 2.4502e-01, time/batch = 15.2326s	
25322/29850 (epoch 42.415), train_loss = 0.81035982, grad/param norm = 2.0606e-01, time/batch = 15.6304s	
25323/29850 (epoch 42.417), train_loss = 0.91827950, grad/param norm = 2.5576e-01, time/batch = 15.6780s	
25324/29850 (epoch 42.419), train_loss = 0.78667292, grad/param norm = 2.2419e-01, time/batch = 15.4218s	
25325/29850 (epoch 42.420), train_loss = 0.80202889, grad/param norm = 2.3471e-01, time/batch = 15.1183s	
25326/29850 (epoch 42.422), train_loss = 0.81050308, grad/param norm = 2.2782e-01, time/batch = 15.3063s	
25327/29850 (epoch 42.424), train_loss = 0.70592818, grad/param norm = 1.9753e-01, time/batch = 15.1516s	
25328/29850 (epoch 42.425), train_loss = 0.87970184, grad/param norm = 2.7174e-01, time/batch = 15.5356s	
25329/29850 (epoch 42.427), train_loss = 0.63022030, grad/param norm = 2.2147e-01, time/batch = 15.7407s	
25330/29850 (epoch 42.429), train_loss = 0.71081059, grad/param norm = 2.2361e-01, time/batch = 15.5244s	
25331/29850 (epoch 42.430), train_loss = 0.65770471, grad/param norm = 2.0627e-01, time/batch = 15.1447s	
25332/29850 (epoch 42.432), train_loss = 0.75883064, grad/param norm = 2.3139e-01, time/batch = 14.9838s	
25333/29850 (epoch 42.434), train_loss = 0.74318526, grad/param norm = 2.0169e-01, time/batch = 15.2051s	
25334/29850 (epoch 42.436), train_loss = 0.78067067, grad/param norm = 2.6655e-01, time/batch = 15.3083s	
25335/29850 (epoch 42.437), train_loss = 0.84465260, grad/param norm = 1.9678e-01, time/batch = 15.3812s	
25336/29850 (epoch 42.439), train_loss = 0.87144372, grad/param norm = 2.4260e-01, time/batch = 15.0678s	
25337/29850 (epoch 42.441), train_loss = 0.79640055, grad/param norm = 2.3556e-01, time/batch = 15.3582s	
25338/29850 (epoch 42.442), train_loss = 0.77565952, grad/param norm = 2.1625e-01, time/batch = 15.3816s	
25339/29850 (epoch 42.444), train_loss = 0.82567535, grad/param norm = 2.3509e-01, time/batch = 15.3524s	
25340/29850 (epoch 42.446), train_loss = 0.88803598, grad/param norm = 2.4852e-01, time/batch = 17.3604s	
25341/29850 (epoch 42.447), train_loss = 0.90626021, grad/param norm = 2.9172e-01, time/batch = 16.7020s	
25342/29850 (epoch 42.449), train_loss = 0.82352304, grad/param norm = 2.6135e-01, time/batch = 17.2048s	
25343/29850 (epoch 42.451), train_loss = 0.64540759, grad/param norm = 2.0983e-01, time/batch = 16.8703s	
25344/29850 (epoch 42.452), train_loss = 0.55814936, grad/param norm = 1.8873e-01, time/batch = 18.0148s	
25345/29850 (epoch 42.454), train_loss = 0.67327142, grad/param norm = 1.9267e-01, time/batch = 15.8426s	
25346/29850 (epoch 42.456), train_loss = 0.88934253, grad/param norm = 2.6275e-01, time/batch = 15.7993s	
25347/29850 (epoch 42.457), train_loss = 0.89185239, grad/param norm = 2.9964e-01, time/batch = 15.7745s	
25348/29850 (epoch 42.459), train_loss = 0.92174708, grad/param norm = 2.4018e-01, time/batch = 15.5211s	
25349/29850 (epoch 42.461), train_loss = 0.95036632, grad/param norm = 2.4495e-01, time/batch = 15.5530s	
25350/29850 (epoch 42.462), train_loss = 0.94515165, grad/param norm = 2.5222e-01, time/batch = 15.7248s	
25351/29850 (epoch 42.464), train_loss = 0.86760988, grad/param norm = 2.6163e-01, time/batch = 15.8169s	
25352/29850 (epoch 42.466), train_loss = 0.70276892, grad/param norm = 2.7055e-01, time/batch = 16.0213s	
25353/29850 (epoch 42.467), train_loss = 0.75045437, grad/param norm = 2.1772e-01, time/batch = 15.3926s	
25354/29850 (epoch 42.469), train_loss = 0.76984502, grad/param norm = 2.0254e-01, time/batch = 15.5479s	
25355/29850 (epoch 42.471), train_loss = 0.77781624, grad/param norm = 2.5919e-01, time/batch = 15.3936s	
25356/29850 (epoch 42.472), train_loss = 0.74484349, grad/param norm = 2.1672e-01, time/batch = 15.6234s	
25357/29850 (epoch 42.474), train_loss = 0.88614056, grad/param norm = 2.6031e-01, time/batch = 15.6838s	
25358/29850 (epoch 42.476), train_loss = 0.81495840, grad/param norm = 2.0596e-01, time/batch = 15.8724s	
25359/29850 (epoch 42.477), train_loss = 0.84708339, grad/param norm = 2.4707e-01, time/batch = 15.8023s	
25360/29850 (epoch 42.479), train_loss = 0.96793957, grad/param norm = 2.4972e-01, time/batch = 15.7160s	
25361/29850 (epoch 42.481), train_loss = 0.81368833, grad/param norm = 2.2689e-01, time/batch = 16.1413s	
25362/29850 (epoch 42.482), train_loss = 0.72864563, grad/param norm = 1.7684e-01, time/batch = 15.8707s	
25363/29850 (epoch 42.484), train_loss = 0.76456131, grad/param norm = 2.2092e-01, time/batch = 15.7869s	
25364/29850 (epoch 42.486), train_loss = 0.82810498, grad/param norm = 3.7453e-01, time/batch = 15.5633s	
25365/29850 (epoch 42.487), train_loss = 0.82350899, grad/param norm = 2.3276e-01, time/batch = 15.4627s	
25366/29850 (epoch 42.489), train_loss = 0.82201948, grad/param norm = 2.5222e-01, time/batch = 15.7235s	
25367/29850 (epoch 42.491), train_loss = 0.72291918, grad/param norm = 2.1009e-01, time/batch = 15.7830s	
25368/29850 (epoch 42.492), train_loss = 0.79867606, grad/param norm = 2.1780e-01, time/batch = 15.5561s	
25369/29850 (epoch 42.494), train_loss = 0.86736178, grad/param norm = 2.3385e-01, time/batch = 15.8333s	
25370/29850 (epoch 42.496), train_loss = 0.92266824, grad/param norm = 2.4389e-01, time/batch = 15.7705s	
25371/29850 (epoch 42.497), train_loss = 0.84706388, grad/param norm = 2.3181e-01, time/batch = 15.8134s	
25372/29850 (epoch 42.499), train_loss = 0.82095423, grad/param norm = 2.5960e-01, time/batch = 15.8618s	
25373/29850 (epoch 42.501), train_loss = 0.70567447, grad/param norm = 2.2221e-01, time/batch = 15.7834s	
25374/29850 (epoch 42.503), train_loss = 0.88740104, grad/param norm = 2.3975e-01, time/batch = 15.8543s	
25375/29850 (epoch 42.504), train_loss = 1.02884945, grad/param norm = 2.2212e-01, time/batch = 15.5317s	
25376/29850 (epoch 42.506), train_loss = 1.01565330, grad/param norm = 2.8793e-01, time/batch = 15.8151s	
25377/29850 (epoch 42.508), train_loss = 0.83684713, grad/param norm = 2.1658e-01, time/batch = 15.4576s	
25378/29850 (epoch 42.509), train_loss = 0.64467635, grad/param norm = 1.9953e-01, time/batch = 15.4287s	
25379/29850 (epoch 42.511), train_loss = 0.86595895, grad/param norm = 2.4517e-01, time/batch = 15.5324s	
25380/29850 (epoch 42.513), train_loss = 0.80592018, grad/param norm = 2.7272e-01, time/batch = 15.7639s	
25381/29850 (epoch 42.514), train_loss = 0.71250471, grad/param norm = 2.0181e-01, time/batch = 15.6239s	
25382/29850 (epoch 42.516), train_loss = 0.76895409, grad/param norm = 2.0476e-01, time/batch = 15.2965s	
25383/29850 (epoch 42.518), train_loss = 0.63791047, grad/param norm = 1.7744e-01, time/batch = 15.5334s	
25384/29850 (epoch 42.519), train_loss = 0.66553959, grad/param norm = 1.8378e-01, time/batch = 15.1435s	
25385/29850 (epoch 42.521), train_loss = 0.60969959, grad/param norm = 1.8451e-01, time/batch = 15.0632s	
25386/29850 (epoch 42.523), train_loss = 0.66841379, grad/param norm = 1.9771e-01, time/batch = 15.2755s	
25387/29850 (epoch 42.524), train_loss = 0.70949548, grad/param norm = 2.2379e-01, time/batch = 15.3283s	
25388/29850 (epoch 42.526), train_loss = 0.74236887, grad/param norm = 2.4893e-01, time/batch = 15.4621s	
25389/29850 (epoch 42.528), train_loss = 0.85643816, grad/param norm = 2.7802e-01, time/batch = 15.0636s	
25390/29850 (epoch 42.529), train_loss = 0.81394411, grad/param norm = 2.2074e-01, time/batch = 15.3643s	
25391/29850 (epoch 42.531), train_loss = 0.78317002, grad/param norm = 3.0634e-01, time/batch = 15.0513s	
25392/29850 (epoch 42.533), train_loss = 0.81981670, grad/param norm = 2.4477e-01, time/batch = 15.2873s	
25393/29850 (epoch 42.534), train_loss = 0.85184504, grad/param norm = 2.3086e-01, time/batch = 15.0713s	
25394/29850 (epoch 42.536), train_loss = 0.75863689, grad/param norm = 2.1889e-01, time/batch = 15.4386s	
25395/29850 (epoch 42.538), train_loss = 0.91700722, grad/param norm = 2.7466e-01, time/batch = 15.2167s	
25396/29850 (epoch 42.539), train_loss = 0.94343284, grad/param norm = 2.5827e-01, time/batch = 14.9776s	
25397/29850 (epoch 42.541), train_loss = 0.58503192, grad/param norm = 2.1174e-01, time/batch = 15.1415s	
25398/29850 (epoch 42.543), train_loss = 0.76836006, grad/param norm = 2.7553e-01, time/batch = 15.6233s	
25399/29850 (epoch 42.544), train_loss = 0.91347172, grad/param norm = 2.5388e-01, time/batch = 14.9843s	
25400/29850 (epoch 42.546), train_loss = 0.87856231, grad/param norm = 2.4079e-01, time/batch = 15.2169s	
25401/29850 (epoch 42.548), train_loss = 0.67076450, grad/param norm = 1.8942e-01, time/batch = 15.1997s	
25402/29850 (epoch 42.549), train_loss = 0.76820011, grad/param norm = 2.2131e-01, time/batch = 15.5138s	
25403/29850 (epoch 42.551), train_loss = 0.70783826, grad/param norm = 2.0269e-01, time/batch = 14.7370s	
25404/29850 (epoch 42.553), train_loss = 0.77567245, grad/param norm = 2.2645e-01, time/batch = 15.0710s	
25405/29850 (epoch 42.554), train_loss = 0.65531298, grad/param norm = 1.8864e-01, time/batch = 15.2247s	
25406/29850 (epoch 42.556), train_loss = 0.68834997, grad/param norm = 2.5116e-01, time/batch = 15.3025s	
25407/29850 (epoch 42.558), train_loss = 0.70858935, grad/param norm = 2.3592e-01, time/batch = 15.3649s	
25408/29850 (epoch 42.559), train_loss = 0.72815962, grad/param norm = 2.4966e-01, time/batch = 15.2069s	
25409/29850 (epoch 42.561), train_loss = 0.80999994, grad/param norm = 2.4822e-01, time/batch = 15.5942s	
25410/29850 (epoch 42.563), train_loss = 0.82274157, grad/param norm = 2.2824e-01, time/batch = 15.5235s	
25411/29850 (epoch 42.564), train_loss = 0.75851692, grad/param norm = 2.7754e-01, time/batch = 15.2169s	
25412/29850 (epoch 42.566), train_loss = 0.78057482, grad/param norm = 2.1026e-01, time/batch = 15.6398s	
25413/29850 (epoch 42.568), train_loss = 0.93177600, grad/param norm = 2.4870e-01, time/batch = 15.4383s	
25414/29850 (epoch 42.570), train_loss = 0.79928973, grad/param norm = 2.1330e-01, time/batch = 15.1439s	
25415/29850 (epoch 42.571), train_loss = 0.86851783, grad/param norm = 2.1809e-01, time/batch = 15.5479s	
25416/29850 (epoch 42.573), train_loss = 0.91453265, grad/param norm = 2.3736e-01, time/batch = 15.4228s	
25417/29850 (epoch 42.575), train_loss = 0.98060197, grad/param norm = 2.1546e-01, time/batch = 15.2873s	
25418/29850 (epoch 42.576), train_loss = 0.88034729, grad/param norm = 2.5543e-01, time/batch = 15.1441s	
25419/29850 (epoch 42.578), train_loss = 0.74102841, grad/param norm = 2.4975e-01, time/batch = 15.0506s	
25420/29850 (epoch 42.580), train_loss = 0.86998422, grad/param norm = 2.4040e-01, time/batch = 15.2110s	
25421/29850 (epoch 42.581), train_loss = 0.72729428, grad/param norm = 1.8999e-01, time/batch = 15.0557s	
25422/29850 (epoch 42.583), train_loss = 0.78820054, grad/param norm = 2.0998e-01, time/batch = 14.9922s	
25423/29850 (epoch 42.585), train_loss = 0.82143483, grad/param norm = 2.3506e-01, time/batch = 15.2031s	
25424/29850 (epoch 42.586), train_loss = 0.83028191, grad/param norm = 2.3721e-01, time/batch = 15.1270s	
25425/29850 (epoch 42.588), train_loss = 0.73175941, grad/param norm = 2.1033e-01, time/batch = 15.2930s	
25426/29850 (epoch 42.590), train_loss = 0.74531263, grad/param norm = 1.9324e-01, time/batch = 15.3018s	
25427/29850 (epoch 42.591), train_loss = 0.78008988, grad/param norm = 2.6050e-01, time/batch = 15.0557s	
25428/29850 (epoch 42.593), train_loss = 0.70872151, grad/param norm = 2.2960e-01, time/batch = 15.6695s	
25429/29850 (epoch 42.595), train_loss = 0.66497405, grad/param norm = 1.8238e-01, time/batch = 15.4250s	
25430/29850 (epoch 42.596), train_loss = 0.69767686, grad/param norm = 2.3066e-01, time/batch = 15.3028s	
25431/29850 (epoch 42.598), train_loss = 0.76631425, grad/param norm = 2.0338e-01, time/batch = 15.2266s	
25432/29850 (epoch 42.600), train_loss = 0.80782109, grad/param norm = 2.1023e-01, time/batch = 15.3031s	
25433/29850 (epoch 42.601), train_loss = 0.68235663, grad/param norm = 2.1097e-01, time/batch = 15.7830s	
25434/29850 (epoch 42.603), train_loss = 0.72348345, grad/param norm = 2.1691e-01, time/batch = 16.2170s	
25435/29850 (epoch 42.605), train_loss = 0.76743953, grad/param norm = 2.3377e-01, time/batch = 15.8719s	
25436/29850 (epoch 42.606), train_loss = 0.52750508, grad/param norm = 1.7156e-01, time/batch = 16.1916s	
25437/29850 (epoch 42.608), train_loss = 0.66935035, grad/param norm = 1.9343e-01, time/batch = 16.3789s	
25438/29850 (epoch 42.610), train_loss = 0.72205047, grad/param norm = 1.9671e-01, time/batch = 15.9026s	
25439/29850 (epoch 42.611), train_loss = 0.67233010, grad/param norm = 1.9483e-01, time/batch = 15.6174s	
25440/29850 (epoch 42.613), train_loss = 0.57330691, grad/param norm = 1.6875e-01, time/batch = 15.7162s	
25441/29850 (epoch 42.615), train_loss = 0.63906276, grad/param norm = 1.9003e-01, time/batch = 15.5311s	
25442/29850 (epoch 42.616), train_loss = 0.66244745, grad/param norm = 2.2380e-01, time/batch = 16.8734s	
25443/29850 (epoch 42.618), train_loss = 0.73293752, grad/param norm = 2.3597e-01, time/batch = 18.6040s	
25444/29850 (epoch 42.620), train_loss = 0.81736714, grad/param norm = 2.2555e-01, time/batch = 16.6739s	
25445/29850 (epoch 42.621), train_loss = 0.89863477, grad/param norm = 2.9078e-01, time/batch = 16.9536s	
25446/29850 (epoch 42.623), train_loss = 0.86119421, grad/param norm = 2.2376e-01, time/batch = 18.4200s	
25447/29850 (epoch 42.625), train_loss = 0.78741580, grad/param norm = 2.1612e-01, time/batch = 17.3732s	
25448/29850 (epoch 42.626), train_loss = 0.80632865, grad/param norm = 2.5065e-01, time/batch = 16.3487s	
25449/29850 (epoch 42.628), train_loss = 0.78736950, grad/param norm = 2.4992e-01, time/batch = 16.1377s	
25450/29850 (epoch 42.630), train_loss = 0.79711052, grad/param norm = 2.5380e-01, time/batch = 18.1202s	
25451/29850 (epoch 42.631), train_loss = 0.81006251, grad/param norm = 2.2221e-01, time/batch = 16.8732s	
25452/29850 (epoch 42.633), train_loss = 0.80576198, grad/param norm = 2.5717e-01, time/batch = 18.3589s	
25453/29850 (epoch 42.635), train_loss = 0.74688181, grad/param norm = 2.2863e-01, time/batch = 18.9457s	
25454/29850 (epoch 42.637), train_loss = 0.69276014, grad/param norm = 2.3944e-01, time/batch = 17.3371s	
25455/29850 (epoch 42.638), train_loss = 0.81155820, grad/param norm = 2.3297e-01, time/batch = 18.2002s	
25456/29850 (epoch 42.640), train_loss = 0.91887680, grad/param norm = 2.7948e-01, time/batch = 17.0410s	
25457/29850 (epoch 42.642), train_loss = 0.76783829, grad/param norm = 2.2764e-01, time/batch = 19.1159s	
25458/29850 (epoch 42.643), train_loss = 0.71201381, grad/param norm = 2.4624e-01, time/batch = 18.3558s	
25459/29850 (epoch 42.645), train_loss = 0.77321398, grad/param norm = 2.1015e-01, time/batch = 17.9405s	
25460/29850 (epoch 42.647), train_loss = 0.90423495, grad/param norm = 2.6407e-01, time/batch = 19.0341s	
25461/29850 (epoch 42.648), train_loss = 0.73015637, grad/param norm = 2.2419e-01, time/batch = 16.8528s	
25462/29850 (epoch 42.650), train_loss = 0.81128497, grad/param norm = 2.3375e-01, time/batch = 15.6912s	
25463/29850 (epoch 42.652), train_loss = 0.81402050, grad/param norm = 2.7437e-01, time/batch = 15.1752s	
25464/29850 (epoch 42.653), train_loss = 0.90009073, grad/param norm = 2.7614e-01, time/batch = 15.8953s	
25465/29850 (epoch 42.655), train_loss = 0.81123703, grad/param norm = 2.1686e-01, time/batch = 15.6925s	
25466/29850 (epoch 42.657), train_loss = 0.78505150, grad/param norm = 2.0248e-01, time/batch = 18.5380s	
25467/29850 (epoch 42.658), train_loss = 0.89082541, grad/param norm = 2.5509e-01, time/batch = 18.2287s	
25468/29850 (epoch 42.660), train_loss = 0.76416237, grad/param norm = 2.3894e-01, time/batch = 16.5511s	
25469/29850 (epoch 42.662), train_loss = 0.88168539, grad/param norm = 2.5081e-01, time/batch = 18.2814s	
25470/29850 (epoch 42.663), train_loss = 0.98810916, grad/param norm = 2.2638e-01, time/batch = 18.1935s	
25471/29850 (epoch 42.665), train_loss = 0.93627184, grad/param norm = 2.9917e-01, time/batch = 18.2528s	
25472/29850 (epoch 42.667), train_loss = 0.86485267, grad/param norm = 3.2353e-01, time/batch = 18.7803s	
25473/29850 (epoch 42.668), train_loss = 0.76353583, grad/param norm = 2.1379e-01, time/batch = 15.6010s	
25474/29850 (epoch 42.670), train_loss = 0.87889490, grad/param norm = 3.2852e-01, time/batch = 16.4749s	
25475/29850 (epoch 42.672), train_loss = 0.88402800, grad/param norm = 2.3779e-01, time/batch = 15.1335s	
25476/29850 (epoch 42.673), train_loss = 0.82305781, grad/param norm = 2.6045e-01, time/batch = 15.4328s	
25477/29850 (epoch 42.675), train_loss = 0.72500528, grad/param norm = 2.4113e-01, time/batch = 15.0258s	
25478/29850 (epoch 42.677), train_loss = 0.74689414, grad/param norm = 2.5230e-01, time/batch = 16.3615s	
25479/29850 (epoch 42.678), train_loss = 0.79118755, grad/param norm = 2.3923e-01, time/batch = 17.1012s	
25480/29850 (epoch 42.680), train_loss = 0.77893045, grad/param norm = 2.2979e-01, time/batch = 17.5610s	
25481/29850 (epoch 42.682), train_loss = 0.77861816, grad/param norm = 2.0889e-01, time/batch = 17.8778s	
25482/29850 (epoch 42.683), train_loss = 0.91357605, grad/param norm = 2.9530e-01, time/batch = 23.4836s	
25483/29850 (epoch 42.685), train_loss = 1.00509090, grad/param norm = 2.6245e-01, time/batch = 21.8780s	
25484/29850 (epoch 42.687), train_loss = 0.82751834, grad/param norm = 2.0957e-01, time/batch = 17.4427s	
25485/29850 (epoch 42.688), train_loss = 0.72330825, grad/param norm = 2.2231e-01, time/batch = 16.4551s	
25486/29850 (epoch 42.690), train_loss = 0.70249899, grad/param norm = 2.1986e-01, time/batch = 17.8724s	
25487/29850 (epoch 42.692), train_loss = 0.88242967, grad/param norm = 2.1053e-01, time/batch = 19.5370s	
25488/29850 (epoch 42.693), train_loss = 0.78895225, grad/param norm = 1.9477e-01, time/batch = 17.3736s	
25489/29850 (epoch 42.695), train_loss = 0.70219571, grad/param norm = 2.1388e-01, time/batch = 17.2690s	
25490/29850 (epoch 42.697), train_loss = 0.80441927, grad/param norm = 2.4563e-01, time/batch = 16.6124s	
25491/29850 (epoch 42.698), train_loss = 0.90966057, grad/param norm = 2.4214e-01, time/batch = 15.3343s	
25492/29850 (epoch 42.700), train_loss = 0.85248493, grad/param norm = 2.8363e-01, time/batch = 16.1015s	
25493/29850 (epoch 42.702), train_loss = 0.82852233, grad/param norm = 2.4868e-01, time/batch = 16.1058s	
25494/29850 (epoch 42.704), train_loss = 0.69159343, grad/param norm = 2.2419e-01, time/batch = 19.2096s	
25495/29850 (epoch 42.705), train_loss = 0.79505032, grad/param norm = 2.2647e-01, time/batch = 16.7136s	
25496/29850 (epoch 42.707), train_loss = 0.73605681, grad/param norm = 2.5150e-01, time/batch = 16.8844s	
25497/29850 (epoch 42.709), train_loss = 0.77916458, grad/param norm = 2.3340e-01, time/batch = 15.6422s	
25498/29850 (epoch 42.710), train_loss = 0.72609357, grad/param norm = 2.5887e-01, time/batch = 17.8795s	
25499/29850 (epoch 42.712), train_loss = 0.83449382, grad/param norm = 2.2500e-01, time/batch = 16.7896s	
25500/29850 (epoch 42.714), train_loss = 0.87135962, grad/param norm = 2.5211e-01, time/batch = 15.1399s	
25501/29850 (epoch 42.715), train_loss = 0.81152054, grad/param norm = 2.2568e-01, time/batch = 15.8710s	
25502/29850 (epoch 42.717), train_loss = 0.61658444, grad/param norm = 2.1905e-01, time/batch = 16.0265s	
25503/29850 (epoch 42.719), train_loss = 0.75516864, grad/param norm = 2.0762e-01, time/batch = 15.6364s	
25504/29850 (epoch 42.720), train_loss = 0.75630336, grad/param norm = 1.9270e-01, time/batch = 14.8183s	
25505/29850 (epoch 42.722), train_loss = 0.71924777, grad/param norm = 1.8222e-01, time/batch = 14.4202s	
25506/29850 (epoch 42.724), train_loss = 0.81439910, grad/param norm = 2.1119e-01, time/batch = 14.3379s	
25507/29850 (epoch 42.725), train_loss = 0.68266280, grad/param norm = 1.9668e-01, time/batch = 14.9732s	
25508/29850 (epoch 42.727), train_loss = 0.65951613, grad/param norm = 2.0079e-01, time/batch = 14.0919s	
25509/29850 (epoch 42.729), train_loss = 0.65079892, grad/param norm = 1.7300e-01, time/batch = 15.2483s	
25510/29850 (epoch 42.730), train_loss = 0.63271434, grad/param norm = 2.2806e-01, time/batch = 14.3038s	
25511/29850 (epoch 42.732), train_loss = 0.87200200, grad/param norm = 2.0853e-01, time/batch = 14.6370s	
25512/29850 (epoch 42.734), train_loss = 0.95830010, grad/param norm = 2.6564e-01, time/batch = 14.6376s	
25513/29850 (epoch 42.735), train_loss = 0.71930625, grad/param norm = 2.2696e-01, time/batch = 14.2530s	
25514/29850 (epoch 42.737), train_loss = 0.67923471, grad/param norm = 1.9605e-01, time/batch = 14.3161s	
25515/29850 (epoch 42.739), train_loss = 0.60828222, grad/param norm = 1.9971e-01, time/batch = 14.4757s	
25516/29850 (epoch 42.740), train_loss = 0.64281628, grad/param norm = 2.1607e-01, time/batch = 14.2500s	
25517/29850 (epoch 42.742), train_loss = 0.58164153, grad/param norm = 1.5765e-01, time/batch = 14.3262s	
25518/29850 (epoch 42.744), train_loss = 0.69307970, grad/param norm = 2.3060e-01, time/batch = 13.9311s	
25519/29850 (epoch 42.745), train_loss = 0.73559825, grad/param norm = 3.0719e-01, time/batch = 14.4707s	
25520/29850 (epoch 42.747), train_loss = 0.76903139, grad/param norm = 2.1283e-01, time/batch = 14.4183s	
25521/29850 (epoch 42.749), train_loss = 0.64670688, grad/param norm = 1.9488e-01, time/batch = 15.0987s	
25522/29850 (epoch 42.750), train_loss = 0.61215315, grad/param norm = 2.5191e-01, time/batch = 14.2395s	
25523/29850 (epoch 42.752), train_loss = 0.54343551, grad/param norm = 1.9777e-01, time/batch = 14.4760s	
25524/29850 (epoch 42.754), train_loss = 0.58689453, grad/param norm = 2.1272e-01, time/batch = 14.5774s	
25525/29850 (epoch 42.755), train_loss = 0.62519847, grad/param norm = 2.3318e-01, time/batch = 14.3455s	
25526/29850 (epoch 42.757), train_loss = 0.66509578, grad/param norm = 1.8202e-01, time/batch = 14.4160s	
25527/29850 (epoch 42.759), train_loss = 0.67551683, grad/param norm = 2.0450e-01, time/batch = 14.6597s	
25528/29850 (epoch 42.760), train_loss = 0.69886311, grad/param norm = 2.2865e-01, time/batch = 14.7183s	
25529/29850 (epoch 42.762), train_loss = 0.62997920, grad/param norm = 2.4417e-01, time/batch = 14.4013s	
25530/29850 (epoch 42.764), train_loss = 0.55747965, grad/param norm = 2.2405e-01, time/batch = 14.8113s	
25531/29850 (epoch 42.765), train_loss = 0.70986881, grad/param norm = 2.2097e-01, time/batch = 14.8913s	
25532/29850 (epoch 42.767), train_loss = 0.70466038, grad/param norm = 2.1181e-01, time/batch = 15.6474s	
25533/29850 (epoch 42.769), train_loss = 0.76578391, grad/param norm = 2.2161e-01, time/batch = 14.8589s	
25534/29850 (epoch 42.771), train_loss = 0.75306297, grad/param norm = 2.2940e-01, time/batch = 15.4130s	
25535/29850 (epoch 42.772), train_loss = 0.75665976, grad/param norm = 2.4614e-01, time/batch = 14.7960s	
25536/29850 (epoch 42.774), train_loss = 0.68728199, grad/param norm = 2.0358e-01, time/batch = 14.4887s	
25537/29850 (epoch 42.776), train_loss = 0.72034370, grad/param norm = 2.1956e-01, time/batch = 14.8776s	
25538/29850 (epoch 42.777), train_loss = 0.82151851, grad/param norm = 2.3927e-01, time/batch = 14.3391s	
25539/29850 (epoch 42.779), train_loss = 0.67210392, grad/param norm = 1.9996e-01, time/batch = 14.7974s	
25540/29850 (epoch 42.781), train_loss = 0.78178797, grad/param norm = 2.0717e-01, time/batch = 15.0349s	
25541/29850 (epoch 42.782), train_loss = 0.79949481, grad/param norm = 2.1995e-01, time/batch = 14.6993s	
25542/29850 (epoch 42.784), train_loss = 0.62166855, grad/param norm = 2.4412e-01, time/batch = 14.3288s	
25543/29850 (epoch 42.786), train_loss = 0.69044439, grad/param norm = 2.2787e-01, time/batch = 15.0203s	
25544/29850 (epoch 42.787), train_loss = 0.58668702, grad/param norm = 2.2719e-01, time/batch = 15.1985s	
25545/29850 (epoch 42.789), train_loss = 0.59741838, grad/param norm = 1.9515e-01, time/batch = 14.8078s	
25546/29850 (epoch 42.791), train_loss = 0.68087969, grad/param norm = 2.9274e-01, time/batch = 14.5810s	
25547/29850 (epoch 42.792), train_loss = 0.78503470, grad/param norm = 2.5062e-01, time/batch = 14.7376s	
25548/29850 (epoch 42.794), train_loss = 0.76259702, grad/param norm = 2.1808e-01, time/batch = 14.8256s	
25549/29850 (epoch 42.796), train_loss = 0.65837869, grad/param norm = 2.0463e-01, time/batch = 14.8850s	
25550/29850 (epoch 42.797), train_loss = 0.57655566, grad/param norm = 2.0246e-01, time/batch = 14.8075s	
25551/29850 (epoch 42.799), train_loss = 0.61928115, grad/param norm = 1.7994e-01, time/batch = 14.5691s	
25552/29850 (epoch 42.801), train_loss = 0.61969221, grad/param norm = 1.8617e-01, time/batch = 14.7223s	
25553/29850 (epoch 42.802), train_loss = 0.59884651, grad/param norm = 2.0855e-01, time/batch = 14.6235s	
25554/29850 (epoch 42.804), train_loss = 0.64550997, grad/param norm = 1.8952e-01, time/batch = 14.7962s	
25555/29850 (epoch 42.806), train_loss = 0.57940274, grad/param norm = 1.9271e-01, time/batch = 14.3956s	
25556/29850 (epoch 42.807), train_loss = 0.62122956, grad/param norm = 1.7287e-01, time/batch = 15.1569s	
25557/29850 (epoch 42.809), train_loss = 0.64678343, grad/param norm = 3.1711e-01, time/batch = 14.6393s	
25558/29850 (epoch 42.811), train_loss = 0.80040752, grad/param norm = 2.9086e-01, time/batch = 14.3317s	
25559/29850 (epoch 42.812), train_loss = 0.76252436, grad/param norm = 2.2161e-01, time/batch = 14.5001s	
25560/29850 (epoch 42.814), train_loss = 0.82286467, grad/param norm = 3.1370e-01, time/batch = 14.9495s	
25561/29850 (epoch 42.816), train_loss = 0.86935589, grad/param norm = 2.2191e-01, time/batch = 14.4668s	
25562/29850 (epoch 42.817), train_loss = 0.76255816, grad/param norm = 2.6449e-01, time/batch = 15.0952s	
25563/29850 (epoch 42.819), train_loss = 0.60341139, grad/param norm = 2.0500e-01, time/batch = 14.3776s	
25564/29850 (epoch 42.821), train_loss = 0.84748215, grad/param norm = 2.8289e-01, time/batch = 14.7918s	
25565/29850 (epoch 42.822), train_loss = 0.87036183, grad/param norm = 2.3758e-01, time/batch = 14.3402s	
25566/29850 (epoch 42.824), train_loss = 0.73727564, grad/param norm = 2.1790e-01, time/batch = 14.7994s	
25567/29850 (epoch 42.826), train_loss = 0.64178262, grad/param norm = 2.1167e-01, time/batch = 14.7247s	
25568/29850 (epoch 42.827), train_loss = 0.58388363, grad/param norm = 2.3981e-01, time/batch = 14.9604s	
25569/29850 (epoch 42.829), train_loss = 0.76277961, grad/param norm = 2.7865e-01, time/batch = 14.4975s	
25570/29850 (epoch 42.831), train_loss = 0.85217514, grad/param norm = 2.4489e-01, time/batch = 14.7284s	
25571/29850 (epoch 42.832), train_loss = 0.76547287, grad/param norm = 2.0722e-01, time/batch = 14.7455s	
25572/29850 (epoch 42.834), train_loss = 0.56713930, grad/param norm = 1.7902e-01, time/batch = 15.2066s	
25573/29850 (epoch 42.836), train_loss = 0.59295502, grad/param norm = 1.9203e-01, time/batch = 15.2628s	
25574/29850 (epoch 42.838), train_loss = 0.69424485, grad/param norm = 2.1389e-01, time/batch = 14.5662s	
25575/29850 (epoch 42.839), train_loss = 0.59850618, grad/param norm = 2.3485e-01, time/batch = 15.2508s	
25576/29850 (epoch 42.841), train_loss = 0.66697291, grad/param norm = 2.1112e-01, time/batch = 14.7057s	
25577/29850 (epoch 42.843), train_loss = 0.58764531, grad/param norm = 2.1470e-01, time/batch = 14.0884s	
25578/29850 (epoch 42.844), train_loss = 0.64787816, grad/param norm = 2.2613e-01, time/batch = 14.2486s	
25579/29850 (epoch 42.846), train_loss = 0.72397720, grad/param norm = 2.3066e-01, time/batch = 14.1755s	
25580/29850 (epoch 42.848), train_loss = 0.78336335, grad/param norm = 2.3747e-01, time/batch = 14.4669s	
25581/29850 (epoch 42.849), train_loss = 0.71979549, grad/param norm = 2.3952e-01, time/batch = 14.4930s	
25582/29850 (epoch 42.851), train_loss = 0.89029425, grad/param norm = 2.3444e-01, time/batch = 15.0418s	
25583/29850 (epoch 42.853), train_loss = 0.71274603, grad/param norm = 2.5560e-01, time/batch = 14.6346s	
25584/29850 (epoch 42.854), train_loss = 0.88129187, grad/param norm = 2.6913e-01, time/batch = 14.7251s	
25585/29850 (epoch 42.856), train_loss = 0.83409078, grad/param norm = 2.9220e-01, time/batch = 14.8370s	
25586/29850 (epoch 42.858), train_loss = 0.75464669, grad/param norm = 3.0181e-01, time/batch = 16.7209s	
25587/29850 (epoch 42.859), train_loss = 0.68123406, grad/param norm = 2.8133e-01, time/batch = 15.0676s	
25588/29850 (epoch 42.861), train_loss = 0.84323472, grad/param norm = 2.7208e-01, time/batch = 15.7646s	
25589/29850 (epoch 42.863), train_loss = 0.86121470, grad/param norm = 2.8864e-01, time/batch = 15.3545s	
25590/29850 (epoch 42.864), train_loss = 0.88618199, grad/param norm = 4.5289e-01, time/batch = 16.0107s	
25591/29850 (epoch 42.866), train_loss = 0.81188724, grad/param norm = 3.9297e-01, time/batch = 17.0042s	
25592/29850 (epoch 42.868), train_loss = 0.92783480, grad/param norm = 2.7697e-01, time/batch = 15.3700s	
25593/29850 (epoch 42.869), train_loss = 0.86539925, grad/param norm = 2.9880e-01, time/batch = 15.1278s	
25594/29850 (epoch 42.871), train_loss = 0.86960173, grad/param norm = 3.3503e-01, time/batch = 17.9686s	
25595/29850 (epoch 42.873), train_loss = 0.79877974, grad/param norm = 2.2363e-01, time/batch = 17.2132s	
25596/29850 (epoch 42.874), train_loss = 0.78267128, grad/param norm = 2.2657e-01, time/batch = 17.8835s	
25597/29850 (epoch 42.876), train_loss = 0.79101703, grad/param norm = 2.7252e-01, time/batch = 16.5628s	
25598/29850 (epoch 42.878), train_loss = 0.78702533, grad/param norm = 2.1638e-01, time/batch = 16.6488s	
25599/29850 (epoch 42.879), train_loss = 0.81116635, grad/param norm = 2.5547e-01, time/batch = 15.4223s	
25600/29850 (epoch 42.881), train_loss = 0.85451257, grad/param norm = 2.3331e-01, time/batch = 15.1224s	
25601/29850 (epoch 42.883), train_loss = 0.79141072, grad/param norm = 2.5081e-01, time/batch = 18.4529s	
25602/29850 (epoch 42.884), train_loss = 0.68284806, grad/param norm = 2.1374e-01, time/batch = 15.4497s	
25603/29850 (epoch 42.886), train_loss = 0.84515063, grad/param norm = 3.4866e-01, time/batch = 18.2932s	
25604/29850 (epoch 42.888), train_loss = 0.76727581, grad/param norm = 2.3686e-01, time/batch = 17.2925s	
25605/29850 (epoch 42.889), train_loss = 0.73951892, grad/param norm = 2.4118e-01, time/batch = 17.3936s	
25606/29850 (epoch 42.891), train_loss = 0.69542756, grad/param norm = 2.0661e-01, time/batch = 17.5498s	
25607/29850 (epoch 42.893), train_loss = 0.73736196, grad/param norm = 2.2331e-01, time/batch = 16.4677s	
25608/29850 (epoch 42.894), train_loss = 0.73010076, grad/param norm = 2.5564e-01, time/batch = 15.6079s	
25609/29850 (epoch 42.896), train_loss = 0.79770088, grad/param norm = 2.7377e-01, time/batch = 17.7115s	
25610/29850 (epoch 42.898), train_loss = 0.91471418, grad/param norm = 2.4477e-01, time/batch = 18.3757s	
25611/29850 (epoch 42.899), train_loss = 0.68334166, grad/param norm = 2.7321e-01, time/batch = 15.6749s	
25612/29850 (epoch 42.901), train_loss = 0.96428970, grad/param norm = 3.4115e-01, time/batch = 15.9799s	
25613/29850 (epoch 42.903), train_loss = 0.82491429, grad/param norm = 3.3926e-01, time/batch = 14.9766s	
25614/29850 (epoch 42.905), train_loss = 1.02197125, grad/param norm = 2.3274e-01, time/batch = 15.3148s	
25615/29850 (epoch 42.906), train_loss = 0.78736348, grad/param norm = 2.8070e-01, time/batch = 15.3728s	
25616/29850 (epoch 42.908), train_loss = 0.93557088, grad/param norm = 2.5560e-01, time/batch = 17.6416s	
25617/29850 (epoch 42.910), train_loss = 0.87586277, grad/param norm = 2.5827e-01, time/batch = 15.3855s	
25618/29850 (epoch 42.911), train_loss = 0.98568889, grad/param norm = 2.4984e-01, time/batch = 17.9549s	
25619/29850 (epoch 42.913), train_loss = 0.93275438, grad/param norm = 2.5756e-01, time/batch = 15.6443s	
25620/29850 (epoch 42.915), train_loss = 0.90948030, grad/param norm = 2.4153e-01, time/batch = 14.7215s	
25621/29850 (epoch 42.916), train_loss = 0.88224514, grad/param norm = 2.5534e-01, time/batch = 15.3010s	
25622/29850 (epoch 42.918), train_loss = 0.74288441, grad/param norm = 2.1473e-01, time/batch = 18.7177s	
25623/29850 (epoch 42.920), train_loss = 0.88757482, grad/param norm = 2.0037e-01, time/batch = 19.1261s	
25624/29850 (epoch 42.921), train_loss = 0.79005089, grad/param norm = 2.5972e-01, time/batch = 16.3865s	
25625/29850 (epoch 42.923), train_loss = 0.79999928, grad/param norm = 2.5438e-01, time/batch = 17.4570s	
25626/29850 (epoch 42.925), train_loss = 0.96563951, grad/param norm = 2.9654e-01, time/batch = 15.9699s	
25627/29850 (epoch 42.926), train_loss = 0.94557193, grad/param norm = 2.5744e-01, time/batch = 17.3816s	
25628/29850 (epoch 42.928), train_loss = 0.79263479, grad/param norm = 2.3411e-01, time/batch = 15.6875s	
25629/29850 (epoch 42.930), train_loss = 0.80850016, grad/param norm = 2.5725e-01, time/batch = 15.5093s	
25630/29850 (epoch 42.931), train_loss = 0.80814643, grad/param norm = 2.2066e-01, time/batch = 16.0070s	
25631/29850 (epoch 42.933), train_loss = 0.95770558, grad/param norm = 2.8899e-01, time/batch = 15.4039s	
25632/29850 (epoch 42.935), train_loss = 0.86965704, grad/param norm = 2.5022e-01, time/batch = 16.2185s	
25633/29850 (epoch 42.936), train_loss = 0.82582453, grad/param norm = 2.4532e-01, time/batch = 15.7098s	
25634/29850 (epoch 42.938), train_loss = 0.70864436, grad/param norm = 2.3016e-01, time/batch = 16.4454s	
25635/29850 (epoch 42.940), train_loss = 0.72761405, grad/param norm = 2.2727e-01, time/batch = 15.4506s	
25636/29850 (epoch 42.941), train_loss = 0.71475465, grad/param norm = 2.4609e-01, time/batch = 15.4871s	
25637/29850 (epoch 42.943), train_loss = 0.75690215, grad/param norm = 2.1990e-01, time/batch = 16.4742s	
25638/29850 (epoch 42.945), train_loss = 0.69165425, grad/param norm = 2.3242e-01, time/batch = 17.8465s	
25639/29850 (epoch 42.946), train_loss = 0.70036604, grad/param norm = 2.2817e-01, time/batch = 14.8770s	
25640/29850 (epoch 42.948), train_loss = 0.82632175, grad/param norm = 2.4361e-01, time/batch = 15.5995s	
25641/29850 (epoch 42.950), train_loss = 0.74162164, grad/param norm = 1.8014e-01, time/batch = 19.5327s	
25642/29850 (epoch 42.951), train_loss = 0.65703363, grad/param norm = 2.1026e-01, time/batch = 17.4610s	
25643/29850 (epoch 42.953), train_loss = 0.75096739, grad/param norm = 2.5074e-01, time/batch = 17.2098s	
25644/29850 (epoch 42.955), train_loss = 0.66414592, grad/param norm = 1.9117e-01, time/batch = 16.1949s	
25645/29850 (epoch 42.956), train_loss = 0.65911549, grad/param norm = 2.3473e-01, time/batch = 18.1972s	
25646/29850 (epoch 42.958), train_loss = 0.62016089, grad/param norm = 2.2211e-01, time/batch = 15.7511s	
25647/29850 (epoch 42.960), train_loss = 0.86807400, grad/param norm = 2.5831e-01, time/batch = 18.2042s	
25648/29850 (epoch 42.961), train_loss = 0.63512549, grad/param norm = 2.3444e-01, time/batch = 15.7601s	
25649/29850 (epoch 42.963), train_loss = 0.64316120, grad/param norm = 2.4196e-01, time/batch = 15.3568s	
25650/29850 (epoch 42.965), train_loss = 0.68259135, grad/param norm = 2.2441e-01, time/batch = 15.4651s	
25651/29850 (epoch 42.966), train_loss = 0.67317680, grad/param norm = 2.1928e-01, time/batch = 16.3966s	
25652/29850 (epoch 42.968), train_loss = 0.68656331, grad/param norm = 2.2923e-01, time/batch = 15.4546s	
25653/29850 (epoch 42.970), train_loss = 0.70895218, grad/param norm = 2.3672e-01, time/batch = 15.6026s	
25654/29850 (epoch 42.972), train_loss = 0.69607095, grad/param norm = 2.0896e-01, time/batch = 17.7934s	
25655/29850 (epoch 42.973), train_loss = 0.67552876, grad/param norm = 1.8634e-01, time/batch = 17.9670s	
25656/29850 (epoch 42.975), train_loss = 0.60616570, grad/param norm = 2.0141e-01, time/batch = 15.8108s	
25657/29850 (epoch 42.977), train_loss = 0.71788724, grad/param norm = 2.1536e-01, time/batch = 17.2058s	
25658/29850 (epoch 42.978), train_loss = 0.62111109, grad/param norm = 1.8095e-01, time/batch = 16.2328s	
25659/29850 (epoch 42.980), train_loss = 0.68094827, grad/param norm = 1.8926e-01, time/batch = 17.6199s	
25660/29850 (epoch 42.982), train_loss = 0.66699368, grad/param norm = 2.0791e-01, time/batch = 15.7003s	
25661/29850 (epoch 42.983), train_loss = 0.69194699, grad/param norm = 2.0440e-01, time/batch = 18.0449s	
25662/29850 (epoch 42.985), train_loss = 0.80209135, grad/param norm = 2.4083e-01, time/batch = 16.8738s	
25663/29850 (epoch 42.987), train_loss = 0.79881682, grad/param norm = 2.3361e-01, time/batch = 17.2079s	
25664/29850 (epoch 42.988), train_loss = 0.73125485, grad/param norm = 2.1052e-01, time/batch = 16.8135s	
25665/29850 (epoch 42.990), train_loss = 0.78666841, grad/param norm = 2.1237e-01, time/batch = 18.2938s	
25666/29850 (epoch 42.992), train_loss = 0.78078725, grad/param norm = 2.0251e-01, time/batch = 15.9258s	
25667/29850 (epoch 42.993), train_loss = 0.78377683, grad/param norm = 2.7012e-01, time/batch = 15.4009s	
25668/29850 (epoch 42.995), train_loss = 0.74926472, grad/param norm = 2.1115e-01, time/batch = 15.1766s	
25669/29850 (epoch 42.997), train_loss = 0.79240495, grad/param norm = 2.2847e-01, time/batch = 15.0273s	
25670/29850 (epoch 42.998), train_loss = 0.79899167, grad/param norm = 2.0186e-01, time/batch = 14.4906s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
25671/29850 (epoch 43.000), train_loss = 0.63769612, grad/param norm = 1.9628e-01, time/batch = 15.0455s	
25672/29850 (epoch 43.002), train_loss = 0.88627796, grad/param norm = 2.4049e-01, time/batch = 15.2058s	
25673/29850 (epoch 43.003), train_loss = 0.64221290, grad/param norm = 2.2546e-01, time/batch = 14.7963s	
25674/29850 (epoch 43.005), train_loss = 0.80788611, grad/param norm = 2.0121e-01, time/batch = 14.7166s	
25675/29850 (epoch 43.007), train_loss = 0.84569840, grad/param norm = 2.8164e-01, time/batch = 14.6585s	
25676/29850 (epoch 43.008), train_loss = 0.99249871, grad/param norm = 2.7292e-01, time/batch = 14.5698s	
25677/29850 (epoch 43.010), train_loss = 0.70294714, grad/param norm = 2.0607e-01, time/batch = 14.4842s	
25678/29850 (epoch 43.012), train_loss = 0.74481688, grad/param norm = 2.4773e-01, time/batch = 14.7952s	
25679/29850 (epoch 43.013), train_loss = 0.79084615, grad/param norm = 2.8503e-01, time/batch = 14.5720s	
25680/29850 (epoch 43.015), train_loss = 0.88805081, grad/param norm = 2.4658e-01, time/batch = 14.5667s	
25681/29850 (epoch 43.017), train_loss = 0.82942257, grad/param norm = 3.0169e-01, time/batch = 14.6659s	
25682/29850 (epoch 43.018), train_loss = 0.91366730, grad/param norm = 2.6665e-01, time/batch = 14.5513s	
25683/29850 (epoch 43.020), train_loss = 0.79739535, grad/param norm = 2.2715e-01, time/batch = 14.7335s	
25684/29850 (epoch 43.022), train_loss = 0.87373680, grad/param norm = 2.7196e-01, time/batch = 14.8934s	
25685/29850 (epoch 43.023), train_loss = 0.84332326, grad/param norm = 2.0605e-01, time/batch = 14.4968s	
25686/29850 (epoch 43.025), train_loss = 0.77033912, grad/param norm = 1.8884e-01, time/batch = 15.0117s	
25687/29850 (epoch 43.027), train_loss = 0.57411693, grad/param norm = 2.0489e-01, time/batch = 14.7863s	
25688/29850 (epoch 43.028), train_loss = 0.73057299, grad/param norm = 2.3352e-01, time/batch = 14.9679s	
25689/29850 (epoch 43.030), train_loss = 0.75245177, grad/param norm = 2.3305e-01, time/batch = 14.3468s	
25690/29850 (epoch 43.032), train_loss = 0.81286909, grad/param norm = 2.1413e-01, time/batch = 14.8793s	
25691/29850 (epoch 43.034), train_loss = 0.71147878, grad/param norm = 2.9809e-01, time/batch = 15.2008s	
25692/29850 (epoch 43.035), train_loss = 0.60528852, grad/param norm = 1.7963e-01, time/batch = 14.8272s	
25693/29850 (epoch 43.037), train_loss = 0.78993163, grad/param norm = 2.4443e-01, time/batch = 14.2602s	
25694/29850 (epoch 43.039), train_loss = 0.69834474, grad/param norm = 1.9620e-01, time/batch = 14.7936s	
25695/29850 (epoch 43.040), train_loss = 0.64249681, grad/param norm = 1.9312e-01, time/batch = 14.9712s	
25696/29850 (epoch 43.042), train_loss = 0.71231556, grad/param norm = 2.5199e-01, time/batch = 14.4985s	
25697/29850 (epoch 43.044), train_loss = 0.74337173, grad/param norm = 1.9081e-01, time/batch = 14.5763s	
25698/29850 (epoch 43.045), train_loss = 0.83019561, grad/param norm = 2.0334e-01, time/batch = 14.8816s	
25699/29850 (epoch 43.047), train_loss = 0.68843216, grad/param norm = 2.2518e-01, time/batch = 14.4914s	
25700/29850 (epoch 43.049), train_loss = 0.80895343, grad/param norm = 2.1186e-01, time/batch = 14.5720s	
25701/29850 (epoch 43.050), train_loss = 0.72352200, grad/param norm = 2.2427e-01, time/batch = 14.5835s	
25702/29850 (epoch 43.052), train_loss = 0.89261296, grad/param norm = 2.6210e-01, time/batch = 14.8738s	
25703/29850 (epoch 43.054), train_loss = 0.76461546, grad/param norm = 2.1339e-01, time/batch = 14.6513s	
25704/29850 (epoch 43.055), train_loss = 0.73256962, grad/param norm = 2.1461e-01, time/batch = 14.8147s	
25705/29850 (epoch 43.057), train_loss = 0.82278894, grad/param norm = 2.0997e-01, time/batch = 15.0316s	
25706/29850 (epoch 43.059), train_loss = 0.81028424, grad/param norm = 2.3024e-01, time/batch = 15.5588s	
25707/29850 (epoch 43.060), train_loss = 0.79054147, grad/param norm = 2.5506e-01, time/batch = 15.6272s	
25708/29850 (epoch 43.062), train_loss = 0.87347210, grad/param norm = 3.4671e-01, time/batch = 15.1200s	
25709/29850 (epoch 43.064), train_loss = 0.86344189, grad/param norm = 2.6710e-01, time/batch = 14.3299s	
25710/29850 (epoch 43.065), train_loss = 0.66170986, grad/param norm = 2.0192e-01, time/batch = 14.5690s	
25711/29850 (epoch 43.067), train_loss = 0.85627131, grad/param norm = 2.1976e-01, time/batch = 18.0025s	
25712/29850 (epoch 43.069), train_loss = 0.79966473, grad/param norm = 2.0484e-01, time/batch = 1.9644s	
25713/29850 (epoch 43.070), train_loss = 0.82988463, grad/param norm = 2.1749e-01, time/batch = 0.6685s	
25714/29850 (epoch 43.072), train_loss = 0.77748453, grad/param norm = 2.4765e-01, time/batch = 0.6697s	
25715/29850 (epoch 43.074), train_loss = 0.86093069, grad/param norm = 2.1964e-01, time/batch = 0.6543s	
25716/29850 (epoch 43.075), train_loss = 0.71424971, grad/param norm = 2.4748e-01, time/batch = 0.6801s	
25717/29850 (epoch 43.077), train_loss = 0.84650582, grad/param norm = 2.5436e-01, time/batch = 0.6867s	
25718/29850 (epoch 43.079), train_loss = 0.97580427, grad/param norm = 3.2063e-01, time/batch = 0.7309s	
25719/29850 (epoch 43.080), train_loss = 0.95666289, grad/param norm = 2.7364e-01, time/batch = 0.9927s	
25720/29850 (epoch 43.082), train_loss = 0.85495275, grad/param norm = 2.4331e-01, time/batch = 0.9920s	
25721/29850 (epoch 43.084), train_loss = 0.95908293, grad/param norm = 2.5521e-01, time/batch = 0.9663s	
25722/29850 (epoch 43.085), train_loss = 0.98173134, grad/param norm = 2.5620e-01, time/batch = 0.9934s	
25723/29850 (epoch 43.087), train_loss = 0.90073310, grad/param norm = 2.3487e-01, time/batch = 1.1283s	
25724/29850 (epoch 43.089), train_loss = 0.84037900, grad/param norm = 2.1818e-01, time/batch = 1.8111s	
25725/29850 (epoch 43.090), train_loss = 0.82310275, grad/param norm = 2.1777e-01, time/batch = 1.8272s	
25726/29850 (epoch 43.092), train_loss = 0.71576961, grad/param norm = 2.1279e-01, time/batch = 6.7727s	
25727/29850 (epoch 43.094), train_loss = 0.92838662, grad/param norm = 2.3904e-01, time/batch = 14.4957s	
25728/29850 (epoch 43.095), train_loss = 0.91622568, grad/param norm = 4.1885e-01, time/batch = 14.6605s	
25729/29850 (epoch 43.097), train_loss = 0.62109359, grad/param norm = 2.0831e-01, time/batch = 15.0449s	
25730/29850 (epoch 43.099), train_loss = 0.63625778, grad/param norm = 1.8067e-01, time/batch = 14.6379s	
25731/29850 (epoch 43.101), train_loss = 0.83734303, grad/param norm = 2.1169e-01, time/batch = 14.5816s	
25732/29850 (epoch 43.102), train_loss = 0.85577869, grad/param norm = 2.2895e-01, time/batch = 14.1756s	
25733/29850 (epoch 43.104), train_loss = 0.74876724, grad/param norm = 2.2145e-01, time/batch = 14.5727s	
25734/29850 (epoch 43.106), train_loss = 0.88614250, grad/param norm = 2.3497e-01, time/batch = 14.1667s	
25735/29850 (epoch 43.107), train_loss = 0.73549774, grad/param norm = 2.0346e-01, time/batch = 14.4781s	
25736/29850 (epoch 43.109), train_loss = 0.79593036, grad/param norm = 2.2429e-01, time/batch = 14.7048s	
25737/29850 (epoch 43.111), train_loss = 0.81321242, grad/param norm = 1.9725e-01, time/batch = 14.8910s	
25738/29850 (epoch 43.112), train_loss = 0.70920443, grad/param norm = 2.0290e-01, time/batch = 14.5645s	
25739/29850 (epoch 43.114), train_loss = 0.73011853, grad/param norm = 2.3623e-01, time/batch = 14.8767s	
25740/29850 (epoch 43.116), train_loss = 0.72180677, grad/param norm = 2.4044e-01, time/batch = 15.1716s	
25741/29850 (epoch 43.117), train_loss = 0.75683874, grad/param norm = 2.2519e-01, time/batch = 15.1795s	
25742/29850 (epoch 43.119), train_loss = 0.74618979, grad/param norm = 2.2362e-01, time/batch = 15.2601s	
25743/29850 (epoch 43.121), train_loss = 0.62843544, grad/param norm = 2.0245e-01, time/batch = 15.6395s	
25744/29850 (epoch 43.122), train_loss = 0.68141116, grad/param norm = 1.9163e-01, time/batch = 15.3377s	
25745/29850 (epoch 43.124), train_loss = 0.71292455, grad/param norm = 2.3729e-01, time/batch = 15.3647s	
25746/29850 (epoch 43.126), train_loss = 0.78570882, grad/param norm = 2.4349e-01, time/batch = 14.6402s	
25747/29850 (epoch 43.127), train_loss = 0.83048067, grad/param norm = 3.4171e-01, time/batch = 14.7326s	
25748/29850 (epoch 43.129), train_loss = 0.80446564, grad/param norm = 2.5257e-01, time/batch = 14.8132s	
25749/29850 (epoch 43.131), train_loss = 0.79929695, grad/param norm = 2.2406e-01, time/batch = 15.0407s	
25750/29850 (epoch 43.132), train_loss = 0.66477207, grad/param norm = 2.2838e-01, time/batch = 14.7267s	
25751/29850 (epoch 43.134), train_loss = 0.77189999, grad/param norm = 2.8105e-01, time/batch = 14.5763s	
25752/29850 (epoch 43.136), train_loss = 0.83238847, grad/param norm = 2.0483e-01, time/batch = 14.2627s	
25753/29850 (epoch 43.137), train_loss = 0.64941414, grad/param norm = 2.1627e-01, time/batch = 14.7176s	
25754/29850 (epoch 43.139), train_loss = 0.77230918, grad/param norm = 2.1164e-01, time/batch = 14.4837s	
25755/29850 (epoch 43.141), train_loss = 0.69270773, grad/param norm = 2.1481e-01, time/batch = 15.3410s	
25756/29850 (epoch 43.142), train_loss = 0.88185812, grad/param norm = 2.2838e-01, time/batch = 14.6397s	
25757/29850 (epoch 43.144), train_loss = 1.00503732, grad/param norm = 2.3974e-01, time/batch = 14.7344s	
25758/29850 (epoch 43.146), train_loss = 0.99247809, grad/param norm = 2.6955e-01, time/batch = 14.3261s	
25759/29850 (epoch 43.147), train_loss = 0.90260487, grad/param norm = 2.6690e-01, time/batch = 14.2532s	
25760/29850 (epoch 43.149), train_loss = 0.83673775, grad/param norm = 2.4709e-01, time/batch = 14.3379s	
25761/29850 (epoch 43.151), train_loss = 0.85280439, grad/param norm = 2.4421e-01, time/batch = 14.8733s	
25762/29850 (epoch 43.152), train_loss = 0.77630841, grad/param norm = 2.1601e-01, time/batch = 14.5805s	
25763/29850 (epoch 43.154), train_loss = 0.73139566, grad/param norm = 2.4036e-01, time/batch = 14.3220s	
25764/29850 (epoch 43.156), train_loss = 0.71263450, grad/param norm = 2.2020e-01, time/batch = 14.4904s	
25765/29850 (epoch 43.157), train_loss = 0.84183024, grad/param norm = 2.8546e-01, time/batch = 15.0471s	
25766/29850 (epoch 43.159), train_loss = 0.74178359, grad/param norm = 2.0533e-01, time/batch = 14.8001s	
25767/29850 (epoch 43.161), train_loss = 0.76671745, grad/param norm = 2.2090e-01, time/batch = 14.5759s	
25768/29850 (epoch 43.162), train_loss = 0.92791333, grad/param norm = 2.7976e-01, time/batch = 14.4919s	
25769/29850 (epoch 43.164), train_loss = 0.85508264, grad/param norm = 2.7304e-01, time/batch = 14.7085s	
25770/29850 (epoch 43.166), train_loss = 0.75543520, grad/param norm = 2.2579e-01, time/batch = 14.4989s	
25771/29850 (epoch 43.168), train_loss = 0.69947105, grad/param norm = 1.9963e-01, time/batch = 15.0334s	
25772/29850 (epoch 43.169), train_loss = 0.91119943, grad/param norm = 2.9543e-01, time/batch = 14.3974s	
25773/29850 (epoch 43.171), train_loss = 0.86386492, grad/param norm = 2.4902e-01, time/batch = 15.2934s	
25774/29850 (epoch 43.173), train_loss = 0.68061632, grad/param norm = 2.6329e-01, time/batch = 14.4720s	
25775/29850 (epoch 43.174), train_loss = 0.76288735, grad/param norm = 2.6709e-01, time/batch = 14.1550s	
25776/29850 (epoch 43.176), train_loss = 0.83133985, grad/param norm = 2.4036e-01, time/batch = 14.8092s	
25777/29850 (epoch 43.178), train_loss = 0.83124264, grad/param norm = 2.3362e-01, time/batch = 14.8034s	
25778/29850 (epoch 43.179), train_loss = 0.64444266, grad/param norm = 2.2368e-01, time/batch = 15.5653s	
25779/29850 (epoch 43.181), train_loss = 0.82402380, grad/param norm = 2.4366e-01, time/batch = 15.1890s	
25780/29850 (epoch 43.183), train_loss = 0.79815626, grad/param norm = 2.1801e-01, time/batch = 14.8052s	
25781/29850 (epoch 43.184), train_loss = 0.89833950, grad/param norm = 2.8617e-01, time/batch = 14.8123s	
25782/29850 (epoch 43.186), train_loss = 0.85059841, grad/param norm = 2.7256e-01, time/batch = 14.6477s	
25783/29850 (epoch 43.188), train_loss = 0.94893654, grad/param norm = 2.8192e-01, time/batch = 14.3251s	
25784/29850 (epoch 43.189), train_loss = 0.85751289, grad/param norm = 2.4517e-01, time/batch = 14.5021s	
25785/29850 (epoch 43.191), train_loss = 0.90599946, grad/param norm = 2.5335e-01, time/batch = 14.4939s	
25786/29850 (epoch 43.193), train_loss = 0.79413540, grad/param norm = 2.2469e-01, time/batch = 15.3892s	
25787/29850 (epoch 43.194), train_loss = 0.89916719, grad/param norm = 2.4337e-01, time/batch = 14.7151s	
25788/29850 (epoch 43.196), train_loss = 0.75900443, grad/param norm = 2.1263e-01, time/batch = 14.4082s	
25789/29850 (epoch 43.198), train_loss = 0.72021640, grad/param norm = 2.1884e-01, time/batch = 14.2396s	
25790/29850 (epoch 43.199), train_loss = 1.01602364, grad/param norm = 2.8583e-01, time/batch = 14.2498s	
25791/29850 (epoch 43.201), train_loss = 0.72180523, grad/param norm = 2.1056e-01, time/batch = 14.2527s	
25792/29850 (epoch 43.203), train_loss = 0.58628312, grad/param norm = 2.6544e-01, time/batch = 15.4769s	
25793/29850 (epoch 43.204), train_loss = 0.77636847, grad/param norm = 2.4908e-01, time/batch = 14.9233s	
25794/29850 (epoch 43.206), train_loss = 0.69096148, grad/param norm = 2.2707e-01, time/batch = 14.4973s	
25795/29850 (epoch 43.208), train_loss = 0.92926503, grad/param norm = 3.0636e-01, time/batch = 15.0504s	
25796/29850 (epoch 43.209), train_loss = 0.71362740, grad/param norm = 2.2439e-01, time/batch = 14.5700s	
25797/29850 (epoch 43.211), train_loss = 0.76388258, grad/param norm = 2.6310e-01, time/batch = 14.0862s	
25798/29850 (epoch 43.213), train_loss = 0.83423361, grad/param norm = 2.2688e-01, time/batch = 14.4846s	
25799/29850 (epoch 43.214), train_loss = 0.65891196, grad/param norm = 1.8352e-01, time/batch = 14.5753s	
25800/29850 (epoch 43.216), train_loss = 0.69509472, grad/param norm = 2.0715e-01, time/batch = 14.5840s	
25801/29850 (epoch 43.218), train_loss = 0.80448272, grad/param norm = 2.2162e-01, time/batch = 15.2064s	
25802/29850 (epoch 43.219), train_loss = 0.81862573, grad/param norm = 3.1704e-01, time/batch = 15.3949s	
25803/29850 (epoch 43.221), train_loss = 0.78132991, grad/param norm = 2.3831e-01, time/batch = 14.6487s	
25804/29850 (epoch 43.223), train_loss = 0.63164072, grad/param norm = 2.0269e-01, time/batch = 14.3396s	
25805/29850 (epoch 43.224), train_loss = 0.63532022, grad/param norm = 2.0235e-01, time/batch = 14.4947s	
25806/29850 (epoch 43.226), train_loss = 0.71308717, grad/param norm = 1.9673e-01, time/batch = 15.1203s	
25807/29850 (epoch 43.228), train_loss = 0.74199538, grad/param norm = 2.0073e-01, time/batch = 14.4128s	
25808/29850 (epoch 43.229), train_loss = 0.65668360, grad/param norm = 2.1421e-01, time/batch = 14.5668s	
25809/29850 (epoch 43.231), train_loss = 0.79873129, grad/param norm = 2.1848e-01, time/batch = 14.8062s	
25810/29850 (epoch 43.233), train_loss = 0.75682731, grad/param norm = 2.4918e-01, time/batch = 15.0449s	
25811/29850 (epoch 43.235), train_loss = 0.72034366, grad/param norm = 2.0344e-01, time/batch = 14.8109s	
25812/29850 (epoch 43.236), train_loss = 0.92603531, grad/param norm = 2.5848e-01, time/batch = 15.0315s	
25813/29850 (epoch 43.238), train_loss = 0.66603097, grad/param norm = 2.4522e-01, time/batch = 15.4125s	
25814/29850 (epoch 43.240), train_loss = 0.67424781, grad/param norm = 2.4105e-01, time/batch = 14.9718s	
25815/29850 (epoch 43.241), train_loss = 0.78241693, grad/param norm = 2.1919e-01, time/batch = 15.0646s	
25816/29850 (epoch 43.243), train_loss = 0.82829800, grad/param norm = 2.4581e-01, time/batch = 15.7282s	
25817/29850 (epoch 43.245), train_loss = 0.69156879, grad/param norm = 2.0110e-01, time/batch = 15.4536s	
25818/29850 (epoch 43.246), train_loss = 0.70449820, grad/param norm = 1.8213e-01, time/batch = 15.2092s	
25819/29850 (epoch 43.248), train_loss = 0.66505308, grad/param norm = 2.0084e-01, time/batch = 14.9669s	
25820/29850 (epoch 43.250), train_loss = 0.71647575, grad/param norm = 1.8117e-01, time/batch = 15.2855s	
25821/29850 (epoch 43.251), train_loss = 0.62974615, grad/param norm = 2.1234e-01, time/batch = 15.4504s	
25822/29850 (epoch 43.253), train_loss = 0.64134011, grad/param norm = 2.4128e-01, time/batch = 15.3740s	
25823/29850 (epoch 43.255), train_loss = 0.67914888, grad/param norm = 2.1639e-01, time/batch = 15.0655s	
25824/29850 (epoch 43.256), train_loss = 0.81196241, grad/param norm = 2.2806e-01, time/batch = 15.1220s	
25825/29850 (epoch 43.258), train_loss = 0.82070369, grad/param norm = 2.6726e-01, time/batch = 15.1398s	
25826/29850 (epoch 43.260), train_loss = 0.73444723, grad/param norm = 1.8655e-01, time/batch = 15.6077s	
25827/29850 (epoch 43.261), train_loss = 0.67007664, grad/param norm = 2.2296e-01, time/batch = 14.9794s	
25828/29850 (epoch 43.263), train_loss = 0.67659474, grad/param norm = 1.8406e-01, time/batch = 14.8925s	
25829/29850 (epoch 43.265), train_loss = 0.74777692, grad/param norm = 2.4591e-01, time/batch = 15.1506s	
25830/29850 (epoch 43.266), train_loss = 0.77458626, grad/param norm = 2.3551e-01, time/batch = 15.2967s	
25831/29850 (epoch 43.268), train_loss = 0.73558333, grad/param norm = 1.8411e-01, time/batch = 15.3866s	
25832/29850 (epoch 43.270), train_loss = 0.70143827, grad/param norm = 2.3517e-01, time/batch = 14.9829s	
25833/29850 (epoch 43.271), train_loss = 0.79911942, grad/param norm = 2.2663e-01, time/batch = 15.5704s	
25834/29850 (epoch 43.273), train_loss = 0.66568461, grad/param norm = 1.9296e-01, time/batch = 14.8989s	
25835/29850 (epoch 43.275), train_loss = 0.66352274, grad/param norm = 2.0643e-01, time/batch = 15.2695s	
25836/29850 (epoch 43.276), train_loss = 0.66000630, grad/param norm = 1.9547e-01, time/batch = 15.3776s	
25837/29850 (epoch 43.278), train_loss = 0.71791231, grad/param norm = 2.2833e-01, time/batch = 15.2326s	
25838/29850 (epoch 43.280), train_loss = 0.94068991, grad/param norm = 3.0312e-01, time/batch = 15.5113s	
25839/29850 (epoch 43.281), train_loss = 0.79540997, grad/param norm = 2.5546e-01, time/batch = 14.8186s	
25840/29850 (epoch 43.283), train_loss = 0.86455597, grad/param norm = 3.1599e-01, time/batch = 14.8160s	
25841/29850 (epoch 43.285), train_loss = 0.84578087, grad/param norm = 2.1751e-01, time/batch = 15.3011s	
25842/29850 (epoch 43.286), train_loss = 0.86616359, grad/param norm = 2.4282e-01, time/batch = 15.2469s	
25843/29850 (epoch 43.288), train_loss = 0.82264054, grad/param norm = 3.3656e-01, time/batch = 15.2253s	
25844/29850 (epoch 43.290), train_loss = 0.78939785, grad/param norm = 2.6287e-01, time/batch = 15.2133s	
25845/29850 (epoch 43.291), train_loss = 0.99667390, grad/param norm = 2.5928e-01, time/batch = 15.2985s	
25846/29850 (epoch 43.293), train_loss = 0.91456551, grad/param norm = 2.5107e-01, time/batch = 14.9014s	
25847/29850 (epoch 43.295), train_loss = 0.98696463, grad/param norm = 2.6737e-01, time/batch = 14.8125s	
25848/29850 (epoch 43.296), train_loss = 0.71565921, grad/param norm = 2.0940e-01, time/batch = 14.9834s	
25849/29850 (epoch 43.298), train_loss = 0.60960752, grad/param norm = 2.0286e-01, time/batch = 15.3667s	
25850/29850 (epoch 43.300), train_loss = 0.67496423, grad/param norm = 2.1810e-01, time/batch = 15.2209s	
25851/29850 (epoch 43.302), train_loss = 0.66682019, grad/param norm = 2.2224e-01, time/batch = 15.2214s	
25852/29850 (epoch 43.303), train_loss = 0.71916372, grad/param norm = 2.4497e-01, time/batch = 15.1362s	
25853/29850 (epoch 43.305), train_loss = 0.87324792, grad/param norm = 2.5544e-01, time/batch = 15.3696s	
25854/29850 (epoch 43.307), train_loss = 0.83323968, grad/param norm = 1.9395e-01, time/batch = 15.0608s	
25855/29850 (epoch 43.308), train_loss = 0.66174745, grad/param norm = 2.1289e-01, time/batch = 15.5216s	
25856/29850 (epoch 43.310), train_loss = 0.82377245, grad/param norm = 2.2220e-01, time/batch = 15.9126s	
25857/29850 (epoch 43.312), train_loss = 0.88737367, grad/param norm = 2.2156e-01, time/batch = 15.4656s	
25858/29850 (epoch 43.313), train_loss = 0.80667494, grad/param norm = 2.9306e-01, time/batch = 15.5276s	
25859/29850 (epoch 43.315), train_loss = 0.82392891, grad/param norm = 2.5664e-01, time/batch = 15.7672s	
25860/29850 (epoch 43.317), train_loss = 0.79368428, grad/param norm = 2.5210e-01, time/batch = 15.4448s	
25861/29850 (epoch 43.318), train_loss = 0.76968792, grad/param norm = 2.3575e-01, time/batch = 15.8151s	
25862/29850 (epoch 43.320), train_loss = 0.73738859, grad/param norm = 2.2805e-01, time/batch = 14.8166s	
25863/29850 (epoch 43.322), train_loss = 0.88012855, grad/param norm = 2.4075e-01, time/batch = 14.9015s	
25864/29850 (epoch 43.323), train_loss = 0.81482549, grad/param norm = 2.2308e-01, time/batch = 15.1987s	
25865/29850 (epoch 43.325), train_loss = 0.85833064, grad/param norm = 2.2869e-01, time/batch = 15.6805s	
25866/29850 (epoch 43.327), train_loss = 0.97148072, grad/param norm = 2.2424e-01, time/batch = 15.1402s	
25867/29850 (epoch 43.328), train_loss = 0.88380790, grad/param norm = 3.2284e-01, time/batch = 15.1527s	
25868/29850 (epoch 43.330), train_loss = 0.86737453, grad/param norm = 2.1877e-01, time/batch = 15.3056s	
25869/29850 (epoch 43.332), train_loss = 0.76557392, grad/param norm = 2.4533e-01, time/batch = 15.4451s	
25870/29850 (epoch 43.333), train_loss = 0.83329664, grad/param norm = 2.3343e-01, time/batch = 15.4521s	
25871/29850 (epoch 43.335), train_loss = 0.89937451, grad/param norm = 2.5316e-01, time/batch = 15.3004s	
25872/29850 (epoch 43.337), train_loss = 0.81735063, grad/param norm = 3.1965e-01, time/batch = 15.5250s	
25873/29850 (epoch 43.338), train_loss = 0.84519986, grad/param norm = 2.2055e-01, time/batch = 15.7436s	
25874/29850 (epoch 43.340), train_loss = 0.68934376, grad/param norm = 1.9690e-01, time/batch = 15.6002s	
25875/29850 (epoch 43.342), train_loss = 0.79733236, grad/param norm = 2.5239e-01, time/batch = 15.2904s	
25876/29850 (epoch 43.343), train_loss = 0.79854029, grad/param norm = 2.6681e-01, time/batch = 15.3661s	
25877/29850 (epoch 43.345), train_loss = 0.85870670, grad/param norm = 2.4209e-01, time/batch = 15.4611s	
25878/29850 (epoch 43.347), train_loss = 0.89064004, grad/param norm = 2.8497e-01, time/batch = 15.4922s	
25879/29850 (epoch 43.348), train_loss = 0.72362500, grad/param norm = 2.0074e-01, time/batch = 15.4524s	
25880/29850 (epoch 43.350), train_loss = 0.83367095, grad/param norm = 2.4010e-01, time/batch = 15.4473s	
25881/29850 (epoch 43.352), train_loss = 0.75216485, grad/param norm = 2.0454e-01, time/batch = 15.6085s	
25882/29850 (epoch 43.353), train_loss = 0.82151452, grad/param norm = 2.2710e-01, time/batch = 15.1401s	
25883/29850 (epoch 43.355), train_loss = 0.74076033, grad/param norm = 2.4210e-01, time/batch = 15.0654s	
25884/29850 (epoch 43.357), train_loss = 0.88432595, grad/param norm = 2.2468e-01, time/batch = 15.2873s	
25885/29850 (epoch 43.358), train_loss = 0.72852366, grad/param norm = 2.2082e-01, time/batch = 15.3560s	
25886/29850 (epoch 43.360), train_loss = 0.78871166, grad/param norm = 2.2613e-01, time/batch = 15.3710s	
25887/29850 (epoch 43.362), train_loss = 0.80419738, grad/param norm = 2.4741e-01, time/batch = 14.8149s	
25888/29850 (epoch 43.363), train_loss = 0.82820079, grad/param norm = 2.3578e-01, time/batch = 14.9588s	
25889/29850 (epoch 43.365), train_loss = 0.90052431, grad/param norm = 2.6765e-01, time/batch = 15.1199s	
25890/29850 (epoch 43.367), train_loss = 0.72078338, grad/param norm = 1.9839e-01, time/batch = 14.8224s	
25891/29850 (epoch 43.369), train_loss = 0.64018659, grad/param norm = 2.4538e-01, time/batch = 14.8933s	
25892/29850 (epoch 43.370), train_loss = 0.66351178, grad/param norm = 2.3181e-01, time/batch = 15.1964s	
25893/29850 (epoch 43.372), train_loss = 0.87559698, grad/param norm = 2.1822e-01, time/batch = 15.2243s	
25894/29850 (epoch 43.374), train_loss = 0.86618678, grad/param norm = 2.2243e-01, time/batch = 15.1128s	
25895/29850 (epoch 43.375), train_loss = 0.81147398, grad/param norm = 2.4490e-01, time/batch = 18.7773s	
25896/29850 (epoch 43.377), train_loss = 0.68300953, grad/param norm = 2.6359e-01, time/batch = 15.8536s	
25897/29850 (epoch 43.379), train_loss = 0.91298706, grad/param norm = 3.1176e-01, time/batch = 16.0076s	
25898/29850 (epoch 43.380), train_loss = 0.85411017, grad/param norm = 2.5907e-01, time/batch = 15.8446s	
25899/29850 (epoch 43.382), train_loss = 0.81381682, grad/param norm = 2.6162e-01, time/batch = 17.3706s	
25900/29850 (epoch 43.384), train_loss = 0.85216424, grad/param norm = 2.5590e-01, time/batch = 18.6352s	
25901/29850 (epoch 43.385), train_loss = 0.83270379, grad/param norm = 2.2157e-01, time/batch = 17.6457s	
25902/29850 (epoch 43.387), train_loss = 0.81886825, grad/param norm = 2.5487e-01, time/batch = 17.8760s	
25903/29850 (epoch 43.389), train_loss = 0.91808239, grad/param norm = 2.6576e-01, time/batch = 18.2081s	
25904/29850 (epoch 43.390), train_loss = 0.86996345, grad/param norm = 2.1273e-01, time/batch = 15.3555s	
25905/29850 (epoch 43.392), train_loss = 0.80773943, grad/param norm = 2.3989e-01, time/batch = 18.0529s	
25906/29850 (epoch 43.394), train_loss = 0.84288315, grad/param norm = 2.2498e-01, time/batch = 16.4636s	
25907/29850 (epoch 43.395), train_loss = 0.74993984, grad/param norm = 2.7152e-01, time/batch = 19.0347s	
25908/29850 (epoch 43.397), train_loss = 0.68844456, grad/param norm = 2.2804e-01, time/batch = 18.7139s	
25909/29850 (epoch 43.399), train_loss = 0.74291129, grad/param norm = 2.4612e-01, time/batch = 17.3736s	
25910/29850 (epoch 43.400), train_loss = 1.06846032, grad/param norm = 2.6056e-01, time/batch = 17.9407s	
25911/29850 (epoch 43.402), train_loss = 0.92431511, grad/param norm = 2.3298e-01, time/batch = 17.3703s	
25912/29850 (epoch 43.404), train_loss = 0.79416337, grad/param norm = 2.0653e-01, time/batch = 19.1243s	
25913/29850 (epoch 43.405), train_loss = 0.73910555, grad/param norm = 2.3421e-01, time/batch = 16.6121s	
25914/29850 (epoch 43.407), train_loss = 0.71965190, grad/param norm = 2.1058e-01, time/batch = 19.1250s	
25915/29850 (epoch 43.409), train_loss = 0.81228455, grad/param norm = 2.1626e-01, time/batch = 15.8626s	
25916/29850 (epoch 43.410), train_loss = 0.88772984, grad/param norm = 2.3236e-01, time/batch = 15.9785s	
25917/29850 (epoch 43.412), train_loss = 0.90243469, grad/param norm = 2.6169e-01, time/batch = 18.4675s	
25918/29850 (epoch 43.414), train_loss = 0.83652034, grad/param norm = 2.4101e-01, time/batch = 16.3879s	
25919/29850 (epoch 43.415), train_loss = 0.79001685, grad/param norm = 1.9488e-01, time/batch = 17.9659s	
25920/29850 (epoch 43.417), train_loss = 0.91913431, grad/param norm = 2.4329e-01, time/batch = 16.8642s	
25921/29850 (epoch 43.419), train_loss = 0.78415926, grad/param norm = 2.2779e-01, time/batch = 18.5524s	
25922/29850 (epoch 43.420), train_loss = 0.79805904, grad/param norm = 2.4732e-01, time/batch = 15.3084s	
25923/29850 (epoch 43.422), train_loss = 0.80464972, grad/param norm = 2.7292e-01, time/batch = 16.0181s	
25924/29850 (epoch 43.424), train_loss = 0.71288381, grad/param norm = 2.3049e-01, time/batch = 16.6128s	
25925/29850 (epoch 43.425), train_loss = 0.86327663, grad/param norm = 2.8912e-01, time/batch = 16.7979s	
25926/29850 (epoch 43.427), train_loss = 0.63262792, grad/param norm = 2.6116e-01, time/batch = 17.7937s	
25927/29850 (epoch 43.429), train_loss = 0.72123102, grad/param norm = 2.3470e-01, time/batch = 16.4148s	
25928/29850 (epoch 43.430), train_loss = 0.66077036, grad/param norm = 2.0678e-01, time/batch = 17.1328s	
25929/29850 (epoch 43.432), train_loss = 0.76641816, grad/param norm = 2.9991e-01, time/batch = 16.6276s	
25930/29850 (epoch 43.434), train_loss = 0.72092734, grad/param norm = 1.8325e-01, time/batch = 16.9425s	
25931/29850 (epoch 43.436), train_loss = 0.77172959, grad/param norm = 2.3313e-01, time/batch = 15.4499s	
25932/29850 (epoch 43.437), train_loss = 0.87568424, grad/param norm = 2.5390e-01, time/batch = 19.1992s	
25933/29850 (epoch 43.439), train_loss = 0.85798333, grad/param norm = 2.2459e-01, time/batch = 18.7034s	
25934/29850 (epoch 43.441), train_loss = 0.78304206, grad/param norm = 2.1887e-01, time/batch = 15.6207s	
25935/29850 (epoch 43.442), train_loss = 0.77555483, grad/param norm = 2.7144e-01, time/batch = 16.3642s	
25936/29850 (epoch 43.444), train_loss = 0.83658125, grad/param norm = 2.6195e-01, time/batch = 16.6372s	
25937/29850 (epoch 43.446), train_loss = 0.89961779, grad/param norm = 2.4748e-01, time/batch = 17.2091s	
25938/29850 (epoch 43.447), train_loss = 0.88440912, grad/param norm = 2.6426e-01, time/batch = 17.5339s	
25939/29850 (epoch 43.449), train_loss = 0.81189647, grad/param norm = 2.6355e-01, time/batch = 16.1212s	
25940/29850 (epoch 43.451), train_loss = 0.63836308, grad/param norm = 2.3916e-01, time/batch = 17.8875s	
25941/29850 (epoch 43.452), train_loss = 0.55041144, grad/param norm = 1.9847e-01, time/batch = 18.7691s	
25942/29850 (epoch 43.454), train_loss = 0.66574944, grad/param norm = 2.0137e-01, time/batch = 15.1275s	
25943/29850 (epoch 43.456), train_loss = 0.86689106, grad/param norm = 2.5652e-01, time/batch = 17.4645s	
25944/29850 (epoch 43.457), train_loss = 0.88450058, grad/param norm = 3.9099e-01, time/batch = 17.2954s	
25945/29850 (epoch 43.459), train_loss = 0.94378597, grad/param norm = 2.6191e-01, time/batch = 19.6962s	
25946/29850 (epoch 43.461), train_loss = 0.95653243, grad/param norm = 2.3651e-01, time/batch = 16.7787s	
25947/29850 (epoch 43.462), train_loss = 0.97724680, grad/param norm = 2.7076e-01, time/batch = 18.2017s	
25948/29850 (epoch 43.464), train_loss = 0.85364843, grad/param norm = 2.5542e-01, time/batch = 18.8450s	
25949/29850 (epoch 43.466), train_loss = 0.70014304, grad/param norm = 2.4051e-01, time/batch = 18.8645s	
25950/29850 (epoch 43.467), train_loss = 0.73720874, grad/param norm = 2.4550e-01, time/batch = 19.4488s	
25951/29850 (epoch 43.469), train_loss = 0.77079877, grad/param norm = 2.1935e-01, time/batch = 19.5031s	
25952/29850 (epoch 43.471), train_loss = 0.77890761, grad/param norm = 2.5884e-01, time/batch = 18.0426s	
25953/29850 (epoch 43.472), train_loss = 0.73247848, grad/param norm = 2.1974e-01, time/batch = 19.0386s	
25954/29850 (epoch 43.474), train_loss = 0.86203302, grad/param norm = 2.4527e-01, time/batch = 32.3389s	
25955/29850 (epoch 43.476), train_loss = 0.80936065, grad/param norm = 2.2373e-01, time/batch = 16.8698s	
25956/29850 (epoch 43.477), train_loss = 0.82991937, grad/param norm = 3.1158e-01, time/batch = 15.8071s	
25957/29850 (epoch 43.479), train_loss = 0.96061224, grad/param norm = 2.3466e-01, time/batch = 15.3841s	
25958/29850 (epoch 43.481), train_loss = 0.79961747, grad/param norm = 2.2688e-01, time/batch = 17.1115s	
25959/29850 (epoch 43.482), train_loss = 0.74513975, grad/param norm = 2.0467e-01, time/batch = 18.6332s	
25960/29850 (epoch 43.484), train_loss = 0.75139490, grad/param norm = 2.0925e-01, time/batch = 16.1210s	
25961/29850 (epoch 43.486), train_loss = 0.82316598, grad/param norm = 2.4037e-01, time/batch = 17.2097s	
25962/29850 (epoch 43.487), train_loss = 0.79171957, grad/param norm = 2.0353e-01, time/batch = 15.3630s	
25963/29850 (epoch 43.489), train_loss = 0.81004692, grad/param norm = 2.8420e-01, time/batch = 18.5300s	
25964/29850 (epoch 43.491), train_loss = 0.71406643, grad/param norm = 2.3214e-01, time/batch = 16.1032s	
25965/29850 (epoch 43.492), train_loss = 0.80441029, grad/param norm = 2.5259e-01, time/batch = 17.9604s	
25966/29850 (epoch 43.494), train_loss = 0.87863532, grad/param norm = 2.5585e-01, time/batch = 18.7185s	
25967/29850 (epoch 43.496), train_loss = 0.91033216, grad/param norm = 2.2454e-01, time/batch = 16.5383s	
25968/29850 (epoch 43.497), train_loss = 0.82817803, grad/param norm = 2.5761e-01, time/batch = 17.4583s	
25969/29850 (epoch 43.499), train_loss = 0.81489968, grad/param norm = 2.4570e-01, time/batch = 18.9661s	
25970/29850 (epoch 43.501), train_loss = 0.70440232, grad/param norm = 3.4795e-01, time/batch = 17.5468s	
25971/29850 (epoch 43.503), train_loss = 0.89255096, grad/param norm = 2.3580e-01, time/batch = 16.0665s	
25972/29850 (epoch 43.504), train_loss = 1.03907043, grad/param norm = 2.5546e-01, time/batch = 16.8822s	
25973/29850 (epoch 43.506), train_loss = 1.01031586, grad/param norm = 3.1456e-01, time/batch = 18.3088s	
25974/29850 (epoch 43.508), train_loss = 0.84559897, grad/param norm = 2.5199e-01, time/batch = 16.5499s	
25975/29850 (epoch 43.509), train_loss = 0.64251935, grad/param norm = 2.1709e-01, time/batch = 17.7926s	
25976/29850 (epoch 43.511), train_loss = 0.85594113, grad/param norm = 2.3669e-01, time/batch = 17.7070s	
25977/29850 (epoch 43.513), train_loss = 0.79976625, grad/param norm = 2.6854e-01, time/batch = 17.2101s	
25978/29850 (epoch 43.514), train_loss = 0.70738015, grad/param norm = 2.3166e-01, time/batch = 17.4772s	
25979/29850 (epoch 43.516), train_loss = 0.75971552, grad/param norm = 1.9634e-01, time/batch = 17.2931s	
25980/29850 (epoch 43.518), train_loss = 0.64076741, grad/param norm = 2.2855e-01, time/batch = 18.7887s	
25981/29850 (epoch 43.519), train_loss = 0.64855952, grad/param norm = 1.9520e-01, time/batch = 17.6276s	
25982/29850 (epoch 43.521), train_loss = 0.60535932, grad/param norm = 1.8052e-01, time/batch = 19.4550s	
25983/29850 (epoch 43.523), train_loss = 0.65538841, grad/param norm = 1.8110e-01, time/batch = 15.9278s	
25984/29850 (epoch 43.524), train_loss = 0.68646653, grad/param norm = 2.3378e-01, time/batch = 16.1025s	
25985/29850 (epoch 43.526), train_loss = 0.74617913, grad/param norm = 2.5459e-01, time/batch = 18.7867s	
25986/29850 (epoch 43.528), train_loss = 0.85439118, grad/param norm = 2.4783e-01, time/batch = 18.7165s	
25987/29850 (epoch 43.529), train_loss = 0.81678699, grad/param norm = 2.4583e-01, time/batch = 17.0509s	
25988/29850 (epoch 43.531), train_loss = 0.79724454, grad/param norm = 2.6016e-01, time/batch = 18.0272s	
25989/29850 (epoch 43.533), train_loss = 0.81645355, grad/param norm = 2.4391e-01, time/batch = 16.4612s	
25990/29850 (epoch 43.534), train_loss = 0.83906152, grad/param norm = 2.5621e-01, time/batch = 18.2152s	
25991/29850 (epoch 43.536), train_loss = 0.74777798, grad/param norm = 2.1158e-01, time/batch = 19.1896s	
25992/29850 (epoch 43.538), train_loss = 0.92369032, grad/param norm = 2.8205e-01, time/batch = 18.1834s	
25993/29850 (epoch 43.539), train_loss = 0.92492626, grad/param norm = 2.4286e-01, time/batch = 18.2244s	
25994/29850 (epoch 43.541), train_loss = 0.56911328, grad/param norm = 1.9556e-01, time/batch = 16.7082s	
25995/29850 (epoch 43.543), train_loss = 0.74730618, grad/param norm = 2.3810e-01, time/batch = 18.0485s	
25996/29850 (epoch 43.544), train_loss = 0.89939138, grad/param norm = 2.5398e-01, time/batch = 16.2804s	
25997/29850 (epoch 43.546), train_loss = 0.85773703, grad/param norm = 2.2563e-01, time/batch = 17.3643s	
25998/29850 (epoch 43.548), train_loss = 0.65723423, grad/param norm = 1.8434e-01, time/batch = 16.1426s	
25999/29850 (epoch 43.549), train_loss = 0.76191603, grad/param norm = 2.0672e-01, time/batch = 16.2173s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch43.55_1.9171.t7	
26000/29850 (epoch 43.551), train_loss = 0.71018445, grad/param norm = 2.0015e-01, time/batch = 18.0114s	
26001/29850 (epoch 43.553), train_loss = 1.57394907, grad/param norm = 3.2827e-01, time/batch = 18.5383s	
26002/29850 (epoch 43.554), train_loss = 0.65273280, grad/param norm = 2.0577e-01, time/batch = 17.5329s	
26003/29850 (epoch 43.556), train_loss = 0.69369663, grad/param norm = 2.6165e-01, time/batch = 19.2083s	
26004/29850 (epoch 43.558), train_loss = 0.70847183, grad/param norm = 1.9741e-01, time/batch = 16.6220s	
26005/29850 (epoch 43.559), train_loss = 0.70936959, grad/param norm = 2.2198e-01, time/batch = 17.7706s	
26006/29850 (epoch 43.561), train_loss = 0.80327781, grad/param norm = 2.5702e-01, time/batch = 17.3472s	
26007/29850 (epoch 43.563), train_loss = 0.82207658, grad/param norm = 2.4422e-01, time/batch = 16.7737s	
26008/29850 (epoch 43.564), train_loss = 0.75142292, grad/param norm = 2.2672e-01, time/batch = 18.5266s	
26009/29850 (epoch 43.566), train_loss = 0.78045777, grad/param norm = 2.3903e-01, time/batch = 18.5524s	
26010/29850 (epoch 43.568), train_loss = 0.91986165, grad/param norm = 2.4568e-01, time/batch = 16.0036s	
26011/29850 (epoch 43.570), train_loss = 0.80668016, grad/param norm = 2.3229e-01, time/batch = 17.4472s	
26012/29850 (epoch 43.571), train_loss = 0.87452725, grad/param norm = 2.3882e-01, time/batch = 19.0455s	
26013/29850 (epoch 43.573), train_loss = 0.92467237, grad/param norm = 3.3157e-01, time/batch = 19.5402s	
26014/29850 (epoch 43.575), train_loss = 0.96807092, grad/param norm = 2.2621e-01, time/batch = 16.5228s	
26015/29850 (epoch 43.576), train_loss = 0.87075094, grad/param norm = 2.7614e-01, time/batch = 17.5467s	
26016/29850 (epoch 43.578), train_loss = 0.72509647, grad/param norm = 2.1164e-01, time/batch = 17.4615s	
26017/29850 (epoch 43.580), train_loss = 0.86738020, grad/param norm = 2.3227e-01, time/batch = 18.7856s	
26018/29850 (epoch 43.581), train_loss = 0.71825075, grad/param norm = 2.0904e-01, time/batch = 18.3650s	
26019/29850 (epoch 43.583), train_loss = 0.77163335, grad/param norm = 2.0798e-01, time/batch = 16.4827s	
26020/29850 (epoch 43.585), train_loss = 0.80599750, grad/param norm = 2.0741e-01, time/batch = 18.1391s	
26021/29850 (epoch 43.586), train_loss = 0.84546651, grad/param norm = 2.9245e-01, time/batch = 19.0315s	
26022/29850 (epoch 43.588), train_loss = 0.71799103, grad/param norm = 2.2670e-01, time/batch = 18.9531s	
26023/29850 (epoch 43.590), train_loss = 0.72646173, grad/param norm = 1.8588e-01, time/batch = 16.7079s	
26024/29850 (epoch 43.591), train_loss = 0.77098221, grad/param norm = 2.4037e-01, time/batch = 15.4300s	
26025/29850 (epoch 43.593), train_loss = 0.69630674, grad/param norm = 2.0904e-01, time/batch = 17.3424s	
26026/29850 (epoch 43.595), train_loss = 0.65257220, grad/param norm = 1.7884e-01, time/batch = 19.1351s	
26027/29850 (epoch 43.596), train_loss = 0.71257736, grad/param norm = 2.6522e-01, time/batch = 17.3566s	
26028/29850 (epoch 43.598), train_loss = 0.75617275, grad/param norm = 2.0598e-01, time/batch = 19.9553s	
26029/29850 (epoch 43.600), train_loss = 0.79986993, grad/param norm = 1.9627e-01, time/batch = 18.6132s	
26030/29850 (epoch 43.601), train_loss = 0.66291672, grad/param norm = 1.8914e-01, time/batch = 15.8918s	
26031/29850 (epoch 43.603), train_loss = 0.72745755, grad/param norm = 2.3125e-01, time/batch = 16.6097s	
26032/29850 (epoch 43.605), train_loss = 0.75295613, grad/param norm = 2.2899e-01, time/batch = 18.2182s	
26033/29850 (epoch 43.606), train_loss = 0.51470915, grad/param norm = 1.7415e-01, time/batch = 18.3919s	
26034/29850 (epoch 43.608), train_loss = 0.66537670, grad/param norm = 2.0585e-01, time/batch = 16.3482s	
26035/29850 (epoch 43.610), train_loss = 0.73793871, grad/param norm = 2.1305e-01, time/batch = 17.1116s	
26036/29850 (epoch 43.611), train_loss = 0.67725089, grad/param norm = 1.8268e-01, time/batch = 17.7051s	
26037/29850 (epoch 43.613), train_loss = 0.58123819, grad/param norm = 1.8315e-01, time/batch = 17.7081s	
26038/29850 (epoch 43.615), train_loss = 0.62785603, grad/param norm = 2.0090e-01, time/batch = 18.3680s	
26039/29850 (epoch 43.616), train_loss = 0.65966202, grad/param norm = 2.2254e-01, time/batch = 18.6236s	
26040/29850 (epoch 43.618), train_loss = 0.71819055, grad/param norm = 2.3229e-01, time/batch = 18.2070s	
26041/29850 (epoch 43.620), train_loss = 0.82030987, grad/param norm = 2.1368e-01, time/batch = 18.4459s	
26042/29850 (epoch 43.621), train_loss = 0.87427843, grad/param norm = 2.6158e-01, time/batch = 18.5476s	
26043/29850 (epoch 43.623), train_loss = 0.87517297, grad/param norm = 2.5122e-01, time/batch = 17.1318s	
26044/29850 (epoch 43.625), train_loss = 0.77420026, grad/param norm = 2.4357e-01, time/batch = 16.1311s	
26045/29850 (epoch 43.626), train_loss = 0.77625644, grad/param norm = 2.1795e-01, time/batch = 18.3776s	
26046/29850 (epoch 43.628), train_loss = 0.78916627, grad/param norm = 2.7769e-01, time/batch = 18.2936s	
26047/29850 (epoch 43.630), train_loss = 0.80243374, grad/param norm = 2.5745e-01, time/batch = 16.9620s	
26048/29850 (epoch 43.631), train_loss = 0.80567048, grad/param norm = 2.3242e-01, time/batch = 15.6911s	
26049/29850 (epoch 43.633), train_loss = 0.78849126, grad/param norm = 2.3801e-01, time/batch = 18.5337s	
26050/29850 (epoch 43.635), train_loss = 0.73594518, grad/param norm = 2.5968e-01, time/batch = 19.2020s	
26051/29850 (epoch 43.637), train_loss = 0.68500561, grad/param norm = 2.2783e-01, time/batch = 17.6947s	
26052/29850 (epoch 43.638), train_loss = 0.80197901, grad/param norm = 2.4421e-01, time/batch = 17.7986s	
26053/29850 (epoch 43.640), train_loss = 0.91867577, grad/param norm = 2.7499e-01, time/batch = 17.8864s	
26054/29850 (epoch 43.642), train_loss = 0.73486637, grad/param norm = 1.9296e-01, time/batch = 17.3697s	
26055/29850 (epoch 43.643), train_loss = 0.70562032, grad/param norm = 2.1754e-01, time/batch = 16.6118s	
26056/29850 (epoch 43.645), train_loss = 0.75024523, grad/param norm = 2.0435e-01, time/batch = 15.8701s	
26057/29850 (epoch 43.647), train_loss = 0.88716321, grad/param norm = 2.3175e-01, time/batch = 19.3556s	
26058/29850 (epoch 43.648), train_loss = 0.69508389, grad/param norm = 2.0147e-01, time/batch = 18.4558s	
26059/29850 (epoch 43.650), train_loss = 0.82343675, grad/param norm = 2.6331e-01, time/batch = 18.1315s	
26060/29850 (epoch 43.652), train_loss = 0.79088395, grad/param norm = 2.3916e-01, time/batch = 17.2953s	
26061/29850 (epoch 43.653), train_loss = 0.85069934, grad/param norm = 2.2135e-01, time/batch = 16.7929s	
26062/29850 (epoch 43.655), train_loss = 0.80671918, grad/param norm = 2.2517e-01, time/batch = 18.4499s	
26063/29850 (epoch 43.657), train_loss = 0.77098372, grad/param norm = 2.1053e-01, time/batch = 18.3684s	
26064/29850 (epoch 43.658), train_loss = 0.87112747, grad/param norm = 3.0695e-01, time/batch = 17.2666s	
26065/29850 (epoch 43.660), train_loss = 0.75676809, grad/param norm = 2.4160e-01, time/batch = 16.9375s	
26066/29850 (epoch 43.662), train_loss = 0.87697857, grad/param norm = 2.5325e-01, time/batch = 15.1193s	
26067/29850 (epoch 43.663), train_loss = 0.98337617, grad/param norm = 2.3044e-01, time/batch = 18.4673s	
26068/29850 (epoch 43.665), train_loss = 0.91700884, grad/param norm = 2.3705e-01, time/batch = 18.2620s	
26069/29850 (epoch 43.667), train_loss = 0.85488707, grad/param norm = 3.3830e-01, time/batch = 17.8001s	
26070/29850 (epoch 43.668), train_loss = 0.76062100, grad/param norm = 2.6896e-01, time/batch = 19.2799s	
26071/29850 (epoch 43.670), train_loss = 0.86489818, grad/param norm = 2.7662e-01, time/batch = 16.7105s	
26072/29850 (epoch 43.672), train_loss = 0.87530800, grad/param norm = 2.4588e-01, time/batch = 18.7728s	
26073/29850 (epoch 43.673), train_loss = 0.79854028, grad/param norm = 2.6505e-01, time/batch = 16.5396s	
26074/29850 (epoch 43.675), train_loss = 0.70051834, grad/param norm = 1.9808e-01, time/batch = 17.1275s	
26075/29850 (epoch 43.677), train_loss = 0.74397769, grad/param norm = 2.7918e-01, time/batch = 17.8663s	
26076/29850 (epoch 43.678), train_loss = 0.79830039, grad/param norm = 2.4960e-01, time/batch = 19.2064s	
26077/29850 (epoch 43.680), train_loss = 0.78371009, grad/param norm = 2.4407e-01, time/batch = 18.5433s	
26078/29850 (epoch 43.682), train_loss = 0.78161287, grad/param norm = 2.3821e-01, time/batch = 17.1839s	
26079/29850 (epoch 43.683), train_loss = 0.89326115, grad/param norm = 2.6448e-01, time/batch = 17.9592s	
26080/29850 (epoch 43.685), train_loss = 1.01260215, grad/param norm = 2.9695e-01, time/batch = 18.0593s	
26081/29850 (epoch 43.687), train_loss = 0.83299490, grad/param norm = 2.1555e-01, time/batch = 16.6905s	
26082/29850 (epoch 43.688), train_loss = 0.72551162, grad/param norm = 2.5875e-01, time/batch = 16.9551s	
26083/29850 (epoch 43.690), train_loss = 0.72729543, grad/param norm = 2.3532e-01, time/batch = 17.6881s	
26084/29850 (epoch 43.692), train_loss = 0.88852778, grad/param norm = 2.4527e-01, time/batch = 18.5131s	
26085/29850 (epoch 43.693), train_loss = 0.78033295, grad/param norm = 1.8465e-01, time/batch = 17.8087s	
26086/29850 (epoch 43.695), train_loss = 0.71018191, grad/param norm = 1.9751e-01, time/batch = 19.3680s	
26087/29850 (epoch 43.697), train_loss = 0.77837899, grad/param norm = 2.3290e-01, time/batch = 17.6945s	
26088/29850 (epoch 43.698), train_loss = 0.90037755, grad/param norm = 2.2357e-01, time/batch = 16.1648s	
26089/29850 (epoch 43.700), train_loss = 0.85555532, grad/param norm = 2.8080e-01, time/batch = 18.3851s	
26090/29850 (epoch 43.702), train_loss = 0.80580407, grad/param norm = 2.5568e-01, time/batch = 16.7299s	
26091/29850 (epoch 43.704), train_loss = 0.67853210, grad/param norm = 2.0114e-01, time/batch = 17.9613s	
26092/29850 (epoch 43.705), train_loss = 0.79023362, grad/param norm = 2.2934e-01, time/batch = 16.3843s	
26093/29850 (epoch 43.707), train_loss = 0.74126357, grad/param norm = 2.4894e-01, time/batch = 18.8439s	
26094/29850 (epoch 43.709), train_loss = 0.79462979, grad/param norm = 2.9220e-01, time/batch = 17.5459s	
26095/29850 (epoch 43.710), train_loss = 0.73250866, grad/param norm = 2.8918e-01, time/batch = 18.6113s	
26096/29850 (epoch 43.712), train_loss = 0.84527786, grad/param norm = 2.5432e-01, time/batch = 17.9786s	
26097/29850 (epoch 43.714), train_loss = 0.88518305, grad/param norm = 2.8673e-01, time/batch = 17.3028s	
26098/29850 (epoch 43.715), train_loss = 0.81602242, grad/param norm = 2.3859e-01, time/batch = 15.7049s	
26099/29850 (epoch 43.717), train_loss = 0.61408253, grad/param norm = 2.1832e-01, time/batch = 19.1870s	
26100/29850 (epoch 43.719), train_loss = 0.76487132, grad/param norm = 2.3265e-01, time/batch = 17.7118s	
26101/29850 (epoch 43.720), train_loss = 0.77470113, grad/param norm = 2.0815e-01, time/batch = 17.6092s	
26102/29850 (epoch 43.722), train_loss = 0.71313691, grad/param norm = 1.8531e-01, time/batch = 19.1204s	
26103/29850 (epoch 43.724), train_loss = 0.81338249, grad/param norm = 2.5280e-01, time/batch = 17.2691s	
26104/29850 (epoch 43.725), train_loss = 0.67940960, grad/param norm = 2.1852e-01, time/batch = 16.3701s	
26105/29850 (epoch 43.727), train_loss = 0.66133784, grad/param norm = 2.2777e-01, time/batch = 18.6025s	
26106/29850 (epoch 43.729), train_loss = 0.64367772, grad/param norm = 1.7928e-01, time/batch = 15.8049s	
26107/29850 (epoch 43.730), train_loss = 0.62829594, grad/param norm = 2.1068e-01, time/batch = 17.0962s	
26108/29850 (epoch 43.732), train_loss = 0.86638931, grad/param norm = 2.2937e-01, time/batch = 17.6283s	
26109/29850 (epoch 43.734), train_loss = 0.93794913, grad/param norm = 2.5772e-01, time/batch = 16.9710s	
26110/29850 (epoch 43.735), train_loss = 0.71500503, grad/param norm = 2.2931e-01, time/batch = 16.3422s	
26111/29850 (epoch 43.737), train_loss = 0.67711921, grad/param norm = 2.0138e-01, time/batch = 18.6247s	
26112/29850 (epoch 43.739), train_loss = 0.61016736, grad/param norm = 2.1487e-01, time/batch = 18.6104s	
26113/29850 (epoch 43.740), train_loss = 0.64469534, grad/param norm = 2.2884e-01, time/batch = 18.1342s	
26114/29850 (epoch 43.742), train_loss = 0.57418573, grad/param norm = 1.7677e-01, time/batch = 19.2941s	
26115/29850 (epoch 43.744), train_loss = 0.69211871, grad/param norm = 2.1683e-01, time/batch = 16.6964s	
26116/29850 (epoch 43.745), train_loss = 0.74120715, grad/param norm = 2.4496e-01, time/batch = 18.2100s	
26117/29850 (epoch 43.747), train_loss = 0.77087047, grad/param norm = 2.3192e-01, time/batch = 16.8925s	
26118/29850 (epoch 43.749), train_loss = 0.65428374, grad/param norm = 2.2631e-01, time/batch = 17.4605s	
26119/29850 (epoch 43.750), train_loss = 0.59116169, grad/param norm = 2.3781e-01, time/batch = 15.0403s	
26120/29850 (epoch 43.752), train_loss = 0.52004073, grad/param norm = 1.8664e-01, time/batch = 17.2920s	
26121/29850 (epoch 43.754), train_loss = 0.58246207, grad/param norm = 2.2079e-01, time/batch = 19.7099s	
26122/29850 (epoch 43.755), train_loss = 0.61155689, grad/param norm = 2.3540e-01, time/batch = 17.2084s	
26123/29850 (epoch 43.757), train_loss = 0.64445922, grad/param norm = 1.6954e-01, time/batch = 19.6322s	
26124/29850 (epoch 43.759), train_loss = 0.65386550, grad/param norm = 1.9880e-01, time/batch = 17.8644s	
26125/29850 (epoch 43.760), train_loss = 0.69629358, grad/param norm = 2.4840e-01, time/batch = 17.8648s	
26126/29850 (epoch 43.762), train_loss = 0.63316783, grad/param norm = 2.2319e-01, time/batch = 19.1984s	
26127/29850 (epoch 43.764), train_loss = 0.54992537, grad/param norm = 3.0728e-01, time/batch = 17.2028s	
26128/29850 (epoch 43.765), train_loss = 0.70632040, grad/param norm = 2.2913e-01, time/batch = 17.1057s	
26129/29850 (epoch 43.767), train_loss = 0.70116150, grad/param norm = 2.3733e-01, time/batch = 15.4520s	
26130/29850 (epoch 43.769), train_loss = 0.75395268, grad/param norm = 2.3468e-01, time/batch = 19.3717s	
26131/29850 (epoch 43.771), train_loss = 0.74812962, grad/param norm = 2.3571e-01, time/batch = 19.3796s	
26132/29850 (epoch 43.772), train_loss = 0.74702385, grad/param norm = 2.5217e-01, time/batch = 16.1146s	
26133/29850 (epoch 43.774), train_loss = 0.67474365, grad/param norm = 2.0930e-01, time/batch = 17.8867s	
26134/29850 (epoch 43.776), train_loss = 0.71445693, grad/param norm = 2.1936e-01, time/batch = 15.9985s	
26135/29850 (epoch 43.777), train_loss = 0.81912387, grad/param norm = 2.4038e-01, time/batch = 15.8024s	
26136/29850 (epoch 43.779), train_loss = 0.66906242, grad/param norm = 2.1100e-01, time/batch = 17.2219s	
26137/29850 (epoch 43.781), train_loss = 0.77740517, grad/param norm = 2.0845e-01, time/batch = 18.3878s	
26138/29850 (epoch 43.782), train_loss = 0.79103142, grad/param norm = 2.2652e-01, time/batch = 18.8614s	
26139/29850 (epoch 43.784), train_loss = 0.62776412, grad/param norm = 3.1843e-01, time/batch = 18.4582s	
26140/29850 (epoch 43.786), train_loss = 0.68163461, grad/param norm = 2.0337e-01, time/batch = 18.0283s	
26141/29850 (epoch 43.787), train_loss = 0.57006798, grad/param norm = 2.2003e-01, time/batch = 17.6179s	
26142/29850 (epoch 43.789), train_loss = 0.60535848, grad/param norm = 1.9089e-01, time/batch = 17.4561s	
26143/29850 (epoch 43.791), train_loss = 0.67021370, grad/param norm = 2.3858e-01, time/batch = 18.3116s	
26144/29850 (epoch 43.792), train_loss = 0.79492862, grad/param norm = 2.5614e-01, time/batch = 17.3752s	
26145/29850 (epoch 43.794), train_loss = 0.74681281, grad/param norm = 2.0563e-01, time/batch = 17.5337s	
26146/29850 (epoch 43.796), train_loss = 0.65779722, grad/param norm = 1.9650e-01, time/batch = 17.1296s	
26147/29850 (epoch 43.797), train_loss = 0.55281232, grad/param norm = 1.8493e-01, time/batch = 19.3605s	
26148/29850 (epoch 43.799), train_loss = 0.61347498, grad/param norm = 1.9926e-01, time/batch = 19.5908s	
26149/29850 (epoch 43.801), train_loss = 0.61943146, grad/param norm = 2.0286e-01, time/batch = 40.4216s	
26150/29850 (epoch 43.802), train_loss = 0.60091017, grad/param norm = 2.2426e-01, time/batch = 16.6418s	
26151/29850 (epoch 43.804), train_loss = 0.63935704, grad/param norm = 1.9549e-01, time/batch = 18.6023s	
26152/29850 (epoch 43.806), train_loss = 0.57660353, grad/param norm = 2.0204e-01, time/batch = 15.5675s	
26153/29850 (epoch 43.807), train_loss = 0.62555660, grad/param norm = 1.7953e-01, time/batch = 18.9643s	
26154/29850 (epoch 43.809), train_loss = 0.62635005, grad/param norm = 2.7705e-01, time/batch = 16.5425s	
26155/29850 (epoch 43.811), train_loss = 0.79541060, grad/param norm = 2.7093e-01, time/batch = 18.7889s	
26156/29850 (epoch 43.812), train_loss = 0.76862664, grad/param norm = 2.5905e-01, time/batch = 16.3755s	
26157/29850 (epoch 43.814), train_loss = 0.79844201, grad/param norm = 2.5727e-01, time/batch = 17.1345s	
26158/29850 (epoch 43.816), train_loss = 0.85543637, grad/param norm = 2.2590e-01, time/batch = 19.6151s	
26159/29850 (epoch 43.817), train_loss = 0.74050218, grad/param norm = 2.8759e-01, time/batch = 16.3685s	
26160/29850 (epoch 43.819), train_loss = 0.58485065, grad/param norm = 2.0724e-01, time/batch = 18.5624s	
26161/29850 (epoch 43.821), train_loss = 0.81894516, grad/param norm = 2.8592e-01, time/batch = 18.2773s	
26162/29850 (epoch 43.822), train_loss = 0.85955165, grad/param norm = 2.4480e-01, time/batch = 18.7111s	
26163/29850 (epoch 43.824), train_loss = 0.74426298, grad/param norm = 2.3521e-01, time/batch = 16.6294s	
26164/29850 (epoch 43.826), train_loss = 0.64530294, grad/param norm = 2.0937e-01, time/batch = 15.8508s	
26165/29850 (epoch 43.827), train_loss = 0.56659899, grad/param norm = 1.9849e-01, time/batch = 18.8862s	
26166/29850 (epoch 43.829), train_loss = 0.74016559, grad/param norm = 2.7317e-01, time/batch = 17.5454s	
26167/29850 (epoch 43.831), train_loss = 0.84891429, grad/param norm = 2.2798e-01, time/batch = 18.1989s	
26168/29850 (epoch 43.832), train_loss = 0.74237827, grad/param norm = 2.0404e-01, time/batch = 17.2165s	
26169/29850 (epoch 43.834), train_loss = 0.56720929, grad/param norm = 1.9360e-01, time/batch = 17.6435s	
26170/29850 (epoch 43.836), train_loss = 0.58749837, grad/param norm = 2.2542e-01, time/batch = 20.3554s	
26171/29850 (epoch 43.838), train_loss = 0.68278421, grad/param norm = 2.5556e-01, time/batch = 17.0156s	
26172/29850 (epoch 43.839), train_loss = 0.58093133, grad/param norm = 2.1275e-01, time/batch = 17.2206s	
26173/29850 (epoch 43.841), train_loss = 0.64301598, grad/param norm = 1.7622e-01, time/batch = 16.4698s	
26174/29850 (epoch 43.843), train_loss = 0.57760753, grad/param norm = 2.0118e-01, time/batch = 17.8691s	
26175/29850 (epoch 43.844), train_loss = 0.63152467, grad/param norm = 2.3002e-01, time/batch = 17.2151s	
26176/29850 (epoch 43.846), train_loss = 0.69541467, grad/param norm = 2.1769e-01, time/batch = 16.6153s	
26177/29850 (epoch 43.848), train_loss = 0.76342664, grad/param norm = 2.4172e-01, time/batch = 18.8650s	
26178/29850 (epoch 43.849), train_loss = 0.70264089, grad/param norm = 2.2452e-01, time/batch = 19.1792s	
26179/29850 (epoch 43.851), train_loss = 0.87957883, grad/param norm = 2.4592e-01, time/batch = 17.8109s	
26180/29850 (epoch 43.853), train_loss = 0.69969229, grad/param norm = 2.6284e-01, time/batch = 19.2019s	
26181/29850 (epoch 43.854), train_loss = 0.87866509, grad/param norm = 2.9132e-01, time/batch = 16.1099s	
26182/29850 (epoch 43.856), train_loss = 0.82084758, grad/param norm = 2.5085e-01, time/batch = 18.4752s	
26183/29850 (epoch 43.858), train_loss = 0.73109621, grad/param norm = 2.4077e-01, time/batch = 17.9465s	
26184/29850 (epoch 43.859), train_loss = 0.66170865, grad/param norm = 2.4209e-01, time/batch = 18.0266s	
26185/29850 (epoch 43.861), train_loss = 0.83590183, grad/param norm = 3.0131e-01, time/batch = 19.6234s	
26186/29850 (epoch 43.863), train_loss = 0.85244795, grad/param norm = 2.8570e-01, time/batch = 16.8242s	
26187/29850 (epoch 43.864), train_loss = 0.84210640, grad/param norm = 2.5772e-01, time/batch = 18.2718s	
26188/29850 (epoch 43.866), train_loss = 0.78259519, grad/param norm = 2.9038e-01, time/batch = 18.3695s	
26189/29850 (epoch 43.868), train_loss = 0.91310492, grad/param norm = 2.6005e-01, time/batch = 17.4434s	
26190/29850 (epoch 43.869), train_loss = 0.84221184, grad/param norm = 3.0030e-01, time/batch = 17.2952s	
26191/29850 (epoch 43.871), train_loss = 0.83283928, grad/param norm = 2.5816e-01, time/batch = 16.0425s	
26192/29850 (epoch 43.873), train_loss = 0.79107625, grad/param norm = 2.3092e-01, time/batch = 17.5393s	
26193/29850 (epoch 43.874), train_loss = 0.78824308, grad/param norm = 2.6794e-01, time/batch = 18.4657s	
26194/29850 (epoch 43.876), train_loss = 0.77412786, grad/param norm = 2.8878e-01, time/batch = 19.0404s	
26195/29850 (epoch 43.878), train_loss = 0.77677301, grad/param norm = 2.2472e-01, time/batch = 17.4646s	
26196/29850 (epoch 43.879), train_loss = 0.81316019, grad/param norm = 2.4244e-01, time/batch = 19.5450s	
26197/29850 (epoch 43.881), train_loss = 0.84270754, grad/param norm = 2.6824e-01, time/batch = 18.1984s	
26198/29850 (epoch 43.883), train_loss = 0.79006129, grad/param norm = 2.4211e-01, time/batch = 17.2920s	
26199/29850 (epoch 43.884), train_loss = 0.68390819, grad/param norm = 2.3864e-01, time/batch = 16.8505s	
26200/29850 (epoch 43.886), train_loss = 0.82293449, grad/param norm = 3.0783e-01, time/batch = 19.1123s	
26201/29850 (epoch 43.888), train_loss = 0.78061947, grad/param norm = 2.7354e-01, time/batch = 17.4317s	
26202/29850 (epoch 43.889), train_loss = 0.71792081, grad/param norm = 2.1025e-01, time/batch = 18.4711s	
26203/29850 (epoch 43.891), train_loss = 0.67658997, grad/param norm = 1.8658e-01, time/batch = 18.1353s	
26204/29850 (epoch 43.893), train_loss = 0.74892412, grad/param norm = 2.2005e-01, time/batch = 17.1240s	
26205/29850 (epoch 43.894), train_loss = 0.72432767, grad/param norm = 2.3691e-01, time/batch = 17.7218s	
26206/29850 (epoch 43.896), train_loss = 0.79164798, grad/param norm = 3.0478e-01, time/batch = 17.0596s	
26207/29850 (epoch 43.898), train_loss = 0.91712934, grad/param norm = 2.8168e-01, time/batch = 17.8004s	
26208/29850 (epoch 43.899), train_loss = 0.68006418, grad/param norm = 2.4244e-01, time/batch = 18.7742s	
26209/29850 (epoch 43.901), train_loss = 0.95079678, grad/param norm = 2.9935e-01, time/batch = 15.8942s	
26210/29850 (epoch 43.903), train_loss = 0.81509849, grad/param norm = 3.4435e-01, time/batch = 17.5640s	
26211/29850 (epoch 43.905), train_loss = 1.01996081, grad/param norm = 2.3944e-01, time/batch = 15.8710s	
26212/29850 (epoch 43.906), train_loss = 0.79324814, grad/param norm = 3.0051e-01, time/batch = 17.2250s	
26213/29850 (epoch 43.908), train_loss = 0.91449091, grad/param norm = 2.3470e-01, time/batch = 15.4485s	
26214/29850 (epoch 43.910), train_loss = 0.84783002, grad/param norm = 2.4978e-01, time/batch = 18.7009s	
26215/29850 (epoch 43.911), train_loss = 0.97318075, grad/param norm = 2.4867e-01, time/batch = 17.2823s	
26216/29850 (epoch 43.913), train_loss = 0.94197072, grad/param norm = 3.0584e-01, time/batch = 18.1295s	
26217/29850 (epoch 43.915), train_loss = 0.92083509, grad/param norm = 2.6787e-01, time/batch = 19.0314s	
26218/29850 (epoch 43.916), train_loss = 0.90167187, grad/param norm = 2.9397e-01, time/batch = 18.6951s	
26219/29850 (epoch 43.918), train_loss = 0.71877001, grad/param norm = 2.0640e-01, time/batch = 16.8491s	
26220/29850 (epoch 43.920), train_loss = 0.88814894, grad/param norm = 2.2282e-01, time/batch = 17.1242s	
26221/29850 (epoch 43.921), train_loss = 0.78158788, grad/param norm = 2.5420e-01, time/batch = 18.0370s	
26222/29850 (epoch 43.923), train_loss = 0.80237032, grad/param norm = 2.4495e-01, time/batch = 17.4784s	
26223/29850 (epoch 43.925), train_loss = 0.93150962, grad/param norm = 2.5189e-01, time/batch = 17.5325s	
26224/29850 (epoch 43.926), train_loss = 0.95231040, grad/param norm = 3.0634e-01, time/batch = 18.2116s	
26225/29850 (epoch 43.928), train_loss = 0.79512757, grad/param norm = 2.2934e-01, time/batch = 20.0344s	
26226/29850 (epoch 43.930), train_loss = 0.79504573, grad/param norm = 2.2065e-01, time/batch = 16.4738s	
26227/29850 (epoch 43.931), train_loss = 0.80041360, grad/param norm = 2.3450e-01, time/batch = 19.9485s	
26228/29850 (epoch 43.933), train_loss = 0.92406663, grad/param norm = 2.6919e-01, time/batch = 20.0045s	
26229/29850 (epoch 43.935), train_loss = 0.85023498, grad/param norm = 2.6923e-01, time/batch = 17.6466s	
26230/29850 (epoch 43.936), train_loss = 0.82603146, grad/param norm = 2.3954e-01, time/batch = 15.1218s	
26231/29850 (epoch 43.938), train_loss = 0.70761840, grad/param norm = 2.3274e-01, time/batch = 17.3649s	
26232/29850 (epoch 43.940), train_loss = 0.71859799, grad/param norm = 2.1743e-01, time/batch = 19.2117s	
26233/29850 (epoch 43.941), train_loss = 0.70888452, grad/param norm = 2.6002e-01, time/batch = 16.0310s	
26234/29850 (epoch 43.943), train_loss = 0.74920667, grad/param norm = 2.2674e-01, time/batch = 17.6380s	
26235/29850 (epoch 43.945), train_loss = 0.69026447, grad/param norm = 2.2902e-01, time/batch = 16.2963s	
26236/29850 (epoch 43.946), train_loss = 0.67845640, grad/param norm = 2.2143e-01, time/batch = 16.9039s	
26237/29850 (epoch 43.948), train_loss = 0.79375643, grad/param norm = 2.2403e-01, time/batch = 16.7897s	
26238/29850 (epoch 43.950), train_loss = 0.73848393, grad/param norm = 1.8988e-01, time/batch = 17.1327s	
26239/29850 (epoch 43.951), train_loss = 0.66566784, grad/param norm = 2.1411e-01, time/batch = 19.0275s	
26240/29850 (epoch 43.953), train_loss = 0.72426424, grad/param norm = 2.3916e-01, time/batch = 17.4520s	
26241/29850 (epoch 43.955), train_loss = 0.65868472, grad/param norm = 1.9204e-01, time/batch = 18.0405s	
26242/29850 (epoch 43.956), train_loss = 0.65683887, grad/param norm = 1.9582e-01, time/batch = 18.8550s	
26243/29850 (epoch 43.958), train_loss = 0.61462077, grad/param norm = 1.8840e-01, time/batch = 17.3567s	
26244/29850 (epoch 43.960), train_loss = 0.85926640, grad/param norm = 2.5898e-01, time/batch = 19.2842s	
26245/29850 (epoch 43.961), train_loss = 0.62685506, grad/param norm = 2.3849e-01, time/batch = 19.1013s	
26246/29850 (epoch 43.963), train_loss = 0.61893004, grad/param norm = 2.2152e-01, time/batch = 17.5512s	
26247/29850 (epoch 43.965), train_loss = 0.68367890, grad/param norm = 2.1695e-01, time/batch = 18.3753s	
26248/29850 (epoch 43.966), train_loss = 0.65472543, grad/param norm = 2.1485e-01, time/batch = 16.5301s	
26249/29850 (epoch 43.968), train_loss = 0.69494933, grad/param norm = 2.6693e-01, time/batch = 18.3744s	
26250/29850 (epoch 43.970), train_loss = 0.71389366, grad/param norm = 2.5256e-01, time/batch = 15.5925s	
26251/29850 (epoch 43.972), train_loss = 0.70354325, grad/param norm = 2.0284e-01, time/batch = 18.4234s	
26252/29850 (epoch 43.973), train_loss = 0.67586311, grad/param norm = 1.9868e-01, time/batch = 18.8682s	
26253/29850 (epoch 43.975), train_loss = 0.59828642, grad/param norm = 1.7651e-01, time/batch = 17.7858s	
26254/29850 (epoch 43.977), train_loss = 0.69308367, grad/param norm = 1.8818e-01, time/batch = 18.6330s	
26255/29850 (epoch 43.978), train_loss = 0.61098344, grad/param norm = 1.9966e-01, time/batch = 18.1144s	
26256/29850 (epoch 43.980), train_loss = 0.68947068, grad/param norm = 1.8087e-01, time/batch = 18.1296s	
26257/29850 (epoch 43.982), train_loss = 0.66601684, grad/param norm = 2.0889e-01, time/batch = 17.3746s	
26258/29850 (epoch 43.983), train_loss = 0.69343372, grad/param norm = 1.9137e-01, time/batch = 17.3682s	
26259/29850 (epoch 43.985), train_loss = 0.78442518, grad/param norm = 2.3358e-01, time/batch = 19.1235s	
26260/29850 (epoch 43.987), train_loss = 0.77406644, grad/param norm = 2.1471e-01, time/batch = 17.6785s	
26261/29850 (epoch 43.988), train_loss = 0.71697761, grad/param norm = 1.9158e-01, time/batch = 17.7795s	
26262/29850 (epoch 43.990), train_loss = 0.78333784, grad/param norm = 2.1670e-01, time/batch = 17.7121s	
26263/29850 (epoch 43.992), train_loss = 0.75857871, grad/param norm = 1.9896e-01, time/batch = 18.8802s	
26264/29850 (epoch 43.993), train_loss = 0.78854163, grad/param norm = 3.0504e-01, time/batch = 17.5617s	
26265/29850 (epoch 43.995), train_loss = 0.75059351, grad/param norm = 2.1773e-01, time/batch = 17.0364s	
26266/29850 (epoch 43.997), train_loss = 0.78075431, grad/param norm = 2.0785e-01, time/batch = 16.8102s	
26267/29850 (epoch 43.998), train_loss = 0.79036260, grad/param norm = 2.0405e-01, time/batch = 18.2181s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
26268/29850 (epoch 44.000), train_loss = 0.62242807, grad/param norm = 2.0239e-01, time/batch = 17.7049s	
26269/29850 (epoch 44.002), train_loss = 0.85318051, grad/param norm = 2.1519e-01, time/batch = 17.4647s	
26270/29850 (epoch 44.003), train_loss = 0.63434439, grad/param norm = 2.3342e-01, time/batch = 16.6919s	
26271/29850 (epoch 44.005), train_loss = 0.80458321, grad/param norm = 2.2162e-01, time/batch = 16.0969s	
26272/29850 (epoch 44.007), train_loss = 0.84552268, grad/param norm = 2.8566e-01, time/batch = 18.8675s	
26273/29850 (epoch 44.008), train_loss = 0.97597210, grad/param norm = 2.6476e-01, time/batch = 17.9528s	
26274/29850 (epoch 44.010), train_loss = 0.68202061, grad/param norm = 2.0704e-01, time/batch = 18.3725s	
26275/29850 (epoch 44.012), train_loss = 0.72979856, grad/param norm = 2.1830e-01, time/batch = 17.7137s	
26276/29850 (epoch 44.013), train_loss = 0.78170686, grad/param norm = 2.9744e-01, time/batch = 19.4626s	
26277/29850 (epoch 44.015), train_loss = 0.85698457, grad/param norm = 2.3881e-01, time/batch = 18.3669s	
26278/29850 (epoch 44.017), train_loss = 0.83421763, grad/param norm = 3.0541e-01, time/batch = 16.6206s	
26279/29850 (epoch 44.018), train_loss = 0.88864801, grad/param norm = 2.4835e-01, time/batch = 19.1285s	
26280/29850 (epoch 44.020), train_loss = 0.80506418, grad/param norm = 2.6744e-01, time/batch = 19.5354s	
26281/29850 (epoch 44.022), train_loss = 0.85798113, grad/param norm = 2.5514e-01, time/batch = 17.1160s	
26282/29850 (epoch 44.023), train_loss = 0.82142827, grad/param norm = 2.0875e-01, time/batch = 16.6410s	
26283/29850 (epoch 44.025), train_loss = 0.77097749, grad/param norm = 2.1796e-01, time/batch = 16.2038s	
26284/29850 (epoch 44.027), train_loss = 0.55444407, grad/param norm = 1.7793e-01, time/batch = 17.6308s	
26285/29850 (epoch 44.028), train_loss = 0.71227172, grad/param norm = 1.9878e-01, time/batch = 16.6363s	
26286/29850 (epoch 44.030), train_loss = 0.71889524, grad/param norm = 2.4107e-01, time/batch = 19.6096s	
26287/29850 (epoch 44.032), train_loss = 0.81124464, grad/param norm = 2.2643e-01, time/batch = 17.7856s	
26288/29850 (epoch 44.034), train_loss = 0.71242617, grad/param norm = 2.5618e-01, time/batch = 15.3774s	
26289/29850 (epoch 44.035), train_loss = 0.60802707, grad/param norm = 1.9781e-01, time/batch = 19.4569s	
26290/29850 (epoch 44.037), train_loss = 0.77817396, grad/param norm = 2.4039e-01, time/batch = 16.1343s	
26291/29850 (epoch 44.039), train_loss = 0.68384411, grad/param norm = 2.3565e-01, time/batch = 18.0447s	
26292/29850 (epoch 44.040), train_loss = 0.64440193, grad/param norm = 2.0631e-01, time/batch = 15.2161s	
26293/29850 (epoch 44.042), train_loss = 0.71426460, grad/param norm = 2.4321e-01, time/batch = 16.1954s	
26294/29850 (epoch 44.044), train_loss = 0.73352840, grad/param norm = 2.1345e-01, time/batch = 18.3905s	
26295/29850 (epoch 44.045), train_loss = 0.83387170, grad/param norm = 2.5145e-01, time/batch = 16.5472s	
26296/29850 (epoch 44.047), train_loss = 0.67883662, grad/param norm = 2.1962e-01, time/batch = 15.6122s	
26297/29850 (epoch 44.049), train_loss = 0.80931135, grad/param norm = 2.4802e-01, time/batch = 18.9547s	
26298/29850 (epoch 44.050), train_loss = 0.72316691, grad/param norm = 2.1270e-01, time/batch = 19.2776s	
26299/29850 (epoch 44.052), train_loss = 0.86818118, grad/param norm = 2.5202e-01, time/batch = 17.0351s	
26300/29850 (epoch 44.054), train_loss = 0.74562419, grad/param norm = 2.2294e-01, time/batch = 16.8756s	
26301/29850 (epoch 44.055), train_loss = 0.73029373, grad/param norm = 2.0830e-01, time/batch = 18.2896s	
26302/29850 (epoch 44.057), train_loss = 0.81192007, grad/param norm = 2.0047e-01, time/batch = 16.2861s	
26303/29850 (epoch 44.059), train_loss = 0.79007072, grad/param norm = 2.4104e-01, time/batch = 19.3663s	
26304/29850 (epoch 44.060), train_loss = 0.79276173, grad/param norm = 2.9295e-01, time/batch = 19.2072s	
26305/29850 (epoch 44.062), train_loss = 0.87554718, grad/param norm = 2.6445e-01, time/batch = 17.8680s	
26306/29850 (epoch 44.064), train_loss = 0.84443156, grad/param norm = 2.3209e-01, time/batch = 17.3628s	
26307/29850 (epoch 44.065), train_loss = 0.66385151, grad/param norm = 2.2279e-01, time/batch = 17.8825s	
26308/29850 (epoch 44.067), train_loss = 0.83741795, grad/param norm = 2.1405e-01, time/batch = 17.5481s	
26309/29850 (epoch 44.069), train_loss = 0.79700053, grad/param norm = 2.1210e-01, time/batch = 17.1387s	
26310/29850 (epoch 44.070), train_loss = 0.85418439, grad/param norm = 2.2529e-01, time/batch = 17.6093s	
26311/29850 (epoch 44.072), train_loss = 0.78693806, grad/param norm = 2.7147e-01, time/batch = 16.5342s	
26312/29850 (epoch 44.074), train_loss = 0.85688714, grad/param norm = 2.3306e-01, time/batch = 16.2753s	
26313/29850 (epoch 44.075), train_loss = 0.72172595, grad/param norm = 2.4152e-01, time/batch = 17.4709s	
26314/29850 (epoch 44.077), train_loss = 0.83766987, grad/param norm = 2.8026e-01, time/batch = 18.7352s	
26315/29850 (epoch 44.079), train_loss = 0.98800408, grad/param norm = 3.5745e-01, time/batch = 17.6236s	
26316/29850 (epoch 44.080), train_loss = 0.94250451, grad/param norm = 2.5973e-01, time/batch = 18.1229s	
26317/29850 (epoch 44.082), train_loss = 0.84427327, grad/param norm = 2.4166e-01, time/batch = 17.4604s	
26318/29850 (epoch 44.084), train_loss = 0.94092642, grad/param norm = 2.5981e-01, time/batch = 18.1290s	
26319/29850 (epoch 44.085), train_loss = 0.97044724, grad/param norm = 2.2336e-01, time/batch = 16.1183s	
26320/29850 (epoch 44.087), train_loss = 0.88793673, grad/param norm = 2.3057e-01, time/batch = 18.9606s	
26321/29850 (epoch 44.089), train_loss = 0.81995974, grad/param norm = 2.1288e-01, time/batch = 19.0457s	
26322/29850 (epoch 44.090), train_loss = 0.80253887, grad/param norm = 2.1280e-01, time/batch = 15.9379s	
26323/29850 (epoch 44.092), train_loss = 0.72335633, grad/param norm = 2.1861e-01, time/batch = 18.3897s	
26324/29850 (epoch 44.094), train_loss = 0.90825348, grad/param norm = 2.1993e-01, time/batch = 16.7282s	
26325/29850 (epoch 44.095), train_loss = 0.86715256, grad/param norm = 3.3732e-01, time/batch = 17.7955s	
26326/29850 (epoch 44.097), train_loss = 0.62023406, grad/param norm = 1.9198e-01, time/batch = 18.9406s	
26327/29850 (epoch 44.099), train_loss = 0.63651813, grad/param norm = 2.2036e-01, time/batch = 16.7103s	
26328/29850 (epoch 44.101), train_loss = 0.84095343, grad/param norm = 2.3137e-01, time/batch = 18.6375s	
26329/29850 (epoch 44.102), train_loss = 0.86360431, grad/param norm = 2.8335e-01, time/batch = 17.1082s	
26330/29850 (epoch 44.104), train_loss = 0.73697273, grad/param norm = 2.7051e-01, time/batch = 18.4552s	
26331/29850 (epoch 44.106), train_loss = 0.87382360, grad/param norm = 2.3457e-01, time/batch = 16.2346s	
26332/29850 (epoch 44.107), train_loss = 0.73050181, grad/param norm = 2.0948e-01, time/batch = 17.0264s	
26333/29850 (epoch 44.109), train_loss = 0.79160345, grad/param norm = 2.5042e-01, time/batch = 17.2083s	
26334/29850 (epoch 44.111), train_loss = 0.81871925, grad/param norm = 2.6233e-01, time/batch = 16.4669s	
26335/29850 (epoch 44.112), train_loss = 0.71383767, grad/param norm = 2.2272e-01, time/batch = 15.0328s	
26336/29850 (epoch 44.114), train_loss = 0.72190947, grad/param norm = 2.1774e-01, time/batch = 18.1257s	
26337/29850 (epoch 44.116), train_loss = 0.70228871, grad/param norm = 2.5376e-01, time/batch = 18.3021s	
26338/29850 (epoch 44.117), train_loss = 0.74683173, grad/param norm = 2.4498e-01, time/batch = 15.4137s	
26339/29850 (epoch 44.119), train_loss = 0.74960168, grad/param norm = 2.6054e-01, time/batch = 17.6298s	
26340/29850 (epoch 44.121), train_loss = 0.62945754, grad/param norm = 2.0976e-01, time/batch = 17.7789s	
26341/29850 (epoch 44.122), train_loss = 0.66697254, grad/param norm = 1.7856e-01, time/batch = 17.2553s	
26342/29850 (epoch 44.124), train_loss = 0.72519637, grad/param norm = 2.5096e-01, time/batch = 19.3687s	
26343/29850 (epoch 44.126), train_loss = 0.76106610, grad/param norm = 2.4790e-01, time/batch = 17.9470s	
26344/29850 (epoch 44.127), train_loss = 0.80681962, grad/param norm = 2.6691e-01, time/batch = 19.0444s	
26345/29850 (epoch 44.129), train_loss = 0.78827171, grad/param norm = 2.2883e-01, time/batch = 19.6201s	
26346/29850 (epoch 44.131), train_loss = 0.80648595, grad/param norm = 2.2735e-01, time/batch = 15.6124s	
26347/29850 (epoch 44.132), train_loss = 0.67271992, grad/param norm = 2.6302e-01, time/batch = 19.6890s	
26348/29850 (epoch 44.134), train_loss = 0.74627129, grad/param norm = 2.6009e-01, time/batch = 18.3744s	
26349/29850 (epoch 44.136), train_loss = 0.84287904, grad/param norm = 2.1564e-01, time/batch = 22.7970s	
26350/29850 (epoch 44.137), train_loss = 0.64710543, grad/param norm = 2.5504e-01, time/batch = 26.7699s	
26351/29850 (epoch 44.139), train_loss = 0.76396838, grad/param norm = 2.0618e-01, time/batch = 15.7835s	
26352/29850 (epoch 44.141), train_loss = 0.68814430, grad/param norm = 2.4934e-01, time/batch = 16.1244s	
26353/29850 (epoch 44.142), train_loss = 0.89655565, grad/param norm = 2.6209e-01, time/batch = 18.9528s	
26354/29850 (epoch 44.144), train_loss = 0.98500840, grad/param norm = 2.9247e-01, time/batch = 19.0401s	
26355/29850 (epoch 44.146), train_loss = 0.99250913, grad/param norm = 2.5280e-01, time/batch = 17.2152s	
26356/29850 (epoch 44.147), train_loss = 0.87216267, grad/param norm = 2.3356e-01, time/batch = 18.4601s	
26357/29850 (epoch 44.149), train_loss = 0.83731865, grad/param norm = 2.4447e-01, time/batch = 16.3463s	
26358/29850 (epoch 44.151), train_loss = 0.81121572, grad/param norm = 2.2217e-01, time/batch = 16.1060s	
26359/29850 (epoch 44.152), train_loss = 0.77221493, grad/param norm = 2.0964e-01, time/batch = 16.6903s	
26360/29850 (epoch 44.154), train_loss = 0.73141635, grad/param norm = 2.5546e-01, time/batch = 18.1453s	
26361/29850 (epoch 44.156), train_loss = 0.72533169, grad/param norm = 2.1619e-01, time/batch = 19.2035s	
26362/29850 (epoch 44.157), train_loss = 0.83606138, grad/param norm = 2.2083e-01, time/batch = 15.0444s	
26363/29850 (epoch 44.159), train_loss = 0.74074802, grad/param norm = 2.1171e-01, time/batch = 18.2203s	
26364/29850 (epoch 44.161), train_loss = 0.75036925, grad/param norm = 2.2729e-01, time/batch = 18.2260s	
26365/29850 (epoch 44.162), train_loss = 0.91347484, grad/param norm = 2.7659e-01, time/batch = 18.0513s	
26366/29850 (epoch 44.164), train_loss = 0.82627363, grad/param norm = 2.3961e-01, time/batch = 18.6085s	
26367/29850 (epoch 44.166), train_loss = 0.76809398, grad/param norm = 2.5556e-01, time/batch = 18.8719s	
26368/29850 (epoch 44.168), train_loss = 0.69560629, grad/param norm = 2.0049e-01, time/batch = 17.8793s	
26369/29850 (epoch 44.169), train_loss = 0.91024408, grad/param norm = 3.2632e-01, time/batch = 15.4583s	
26370/29850 (epoch 44.171), train_loss = 0.87495242, grad/param norm = 2.7772e-01, time/batch = 18.6929s	
26371/29850 (epoch 44.173), train_loss = 0.68081628, grad/param norm = 2.0343e-01, time/batch = 18.8723s	
26372/29850 (epoch 44.174), train_loss = 0.75832235, grad/param norm = 2.4612e-01, time/batch = 18.3566s	
26373/29850 (epoch 44.176), train_loss = 0.83230797, grad/param norm = 2.2837e-01, time/batch = 17.3566s	
26374/29850 (epoch 44.178), train_loss = 0.84462437, grad/param norm = 2.6296e-01, time/batch = 16.9669s	
26375/29850 (epoch 44.179), train_loss = 0.64632815, grad/param norm = 2.2603e-01, time/batch = 17.9515s	
26376/29850 (epoch 44.181), train_loss = 0.79049887, grad/param norm = 2.3956e-01, time/batch = 18.9184s	
26377/29850 (epoch 44.183), train_loss = 0.80197704, grad/param norm = 2.3718e-01, time/batch = 19.6179s	
26378/29850 (epoch 44.184), train_loss = 0.87934267, grad/param norm = 2.4050e-01, time/batch = 19.0506s	
26379/29850 (epoch 44.186), train_loss = 0.84049743, grad/param norm = 2.4472e-01, time/batch = 18.8569s	
26380/29850 (epoch 44.188), train_loss = 0.91062873, grad/param norm = 2.2440e-01, time/batch = 17.9688s	
26381/29850 (epoch 44.189), train_loss = 0.84778483, grad/param norm = 2.5661e-01, time/batch = 18.7933s	
26382/29850 (epoch 44.191), train_loss = 0.87171037, grad/param norm = 2.3524e-01, time/batch = 16.1667s	
26383/29850 (epoch 44.193), train_loss = 0.78218481, grad/param norm = 2.1814e-01, time/batch = 18.5387s	
26384/29850 (epoch 44.194), train_loss = 0.87240974, grad/param norm = 2.3232e-01, time/batch = 17.2187s	
26385/29850 (epoch 44.196), train_loss = 0.77335496, grad/param norm = 2.0238e-01, time/batch = 17.7938s	
26386/29850 (epoch 44.198), train_loss = 0.69788048, grad/param norm = 2.1101e-01, time/batch = 19.9539s	
26387/29850 (epoch 44.199), train_loss = 0.98085108, grad/param norm = 2.5343e-01, time/batch = 18.3883s	
26388/29850 (epoch 44.201), train_loss = 0.72960773, grad/param norm = 2.2824e-01, time/batch = 17.6284s	
26389/29850 (epoch 44.203), train_loss = 0.57643871, grad/param norm = 2.3734e-01, time/batch = 17.1069s	
26390/29850 (epoch 44.204), train_loss = 0.77165724, grad/param norm = 2.6234e-01, time/batch = 18.6260s	
26391/29850 (epoch 44.206), train_loss = 0.69221384, grad/param norm = 2.1572e-01, time/batch = 18.9262s	
26392/29850 (epoch 44.208), train_loss = 0.90069345, grad/param norm = 2.5539e-01, time/batch = 15.6032s	
26393/29850 (epoch 44.209), train_loss = 0.69537939, grad/param norm = 2.0756e-01, time/batch = 16.7045s	
26394/29850 (epoch 44.211), train_loss = 0.74981183, grad/param norm = 2.0205e-01, time/batch = 19.3696s	
26395/29850 (epoch 44.213), train_loss = 0.82855518, grad/param norm = 2.5251e-01, time/batch = 16.9789s	
26396/29850 (epoch 44.214), train_loss = 0.65140622, grad/param norm = 1.9208e-01, time/batch = 18.6141s	
26397/29850 (epoch 44.216), train_loss = 0.68708600, grad/param norm = 1.9770e-01, time/batch = 17.5447s	
26398/29850 (epoch 44.218), train_loss = 0.79853105, grad/param norm = 2.3234e-01, time/batch = 18.7816s	
26399/29850 (epoch 44.219), train_loss = 0.79566662, grad/param norm = 2.5774e-01, time/batch = 17.7788s	
26400/29850 (epoch 44.221), train_loss = 0.77964133, grad/param norm = 2.9052e-01, time/batch = 16.2244s	
26401/29850 (epoch 44.223), train_loss = 0.63199233, grad/param norm = 2.6595e-01, time/batch = 19.2879s	
26402/29850 (epoch 44.224), train_loss = 0.63827005, grad/param norm = 2.0329e-01, time/batch = 16.9553s	
26403/29850 (epoch 44.226), train_loss = 0.70563322, grad/param norm = 2.2855e-01, time/batch = 17.2701s	
26404/29850 (epoch 44.228), train_loss = 0.73912686, grad/param norm = 2.1201e-01, time/batch = 19.2058s	
26405/29850 (epoch 44.229), train_loss = 0.63570931, grad/param norm = 1.8245e-01, time/batch = 17.6159s	
26406/29850 (epoch 44.231), train_loss = 0.80177084, grad/param norm = 2.2781e-01, time/batch = 19.3712s	
26407/29850 (epoch 44.233), train_loss = 0.75140877, grad/param norm = 2.1772e-01, time/batch = 17.1242s	
26408/29850 (epoch 44.235), train_loss = 0.69733304, grad/param norm = 2.0000e-01, time/batch = 19.6915s	
26409/29850 (epoch 44.236), train_loss = 0.90625711, grad/param norm = 2.4793e-01, time/batch = 18.1296s	
26410/29850 (epoch 44.238), train_loss = 0.68669091, grad/param norm = 2.5575e-01, time/batch = 16.7671s	
26411/29850 (epoch 44.240), train_loss = 0.67701579, grad/param norm = 2.6901e-01, time/batch = 17.8541s	
26412/29850 (epoch 44.241), train_loss = 0.77902766, grad/param norm = 2.1724e-01, time/batch = 15.8464s	
26413/29850 (epoch 44.243), train_loss = 0.82245585, grad/param norm = 2.5192e-01, time/batch = 19.3015s	
26414/29850 (epoch 44.245), train_loss = 0.68381722, grad/param norm = 2.1569e-01, time/batch = 18.9574s	
26415/29850 (epoch 44.246), train_loss = 0.71292021, grad/param norm = 1.9623e-01, time/batch = 17.1973s	
26416/29850 (epoch 44.248), train_loss = 0.65328660, grad/param norm = 1.9618e-01, time/batch = 1.3180s	
26417/29850 (epoch 44.250), train_loss = 0.73229649, grad/param norm = 2.1464e-01, time/batch = 0.6450s	
26418/29850 (epoch 44.251), train_loss = 0.62551241, grad/param norm = 2.1412e-01, time/batch = 0.6538s	
26419/29850 (epoch 44.253), train_loss = 0.62553750, grad/param norm = 2.4818e-01, time/batch = 0.6461s	
26420/29850 (epoch 44.255), train_loss = 0.67748661, grad/param norm = 2.5072e-01, time/batch = 0.6466s	
26421/29850 (epoch 44.256), train_loss = 0.80208959, grad/param norm = 2.3335e-01, time/batch = 0.6509s	
26422/29850 (epoch 44.258), train_loss = 0.80309278, grad/param norm = 2.1900e-01, time/batch = 0.6503s	
26423/29850 (epoch 44.260), train_loss = 0.74265901, grad/param norm = 2.1555e-01, time/batch = 0.7495s	
26424/29850 (epoch 44.261), train_loss = 0.69187162, grad/param norm = 2.3950e-01, time/batch = 0.9449s	
26425/29850 (epoch 44.263), train_loss = 0.68515978, grad/param norm = 2.0877e-01, time/batch = 0.9546s	
26426/29850 (epoch 44.265), train_loss = 0.75301670, grad/param norm = 2.4738e-01, time/batch = 0.9421s	
26427/29850 (epoch 44.266), train_loss = 0.76646585, grad/param norm = 2.3651e-01, time/batch = 0.9443s	
26428/29850 (epoch 44.268), train_loss = 0.72835591, grad/param norm = 2.2278e-01, time/batch = 1.0071s	
26429/29850 (epoch 44.270), train_loss = 0.67240310, grad/param norm = 2.1009e-01, time/batch = 1.7747s	
26430/29850 (epoch 44.271), train_loss = 0.78298471, grad/param norm = 2.2168e-01, time/batch = 1.7681s	
26431/29850 (epoch 44.273), train_loss = 0.65263057, grad/param norm = 1.9518e-01, time/batch = 6.7878s	
26432/29850 (epoch 44.275), train_loss = 0.66917201, grad/param norm = 2.1923e-01, time/batch = 17.8762s	
26433/29850 (epoch 44.276), train_loss = 0.65842664, grad/param norm = 1.9687e-01, time/batch = 17.0433s	
26434/29850 (epoch 44.278), train_loss = 0.71641753, grad/param norm = 2.1101e-01, time/batch = 17.7765s	
26435/29850 (epoch 44.280), train_loss = 0.93707147, grad/param norm = 3.9358e-01, time/batch = 18.0295s	
26436/29850 (epoch 44.281), train_loss = 0.79191765, grad/param norm = 2.5211e-01, time/batch = 18.7035s	
26437/29850 (epoch 44.283), train_loss = 0.84461956, grad/param norm = 3.2206e-01, time/batch = 18.3501s	
26438/29850 (epoch 44.285), train_loss = 0.85557412, grad/param norm = 2.5053e-01, time/batch = 19.1155s	
26439/29850 (epoch 44.286), train_loss = 0.86533126, grad/param norm = 2.4063e-01, time/batch = 17.2168s	
26440/29850 (epoch 44.288), train_loss = 0.80338845, grad/param norm = 3.1657e-01, time/batch = 17.0494s	
26441/29850 (epoch 44.290), train_loss = 0.80209953, grad/param norm = 2.6829e-01, time/batch = 19.0463s	
26442/29850 (epoch 44.291), train_loss = 0.99535838, grad/param norm = 2.6386e-01, time/batch = 18.0352s	
26443/29850 (epoch 44.293), train_loss = 0.90116737, grad/param norm = 5.2976e-01, time/batch = 17.9655s	
26444/29850 (epoch 44.295), train_loss = 0.97698056, grad/param norm = 2.6434e-01, time/batch = 16.9435s	
26445/29850 (epoch 44.296), train_loss = 0.72278878, grad/param norm = 1.9066e-01, time/batch = 17.9487s	
26446/29850 (epoch 44.298), train_loss = 0.60110554, grad/param norm = 1.9389e-01, time/batch = 19.0363s	
26447/29850 (epoch 44.300), train_loss = 0.66828902, grad/param norm = 2.2512e-01, time/batch = 16.7920s	
26448/29850 (epoch 44.302), train_loss = 0.64616800, grad/param norm = 1.9071e-01, time/batch = 18.5497s	
26449/29850 (epoch 44.303), train_loss = 0.71615624, grad/param norm = 2.3470e-01, time/batch = 16.6473s	
26450/29850 (epoch 44.305), train_loss = 0.87435513, grad/param norm = 2.3219e-01, time/batch = 17.0970s	
26451/29850 (epoch 44.307), train_loss = 0.84685937, grad/param norm = 2.3186e-01, time/batch = 18.5535s	
26452/29850 (epoch 44.308), train_loss = 0.66874916, grad/param norm = 2.3924e-01, time/batch = 17.4684s	
26453/29850 (epoch 44.310), train_loss = 0.83105666, grad/param norm = 2.3554e-01, time/batch = 17.2922s	
26454/29850 (epoch 44.312), train_loss = 0.87871384, grad/param norm = 2.1568e-01, time/batch = 17.3009s	
26455/29850 (epoch 44.313), train_loss = 0.77943351, grad/param norm = 2.5840e-01, time/batch = 18.0528s	
26456/29850 (epoch 44.315), train_loss = 0.82017115, grad/param norm = 2.3890e-01, time/batch = 17.9504s	
26457/29850 (epoch 44.317), train_loss = 0.78518770, grad/param norm = 2.3177e-01, time/batch = 17.9430s	
26458/29850 (epoch 44.318), train_loss = 0.74745748, grad/param norm = 2.4839e-01, time/batch = 16.4800s	
26459/29850 (epoch 44.320), train_loss = 0.71986860, grad/param norm = 2.2255e-01, time/batch = 18.4007s	
26460/29850 (epoch 44.322), train_loss = 0.86484212, grad/param norm = 2.5457e-01, time/batch = 16.4403s	
26461/29850 (epoch 44.323), train_loss = 0.80771709, grad/param norm = 2.6720e-01, time/batch = 17.5548s	
26462/29850 (epoch 44.325), train_loss = 0.85157760, grad/param norm = 2.3129e-01, time/batch = 16.5234s	
26463/29850 (epoch 44.327), train_loss = 0.97744879, grad/param norm = 2.7157e-01, time/batch = 19.2894s	
26464/29850 (epoch 44.328), train_loss = 0.92559981, grad/param norm = 4.4231e-01, time/batch = 18.3447s	
26465/29850 (epoch 44.330), train_loss = 0.85180268, grad/param norm = 2.1509e-01, time/batch = 16.5617s	
26466/29850 (epoch 44.332), train_loss = 0.76873362, grad/param norm = 2.2209e-01, time/batch = 16.8437s	
26467/29850 (epoch 44.333), train_loss = 0.84241680, grad/param norm = 2.6856e-01, time/batch = 15.7162s	
26468/29850 (epoch 44.335), train_loss = 0.87962004, grad/param norm = 2.3710e-01, time/batch = 15.1969s	
26469/29850 (epoch 44.337), train_loss = 0.79595512, grad/param norm = 2.5047e-01, time/batch = 18.2210s	
26470/29850 (epoch 44.338), train_loss = 0.83776653, grad/param norm = 2.1220e-01, time/batch = 19.6004s	
26471/29850 (epoch 44.340), train_loss = 0.68994860, grad/param norm = 2.1026e-01, time/batch = 18.7818s	
26472/29850 (epoch 44.342), train_loss = 0.78387588, grad/param norm = 2.3811e-01, time/batch = 18.6274s	
26473/29850 (epoch 44.343), train_loss = 0.77841941, grad/param norm = 2.5489e-01, time/batch = 18.8529s	
26474/29850 (epoch 44.345), train_loss = 0.87274547, grad/param norm = 2.6693e-01, time/batch = 18.6897s	
26475/29850 (epoch 44.347), train_loss = 0.87544074, grad/param norm = 2.6606e-01, time/batch = 19.0196s	
26476/29850 (epoch 44.348), train_loss = 0.71869759, grad/param norm = 2.5317e-01, time/batch = 18.3785s	
26477/29850 (epoch 44.350), train_loss = 0.82140942, grad/param norm = 2.4003e-01, time/batch = 15.9628s	
26478/29850 (epoch 44.352), train_loss = 0.75241427, grad/param norm = 2.8242e-01, time/batch = 18.2079s	
26479/29850 (epoch 44.353), train_loss = 0.81145512, grad/param norm = 2.9983e-01, time/batch = 19.4624s	
26480/29850 (epoch 44.355), train_loss = 0.73953325, grad/param norm = 2.3649e-01, time/batch = 16.9688s	
26481/29850 (epoch 44.357), train_loss = 0.89352524, grad/param norm = 2.4317e-01, time/batch = 17.6231s	
26482/29850 (epoch 44.358), train_loss = 0.71303213, grad/param norm = 2.1746e-01, time/batch = 17.7127s	
26483/29850 (epoch 44.360), train_loss = 0.79944056, grad/param norm = 2.5122e-01, time/batch = 18.9699s	
26484/29850 (epoch 44.362), train_loss = 0.77475656, grad/param norm = 2.2674e-01, time/batch = 17.3825s	
26485/29850 (epoch 44.363), train_loss = 0.81629801, grad/param norm = 2.6291e-01, time/batch = 19.4541s	
26486/29850 (epoch 44.365), train_loss = 0.88548392, grad/param norm = 2.5456e-01, time/batch = 17.5429s	
26487/29850 (epoch 44.367), train_loss = 0.70119307, grad/param norm = 1.9585e-01, time/batch = 15.9702s	
26488/29850 (epoch 44.369), train_loss = 0.62846565, grad/param norm = 2.1319e-01, time/batch = 19.5556s	
26489/29850 (epoch 44.370), train_loss = 0.64362096, grad/param norm = 2.1829e-01, time/batch = 15.3064s	
26490/29850 (epoch 44.372), train_loss = 0.89634094, grad/param norm = 2.6194e-01, time/batch = 15.1245s	
26491/29850 (epoch 44.374), train_loss = 0.84741086, grad/param norm = 2.1723e-01, time/batch = 17.8694s	
26492/29850 (epoch 44.375), train_loss = 0.80856990, grad/param norm = 2.1803e-01, time/batch = 19.1312s	
26493/29850 (epoch 44.377), train_loss = 0.68113064, grad/param norm = 2.2636e-01, time/batch = 16.9445s	
26494/29850 (epoch 44.379), train_loss = 0.89820666, grad/param norm = 2.6687e-01, time/batch = 16.7870s	
26495/29850 (epoch 44.380), train_loss = 0.83366378, grad/param norm = 2.3946e-01, time/batch = 18.3568s	
26496/29850 (epoch 44.382), train_loss = 0.82623185, grad/param norm = 3.8706e-01, time/batch = 19.2156s	
26497/29850 (epoch 44.384), train_loss = 0.83868841, grad/param norm = 2.5758e-01, time/batch = 17.8423s	
26498/29850 (epoch 44.385), train_loss = 0.83530421, grad/param norm = 2.7150e-01, time/batch = 17.7996s	
26499/29850 (epoch 44.387), train_loss = 0.82870972, grad/param norm = 2.6352e-01, time/batch = 18.1056s	
26500/29850 (epoch 44.389), train_loss = 0.90419126, grad/param norm = 2.5616e-01, time/batch = 18.6962s	
26501/29850 (epoch 44.390), train_loss = 0.86378197, grad/param norm = 2.2945e-01, time/batch = 17.6191s	
26502/29850 (epoch 44.392), train_loss = 0.78917562, grad/param norm = 2.6804e-01, time/batch = 19.7933s	
26503/29850 (epoch 44.394), train_loss = 0.83538977, grad/param norm = 2.3588e-01, time/batch = 19.0418s	
26504/29850 (epoch 44.395), train_loss = 0.75444414, grad/param norm = 2.6600e-01, time/batch = 18.4486s	
26505/29850 (epoch 44.397), train_loss = 0.67889980, grad/param norm = 2.1000e-01, time/batch = 17.6380s	
26506/29850 (epoch 44.399), train_loss = 0.72919206, grad/param norm = 2.2793e-01, time/batch = 16.9782s	
26507/29850 (epoch 44.400), train_loss = 1.06008880, grad/param norm = 2.6318e-01, time/batch = 16.6393s	
26508/29850 (epoch 44.402), train_loss = 0.90561920, grad/param norm = 2.4895e-01, time/batch = 17.1481s	
26509/29850 (epoch 44.404), train_loss = 0.79439861, grad/param norm = 2.2974e-01, time/batch = 15.7743s	
26510/29850 (epoch 44.405), train_loss = 0.76272289, grad/param norm = 3.3250e-01, time/batch = 18.2229s	
26511/29850 (epoch 44.407), train_loss = 0.73710483, grad/param norm = 2.3090e-01, time/batch = 19.0135s	
26512/29850 (epoch 44.409), train_loss = 0.79929113, grad/param norm = 2.3481e-01, time/batch = 17.6444s	
26513/29850 (epoch 44.410), train_loss = 0.88393642, grad/param norm = 2.3907e-01, time/batch = 18.0416s	
26514/29850 (epoch 44.412), train_loss = 0.88725357, grad/param norm = 2.3427e-01, time/batch = 15.5260s	
26515/29850 (epoch 44.414), train_loss = 0.81568017, grad/param norm = 2.4809e-01, time/batch = 16.3024s	
26516/29850 (epoch 44.415), train_loss = 0.79488537, grad/param norm = 2.2462e-01, time/batch = 18.3099s	
26517/29850 (epoch 44.417), train_loss = 0.92711210, grad/param norm = 2.9301e-01, time/batch = 17.7752s	
26518/29850 (epoch 44.419), train_loss = 0.75561994, grad/param norm = 2.4197e-01, time/batch = 17.7863s	
26519/29850 (epoch 44.420), train_loss = 0.76739891, grad/param norm = 2.3507e-01, time/batch = 20.1112s	
26520/29850 (epoch 44.422), train_loss = 0.78738784, grad/param norm = 2.6888e-01, time/batch = 17.2880s	
26521/29850 (epoch 44.424), train_loss = 0.70020535, grad/param norm = 2.1574e-01, time/batch = 18.2051s	
26522/29850 (epoch 44.425), train_loss = 0.86348396, grad/param norm = 3.0738e-01, time/batch = 18.8731s	
26523/29850 (epoch 44.427), train_loss = 0.60693820, grad/param norm = 2.2448e-01, time/batch = 17.3600s	
26524/29850 (epoch 44.429), train_loss = 0.70205061, grad/param norm = 2.3122e-01, time/batch = 16.8843s	
26525/29850 (epoch 44.430), train_loss = 0.65538232, grad/param norm = 2.1402e-01, time/batch = 18.2982s	
26526/29850 (epoch 44.432), train_loss = 0.76694254, grad/param norm = 2.7608e-01, time/batch = 20.0422s	
26527/29850 (epoch 44.434), train_loss = 0.71256720, grad/param norm = 1.7764e-01, time/batch = 15.8818s	
26528/29850 (epoch 44.436), train_loss = 0.76483450, grad/param norm = 2.6209e-01, time/batch = 16.0251s	
26529/29850 (epoch 44.437), train_loss = 0.84918768, grad/param norm = 2.2475e-01, time/batch = 19.0352s	
26530/29850 (epoch 44.439), train_loss = 0.85478461, grad/param norm = 2.5250e-01, time/batch = 19.1218s	
26531/29850 (epoch 44.441), train_loss = 0.77748988, grad/param norm = 2.2349e-01, time/batch = 16.7661s	
26532/29850 (epoch 44.442), train_loss = 0.77997190, grad/param norm = 2.3328e-01, time/batch = 17.7939s	
26533/29850 (epoch 44.444), train_loss = 0.80527203, grad/param norm = 2.3076e-01, time/batch = 19.0454s	
26534/29850 (epoch 44.446), train_loss = 0.87775831, grad/param norm = 2.5643e-01, time/batch = 16.6247s	
26535/29850 (epoch 44.447), train_loss = 0.89358953, grad/param norm = 3.5650e-01, time/batch = 15.6230s	
26536/29850 (epoch 44.449), train_loss = 0.79916894, grad/param norm = 2.7285e-01, time/batch = 16.5483s	
26537/29850 (epoch 44.451), train_loss = 0.63993227, grad/param norm = 2.1902e-01, time/batch = 18.9220s	
26538/29850 (epoch 44.452), train_loss = 0.54838006, grad/param norm = 1.9437e-01, time/batch = 18.5368s	
26539/29850 (epoch 44.454), train_loss = 0.65616534, grad/param norm = 1.9309e-01, time/batch = 18.3885s	
26540/29850 (epoch 44.456), train_loss = 0.84425887, grad/param norm = 2.4029e-01, time/batch = 19.1200s	
26541/29850 (epoch 44.457), train_loss = 0.88884067, grad/param norm = 3.3541e-01, time/batch = 18.9377s	
26542/29850 (epoch 44.459), train_loss = 0.91236028, grad/param norm = 2.9611e-01, time/batch = 17.1265s	
26543/29850 (epoch 44.461), train_loss = 0.94744537, grad/param norm = 2.5911e-01, time/batch = 17.7973s	
26544/29850 (epoch 44.462), train_loss = 0.95120461, grad/param norm = 2.4782e-01, time/batch = 16.6099s	
26545/29850 (epoch 44.464), train_loss = 0.84498582, grad/param norm = 2.3414e-01, time/batch = 16.4716s	
26546/29850 (epoch 44.466), train_loss = 0.70226747, grad/param norm = 2.7825e-01, time/batch = 18.2028s	
26547/29850 (epoch 44.467), train_loss = 0.73168594, grad/param norm = 3.2328e-01, time/batch = 17.6327s	
26548/29850 (epoch 44.469), train_loss = 0.76356386, grad/param norm = 2.0954e-01, time/batch = 18.4543s	
26549/29850 (epoch 44.471), train_loss = 0.77639474, grad/param norm = 2.5690e-01, time/batch = 16.9683s	
26550/29850 (epoch 44.472), train_loss = 0.76176363, grad/param norm = 2.2612e-01, time/batch = 18.0405s	
26551/29850 (epoch 44.474), train_loss = 0.88260117, grad/param norm = 2.9795e-01, time/batch = 17.3645s	
26552/29850 (epoch 44.476), train_loss = 0.79876709, grad/param norm = 2.1085e-01, time/batch = 18.1285s	
26553/29850 (epoch 44.477), train_loss = 0.82551174, grad/param norm = 2.7912e-01, time/batch = 17.1256s	
26554/29850 (epoch 44.479), train_loss = 0.95762570, grad/param norm = 2.6209e-01, time/batch = 18.2032s	
26555/29850 (epoch 44.481), train_loss = 0.81169215, grad/param norm = 2.3994e-01, time/batch = 18.6166s	
26556/29850 (epoch 44.482), train_loss = 0.74326670, grad/param norm = 2.2103e-01, time/batch = 17.3703s	
26557/29850 (epoch 44.484), train_loss = 0.75740823, grad/param norm = 2.3730e-01, time/batch = 18.6174s	
26558/29850 (epoch 44.486), train_loss = 0.82127888, grad/param norm = 2.7004e-01, time/batch = 18.9438s	
26559/29850 (epoch 44.487), train_loss = 0.79592059, grad/param norm = 2.1504e-01, time/batch = 15.6786s	
26560/29850 (epoch 44.489), train_loss = 0.80353350, grad/param norm = 2.4620e-01, time/batch = 18.4644s	
26561/29850 (epoch 44.491), train_loss = 0.71182624, grad/param norm = 2.1201e-01, time/batch = 17.1325s	
26562/29850 (epoch 44.492), train_loss = 0.80076119, grad/param norm = 2.4749e-01, time/batch = 17.5507s	
26563/29850 (epoch 44.494), train_loss = 0.84899972, grad/param norm = 2.3609e-01, time/batch = 18.6349s	
26564/29850 (epoch 44.496), train_loss = 0.92549123, grad/param norm = 2.2221e-01, time/batch = 23.4477s	
26565/29850 (epoch 44.497), train_loss = 0.82476096, grad/param norm = 2.2755e-01, time/batch = 25.7711s	
26566/29850 (epoch 44.499), train_loss = 0.79910212, grad/param norm = 2.4818e-01, time/batch = 15.9329s	
26567/29850 (epoch 44.501), train_loss = 0.71343279, grad/param norm = 3.2754e-01, time/batch = 16.8676s	
26568/29850 (epoch 44.503), train_loss = 0.88707297, grad/param norm = 2.4726e-01, time/batch = 17.1502s	
26569/29850 (epoch 44.504), train_loss = 1.03741706, grad/param norm = 2.3852e-01, time/batch = 19.7220s	
26570/29850 (epoch 44.506), train_loss = 1.01449189, grad/param norm = 2.8704e-01, time/batch = 16.6503s	
26571/29850 (epoch 44.508), train_loss = 0.83614201, grad/param norm = 2.3034e-01, time/batch = 18.5504s	
26572/29850 (epoch 44.509), train_loss = 0.63006219, grad/param norm = 2.1129e-01, time/batch = 18.1325s	
26573/29850 (epoch 44.511), train_loss = 0.83790611, grad/param norm = 2.2506e-01, time/batch = 17.6991s	
26574/29850 (epoch 44.513), train_loss = 0.78031671, grad/param norm = 3.0890e-01, time/batch = 18.5315s	
26575/29850 (epoch 44.514), train_loss = 0.71744380, grad/param norm = 2.0235e-01, time/batch = 15.2124s	
26576/29850 (epoch 44.516), train_loss = 0.74650712, grad/param norm = 2.1505e-01, time/batch = 16.6877s	
26577/29850 (epoch 44.518), train_loss = 0.63344581, grad/param norm = 2.0120e-01, time/batch = 16.7145s	
26578/29850 (epoch 44.519), train_loss = 0.65878575, grad/param norm = 2.1025e-01, time/batch = 15.4839s	
26579/29850 (epoch 44.521), train_loss = 0.61046604, grad/param norm = 1.9438e-01, time/batch = 16.0600s	
26580/29850 (epoch 44.523), train_loss = 0.65360747, grad/param norm = 1.7481e-01, time/batch = 17.8879s	
26581/29850 (epoch 44.524), train_loss = 0.70016178, grad/param norm = 2.6552e-01, time/batch = 15.7645s	
26582/29850 (epoch 44.526), train_loss = 0.72875255, grad/param norm = 2.3817e-01, time/batch = 16.6276s	
26583/29850 (epoch 44.528), train_loss = 0.83425272, grad/param norm = 2.2700e-01, time/batch = 17.5652s	
26584/29850 (epoch 44.529), train_loss = 0.81749199, grad/param norm = 2.5480e-01, time/batch = 17.7901s	
26585/29850 (epoch 44.531), train_loss = 0.76270578, grad/param norm = 2.3803e-01, time/batch = 15.6153s	
26586/29850 (epoch 44.533), train_loss = 0.78819636, grad/param norm = 2.2511e-01, time/batch = 15.8914s	
26587/29850 (epoch 44.534), train_loss = 0.82992102, grad/param norm = 2.2746e-01, time/batch = 18.9699s	
26588/29850 (epoch 44.536), train_loss = 0.74363595, grad/param norm = 2.3040e-01, time/batch = 16.6966s	
26589/29850 (epoch 44.538), train_loss = 0.89574331, grad/param norm = 2.5145e-01, time/batch = 18.6375s	
26590/29850 (epoch 44.539), train_loss = 0.92313926, grad/param norm = 3.1825e-01, time/batch = 15.7158s	
26591/29850 (epoch 44.541), train_loss = 0.55450363, grad/param norm = 1.9189e-01, time/batch = 18.0455s	
26592/29850 (epoch 44.543), train_loss = 0.75821099, grad/param norm = 2.8831e-01, time/batch = 19.6105s	
26593/29850 (epoch 44.544), train_loss = 0.89525374, grad/param norm = 2.7214e-01, time/batch = 18.5414s	
26594/29850 (epoch 44.546), train_loss = 0.85510508, grad/param norm = 2.2881e-01, time/batch = 18.2005s	
26595/29850 (epoch 44.548), train_loss = 0.65813345, grad/param norm = 2.0586e-01, time/batch = 16.9385s	
26596/29850 (epoch 44.549), train_loss = 0.76997213, grad/param norm = 2.2911e-01, time/batch = 17.1248s	
26597/29850 (epoch 44.551), train_loss = 0.70774282, grad/param norm = 2.1315e-01, time/batch = 17.1995s	
26598/29850 (epoch 44.553), train_loss = 0.77534246, grad/param norm = 2.3669e-01, time/batch = 16.0385s	
26599/29850 (epoch 44.554), train_loss = 0.64210571, grad/param norm = 2.2735e-01, time/batch = 17.6381s	
26600/29850 (epoch 44.556), train_loss = 0.69083148, grad/param norm = 3.2907e-01, time/batch = 18.1247s	
26601/29850 (epoch 44.558), train_loss = 0.70556061, grad/param norm = 3.1134e-01, time/batch = 17.6223s	
26602/29850 (epoch 44.559), train_loss = 0.71424088, grad/param norm = 2.2313e-01, time/batch = 20.2820s	
26603/29850 (epoch 44.561), train_loss = 0.78394657, grad/param norm = 2.2044e-01, time/batch = 17.2911s	
26604/29850 (epoch 44.563), train_loss = 0.80595854, grad/param norm = 2.1255e-01, time/batch = 18.8621s	
26605/29850 (epoch 44.564), train_loss = 0.73718618, grad/param norm = 2.4220e-01, time/batch = 16.6971s	
26606/29850 (epoch 44.566), train_loss = 0.77064819, grad/param norm = 2.2483e-01, time/batch = 19.9718s	
26607/29850 (epoch 44.568), train_loss = 0.92248788, grad/param norm = 3.1096e-01, time/batch = 17.1813s	
26608/29850 (epoch 44.570), train_loss = 0.79823707, grad/param norm = 2.1796e-01, time/batch = 16.3815s	
26609/29850 (epoch 44.571), train_loss = 0.85276105, grad/param norm = 2.3284e-01, time/batch = 17.2175s	
26610/29850 (epoch 44.573), train_loss = 0.93874901, grad/param norm = 3.3954e-01, time/batch = 17.8032s	
26611/29850 (epoch 44.575), train_loss = 0.98218665, grad/param norm = 2.3770e-01, time/batch = 17.0141s	
26612/29850 (epoch 44.576), train_loss = 0.85479841, grad/param norm = 2.2627e-01, time/batch = 17.0331s	
26613/29850 (epoch 44.578), train_loss = 0.73022527, grad/param norm = 2.3992e-01, time/batch = 19.3830s	
26614/29850 (epoch 44.580), train_loss = 0.86728405, grad/param norm = 3.1747e-01, time/batch = 19.6956s	
26615/29850 (epoch 44.581), train_loss = 0.72661283, grad/param norm = 2.0900e-01, time/batch = 16.4532s	
26616/29850 (epoch 44.583), train_loss = 0.77611719, grad/param norm = 2.1476e-01, time/batch = 16.7616s	
26617/29850 (epoch 44.585), train_loss = 0.80021559, grad/param norm = 2.3047e-01, time/batch = 18.0392s	
26618/29850 (epoch 44.586), train_loss = 0.81733101, grad/param norm = 2.2848e-01, time/batch = 16.6072s	
26619/29850 (epoch 44.588), train_loss = 0.70288092, grad/param norm = 2.0326e-01, time/batch = 17.4470s	
26620/29850 (epoch 44.590), train_loss = 0.73084131, grad/param norm = 1.9752e-01, time/batch = 19.6191s	
26621/29850 (epoch 44.591), train_loss = 0.77837454, grad/param norm = 2.3532e-01, time/batch = 18.2079s	
26622/29850 (epoch 44.593), train_loss = 0.69228977, grad/param norm = 2.0632e-01, time/batch = 18.4594s	
26623/29850 (epoch 44.595), train_loss = 0.65992900, grad/param norm = 2.0454e-01, time/batch = 17.9766s	
26624/29850 (epoch 44.596), train_loss = 0.69269622, grad/param norm = 2.6147e-01, time/batch = 18.4495s	
26625/29850 (epoch 44.598), train_loss = 0.74892063, grad/param norm = 1.9912e-01, time/batch = 18.2043s	
26626/29850 (epoch 44.600), train_loss = 0.79949766, grad/param norm = 2.4473e-01, time/batch = 18.2110s	
26627/29850 (epoch 44.601), train_loss = 0.66984611, grad/param norm = 2.1946e-01, time/batch = 19.3800s	
26628/29850 (epoch 44.603), train_loss = 0.70938478, grad/param norm = 1.8962e-01, time/batch = 16.0386s	
26629/29850 (epoch 44.605), train_loss = 0.74459586, grad/param norm = 2.3160e-01, time/batch = 16.7269s	
26630/29850 (epoch 44.606), train_loss = 0.51973646, grad/param norm = 2.1154e-01, time/batch = 16.5436s	
26631/29850 (epoch 44.608), train_loss = 0.64985029, grad/param norm = 1.8574e-01, time/batch = 18.0348s	
26632/29850 (epoch 44.610), train_loss = 0.72418895, grad/param norm = 1.9311e-01, time/batch = 18.4600s	
26633/29850 (epoch 44.611), train_loss = 0.65889842, grad/param norm = 1.8853e-01, time/batch = 16.3843s	
26634/29850 (epoch 44.613), train_loss = 0.56823380, grad/param norm = 1.8542e-01, time/batch = 17.3049s	
26635/29850 (epoch 44.615), train_loss = 0.64930623, grad/param norm = 2.2541e-01, time/batch = 16.7919s	
26636/29850 (epoch 44.616), train_loss = 0.64767478, grad/param norm = 2.1489e-01, time/batch = 18.8064s	
26637/29850 (epoch 44.618), train_loss = 0.70571664, grad/param norm = 1.9854e-01, time/batch = 18.4690s	
26638/29850 (epoch 44.620), train_loss = 0.80682188, grad/param norm = 2.3000e-01, time/batch = 16.3863s	
26639/29850 (epoch 44.621), train_loss = 0.85728566, grad/param norm = 2.6167e-01, time/batch = 19.1250s	
26640/29850 (epoch 44.623), train_loss = 0.84537652, grad/param norm = 2.2369e-01, time/batch = 17.3756s	
26641/29850 (epoch 44.625), train_loss = 0.76746696, grad/param norm = 2.3591e-01, time/batch = 18.0367s	
26642/29850 (epoch 44.626), train_loss = 0.77090019, grad/param norm = 2.3203e-01, time/batch = 18.2028s	
26643/29850 (epoch 44.628), train_loss = 0.77832683, grad/param norm = 2.8175e-01, time/batch = 16.5842s	
26644/29850 (epoch 44.630), train_loss = 0.79110338, grad/param norm = 2.4017e-01, time/batch = 17.6305s	
26645/29850 (epoch 44.631), train_loss = 0.80232269, grad/param norm = 2.4175e-01, time/batch = 15.5356s	
26646/29850 (epoch 44.633), train_loss = 0.81379867, grad/param norm = 3.5154e-01, time/batch = 19.4537s	
26647/29850 (epoch 44.635), train_loss = 0.75610006, grad/param norm = 3.8426e-01, time/batch = 18.1441s	
26648/29850 (epoch 44.637), train_loss = 0.70014797, grad/param norm = 2.6472e-01, time/batch = 16.7887s	
26649/29850 (epoch 44.638), train_loss = 0.82345227, grad/param norm = 2.7732e-01, time/batch = 17.7901s	
26650/29850 (epoch 44.640), train_loss = 0.92932120, grad/param norm = 2.9782e-01, time/batch = 17.6939s	
26651/29850 (epoch 44.642), train_loss = 0.74745778, grad/param norm = 2.1592e-01, time/batch = 19.4578s	
26652/29850 (epoch 44.643), train_loss = 0.71216454, grad/param norm = 2.3698e-01, time/batch = 16.6946s	
26653/29850 (epoch 44.645), train_loss = 0.75087836, grad/param norm = 2.1621e-01, time/batch = 18.7987s	
26654/29850 (epoch 44.647), train_loss = 0.89134644, grad/param norm = 2.8519e-01, time/batch = 17.8567s	
26655/29850 (epoch 44.648), train_loss = 0.71410388, grad/param norm = 2.3900e-01, time/batch = 17.3697s	
26656/29850 (epoch 44.650), train_loss = 0.78841708, grad/param norm = 2.0812e-01, time/batch = 17.7633s	
26657/29850 (epoch 44.652), train_loss = 0.78551974, grad/param norm = 2.2129e-01, time/batch = 17.1182s	
26658/29850 (epoch 44.653), train_loss = 0.88449038, grad/param norm = 3.8267e-01, time/batch = 18.9405s	
26659/29850 (epoch 44.655), train_loss = 0.79923830, grad/param norm = 2.1462e-01, time/batch = 19.4424s	
26660/29850 (epoch 44.657), train_loss = 0.75661706, grad/param norm = 2.0899e-01, time/batch = 18.6288s	
26661/29850 (epoch 44.658), train_loss = 0.88703487, grad/param norm = 2.4448e-01, time/batch = 18.3609s	
26662/29850 (epoch 44.660), train_loss = 0.74061747, grad/param norm = 2.1742e-01, time/batch = 18.9519s	
26663/29850 (epoch 44.662), train_loss = 0.89071883, grad/param norm = 3.0307e-01, time/batch = 17.1382s	
26664/29850 (epoch 44.663), train_loss = 0.99834871, grad/param norm = 2.6946e-01, time/batch = 19.4566s	
26665/29850 (epoch 44.665), train_loss = 0.91749804, grad/param norm = 2.7444e-01, time/batch = 17.1817s	
26666/29850 (epoch 44.667), train_loss = 0.83574289, grad/param norm = 2.6448e-01, time/batch = 18.6388s	
26667/29850 (epoch 44.668), train_loss = 0.73317155, grad/param norm = 2.3366e-01, time/batch = 16.9458s	
26668/29850 (epoch 44.670), train_loss = 0.85376916, grad/param norm = 3.0612e-01, time/batch = 17.2916s	
26669/29850 (epoch 44.672), train_loss = 0.89789905, grad/param norm = 3.1423e-01, time/batch = 16.8783s	
26670/29850 (epoch 44.673), train_loss = 0.82218233, grad/param norm = 2.7877e-01, time/batch = 17.9545s	
26671/29850 (epoch 44.675), train_loss = 0.71226335, grad/param norm = 2.2239e-01, time/batch = 19.0382s	
26672/29850 (epoch 44.677), train_loss = 0.75353948, grad/param norm = 2.8330e-01, time/batch = 15.7799s	
26673/29850 (epoch 44.678), train_loss = 0.78021194, grad/param norm = 2.4144e-01, time/batch = 17.0085s	
26674/29850 (epoch 44.680), train_loss = 0.77806578, grad/param norm = 2.2458e-01, time/batch = 17.7835s	
26675/29850 (epoch 44.682), train_loss = 0.78180191, grad/param norm = 2.5093e-01, time/batch = 17.2175s	
26676/29850 (epoch 44.683), train_loss = 0.87863529, grad/param norm = 2.6688e-01, time/batch = 19.1322s	
26677/29850 (epoch 44.685), train_loss = 0.97453575, grad/param norm = 2.3949e-01, time/batch = 15.1081s	
26678/29850 (epoch 44.687), train_loss = 0.82672212, grad/param norm = 2.4137e-01, time/batch = 17.8371s	
26679/29850 (epoch 44.688), train_loss = 0.70661813, grad/param norm = 2.5417e-01, time/batch = 18.1446s	
26680/29850 (epoch 44.690), train_loss = 0.70981829, grad/param norm = 2.4223e-01, time/batch = 17.6020s	
26681/29850 (epoch 44.692), train_loss = 0.89412050, grad/param norm = 2.5513e-01, time/batch = 18.8750s	
26682/29850 (epoch 44.693), train_loss = 0.78415858, grad/param norm = 2.1340e-01, time/batch = 17.6941s	
26683/29850 (epoch 44.695), train_loss = 0.68596020, grad/param norm = 1.9419e-01, time/batch = 18.6845s	
26684/29850 (epoch 44.697), train_loss = 0.77800333, grad/param norm = 2.3681e-01, time/batch = 15.0274s	
26685/29850 (epoch 44.698), train_loss = 0.89799732, grad/param norm = 2.3711e-01, time/batch = 16.5525s	
26686/29850 (epoch 44.700), train_loss = 0.84562937, grad/param norm = 2.7458e-01, time/batch = 18.6204s	
26687/29850 (epoch 44.702), train_loss = 0.80630546, grad/param norm = 2.6172e-01, time/batch = 17.5499s	
26688/29850 (epoch 44.704), train_loss = 0.67692690, grad/param norm = 2.0434e-01, time/batch = 18.4616s	
26689/29850 (epoch 44.705), train_loss = 0.78619718, grad/param norm = 2.5143e-01, time/batch = 19.2805s	
26690/29850 (epoch 44.707), train_loss = 0.72326424, grad/param norm = 2.3502e-01, time/batch = 18.0358s	
26691/29850 (epoch 44.709), train_loss = 0.76166576, grad/param norm = 2.3940e-01, time/batch = 16.6890s	
26692/29850 (epoch 44.710), train_loss = 0.71403325, grad/param norm = 2.7935e-01, time/batch = 16.7062s	
26693/29850 (epoch 44.712), train_loss = 0.83507531, grad/param norm = 2.4308e-01, time/batch = 18.7984s	
26694/29850 (epoch 44.714), train_loss = 0.85528601, grad/param norm = 2.5835e-01, time/batch = 17.4615s	
26695/29850 (epoch 44.715), train_loss = 0.81275566, grad/param norm = 2.3277e-01, time/batch = 18.0383s	
26696/29850 (epoch 44.717), train_loss = 0.61158158, grad/param norm = 2.2593e-01, time/batch = 14.6559s	
26697/29850 (epoch 44.719), train_loss = 0.74579632, grad/param norm = 2.1275e-01, time/batch = 18.7197s	
26698/29850 (epoch 44.720), train_loss = 0.74968526, grad/param norm = 1.9667e-01, time/batch = 19.2075s	
26699/29850 (epoch 44.722), train_loss = 0.71185078, grad/param norm = 1.8819e-01, time/batch = 15.6792s	
26700/29850 (epoch 44.724), train_loss = 0.81521106, grad/param norm = 2.8790e-01, time/batch = 15.6493s	
26701/29850 (epoch 44.725), train_loss = 0.66375555, grad/param norm = 2.0088e-01, time/batch = 17.4686s	
26702/29850 (epoch 44.727), train_loss = 0.66265188, grad/param norm = 2.3394e-01, time/batch = 15.0947s	
26703/29850 (epoch 44.729), train_loss = 0.64037670, grad/param norm = 1.6929e-01, time/batch = 15.1296s	
26704/29850 (epoch 44.730), train_loss = 0.61788100, grad/param norm = 2.1535e-01, time/batch = 15.8658s	
26705/29850 (epoch 44.732), train_loss = 0.84184701, grad/param norm = 2.1190e-01, time/batch = 15.0232s	
26706/29850 (epoch 44.734), train_loss = 0.94647678, grad/param norm = 3.0983e-01, time/batch = 14.7592s	
26707/29850 (epoch 44.735), train_loss = 0.72487678, grad/param norm = 2.4316e-01, time/batch = 14.4263s	
26708/29850 (epoch 44.737), train_loss = 0.67458578, grad/param norm = 1.9791e-01, time/batch = 15.4299s	
26709/29850 (epoch 44.739), train_loss = 0.58615397, grad/param norm = 1.9525e-01, time/batch = 16.7999s	
26710/29850 (epoch 44.740), train_loss = 0.63866450, grad/param norm = 2.3413e-01, time/batch = 17.3104s	
26711/29850 (epoch 44.742), train_loss = 0.56384191, grad/param norm = 1.6857e-01, time/batch = 18.9695s	
26712/29850 (epoch 44.744), train_loss = 0.69076404, grad/param norm = 2.6971e-01, time/batch = 15.9731s	
26713/29850 (epoch 44.745), train_loss = 0.72935322, grad/param norm = 2.2330e-01, time/batch = 18.2072s	
26714/29850 (epoch 44.747), train_loss = 0.76829643, grad/param norm = 2.3121e-01, time/batch = 18.3902s	
26715/29850 (epoch 44.749), train_loss = 0.64563156, grad/param norm = 2.0429e-01, time/batch = 17.6988s	
26716/29850 (epoch 44.750), train_loss = 0.59073065, grad/param norm = 2.2063e-01, time/batch = 19.8746s	
26717/29850 (epoch 44.752), train_loss = 0.51454956, grad/param norm = 1.7289e-01, time/batch = 17.8465s	
26718/29850 (epoch 44.754), train_loss = 0.59443548, grad/param norm = 2.3152e-01, time/batch = 18.5478s	
26719/29850 (epoch 44.755), train_loss = 0.59843339, grad/param norm = 2.3354e-01, time/batch = 15.3622s	
26720/29850 (epoch 44.757), train_loss = 0.65040491, grad/param norm = 1.9109e-01, time/batch = 17.7886s	
26721/29850 (epoch 44.759), train_loss = 0.64675678, grad/param norm = 2.1178e-01, time/batch = 19.4667s	
26722/29850 (epoch 44.760), train_loss = 0.68928555, grad/param norm = 2.1423e-01, time/batch = 18.0332s	
26723/29850 (epoch 44.762), train_loss = 0.62040798, grad/param norm = 2.0662e-01, time/batch = 18.2122s	
26724/29850 (epoch 44.764), train_loss = 0.55781070, grad/param norm = 2.1544e-01, time/batch = 19.2766s	
26725/29850 (epoch 44.765), train_loss = 0.71580091, grad/param norm = 2.5222e-01, time/batch = 18.2083s	
26726/29850 (epoch 44.767), train_loss = 0.68688499, grad/param norm = 1.9801e-01, time/batch = 17.6579s	
26727/29850 (epoch 44.769), train_loss = 0.74188348, grad/param norm = 2.1514e-01, time/batch = 17.9310s	
26728/29850 (epoch 44.771), train_loss = 0.73602762, grad/param norm = 2.2497e-01, time/batch = 19.6215s	
26729/29850 (epoch 44.772), train_loss = 0.72122834, grad/param norm = 2.2328e-01, time/batch = 15.4504s	
26730/29850 (epoch 44.774), train_loss = 0.68043713, grad/param norm = 2.1594e-01, time/batch = 15.7067s	
26731/29850 (epoch 44.776), train_loss = 0.71460447, grad/param norm = 2.2276e-01, time/batch = 19.4519s	
26732/29850 (epoch 44.777), train_loss = 0.82696811, grad/param norm = 3.0307e-01, time/batch = 17.3990s	
26733/29850 (epoch 44.779), train_loss = 0.64383349, grad/param norm = 2.2185e-01, time/batch = 17.5341s	
26734/29850 (epoch 44.781), train_loss = 0.78606032, grad/param norm = 2.7726e-01, time/batch = 17.3000s	
26735/29850 (epoch 44.782), train_loss = 0.78298726, grad/param norm = 2.1670e-01, time/batch = 17.0302s	
26736/29850 (epoch 44.784), train_loss = 0.61640590, grad/param norm = 2.4602e-01, time/batch = 17.0168s	
26737/29850 (epoch 44.786), train_loss = 0.67999531, grad/param norm = 2.3254e-01, time/batch = 15.5273s	
26738/29850 (epoch 44.787), train_loss = 0.57833226, grad/param norm = 2.6304e-01, time/batch = 20.0240s	
26739/29850 (epoch 44.789), train_loss = 0.59451220, grad/param norm = 1.9368e-01, time/batch = 18.8768s	
26740/29850 (epoch 44.791), train_loss = 0.67165339, grad/param norm = 2.4319e-01, time/batch = 18.1995s	
26741/29850 (epoch 44.792), train_loss = 0.77981891, grad/param norm = 2.5104e-01, time/batch = 18.9354s	
26742/29850 (epoch 44.794), train_loss = 0.74482768, grad/param norm = 2.2730e-01, time/batch = 17.3843s	
26743/29850 (epoch 44.796), train_loss = 0.64816216, grad/param norm = 2.2428e-01, time/batch = 18.7056s	
26744/29850 (epoch 44.797), train_loss = 0.55192798, grad/param norm = 1.8777e-01, time/batch = 18.7127s	
26745/29850 (epoch 44.799), train_loss = 0.60364496, grad/param norm = 1.7443e-01, time/batch = 16.8800s	
26746/29850 (epoch 44.801), train_loss = 0.62901609, grad/param norm = 2.0320e-01, time/batch = 18.2162s	
26747/29850 (epoch 44.802), train_loss = 0.59577555, grad/param norm = 2.0766e-01, time/batch = 17.3761s	
26748/29850 (epoch 44.804), train_loss = 0.63187121, grad/param norm = 1.8948e-01, time/batch = 18.9617s	
26749/29850 (epoch 44.806), train_loss = 0.56497620, grad/param norm = 2.0544e-01, time/batch = 18.8061s	
26750/29850 (epoch 44.807), train_loss = 0.61421040, grad/param norm = 1.8943e-01, time/batch = 15.9386s	
26751/29850 (epoch 44.809), train_loss = 0.62511863, grad/param norm = 2.2124e-01, time/batch = 16.2975s	
26752/29850 (epoch 44.811), train_loss = 0.78795898, grad/param norm = 2.6842e-01, time/batch = 17.4807s	
26753/29850 (epoch 44.812), train_loss = 0.74158799, grad/param norm = 2.2052e-01, time/batch = 17.1285s	
26754/29850 (epoch 44.814), train_loss = 0.79674231, grad/param norm = 3.1489e-01, time/batch = 17.2807s	
26755/29850 (epoch 44.816), train_loss = 0.87124466, grad/param norm = 2.3256e-01, time/batch = 18.0444s	
26756/29850 (epoch 44.817), train_loss = 0.76714181, grad/param norm = 2.8701e-01, time/batch = 19.1311s	
26757/29850 (epoch 44.819), train_loss = 0.58192738, grad/param norm = 1.9980e-01, time/batch = 17.5354s	
26758/29850 (epoch 44.821), train_loss = 0.83221428, grad/param norm = 2.8363e-01, time/batch = 17.6342s	
26759/29850 (epoch 44.822), train_loss = 0.85155765, grad/param norm = 2.1389e-01, time/batch = 16.5470s	
26760/29850 (epoch 44.824), train_loss = 0.74443523, grad/param norm = 2.3628e-01, time/batch = 17.3775s	
26761/29850 (epoch 44.826), train_loss = 0.62623926, grad/param norm = 2.0314e-01, time/batch = 19.7723s	
26762/29850 (epoch 44.827), train_loss = 0.55944190, grad/param norm = 2.3337e-01, time/batch = 17.1807s	
26763/29850 (epoch 44.829), train_loss = 0.73891412, grad/param norm = 2.5794e-01, time/batch = 17.6201s	
26764/29850 (epoch 44.831), train_loss = 0.85842030, grad/param norm = 2.6613e-01, time/batch = 19.0298s	
26765/29850 (epoch 44.832), train_loss = 0.74957854, grad/param norm = 2.0816e-01, time/batch = 17.8864s	
26766/29850 (epoch 44.834), train_loss = 0.55608872, grad/param norm = 2.0091e-01, time/batch = 18.2921s	
26767/29850 (epoch 44.836), train_loss = 0.58060368, grad/param norm = 2.0894e-01, time/batch = 27.6146s	
26768/29850 (epoch 44.838), train_loss = 0.65735906, grad/param norm = 2.0684e-01, time/batch = 19.9330s	
26769/29850 (epoch 44.839), train_loss = 0.56818350, grad/param norm = 2.1575e-01, time/batch = 16.4701s	
26770/29850 (epoch 44.841), train_loss = 0.65570522, grad/param norm = 2.0839e-01, time/batch = 16.8470s	
26771/29850 (epoch 44.843), train_loss = 0.57942238, grad/param norm = 2.2413e-01, time/batch = 16.7844s	
26772/29850 (epoch 44.844), train_loss = 0.62342796, grad/param norm = 2.3617e-01, time/batch = 15.6209s	
26773/29850 (epoch 44.846), train_loss = 0.69343346, grad/param norm = 1.9765e-01, time/batch = 17.1171s	
26774/29850 (epoch 44.848), train_loss = 0.76646306, grad/param norm = 2.5939e-01, time/batch = 18.2098s	
26775/29850 (epoch 44.849), train_loss = 0.69276714, grad/param norm = 2.3202e-01, time/batch = 17.1353s	
26776/29850 (epoch 44.851), train_loss = 0.89042162, grad/param norm = 2.3586e-01, time/batch = 18.5251s	
26777/29850 (epoch 44.853), train_loss = 0.68359069, grad/param norm = 2.4983e-01, time/batch = 18.2105s	
26778/29850 (epoch 44.854), train_loss = 0.85447688, grad/param norm = 2.4738e-01, time/batch = 18.2230s	
26779/29850 (epoch 44.856), train_loss = 0.83007612, grad/param norm = 2.5735e-01, time/batch = 16.3760s	
26780/29850 (epoch 44.858), train_loss = 0.74917466, grad/param norm = 2.8999e-01, time/batch = 16.6205s	
26781/29850 (epoch 44.859), train_loss = 0.64161843, grad/param norm = 2.1151e-01, time/batch = 20.2058s	
26782/29850 (epoch 44.861), train_loss = 0.79214433, grad/param norm = 2.4484e-01, time/batch = 18.6259s	
26783/29850 (epoch 44.863), train_loss = 0.83862967, grad/param norm = 3.2466e-01, time/batch = 17.6938s	
26784/29850 (epoch 44.864), train_loss = 0.82953315, grad/param norm = 2.5718e-01, time/batch = 15.4595s	
26785/29850 (epoch 44.866), train_loss = 0.76194310, grad/param norm = 2.7857e-01, time/batch = 16.4454s	
26786/29850 (epoch 44.868), train_loss = 0.92035014, grad/param norm = 2.8571e-01, time/batch = 19.2703s	
26787/29850 (epoch 44.869), train_loss = 0.84840217, grad/param norm = 2.8613e-01, time/batch = 17.6137s	
26788/29850 (epoch 44.871), train_loss = 0.81239069, grad/param norm = 2.3012e-01, time/batch = 16.8844s	
26789/29850 (epoch 44.873), train_loss = 0.78206225, grad/param norm = 2.4196e-01, time/batch = 18.0473s	
26790/29850 (epoch 44.874), train_loss = 0.77767285, grad/param norm = 2.1311e-01, time/batch = 17.3681s	
26791/29850 (epoch 44.876), train_loss = 0.78274038, grad/param norm = 4.1155e-01, time/batch = 18.1032s	
26792/29850 (epoch 44.878), train_loss = 0.76888362, grad/param norm = 2.2199e-01, time/batch = 17.2823s	
26793/29850 (epoch 44.879), train_loss = 0.80348688, grad/param norm = 2.2610e-01, time/batch = 17.1131s	
26794/29850 (epoch 44.881), train_loss = 0.86228025, grad/param norm = 2.7542e-01, time/batch = 19.2656s	
26795/29850 (epoch 44.883), train_loss = 0.77393508, grad/param norm = 2.3732e-01, time/batch = 18.2897s	
26796/29850 (epoch 44.884), train_loss = 0.67174488, grad/param norm = 2.3043e-01, time/batch = 18.7172s	
26797/29850 (epoch 44.886), train_loss = 0.80895009, grad/param norm = 3.1274e-01, time/batch = 18.0427s	
26798/29850 (epoch 44.888), train_loss = 0.75991519, grad/param norm = 2.3857e-01, time/batch = 19.2729s	
26799/29850 (epoch 44.889), train_loss = 0.70482066, grad/param norm = 2.0777e-01, time/batch = 17.8664s	
26800/29850 (epoch 44.891), train_loss = 0.66540066, grad/param norm = 1.8892e-01, time/batch = 16.9804s	
26801/29850 (epoch 44.893), train_loss = 0.73389670, grad/param norm = 2.8464e-01, time/batch = 18.0232s	
26802/29850 (epoch 44.894), train_loss = 0.71730372, grad/param norm = 2.3663e-01, time/batch = 17.9565s	
26803/29850 (epoch 44.896), train_loss = 0.77011899, grad/param norm = 2.5887e-01, time/batch = 18.6203s	
26804/29850 (epoch 44.898), train_loss = 0.91479643, grad/param norm = 2.4486e-01, time/batch = 19.2027s	
26805/29850 (epoch 44.899), train_loss = 0.65370732, grad/param norm = 2.5067e-01, time/batch = 19.4640s	
26806/29850 (epoch 44.901), train_loss = 0.93249209, grad/param norm = 2.9665e-01, time/batch = 17.1304s	
26807/29850 (epoch 44.903), train_loss = 0.79903576, grad/param norm = 3.0585e-01, time/batch = 17.2859s	
26808/29850 (epoch 44.905), train_loss = 1.00352336, grad/param norm = 2.5755e-01, time/batch = 17.9358s	
26809/29850 (epoch 44.906), train_loss = 0.78376870, grad/param norm = 2.9358e-01, time/batch = 14.7390s	
26810/29850 (epoch 44.908), train_loss = 0.92097581, grad/param norm = 3.2237e-01, time/batch = 17.6257s	
26811/29850 (epoch 44.910), train_loss = 0.84666139, grad/param norm = 2.2349e-01, time/batch = 18.6291s	
26812/29850 (epoch 44.911), train_loss = 0.97753640, grad/param norm = 2.3787e-01, time/batch = 16.3467s	
26813/29850 (epoch 44.913), train_loss = 0.91180585, grad/param norm = 2.5995e-01, time/batch = 17.3757s	
26814/29850 (epoch 44.915), train_loss = 0.91279028, grad/param norm = 2.5892e-01, time/batch = 18.2990s	
26815/29850 (epoch 44.916), train_loss = 0.86786480, grad/param norm = 2.6997e-01, time/batch = 17.5426s	
26816/29850 (epoch 44.918), train_loss = 0.71118900, grad/param norm = 2.2487e-01, time/batch = 18.6259s	
26817/29850 (epoch 44.920), train_loss = 0.87574298, grad/param norm = 2.0608e-01, time/batch = 15.5285s	
26818/29850 (epoch 44.921), train_loss = 0.76567054, grad/param norm = 2.3837e-01, time/batch = 17.7915s	
26819/29850 (epoch 44.923), train_loss = 0.79640527, grad/param norm = 2.7223e-01, time/batch = 18.8017s	
26820/29850 (epoch 44.925), train_loss = 0.92718356, grad/param norm = 2.6848e-01, time/batch = 17.3690s	
26821/29850 (epoch 44.926), train_loss = 0.94643737, grad/param norm = 2.9778e-01, time/batch = 17.7934s	
26822/29850 (epoch 44.928), train_loss = 0.77942840, grad/param norm = 2.2430e-01, time/batch = 19.5308s	
26823/29850 (epoch 44.930), train_loss = 0.79087588, grad/param norm = 2.3290e-01, time/batch = 17.7113s	
26824/29850 (epoch 44.931), train_loss = 0.80253516, grad/param norm = 2.5099e-01, time/batch = 18.3063s	
26825/29850 (epoch 44.933), train_loss = 0.90870075, grad/param norm = 2.3158e-01, time/batch = 18.3736s	
26826/29850 (epoch 44.935), train_loss = 0.84576807, grad/param norm = 2.4824e-01, time/batch = 18.2794s	
26827/29850 (epoch 44.936), train_loss = 0.82477133, grad/param norm = 2.6366e-01, time/batch = 17.2035s	
26828/29850 (epoch 44.938), train_loss = 0.69271390, grad/param norm = 2.2363e-01, time/batch = 17.9675s	
26829/29850 (epoch 44.940), train_loss = 0.71491472, grad/param norm = 2.3735e-01, time/batch = 16.7004s	
26830/29850 (epoch 44.941), train_loss = 0.69445692, grad/param norm = 2.4415e-01, time/batch = 15.7190s	
26831/29850 (epoch 44.943), train_loss = 0.73987750, grad/param norm = 2.2814e-01, time/batch = 19.8636s	
26832/29850 (epoch 44.945), train_loss = 0.67777072, grad/param norm = 2.3939e-01, time/batch = 17.4608s	
26833/29850 (epoch 44.946), train_loss = 0.68197188, grad/param norm = 2.4424e-01, time/batch = 15.2073s	
26834/29850 (epoch 44.948), train_loss = 0.78841443, grad/param norm = 2.1968e-01, time/batch = 16.1876s	
26835/29850 (epoch 44.950), train_loss = 0.72806497, grad/param norm = 1.8077e-01, time/batch = 17.2896s	
26836/29850 (epoch 44.951), train_loss = 0.64169503, grad/param norm = 1.9614e-01, time/batch = 18.6327s	
26837/29850 (epoch 44.953), train_loss = 0.72556507, grad/param norm = 2.2702e-01, time/batch = 15.7012s	
26838/29850 (epoch 44.955), train_loss = 0.63165482, grad/param norm = 1.6951e-01, time/batch = 18.4515s	
26839/29850 (epoch 44.956), train_loss = 0.65194763, grad/param norm = 2.0408e-01, time/batch = 18.6387s	
26840/29850 (epoch 44.958), train_loss = 0.60000460, grad/param norm = 1.8222e-01, time/batch = 17.8691s	
26841/29850 (epoch 44.960), train_loss = 0.84959970, grad/param norm = 2.7339e-01, time/batch = 17.0506s	
26842/29850 (epoch 44.961), train_loss = 0.62910703, grad/param norm = 2.0736e-01, time/batch = 18.8770s	
26843/29850 (epoch 44.963), train_loss = 0.60894651, grad/param norm = 2.4150e-01, time/batch = 17.7071s	
26844/29850 (epoch 44.965), train_loss = 0.66712385, grad/param norm = 2.3420e-01, time/batch = 17.8757s	
26845/29850 (epoch 44.966), train_loss = 0.65843285, grad/param norm = 2.4111e-01, time/batch = 15.2966s	
26846/29850 (epoch 44.968), train_loss = 0.67819882, grad/param norm = 2.9917e-01, time/batch = 17.5416s	
26847/29850 (epoch 44.970), train_loss = 0.69521694, grad/param norm = 2.2234e-01, time/batch = 17.9482s	
26848/29850 (epoch 44.972), train_loss = 0.68990221, grad/param norm = 2.0074e-01, time/batch = 19.6002s	
26849/29850 (epoch 44.973), train_loss = 0.65797845, grad/param norm = 1.8448e-01, time/batch = 18.0512s	
26850/29850 (epoch 44.975), train_loss = 0.60328836, grad/param norm = 2.2196e-01, time/batch = 17.9476s	
26851/29850 (epoch 44.977), train_loss = 0.71503214, grad/param norm = 2.6237e-01, time/batch = 18.1234s	
26852/29850 (epoch 44.978), train_loss = 0.59272329, grad/param norm = 1.7249e-01, time/batch = 16.9907s	
26853/29850 (epoch 44.980), train_loss = 0.67778869, grad/param norm = 2.1560e-01, time/batch = 18.2951s	
26854/29850 (epoch 44.982), train_loss = 0.63530844, grad/param norm = 1.9531e-01, time/batch = 17.2960s	
26855/29850 (epoch 44.983), train_loss = 0.68289330, grad/param norm = 1.9620e-01, time/batch = 18.2935s	
26856/29850 (epoch 44.985), train_loss = 0.79166534, grad/param norm = 2.5690e-01, time/batch = 16.7736s	
26857/29850 (epoch 44.987), train_loss = 0.76572384, grad/param norm = 2.3670e-01, time/batch = 18.2816s	
26858/29850 (epoch 44.988), train_loss = 0.71344024, grad/param norm = 1.9348e-01, time/batch = 15.9731s	
26859/29850 (epoch 44.990), train_loss = 0.78007793, grad/param norm = 2.2222e-01, time/batch = 18.6326s	
26860/29850 (epoch 44.992), train_loss = 0.75525446, grad/param norm = 2.0635e-01, time/batch = 17.8756s	
26861/29850 (epoch 44.993), train_loss = 0.78421266, grad/param norm = 2.4264e-01, time/batch = 16.7052s	
26862/29850 (epoch 44.995), train_loss = 0.74529313, grad/param norm = 2.2672e-01, time/batch = 16.8931s	
26863/29850 (epoch 44.997), train_loss = 0.77519096, grad/param norm = 2.1565e-01, time/batch = 18.2254s	
26864/29850 (epoch 44.998), train_loss = 0.78598520, grad/param norm = 2.1142e-01, time/batch = 16.9203s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
26865/29850 (epoch 45.000), train_loss = 0.60783142, grad/param norm = 1.8120e-01, time/batch = 18.9542s	
26866/29850 (epoch 45.002), train_loss = 0.86060058, grad/param norm = 2.9017e-01, time/batch = 17.8870s	
26867/29850 (epoch 45.003), train_loss = 0.62508974, grad/param norm = 2.2541e-01, time/batch = 16.5386s	
26868/29850 (epoch 45.005), train_loss = 0.80786851, grad/param norm = 2.0916e-01, time/batch = 17.3592s	
26869/29850 (epoch 45.007), train_loss = 0.85592529, grad/param norm = 2.7443e-01, time/batch = 17.1320s	
26870/29850 (epoch 45.008), train_loss = 0.95900260, grad/param norm = 3.0445e-01, time/batch = 17.0620s	
26871/29850 (epoch 45.010), train_loss = 0.69706801, grad/param norm = 2.3309e-01, time/batch = 17.2962s	
26872/29850 (epoch 45.012), train_loss = 0.75878311, grad/param norm = 2.5594e-01, time/batch = 18.3866s	
26873/29850 (epoch 45.013), train_loss = 0.76197998, grad/param norm = 2.6714e-01, time/batch = 16.8760s	
26874/29850 (epoch 45.015), train_loss = 0.84965134, grad/param norm = 2.4788e-01, time/batch = 15.9440s	
26875/29850 (epoch 45.017), train_loss = 0.80311544, grad/param norm = 2.4976e-01, time/batch = 18.3916s	
26876/29850 (epoch 45.018), train_loss = 0.88364187, grad/param norm = 2.5012e-01, time/batch = 17.8707s	
26877/29850 (epoch 45.020), train_loss = 0.77796159, grad/param norm = 2.3483e-01, time/batch = 17.6183s	
26878/29850 (epoch 45.022), train_loss = 0.86871153, grad/param norm = 2.9085e-01, time/batch = 17.6129s	
26879/29850 (epoch 45.023), train_loss = 0.83611491, grad/param norm = 1.9898e-01, time/batch = 17.6309s	
26880/29850 (epoch 45.025), train_loss = 0.76184314, grad/param norm = 2.1271e-01, time/batch = 18.1395s	
26881/29850 (epoch 45.027), train_loss = 0.56686646, grad/param norm = 2.0166e-01, time/batch = 17.7888s	
26882/29850 (epoch 45.028), train_loss = 0.70628203, grad/param norm = 2.0062e-01, time/batch = 18.8833s	
26883/29850 (epoch 45.030), train_loss = 0.70789376, grad/param norm = 2.3698e-01, time/batch = 15.8551s	
26884/29850 (epoch 45.032), train_loss = 0.81142968, grad/param norm = 2.3342e-01, time/batch = 17.6212s	
26885/29850 (epoch 45.034), train_loss = 0.70493538, grad/param norm = 2.1149e-01, time/batch = 17.9405s	
26886/29850 (epoch 45.035), train_loss = 0.60541955, grad/param norm = 2.1279e-01, time/batch = 17.8045s	
26887/29850 (epoch 45.037), train_loss = 0.74264431, grad/param norm = 2.2084e-01, time/batch = 18.5436s	
26888/29850 (epoch 45.039), train_loss = 0.68058911, grad/param norm = 1.9440e-01, time/batch = 15.7905s	
26889/29850 (epoch 45.040), train_loss = 0.63027478, grad/param norm = 2.0374e-01, time/batch = 19.0452s	
26890/29850 (epoch 45.042), train_loss = 0.68113758, grad/param norm = 2.3536e-01, time/batch = 19.0390s	
26891/29850 (epoch 45.044), train_loss = 0.73372025, grad/param norm = 1.9555e-01, time/batch = 15.7599s	
26892/29850 (epoch 45.045), train_loss = 0.80797649, grad/param norm = 2.2759e-01, time/batch = 18.2920s	
26893/29850 (epoch 45.047), train_loss = 0.65430618, grad/param norm = 2.1267e-01, time/batch = 18.2740s	
26894/29850 (epoch 45.049), train_loss = 0.78791860, grad/param norm = 2.5612e-01, time/batch = 18.1991s	
26895/29850 (epoch 45.050), train_loss = 0.71796812, grad/param norm = 2.2097e-01, time/batch = 18.7932s	
26896/29850 (epoch 45.052), train_loss = 0.85192089, grad/param norm = 2.3036e-01, time/batch = 15.3187s	
26897/29850 (epoch 45.054), train_loss = 0.74991419, grad/param norm = 2.4613e-01, time/batch = 18.1260s	
26898/29850 (epoch 45.055), train_loss = 0.73987414, grad/param norm = 2.4722e-01, time/batch = 16.6184s	
26899/29850 (epoch 45.057), train_loss = 0.81802945, grad/param norm = 2.1469e-01, time/batch = 19.7003s	
26900/29850 (epoch 45.059), train_loss = 0.80789412, grad/param norm = 2.3596e-01, time/batch = 19.6341s	
26901/29850 (epoch 45.060), train_loss = 0.77873161, grad/param norm = 2.2727e-01, time/batch = 16.8781s	
26902/29850 (epoch 45.062), train_loss = 0.84656475, grad/param norm = 2.4803e-01, time/batch = 16.1933s	
26903/29850 (epoch 45.064), train_loss = 0.86095328, grad/param norm = 2.6255e-01, time/batch = 15.8871s	
26904/29850 (epoch 45.065), train_loss = 0.65551197, grad/param norm = 2.4217e-01, time/batch = 18.1310s	
26905/29850 (epoch 45.067), train_loss = 0.81945640, grad/param norm = 2.1334e-01, time/batch = 17.5384s	
26906/29850 (epoch 45.069), train_loss = 0.80439162, grad/param norm = 2.1245e-01, time/batch = 18.2142s	
26907/29850 (epoch 45.070), train_loss = 0.83258130, grad/param norm = 2.2683e-01, time/batch = 19.1319s	
26908/29850 (epoch 45.072), train_loss = 0.77261420, grad/param norm = 2.1912e-01, time/batch = 17.3743s	
26909/29850 (epoch 45.074), train_loss = 0.83961851, grad/param norm = 2.0418e-01, time/batch = 19.4461s	
26910/29850 (epoch 45.075), train_loss = 0.70916083, grad/param norm = 2.4964e-01, time/batch = 17.6920s	
26911/29850 (epoch 45.077), train_loss = 0.82628495, grad/param norm = 2.3591e-01, time/batch = 18.6136s	
26912/29850 (epoch 45.079), train_loss = 0.95854561, grad/param norm = 3.7742e-01, time/batch = 16.3005s	
26913/29850 (epoch 45.080), train_loss = 0.94851455, grad/param norm = 2.9326e-01, time/batch = 16.6038s	
26914/29850 (epoch 45.082), train_loss = 0.83184472, grad/param norm = 2.7519e-01, time/batch = 19.1282s	
26915/29850 (epoch 45.084), train_loss = 0.93270557, grad/param norm = 2.4696e-01, time/batch = 18.6113s	
26916/29850 (epoch 45.085), train_loss = 0.95661925, grad/param norm = 2.3971e-01, time/batch = 17.9730s	
26917/29850 (epoch 45.087), train_loss = 0.89149983, grad/param norm = 2.5185e-01, time/batch = 18.6280s	
26918/29850 (epoch 45.089), train_loss = 0.82193625, grad/param norm = 2.1269e-01, time/batch = 16.0176s	
26919/29850 (epoch 45.090), train_loss = 0.81580776, grad/param norm = 2.4480e-01, time/batch = 19.0416s	
26920/29850 (epoch 45.092), train_loss = 0.71623571, grad/param norm = 2.3494e-01, time/batch = 16.7323s	
26921/29850 (epoch 45.094), train_loss = 0.89290654, grad/param norm = 2.4851e-01, time/batch = 17.6076s	
26922/29850 (epoch 45.095), train_loss = 0.87985174, grad/param norm = 3.2089e-01, time/batch = 17.9427s	
26923/29850 (epoch 45.097), train_loss = 0.60248557, grad/param norm = 1.8366e-01, time/batch = 15.9307s	
26924/29850 (epoch 45.099), train_loss = 0.63081272, grad/param norm = 1.9346e-01, time/batch = 17.5635s	
26925/29850 (epoch 45.101), train_loss = 0.82881667, grad/param norm = 2.4191e-01, time/batch = 16.5499s	
26926/29850 (epoch 45.102), train_loss = 0.84063350, grad/param norm = 2.3596e-01, time/batch = 19.8755s	
26927/29850 (epoch 45.104), train_loss = 0.73634986, grad/param norm = 2.4214e-01, time/batch = 17.0388s	
26928/29850 (epoch 45.106), train_loss = 0.85428727, grad/param norm = 2.3147e-01, time/batch = 18.2862s	
26929/29850 (epoch 45.107), train_loss = 0.72742170, grad/param norm = 1.8254e-01, time/batch = 17.8865s	
26930/29850 (epoch 45.109), train_loss = 0.78018664, grad/param norm = 2.2316e-01, time/batch = 18.4510s	
26931/29850 (epoch 45.111), train_loss = 0.80168459, grad/param norm = 2.1439e-01, time/batch = 16.8002s	
26932/29850 (epoch 45.112), train_loss = 0.69122014, grad/param norm = 2.0810e-01, time/batch = 17.8627s	
26933/29850 (epoch 45.114), train_loss = 0.70064642, grad/param norm = 2.3115e-01, time/batch = 19.6263s	
26934/29850 (epoch 45.116), train_loss = 0.70808675, grad/param norm = 2.3367e-01, time/batch = 19.1308s	
26935/29850 (epoch 45.117), train_loss = 0.74411631, grad/param norm = 2.2229e-01, time/batch = 15.6576s	
26936/29850 (epoch 45.119), train_loss = 0.72940921, grad/param norm = 2.2133e-01, time/batch = 18.2781s	
26937/29850 (epoch 45.121), train_loss = 0.62482588, grad/param norm = 2.2865e-01, time/batch = 17.9757s	
26938/29850 (epoch 45.122), train_loss = 0.67161852, grad/param norm = 2.0136e-01, time/batch = 17.0616s	
26939/29850 (epoch 45.124), train_loss = 0.69729723, grad/param norm = 1.9667e-01, time/batch = 17.8748s	
26940/29850 (epoch 45.126), train_loss = 0.75406805, grad/param norm = 2.1290e-01, time/batch = 19.8072s	
26941/29850 (epoch 45.127), train_loss = 0.79737082, grad/param norm = 2.5342e-01, time/batch = 17.3541s	
26942/29850 (epoch 45.129), train_loss = 0.78430381, grad/param norm = 2.3623e-01, time/batch = 18.3853s	
26943/29850 (epoch 45.131), train_loss = 0.78857805, grad/param norm = 2.5451e-01, time/batch = 18.2041s	
26944/29850 (epoch 45.132), train_loss = 0.66665254, grad/param norm = 2.3752e-01, time/batch = 17.0457s	
26945/29850 (epoch 45.134), train_loss = 0.76043913, grad/param norm = 2.4965e-01, time/batch = 17.4579s	
26946/29850 (epoch 45.136), train_loss = 0.82373260, grad/param norm = 2.2851e-01, time/batch = 17.6193s	
26947/29850 (epoch 45.137), train_loss = 0.61957002, grad/param norm = 1.8057e-01, time/batch = 16.7249s	
26948/29850 (epoch 45.139), train_loss = 0.76473561, grad/param norm = 2.7374e-01, time/batch = 17.2817s	
26949/29850 (epoch 45.141), train_loss = 0.69385103, grad/param norm = 2.3973e-01, time/batch = 17.1539s	
26950/29850 (epoch 45.142), train_loss = 0.88922369, grad/param norm = 2.7300e-01, time/batch = 19.2122s	
26951/29850 (epoch 45.144), train_loss = 0.97919998, grad/param norm = 2.5215e-01, time/batch = 18.9420s	
26952/29850 (epoch 45.146), train_loss = 0.96688066, grad/param norm = 2.7845e-01, time/batch = 17.1866s	
26953/29850 (epoch 45.147), train_loss = 0.87823511, grad/param norm = 2.8987e-01, time/batch = 17.9680s	
26954/29850 (epoch 45.149), train_loss = 0.82696878, grad/param norm = 2.2722e-01, time/batch = 16.8549s	
26955/29850 (epoch 45.151), train_loss = 0.81653914, grad/param norm = 2.5663e-01, time/batch = 17.0332s	
26956/29850 (epoch 45.152), train_loss = 0.78716943, grad/param norm = 2.2288e-01, time/batch = 19.5297s	
26957/29850 (epoch 45.154), train_loss = 0.72178467, grad/param norm = 2.5230e-01, time/batch = 15.3736s	
26958/29850 (epoch 45.156), train_loss = 0.72107194, grad/param norm = 2.7912e-01, time/batch = 18.1286s	
26959/29850 (epoch 45.157), train_loss = 0.82747579, grad/param norm = 2.3118e-01, time/batch = 18.2198s	
26960/29850 (epoch 45.159), train_loss = 0.73253110, grad/param norm = 2.0366e-01, time/batch = 17.8883s	
26961/29850 (epoch 45.161), train_loss = 0.74927687, grad/param norm = 2.3487e-01, time/batch = 18.8488s	
26962/29850 (epoch 45.162), train_loss = 0.89944718, grad/param norm = 2.5683e-01, time/batch = 16.3644s	
26963/29850 (epoch 45.164), train_loss = 0.82527961, grad/param norm = 2.3929e-01, time/batch = 19.3674s	
26964/29850 (epoch 45.166), train_loss = 0.73167956, grad/param norm = 2.2193e-01, time/batch = 18.5379s	
26965/29850 (epoch 45.168), train_loss = 0.69655145, grad/param norm = 2.1328e-01, time/batch = 16.6333s	
26966/29850 (epoch 45.169), train_loss = 0.89412427, grad/param norm = 3.1323e-01, time/batch = 18.4552s	
26967/29850 (epoch 45.171), train_loss = 0.86670222, grad/param norm = 2.6221e-01, time/batch = 18.3917s	
26968/29850 (epoch 45.173), train_loss = 0.67404966, grad/param norm = 2.2660e-01, time/batch = 22.5341s	
26969/29850 (epoch 45.174), train_loss = 0.74409207, grad/param norm = 2.6359e-01, time/batch = 26.1253s	
26970/29850 (epoch 45.176), train_loss = 0.80594504, grad/param norm = 2.0288e-01, time/batch = 17.1349s	
26971/29850 (epoch 45.178), train_loss = 0.81928859, grad/param norm = 2.3396e-01, time/batch = 17.3004s	
26972/29850 (epoch 45.179), train_loss = 0.63997109, grad/param norm = 2.2423e-01, time/batch = 19.5414s	
26973/29850 (epoch 45.181), train_loss = 0.79539558, grad/param norm = 2.5986e-01, time/batch = 19.1189s	
26974/29850 (epoch 45.183), train_loss = 0.79129093, grad/param norm = 2.1382e-01, time/batch = 15.3314s	
26975/29850 (epoch 45.184), train_loss = 0.87869279, grad/param norm = 2.8284e-01, time/batch = 17.9428s	
26976/29850 (epoch 45.186), train_loss = 0.84903388, grad/param norm = 2.7437e-01, time/batch = 16.9736s	
26977/29850 (epoch 45.188), train_loss = 0.91871839, grad/param norm = 2.5588e-01, time/batch = 17.5707s	
26978/29850 (epoch 45.189), train_loss = 0.83119484, grad/param norm = 2.6318e-01, time/batch = 17.3916s	
26979/29850 (epoch 45.191), train_loss = 0.87375240, grad/param norm = 2.3930e-01, time/batch = 17.8222s	
26980/29850 (epoch 45.193), train_loss = 0.78137973, grad/param norm = 2.2975e-01, time/batch = 16.1441s	
26981/29850 (epoch 45.194), train_loss = 0.88956349, grad/param norm = 2.4493e-01, time/batch = 17.6249s	
26982/29850 (epoch 45.196), train_loss = 0.74968703, grad/param norm = 2.0454e-01, time/batch = 17.1899s	
26983/29850 (epoch 45.198), train_loss = 0.69384153, grad/param norm = 2.0762e-01, time/batch = 19.2826s	
26984/29850 (epoch 45.199), train_loss = 0.97499586, grad/param norm = 2.7010e-01, time/batch = 17.8605s	
26985/29850 (epoch 45.201), train_loss = 0.71404613, grad/param norm = 2.1781e-01, time/batch = 15.8024s	
26986/29850 (epoch 45.203), train_loss = 0.57531987, grad/param norm = 2.4608e-01, time/batch = 18.3785s	
26987/29850 (epoch 45.204), train_loss = 0.75950222, grad/param norm = 2.7224e-01, time/batch = 17.2185s	
26988/29850 (epoch 45.206), train_loss = 0.69228445, grad/param norm = 2.4581e-01, time/batch = 15.6380s	
26989/29850 (epoch 45.208), train_loss = 0.87274528, grad/param norm = 2.3127e-01, time/batch = 17.9803s	
26990/29850 (epoch 45.209), train_loss = 0.67978173, grad/param norm = 2.6245e-01, time/batch = 19.4612s	
26991/29850 (epoch 45.211), train_loss = 0.74535682, grad/param norm = 2.1954e-01, time/batch = 17.5385s	
26992/29850 (epoch 45.213), train_loss = 0.82457225, grad/param norm = 2.7423e-01, time/batch = 18.0502s	
26993/29850 (epoch 45.214), train_loss = 0.65769371, grad/param norm = 1.9822e-01, time/batch = 19.1251s	
26994/29850 (epoch 45.216), train_loss = 0.66797163, grad/param norm = 2.0126e-01, time/batch = 17.8599s	
26995/29850 (epoch 45.218), train_loss = 0.79627179, grad/param norm = 2.0273e-01, time/batch = 17.6200s	
26996/29850 (epoch 45.219), train_loss = 0.76287288, grad/param norm = 2.4123e-01, time/batch = 16.7292s	
26997/29850 (epoch 45.221), train_loss = 0.78125429, grad/param norm = 2.4511e-01, time/batch = 18.1104s	
26998/29850 (epoch 45.223), train_loss = 0.61613567, grad/param norm = 1.9818e-01, time/batch = 15.8688s	
26999/29850 (epoch 45.224), train_loss = 0.62773206, grad/param norm = 2.0223e-01, time/batch = 16.4409s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch45.23_1.9216.t7	
27000/29850 (epoch 45.226), train_loss = 0.69063985, grad/param norm = 2.1363e-01, time/batch = 18.2840s	
27001/29850 (epoch 45.228), train_loss = 1.41844839, grad/param norm = 2.9779e-01, time/batch = 16.3515s	
27002/29850 (epoch 45.229), train_loss = 0.63780222, grad/param norm = 2.1388e-01, time/batch = 19.4518s	
27003/29850 (epoch 45.231), train_loss = 0.78311736, grad/param norm = 2.2596e-01, time/batch = 17.0395s	
27004/29850 (epoch 45.233), train_loss = 0.74304533, grad/param norm = 2.2570e-01, time/batch = 17.6969s	
27005/29850 (epoch 45.235), train_loss = 0.69562445, grad/param norm = 2.3746e-01, time/batch = 18.4548s	
27006/29850 (epoch 45.236), train_loss = 0.90806536, grad/param norm = 3.9509e-01, time/batch = 18.1330s	
27007/29850 (epoch 45.238), train_loss = 0.66846199, grad/param norm = 2.4717e-01, time/batch = 15.9395s	
27008/29850 (epoch 45.240), train_loss = 0.67946840, grad/param norm = 2.3356e-01, time/batch = 18.5380s	
27009/29850 (epoch 45.241), train_loss = 0.79611889, grad/param norm = 2.7009e-01, time/batch = 17.3848s	
27010/29850 (epoch 45.243), train_loss = 0.82989832, grad/param norm = 2.6491e-01, time/batch = 19.2075s	
27011/29850 (epoch 45.245), train_loss = 0.67978760, grad/param norm = 2.2550e-01, time/batch = 15.5297s	
27012/29850 (epoch 45.246), train_loss = 0.68944723, grad/param norm = 2.1177e-01, time/batch = 19.9580s	
27013/29850 (epoch 45.248), train_loss = 0.64722781, grad/param norm = 2.0407e-01, time/batch = 18.6310s	
27014/29850 (epoch 45.250), train_loss = 0.72551294, grad/param norm = 2.1760e-01, time/batch = 16.5421s	
27015/29850 (epoch 45.251), train_loss = 0.62156471, grad/param norm = 2.2015e-01, time/batch = 18.8845s	
27016/29850 (epoch 45.253), train_loss = 0.62401838, grad/param norm = 2.3790e-01, time/batch = 19.1125s	
27017/29850 (epoch 45.255), train_loss = 0.67506113, grad/param norm = 2.3327e-01, time/batch = 17.9522s	
27018/29850 (epoch 45.256), train_loss = 0.80023159, grad/param norm = 2.4727e-01, time/batch = 18.1199s	
27019/29850 (epoch 45.258), train_loss = 0.80118675, grad/param norm = 2.3886e-01, time/batch = 17.8593s	
27020/29850 (epoch 45.260), train_loss = 0.72821135, grad/param norm = 1.9454e-01, time/batch = 17.8680s	
27021/29850 (epoch 45.261), train_loss = 0.67681975, grad/param norm = 2.2018e-01, time/batch = 16.7947s	
27022/29850 (epoch 45.263), train_loss = 0.68717390, grad/param norm = 2.0523e-01, time/batch = 18.8532s	
27023/29850 (epoch 45.265), train_loss = 0.73291235, grad/param norm = 2.3644e-01, time/batch = 18.5281s	
27024/29850 (epoch 45.266), train_loss = 0.74508070, grad/param norm = 2.1203e-01, time/batch = 16.1910s	
27025/29850 (epoch 45.268), train_loss = 0.71211231, grad/param norm = 1.8832e-01, time/batch = 18.1026s	
27026/29850 (epoch 45.270), train_loss = 0.67670079, grad/param norm = 2.1476e-01, time/batch = 17.3912s	
27027/29850 (epoch 45.271), train_loss = 0.77141287, grad/param norm = 2.1899e-01, time/batch = 18.2779s	
27028/29850 (epoch 45.273), train_loss = 0.64043821, grad/param norm = 2.1810e-01, time/batch = 16.9638s	
27029/29850 (epoch 45.275), train_loss = 0.64553785, grad/param norm = 2.0474e-01, time/batch = 17.2919s	
27030/29850 (epoch 45.276), train_loss = 0.64928029, grad/param norm = 1.9186e-01, time/batch = 14.7496s	
27031/29850 (epoch 45.278), train_loss = 0.70792182, grad/param norm = 2.2588e-01, time/batch = 17.3761s	
27032/29850 (epoch 45.280), train_loss = 0.90342812, grad/param norm = 3.3124e-01, time/batch = 17.3840s	
27033/29850 (epoch 45.281), train_loss = 0.77730711, grad/param norm = 2.2505e-01, time/batch = 17.6303s	
27034/29850 (epoch 45.283), train_loss = 0.84368829, grad/param norm = 2.7887e-01, time/batch = 18.1194s	
27035/29850 (epoch 45.285), train_loss = 0.82695161, grad/param norm = 2.2165e-01, time/batch = 19.4531s	
27036/29850 (epoch 45.286), train_loss = 0.87875741, grad/param norm = 2.6690e-01, time/batch = 18.9674s	
27037/29850 (epoch 45.288), train_loss = 0.77269028, grad/param norm = 2.7906e-01, time/batch = 17.3358s	
27038/29850 (epoch 45.290), train_loss = 0.76828959, grad/param norm = 2.4011e-01, time/batch = 17.3692s	
27039/29850 (epoch 45.291), train_loss = 0.98023366, grad/param norm = 2.5531e-01, time/batch = 19.7829s	
27040/29850 (epoch 45.293), train_loss = 0.91361089, grad/param norm = 2.6414e-01, time/batch = 17.8007s	
27041/29850 (epoch 45.295), train_loss = 0.95682078, grad/param norm = 2.5483e-01, time/batch = 15.8530s	
27042/29850 (epoch 45.296), train_loss = 0.71467861, grad/param norm = 2.0157e-01, time/batch = 19.5445s	
27043/29850 (epoch 45.298), train_loss = 0.60389558, grad/param norm = 2.0963e-01, time/batch = 18.9573s	
27044/29850 (epoch 45.300), train_loss = 0.66232636, grad/param norm = 2.1462e-01, time/batch = 17.6137s	
27045/29850 (epoch 45.302), train_loss = 0.68474216, grad/param norm = 2.9593e-01, time/batch = 19.7725s	
27046/29850 (epoch 45.303), train_loss = 0.72700885, grad/param norm = 2.6318e-01, time/batch = 16.6209s	
27047/29850 (epoch 45.305), train_loss = 0.85055431, grad/param norm = 2.1674e-01, time/batch = 17.4518s	
27048/29850 (epoch 45.307), train_loss = 0.82773856, grad/param norm = 2.1662e-01, time/batch = 16.7099s	
27049/29850 (epoch 45.308), train_loss = 0.64426296, grad/param norm = 2.1840e-01, time/batch = 19.7063s	
27050/29850 (epoch 45.310), train_loss = 0.81780861, grad/param norm = 2.2293e-01, time/batch = 18.6150s	
27051/29850 (epoch 45.312), train_loss = 0.85778574, grad/param norm = 2.0801e-01, time/batch = 17.3548s	
27052/29850 (epoch 45.313), train_loss = 0.79244243, grad/param norm = 2.8208e-01, time/batch = 19.4515s	
27053/29850 (epoch 45.315), train_loss = 0.81382836, grad/param norm = 2.4525e-01, time/batch = 16.5322s	
27054/29850 (epoch 45.317), train_loss = 0.76527946, grad/param norm = 2.1896e-01, time/batch = 17.1234s	
27055/29850 (epoch 45.318), train_loss = 0.74073392, grad/param norm = 2.2941e-01, time/batch = 17.9731s	
27056/29850 (epoch 45.320), train_loss = 0.72698904, grad/param norm = 2.2105e-01, time/batch = 17.1353s	
27057/29850 (epoch 45.322), train_loss = 0.85132028, grad/param norm = 2.5145e-01, time/batch = 17.5594s	
27058/29850 (epoch 45.323), train_loss = 0.80205511, grad/param norm = 2.5963e-01, time/batch = 17.4494s	
27059/29850 (epoch 45.325), train_loss = 0.83673673, grad/param norm = 2.1262e-01, time/batch = 18.7123s	
27060/29850 (epoch 45.327), train_loss = 0.96140196, grad/param norm = 2.5029e-01, time/batch = 17.8899s	
27061/29850 (epoch 45.328), train_loss = 0.88039061, grad/param norm = 2.7734e-01, time/batch = 15.8566s	
27062/29850 (epoch 45.330), train_loss = 0.85283977, grad/param norm = 2.4181e-01, time/batch = 17.6376s	
27063/29850 (epoch 45.332), train_loss = 0.79951302, grad/param norm = 2.6145e-01, time/batch = 18.2199s	
27064/29850 (epoch 45.333), train_loss = 0.81663509, grad/param norm = 2.3276e-01, time/batch = 18.1315s	
27065/29850 (epoch 45.335), train_loss = 0.89009806, grad/param norm = 2.5079e-01, time/batch = 16.4639s	
27066/29850 (epoch 45.337), train_loss = 0.78694194, grad/param norm = 2.5313e-01, time/batch = 18.3869s	
27067/29850 (epoch 45.338), train_loss = 0.84622669, grad/param norm = 2.0882e-01, time/batch = 18.3905s	
27068/29850 (epoch 45.340), train_loss = 0.67700783, grad/param norm = 2.0424e-01, time/batch = 17.4466s	
27069/29850 (epoch 45.342), train_loss = 0.80331798, grad/param norm = 2.8380e-01, time/batch = 17.0529s	
27070/29850 (epoch 45.343), train_loss = 0.77096135, grad/param norm = 2.5135e-01, time/batch = 16.9614s	
27071/29850 (epoch 45.345), train_loss = 0.85369066, grad/param norm = 2.7759e-01, time/batch = 16.0908s	
27072/29850 (epoch 45.347), train_loss = 0.84562316, grad/param norm = 2.4379e-01, time/batch = 19.0365s	
27073/29850 (epoch 45.348), train_loss = 0.72936664, grad/param norm = 2.2217e-01, time/batch = 17.1486s	
27074/29850 (epoch 45.350), train_loss = 0.81085397, grad/param norm = 2.3892e-01, time/batch = 18.2069s	
27075/29850 (epoch 45.352), train_loss = 0.74594556, grad/param norm = 2.1419e-01, time/batch = 17.4439s	
27076/29850 (epoch 45.353), train_loss = 0.80363699, grad/param norm = 2.3056e-01, time/batch = 18.3844s	
27077/29850 (epoch 45.355), train_loss = 0.71484000, grad/param norm = 2.2883e-01, time/batch = 19.2116s	
27078/29850 (epoch 45.357), train_loss = 0.87666072, grad/param norm = 2.2084e-01, time/batch = 13.3087s	
27079/29850 (epoch 45.358), train_loss = 0.71186672, grad/param norm = 2.2559e-01, time/batch = 0.6617s	
27080/29850 (epoch 45.360), train_loss = 0.76193546, grad/param norm = 2.2404e-01, time/batch = 0.6588s	
27081/29850 (epoch 45.362), train_loss = 0.78429786, grad/param norm = 2.4957e-01, time/batch = 0.6581s	
27082/29850 (epoch 45.363), train_loss = 0.82622956, grad/param norm = 2.7199e-01, time/batch = 0.6608s	
27083/29850 (epoch 45.365), train_loss = 0.89013548, grad/param norm = 2.7809e-01, time/batch = 0.6716s	
27084/29850 (epoch 45.367), train_loss = 0.70791104, grad/param norm = 2.2368e-01, time/batch = 0.6637s	
27085/29850 (epoch 45.369), train_loss = 0.61992016, grad/param norm = 2.4537e-01, time/batch = 0.6614s	
27086/29850 (epoch 45.370), train_loss = 0.65529507, grad/param norm = 2.4124e-01, time/batch = 0.8932s	
27087/29850 (epoch 45.372), train_loss = 0.86087646, grad/param norm = 2.2629e-01, time/batch = 0.9909s	
27088/29850 (epoch 45.374), train_loss = 0.85638533, grad/param norm = 2.3782e-01, time/batch = 0.9895s	
27089/29850 (epoch 45.375), train_loss = 0.81747905, grad/param norm = 2.7336e-01, time/batch = 0.9720s	
27090/29850 (epoch 45.377), train_loss = 0.66833807, grad/param norm = 2.0198e-01, time/batch = 0.9847s	
27091/29850 (epoch 45.379), train_loss = 0.88254829, grad/param norm = 2.3655e-01, time/batch = 1.5425s	
27092/29850 (epoch 45.380), train_loss = 0.81926217, grad/param norm = 2.3572e-01, time/batch = 1.7847s	
27093/29850 (epoch 45.382), train_loss = 0.80647451, grad/param norm = 2.5438e-01, time/batch = 1.7923s	
27094/29850 (epoch 45.384), train_loss = 0.83977372, grad/param norm = 2.6380e-01, time/batch = 14.4197s	
27095/29850 (epoch 45.385), train_loss = 0.82317134, grad/param norm = 2.5902e-01, time/batch = 15.5218s	
27096/29850 (epoch 45.387), train_loss = 0.80296306, grad/param norm = 2.6355e-01, time/batch = 16.9631s	
27097/29850 (epoch 45.389), train_loss = 0.89297322, grad/param norm = 2.6282e-01, time/batch = 18.8711s	
27098/29850 (epoch 45.390), train_loss = 0.85633546, grad/param norm = 2.3733e-01, time/batch = 19.0402s	
27099/29850 (epoch 45.392), train_loss = 0.79923264, grad/param norm = 2.5429e-01, time/batch = 17.9529s	
27100/29850 (epoch 45.394), train_loss = 0.83140896, grad/param norm = 2.2881e-01, time/batch = 19.9630s	
27101/29850 (epoch 45.395), train_loss = 0.74796807, grad/param norm = 2.6970e-01, time/batch = 17.4458s	
27102/29850 (epoch 45.397), train_loss = 0.68295729, grad/param norm = 2.5403e-01, time/batch = 18.2771s	
27103/29850 (epoch 45.399), train_loss = 0.71456340, grad/param norm = 2.2512e-01, time/batch = 17.4709s	
27104/29850 (epoch 45.400), train_loss = 1.06197120, grad/param norm = 2.6781e-01, time/batch = 17.4461s	
27105/29850 (epoch 45.402), train_loss = 0.88404666, grad/param norm = 2.3034e-01, time/batch = 18.7867s	
27106/29850 (epoch 45.404), train_loss = 0.78484085, grad/param norm = 2.2386e-01, time/batch = 16.4568s	
27107/29850 (epoch 45.405), train_loss = 0.73484708, grad/param norm = 3.0030e-01, time/batch = 19.7918s	
27108/29850 (epoch 45.407), train_loss = 0.71543798, grad/param norm = 2.2401e-01, time/batch = 17.8846s	
27109/29850 (epoch 45.409), train_loss = 0.79704074, grad/param norm = 2.5660e-01, time/batch = 16.6900s	
27110/29850 (epoch 45.410), train_loss = 0.86833222, grad/param norm = 2.4179e-01, time/batch = 17.7179s	
27111/29850 (epoch 45.412), train_loss = 0.89416618, grad/param norm = 3.2443e-01, time/batch = 17.4701s	
27112/29850 (epoch 45.414), train_loss = 0.81699540, grad/param norm = 2.4637e-01, time/batch = 17.9456s	
27113/29850 (epoch 45.415), train_loss = 0.78009950, grad/param norm = 2.1889e-01, time/batch = 16.7001s	
27114/29850 (epoch 45.417), train_loss = 0.89052100, grad/param norm = 2.5214e-01, time/batch = 16.3771s	
27115/29850 (epoch 45.419), train_loss = 0.76271077, grad/param norm = 2.2525e-01, time/batch = 17.5334s	
27116/29850 (epoch 45.420), train_loss = 0.77245938, grad/param norm = 2.4400e-01, time/batch = 17.7911s	
27117/29850 (epoch 45.422), train_loss = 0.77031163, grad/param norm = 2.1062e-01, time/batch = 17.7082s	
27118/29850 (epoch 45.424), train_loss = 0.67716736, grad/param norm = 2.2155e-01, time/batch = 18.2037s	
27119/29850 (epoch 45.425), train_loss = 0.84376152, grad/param norm = 2.6943e-01, time/batch = 17.6118s	
27120/29850 (epoch 45.427), train_loss = 0.59343410, grad/param norm = 2.1290e-01, time/batch = 15.4843s	
27121/29850 (epoch 45.429), train_loss = 0.68380644, grad/param norm = 2.4683e-01, time/batch = 18.1454s	
27122/29850 (epoch 45.430), train_loss = 0.64170017, grad/param norm = 1.9832e-01, time/batch = 17.0546s	
27123/29850 (epoch 45.432), train_loss = 0.76312939, grad/param norm = 2.5846e-01, time/batch = 15.8693s	
27124/29850 (epoch 45.434), train_loss = 0.72452712, grad/param norm = 2.0146e-01, time/batch = 17.7020s	
27125/29850 (epoch 45.436), train_loss = 0.75367102, grad/param norm = 2.5641e-01, time/batch = 17.2922s	
27126/29850 (epoch 45.437), train_loss = 0.84161477, grad/param norm = 1.9809e-01, time/batch = 17.6981s	
27127/29850 (epoch 45.439), train_loss = 0.84752716, grad/param norm = 2.4032e-01, time/batch = 14.9054s	
27128/29850 (epoch 45.441), train_loss = 0.76202542, grad/param norm = 2.3521e-01, time/batch = 16.0411s	
27129/29850 (epoch 45.442), train_loss = 0.75958860, grad/param norm = 2.3761e-01, time/batch = 17.0544s	
27130/29850 (epoch 45.444), train_loss = 0.80012578, grad/param norm = 2.5833e-01, time/batch = 17.2656s	
27131/29850 (epoch 45.446), train_loss = 0.86853383, grad/param norm = 2.4267e-01, time/batch = 17.0641s	
27132/29850 (epoch 45.447), train_loss = 0.88802713, grad/param norm = 2.9165e-01, time/batch = 17.2104s	
27133/29850 (epoch 45.449), train_loss = 0.79959492, grad/param norm = 2.4151e-01, time/batch = 18.0559s	
27134/29850 (epoch 45.451), train_loss = 0.63129780, grad/param norm = 2.1553e-01, time/batch = 17.8938s	
27135/29850 (epoch 45.452), train_loss = 0.53318707, grad/param norm = 2.0163e-01, time/batch = 19.1263s	
27136/29850 (epoch 45.454), train_loss = 0.65587554, grad/param norm = 2.0625e-01, time/batch = 17.0253s	
27137/29850 (epoch 45.456), train_loss = 0.84884881, grad/param norm = 2.5090e-01, time/batch = 18.6025s	
27138/29850 (epoch 45.457), train_loss = 0.88103092, grad/param norm = 4.9498e-01, time/batch = 17.8056s	
27139/29850 (epoch 45.459), train_loss = 0.92066377, grad/param norm = 2.6780e-01, time/batch = 19.4521s	
27140/29850 (epoch 45.461), train_loss = 0.93151923, grad/param norm = 2.6398e-01, time/batch = 16.7889s	
27141/29850 (epoch 45.462), train_loss = 0.95118799, grad/param norm = 2.7946e-01, time/batch = 18.2910s	
27142/29850 (epoch 45.464), train_loss = 0.83195830, grad/param norm = 2.2301e-01, time/batch = 18.9657s	
27143/29850 (epoch 45.466), train_loss = 0.68908472, grad/param norm = 2.4416e-01, time/batch = 17.3546s	
27144/29850 (epoch 45.467), train_loss = 0.72469400, grad/param norm = 2.3714e-01, time/batch = 19.8468s	
27145/29850 (epoch 45.469), train_loss = 0.75865405, grad/param norm = 2.2116e-01, time/batch = 15.9404s	
27146/29850 (epoch 45.471), train_loss = 0.75767791, grad/param norm = 2.4506e-01, time/batch = 17.2100s	
27147/29850 (epoch 45.472), train_loss = 0.72586074, grad/param norm = 2.0218e-01, time/batch = 16.7794s	
27148/29850 (epoch 45.474), train_loss = 0.84704920, grad/param norm = 2.3589e-01, time/batch = 19.2993s	
27149/29850 (epoch 45.476), train_loss = 0.79860399, grad/param norm = 2.1728e-01, time/batch = 19.8782s	
27150/29850 (epoch 45.477), train_loss = 0.82468242, grad/param norm = 3.0510e-01, time/batch = 15.6834s	
27151/29850 (epoch 45.479), train_loss = 0.94387497, grad/param norm = 2.4587e-01, time/batch = 19.0523s	
27152/29850 (epoch 45.481), train_loss = 0.80741541, grad/param norm = 2.5883e-01, time/batch = 17.1245s	
27153/29850 (epoch 45.482), train_loss = 0.71080136, grad/param norm = 1.9009e-01, time/batch = 17.9409s	
27154/29850 (epoch 45.484), train_loss = 0.74802106, grad/param norm = 2.0770e-01, time/batch = 18.2823s	
27155/29850 (epoch 45.486), train_loss = 0.81172919, grad/param norm = 2.5729e-01, time/batch = 15.9089s	
27156/29850 (epoch 45.487), train_loss = 0.77785952, grad/param norm = 2.3615e-01, time/batch = 18.9556s	
27157/29850 (epoch 45.489), train_loss = 0.79330339, grad/param norm = 2.5810e-01, time/batch = 18.5180s	
27158/29850 (epoch 45.491), train_loss = 0.69914782, grad/param norm = 2.0338e-01, time/batch = 19.1241s	
27159/29850 (epoch 45.492), train_loss = 0.77815838, grad/param norm = 2.4452e-01, time/batch = 17.5613s	
27160/29850 (epoch 45.494), train_loss = 0.84140308, grad/param norm = 2.3039e-01, time/batch = 16.4575s	
27161/29850 (epoch 45.496), train_loss = 0.90721562, grad/param norm = 2.3003e-01, time/batch = 18.6338s	
27162/29850 (epoch 45.497), train_loss = 0.79448122, grad/param norm = 2.0408e-01, time/batch = 18.0493s	
27163/29850 (epoch 45.499), train_loss = 0.79932102, grad/param norm = 2.5421e-01, time/batch = 17.2913s	
27164/29850 (epoch 45.501), train_loss = 0.68422218, grad/param norm = 3.7404e-01, time/batch = 18.3929s	
27165/29850 (epoch 45.503), train_loss = 0.89719951, grad/param norm = 2.6651e-01, time/batch = 16.5330s	
27166/29850 (epoch 45.504), train_loss = 1.03447271, grad/param norm = 2.6367e-01, time/batch = 19.9428s	
27167/29850 (epoch 45.506), train_loss = 1.00748460, grad/param norm = 2.9930e-01, time/batch = 15.2637s	
27168/29850 (epoch 45.508), train_loss = 0.83741349, grad/param norm = 2.2037e-01, time/batch = 18.3822s	
27169/29850 (epoch 45.509), train_loss = 0.62402718, grad/param norm = 2.0579e-01, time/batch = 16.2234s	
27170/29850 (epoch 45.511), train_loss = 0.84594708, grad/param norm = 2.5731e-01, time/batch = 16.9802s	
27171/29850 (epoch 45.513), train_loss = 0.77276088, grad/param norm = 2.6323e-01, time/batch = 17.3079s	
27172/29850 (epoch 45.514), train_loss = 0.69912871, grad/param norm = 2.2198e-01, time/batch = 17.8873s	
27173/29850 (epoch 45.516), train_loss = 0.74243430, grad/param norm = 2.0668e-01, time/batch = 18.8536s	
27174/29850 (epoch 45.518), train_loss = 0.62101129, grad/param norm = 1.9321e-01, time/batch = 18.8586s	
27175/29850 (epoch 45.519), train_loss = 0.64841023, grad/param norm = 2.0484e-01, time/batch = 19.1148s	
27176/29850 (epoch 45.521), train_loss = 0.61082370, grad/param norm = 2.0412e-01, time/batch = 16.7291s	
27177/29850 (epoch 45.523), train_loss = 0.65127147, grad/param norm = 2.0972e-01, time/batch = 27.7220s	
27178/29850 (epoch 45.524), train_loss = 0.66419322, grad/param norm = 2.0202e-01, time/batch = 20.3481s	
27179/29850 (epoch 45.526), train_loss = 0.72105741, grad/param norm = 2.6535e-01, time/batch = 16.9579s	
27180/29850 (epoch 45.528), train_loss = 0.82743093, grad/param norm = 2.1859e-01, time/batch = 18.7716s	
27181/29850 (epoch 45.529), train_loss = 0.80258079, grad/param norm = 2.7743e-01, time/batch = 19.5426s	
27182/29850 (epoch 45.531), train_loss = 0.77780798, grad/param norm = 2.8856e-01, time/batch = 16.6488s	
27183/29850 (epoch 45.533), train_loss = 0.79264031, grad/param norm = 2.3905e-01, time/batch = 16.4464s	
27184/29850 (epoch 45.534), train_loss = 0.83327536, grad/param norm = 2.4642e-01, time/batch = 17.6091s	
27185/29850 (epoch 45.536), train_loss = 0.73529731, grad/param norm = 2.6938e-01, time/batch = 16.9715s	
27186/29850 (epoch 45.538), train_loss = 0.91715676, grad/param norm = 2.9939e-01, time/batch = 16.6406s	
27187/29850 (epoch 45.539), train_loss = 0.89361444, grad/param norm = 2.3595e-01, time/batch = 17.6389s	
27188/29850 (epoch 45.541), train_loss = 0.56513429, grad/param norm = 1.9449e-01, time/batch = 18.7887s	
27189/29850 (epoch 45.543), train_loss = 0.73436034, grad/param norm = 2.2981e-01, time/batch = 17.7132s	
27190/29850 (epoch 45.544), train_loss = 0.88641125, grad/param norm = 2.8961e-01, time/batch = 18.2632s	
27191/29850 (epoch 45.546), train_loss = 0.84404455, grad/param norm = 2.3110e-01, time/batch = 18.1990s	
27192/29850 (epoch 45.548), train_loss = 0.64761981, grad/param norm = 2.0000e-01, time/batch = 19.1286s	
27193/29850 (epoch 45.549), train_loss = 0.73816169, grad/param norm = 1.9910e-01, time/batch = 16.3739s	
27194/29850 (epoch 45.551), train_loss = 0.69123905, grad/param norm = 1.8993e-01, time/batch = 19.0663s	
27195/29850 (epoch 45.553), train_loss = 0.78057098, grad/param norm = 2.1969e-01, time/batch = 16.0322s	
27196/29850 (epoch 45.554), train_loss = 0.63589802, grad/param norm = 2.0268e-01, time/batch = 17.2150s	
27197/29850 (epoch 45.556), train_loss = 0.69324317, grad/param norm = 2.5804e-01, time/batch = 18.2754s	
27198/29850 (epoch 45.558), train_loss = 0.71062040, grad/param norm = 3.0960e-01, time/batch = 17.2207s	
27199/29850 (epoch 45.559), train_loss = 0.69459428, grad/param norm = 2.0911e-01, time/batch = 19.6222s	
27200/29850 (epoch 45.561), train_loss = 0.79228695, grad/param norm = 2.7188e-01, time/batch = 16.3512s	
27201/29850 (epoch 45.563), train_loss = 0.80514184, grad/param norm = 2.2480e-01, time/batch = 16.1941s	
27202/29850 (epoch 45.564), train_loss = 0.74811887, grad/param norm = 2.4283e-01, time/batch = 17.4460s	
27203/29850 (epoch 45.566), train_loss = 0.75896132, grad/param norm = 2.1259e-01, time/batch = 17.7006s	
27204/29850 (epoch 45.568), train_loss = 0.91683330, grad/param norm = 2.7691e-01, time/batch = 17.3448s	
27205/29850 (epoch 45.570), train_loss = 0.79493699, grad/param norm = 2.3494e-01, time/batch = 19.8760s	
27206/29850 (epoch 45.571), train_loss = 0.85390132, grad/param norm = 2.2305e-01, time/batch = 17.9627s	
27207/29850 (epoch 45.573), train_loss = 0.90863845, grad/param norm = 2.5798e-01, time/batch = 17.0669s	
27208/29850 (epoch 45.575), train_loss = 0.96513731, grad/param norm = 2.2931e-01, time/batch = 18.5544s	
27209/29850 (epoch 45.576), train_loss = 0.85083864, grad/param norm = 2.4567e-01, time/batch = 19.7961s	
27210/29850 (epoch 45.578), train_loss = 0.72187117, grad/param norm = 2.6051e-01, time/batch = 15.8331s	
27211/29850 (epoch 45.580), train_loss = 0.84210505, grad/param norm = 2.4986e-01, time/batch = 18.0354s	
27212/29850 (epoch 45.581), train_loss = 0.72313508, grad/param norm = 2.6927e-01, time/batch = 17.1251s	
27213/29850 (epoch 45.583), train_loss = 0.78606002, grad/param norm = 2.4723e-01, time/batch = 16.1964s	
27214/29850 (epoch 45.585), train_loss = 0.80722499, grad/param norm = 2.4533e-01, time/batch = 19.1097s	
27215/29850 (epoch 45.586), train_loss = 0.82539891, grad/param norm = 3.1489e-01, time/batch = 16.8832s	
27216/29850 (epoch 45.588), train_loss = 0.71250967, grad/param norm = 2.3017e-01, time/batch = 19.1242s	
27217/29850 (epoch 45.590), train_loss = 0.73060299, grad/param norm = 2.0400e-01, time/batch = 17.4673s	
27218/29850 (epoch 45.591), train_loss = 0.76471391, grad/param norm = 2.4954e-01, time/batch = 19.3748s	
27219/29850 (epoch 45.593), train_loss = 0.69723006, grad/param norm = 2.0335e-01, time/batch = 17.0513s	
27220/29850 (epoch 45.595), train_loss = 0.64569009, grad/param norm = 1.9588e-01, time/batch = 17.1173s	
27221/29850 (epoch 45.596), train_loss = 0.68778348, grad/param norm = 2.4198e-01, time/batch = 19.7717s	
27222/29850 (epoch 45.598), train_loss = 0.74838835, grad/param norm = 2.3332e-01, time/batch = 16.7674s	
27223/29850 (epoch 45.600), train_loss = 0.77869646, grad/param norm = 2.0040e-01, time/batch = 18.8736s	
27224/29850 (epoch 45.601), train_loss = 0.66278686, grad/param norm = 2.0517e-01, time/batch = 19.5282s	
27225/29850 (epoch 45.603), train_loss = 0.71345827, grad/param norm = 2.4650e-01, time/batch = 17.2918s	
27226/29850 (epoch 45.605), train_loss = 0.73035896, grad/param norm = 2.0696e-01, time/batch = 17.2893s	
27227/29850 (epoch 45.606), train_loss = 0.50905655, grad/param norm = 1.8511e-01, time/batch = 18.0338s	
27228/29850 (epoch 45.608), train_loss = 0.65740925, grad/param norm = 2.1946e-01, time/batch = 17.3110s	
27229/29850 (epoch 45.610), train_loss = 0.71334846, grad/param norm = 2.1023e-01, time/batch = 16.9759s	
27230/29850 (epoch 45.611), train_loss = 0.65691156, grad/param norm = 1.9815e-01, time/batch = 15.5320s	
27231/29850 (epoch 45.613), train_loss = 0.57185365, grad/param norm = 1.9873e-01, time/batch = 17.0292s	
27232/29850 (epoch 45.615), train_loss = 0.61701533, grad/param norm = 1.9253e-01, time/batch = 17.3786s	
27233/29850 (epoch 45.616), train_loss = 0.63822872, grad/param norm = 2.2098e-01, time/batch = 17.8792s	
27234/29850 (epoch 45.618), train_loss = 0.69174270, grad/param norm = 2.0765e-01, time/batch = 18.7145s	
27235/29850 (epoch 45.620), train_loss = 0.79875712, grad/param norm = 2.5406e-01, time/batch = 18.3797s	
27236/29850 (epoch 45.621), train_loss = 0.86969614, grad/param norm = 2.7822e-01, time/batch = 18.5167s	
27237/29850 (epoch 45.623), train_loss = 0.86260724, grad/param norm = 2.6673e-01, time/batch = 16.4719s	
27238/29850 (epoch 45.625), train_loss = 0.76030320, grad/param norm = 2.4338e-01, time/batch = 18.5528s	
27239/29850 (epoch 45.626), train_loss = 0.77779991, grad/param norm = 2.2946e-01, time/batch = 18.9682s	
27240/29850 (epoch 45.628), train_loss = 0.76982177, grad/param norm = 2.9644e-01, time/batch = 16.2108s	
27241/29850 (epoch 45.630), train_loss = 0.77875126, grad/param norm = 2.1464e-01, time/batch = 16.4040s	
27242/29850 (epoch 45.631), train_loss = 0.79872581, grad/param norm = 2.3319e-01, time/batch = 17.3033s	
27243/29850 (epoch 45.633), train_loss = 0.80591690, grad/param norm = 2.8679e-01, time/batch = 17.8465s	
27244/29850 (epoch 45.635), train_loss = 0.73927470, grad/param norm = 2.6092e-01, time/batch = 17.0345s	
27245/29850 (epoch 45.637), train_loss = 0.66753049, grad/param norm = 1.9119e-01, time/batch = 18.5320s	
27246/29850 (epoch 45.638), train_loss = 0.79767398, grad/param norm = 2.4574e-01, time/batch = 16.5345s	
27247/29850 (epoch 45.640), train_loss = 0.90392707, grad/param norm = 2.7068e-01, time/batch = 16.0607s	
27248/29850 (epoch 45.642), train_loss = 0.74332863, grad/param norm = 2.0516e-01, time/batch = 18.0481s	
27249/29850 (epoch 45.643), train_loss = 0.68838042, grad/param norm = 2.1731e-01, time/batch = 19.4555s	
27250/29850 (epoch 45.645), train_loss = 0.74010451, grad/param norm = 2.1180e-01, time/batch = 17.1185s	
27251/29850 (epoch 45.647), train_loss = 0.87407647, grad/param norm = 2.7388e-01, time/batch = 18.1352s	
27252/29850 (epoch 45.648), train_loss = 0.66913480, grad/param norm = 2.0062e-01, time/batch = 18.7131s	
27253/29850 (epoch 45.650), train_loss = 0.79880051, grad/param norm = 2.4215e-01, time/batch = 17.1163s	
27254/29850 (epoch 45.652), train_loss = 0.78678509, grad/param norm = 2.8624e-01, time/batch = 18.6248s	
27255/29850 (epoch 45.653), train_loss = 0.85685000, grad/param norm = 3.2486e-01, time/batch = 17.1336s	
27256/29850 (epoch 45.655), train_loss = 0.79593511, grad/param norm = 2.0896e-01, time/batch = 18.8746s	
27257/29850 (epoch 45.657), train_loss = 0.75755435, grad/param norm = 1.9543e-01, time/batch = 17.6205s	
27258/29850 (epoch 45.658), train_loss = 0.87375299, grad/param norm = 2.5666e-01, time/batch = 18.5467s	
27259/29850 (epoch 45.660), train_loss = 0.74841501, grad/param norm = 2.6344e-01, time/batch = 19.1126s	
27260/29850 (epoch 45.662), train_loss = 0.87968197, grad/param norm = 2.7608e-01, time/batch = 16.6339s	
27261/29850 (epoch 45.663), train_loss = 0.98270416, grad/param norm = 2.3896e-01, time/batch = 16.1931s	
27262/29850 (epoch 45.665), train_loss = 0.91277041, grad/param norm = 2.6650e-01, time/batch = 18.0522s	
27263/29850 (epoch 45.667), train_loss = 0.83261119, grad/param norm = 2.6838e-01, time/batch = 18.9550s	
27264/29850 (epoch 45.668), train_loss = 0.71162623, grad/param norm = 2.1959e-01, time/batch = 15.9441s	
27265/29850 (epoch 45.670), train_loss = 0.85116372, grad/param norm = 2.9193e-01, time/batch = 18.4291s	
27266/29850 (epoch 45.672), train_loss = 0.86919775, grad/param norm = 2.6971e-01, time/batch = 19.1267s	
27267/29850 (epoch 45.673), train_loss = 0.79640472, grad/param norm = 2.6345e-01, time/batch = 18.0265s	
27268/29850 (epoch 45.675), train_loss = 0.71091228, grad/param norm = 2.3602e-01, time/batch = 19.1221s	
27269/29850 (epoch 45.677), train_loss = 0.72404578, grad/param norm = 2.0642e-01, time/batch = 16.7934s	
27270/29850 (epoch 45.678), train_loss = 0.77140429, grad/param norm = 2.4177e-01, time/batch = 16.9004s	
27271/29850 (epoch 45.680), train_loss = 0.77308713, grad/param norm = 2.2363e-01, time/batch = 20.1342s	
27272/29850 (epoch 45.682), train_loss = 0.76969288, grad/param norm = 2.3688e-01, time/batch = 17.9688s	
27273/29850 (epoch 45.683), train_loss = 0.87088430, grad/param norm = 2.9944e-01, time/batch = 18.3724s	
27274/29850 (epoch 45.685), train_loss = 0.98062492, grad/param norm = 2.4958e-01, time/batch = 16.8933s	
27275/29850 (epoch 45.687), train_loss = 0.82769301, grad/param norm = 2.4205e-01, time/batch = 17.8112s	
27276/29850 (epoch 45.688), train_loss = 0.69569450, grad/param norm = 2.3072e-01, time/batch = 19.6375s	
27277/29850 (epoch 45.690), train_loss = 0.70341413, grad/param norm = 2.3198e-01, time/batch = 16.3630s	
27278/29850 (epoch 45.692), train_loss = 0.87822351, grad/param norm = 2.4042e-01, time/batch = 19.6330s	
27279/29850 (epoch 45.693), train_loss = 0.77620925, grad/param norm = 2.0075e-01, time/batch = 18.7852s	
27280/29850 (epoch 45.695), train_loss = 0.69440262, grad/param norm = 2.4907e-01, time/batch = 17.5420s	
27281/29850 (epoch 45.697), train_loss = 0.76492365, grad/param norm = 2.1723e-01, time/batch = 19.1112s	
27282/29850 (epoch 45.698), train_loss = 0.89280440, grad/param norm = 2.2030e-01, time/batch = 18.3838s	
27283/29850 (epoch 45.700), train_loss = 0.82569381, grad/param norm = 2.5291e-01, time/batch = 17.6909s	
27284/29850 (epoch 45.702), train_loss = 0.79884104, grad/param norm = 2.9354e-01, time/batch = 17.4530s	
27285/29850 (epoch 45.704), train_loss = 0.67350704, grad/param norm = 2.2740e-01, time/batch = 19.1989s	
27286/29850 (epoch 45.705), train_loss = 0.79240105, grad/param norm = 2.9732e-01, time/batch = 17.0440s	
27287/29850 (epoch 45.707), train_loss = 0.73858651, grad/param norm = 2.3613e-01, time/batch = 16.9449s	
27288/29850 (epoch 45.709), train_loss = 0.76744363, grad/param norm = 2.6335e-01, time/batch = 18.1092s	
27289/29850 (epoch 45.710), train_loss = 0.70762335, grad/param norm = 2.4199e-01, time/batch = 18.2791s	
27290/29850 (epoch 45.712), train_loss = 0.81612070, grad/param norm = 2.1997e-01, time/batch = 17.5460s	
27291/29850 (epoch 45.714), train_loss = 0.84712831, grad/param norm = 2.5169e-01, time/batch = 19.1299s	
27292/29850 (epoch 45.715), train_loss = 0.79631842, grad/param norm = 2.2901e-01, time/batch = 18.0468s	
27293/29850 (epoch 45.717), train_loss = 0.59173393, grad/param norm = 2.1432e-01, time/batch = 15.9644s	
27294/29850 (epoch 45.719), train_loss = 0.75509491, grad/param norm = 2.3471e-01, time/batch = 18.1817s	
27295/29850 (epoch 45.720), train_loss = 0.76258001, grad/param norm = 2.0835e-01, time/batch = 17.7013s	
27296/29850 (epoch 45.722), train_loss = 0.71466954, grad/param norm = 1.9030e-01, time/batch = 17.9460s	
27297/29850 (epoch 45.724), train_loss = 0.80392238, grad/param norm = 2.7423e-01, time/batch = 17.4341s	
27298/29850 (epoch 45.725), train_loss = 0.65796400, grad/param norm = 2.0370e-01, time/batch = 17.5644s	
27299/29850 (epoch 45.727), train_loss = 0.64584603, grad/param norm = 2.2546e-01, time/batch = 17.7977s	
27300/29850 (epoch 45.729), train_loss = 0.64037484, grad/param norm = 1.8869e-01, time/batch = 17.5379s	
27301/29850 (epoch 45.730), train_loss = 0.62176190, grad/param norm = 2.1469e-01, time/batch = 18.3713s	
27302/29850 (epoch 45.732), train_loss = 0.84651022, grad/param norm = 2.2273e-01, time/batch = 18.1899s	
27303/29850 (epoch 45.734), train_loss = 0.94859497, grad/param norm = 3.1548e-01, time/batch = 17.6154s	
27304/29850 (epoch 45.735), train_loss = 0.71382149, grad/param norm = 2.2529e-01, time/batch = 15.2646s	
27305/29850 (epoch 45.737), train_loss = 0.65437843, grad/param norm = 1.9638e-01, time/batch = 18.6349s	
27306/29850 (epoch 45.739), train_loss = 0.58941686, grad/param norm = 1.9552e-01, time/batch = 17.2331s	
27307/29850 (epoch 45.740), train_loss = 0.61458946, grad/param norm = 2.1242e-01, time/batch = 17.8726s	
27308/29850 (epoch 45.742), train_loss = 0.56301602, grad/param norm = 1.7187e-01, time/batch = 19.1214s	
27309/29850 (epoch 45.744), train_loss = 0.68837597, grad/param norm = 2.4862e-01, time/batch = 19.2715s	
27310/29850 (epoch 45.745), train_loss = 0.72360378, grad/param norm = 2.5487e-01, time/batch = 15.7885s	
27311/29850 (epoch 45.747), train_loss = 0.75447621, grad/param norm = 2.1630e-01, time/batch = 18.1108s	
27312/29850 (epoch 45.749), train_loss = 0.63866272, grad/param norm = 2.0000e-01, time/batch = 17.5466s	
27313/29850 (epoch 45.750), train_loss = 0.58025839, grad/param norm = 2.2570e-01, time/batch = 17.3772s	
27314/29850 (epoch 45.752), train_loss = 0.51422565, grad/param norm = 1.8326e-01, time/batch = 17.5435s	
27315/29850 (epoch 45.754), train_loss = 0.56554756, grad/param norm = 2.1604e-01, time/batch = 18.5408s	
27316/29850 (epoch 45.755), train_loss = 0.58528405, grad/param norm = 2.1542e-01, time/batch = 17.6285s	
27317/29850 (epoch 45.757), train_loss = 0.63219883, grad/param norm = 1.6954e-01, time/batch = 17.1992s	
27318/29850 (epoch 45.759), train_loss = 0.64398134, grad/param norm = 1.9353e-01, time/batch = 19.5386s	
27319/29850 (epoch 45.760), train_loss = 0.66702108, grad/param norm = 1.9961e-01, time/batch = 16.5305s	
27320/29850 (epoch 45.762), train_loss = 0.61458112, grad/param norm = 2.8354e-01, time/batch = 17.7019s	
27321/29850 (epoch 45.764), train_loss = 0.53274576, grad/param norm = 2.1815e-01, time/batch = 17.2070s	
27322/29850 (epoch 45.765), train_loss = 0.68269465, grad/param norm = 2.2763e-01, time/batch = 18.1414s	
27323/29850 (epoch 45.767), train_loss = 0.68917959, grad/param norm = 2.3697e-01, time/batch = 18.7064s	
27324/29850 (epoch 45.769), train_loss = 0.74492728, grad/param norm = 2.3802e-01, time/batch = 17.4561s	
27325/29850 (epoch 45.771), train_loss = 0.73723887, grad/param norm = 2.1197e-01, time/batch = 18.6434s	
27326/29850 (epoch 45.772), train_loss = 0.72873396, grad/param norm = 2.4665e-01, time/batch = 16.0323s	
27327/29850 (epoch 45.774), train_loss = 0.68892489, grad/param norm = 2.2800e-01, time/batch = 16.1903s	
27328/29850 (epoch 45.776), train_loss = 0.70135254, grad/param norm = 2.2048e-01, time/batch = 19.0183s	
27329/29850 (epoch 45.777), train_loss = 0.80058173, grad/param norm = 2.4492e-01, time/batch = 17.1338s	
27330/29850 (epoch 45.779), train_loss = 0.65054591, grad/param norm = 1.9477e-01, time/batch = 18.7674s	
27331/29850 (epoch 45.781), train_loss = 0.73850922, grad/param norm = 2.1908e-01, time/batch = 18.3667s	
27332/29850 (epoch 45.782), train_loss = 0.76067914, grad/param norm = 2.2287e-01, time/batch = 18.2217s	
27333/29850 (epoch 45.784), train_loss = 0.59346663, grad/param norm = 2.2679e-01, time/batch = 19.3705s	
27334/29850 (epoch 45.786), train_loss = 0.67409941, grad/param norm = 2.5058e-01, time/batch = 18.2878s	
27335/29850 (epoch 45.787), train_loss = 0.55783740, grad/param norm = 2.1350e-01, time/batch = 18.4730s	
27336/29850 (epoch 45.789), train_loss = 0.58739827, grad/param norm = 1.8516e-01, time/batch = 15.4318s	
27337/29850 (epoch 45.791), train_loss = 0.63685436, grad/param norm = 2.2864e-01, time/batch = 17.5420s	
27338/29850 (epoch 45.792), train_loss = 0.76534981, grad/param norm = 2.3343e-01, time/batch = 18.0368s	
27339/29850 (epoch 45.794), train_loss = 0.72967995, grad/param norm = 2.0646e-01, time/batch = 17.8866s	
27340/29850 (epoch 45.796), train_loss = 0.62576796, grad/param norm = 2.1975e-01, time/batch = 17.2017s	
27341/29850 (epoch 45.797), train_loss = 0.54550964, grad/param norm = 1.9667e-01, time/batch = 17.8006s	
27342/29850 (epoch 45.799), train_loss = 0.60025878, grad/param norm = 1.9351e-01, time/batch = 16.5588s	
27343/29850 (epoch 45.801), train_loss = 0.59226187, grad/param norm = 1.8347e-01, time/batch = 18.3007s	
27344/29850 (epoch 45.802), train_loss = 0.59389316, grad/param norm = 2.3447e-01, time/batch = 15.4017s	
27345/29850 (epoch 45.804), train_loss = 0.63197751, grad/param norm = 1.8779e-01, time/batch = 19.4508s	
27346/29850 (epoch 45.806), train_loss = 0.55938449, grad/param norm = 1.8817e-01, time/batch = 17.6322s	
27347/29850 (epoch 45.807), train_loss = 0.61720543, grad/param norm = 1.8298e-01, time/batch = 17.2760s	
27348/29850 (epoch 45.809), train_loss = 0.61322822, grad/param norm = 2.4333e-01, time/batch = 18.5235s	
27349/29850 (epoch 45.811), train_loss = 0.77172093, grad/param norm = 2.7349e-01, time/batch = 15.7017s	
27350/29850 (epoch 45.812), train_loss = 0.72469916, grad/param norm = 2.2467e-01, time/batch = 18.2993s	
27351/29850 (epoch 45.814), train_loss = 0.77788226, grad/param norm = 3.0979e-01, time/batch = 17.6229s	
27352/29850 (epoch 45.816), train_loss = 0.84923956, grad/param norm = 2.2879e-01, time/batch = 19.7950s	
27353/29850 (epoch 45.817), train_loss = 0.71948032, grad/param norm = 2.6055e-01, time/batch = 16.2687s	
27354/29850 (epoch 45.819), train_loss = 0.56264928, grad/param norm = 1.9065e-01, time/batch = 17.3788s	
27355/29850 (epoch 45.821), train_loss = 0.81416201, grad/param norm = 2.9251e-01, time/batch = 19.2093s	
27356/29850 (epoch 45.822), train_loss = 0.83716774, grad/param norm = 2.2982e-01, time/batch = 18.6043s	
27357/29850 (epoch 45.824), train_loss = 0.71392811, grad/param norm = 2.1662e-01, time/batch = 17.7781s	
27358/29850 (epoch 45.826), train_loss = 0.61878938, grad/param norm = 2.0624e-01, time/batch = 17.1097s	
27359/29850 (epoch 45.827), train_loss = 0.56775152, grad/param norm = 2.6241e-01, time/batch = 19.6117s	
27360/29850 (epoch 45.829), train_loss = 0.72546174, grad/param norm = 2.5294e-01, time/batch = 18.2811s	
27361/29850 (epoch 45.831), train_loss = 0.82605701, grad/param norm = 2.3365e-01, time/batch = 17.1212s	
27362/29850 (epoch 45.832), train_loss = 0.72329488, grad/param norm = 2.0809e-01, time/batch = 17.8863s	
27363/29850 (epoch 45.834), train_loss = 0.54793970, grad/param norm = 1.8303e-01, time/batch = 18.0466s	
27364/29850 (epoch 45.836), train_loss = 0.56970553, grad/param norm = 2.0055e-01, time/batch = 16.7959s	
27365/29850 (epoch 45.838), train_loss = 0.65590016, grad/param norm = 2.3339e-01, time/batch = 18.7039s	
27366/29850 (epoch 45.839), train_loss = 0.55715154, grad/param norm = 2.1001e-01, time/batch = 17.7256s	
27367/29850 (epoch 45.841), train_loss = 0.65116751, grad/param norm = 2.1251e-01, time/batch = 16.4733s	
27368/29850 (epoch 45.843), train_loss = 0.56031050, grad/param norm = 2.0552e-01, time/batch = 14.4737s	
27369/29850 (epoch 45.844), train_loss = 0.60220724, grad/param norm = 2.0709e-01, time/batch = 17.6420s	
27370/29850 (epoch 45.846), train_loss = 0.67374108, grad/param norm = 2.1335e-01, time/batch = 15.2826s	
27371/29850 (epoch 45.848), train_loss = 0.75441070, grad/param norm = 2.4154e-01, time/batch = 17.8536s	
27372/29850 (epoch 45.849), train_loss = 0.68126141, grad/param norm = 2.2155e-01, time/batch = 18.4476s	
27373/29850 (epoch 45.851), train_loss = 0.85770113, grad/param norm = 2.4755e-01, time/batch = 16.9569s	
27374/29850 (epoch 45.853), train_loss = 0.67150716, grad/param norm = 2.5318e-01, time/batch = 17.3708s	
27375/29850 (epoch 45.854), train_loss = 0.86867302, grad/param norm = 2.6183e-01, time/batch = 19.6146s	
27376/29850 (epoch 45.856), train_loss = 0.82455117, grad/param norm = 3.2273e-01, time/batch = 17.8016s	
27377/29850 (epoch 45.858), train_loss = 0.72793435, grad/param norm = 2.4366e-01, time/batch = 18.7885s	
27378/29850 (epoch 45.859), train_loss = 0.65175828, grad/param norm = 3.0258e-01, time/batch = 32.7422s	
27379/29850 (epoch 45.861), train_loss = 0.79980194, grad/param norm = 2.7644e-01, time/batch = 15.1042s	
27380/29850 (epoch 45.863), train_loss = 0.83647966, grad/param norm = 3.1416e-01, time/batch = 15.8427s	
27381/29850 (epoch 45.864), train_loss = 0.82292732, grad/param norm = 2.5602e-01, time/batch = 20.0326s	
27382/29850 (epoch 45.866), train_loss = 0.76395144, grad/param norm = 3.1060e-01, time/batch = 18.7077s	
27383/29850 (epoch 45.868), train_loss = 0.90721169, grad/param norm = 2.7064e-01, time/batch = 17.8697s	
27384/29850 (epoch 45.869), train_loss = 0.83033720, grad/param norm = 2.9746e-01, time/batch = 18.8802s	
27385/29850 (epoch 45.871), train_loss = 0.82453954, grad/param norm = 2.4577e-01, time/batch = 18.1279s	
27386/29850 (epoch 45.873), train_loss = 0.79666298, grad/param norm = 2.6388e-01, time/batch = 16.3735s	
27387/29850 (epoch 45.874), train_loss = 0.76864687, grad/param norm = 2.2257e-01, time/batch = 16.2778s	
27388/29850 (epoch 45.876), train_loss = 0.77612284, grad/param norm = 2.8376e-01, time/batch = 17.2209s	
27389/29850 (epoch 45.878), train_loss = 0.75667683, grad/param norm = 2.2770e-01, time/batch = 17.3132s	
27390/29850 (epoch 45.879), train_loss = 0.80755600, grad/param norm = 2.6208e-01, time/batch = 17.5318s	
27391/29850 (epoch 45.881), train_loss = 0.84221602, grad/param norm = 2.7272e-01, time/batch = 18.1377s	
27392/29850 (epoch 45.883), train_loss = 0.78863412, grad/param norm = 2.6482e-01, time/batch = 17.9679s	
27393/29850 (epoch 45.884), train_loss = 0.67601330, grad/param norm = 2.3892e-01, time/batch = 19.2210s	
27394/29850 (epoch 45.886), train_loss = 0.81986335, grad/param norm = 2.9056e-01, time/batch = 16.1130s	
27395/29850 (epoch 45.888), train_loss = 0.76404272, grad/param norm = 2.9613e-01, time/batch = 18.4696s	
27396/29850 (epoch 45.889), train_loss = 0.70131961, grad/param norm = 2.0382e-01, time/batch = 18.2156s	
27397/29850 (epoch 45.891), train_loss = 0.67185793, grad/param norm = 2.0169e-01, time/batch = 15.8753s	
27398/29850 (epoch 45.893), train_loss = 0.72481524, grad/param norm = 2.7728e-01, time/batch = 17.1114s	
27399/29850 (epoch 45.894), train_loss = 0.71407585, grad/param norm = 2.6634e-01, time/batch = 18.4521s	
27400/29850 (epoch 45.896), train_loss = 0.77404490, grad/param norm = 2.9693e-01, time/batch = 17.3738s	
27401/29850 (epoch 45.898), train_loss = 0.89768533, grad/param norm = 2.3052e-01, time/batch = 17.9538s	
27402/29850 (epoch 45.899), train_loss = 0.65440322, grad/param norm = 2.4015e-01, time/batch = 16.6916s	
27403/29850 (epoch 45.901), train_loss = 0.93440678, grad/param norm = 3.2751e-01, time/batch = 17.0452s	
27404/29850 (epoch 45.903), train_loss = 0.79683358, grad/param norm = 3.4718e-01, time/batch = 16.6092s	
27405/29850 (epoch 45.905), train_loss = 0.99989354, grad/param norm = 2.5561e-01, time/batch = 19.3641s	
27406/29850 (epoch 45.906), train_loss = 0.75846976, grad/param norm = 2.7960e-01, time/batch = 18.6267s	
27407/29850 (epoch 45.908), train_loss = 0.91766701, grad/param norm = 3.2427e-01, time/batch = 18.1216s	
27408/29850 (epoch 45.910), train_loss = 0.83809430, grad/param norm = 2.6812e-01, time/batch = 16.7997s	
27409/29850 (epoch 45.911), train_loss = 0.96215304, grad/param norm = 2.6072e-01, time/batch = 17.5628s	
27410/29850 (epoch 45.913), train_loss = 0.89708141, grad/param norm = 2.7224e-01, time/batch = 18.6268s	
27411/29850 (epoch 45.915), train_loss = 0.89674348, grad/param norm = 2.4132e-01, time/batch = 16.7744s	
27412/29850 (epoch 45.916), train_loss = 0.87534427, grad/param norm = 2.7755e-01, time/batch = 18.3007s	
27413/29850 (epoch 45.918), train_loss = 0.70302349, grad/param norm = 2.0938e-01, time/batch = 17.9812s	
27414/29850 (epoch 45.920), train_loss = 0.86902108, grad/param norm = 2.2568e-01, time/batch = 15.2804s	
27415/29850 (epoch 45.921), train_loss = 0.75855840, grad/param norm = 3.0171e-01, time/batch = 18.6198s	
27416/29850 (epoch 45.923), train_loss = 0.78060364, grad/param norm = 2.4405e-01, time/batch = 16.6317s	
27417/29850 (epoch 45.925), train_loss = 0.92147861, grad/param norm = 2.3818e-01, time/batch = 18.4639s	
27418/29850 (epoch 45.926), train_loss = 0.92310608, grad/param norm = 2.8443e-01, time/batch = 17.2823s	
27419/29850 (epoch 45.928), train_loss = 0.78549535, grad/param norm = 2.4680e-01, time/batch = 18.9737s	
27420/29850 (epoch 45.930), train_loss = 0.78306894, grad/param norm = 2.6508e-01, time/batch = 17.2920s	
27421/29850 (epoch 45.931), train_loss = 0.80173666, grad/param norm = 3.0398e-01, time/batch = 16.7848s	
27422/29850 (epoch 45.933), train_loss = 0.90939539, grad/param norm = 2.3371e-01, time/batch = 16.3634s	
27423/29850 (epoch 45.935), train_loss = 0.83443999, grad/param norm = 2.3333e-01, time/batch = 16.1072s	
27424/29850 (epoch 45.936), train_loss = 0.81883558, grad/param norm = 2.6665e-01, time/batch = 16.4405s	
27425/29850 (epoch 45.938), train_loss = 0.70459104, grad/param norm = 2.8217e-01, time/batch = 17.0416s	
27426/29850 (epoch 45.940), train_loss = 0.70172362, grad/param norm = 2.2096e-01, time/batch = 19.2128s	
27427/29850 (epoch 45.941), train_loss = 0.68489953, grad/param norm = 2.4741e-01, time/batch = 17.2809s	
27428/29850 (epoch 45.943), train_loss = 0.73482566, grad/param norm = 2.2941e-01, time/batch = 17.4381s	
27429/29850 (epoch 45.945), train_loss = 0.68443439, grad/param norm = 2.8564e-01, time/batch = 16.1177s	
27430/29850 (epoch 45.946), train_loss = 0.67623758, grad/param norm = 2.4040e-01, time/batch = 17.3855s	
27431/29850 (epoch 45.948), train_loss = 0.77921871, grad/param norm = 2.4829e-01, time/batch = 17.1970s	
27432/29850 (epoch 45.950), train_loss = 0.72380448, grad/param norm = 1.7752e-01, time/batch = 16.1191s	
27433/29850 (epoch 45.951), train_loss = 0.65171077, grad/param norm = 2.1617e-01, time/batch = 17.7569s	
27434/29850 (epoch 45.953), train_loss = 0.71816111, grad/param norm = 2.3859e-01, time/batch = 18.8866s	
27435/29850 (epoch 45.955), train_loss = 0.64737292, grad/param norm = 2.0600e-01, time/batch = 18.4522s	
27436/29850 (epoch 45.956), train_loss = 0.63022428, grad/param norm = 2.0966e-01, time/batch = 19.1265s	
27437/29850 (epoch 45.958), train_loss = 0.60187030, grad/param norm = 2.0582e-01, time/batch = 16.5420s	
27438/29850 (epoch 45.960), train_loss = 0.85660573, grad/param norm = 2.7072e-01, time/batch = 17.6978s	
27439/29850 (epoch 45.961), train_loss = 0.62229309, grad/param norm = 2.2271e-01, time/batch = 18.2222s	
27440/29850 (epoch 45.963), train_loss = 0.60580088, grad/param norm = 2.3118e-01, time/batch = 18.3566s	
27441/29850 (epoch 45.965), train_loss = 0.66369702, grad/param norm = 2.4637e-01, time/batch = 17.0368s	
27442/29850 (epoch 45.966), train_loss = 0.65090166, grad/param norm = 2.4517e-01, time/batch = 19.0289s	
27443/29850 (epoch 45.968), train_loss = 0.67977471, grad/param norm = 2.8283e-01, time/batch = 19.6088s	
27444/29850 (epoch 45.970), train_loss = 0.70382405, grad/param norm = 2.4431e-01, time/batch = 16.9714s	
27445/29850 (epoch 45.972), train_loss = 0.67163301, grad/param norm = 1.9382e-01, time/batch = 16.6182s	
27446/29850 (epoch 45.973), train_loss = 0.65980590, grad/param norm = 1.9648e-01, time/batch = 17.3756s	
27447/29850 (epoch 45.975), train_loss = 0.60141651, grad/param norm = 1.9666e-01, time/batch = 18.3904s	
27448/29850 (epoch 45.977), train_loss = 0.68554451, grad/param norm = 1.9605e-01, time/batch = 16.9632s	
27449/29850 (epoch 45.978), train_loss = 0.59475245, grad/param norm = 1.8207e-01, time/batch = 17.3708s	
27450/29850 (epoch 45.980), train_loss = 0.67552186, grad/param norm = 1.8780e-01, time/batch = 17.7204s	
27451/29850 (epoch 45.982), train_loss = 0.62812111, grad/param norm = 2.1145e-01, time/batch = 17.6249s	
27452/29850 (epoch 45.983), train_loss = 0.66393642, grad/param norm = 1.8477e-01, time/batch = 16.8390s	
27453/29850 (epoch 45.985), train_loss = 0.77850282, grad/param norm = 2.4177e-01, time/batch = 17.1239s	
27454/29850 (epoch 45.987), train_loss = 0.78079339, grad/param norm = 2.4534e-01, time/batch = 16.6330s	
27455/29850 (epoch 45.988), train_loss = 0.72888281, grad/param norm = 2.0734e-01, time/batch = 15.3937s	
27456/29850 (epoch 45.990), train_loss = 0.77257184, grad/param norm = 2.2058e-01, time/batch = 18.2143s	
27457/29850 (epoch 45.992), train_loss = 0.76295828, grad/param norm = 2.2758e-01, time/batch = 18.4573s	
27458/29850 (epoch 45.993), train_loss = 0.77527925, grad/param norm = 2.5758e-01, time/batch = 16.8317s	
27459/29850 (epoch 45.995), train_loss = 0.74966780, grad/param norm = 2.6505e-01, time/batch = 20.4530s	
27460/29850 (epoch 45.997), train_loss = 0.77408428, grad/param norm = 2.0429e-01, time/batch = 16.8779s	
27461/29850 (epoch 45.998), train_loss = 0.78141866, grad/param norm = 2.0716e-01, time/batch = 18.6265s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
27462/29850 (epoch 46.000), train_loss = 0.61497230, grad/param norm = 1.9926e-01, time/batch = 16.4500s	
27463/29850 (epoch 46.002), train_loss = 0.86037120, grad/param norm = 2.5174e-01, time/batch = 15.2075s	
27464/29850 (epoch 46.003), train_loss = 0.62988704, grad/param norm = 2.5019e-01, time/batch = 18.1395s	
27465/29850 (epoch 46.005), train_loss = 0.80938356, grad/param norm = 2.5043e-01, time/batch = 18.0331s	
27466/29850 (epoch 46.007), train_loss = 0.84581754, grad/param norm = 2.9061e-01, time/batch = 19.3692s	
27467/29850 (epoch 46.008), train_loss = 0.97013622, grad/param norm = 3.0274e-01, time/batch = 16.9786s	
27468/29850 (epoch 46.010), train_loss = 0.66403568, grad/param norm = 2.1517e-01, time/batch = 18.0103s	
27469/29850 (epoch 46.012), train_loss = 0.71331757, grad/param norm = 2.0053e-01, time/batch = 17.4591s	
27470/29850 (epoch 46.013), train_loss = 0.75944712, grad/param norm = 2.7068e-01, time/batch = 18.3633s	
27471/29850 (epoch 46.015), train_loss = 0.84771444, grad/param norm = 2.6832e-01, time/batch = 16.9584s	
27472/29850 (epoch 46.017), train_loss = 0.79346112, grad/param norm = 2.6680e-01, time/batch = 16.1788s	
27473/29850 (epoch 46.018), train_loss = 0.87595808, grad/param norm = 2.2879e-01, time/batch = 18.1945s	
27474/29850 (epoch 46.020), train_loss = 0.78559982, grad/param norm = 2.7580e-01, time/batch = 18.5489s	
27475/29850 (epoch 46.022), train_loss = 0.85371187, grad/param norm = 2.3001e-01, time/batch = 15.5594s	
27476/29850 (epoch 46.023), train_loss = 0.82198571, grad/param norm = 2.0681e-01, time/batch = 17.3062s	
27477/29850 (epoch 46.025), train_loss = 0.75715652, grad/param norm = 1.9303e-01, time/batch = 19.7002s	
27478/29850 (epoch 46.027), train_loss = 0.55257694, grad/param norm = 2.0545e-01, time/batch = 18.1169s	
27479/29850 (epoch 46.028), train_loss = 0.69147134, grad/param norm = 2.1690e-01, time/batch = 16.4430s	
27480/29850 (epoch 46.030), train_loss = 0.71140993, grad/param norm = 2.3987e-01, time/batch = 17.2890s	
27481/29850 (epoch 46.032), train_loss = 0.80517653, grad/param norm = 2.7316e-01, time/batch = 17.4504s	
27482/29850 (epoch 46.034), train_loss = 0.68595219, grad/param norm = 2.6397e-01, time/batch = 16.3858s	
27483/29850 (epoch 46.035), train_loss = 0.60149530, grad/param norm = 1.8375e-01, time/batch = 17.3724s	
27484/29850 (epoch 46.037), train_loss = 0.76224495, grad/param norm = 2.5878e-01, time/batch = 18.1471s	
27485/29850 (epoch 46.039), train_loss = 0.66878049, grad/param norm = 1.8958e-01, time/batch = 17.9583s	
27486/29850 (epoch 46.040), train_loss = 0.62139040, grad/param norm = 2.1035e-01, time/batch = 16.3791s	
27487/29850 (epoch 46.042), train_loss = 0.68144620, grad/param norm = 2.1602e-01, time/batch = 19.6148s	
27488/29850 (epoch 46.044), train_loss = 0.74371735, grad/param norm = 2.4149e-01, time/batch = 17.2914s	
27489/29850 (epoch 46.045), train_loss = 0.81880510, grad/param norm = 2.7518e-01, time/batch = 16.6235s	
27490/29850 (epoch 46.047), train_loss = 0.67419638, grad/param norm = 2.3611e-01, time/batch = 17.7214s	
27491/29850 (epoch 46.049), train_loss = 0.76580989, grad/param norm = 2.2246e-01, time/batch = 16.2143s	
27492/29850 (epoch 46.050), train_loss = 0.71609549, grad/param norm = 2.2331e-01, time/batch = 16.8508s	
27493/29850 (epoch 46.052), train_loss = 0.86567194, grad/param norm = 2.9397e-01, time/batch = 16.6496s	
27494/29850 (epoch 46.054), train_loss = 0.74867993, grad/param norm = 2.3912e-01, time/batch = 18.8815s	
27495/29850 (epoch 46.055), train_loss = 0.72827375, grad/param norm = 2.2215e-01, time/batch = 18.4756s	
27496/29850 (epoch 46.057), train_loss = 0.81180705, grad/param norm = 2.2164e-01, time/batch = 16.8742s	
27497/29850 (epoch 46.059), train_loss = 0.76756855, grad/param norm = 2.3322e-01, time/batch = 17.6404s	
27498/29850 (epoch 46.060), train_loss = 0.77052565, grad/param norm = 2.8612e-01, time/batch = 17.7871s	
27499/29850 (epoch 46.062), train_loss = 0.84243389, grad/param norm = 2.5546e-01, time/batch = 16.1033s	
27500/29850 (epoch 46.064), train_loss = 0.84457493, grad/param norm = 2.5058e-01, time/batch = 18.5177s	
27501/29850 (epoch 46.065), train_loss = 0.62783808, grad/param norm = 2.0266e-01, time/batch = 17.2891s	
27502/29850 (epoch 46.067), train_loss = 0.81348638, grad/param norm = 2.3708e-01, time/batch = 17.8799s	
27503/29850 (epoch 46.069), train_loss = 0.77758165, grad/param norm = 1.9958e-01, time/batch = 17.9672s	
27504/29850 (epoch 46.070), train_loss = 0.83526729, grad/param norm = 2.4766e-01, time/batch = 14.4169s	
27505/29850 (epoch 46.072), train_loss = 0.75718709, grad/param norm = 2.4443e-01, time/batch = 15.2247s	
27506/29850 (epoch 46.074), train_loss = 0.84262784, grad/param norm = 2.2400e-01, time/batch = 16.8037s	
27507/29850 (epoch 46.075), train_loss = 0.70236845, grad/param norm = 2.5137e-01, time/batch = 18.6871s	
27508/29850 (epoch 46.077), train_loss = 0.82007132, grad/param norm = 2.8868e-01, time/batch = 16.0374s	
27509/29850 (epoch 46.079), train_loss = 0.97240435, grad/param norm = 3.4215e-01, time/batch = 18.0412s	
27510/29850 (epoch 46.080), train_loss = 0.91750656, grad/param norm = 2.9051e-01, time/batch = 18.0150s	
27511/29850 (epoch 46.082), train_loss = 0.82262128, grad/param norm = 2.2897e-01, time/batch = 18.2215s	
27512/29850 (epoch 46.084), train_loss = 0.93297114, grad/param norm = 2.6793e-01, time/batch = 17.5453s	
27513/29850 (epoch 46.085), train_loss = 0.94596857, grad/param norm = 2.5776e-01, time/batch = 15.9473s	
27514/29850 (epoch 46.087), train_loss = 0.87925469, grad/param norm = 2.2668e-01, time/batch = 19.2904s	
27515/29850 (epoch 46.089), train_loss = 0.80825369, grad/param norm = 2.2028e-01, time/batch = 17.3844s	
27516/29850 (epoch 46.090), train_loss = 0.80342992, grad/param norm = 2.1642e-01, time/batch = 17.1175s	
27517/29850 (epoch 46.092), train_loss = 0.71256422, grad/param norm = 2.2687e-01, time/batch = 20.5276s	
27518/29850 (epoch 46.094), train_loss = 0.89789525, grad/param norm = 2.4856e-01, time/batch = 15.3533s	
27519/29850 (epoch 46.095), train_loss = 0.83405420, grad/param norm = 2.6407e-01, time/batch = 18.3804s	
27520/29850 (epoch 46.097), train_loss = 0.59507544, grad/param norm = 1.7980e-01, time/batch = 17.4589s	
27521/29850 (epoch 46.099), train_loss = 0.63482354, grad/param norm = 2.0352e-01, time/batch = 19.2942s	
27522/29850 (epoch 46.101), train_loss = 0.81225152, grad/param norm = 2.3685e-01, time/batch = 17.7142s	
27523/29850 (epoch 46.102), train_loss = 0.82328309, grad/param norm = 2.4305e-01, time/batch = 17.4460s	
27524/29850 (epoch 46.104), train_loss = 0.73323596, grad/param norm = 2.9645e-01, time/batch = 17.2687s	
27525/29850 (epoch 46.106), train_loss = 0.85567253, grad/param norm = 2.3209e-01, time/batch = 18.3003s	
27526/29850 (epoch 46.107), train_loss = 0.72120697, grad/param norm = 2.1265e-01, time/batch = 17.2844s	
27527/29850 (epoch 46.109), train_loss = 0.78638485, grad/param norm = 2.4373e-01, time/batch = 19.6950s	
27528/29850 (epoch 46.111), train_loss = 0.80106232, grad/param norm = 2.4837e-01, time/batch = 18.8642s	
27529/29850 (epoch 46.112), train_loss = 0.68801819, grad/param norm = 2.2742e-01, time/batch = 19.1051s	
27530/29850 (epoch 46.114), train_loss = 0.71482580, grad/param norm = 2.5719e-01, time/batch = 16.9650s	
27531/29850 (epoch 46.116), train_loss = 0.69532522, grad/param norm = 2.0641e-01, time/batch = 18.4691s	
27532/29850 (epoch 46.117), train_loss = 0.72443922, grad/param norm = 2.5298e-01, time/batch = 16.6101s	
27533/29850 (epoch 46.119), train_loss = 0.73023615, grad/param norm = 2.3183e-01, time/batch = 17.2802s	
27534/29850 (epoch 46.121), train_loss = 0.62268822, grad/param norm = 2.3535e-01, time/batch = 18.8735s	
27535/29850 (epoch 46.122), train_loss = 0.66207160, grad/param norm = 1.7408e-01, time/batch = 16.6347s	
27536/29850 (epoch 46.124), train_loss = 0.71060627, grad/param norm = 2.6440e-01, time/batch = 18.7034s	
27537/29850 (epoch 46.126), train_loss = 0.75723545, grad/param norm = 2.3506e-01, time/batch = 17.1347s	
27538/29850 (epoch 46.127), train_loss = 0.79439503, grad/param norm = 2.7711e-01, time/batch = 19.7686s	
27539/29850 (epoch 46.129), train_loss = 0.77568390, grad/param norm = 2.5918e-01, time/batch = 16.9533s	
27540/29850 (epoch 46.131), train_loss = 0.76826908, grad/param norm = 1.9620e-01, time/batch = 17.8386s	
27541/29850 (epoch 46.132), train_loss = 0.66624883, grad/param norm = 2.3299e-01, time/batch = 18.6265s	
27542/29850 (epoch 46.134), train_loss = 0.73770098, grad/param norm = 2.4741e-01, time/batch = 17.6337s	
27543/29850 (epoch 46.136), train_loss = 0.81402372, grad/param norm = 2.2072e-01, time/batch = 17.1155s	
27544/29850 (epoch 46.137), train_loss = 0.63176330, grad/param norm = 2.3835e-01, time/batch = 19.0543s	
27545/29850 (epoch 46.139), train_loss = 0.76651437, grad/param norm = 2.4637e-01, time/batch = 17.0509s	
27546/29850 (epoch 46.141), train_loss = 0.68238566, grad/param norm = 2.2791e-01, time/batch = 17.4533s	
27547/29850 (epoch 46.142), train_loss = 0.86918571, grad/param norm = 2.5848e-01, time/batch = 16.1253s	
27548/29850 (epoch 46.144), train_loss = 0.98887648, grad/param norm = 2.9312e-01, time/batch = 17.8673s	
27549/29850 (epoch 46.146), train_loss = 0.98012970, grad/param norm = 2.6834e-01, time/batch = 18.2077s	
27550/29850 (epoch 46.147), train_loss = 0.87298321, grad/param norm = 2.6562e-01, time/batch = 17.9363s	
27551/29850 (epoch 46.149), train_loss = 0.81529681, grad/param norm = 2.8807e-01, time/batch = 16.9602s	
27552/29850 (epoch 46.151), train_loss = 0.81752179, grad/param norm = 2.5651e-01, time/batch = 17.7104s	
27553/29850 (epoch 46.152), train_loss = 0.76489329, grad/param norm = 2.2930e-01, time/batch = 16.1230s	
27554/29850 (epoch 46.154), train_loss = 0.71687193, grad/param norm = 2.4839e-01, time/batch = 16.7007s	
27555/29850 (epoch 46.156), train_loss = 0.71801303, grad/param norm = 2.3621e-01, time/batch = 18.3761s	
27556/29850 (epoch 46.157), train_loss = 0.81853132, grad/param norm = 2.3225e-01, time/batch = 16.1185s	
27557/29850 (epoch 46.159), train_loss = 0.72002286, grad/param norm = 2.0827e-01, time/batch = 18.8499s	
27558/29850 (epoch 46.161), train_loss = 0.73995184, grad/param norm = 2.2870e-01, time/batch = 19.0596s	
27559/29850 (epoch 46.162), train_loss = 0.90241398, grad/param norm = 2.9862e-01, time/batch = 17.9335s	
27560/29850 (epoch 46.164), train_loss = 0.81758413, grad/param norm = 2.5508e-01, time/batch = 18.0196s	
27561/29850 (epoch 46.166), train_loss = 0.74354542, grad/param norm = 2.2254e-01, time/batch = 18.5317s	
27562/29850 (epoch 46.168), train_loss = 0.68298526, grad/param norm = 2.2636e-01, time/batch = 19.5278s	
27563/29850 (epoch 46.169), train_loss = 0.89017606, grad/param norm = 3.6786e-01, time/batch = 16.0452s	
27564/29850 (epoch 46.171), train_loss = 0.85155928, grad/param norm = 2.3003e-01, time/batch = 15.1453s	
27565/29850 (epoch 46.173), train_loss = 0.66725994, grad/param norm = 2.3951e-01, time/batch = 16.7297s	
27566/29850 (epoch 46.174), train_loss = 0.74414595, grad/param norm = 2.5387e-01, time/batch = 18.3840s	
27567/29850 (epoch 46.176), train_loss = 0.80894589, grad/param norm = 2.5010e-01, time/batch = 18.8562s	
27568/29850 (epoch 46.178), train_loss = 0.81372400, grad/param norm = 2.2404e-01, time/batch = 17.2244s	
27569/29850 (epoch 46.179), train_loss = 0.64407742, grad/param norm = 2.5311e-01, time/batch = 19.8642s	
27570/29850 (epoch 46.181), train_loss = 0.79088834, grad/param norm = 2.4681e-01, time/batch = 16.6028s	
27571/29850 (epoch 46.183), train_loss = 0.79088402, grad/param norm = 2.2356e-01, time/batch = 18.9599s	
27572/29850 (epoch 46.184), train_loss = 0.87429419, grad/param norm = 2.6877e-01, time/batch = 17.4732s	
27573/29850 (epoch 46.186), train_loss = 0.82571537, grad/param norm = 3.1685e-01, time/batch = 16.8645s	
27574/29850 (epoch 46.188), train_loss = 0.92662433, grad/param norm = 2.6918e-01, time/batch = 17.0272s	
27575/29850 (epoch 46.189), train_loss = 0.83845237, grad/param norm = 2.5175e-01, time/batch = 16.4437s	
27576/29850 (epoch 46.191), train_loss = 0.86312959, grad/param norm = 2.2888e-01, time/batch = 18.2247s	
27577/29850 (epoch 46.193), train_loss = 0.76422494, grad/param norm = 2.1786e-01, time/batch = 17.1290s	
27578/29850 (epoch 46.194), train_loss = 0.87237043, grad/param norm = 2.4155e-01, time/batch = 19.2096s	
27579/29850 (epoch 46.196), train_loss = 0.74585852, grad/param norm = 2.0853e-01, time/batch = 19.1074s	
27580/29850 (epoch 46.198), train_loss = 0.70018752, grad/param norm = 2.3326e-01, time/batch = 28.6602s	
27581/29850 (epoch 46.199), train_loss = 0.95919346, grad/param norm = 2.7200e-01, time/batch = 19.3443s	
27582/29850 (epoch 46.201), train_loss = 0.71060037, grad/param norm = 1.9680e-01, time/batch = 17.7759s	
27583/29850 (epoch 46.203), train_loss = 0.59006542, grad/param norm = 3.1236e-01, time/batch = 18.4427s	
27584/29850 (epoch 46.204), train_loss = 0.75589746, grad/param norm = 2.6073e-01, time/batch = 18.5573s	
27585/29850 (epoch 46.206), train_loss = 0.66392851, grad/param norm = 2.2736e-01, time/batch = 17.1390s	
27586/29850 (epoch 46.208), train_loss = 0.88978331, grad/param norm = 3.0029e-01, time/batch = 14.8945s	
27587/29850 (epoch 46.209), train_loss = 0.69864877, grad/param norm = 2.2771e-01, time/batch = 20.1332s	
27588/29850 (epoch 46.211), train_loss = 0.74760294, grad/param norm = 2.3880e-01, time/batch = 17.1243s	
27589/29850 (epoch 46.213), train_loss = 0.80744205, grad/param norm = 2.3735e-01, time/batch = 17.5318s	
27590/29850 (epoch 46.214), train_loss = 0.63124212, grad/param norm = 1.9512e-01, time/batch = 17.3736s	
27591/29850 (epoch 46.216), train_loss = 0.67746630, grad/param norm = 2.1939e-01, time/batch = 17.2101s	
27592/29850 (epoch 46.218), train_loss = 0.78508304, grad/param norm = 2.6286e-01, time/batch = 18.6221s	
27593/29850 (epoch 46.219), train_loss = 0.77512621, grad/param norm = 2.4896e-01, time/batch = 17.8658s	
27594/29850 (epoch 46.221), train_loss = 0.75170973, grad/param norm = 2.3367e-01, time/batch = 19.1883s	
27595/29850 (epoch 46.223), train_loss = 0.61013264, grad/param norm = 2.2319e-01, time/batch = 17.4721s	
27596/29850 (epoch 46.224), train_loss = 0.61727406, grad/param norm = 1.9964e-01, time/batch = 16.2632s	
27597/29850 (epoch 46.226), train_loss = 0.68042605, grad/param norm = 2.1460e-01, time/batch = 18.2157s	
27598/29850 (epoch 46.228), train_loss = 0.73319340, grad/param norm = 2.2858e-01, time/batch = 18.3116s	
27599/29850 (epoch 46.229), train_loss = 0.62779719, grad/param norm = 1.8900e-01, time/batch = 16.2793s	
27600/29850 (epoch 46.231), train_loss = 0.79286225, grad/param norm = 2.3609e-01, time/batch = 17.8619s	
27601/29850 (epoch 46.233), train_loss = 0.73465151, grad/param norm = 2.4424e-01, time/batch = 17.1081s	
27602/29850 (epoch 46.235), train_loss = 0.69496222, grad/param norm = 1.9355e-01, time/batch = 18.8797s	
27603/29850 (epoch 46.236), train_loss = 0.89961427, grad/param norm = 2.7209e-01, time/batch = 18.0213s	
27604/29850 (epoch 46.238), train_loss = 0.65276576, grad/param norm = 2.2211e-01, time/batch = 18.6088s	
27605/29850 (epoch 46.240), train_loss = 0.65248821, grad/param norm = 2.1143e-01, time/batch = 15.6025s	
27606/29850 (epoch 46.241), train_loss = 0.77388175, grad/param norm = 2.2479e-01, time/batch = 16.5478s	
27607/29850 (epoch 46.243), train_loss = 0.81088633, grad/param norm = 2.3580e-01, time/batch = 18.5446s	
27608/29850 (epoch 46.245), train_loss = 0.68614274, grad/param norm = 2.3004e-01, time/batch = 18.5392s	
27609/29850 (epoch 46.246), train_loss = 0.69095122, grad/param norm = 2.0874e-01, time/batch = 17.8781s	
27610/29850 (epoch 46.248), train_loss = 0.63946462, grad/param norm = 2.0626e-01, time/batch = 17.2980s	
27611/29850 (epoch 46.250), train_loss = 0.71459299, grad/param norm = 1.9826e-01, time/batch = 16.9722s	
27612/29850 (epoch 46.251), train_loss = 0.61763792, grad/param norm = 2.8682e-01, time/batch = 18.3969s	
27613/29850 (epoch 46.253), train_loss = 0.61521192, grad/param norm = 2.1921e-01, time/batch = 15.7926s	
27614/29850 (epoch 46.255), train_loss = 0.66340685, grad/param norm = 2.2185e-01, time/batch = 16.8133s	
27615/29850 (epoch 46.256), train_loss = 0.80095831, grad/param norm = 2.6663e-01, time/batch = 17.5517s	
27616/29850 (epoch 46.258), train_loss = 0.80272740, grad/param norm = 2.3623e-01, time/batch = 17.6197s	
27617/29850 (epoch 46.260), train_loss = 0.71725666, grad/param norm = 1.9266e-01, time/batch = 15.1116s	
27618/29850 (epoch 46.261), train_loss = 0.66803067, grad/param norm = 2.1833e-01, time/batch = 19.4456s	
27619/29850 (epoch 46.263), train_loss = 0.66172038, grad/param norm = 1.8497e-01, time/batch = 17.3062s	
27620/29850 (epoch 46.265), train_loss = 0.72216505, grad/param norm = 2.4282e-01, time/batch = 16.8833s	
27621/29850 (epoch 46.266), train_loss = 0.74573244, grad/param norm = 2.0904e-01, time/batch = 18.3737s	
27622/29850 (epoch 46.268), train_loss = 0.71661674, grad/param norm = 1.9452e-01, time/batch = 17.8677s	
27623/29850 (epoch 46.270), train_loss = 0.66065631, grad/param norm = 2.1813e-01, time/batch = 18.0313s	
27624/29850 (epoch 46.271), train_loss = 0.76521468, grad/param norm = 2.1837e-01, time/batch = 16.0523s	
27625/29850 (epoch 46.273), train_loss = 0.65272010, grad/param norm = 2.2907e-01, time/batch = 18.6254s	
27626/29850 (epoch 46.275), train_loss = 0.65103845, grad/param norm = 1.9980e-01, time/batch = 17.8035s	
27627/29850 (epoch 46.276), train_loss = 0.65008413, grad/param norm = 1.9718e-01, time/batch = 17.7007s	
27628/29850 (epoch 46.278), train_loss = 0.70044533, grad/param norm = 2.0943e-01, time/batch = 18.6278s	
27629/29850 (epoch 46.280), train_loss = 0.91415265, grad/param norm = 3.5150e-01, time/batch = 19.1466s	
27630/29850 (epoch 46.281), train_loss = 0.76898388, grad/param norm = 2.5085e-01, time/batch = 15.6879s	
27631/29850 (epoch 46.283), train_loss = 0.84225336, grad/param norm = 3.1087e-01, time/batch = 17.7118s	
27632/29850 (epoch 46.285), train_loss = 0.82176236, grad/param norm = 2.3059e-01, time/batch = 17.7249s	
27633/29850 (epoch 46.286), train_loss = 0.86233105, grad/param norm = 2.3501e-01, time/batch = 17.8708s	
27634/29850 (epoch 46.288), train_loss = 0.77649592, grad/param norm = 2.7579e-01, time/batch = 17.3615s	
27635/29850 (epoch 46.290), train_loss = 0.76630792, grad/param norm = 2.2668e-01, time/batch = 19.0512s	
27636/29850 (epoch 46.291), train_loss = 0.97779967, grad/param norm = 3.0370e-01, time/batch = 18.2246s	
27637/29850 (epoch 46.293), train_loss = 0.88655401, grad/param norm = 2.5439e-01, time/batch = 18.8517s	
27638/29850 (epoch 46.295), train_loss = 0.94093337, grad/param norm = 2.3721e-01, time/batch = 19.5369s	
27639/29850 (epoch 46.296), train_loss = 0.70055705, grad/param norm = 1.9372e-01, time/batch = 16.2268s	
27640/29850 (epoch 46.298), train_loss = 0.59196119, grad/param norm = 2.0850e-01, time/batch = 15.3425s	
27641/29850 (epoch 46.300), train_loss = 0.64998408, grad/param norm = 1.9916e-01, time/batch = 15.3768s	
27642/29850 (epoch 46.302), train_loss = 0.65835330, grad/param norm = 2.0802e-01, time/batch = 18.2090s	
27643/29850 (epoch 46.303), train_loss = 0.67428953, grad/param norm = 2.1007e-01, time/batch = 17.8507s	
27644/29850 (epoch 46.305), train_loss = 0.85014631, grad/param norm = 2.4805e-01, time/batch = 18.5404s	
27645/29850 (epoch 46.307), train_loss = 0.83014132, grad/param norm = 2.6540e-01, time/batch = 17.7945s	
27646/29850 (epoch 46.308), train_loss = 0.64815016, grad/param norm = 2.5636e-01, time/batch = 18.3864s	
27647/29850 (epoch 46.310), train_loss = 0.80740923, grad/param norm = 2.3520e-01, time/batch = 15.8663s	
27648/29850 (epoch 46.312), train_loss = 0.84545591, grad/param norm = 2.2070e-01, time/batch = 17.8101s	
27649/29850 (epoch 46.313), train_loss = 0.76018637, grad/param norm = 2.3787e-01, time/batch = 17.3884s	
27650/29850 (epoch 46.315), train_loss = 0.80471928, grad/param norm = 2.5804e-01, time/batch = 16.7173s	
27651/29850 (epoch 46.317), train_loss = 0.75705220, grad/param norm = 2.1937e-01, time/batch = 19.7671s	
27652/29850 (epoch 46.318), train_loss = 0.73118199, grad/param norm = 2.3550e-01, time/batch = 17.7221s	
27653/29850 (epoch 46.320), train_loss = 0.71133403, grad/param norm = 2.1984e-01, time/batch = 18.1081s	
27654/29850 (epoch 46.322), train_loss = 0.84686036, grad/param norm = 2.6542e-01, time/batch = 17.8683s	
27655/29850 (epoch 46.323), train_loss = 0.77958435, grad/param norm = 2.3647e-01, time/batch = 19.0440s	
27656/29850 (epoch 46.325), train_loss = 0.82764042, grad/param norm = 2.1001e-01, time/batch = 16.2199s	
27657/29850 (epoch 46.327), train_loss = 0.95537283, grad/param norm = 2.3699e-01, time/batch = 16.9425s	
27658/29850 (epoch 46.328), train_loss = 0.88397977, grad/param norm = 3.3118e-01, time/batch = 17.9538s	
27659/29850 (epoch 46.330), train_loss = 0.84054188, grad/param norm = 2.1622e-01, time/batch = 18.8012s	
27660/29850 (epoch 46.332), train_loss = 0.75422118, grad/param norm = 2.5087e-01, time/batch = 16.2128s	
27661/29850 (epoch 46.333), train_loss = 0.80635924, grad/param norm = 2.4966e-01, time/batch = 18.4681s	
27662/29850 (epoch 46.335), train_loss = 0.86681485, grad/param norm = 2.4009e-01, time/batch = 18.3728s	
27663/29850 (epoch 46.337), train_loss = 0.78283605, grad/param norm = 2.8476e-01, time/batch = 18.5531s	
27664/29850 (epoch 46.338), train_loss = 0.82972399, grad/param norm = 2.2210e-01, time/batch = 15.1688s	
27665/29850 (epoch 46.340), train_loss = 0.68059925, grad/param norm = 2.2130e-01, time/batch = 16.3151s	
27666/29850 (epoch 46.342), train_loss = 0.79248248, grad/param norm = 3.4775e-01, time/batch = 17.7987s	
27667/29850 (epoch 46.343), train_loss = 0.76563964, grad/param norm = 2.7379e-01, time/batch = 18.2132s	
27668/29850 (epoch 46.345), train_loss = 0.83786639, grad/param norm = 2.6009e-01, time/batch = 18.1928s	
27669/29850 (epoch 46.347), train_loss = 0.84284606, grad/param norm = 2.9565e-01, time/batch = 19.5532s	
27670/29850 (epoch 46.348), train_loss = 0.70428161, grad/param norm = 2.1312e-01, time/batch = 17.5471s	
27671/29850 (epoch 46.350), train_loss = 0.81020075, grad/param norm = 2.4176e-01, time/batch = 17.2953s	
27672/29850 (epoch 46.352), train_loss = 0.73688519, grad/param norm = 2.0276e-01, time/batch = 18.9562s	
27673/29850 (epoch 46.353), train_loss = 0.79283708, grad/param norm = 2.3526e-01, time/batch = 15.3097s	
27674/29850 (epoch 46.355), train_loss = 0.72315500, grad/param norm = 2.3255e-01, time/batch = 16.7149s	
27675/29850 (epoch 46.357), train_loss = 0.84846821, grad/param norm = 2.1224e-01, time/batch = 15.5433s	
27676/29850 (epoch 46.358), train_loss = 0.70732791, grad/param norm = 2.1928e-01, time/batch = 16.9724s	
27677/29850 (epoch 46.360), train_loss = 0.77937493, grad/param norm = 2.8003e-01, time/batch = 17.1182s	
27678/29850 (epoch 46.362), train_loss = 0.78039040, grad/param norm = 2.5480e-01, time/batch = 17.2905s	
27679/29850 (epoch 46.363), train_loss = 0.79731890, grad/param norm = 2.5294e-01, time/batch = 18.1262s	
27680/29850 (epoch 46.365), train_loss = 0.87959971, grad/param norm = 2.8068e-01, time/batch = 19.1418s	
27681/29850 (epoch 46.367), train_loss = 0.70384762, grad/param norm = 2.2000e-01, time/batch = 17.0995s	
27682/29850 (epoch 46.369), train_loss = 0.61593495, grad/param norm = 2.3879e-01, time/batch = 18.9653s	
27683/29850 (epoch 46.370), train_loss = 0.66247348, grad/param norm = 2.4841e-01, time/batch = 17.7010s	
27684/29850 (epoch 46.372), train_loss = 0.84707781, grad/param norm = 2.3073e-01, time/batch = 18.1158s	
27685/29850 (epoch 46.374), train_loss = 0.83524672, grad/param norm = 2.1491e-01, time/batch = 19.2053s	
27686/29850 (epoch 46.375), train_loss = 0.79545395, grad/param norm = 2.2357e-01, time/batch = 18.9438s	
27687/29850 (epoch 46.377), train_loss = 0.67082584, grad/param norm = 2.2102e-01, time/batch = 18.1840s	
27688/29850 (epoch 46.379), train_loss = 0.86459979, grad/param norm = 2.4727e-01, time/batch = 19.5402s	
27689/29850 (epoch 46.380), train_loss = 0.83121565, grad/param norm = 2.4881e-01, time/batch = 19.2900s	
27690/29850 (epoch 46.382), train_loss = 0.78815182, grad/param norm = 2.4665e-01, time/batch = 17.5059s	
27691/29850 (epoch 46.384), train_loss = 0.81280535, grad/param norm = 2.4176e-01, time/batch = 17.6255s	
27692/29850 (epoch 46.385), train_loss = 0.82339902, grad/param norm = 2.5305e-01, time/batch = 19.2127s	
27693/29850 (epoch 46.387), train_loss = 0.78874977, grad/param norm = 2.4936e-01, time/batch = 18.8612s	
27694/29850 (epoch 46.389), train_loss = 0.89133547, grad/param norm = 2.7718e-01, time/batch = 16.3690s	
27695/29850 (epoch 46.390), train_loss = 0.85849320, grad/param norm = 2.2229e-01, time/batch = 19.6067s	
27696/29850 (epoch 46.392), train_loss = 0.78409917, grad/param norm = 2.4860e-01, time/batch = 18.8858s	
27697/29850 (epoch 46.394), train_loss = 0.79959522, grad/param norm = 2.1964e-01, time/batch = 15.6792s	
27698/29850 (epoch 46.395), train_loss = 0.73677982, grad/param norm = 2.4890e-01, time/batch = 18.4645s	
27699/29850 (epoch 46.397), train_loss = 0.66443155, grad/param norm = 2.2842e-01, time/batch = 14.7441s	
27700/29850 (epoch 46.399), train_loss = 0.72451618, grad/param norm = 2.6146e-01, time/batch = 18.3685s	
27701/29850 (epoch 46.400), train_loss = 1.03831424, grad/param norm = 2.7919e-01, time/batch = 18.2751s	
27702/29850 (epoch 46.402), train_loss = 0.87137473, grad/param norm = 2.1892e-01, time/batch = 18.9591s	
27703/29850 (epoch 46.404), train_loss = 0.78698397, grad/param norm = 2.3717e-01, time/batch = 18.0409s	
27704/29850 (epoch 46.405), train_loss = 0.71149263, grad/param norm = 2.4971e-01, time/batch = 18.0354s	
27705/29850 (epoch 46.407), train_loss = 0.70127227, grad/param norm = 2.5236e-01, time/batch = 19.7888s	
27706/29850 (epoch 46.409), train_loss = 0.80708856, grad/param norm = 2.6466e-01, time/batch = 15.5403s	
27707/29850 (epoch 46.410), train_loss = 0.85528620, grad/param norm = 2.3759e-01, time/batch = 17.3010s	
27708/29850 (epoch 46.412), train_loss = 0.87807156, grad/param norm = 2.5543e-01, time/batch = 19.3784s	
27709/29850 (epoch 46.414), train_loss = 0.82244755, grad/param norm = 2.7779e-01, time/batch = 16.8542s	
27710/29850 (epoch 46.415), train_loss = 0.77100365, grad/param norm = 2.1308e-01, time/batch = 17.8845s	
27711/29850 (epoch 46.417), train_loss = 0.90699978, grad/param norm = 2.9221e-01, time/batch = 14.8118s	
27712/29850 (epoch 46.419), train_loss = 0.74436262, grad/param norm = 2.2243e-01, time/batch = 16.7417s	
27713/29850 (epoch 46.420), train_loss = 0.76015714, grad/param norm = 2.6446e-01, time/batch = 15.7215s	
27714/29850 (epoch 46.422), train_loss = 0.76164878, grad/param norm = 2.1728e-01, time/batch = 15.0931s	
27715/29850 (epoch 46.424), train_loss = 0.67853099, grad/param norm = 2.2220e-01, time/batch = 18.2777s	
27716/29850 (epoch 46.425), train_loss = 0.85604658, grad/param norm = 2.8457e-01, time/batch = 17.1165s	
27717/29850 (epoch 46.427), train_loss = 0.59433997, grad/param norm = 2.3451e-01, time/batch = 18.5328s	
27718/29850 (epoch 46.429), train_loss = 0.67237680, grad/param norm = 2.0880e-01, time/batch = 18.8641s	
27719/29850 (epoch 46.430), train_loss = 0.64158720, grad/param norm = 2.1729e-01, time/batch = 20.0307s	
27720/29850 (epoch 46.432), train_loss = 0.73309084, grad/param norm = 2.3133e-01, time/batch = 17.2894s	
27721/29850 (epoch 46.434), train_loss = 0.70059433, grad/param norm = 2.1036e-01, time/batch = 17.2829s	
27722/29850 (epoch 46.436), train_loss = 0.73417637, grad/param norm = 2.4629e-01, time/batch = 18.5473s	
27723/29850 (epoch 46.437), train_loss = 0.84180811, grad/param norm = 2.3621e-01, time/batch = 16.9671s	
27724/29850 (epoch 46.439), train_loss = 0.83192025, grad/param norm = 2.3495e-01, time/batch = 16.4581s	
27725/29850 (epoch 46.441), train_loss = 0.75423197, grad/param norm = 2.1801e-01, time/batch = 15.8010s	
27726/29850 (epoch 46.442), train_loss = 0.75663663, grad/param norm = 2.3107e-01, time/batch = 18.6290s	
27727/29850 (epoch 46.444), train_loss = 0.80138826, grad/param norm = 2.8783e-01, time/batch = 17.4736s	
27728/29850 (epoch 46.446), train_loss = 0.86356234, grad/param norm = 2.3809e-01, time/batch = 17.9445s	
27729/29850 (epoch 46.447), train_loss = 0.87704092, grad/param norm = 2.6165e-01, time/batch = 17.7863s	
27730/29850 (epoch 46.449), train_loss = 0.80197772, grad/param norm = 3.2859e-01, time/batch = 19.3688s	
27731/29850 (epoch 46.451), train_loss = 0.62619201, grad/param norm = 2.0650e-01, time/batch = 15.0158s	
27732/29850 (epoch 46.452), train_loss = 0.52908165, grad/param norm = 1.9449e-01, time/batch = 0.6636s	
27733/29850 (epoch 46.454), train_loss = 0.63286979, grad/param norm = 2.0416e-01, time/batch = 0.6492s	
27734/29850 (epoch 46.456), train_loss = 0.82839760, grad/param norm = 2.4840e-01, time/batch = 0.6463s	
27735/29850 (epoch 46.457), train_loss = 0.91210668, grad/param norm = 4.7004e-01, time/batch = 0.6397s	
27736/29850 (epoch 46.459), train_loss = 0.90528192, grad/param norm = 2.8597e-01, time/batch = 0.6587s	
27737/29850 (epoch 46.461), train_loss = 0.91815826, grad/param norm = 2.3274e-01, time/batch = 0.6484s	
27738/29850 (epoch 46.462), train_loss = 0.93572306, grad/param norm = 2.5495e-01, time/batch = 0.6380s	
27739/29850 (epoch 46.464), train_loss = 0.82579924, grad/param norm = 2.3774e-01, time/batch = 0.7747s	
27740/29850 (epoch 46.466), train_loss = 0.69264775, grad/param norm = 2.4814e-01, time/batch = 0.9577s	
27741/29850 (epoch 46.467), train_loss = 0.70820396, grad/param norm = 2.1548e-01, time/batch = 0.9627s	
27742/29850 (epoch 46.469), train_loss = 0.74848941, grad/param norm = 2.0961e-01, time/batch = 0.9515s	
27743/29850 (epoch 46.471), train_loss = 0.76939706, grad/param norm = 2.3741e-01, time/batch = 0.9412s	
27744/29850 (epoch 46.472), train_loss = 0.72641558, grad/param norm = 2.1815e-01, time/batch = 1.1709s	
27745/29850 (epoch 46.474), train_loss = 0.84954718, grad/param norm = 2.5803e-01, time/batch = 1.7626s	
27746/29850 (epoch 46.476), train_loss = 0.79389803, grad/param norm = 2.3735e-01, time/batch = 1.7873s	
27747/29850 (epoch 46.477), train_loss = 0.82663190, grad/param norm = 3.2929e-01, time/batch = 8.0759s	
27748/29850 (epoch 46.479), train_loss = 0.93343226, grad/param norm = 2.3602e-01, time/batch = 18.0355s	
27749/29850 (epoch 46.481), train_loss = 0.78709829, grad/param norm = 2.1054e-01, time/batch = 16.3119s	
27750/29850 (epoch 46.482), train_loss = 0.72290303, grad/param norm = 2.0710e-01, time/batch = 16.4402s	
27751/29850 (epoch 46.484), train_loss = 0.74212846, grad/param norm = 2.1207e-01, time/batch = 19.3733s	
27752/29850 (epoch 46.486), train_loss = 0.79444797, grad/param norm = 2.7783e-01, time/batch = 18.2136s	
27753/29850 (epoch 46.487), train_loss = 0.77167415, grad/param norm = 2.3645e-01, time/batch = 19.3456s	
27754/29850 (epoch 46.489), train_loss = 0.78041053, grad/param norm = 2.6795e-01, time/batch = 17.9699s	
27755/29850 (epoch 46.491), train_loss = 0.69939689, grad/param norm = 2.1936e-01, time/batch = 17.1319s	
27756/29850 (epoch 46.492), train_loss = 0.79646962, grad/param norm = 2.7725e-01, time/batch = 17.6985s	
27757/29850 (epoch 46.494), train_loss = 0.84354411, grad/param norm = 2.4614e-01, time/batch = 17.0830s	
27758/29850 (epoch 46.496), train_loss = 0.89134785, grad/param norm = 2.3509e-01, time/batch = 19.3734s	
27759/29850 (epoch 46.497), train_loss = 0.82466534, grad/param norm = 2.6753e-01, time/batch = 16.9451s	
27760/29850 (epoch 46.499), train_loss = 0.78807237, grad/param norm = 2.4027e-01, time/batch = 17.5380s	
27761/29850 (epoch 46.501), train_loss = 0.68918345, grad/param norm = 3.4735e-01, time/batch = 19.0401s	
27762/29850 (epoch 46.503), train_loss = 0.89218038, grad/param norm = 2.6454e-01, time/batch = 19.1050s	
27763/29850 (epoch 46.504), train_loss = 1.03831492, grad/param norm = 2.7161e-01, time/batch = 17.5291s	
27764/29850 (epoch 46.506), train_loss = 0.99032259, grad/param norm = 2.6677e-01, time/batch = 18.0568s	
27765/29850 (epoch 46.508), train_loss = 0.81889400, grad/param norm = 2.3440e-01, time/batch = 18.2159s	
27766/29850 (epoch 46.509), train_loss = 0.61201014, grad/param norm = 2.1295e-01, time/batch = 15.7929s	
27767/29850 (epoch 46.511), train_loss = 0.81966615, grad/param norm = 2.4284e-01, time/batch = 16.0994s	
27768/29850 (epoch 46.513), train_loss = 0.78250292, grad/param norm = 3.1396e-01, time/batch = 17.6792s	
27769/29850 (epoch 46.514), train_loss = 0.68919961, grad/param norm = 2.3130e-01, time/batch = 16.0344s	
27770/29850 (epoch 46.516), train_loss = 0.72991333, grad/param norm = 1.9435e-01, time/batch = 18.3936s	
27771/29850 (epoch 46.518), train_loss = 0.62775278, grad/param norm = 2.0949e-01, time/batch = 18.8733s	
27772/29850 (epoch 46.519), train_loss = 0.64587438, grad/param norm = 2.0838e-01, time/batch = 16.8007s	
27773/29850 (epoch 46.521), train_loss = 0.58910150, grad/param norm = 1.7630e-01, time/batch = 16.8805s	
27774/29850 (epoch 46.523), train_loss = 0.64496797, grad/param norm = 2.0756e-01, time/batch = 18.7138s	
27775/29850 (epoch 46.524), train_loss = 0.65715098, grad/param norm = 2.2845e-01, time/batch = 17.6452s	
27776/29850 (epoch 46.526), train_loss = 0.71109711, grad/param norm = 2.5475e-01, time/batch = 18.1291s	
27777/29850 (epoch 46.528), train_loss = 0.81539562, grad/param norm = 2.5110e-01, time/batch = 18.2705s	
27778/29850 (epoch 46.529), train_loss = 0.79955350, grad/param norm = 2.2794e-01, time/batch = 18.5541s	
27779/29850 (epoch 46.531), train_loss = 0.75212947, grad/param norm = 2.6377e-01, time/batch = 17.7815s	
27780/29850 (epoch 46.533), train_loss = 0.78801646, grad/param norm = 2.5133e-01, time/batch = 18.2014s	
27781/29850 (epoch 46.534), train_loss = 0.81873394, grad/param norm = 2.3487e-01, time/batch = 15.8670s	
27782/29850 (epoch 46.536), train_loss = 0.74430665, grad/param norm = 2.8833e-01, time/batch = 18.9594s	
27783/29850 (epoch 46.538), train_loss = 0.89094184, grad/param norm = 2.6345e-01, time/batch = 17.8542s	
27784/29850 (epoch 46.539), train_loss = 0.90060796, grad/param norm = 2.5492e-01, time/batch = 16.2638s	
27785/29850 (epoch 46.541), train_loss = 0.55540783, grad/param norm = 1.9376e-01, time/batch = 18.5289s	
27786/29850 (epoch 46.543), train_loss = 0.72392406, grad/param norm = 2.2627e-01, time/batch = 16.8656s	
27787/29850 (epoch 46.544), train_loss = 0.88653370, grad/param norm = 2.9357e-01, time/batch = 18.3722s	
27788/29850 (epoch 46.546), train_loss = 0.85781088, grad/param norm = 2.2623e-01, time/batch = 18.3850s	
27789/29850 (epoch 46.548), train_loss = 0.63081039, grad/param norm = 1.9326e-01, time/batch = 17.5232s	
27790/29850 (epoch 46.549), train_loss = 0.73994424, grad/param norm = 2.0172e-01, time/batch = 17.4505s	
27791/29850 (epoch 46.551), train_loss = 0.68885252, grad/param norm = 2.1289e-01, time/batch = 19.3747s	
27792/29850 (epoch 46.553), train_loss = 0.75852789, grad/param norm = 2.1155e-01, time/batch = 18.4003s	
27793/29850 (epoch 46.554), train_loss = 0.63405204, grad/param norm = 1.9932e-01, time/batch = 16.5948s	
27794/29850 (epoch 46.556), train_loss = 0.66217168, grad/param norm = 2.3216e-01, time/batch = 17.7158s	
27795/29850 (epoch 46.558), train_loss = 0.68717953, grad/param norm = 2.2877e-01, time/batch = 19.7846s	
27796/29850 (epoch 46.559), train_loss = 0.68019253, grad/param norm = 2.2215e-01, time/batch = 26.7598s	
27797/29850 (epoch 46.561), train_loss = 0.77496862, grad/param norm = 2.2525e-01, time/batch = 23.5689s	
27798/29850 (epoch 46.563), train_loss = 0.79493959, grad/param norm = 2.2258e-01, time/batch = 15.3666s	
27799/29850 (epoch 46.564), train_loss = 0.72679395, grad/param norm = 2.1994e-01, time/batch = 15.6135s	
27800/29850 (epoch 46.566), train_loss = 0.75943373, grad/param norm = 2.1481e-01, time/batch = 17.8757s	
27801/29850 (epoch 46.568), train_loss = 0.90747867, grad/param norm = 2.6311e-01, time/batch = 17.1160s	
27802/29850 (epoch 46.570), train_loss = 0.78278021, grad/param norm = 2.4417e-01, time/batch = 16.1430s	
27803/29850 (epoch 46.571), train_loss = 0.83111144, grad/param norm = 2.1497e-01, time/batch = 14.9190s	
27804/29850 (epoch 46.573), train_loss = 0.88139755, grad/param norm = 2.5306e-01, time/batch = 16.8054s	
27805/29850 (epoch 46.575), train_loss = 0.93437401, grad/param norm = 2.2788e-01, time/batch = 17.2026s	
27806/29850 (epoch 46.576), train_loss = 0.84679281, grad/param norm = 2.5889e-01, time/batch = 15.8700s	
27807/29850 (epoch 46.578), train_loss = 0.70747448, grad/param norm = 2.1227e-01, time/batch = 19.8629s	
27808/29850 (epoch 46.580), train_loss = 0.84967722, grad/param norm = 2.3019e-01, time/batch = 18.4609s	
27809/29850 (epoch 46.581), train_loss = 0.71051951, grad/param norm = 2.0227e-01, time/batch = 17.1948s	
27810/29850 (epoch 46.583), train_loss = 0.76061598, grad/param norm = 2.3100e-01, time/batch = 19.7005s	
27811/29850 (epoch 46.585), train_loss = 0.78062334, grad/param norm = 2.2172e-01, time/batch = 18.2864s	
27812/29850 (epoch 46.586), train_loss = 0.81965054, grad/param norm = 2.5059e-01, time/batch = 18.3664s	
27813/29850 (epoch 46.588), train_loss = 0.69641165, grad/param norm = 2.2008e-01, time/batch = 16.0541s	
27814/29850 (epoch 46.590), train_loss = 0.71017978, grad/param norm = 1.9171e-01, time/batch = 19.2047s	
27815/29850 (epoch 46.591), train_loss = 0.77203261, grad/param norm = 2.3828e-01, time/batch = 19.3830s	
27816/29850 (epoch 46.593), train_loss = 0.68627825, grad/param norm = 2.5202e-01, time/batch = 16.0202s	
27817/29850 (epoch 46.595), train_loss = 0.63714863, grad/param norm = 1.9680e-01, time/batch = 18.1101s	
27818/29850 (epoch 46.596), train_loss = 0.68566840, grad/param norm = 2.2234e-01, time/batch = 17.1344s	
27819/29850 (epoch 46.598), train_loss = 0.75551946, grad/param norm = 2.2479e-01, time/batch = 16.9443s	
27820/29850 (epoch 46.600), train_loss = 0.79343385, grad/param norm = 2.1966e-01, time/batch = 18.6161s	
27821/29850 (epoch 46.601), train_loss = 0.65063402, grad/param norm = 1.7984e-01, time/batch = 18.7293s	
27822/29850 (epoch 46.603), train_loss = 0.71213246, grad/param norm = 2.6102e-01, time/batch = 16.6249s	
27823/29850 (epoch 46.605), train_loss = 0.73411278, grad/param norm = 2.2831e-01, time/batch = 16.5148s	
27824/29850 (epoch 46.606), train_loss = 0.50094768, grad/param norm = 1.9830e-01, time/batch = 18.8776s	
27825/29850 (epoch 46.608), train_loss = 0.65787520, grad/param norm = 2.0814e-01, time/batch = 18.1363s	
27826/29850 (epoch 46.610), train_loss = 0.69914857, grad/param norm = 2.1931e-01, time/batch = 16.3057s	
27827/29850 (epoch 46.611), train_loss = 0.63632350, grad/param norm = 1.7180e-01, time/batch = 20.3506s	
27828/29850 (epoch 46.613), train_loss = 0.55902919, grad/param norm = 1.7719e-01, time/batch = 19.1292s	
27829/29850 (epoch 46.615), train_loss = 0.59944519, grad/param norm = 1.8829e-01, time/batch = 16.7778s	
27830/29850 (epoch 46.616), train_loss = 0.63103171, grad/param norm = 2.1115e-01, time/batch = 14.9928s	
27831/29850 (epoch 46.618), train_loss = 0.68973342, grad/param norm = 2.1580e-01, time/batch = 16.6339s	
27832/29850 (epoch 46.620), train_loss = 0.78468620, grad/param norm = 2.4119e-01, time/batch = 16.6114s	
27833/29850 (epoch 46.621), train_loss = 0.85413162, grad/param norm = 2.6475e-01, time/batch = 16.7135s	
27834/29850 (epoch 46.623), train_loss = 0.83627471, grad/param norm = 2.3882e-01, time/batch = 19.4648s	
27835/29850 (epoch 46.625), train_loss = 0.76001932, grad/param norm = 2.1253e-01, time/batch = 17.7235s	
27836/29850 (epoch 46.626), train_loss = 0.74309755, grad/param norm = 2.1558e-01, time/batch = 18.1217s	
27837/29850 (epoch 46.628), train_loss = 0.75256272, grad/param norm = 2.4783e-01, time/batch = 17.7119s	
27838/29850 (epoch 46.630), train_loss = 0.77564833, grad/param norm = 2.5505e-01, time/batch = 18.8791s	
27839/29850 (epoch 46.631), train_loss = 0.80244626, grad/param norm = 2.6619e-01, time/batch = 15.7546s	
27840/29850 (epoch 46.633), train_loss = 0.78761306, grad/param norm = 2.6070e-01, time/batch = 15.9589s	
27841/29850 (epoch 46.635), train_loss = 0.73491892, grad/param norm = 2.7227e-01, time/batch = 18.8928s	
27842/29850 (epoch 46.637), train_loss = 0.67190859, grad/param norm = 2.1460e-01, time/batch = 16.5622s	
27843/29850 (epoch 46.638), train_loss = 0.79265008, grad/param norm = 2.3732e-01, time/batch = 17.7109s	
27844/29850 (epoch 46.640), train_loss = 0.91012791, grad/param norm = 2.9640e-01, time/batch = 18.9510s	
27845/29850 (epoch 46.642), train_loss = 0.72735485, grad/param norm = 2.0894e-01, time/batch = 17.2168s	
27846/29850 (epoch 46.643), train_loss = 0.67130651, grad/param norm = 2.3995e-01, time/batch = 16.8087s	
27847/29850 (epoch 46.645), train_loss = 0.74820028, grad/param norm = 2.3996e-01, time/batch = 15.0958s	
27848/29850 (epoch 46.647), train_loss = 0.84745666, grad/param norm = 2.7401e-01, time/batch = 15.0144s	
27849/29850 (epoch 46.648), train_loss = 0.68236747, grad/param norm = 2.2690e-01, time/batch = 16.8635s	
27850/29850 (epoch 46.650), train_loss = 0.78976872, grad/param norm = 2.4618e-01, time/batch = 17.3687s	
27851/29850 (epoch 46.652), train_loss = 0.76143612, grad/param norm = 2.4245e-01, time/batch = 19.1972s	
27852/29850 (epoch 46.653), train_loss = 0.84978598, grad/param norm = 2.9634e-01, time/batch = 17.2205s	
27853/29850 (epoch 46.655), train_loss = 0.77407781, grad/param norm = 1.9669e-01, time/batch = 17.7036s	
27854/29850 (epoch 46.657), train_loss = 0.75306310, grad/param norm = 2.2038e-01, time/batch = 17.4601s	
27855/29850 (epoch 46.658), train_loss = 0.85455402, grad/param norm = 2.5528e-01, time/batch = 18.8819s	
27856/29850 (epoch 46.660), train_loss = 0.72280408, grad/param norm = 2.0718e-01, time/batch = 15.8122s	
27857/29850 (epoch 46.662), train_loss = 0.86898918, grad/param norm = 2.7135e-01, time/batch = 16.2840s	
27858/29850 (epoch 46.663), train_loss = 0.95876428, grad/param norm = 2.2633e-01, time/batch = 17.5913s	
27859/29850 (epoch 46.665), train_loss = 0.89297018, grad/param norm = 2.4050e-01, time/batch = 16.9262s	
27860/29850 (epoch 46.667), train_loss = 0.81571485, grad/param norm = 2.8799e-01, time/batch = 17.6075s	
27861/29850 (epoch 46.668), train_loss = 0.72460139, grad/param norm = 2.8262e-01, time/batch = 19.2056s	
27862/29850 (epoch 46.670), train_loss = 0.82632037, grad/param norm = 2.6384e-01, time/batch = 16.9785s	
27863/29850 (epoch 46.672), train_loss = 0.83985912, grad/param norm = 2.5279e-01, time/batch = 18.3712s	
27864/29850 (epoch 46.673), train_loss = 0.78418941, grad/param norm = 2.6072e-01, time/batch = 16.5371s	
27865/29850 (epoch 46.675), train_loss = 0.70107640, grad/param norm = 2.2847e-01, time/batch = 17.9624s	
27866/29850 (epoch 46.677), train_loss = 0.71681508, grad/param norm = 2.0967e-01, time/batch = 16.3852s	
27867/29850 (epoch 46.678), train_loss = 0.77997953, grad/param norm = 2.4919e-01, time/batch = 16.7993s	
27868/29850 (epoch 46.680), train_loss = 0.74784428, grad/param norm = 2.3087e-01, time/batch = 17.8765s	
27869/29850 (epoch 46.682), train_loss = 0.75094379, grad/param norm = 2.0931e-01, time/batch = 16.7023s	
27870/29850 (epoch 46.683), train_loss = 0.86721616, grad/param norm = 2.7947e-01, time/batch = 17.7841s	
27871/29850 (epoch 46.685), train_loss = 0.96399814, grad/param norm = 2.5774e-01, time/batch = 15.4204s	
27872/29850 (epoch 46.687), train_loss = 0.80267408, grad/param norm = 2.2982e-01, time/batch = 18.5478s	
27873/29850 (epoch 46.688), train_loss = 0.68884303, grad/param norm = 2.7624e-01, time/batch = 15.3807s	
27874/29850 (epoch 46.690), train_loss = 0.68266944, grad/param norm = 2.0200e-01, time/batch = 16.2638s	
27875/29850 (epoch 46.692), train_loss = 0.88620591, grad/param norm = 2.4866e-01, time/batch = 17.4511s	
27876/29850 (epoch 46.693), train_loss = 0.75741709, grad/param norm = 1.9901e-01, time/batch = 19.6107s	
27877/29850 (epoch 46.695), train_loss = 0.69473886, grad/param norm = 1.9383e-01, time/batch = 17.3773s	
27878/29850 (epoch 46.697), train_loss = 0.75044294, grad/param norm = 2.2513e-01, time/batch = 17.6135s	
27879/29850 (epoch 46.698), train_loss = 0.87742213, grad/param norm = 2.2513e-01, time/batch = 18.1296s	
27880/29850 (epoch 46.700), train_loss = 0.81870955, grad/param norm = 2.8783e-01, time/batch = 17.6338s	
27881/29850 (epoch 46.702), train_loss = 0.80370034, grad/param norm = 2.9724e-01, time/batch = 16.2790s	
27882/29850 (epoch 46.704), train_loss = 0.67624262, grad/param norm = 2.3002e-01, time/batch = 18.4424s	
27883/29850 (epoch 46.705), train_loss = 0.76401112, grad/param norm = 2.4104e-01, time/batch = 17.2144s	
27884/29850 (epoch 46.707), train_loss = 0.72205923, grad/param norm = 2.5713e-01, time/batch = 18.3627s	
27885/29850 (epoch 46.709), train_loss = 0.74409144, grad/param norm = 2.3671e-01, time/batch = 17.6226s	
27886/29850 (epoch 46.710), train_loss = 0.70224537, grad/param norm = 2.1958e-01, time/batch = 17.1399s	
27887/29850 (epoch 46.712), train_loss = 0.81300820, grad/param norm = 2.1680e-01, time/batch = 16.7659s	
27888/29850 (epoch 46.714), train_loss = 0.84647007, grad/param norm = 2.8155e-01, time/batch = 15.2722s	
27889/29850 (epoch 46.715), train_loss = 0.79515672, grad/param norm = 2.3097e-01, time/batch = 18.5447s	
27890/29850 (epoch 46.717), train_loss = 0.59381753, grad/param norm = 3.0854e-01, time/batch = 15.8051s	
27891/29850 (epoch 46.719), train_loss = 0.73351562, grad/param norm = 2.2043e-01, time/batch = 17.7722s	
27892/29850 (epoch 46.720), train_loss = 0.75558578, grad/param norm = 2.1226e-01, time/batch = 18.2219s	
27893/29850 (epoch 46.722), train_loss = 0.70915426, grad/param norm = 1.9029e-01, time/batch = 18.7149s	
27894/29850 (epoch 46.724), train_loss = 0.78591790, grad/param norm = 2.4341e-01, time/batch = 19.2882s	
27895/29850 (epoch 46.725), train_loss = 0.66029239, grad/param norm = 1.9491e-01, time/batch = 18.5170s	
27896/29850 (epoch 46.727), train_loss = 0.64641726, grad/param norm = 2.4592e-01, time/batch = 18.9378s	
27897/29850 (epoch 46.729), train_loss = 0.63096863, grad/param norm = 1.6240e-01, time/batch = 19.2691s	
27898/29850 (epoch 46.730), train_loss = 0.60186463, grad/param norm = 2.1918e-01, time/batch = 15.4641s	
27899/29850 (epoch 46.732), train_loss = 0.82749905, grad/param norm = 2.1882e-01, time/batch = 18.1294s	
27900/29850 (epoch 46.734), train_loss = 0.91872975, grad/param norm = 2.7816e-01, time/batch = 15.9477s	
27901/29850 (epoch 46.735), train_loss = 0.69178833, grad/param norm = 2.2553e-01, time/batch = 18.1200s	
27902/29850 (epoch 46.737), train_loss = 0.67106739, grad/param norm = 2.1523e-01, time/batch = 16.5376s	
27903/29850 (epoch 46.739), train_loss = 0.57449194, grad/param norm = 1.9176e-01, time/batch = 19.1087s	
27904/29850 (epoch 46.740), train_loss = 0.61035041, grad/param norm = 2.4629e-01, time/batch = 16.5425s	
27905/29850 (epoch 46.742), train_loss = 0.55385425, grad/param norm = 1.8358e-01, time/batch = 17.1222s	
27906/29850 (epoch 46.744), train_loss = 0.67596503, grad/param norm = 2.1484e-01, time/batch = 19.8596s	
27907/29850 (epoch 46.745), train_loss = 0.70968620, grad/param norm = 2.6286e-01, time/batch = 16.2124s	
27908/29850 (epoch 46.747), train_loss = 0.73143512, grad/param norm = 2.2493e-01, time/batch = 15.8692s	
27909/29850 (epoch 46.749), train_loss = 0.62913177, grad/param norm = 2.2402e-01, time/batch = 18.2187s	
27910/29850 (epoch 46.750), train_loss = 0.58719166, grad/param norm = 2.4147e-01, time/batch = 17.3036s	
27911/29850 (epoch 46.752), train_loss = 0.49608194, grad/param norm = 1.7943e-01, time/batch = 17.3867s	
27912/29850 (epoch 46.754), train_loss = 0.56358776, grad/param norm = 2.1836e-01, time/batch = 18.9474s	
27913/29850 (epoch 46.755), train_loss = 0.56999876, grad/param norm = 2.4258e-01, time/batch = 18.2934s	
27914/29850 (epoch 46.757), train_loss = 0.62892160, grad/param norm = 1.8576e-01, time/batch = 17.3094s	
27915/29850 (epoch 46.759), train_loss = 0.63658783, grad/param norm = 1.9508e-01, time/batch = 15.5401s	
27916/29850 (epoch 46.760), train_loss = 0.66907170, grad/param norm = 2.1989e-01, time/batch = 18.2284s	
27917/29850 (epoch 46.762), train_loss = 0.63170223, grad/param norm = 4.9675e-01, time/batch = 16.5583s	
27918/29850 (epoch 46.764), train_loss = 0.54692354, grad/param norm = 2.1120e-01, time/batch = 16.6124s	
27919/29850 (epoch 46.765), train_loss = 0.68583414, grad/param norm = 2.2261e-01, time/batch = 17.7664s	
27920/29850 (epoch 46.767), train_loss = 0.69495179, grad/param norm = 2.2198e-01, time/batch = 17.7023s	
27921/29850 (epoch 46.769), train_loss = 0.74011179, grad/param norm = 2.5107e-01, time/batch = 15.1314s	
27922/29850 (epoch 46.771), train_loss = 0.74397636, grad/param norm = 2.5392e-01, time/batch = 16.6882s	
27923/29850 (epoch 46.772), train_loss = 0.71582273, grad/param norm = 2.4142e-01, time/batch = 16.7883s	
27924/29850 (epoch 46.774), train_loss = 0.66144332, grad/param norm = 2.4268e-01, time/batch = 17.3808s	
27925/29850 (epoch 46.776), train_loss = 0.68708933, grad/param norm = 2.2646e-01, time/batch = 17.1909s	
27926/29850 (epoch 46.777), train_loss = 0.79525289, grad/param norm = 2.4395e-01, time/batch = 17.3825s	
27927/29850 (epoch 46.779), train_loss = 0.66104966, grad/param norm = 2.1366e-01, time/batch = 17.9697s	
27928/29850 (epoch 46.781), train_loss = 0.76271136, grad/param norm = 2.3403e-01, time/batch = 16.8176s	
27929/29850 (epoch 46.782), train_loss = 0.76284570, grad/param norm = 2.2056e-01, time/batch = 16.3922s	
27930/29850 (epoch 46.784), train_loss = 0.59852535, grad/param norm = 3.4618e-01, time/batch = 18.8767s	
27931/29850 (epoch 46.786), train_loss = 0.67661181, grad/param norm = 2.1483e-01, time/batch = 19.5424s	
27932/29850 (epoch 46.787), train_loss = 0.57019356, grad/param norm = 2.4249e-01, time/batch = 16.5455s	
27933/29850 (epoch 46.789), train_loss = 0.57378538, grad/param norm = 1.9578e-01, time/batch = 17.0592s	
27934/29850 (epoch 46.791), train_loss = 0.64288725, grad/param norm = 3.2946e-01, time/batch = 16.2292s	
27935/29850 (epoch 46.792), train_loss = 0.76636141, grad/param norm = 2.5560e-01, time/batch = 14.8228s	
27936/29850 (epoch 46.794), train_loss = 0.71035170, grad/param norm = 2.2588e-01, time/batch = 15.9572s	
27937/29850 (epoch 46.796), train_loss = 0.62387074, grad/param norm = 1.8602e-01, time/batch = 19.5519s	
27938/29850 (epoch 46.797), train_loss = 0.55372614, grad/param norm = 2.4564e-01, time/batch = 19.4589s	
27939/29850 (epoch 46.799), train_loss = 0.58150722, grad/param norm = 1.8418e-01, time/batch = 15.5765s	
27940/29850 (epoch 46.801), train_loss = 0.59070851, grad/param norm = 1.9265e-01, time/batch = 19.7767s	
27941/29850 (epoch 46.802), train_loss = 0.58215598, grad/param norm = 2.3465e-01, time/batch = 17.1981s	
27942/29850 (epoch 46.804), train_loss = 0.63404056, grad/param norm = 2.1427e-01, time/batch = 17.4525s	
27943/29850 (epoch 46.806), train_loss = 0.54868537, grad/param norm = 1.8465e-01, time/batch = 16.2950s	
27944/29850 (epoch 46.807), train_loss = 0.60376621, grad/param norm = 2.0486e-01, time/batch = 17.5388s	
27945/29850 (epoch 46.809), train_loss = 0.61088925, grad/param norm = 2.5103e-01, time/batch = 18.7933s	
27946/29850 (epoch 46.811), train_loss = 0.77577686, grad/param norm = 2.9740e-01, time/batch = 16.6343s	
27947/29850 (epoch 46.812), train_loss = 0.74424308, grad/param norm = 2.5647e-01, time/batch = 14.5805s	
27948/29850 (epoch 46.814), train_loss = 0.78247246, grad/param norm = 3.1072e-01, time/batch = 17.2213s	
27949/29850 (epoch 46.816), train_loss = 0.84059749, grad/param norm = 2.2393e-01, time/batch = 16.8051s	
27950/29850 (epoch 46.817), train_loss = 0.73374373, grad/param norm = 2.9806e-01, time/batch = 16.6329s	
27951/29850 (epoch 46.819), train_loss = 0.57163152, grad/param norm = 2.1354e-01, time/batch = 17.9737s	
27952/29850 (epoch 46.821), train_loss = 0.83341430, grad/param norm = 3.5812e-01, time/batch = 17.1346s	
27953/29850 (epoch 46.822), train_loss = 0.85946301, grad/param norm = 2.7262e-01, time/batch = 18.1095s	
27954/29850 (epoch 46.824), train_loss = 0.71546708, grad/param norm = 2.0440e-01, time/batch = 18.6272s	
27955/29850 (epoch 46.826), train_loss = 0.63958018, grad/param norm = 2.5370e-01, time/batch = 18.8781s	
27956/29850 (epoch 46.827), train_loss = 0.56589018, grad/param norm = 2.4126e-01, time/batch = 18.2889s	
27957/29850 (epoch 46.829), train_loss = 0.73122124, grad/param norm = 2.7741e-01, time/batch = 18.9420s	
27958/29850 (epoch 46.831), train_loss = 0.83964721, grad/param norm = 2.6013e-01, time/batch = 15.8417s	
27959/29850 (epoch 46.832), train_loss = 0.72314149, grad/param norm = 2.2041e-01, time/batch = 16.8081s	
27960/29850 (epoch 46.834), train_loss = 0.54341704, grad/param norm = 1.7494e-01, time/batch = 17.2835s	
27961/29850 (epoch 46.836), train_loss = 0.55602676, grad/param norm = 1.9324e-01, time/batch = 17.4695s	
27962/29850 (epoch 46.838), train_loss = 0.65118550, grad/param norm = 2.2029e-01, time/batch = 18.4624s	
27963/29850 (epoch 46.839), train_loss = 0.56486029, grad/param norm = 2.1690e-01, time/batch = 16.5997s	
27964/29850 (epoch 46.841), train_loss = 0.63382940, grad/param norm = 1.9442e-01, time/batch = 17.7218s	
27965/29850 (epoch 46.843), train_loss = 0.55909818, grad/param norm = 2.0744e-01, time/batch = 18.4589s	
27966/29850 (epoch 46.844), train_loss = 0.60266169, grad/param norm = 2.0246e-01, time/batch = 18.7770s	
27967/29850 (epoch 46.846), train_loss = 0.67678129, grad/param norm = 2.3356e-01, time/batch = 16.1448s	
27968/29850 (epoch 46.848), train_loss = 0.74843830, grad/param norm = 3.1684e-01, time/batch = 18.0987s	
27969/29850 (epoch 46.849), train_loss = 0.67632638, grad/param norm = 2.0973e-01, time/batch = 16.3975s	
27970/29850 (epoch 46.851), train_loss = 0.86363230, grad/param norm = 2.4620e-01, time/batch = 17.2010s	
27971/29850 (epoch 46.853), train_loss = 0.68745719, grad/param norm = 2.7569e-01, time/batch = 18.7856s	
27972/29850 (epoch 46.854), train_loss = 0.83721784, grad/param norm = 2.5911e-01, time/batch = 15.0535s	
27973/29850 (epoch 46.856), train_loss = 0.82334905, grad/param norm = 2.6428e-01, time/batch = 17.2085s	
27974/29850 (epoch 46.858), train_loss = 0.73623279, grad/param norm = 4.0691e-01, time/batch = 16.9710s	
27975/29850 (epoch 46.859), train_loss = 0.63552366, grad/param norm = 2.2782e-01, time/batch = 16.7199s	
27976/29850 (epoch 46.861), train_loss = 0.80021842, grad/param norm = 2.6511e-01, time/batch = 16.8004s	
27977/29850 (epoch 46.863), train_loss = 0.81782303, grad/param norm = 3.0651e-01, time/batch = 17.5427s	
27978/29850 (epoch 46.864), train_loss = 0.84716107, grad/param norm = 3.1293e-01, time/batch = 19.3018s	
27979/29850 (epoch 46.866), train_loss = 0.74122026, grad/param norm = 2.6840e-01, time/batch = 17.9608s	
27980/29850 (epoch 46.868), train_loss = 0.91830778, grad/param norm = 3.0803e-01, time/batch = 17.1159s	
27981/29850 (epoch 46.869), train_loss = 0.84753013, grad/param norm = 3.6517e-01, time/batch = 19.7004s	
27982/29850 (epoch 46.871), train_loss = 0.81384641, grad/param norm = 2.7935e-01, time/batch = 19.5439s	
27983/29850 (epoch 46.873), train_loss = 0.79110514, grad/param norm = 2.6502e-01, time/batch = 16.9608s	
27984/29850 (epoch 46.874), train_loss = 0.79062407, grad/param norm = 2.4830e-01, time/batch = 16.5563s	
27985/29850 (epoch 46.876), train_loss = 0.76344272, grad/param norm = 3.0725e-01, time/batch = 17.3069s	
27986/29850 (epoch 46.878), train_loss = 0.75386845, grad/param norm = 2.2637e-01, time/batch = 17.5618s	
27987/29850 (epoch 46.879), train_loss = 0.79596468, grad/param norm = 2.5742e-01, time/batch = 17.2887s	
27988/29850 (epoch 46.881), train_loss = 0.82460167, grad/param norm = 2.5871e-01, time/batch = 17.2142s	
27989/29850 (epoch 46.883), train_loss = 0.76604006, grad/param norm = 2.5054e-01, time/batch = 19.5431s	
27990/29850 (epoch 46.884), train_loss = 0.66356857, grad/param norm = 2.4024e-01, time/batch = 17.0154s	
27991/29850 (epoch 46.886), train_loss = 0.83125979, grad/param norm = 3.2477e-01, time/batch = 19.2616s	
27992/29850 (epoch 46.888), train_loss = 0.76184705, grad/param norm = 2.6946e-01, time/batch = 15.7014s	
27993/29850 (epoch 46.889), train_loss = 0.70302222, grad/param norm = 2.2505e-01, time/batch = 17.2152s	
27994/29850 (epoch 46.891), train_loss = 0.65960632, grad/param norm = 2.0951e-01, time/batch = 17.9462s	
27995/29850 (epoch 46.893), train_loss = 0.70440249, grad/param norm = 2.8402e-01, time/batch = 18.6372s	
27996/29850 (epoch 46.894), train_loss = 0.71128211, grad/param norm = 2.4561e-01, time/batch = 17.6229s	
27997/29850 (epoch 46.896), train_loss = 0.76236525, grad/param norm = 2.7385e-01, time/batch = 17.2881s	
27998/29850 (epoch 46.898), train_loss = 0.89573497, grad/param norm = 2.5596e-01, time/batch = 19.7857s	
27999/29850 (epoch 46.899), train_loss = 0.65410461, grad/param norm = 2.3094e-01, time/batch = 18.2900s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch46.90_1.9305.t7	
28000/29850 (epoch 46.901), train_loss = 0.93096236, grad/param norm = 3.6687e-01, time/batch = 22.4625s	
28001/29850 (epoch 46.903), train_loss = 1.77701729, grad/param norm = 6.6129e-01, time/batch = 18.2039s	
28002/29850 (epoch 46.905), train_loss = 1.00218611, grad/param norm = 2.8712e-01, time/batch = 15.6202s	
28003/29850 (epoch 46.906), train_loss = 0.75735260, grad/param norm = 3.0639e-01, time/batch = 19.2124s	
28004/29850 (epoch 46.908), train_loss = 0.90831392, grad/param norm = 2.7122e-01, time/batch = 17.8864s	
28005/29850 (epoch 46.910), train_loss = 0.83655008, grad/param norm = 2.4599e-01, time/batch = 17.9463s	
28006/29850 (epoch 46.911), train_loss = 0.97445924, grad/param norm = 2.5497e-01, time/batch = 17.9654s	
28007/29850 (epoch 46.913), train_loss = 0.91070534, grad/param norm = 2.8519e-01, time/batch = 17.9598s	
28008/29850 (epoch 46.915), train_loss = 0.90568077, grad/param norm = 2.6390e-01, time/batch = 18.3788s	
28009/29850 (epoch 46.916), train_loss = 0.86656155, grad/param norm = 2.4272e-01, time/batch = 15.9411s	
28010/29850 (epoch 46.918), train_loss = 0.71817499, grad/param norm = 2.5211e-01, time/batch = 19.7049s	
28011/29850 (epoch 46.920), train_loss = 0.85610104, grad/param norm = 2.2118e-01, time/batch = 17.1236s	
28012/29850 (epoch 46.921), train_loss = 0.75005490, grad/param norm = 2.5559e-01, time/batch = 18.0329s	
28013/29850 (epoch 46.923), train_loss = 0.78841761, grad/param norm = 2.4379e-01, time/batch = 18.1125s	
28014/29850 (epoch 46.925), train_loss = 0.93201566, grad/param norm = 2.9939e-01, time/batch = 18.3039s	
28015/29850 (epoch 46.926), train_loss = 0.90685395, grad/param norm = 2.9969e-01, time/batch = 17.9644s	
28016/29850 (epoch 46.928), train_loss = 0.76618634, grad/param norm = 2.2170e-01, time/batch = 18.7188s	
28017/29850 (epoch 46.930), train_loss = 0.79098114, grad/param norm = 2.5231e-01, time/batch = 16.3164s	
28018/29850 (epoch 46.931), train_loss = 0.78145217, grad/param norm = 2.6678e-01, time/batch = 17.7827s	
28019/29850 (epoch 46.933), train_loss = 0.90127873, grad/param norm = 2.7953e-01, time/batch = 15.4396s	
28020/29850 (epoch 46.935), train_loss = 0.83419107, grad/param norm = 2.7607e-01, time/batch = 18.2708s	
28021/29850 (epoch 46.936), train_loss = 0.80888571, grad/param norm = 2.4819e-01, time/batch = 19.3789s	
28022/29850 (epoch 46.938), train_loss = 0.69000893, grad/param norm = 2.3408e-01, time/batch = 17.1261s	
28023/29850 (epoch 46.940), train_loss = 0.71429706, grad/param norm = 2.3443e-01, time/batch = 17.2954s	
28024/29850 (epoch 46.941), train_loss = 0.69006831, grad/param norm = 2.6216e-01, time/batch = 17.7820s	
28025/29850 (epoch 46.943), train_loss = 0.71781425, grad/param norm = 2.2910e-01, time/batch = 18.3618s	
28026/29850 (epoch 46.945), train_loss = 0.69473727, grad/param norm = 2.9440e-01, time/batch = 16.1913s	
28027/29850 (epoch 46.946), train_loss = 0.66683028, grad/param norm = 2.1870e-01, time/batch = 17.3182s	
28028/29850 (epoch 46.948), train_loss = 0.79221183, grad/param norm = 2.7050e-01, time/batch = 16.8867s	
28029/29850 (epoch 46.950), train_loss = 0.73485867, grad/param norm = 1.8355e-01, time/batch = 17.1254s	
28030/29850 (epoch 46.951), train_loss = 0.62526322, grad/param norm = 2.1812e-01, time/batch = 14.7401s	
28031/29850 (epoch 46.953), train_loss = 0.71299530, grad/param norm = 2.3182e-01, time/batch = 19.7815s	
28032/29850 (epoch 46.955), train_loss = 0.63725101, grad/param norm = 1.9999e-01, time/batch = 18.5363s	
28033/29850 (epoch 46.956), train_loss = 0.64166690, grad/param norm = 2.2201e-01, time/batch = 17.5348s	
28034/29850 (epoch 46.958), train_loss = 0.59411311, grad/param norm = 2.0054e-01, time/batch = 17.0647s	
28035/29850 (epoch 46.960), train_loss = 0.85911333, grad/param norm = 2.9812e-01, time/batch = 16.3402s	
28036/29850 (epoch 46.961), train_loss = 0.60019160, grad/param norm = 2.6952e-01, time/batch = 16.9695s	
28037/29850 (epoch 46.963), train_loss = 0.60792125, grad/param norm = 2.1114e-01, time/batch = 16.8822s	
28038/29850 (epoch 46.965), train_loss = 0.66931327, grad/param norm = 2.4113e-01, time/batch = 14.6534s	
28039/29850 (epoch 46.966), train_loss = 0.63930188, grad/param norm = 2.2742e-01, time/batch = 16.8075s	
28040/29850 (epoch 46.968), train_loss = 0.65916683, grad/param norm = 2.1932e-01, time/batch = 17.8748s	
28041/29850 (epoch 46.970), train_loss = 0.70001390, grad/param norm = 2.5317e-01, time/batch = 17.8886s	
28042/29850 (epoch 46.972), train_loss = 0.68304739, grad/param norm = 2.3429e-01, time/batch = 18.3787s	
28043/29850 (epoch 46.973), train_loss = 0.65826636, grad/param norm = 2.1868e-01, time/batch = 16.3748s	
28044/29850 (epoch 46.975), train_loss = 0.60236441, grad/param norm = 2.2615e-01, time/batch = 15.8117s	
28045/29850 (epoch 46.977), train_loss = 0.68736100, grad/param norm = 1.9696e-01, time/batch = 16.6324s	
28046/29850 (epoch 46.978), train_loss = 0.59365374, grad/param norm = 1.8696e-01, time/batch = 17.3020s	
28047/29850 (epoch 46.980), train_loss = 0.65136573, grad/param norm = 1.8099e-01, time/batch = 17.8708s	
28048/29850 (epoch 46.982), train_loss = 0.63615476, grad/param norm = 2.2021e-01, time/batch = 17.3061s	
28049/29850 (epoch 46.983), train_loss = 0.67237068, grad/param norm = 1.8698e-01, time/batch = 20.1172s	
28050/29850 (epoch 46.985), train_loss = 0.77581084, grad/param norm = 2.6660e-01, time/batch = 15.6945s	
28051/29850 (epoch 46.987), train_loss = 0.74244065, grad/param norm = 2.1035e-01, time/batch = 17.6341s	
28052/29850 (epoch 46.988), train_loss = 0.71998668, grad/param norm = 2.3319e-01, time/batch = 17.9606s	
28053/29850 (epoch 46.990), train_loss = 0.77391335, grad/param norm = 2.2004e-01, time/batch = 17.5155s	
28054/29850 (epoch 46.992), train_loss = 0.76126730, grad/param norm = 2.4800e-01, time/batch = 18.8717s	
28055/29850 (epoch 46.993), train_loss = 0.75000162, grad/param norm = 2.2189e-01, time/batch = 16.1419s	
28056/29850 (epoch 46.995), train_loss = 0.72601479, grad/param norm = 2.1902e-01, time/batch = 18.0398s	
28057/29850 (epoch 46.997), train_loss = 0.77394137, grad/param norm = 2.1548e-01, time/batch = 17.7073s	
28058/29850 (epoch 46.998), train_loss = 0.77942640, grad/param norm = 2.0968e-01, time/batch = 18.1908s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
28059/29850 (epoch 47.000), train_loss = 0.60203347, grad/param norm = 1.9987e-01, time/batch = 18.2195s	
28060/29850 (epoch 47.002), train_loss = 0.83832092, grad/param norm = 2.4908e-01, time/batch = 16.8736s	
28061/29850 (epoch 47.003), train_loss = 0.61557834, grad/param norm = 2.1396e-01, time/batch = 16.1957s	
28062/29850 (epoch 47.005), train_loss = 0.80119735, grad/param norm = 2.2811e-01, time/batch = 16.3050s	
28063/29850 (epoch 47.007), train_loss = 0.83571712, grad/param norm = 2.8889e-01, time/batch = 17.5660s	
28064/29850 (epoch 47.008), train_loss = 0.96348605, grad/param norm = 2.9069e-01, time/batch = 16.1210s	
28065/29850 (epoch 47.010), train_loss = 0.67828444, grad/param norm = 2.1424e-01, time/batch = 18.3738s	
28066/29850 (epoch 47.012), train_loss = 0.72481937, grad/param norm = 2.2362e-01, time/batch = 18.9736s	
28067/29850 (epoch 47.013), train_loss = 0.77116467, grad/param norm = 3.3135e-01, time/batch = 16.9607s	
28068/29850 (epoch 47.015), train_loss = 0.83723308, grad/param norm = 2.3746e-01, time/batch = 17.4755s	
28069/29850 (epoch 47.017), train_loss = 0.79340368, grad/param norm = 2.7318e-01, time/batch = 15.9878s	
28070/29850 (epoch 47.018), train_loss = 0.87914775, grad/param norm = 2.6473e-01, time/batch = 17.6285s	
28071/29850 (epoch 47.020), train_loss = 0.77778271, grad/param norm = 2.6429e-01, time/batch = 18.3842s	
28072/29850 (epoch 47.022), train_loss = 0.83411042, grad/param norm = 2.4560e-01, time/batch = 17.9703s	
28073/29850 (epoch 47.023), train_loss = 0.79974338, grad/param norm = 1.7972e-01, time/batch = 18.4622s	
28074/29850 (epoch 47.025), train_loss = 0.74707707, grad/param norm = 2.4017e-01, time/batch = 17.2031s	
28075/29850 (epoch 47.027), train_loss = 0.54982408, grad/param norm = 2.1929e-01, time/batch = 19.1205s	
28076/29850 (epoch 47.028), train_loss = 0.69519384, grad/param norm = 2.0191e-01, time/batch = 15.6376s	
28077/29850 (epoch 47.030), train_loss = 0.69897615, grad/param norm = 2.5500e-01, time/batch = 17.8720s	
28078/29850 (epoch 47.032), train_loss = 0.79707916, grad/param norm = 2.3678e-01, time/batch = 17.8718s	
28079/29850 (epoch 47.034), train_loss = 0.67697140, grad/param norm = 2.1119e-01, time/batch = 15.5679s	
28080/29850 (epoch 47.035), train_loss = 0.58828829, grad/param norm = 1.9118e-01, time/batch = 17.3091s	
28081/29850 (epoch 47.037), train_loss = 0.74577859, grad/param norm = 3.0004e-01, time/batch = 16.2694s	
28082/29850 (epoch 47.039), train_loss = 0.66790546, grad/param norm = 1.9031e-01, time/batch = 18.9463s	
28083/29850 (epoch 47.040), train_loss = 0.62580398, grad/param norm = 1.9550e-01, time/batch = 19.1345s	
28084/29850 (epoch 47.042), train_loss = 0.68014016, grad/param norm = 2.1317e-01, time/batch = 18.1213s	
28085/29850 (epoch 47.044), train_loss = 0.72277271, grad/param norm = 1.9305e-01, time/batch = 16.8853s	
28086/29850 (epoch 47.045), train_loss = 0.80023488, grad/param norm = 2.1485e-01, time/batch = 17.1923s	
28087/29850 (epoch 47.047), train_loss = 0.62984014, grad/param norm = 2.2935e-01, time/batch = 17.5241s	
28088/29850 (epoch 47.049), train_loss = 0.76651486, grad/param norm = 2.0163e-01, time/batch = 18.5520s	
28089/29850 (epoch 47.050), train_loss = 0.70260444, grad/param norm = 2.1289e-01, time/batch = 16.2211s	
28090/29850 (epoch 47.052), train_loss = 0.86086349, grad/param norm = 3.2872e-01, time/batch = 15.3852s	
28091/29850 (epoch 47.054), train_loss = 0.72738860, grad/param norm = 2.0765e-01, time/batch = 17.6407s	
28092/29850 (epoch 47.055), train_loss = 0.71466195, grad/param norm = 2.1334e-01, time/batch = 17.4669s	
28093/29850 (epoch 47.057), train_loss = 0.78945852, grad/param norm = 1.9206e-01, time/batch = 19.2055s	
28094/29850 (epoch 47.059), train_loss = 0.78217262, grad/param norm = 2.4357e-01, time/batch = 17.8605s	
28095/29850 (epoch 47.060), train_loss = 0.77188348, grad/param norm = 2.4451e-01, time/batch = 15.7007s	
28096/29850 (epoch 47.062), train_loss = 0.83320105, grad/param norm = 2.9651e-01, time/batch = 16.7309s	
28097/29850 (epoch 47.064), train_loss = 0.84596614, grad/param norm = 2.5755e-01, time/batch = 17.8859s	
28098/29850 (epoch 47.065), train_loss = 0.62613998, grad/param norm = 2.0373e-01, time/batch = 16.5220s	
28099/29850 (epoch 47.067), train_loss = 0.80558234, grad/param norm = 2.2336e-01, time/batch = 18.7987s	
28100/29850 (epoch 47.069), train_loss = 0.76914595, grad/param norm = 2.0889e-01, time/batch = 18.2071s	
28101/29850 (epoch 47.070), train_loss = 0.83022495, grad/param norm = 2.4165e-01, time/batch = 17.7930s	
28102/29850 (epoch 47.072), train_loss = 0.76097658, grad/param norm = 2.4567e-01, time/batch = 17.5600s	
28103/29850 (epoch 47.074), train_loss = 0.83451992, grad/param norm = 2.1442e-01, time/batch = 19.3013s	
28104/29850 (epoch 47.075), train_loss = 0.70163338, grad/param norm = 2.7022e-01, time/batch = 15.1983s	
28105/29850 (epoch 47.077), train_loss = 0.80824913, grad/param norm = 2.3673e-01, time/batch = 17.5354s	
28106/29850 (epoch 47.079), train_loss = 0.97500143, grad/param norm = 3.8428e-01, time/batch = 18.6307s	
28107/29850 (epoch 47.080), train_loss = 0.93443299, grad/param norm = 2.9852e-01, time/batch = 19.2132s	
28108/29850 (epoch 47.082), train_loss = 0.83223084, grad/param norm = 2.6738e-01, time/batch = 16.6284s	
28109/29850 (epoch 47.084), train_loss = 0.92431921, grad/param norm = 2.6915e-01, time/batch = 19.0357s	
28110/29850 (epoch 47.085), train_loss = 0.95259243, grad/param norm = 2.7767e-01, time/batch = 18.7179s	
28111/29850 (epoch 47.087), train_loss = 0.88455719, grad/param norm = 2.4946e-01, time/batch = 17.3653s	
28112/29850 (epoch 47.089), train_loss = 0.80679887, grad/param norm = 2.1986e-01, time/batch = 16.6445s	
28113/29850 (epoch 47.090), train_loss = 0.80400423, grad/param norm = 2.1737e-01, time/batch = 18.5470s	
28114/29850 (epoch 47.092), train_loss = 0.70653260, grad/param norm = 2.5983e-01, time/batch = 18.3795s	
28115/29850 (epoch 47.094), train_loss = 0.89402177, grad/param norm = 2.7652e-01, time/batch = 15.4396s	
28116/29850 (epoch 47.095), train_loss = 0.83352186, grad/param norm = 3.2596e-01, time/batch = 19.1226s	
28117/29850 (epoch 47.097), train_loss = 0.59127550, grad/param norm = 1.9928e-01, time/batch = 20.0536s	
28118/29850 (epoch 47.099), train_loss = 0.61134968, grad/param norm = 1.9379e-01, time/batch = 16.4193s	
28119/29850 (epoch 47.101), train_loss = 0.80789089, grad/param norm = 2.3283e-01, time/batch = 19.0646s	
28120/29850 (epoch 47.102), train_loss = 0.82035010, grad/param norm = 2.2494e-01, time/batch = 16.3731s	
28121/29850 (epoch 47.104), train_loss = 0.73229841, grad/param norm = 2.6844e-01, time/batch = 18.7909s	
28122/29850 (epoch 47.106), train_loss = 0.84042658, grad/param norm = 2.2086e-01, time/batch = 16.7824s	
28123/29850 (epoch 47.107), train_loss = 0.72435840, grad/param norm = 2.1635e-01, time/batch = 18.8733s	
28124/29850 (epoch 47.109), train_loss = 0.75872199, grad/param norm = 2.1283e-01, time/batch = 18.7029s	
28125/29850 (epoch 47.111), train_loss = 0.78923986, grad/param norm = 2.2572e-01, time/batch = 18.8805s	
28126/29850 (epoch 47.112), train_loss = 0.67668313, grad/param norm = 2.0452e-01, time/batch = 17.8618s	
28127/29850 (epoch 47.114), train_loss = 0.70410357, grad/param norm = 3.0211e-01, time/batch = 19.8712s	
28128/29850 (epoch 47.116), train_loss = 0.68229247, grad/param norm = 2.2778e-01, time/batch = 16.9540s	
28129/29850 (epoch 47.117), train_loss = 0.72349228, grad/param norm = 2.2359e-01, time/batch = 16.5443s	
28130/29850 (epoch 47.119), train_loss = 0.72802778, grad/param norm = 2.1728e-01, time/batch = 18.2998s	
28131/29850 (epoch 47.121), train_loss = 0.60815559, grad/param norm = 2.3625e-01, time/batch = 16.4235s	
28132/29850 (epoch 47.122), train_loss = 0.67190264, grad/param norm = 1.9697e-01, time/batch = 18.1266s	
28133/29850 (epoch 47.124), train_loss = 0.69161815, grad/param norm = 2.1669e-01, time/batch = 18.4721s	
28134/29850 (epoch 47.126), train_loss = 0.75281101, grad/param norm = 2.2889e-01, time/batch = 19.1909s	
28135/29850 (epoch 47.127), train_loss = 0.77908521, grad/param norm = 2.5685e-01, time/batch = 19.0332s	
28136/29850 (epoch 47.129), train_loss = 0.77481055, grad/param norm = 2.4126e-01, time/batch = 17.6401s	
28137/29850 (epoch 47.131), train_loss = 0.77156708, grad/param norm = 2.1513e-01, time/batch = 17.1296s	
28138/29850 (epoch 47.132), train_loss = 0.64849755, grad/param norm = 2.0961e-01, time/batch = 15.6799s	
28139/29850 (epoch 47.134), train_loss = 0.73627526, grad/param norm = 2.4134e-01, time/batch = 18.6176s	
28140/29850 (epoch 47.136), train_loss = 0.82484292, grad/param norm = 2.4744e-01, time/batch = 16.4714s	
28141/29850 (epoch 47.137), train_loss = 0.61967717, grad/param norm = 2.0411e-01, time/batch = 16.7922s	
28142/29850 (epoch 47.139), train_loss = 0.74584509, grad/param norm = 2.2156e-01, time/batch = 14.8218s	
28143/29850 (epoch 47.141), train_loss = 0.66969937, grad/param norm = 2.3533e-01, time/batch = 19.1954s	
28144/29850 (epoch 47.142), train_loss = 0.87279772, grad/param norm = 2.6457e-01, time/batch = 18.8024s	
28145/29850 (epoch 47.144), train_loss = 0.99289130, grad/param norm = 2.8852e-01, time/batch = 15.9417s	
28146/29850 (epoch 47.146), train_loss = 0.95149217, grad/param norm = 2.7213e-01, time/batch = 16.7304s	
28147/29850 (epoch 47.147), train_loss = 0.86998337, grad/param norm = 2.7453e-01, time/batch = 17.3153s	
28148/29850 (epoch 47.149), train_loss = 0.81254870, grad/param norm = 2.2954e-01, time/batch = 16.8051s	
28149/29850 (epoch 47.151), train_loss = 0.81909553, grad/param norm = 2.9143e-01, time/batch = 17.8066s	
28150/29850 (epoch 47.152), train_loss = 0.77208517, grad/param norm = 2.2055e-01, time/batch = 19.7115s	
28151/29850 (epoch 47.154), train_loss = 0.70558713, grad/param norm = 2.5646e-01, time/batch = 17.0051s	
28152/29850 (epoch 47.156), train_loss = 0.69851271, grad/param norm = 2.2212e-01, time/batch = 15.8718s	
28153/29850 (epoch 47.157), train_loss = 0.80182843, grad/param norm = 2.4602e-01, time/batch = 19.1328s	
28154/29850 (epoch 47.159), train_loss = 0.72768505, grad/param norm = 2.3776e-01, time/batch = 17.5440s	
28155/29850 (epoch 47.161), train_loss = 0.74914496, grad/param norm = 2.4207e-01, time/batch = 16.4677s	
28156/29850 (epoch 47.162), train_loss = 0.88247577, grad/param norm = 2.3687e-01, time/batch = 18.6275s	
28157/29850 (epoch 47.164), train_loss = 0.81496907, grad/param norm = 2.8630e-01, time/batch = 17.4752s	
28158/29850 (epoch 47.166), train_loss = 0.72815453, grad/param norm = 2.1960e-01, time/batch = 17.1330s	
28159/29850 (epoch 47.168), train_loss = 0.69329796, grad/param norm = 2.3424e-01, time/batch = 16.6377s	
28160/29850 (epoch 47.169), train_loss = 0.87591696, grad/param norm = 2.8211e-01, time/batch = 18.5487s	
28161/29850 (epoch 47.171), train_loss = 0.85088525, grad/param norm = 2.4528e-01, time/batch = 15.5430s	
28162/29850 (epoch 47.173), train_loss = 0.67473055, grad/param norm = 2.4677e-01, time/batch = 16.7849s	
28163/29850 (epoch 47.174), train_loss = 0.73648963, grad/param norm = 2.8327e-01, time/batch = 19.1241s	
28164/29850 (epoch 47.176), train_loss = 0.80517844, grad/param norm = 2.3420e-01, time/batch = 17.2179s	
28165/29850 (epoch 47.178), train_loss = 0.80976894, grad/param norm = 2.6694e-01, time/batch = 17.0422s	
28166/29850 (epoch 47.179), train_loss = 0.62066621, grad/param norm = 2.0552e-01, time/batch = 17.9600s	
28167/29850 (epoch 47.181), train_loss = 0.79117893, grad/param norm = 2.5401e-01, time/batch = 19.9431s	
28168/29850 (epoch 47.183), train_loss = 0.77994370, grad/param norm = 2.1557e-01, time/batch = 18.7121s	
28169/29850 (epoch 47.184), train_loss = 0.86015218, grad/param norm = 2.5461e-01, time/batch = 17.2873s	
28170/29850 (epoch 47.186), train_loss = 0.82402000, grad/param norm = 2.4054e-01, time/batch = 19.0149s	
28171/29850 (epoch 47.188), train_loss = 0.90715529, grad/param norm = 2.3516e-01, time/batch = 16.4452s	
28172/29850 (epoch 47.189), train_loss = 0.82336623, grad/param norm = 2.4514e-01, time/batch = 18.5326s	
28173/29850 (epoch 47.191), train_loss = 0.85273776, grad/param norm = 2.2898e-01, time/batch = 16.9795s	
28174/29850 (epoch 47.193), train_loss = 0.75247496, grad/param norm = 2.0260e-01, time/batch = 19.6292s	
28175/29850 (epoch 47.194), train_loss = 0.87122792, grad/param norm = 2.4879e-01, time/batch = 17.1792s	
28176/29850 (epoch 47.196), train_loss = 0.73907634, grad/param norm = 2.2268e-01, time/batch = 19.7818s	
28177/29850 (epoch 47.198), train_loss = 0.69309030, grad/param norm = 2.0843e-01, time/batch = 18.0316s	
28178/29850 (epoch 47.199), train_loss = 0.96347565, grad/param norm = 3.2528e-01, time/batch = 17.3678s	
28179/29850 (epoch 47.201), train_loss = 0.72113554, grad/param norm = 2.1910e-01, time/batch = 18.2082s	
28180/29850 (epoch 47.203), train_loss = 0.55465311, grad/param norm = 2.2981e-01, time/batch = 17.2853s	
28181/29850 (epoch 47.204), train_loss = 0.76869689, grad/param norm = 2.4868e-01, time/batch = 15.5319s	
28182/29850 (epoch 47.206), train_loss = 0.66593381, grad/param norm = 2.2221e-01, time/batch = 17.3754s	
28183/29850 (epoch 47.208), train_loss = 0.89285934, grad/param norm = 2.9469e-01, time/batch = 17.7134s	
28184/29850 (epoch 47.209), train_loss = 0.68771312, grad/param norm = 2.3883e-01, time/batch = 17.3642s	
28185/29850 (epoch 47.211), train_loss = 0.75206336, grad/param norm = 2.2232e-01, time/batch = 16.8628s	
28186/29850 (epoch 47.213), train_loss = 0.80549704, grad/param norm = 2.3950e-01, time/batch = 19.1250s	
28187/29850 (epoch 47.214), train_loss = 0.63431222, grad/param norm = 1.8698e-01, time/batch = 16.7389s	
28188/29850 (epoch 47.216), train_loss = 0.67832553, grad/param norm = 2.3902e-01, time/batch = 17.0463s	
28189/29850 (epoch 47.218), train_loss = 0.77783472, grad/param norm = 2.3717e-01, time/batch = 17.9507s	
28190/29850 (epoch 47.219), train_loss = 0.75205540, grad/param norm = 2.5255e-01, time/batch = 18.7219s	
28191/29850 (epoch 47.221), train_loss = 0.75370869, grad/param norm = 2.3143e-01, time/batch = 19.4599s	
28192/29850 (epoch 47.223), train_loss = 0.60306744, grad/param norm = 2.1764e-01, time/batch = 16.5165s	
28193/29850 (epoch 47.224), train_loss = 0.60716377, grad/param norm = 2.3665e-01, time/batch = 19.1763s	
28194/29850 (epoch 47.226), train_loss = 0.68092611, grad/param norm = 2.3101e-01, time/batch = 18.8786s	
28195/29850 (epoch 47.228), train_loss = 0.72976584, grad/param norm = 2.3040e-01, time/batch = 25.6008s	
28196/29850 (epoch 47.229), train_loss = 0.62585449, grad/param norm = 2.0471e-01, time/batch = 24.0668s	
28197/29850 (epoch 47.231), train_loss = 0.77680843, grad/param norm = 2.3534e-01, time/batch = 17.0641s	
28198/29850 (epoch 47.233), train_loss = 0.73298291, grad/param norm = 2.3213e-01, time/batch = 17.3667s	
28199/29850 (epoch 47.235), train_loss = 0.68225001, grad/param norm = 2.1166e-01, time/batch = 18.4622s	
28200/29850 (epoch 47.236), train_loss = 0.88095694, grad/param norm = 2.4993e-01, time/batch = 18.5338s	
28201/29850 (epoch 47.238), train_loss = 0.64810966, grad/param norm = 2.1897e-01, time/batch = 17.6185s	
28202/29850 (epoch 47.240), train_loss = 0.64153563, grad/param norm = 2.1549e-01, time/batch = 17.7161s	
28203/29850 (epoch 47.241), train_loss = 0.75235407, grad/param norm = 2.7771e-01, time/batch = 18.3004s	
28204/29850 (epoch 47.243), train_loss = 0.79285580, grad/param norm = 2.2672e-01, time/batch = 17.2584s	
28205/29850 (epoch 47.245), train_loss = 0.65975107, grad/param norm = 2.1838e-01, time/batch = 15.5229s	
28206/29850 (epoch 47.246), train_loss = 0.69898833, grad/param norm = 1.9859e-01, time/batch = 17.5432s	
28207/29850 (epoch 47.248), train_loss = 0.64627232, grad/param norm = 2.5355e-01, time/batch = 18.9563s	
28208/29850 (epoch 47.250), train_loss = 0.70187683, grad/param norm = 1.9244e-01, time/batch = 16.4601s	
28209/29850 (epoch 47.251), train_loss = 0.60376528, grad/param norm = 1.9812e-01, time/batch = 19.3741s	
28210/29850 (epoch 47.253), train_loss = 0.59974156, grad/param norm = 2.3875e-01, time/batch = 17.6194s	
28211/29850 (epoch 47.255), train_loss = 0.65939668, grad/param norm = 2.2234e-01, time/batch = 17.4497s	
28212/29850 (epoch 47.256), train_loss = 0.77616193, grad/param norm = 2.3811e-01, time/batch = 15.7843s	
28213/29850 (epoch 47.258), train_loss = 0.79011724, grad/param norm = 2.4350e-01, time/batch = 17.0667s	
28214/29850 (epoch 47.260), train_loss = 0.73027262, grad/param norm = 2.3262e-01, time/batch = 17.9814s	
28215/29850 (epoch 47.261), train_loss = 0.67716185, grad/param norm = 2.7582e-01, time/batch = 17.4485s	
28216/29850 (epoch 47.263), train_loss = 0.64686051, grad/param norm = 1.8346e-01, time/batch = 18.2024s	
28217/29850 (epoch 47.265), train_loss = 0.71454219, grad/param norm = 2.2270e-01, time/batch = 18.5562s	
28218/29850 (epoch 47.266), train_loss = 0.75321678, grad/param norm = 3.1728e-01, time/batch = 17.7870s	
28219/29850 (epoch 47.268), train_loss = 0.70616466, grad/param norm = 2.0595e-01, time/batch = 17.8842s	
28220/29850 (epoch 47.270), train_loss = 0.66791551, grad/param norm = 2.0452e-01, time/batch = 18.2920s	
28221/29850 (epoch 47.271), train_loss = 0.76123763, grad/param norm = 2.3662e-01, time/batch = 16.2539s	
28222/29850 (epoch 47.273), train_loss = 0.62724979, grad/param norm = 1.9936e-01, time/batch = 18.2881s	
28223/29850 (epoch 47.275), train_loss = 0.64217344, grad/param norm = 2.1612e-01, time/batch = 19.2904s	
28224/29850 (epoch 47.276), train_loss = 0.64328550, grad/param norm = 2.0201e-01, time/batch = 16.3579s	
28225/29850 (epoch 47.278), train_loss = 0.69757642, grad/param norm = 2.2883e-01, time/batch = 17.6268s	
28226/29850 (epoch 47.280), train_loss = 0.90249323, grad/param norm = 3.0740e-01, time/batch = 17.8733s	
28227/29850 (epoch 47.281), train_loss = 0.75862001, grad/param norm = 2.2758e-01, time/batch = 18.9592s	
28228/29850 (epoch 47.283), train_loss = 0.80564325, grad/param norm = 2.7331e-01, time/batch = 17.2997s	
28229/29850 (epoch 47.285), train_loss = 0.82544378, grad/param norm = 2.2692e-01, time/batch = 17.8760s	
28230/29850 (epoch 47.286), train_loss = 0.85243368, grad/param norm = 2.3778e-01, time/batch = 16.0756s	
28231/29850 (epoch 47.288), train_loss = 0.75836091, grad/param norm = 2.7400e-01, time/batch = 17.9597s	
28232/29850 (epoch 47.290), train_loss = 0.75285090, grad/param norm = 2.9056e-01, time/batch = 16.6868s	
28233/29850 (epoch 47.291), train_loss = 0.94836115, grad/param norm = 2.3269e-01, time/batch = 18.4632s	
28234/29850 (epoch 47.293), train_loss = 0.88848324, grad/param norm = 2.7817e-01, time/batch = 19.7049s	
28235/29850 (epoch 47.295), train_loss = 0.92808175, grad/param norm = 2.3965e-01, time/batch = 17.6291s	
28236/29850 (epoch 47.296), train_loss = 0.71097616, grad/param norm = 2.1990e-01, time/batch = 17.6368s	
28237/29850 (epoch 47.298), train_loss = 0.59082625, grad/param norm = 2.0340e-01, time/batch = 18.1368s	
28238/29850 (epoch 47.300), train_loss = 0.64445948, grad/param norm = 2.0952e-01, time/batch = 16.5227s	
28239/29850 (epoch 47.302), train_loss = 0.64566037, grad/param norm = 2.0942e-01, time/batch = 16.4801s	
28240/29850 (epoch 47.303), train_loss = 0.68801444, grad/param norm = 2.0675e-01, time/batch = 17.7035s	
28241/29850 (epoch 47.305), train_loss = 0.85172512, grad/param norm = 2.1835e-01, time/batch = 17.8021s	
28242/29850 (epoch 47.307), train_loss = 0.81342440, grad/param norm = 2.2430e-01, time/batch = 17.6267s	
28243/29850 (epoch 47.308), train_loss = 0.63650637, grad/param norm = 2.4824e-01, time/batch = 15.1293s	
28244/29850 (epoch 47.310), train_loss = 0.80665393, grad/param norm = 2.4962e-01, time/batch = 18.1227s	
28245/29850 (epoch 47.312), train_loss = 0.85455134, grad/param norm = 2.2928e-01, time/batch = 17.1330s	
28246/29850 (epoch 47.313), train_loss = 0.77985902, grad/param norm = 2.9053e-01, time/batch = 17.6948s	
28247/29850 (epoch 47.315), train_loss = 0.80435516, grad/param norm = 2.3035e-01, time/batch = 16.7335s	
28248/29850 (epoch 47.317), train_loss = 0.75975899, grad/param norm = 2.6057e-01, time/batch = 18.3816s	
28249/29850 (epoch 47.318), train_loss = 0.72829112, grad/param norm = 2.3797e-01, time/batch = 15.8058s	
28250/29850 (epoch 47.320), train_loss = 0.69488270, grad/param norm = 2.1059e-01, time/batch = 18.2167s	
28251/29850 (epoch 47.322), train_loss = 0.84597463, grad/param norm = 2.3620e-01, time/batch = 18.4613s	
28252/29850 (epoch 47.323), train_loss = 0.77747116, grad/param norm = 2.3474e-01, time/batch = 16.1250s	
28253/29850 (epoch 47.325), train_loss = 0.82805424, grad/param norm = 2.4152e-01, time/batch = 19.3090s	
28254/29850 (epoch 47.327), train_loss = 0.96754656, grad/param norm = 2.7053e-01, time/batch = 15.3606s	
28255/29850 (epoch 47.328), train_loss = 0.87236115, grad/param norm = 3.1313e-01, time/batch = 17.1738s	
28256/29850 (epoch 47.330), train_loss = 0.82793683, grad/param norm = 2.1993e-01, time/batch = 17.7897s	
28257/29850 (epoch 47.332), train_loss = 0.74802276, grad/param norm = 2.2313e-01, time/batch = 17.1162s	
28258/29850 (epoch 47.333), train_loss = 0.79633059, grad/param norm = 2.3011e-01, time/batch = 16.0579s	
28259/29850 (epoch 47.335), train_loss = 0.85026434, grad/param norm = 2.2928e-01, time/batch = 17.5158s	
28260/29850 (epoch 47.337), train_loss = 0.76755784, grad/param norm = 2.4923e-01, time/batch = 17.9699s	
28261/29850 (epoch 47.338), train_loss = 0.80904383, grad/param norm = 2.0928e-01, time/batch = 18.8901s	
28262/29850 (epoch 47.340), train_loss = 0.67112478, grad/param norm = 2.1023e-01, time/batch = 18.0262s	
28263/29850 (epoch 47.342), train_loss = 0.77703386, grad/param norm = 2.6725e-01, time/batch = 15.6510s	
28264/29850 (epoch 47.343), train_loss = 0.75509310, grad/param norm = 2.4994e-01, time/batch = 17.5539s	
28265/29850 (epoch 47.345), train_loss = 0.83300685, grad/param norm = 2.6600e-01, time/batch = 17.8995s	
28266/29850 (epoch 47.347), train_loss = 0.84174751, grad/param norm = 3.0779e-01, time/batch = 15.9664s	
28267/29850 (epoch 47.348), train_loss = 0.70728818, grad/param norm = 2.2973e-01, time/batch = 19.7076s	
28268/29850 (epoch 47.350), train_loss = 0.79510940, grad/param norm = 2.5637e-01, time/batch = 18.0531s	
28269/29850 (epoch 47.352), train_loss = 0.72692674, grad/param norm = 2.2377e-01, time/batch = 17.1241s	
28270/29850 (epoch 47.353), train_loss = 0.79175270, grad/param norm = 2.2443e-01, time/batch = 19.0390s	
28271/29850 (epoch 47.355), train_loss = 0.69192302, grad/param norm = 2.1773e-01, time/batch = 18.5452s	
28272/29850 (epoch 47.357), train_loss = 0.86817719, grad/param norm = 2.2446e-01, time/batch = 17.3534s	
28273/29850 (epoch 47.358), train_loss = 0.70684689, grad/param norm = 2.1433e-01, time/batch = 17.4276s	
28274/29850 (epoch 47.360), train_loss = 0.76805282, grad/param norm = 2.3858e-01, time/batch = 18.1434s	
28275/29850 (epoch 47.362), train_loss = 0.77622075, grad/param norm = 2.5047e-01, time/batch = 17.8150s	
28276/29850 (epoch 47.363), train_loss = 0.79893042, grad/param norm = 2.5423e-01, time/batch = 16.5276s	
28277/29850 (epoch 47.365), train_loss = 0.87041086, grad/param norm = 2.8824e-01, time/batch = 17.0384s	
28278/29850 (epoch 47.367), train_loss = 0.70536947, grad/param norm = 2.2082e-01, time/batch = 17.1971s	
28279/29850 (epoch 47.369), train_loss = 0.63229739, grad/param norm = 2.9032e-01, time/batch = 17.5353s	
28280/29850 (epoch 47.370), train_loss = 0.62883631, grad/param norm = 2.0485e-01, time/batch = 16.4646s	
28281/29850 (epoch 47.372), train_loss = 0.87666952, grad/param norm = 2.4329e-01, time/batch = 16.9581s	
28282/29850 (epoch 47.374), train_loss = 0.84647190, grad/param norm = 2.2673e-01, time/batch = 17.2348s	
28283/29850 (epoch 47.375), train_loss = 0.79248533, grad/param norm = 2.4761e-01, time/batch = 17.4540s	
28284/29850 (epoch 47.377), train_loss = 0.63664609, grad/param norm = 1.9106e-01, time/batch = 17.3937s	
28285/29850 (epoch 47.379), train_loss = 0.86142079, grad/param norm = 2.3537e-01, time/batch = 18.8869s	
28286/29850 (epoch 47.380), train_loss = 0.82591336, grad/param norm = 2.4678e-01, time/batch = 18.5454s	
28287/29850 (epoch 47.382), train_loss = 0.78883986, grad/param norm = 2.7647e-01, time/batch = 18.7891s	
28288/29850 (epoch 47.384), train_loss = 0.81264633, grad/param norm = 2.4212e-01, time/batch = 15.0483s	
28289/29850 (epoch 47.385), train_loss = 0.80903552, grad/param norm = 2.3611e-01, time/batch = 17.1086s	
28290/29850 (epoch 47.387), train_loss = 0.77999015, grad/param norm = 2.8230e-01, time/batch = 19.1333s	
28291/29850 (epoch 47.389), train_loss = 0.88196564, grad/param norm = 2.4678e-01, time/batch = 18.1108s	
28292/29850 (epoch 47.390), train_loss = 0.83962133, grad/param norm = 2.1831e-01, time/batch = 19.5477s	
28293/29850 (epoch 47.392), train_loss = 0.77396989, grad/param norm = 2.7067e-01, time/batch = 18.7761s	
28294/29850 (epoch 47.394), train_loss = 0.80096634, grad/param norm = 2.2324e-01, time/batch = 17.6299s	
28295/29850 (epoch 47.395), train_loss = 0.72558095, grad/param norm = 2.3229e-01, time/batch = 19.1973s	
28296/29850 (epoch 47.397), train_loss = 0.66108471, grad/param norm = 2.6840e-01, time/batch = 16.2770s	
28297/29850 (epoch 47.399), train_loss = 0.71218280, grad/param norm = 2.9635e-01, time/batch = 17.1205s	
28298/29850 (epoch 47.400), train_loss = 1.03084284, grad/param norm = 2.5217e-01, time/batch = 15.6299s	
28299/29850 (epoch 47.402), train_loss = 0.87559797, grad/param norm = 2.6975e-01, time/batch = 17.1124s	
28300/29850 (epoch 47.404), train_loss = 0.77906315, grad/param norm = 2.3164e-01, time/batch = 17.4501s	
28301/29850 (epoch 47.405), train_loss = 0.71080914, grad/param norm = 2.5925e-01, time/batch = 16.5259s	
28302/29850 (epoch 47.407), train_loss = 0.69667174, grad/param norm = 2.0775e-01, time/batch = 18.7170s	
28303/29850 (epoch 47.409), train_loss = 0.78051785, grad/param norm = 2.8488e-01, time/batch = 18.1227s	
28304/29850 (epoch 47.410), train_loss = 0.84909202, grad/param norm = 2.2682e-01, time/batch = 18.6249s	
28305/29850 (epoch 47.412), train_loss = 0.85843068, grad/param norm = 2.3441e-01, time/batch = 16.6273s	
28306/29850 (epoch 47.414), train_loss = 0.79278173, grad/param norm = 2.3498e-01, time/batch = 17.2103s	
28307/29850 (epoch 47.415), train_loss = 0.75906641, grad/param norm = 2.1475e-01, time/batch = 19.2168s	
28308/29850 (epoch 47.417), train_loss = 0.89056663, grad/param norm = 3.0633e-01, time/batch = 18.3012s	
28309/29850 (epoch 47.419), train_loss = 0.74497798, grad/param norm = 2.9586e-01, time/batch = 17.5456s	
28310/29850 (epoch 47.420), train_loss = 0.74935552, grad/param norm = 2.3615e-01, time/batch = 19.1843s	
28311/29850 (epoch 47.422), train_loss = 0.76448455, grad/param norm = 2.3189e-01, time/batch = 18.8800s	
28312/29850 (epoch 47.424), train_loss = 0.66151810, grad/param norm = 2.1572e-01, time/batch = 18.3763s	
28313/29850 (epoch 47.425), train_loss = 0.83207489, grad/param norm = 2.8442e-01, time/batch = 16.5000s	
28314/29850 (epoch 47.427), train_loss = 0.59057539, grad/param norm = 2.2276e-01, time/batch = 18.3034s	
28315/29850 (epoch 47.429), train_loss = 0.68326145, grad/param norm = 2.0975e-01, time/batch = 18.7865s	
28316/29850 (epoch 47.430), train_loss = 0.63103692, grad/param norm = 1.8313e-01, time/batch = 17.2861s	
28317/29850 (epoch 47.432), train_loss = 0.72102985, grad/param norm = 2.3556e-01, time/batch = 19.7030s	
28318/29850 (epoch 47.434), train_loss = 0.69409437, grad/param norm = 1.9639e-01, time/batch = 17.1472s	
28319/29850 (epoch 47.436), train_loss = 0.74013855, grad/param norm = 2.3097e-01, time/batch = 18.0256s	
28320/29850 (epoch 47.437), train_loss = 0.82875699, grad/param norm = 2.1635e-01, time/batch = 18.1015s	
28321/29850 (epoch 47.439), train_loss = 0.82957368, grad/param norm = 2.2840e-01, time/batch = 18.7161s	
28322/29850 (epoch 47.441), train_loss = 0.75125191, grad/param norm = 2.2641e-01, time/batch = 17.2173s	
28323/29850 (epoch 47.442), train_loss = 0.74608105, grad/param norm = 2.5912e-01, time/batch = 15.5440s	
28324/29850 (epoch 47.444), train_loss = 0.79133708, grad/param norm = 2.5464e-01, time/batch = 20.0497s	
28325/29850 (epoch 47.446), train_loss = 0.86367997, grad/param norm = 2.3497e-01, time/batch = 17.4540s	
28326/29850 (epoch 47.447), train_loss = 0.88320333, grad/param norm = 2.6451e-01, time/batch = 16.1973s	
28327/29850 (epoch 47.449), train_loss = 0.79909669, grad/param norm = 2.6135e-01, time/batch = 18.0266s	
28328/29850 (epoch 47.451), train_loss = 0.60831801, grad/param norm = 2.0013e-01, time/batch = 17.2282s	
28329/29850 (epoch 47.452), train_loss = 0.52421134, grad/param norm = 1.8338e-01, time/batch = 15.2132s	
28330/29850 (epoch 47.454), train_loss = 0.63685161, grad/param norm = 2.0935e-01, time/batch = 15.2000s	
28331/29850 (epoch 47.456), train_loss = 0.81546462, grad/param norm = 2.7211e-01, time/batch = 17.4731s	
28332/29850 (epoch 47.457), train_loss = 0.85951751, grad/param norm = 3.6452e-01, time/batch = 16.8098s	
28333/29850 (epoch 47.459), train_loss = 0.91820372, grad/param norm = 3.1336e-01, time/batch = 17.3844s	
28334/29850 (epoch 47.461), train_loss = 0.91902607, grad/param norm = 2.7209e-01, time/batch = 18.3548s	
28335/29850 (epoch 47.462), train_loss = 0.94837204, grad/param norm = 2.6780e-01, time/batch = 18.1164s	
28336/29850 (epoch 47.464), train_loss = 0.81734081, grad/param norm = 2.5392e-01, time/batch = 18.5452s	
28337/29850 (epoch 47.466), train_loss = 0.67724425, grad/param norm = 2.4608e-01, time/batch = 18.2200s	
28338/29850 (epoch 47.467), train_loss = 0.70736762, grad/param norm = 2.2508e-01, time/batch = 19.1178s	
28339/29850 (epoch 47.469), train_loss = 0.75500686, grad/param norm = 2.1892e-01, time/batch = 16.7001s	
28340/29850 (epoch 47.471), train_loss = 0.74702740, grad/param norm = 2.4939e-01, time/batch = 16.8957s	
28341/29850 (epoch 47.472), train_loss = 0.71145200, grad/param norm = 2.1003e-01, time/batch = 17.2982s	
28342/29850 (epoch 47.474), train_loss = 0.82522271, grad/param norm = 2.4346e-01, time/batch = 18.1336s	
28343/29850 (epoch 47.476), train_loss = 0.78137517, grad/param norm = 2.0264e-01, time/batch = 16.7164s	
28344/29850 (epoch 47.477), train_loss = 0.81574031, grad/param norm = 2.9040e-01, time/batch = 16.7382s	
28345/29850 (epoch 47.479), train_loss = 0.93910110, grad/param norm = 2.5779e-01, time/batch = 18.4072s	
28346/29850 (epoch 47.481), train_loss = 0.79048479, grad/param norm = 2.4655e-01, time/batch = 18.5349s	
28347/29850 (epoch 47.482), train_loss = 0.71689612, grad/param norm = 2.1488e-01, time/batch = 16.2549s	
28348/29850 (epoch 47.484), train_loss = 0.74391207, grad/param norm = 2.3354e-01, time/batch = 16.4571s	
28349/29850 (epoch 47.486), train_loss = 0.78274494, grad/param norm = 2.2573e-01, time/batch = 17.6153s	
28350/29850 (epoch 47.487), train_loss = 0.75373449, grad/param norm = 2.1218e-01, time/batch = 17.5421s	
28351/29850 (epoch 47.489), train_loss = 0.78401011, grad/param norm = 2.3377e-01, time/batch = 16.5640s	
28352/29850 (epoch 47.491), train_loss = 0.68634873, grad/param norm = 1.9490e-01, time/batch = 16.6913s	
28353/29850 (epoch 47.492), train_loss = 0.77612290, grad/param norm = 2.5366e-01, time/batch = 17.2244s	
28354/29850 (epoch 47.494), train_loss = 0.84505883, grad/param norm = 2.4738e-01, time/batch = 15.6371s	
28355/29850 (epoch 47.496), train_loss = 0.89182784, grad/param norm = 2.2770e-01, time/batch = 17.0510s	
28356/29850 (epoch 47.497), train_loss = 0.78648631, grad/param norm = 2.2486e-01, time/batch = 17.8810s	
28357/29850 (epoch 47.499), train_loss = 0.79131450, grad/param norm = 2.8407e-01, time/batch = 16.1085s	
28358/29850 (epoch 47.501), train_loss = 0.67366404, grad/param norm = 3.1043e-01, time/batch = 16.6344s	
28359/29850 (epoch 47.503), train_loss = 0.85775619, grad/param norm = 2.2065e-01, time/batch = 15.0383s	
28360/29850 (epoch 47.504), train_loss = 1.01988991, grad/param norm = 2.7709e-01, time/batch = 15.1885s	
28361/29850 (epoch 47.506), train_loss = 0.97691898, grad/param norm = 2.8051e-01, time/batch = 15.5215s	
28362/29850 (epoch 47.508), train_loss = 0.80772561, grad/param norm = 2.5476e-01, time/batch = 15.5631s	
28363/29850 (epoch 47.509), train_loss = 0.60366525, grad/param norm = 1.9458e-01, time/batch = 14.3763s	
28364/29850 (epoch 47.511), train_loss = 0.81296170, grad/param norm = 2.4432e-01, time/batch = 15.4441s	
28365/29850 (epoch 47.513), train_loss = 0.77529861, grad/param norm = 3.2083e-01, time/batch = 15.3491s	
28366/29850 (epoch 47.514), train_loss = 0.68897978, grad/param norm = 2.3617e-01, time/batch = 17.8770s	
28367/29850 (epoch 47.516), train_loss = 0.72438796, grad/param norm = 2.0838e-01, time/batch = 16.8001s	
28368/29850 (epoch 47.518), train_loss = 0.61333259, grad/param norm = 2.0418e-01, time/batch = 17.5719s	
28369/29850 (epoch 47.519), train_loss = 0.63976950, grad/param norm = 2.1139e-01, time/batch = 14.7153s	
28370/29850 (epoch 47.521), train_loss = 0.59768683, grad/param norm = 2.0081e-01, time/batch = 18.7215s	
28371/29850 (epoch 47.523), train_loss = 0.64943566, grad/param norm = 2.1836e-01, time/batch = 18.4736s	
28372/29850 (epoch 47.524), train_loss = 0.64498256, grad/param norm = 1.9832e-01, time/batch = 16.8834s	
28373/29850 (epoch 47.526), train_loss = 0.69552012, grad/param norm = 2.7314e-01, time/batch = 17.3881s	
28374/29850 (epoch 47.528), train_loss = 0.81613097, grad/param norm = 2.6543e-01, time/batch = 18.1429s	
28375/29850 (epoch 47.529), train_loss = 0.78067500, grad/param norm = 2.3327e-01, time/batch = 17.5270s	
28376/29850 (epoch 47.531), train_loss = 0.77909380, grad/param norm = 3.1110e-01, time/batch = 16.3769s	
28377/29850 (epoch 47.533), train_loss = 0.79443129, grad/param norm = 2.7686e-01, time/batch = 17.9726s	
28378/29850 (epoch 47.534), train_loss = 0.81372242, grad/param norm = 2.4412e-01, time/batch = 17.4206s	
28379/29850 (epoch 47.536), train_loss = 0.71446613, grad/param norm = 2.3867e-01, time/batch = 15.6259s	
28380/29850 (epoch 47.538), train_loss = 0.86662018, grad/param norm = 2.8782e-01, time/batch = 16.7893s	
28381/29850 (epoch 47.539), train_loss = 0.88997859, grad/param norm = 2.6311e-01, time/batch = 19.7043s	
28382/29850 (epoch 47.541), train_loss = 0.54325529, grad/param norm = 2.0465e-01, time/batch = 16.5890s	
28383/29850 (epoch 47.543), train_loss = 0.72080625, grad/param norm = 2.3811e-01, time/batch = 0.6793s	
28384/29850 (epoch 47.544), train_loss = 0.87759951, grad/param norm = 2.7552e-01, time/batch = 0.6709s	
28385/29850 (epoch 47.546), train_loss = 0.85562255, grad/param norm = 2.6140e-01, time/batch = 0.6596s	
28386/29850 (epoch 47.548), train_loss = 0.62149204, grad/param norm = 1.8303e-01, time/batch = 0.6603s	
28387/29850 (epoch 47.549), train_loss = 0.74595697, grad/param norm = 2.2588e-01, time/batch = 0.6587s	
28388/29850 (epoch 47.551), train_loss = 0.68747785, grad/param norm = 2.1672e-01, time/batch = 0.6591s	
28389/29850 (epoch 47.553), train_loss = 0.76062434, grad/param norm = 2.2828e-01, time/batch = 0.6679s	
28390/29850 (epoch 47.554), train_loss = 0.61466221, grad/param norm = 1.9340e-01, time/batch = 0.8256s	
28391/29850 (epoch 47.556), train_loss = 0.66830928, grad/param norm = 2.6118e-01, time/batch = 0.9499s	
28392/29850 (epoch 47.558), train_loss = 0.67796755, grad/param norm = 2.2579e-01, time/batch = 0.9812s	
28393/29850 (epoch 47.559), train_loss = 0.68432529, grad/param norm = 2.2314e-01, time/batch = 0.9733s	
28394/29850 (epoch 47.561), train_loss = 0.76959941, grad/param norm = 2.1626e-01, time/batch = 0.9625s	
28395/29850 (epoch 47.563), train_loss = 0.79617615, grad/param norm = 2.2440e-01, time/batch = 1.3624s	
28396/29850 (epoch 47.564), train_loss = 0.72672086, grad/param norm = 3.3024e-01, time/batch = 1.7912s	
28397/29850 (epoch 47.566), train_loss = 0.76220257, grad/param norm = 2.4293e-01, time/batch = 1.7699s	
28398/29850 (epoch 47.568), train_loss = 0.90578349, grad/param norm = 2.6358e-01, time/batch = 12.9844s	
28399/29850 (epoch 47.570), train_loss = 0.77096586, grad/param norm = 2.3214e-01, time/batch = 17.3127s	
28400/29850 (epoch 47.571), train_loss = 0.83117960, grad/param norm = 2.3906e-01, time/batch = 16.8858s	
28401/29850 (epoch 47.573), train_loss = 0.87152366, grad/param norm = 2.6284e-01, time/batch = 20.1114s	
28402/29850 (epoch 47.575), train_loss = 0.96092790, grad/param norm = 2.3852e-01, time/batch = 17.4411s	
28403/29850 (epoch 47.576), train_loss = 0.82904731, grad/param norm = 2.5287e-01, time/batch = 17.9485s	
28404/29850 (epoch 47.578), train_loss = 0.70761890, grad/param norm = 2.1456e-01, time/batch = 17.5221s	
28405/29850 (epoch 47.580), train_loss = 0.81754739, grad/param norm = 2.1915e-01, time/batch = 17.9623s	
28406/29850 (epoch 47.581), train_loss = 0.72267340, grad/param norm = 2.0937e-01, time/batch = 16.0438s	
28407/29850 (epoch 47.583), train_loss = 0.76699770, grad/param norm = 2.2761e-01, time/batch = 16.8844s	
28408/29850 (epoch 47.585), train_loss = 0.77829559, grad/param norm = 2.3071e-01, time/batch = 17.5362s	
28409/29850 (epoch 47.586), train_loss = 0.80754559, grad/param norm = 2.7575e-01, time/batch = 19.1349s	
28410/29850 (epoch 47.588), train_loss = 0.69595078, grad/param norm = 2.2303e-01, time/batch = 17.2959s	
28411/29850 (epoch 47.590), train_loss = 0.70736482, grad/param norm = 1.7746e-01, time/batch = 19.6260s	
28412/29850 (epoch 47.591), train_loss = 0.76354761, grad/param norm = 2.7121e-01, time/batch = 16.7911s	
28413/29850 (epoch 47.593), train_loss = 0.67016123, grad/param norm = 1.9814e-01, time/batch = 18.0402s	
28414/29850 (epoch 47.595), train_loss = 0.63410521, grad/param norm = 2.1415e-01, time/batch = 32.7782s	
28415/29850 (epoch 47.596), train_loss = 0.66225936, grad/param norm = 2.5649e-01, time/batch = 17.8051s	
28416/29850 (epoch 47.598), train_loss = 0.73071266, grad/param norm = 2.0948e-01, time/batch = 16.1042s	
28417/29850 (epoch 47.600), train_loss = 0.76733328, grad/param norm = 2.2084e-01, time/batch = 18.6164s	
28418/29850 (epoch 47.601), train_loss = 0.65073112, grad/param norm = 2.0516e-01, time/batch = 18.8904s	
28419/29850 (epoch 47.603), train_loss = 0.68989973, grad/param norm = 2.1267e-01, time/batch = 18.1379s	
28420/29850 (epoch 47.605), train_loss = 0.73393443, grad/param norm = 2.2656e-01, time/batch = 17.1831s	
28421/29850 (epoch 47.606), train_loss = 0.48523120, grad/param norm = 1.7955e-01, time/batch = 18.5352s	
28422/29850 (epoch 47.608), train_loss = 0.64584853, grad/param norm = 2.5150e-01, time/batch = 16.8752s	
28423/29850 (epoch 47.610), train_loss = 0.69528399, grad/param norm = 1.9249e-01, time/batch = 17.0473s	
28424/29850 (epoch 47.611), train_loss = 0.63821256, grad/param norm = 1.8878e-01, time/batch = 18.5488s	
28425/29850 (epoch 47.613), train_loss = 0.54971794, grad/param norm = 1.7172e-01, time/batch = 19.5249s	
28426/29850 (epoch 47.615), train_loss = 0.60150559, grad/param norm = 2.0068e-01, time/batch = 16.7921s	
28427/29850 (epoch 47.616), train_loss = 0.61929027, grad/param norm = 2.2178e-01, time/batch = 18.7962s	
28428/29850 (epoch 47.618), train_loss = 0.67679319, grad/param norm = 1.9933e-01, time/batch = 16.2129s	
28429/29850 (epoch 47.620), train_loss = 0.79382992, grad/param norm = 2.3411e-01, time/batch = 18.7980s	
28430/29850 (epoch 47.621), train_loss = 0.83104960, grad/param norm = 2.7550e-01, time/batch = 17.6369s	
28431/29850 (epoch 47.623), train_loss = 0.82445204, grad/param norm = 2.2832e-01, time/batch = 18.0568s	
28432/29850 (epoch 47.625), train_loss = 0.74601350, grad/param norm = 2.4619e-01, time/batch = 17.3923s	
28433/29850 (epoch 47.626), train_loss = 0.73041747, grad/param norm = 2.3078e-01, time/batch = 15.4926s	
28434/29850 (epoch 47.628), train_loss = 0.76491761, grad/param norm = 2.9129e-01, time/batch = 16.7002s	
28435/29850 (epoch 47.630), train_loss = 0.76250675, grad/param norm = 2.5381e-01, time/batch = 17.5290s	
28436/29850 (epoch 47.631), train_loss = 0.77473381, grad/param norm = 2.4796e-01, time/batch = 17.7980s	
28437/29850 (epoch 47.633), train_loss = 0.77614827, grad/param norm = 3.4736e-01, time/batch = 18.8819s	
28438/29850 (epoch 47.635), train_loss = 0.72438601, grad/param norm = 2.7843e-01, time/batch = 17.1430s	
28439/29850 (epoch 47.637), train_loss = 0.67122837, grad/param norm = 2.3204e-01, time/batch = 17.0190s	
28440/29850 (epoch 47.638), train_loss = 0.79868518, grad/param norm = 2.4740e-01, time/batch = 17.1076s	
28441/29850 (epoch 47.640), train_loss = 0.90487503, grad/param norm = 2.9632e-01, time/batch = 15.7786s	
28442/29850 (epoch 47.642), train_loss = 0.72032173, grad/param norm = 2.1139e-01, time/batch = 19.0341s	
28443/29850 (epoch 47.643), train_loss = 0.65971548, grad/param norm = 2.2165e-01, time/batch = 17.2968s	
28444/29850 (epoch 47.645), train_loss = 0.73749759, grad/param norm = 2.1220e-01, time/batch = 18.2846s	
28445/29850 (epoch 47.647), train_loss = 0.87631816, grad/param norm = 3.2075e-01, time/batch = 18.8804s	
28446/29850 (epoch 47.648), train_loss = 0.67555273, grad/param norm = 2.0092e-01, time/batch = 18.1195s	
28447/29850 (epoch 47.650), train_loss = 0.78273834, grad/param norm = 2.5626e-01, time/batch = 17.1193s	
28448/29850 (epoch 47.652), train_loss = 0.75515785, grad/param norm = 2.8179e-01, time/batch = 16.0493s	
28449/29850 (epoch 47.653), train_loss = 0.84819604, grad/param norm = 3.7377e-01, time/batch = 18.4563s	
28450/29850 (epoch 47.655), train_loss = 0.79154826, grad/param norm = 2.1270e-01, time/batch = 16.9517s	
28451/29850 (epoch 47.657), train_loss = 0.73734109, grad/param norm = 2.2619e-01, time/batch = 19.4624s	
28452/29850 (epoch 47.658), train_loss = 0.86694435, grad/param norm = 2.6452e-01, time/batch = 17.8027s	
28453/29850 (epoch 47.660), train_loss = 0.73220828, grad/param norm = 2.5115e-01, time/batch = 16.3728s	
28454/29850 (epoch 47.662), train_loss = 0.86559135, grad/param norm = 2.8821e-01, time/batch = 19.7860s	
28455/29850 (epoch 47.663), train_loss = 0.96892950, grad/param norm = 2.6870e-01, time/batch = 18.7153s	
28456/29850 (epoch 47.665), train_loss = 0.89415473, grad/param norm = 2.6145e-01, time/batch = 16.8693s	
28457/29850 (epoch 47.667), train_loss = 0.81763773, grad/param norm = 2.7952e-01, time/batch = 15.4649s	
28458/29850 (epoch 47.668), train_loss = 0.70587353, grad/param norm = 2.5947e-01, time/batch = 16.2564s	
28459/29850 (epoch 47.670), train_loss = 0.81517002, grad/param norm = 3.0517e-01, time/batch = 19.5435s	
28460/29850 (epoch 47.672), train_loss = 0.86014572, grad/param norm = 2.4184e-01, time/batch = 17.1413s	
28461/29850 (epoch 47.673), train_loss = 0.80246784, grad/param norm = 2.7105e-01, time/batch = 18.6224s	
28462/29850 (epoch 47.675), train_loss = 0.68850221, grad/param norm = 2.2025e-01, time/batch = 19.6296s	
28463/29850 (epoch 47.677), train_loss = 0.70362693, grad/param norm = 2.4242e-01, time/batch = 17.7926s	
28464/29850 (epoch 47.678), train_loss = 0.76007567, grad/param norm = 2.3156e-01, time/batch = 15.0333s	
28465/29850 (epoch 47.680), train_loss = 0.76507547, grad/param norm = 2.7193e-01, time/batch = 17.7025s	
28466/29850 (epoch 47.682), train_loss = 0.75430729, grad/param norm = 2.2762e-01, time/batch = 17.5612s	
28467/29850 (epoch 47.683), train_loss = 0.86324437, grad/param norm = 2.8759e-01, time/batch = 15.8663s	
28468/29850 (epoch 47.685), train_loss = 0.93539900, grad/param norm = 2.5265e-01, time/batch = 17.7214s	
28469/29850 (epoch 47.687), train_loss = 0.80975769, grad/param norm = 2.2948e-01, time/batch = 19.1316s	
28470/29850 (epoch 47.688), train_loss = 0.70133067, grad/param norm = 2.8661e-01, time/batch = 17.8678s	
28471/29850 (epoch 47.690), train_loss = 0.69605253, grad/param norm = 2.0963e-01, time/batch = 18.5424s	
28472/29850 (epoch 47.692), train_loss = 0.88654868, grad/param norm = 2.7388e-01, time/batch = 17.8805s	
28473/29850 (epoch 47.693), train_loss = 0.75735828, grad/param norm = 2.1272e-01, time/batch = 17.2694s	
28474/29850 (epoch 47.695), train_loss = 0.68132955, grad/param norm = 1.9784e-01, time/batch = 17.4391s	
28475/29850 (epoch 47.697), train_loss = 0.75801125, grad/param norm = 2.4797e-01, time/batch = 19.0355s	
28476/29850 (epoch 47.698), train_loss = 0.85807169, grad/param norm = 2.1946e-01, time/batch = 19.4546s	
28477/29850 (epoch 47.700), train_loss = 0.81357527, grad/param norm = 2.9943e-01, time/batch = 18.2703s	
28478/29850 (epoch 47.702), train_loss = 0.78173211, grad/param norm = 3.4213e-01, time/batch = 17.2894s	
28479/29850 (epoch 47.704), train_loss = 0.66219038, grad/param norm = 2.4763e-01, time/batch = 19.5403s	
28480/29850 (epoch 47.705), train_loss = 0.76058897, grad/param norm = 2.6673e-01, time/batch = 16.4793s	
28481/29850 (epoch 47.707), train_loss = 0.70636071, grad/param norm = 2.4733e-01, time/batch = 16.0958s	
28482/29850 (epoch 47.709), train_loss = 0.74641069, grad/param norm = 2.2450e-01, time/batch = 16.3883s	
28483/29850 (epoch 47.710), train_loss = 0.71186264, grad/param norm = 2.5186e-01, time/batch = 17.9622s	
28484/29850 (epoch 47.712), train_loss = 0.80712687, grad/param norm = 2.2088e-01, time/batch = 16.1288s	
28485/29850 (epoch 47.714), train_loss = 0.83414335, grad/param norm = 2.5630e-01, time/batch = 17.5348s	
28486/29850 (epoch 47.715), train_loss = 0.78645335, grad/param norm = 2.3820e-01, time/batch = 14.7539s	
28487/29850 (epoch 47.717), train_loss = 0.59209770, grad/param norm = 2.2525e-01, time/batch = 15.8736s	
28488/29850 (epoch 47.719), train_loss = 0.74530917, grad/param norm = 2.2432e-01, time/batch = 18.4688s	
28489/29850 (epoch 47.720), train_loss = 0.75075559, grad/param norm = 2.2875e-01, time/batch = 17.7109s	
28490/29850 (epoch 47.722), train_loss = 0.68588515, grad/param norm = 1.8933e-01, time/batch = 17.6056s	
28491/29850 (epoch 47.724), train_loss = 0.79211850, grad/param norm = 2.7629e-01, time/batch = 18.2746s	
28492/29850 (epoch 47.725), train_loss = 0.64139134, grad/param norm = 1.9381e-01, time/batch = 17.1258s	
28493/29850 (epoch 47.727), train_loss = 0.61575382, grad/param norm = 2.1484e-01, time/batch = 18.8752s	
28494/29850 (epoch 47.729), train_loss = 0.62595370, grad/param norm = 1.6541e-01, time/batch = 16.8879s	
28495/29850 (epoch 47.730), train_loss = 0.60699535, grad/param norm = 2.0639e-01, time/batch = 17.5552s	
28496/29850 (epoch 47.732), train_loss = 0.81386226, grad/param norm = 2.1736e-01, time/batch = 18.3050s	
28497/29850 (epoch 47.734), train_loss = 0.91896479, grad/param norm = 2.9955e-01, time/batch = 17.5362s	
28498/29850 (epoch 47.735), train_loss = 0.68845467, grad/param norm = 2.1848e-01, time/batch = 16.0734s	
28499/29850 (epoch 47.737), train_loss = 0.65626415, grad/param norm = 2.1428e-01, time/batch = 17.6507s	
28500/29850 (epoch 47.739), train_loss = 0.56191144, grad/param norm = 2.0347e-01, time/batch = 14.9058s	
28501/29850 (epoch 47.740), train_loss = 0.60855012, grad/param norm = 2.3588e-01, time/batch = 16.6068s	
28502/29850 (epoch 47.742), train_loss = 0.53970367, grad/param norm = 1.7924e-01, time/batch = 17.9640s	
28503/29850 (epoch 47.744), train_loss = 0.66989567, grad/param norm = 2.2307e-01, time/batch = 19.5425s	
28504/29850 (epoch 47.745), train_loss = 0.71364905, grad/param norm = 2.9119e-01, time/batch = 17.8741s	
28505/29850 (epoch 47.747), train_loss = 0.73433280, grad/param norm = 2.2398e-01, time/batch = 19.2781s	
28506/29850 (epoch 47.749), train_loss = 0.62829491, grad/param norm = 2.2696e-01, time/batch = 16.4632s	
28507/29850 (epoch 47.750), train_loss = 0.56884388, grad/param norm = 2.0772e-01, time/batch = 17.1155s	
28508/29850 (epoch 47.752), train_loss = 0.49256408, grad/param norm = 2.3367e-01, time/batch = 17.6223s	
28509/29850 (epoch 47.754), train_loss = 0.57238859, grad/param norm = 2.2717e-01, time/batch = 17.5192s	
28510/29850 (epoch 47.755), train_loss = 0.57452853, grad/param norm = 2.3978e-01, time/batch = 18.6315s	
28511/29850 (epoch 47.757), train_loss = 0.64904332, grad/param norm = 1.8964e-01, time/batch = 17.1249s	
28512/29850 (epoch 47.759), train_loss = 0.63488622, grad/param norm = 2.2008e-01, time/batch = 16.6320s	
28513/29850 (epoch 47.760), train_loss = 0.67318753, grad/param norm = 2.5757e-01, time/batch = 18.1996s	
28514/29850 (epoch 47.762), train_loss = 0.65607978, grad/param norm = 4.9620e-01, time/batch = 17.1253s	
28515/29850 (epoch 47.764), train_loss = 0.53406912, grad/param norm = 2.1092e-01, time/batch = 16.9822s	
28516/29850 (epoch 47.765), train_loss = 0.69034618, grad/param norm = 2.5842e-01, time/batch = 17.2198s	
28517/29850 (epoch 47.767), train_loss = 0.68342959, grad/param norm = 2.2536e-01, time/batch = 18.2998s	
28518/29850 (epoch 47.769), train_loss = 0.74409628, grad/param norm = 2.4162e-01, time/batch = 16.4337s	
28519/29850 (epoch 47.771), train_loss = 0.72806847, grad/param norm = 2.5699e-01, time/batch = 18.6239s	
28520/29850 (epoch 47.772), train_loss = 0.71250632, grad/param norm = 2.4541e-01, time/batch = 18.9535s	
28521/29850 (epoch 47.774), train_loss = 0.66222784, grad/param norm = 2.2373e-01, time/batch = 15.7817s	
28522/29850 (epoch 47.776), train_loss = 0.67425424, grad/param norm = 2.1252e-01, time/batch = 17.5434s	
28523/29850 (epoch 47.777), train_loss = 0.80056375, grad/param norm = 2.6364e-01, time/batch = 18.6411s	
28524/29850 (epoch 47.779), train_loss = 0.64293253, grad/param norm = 2.3766e-01, time/batch = 17.3631s	
28525/29850 (epoch 47.781), train_loss = 0.74677341, grad/param norm = 2.1790e-01, time/batch = 16.9502s	
28526/29850 (epoch 47.782), train_loss = 0.74620041, grad/param norm = 2.1218e-01, time/batch = 15.1146s	
28527/29850 (epoch 47.784), train_loss = 0.60566196, grad/param norm = 3.0250e-01, time/batch = 15.0082s	
28528/29850 (epoch 47.786), train_loss = 0.65674078, grad/param norm = 2.1930e-01, time/batch = 15.1816s	
28529/29850 (epoch 47.787), train_loss = 0.54806870, grad/param norm = 2.1610e-01, time/batch = 17.9647s	
28530/29850 (epoch 47.789), train_loss = 0.56614179, grad/param norm = 1.7384e-01, time/batch = 15.4762s	
28531/29850 (epoch 47.791), train_loss = 0.64056937, grad/param norm = 2.7731e-01, time/batch = 19.3758s	
28532/29850 (epoch 47.792), train_loss = 0.76638443, grad/param norm = 2.6854e-01, time/batch = 16.4607s	
28533/29850 (epoch 47.794), train_loss = 0.71756284, grad/param norm = 2.3050e-01, time/batch = 18.4662s	
28534/29850 (epoch 47.796), train_loss = 0.61406265, grad/param norm = 2.1081e-01, time/batch = 15.7288s	
28535/29850 (epoch 47.797), train_loss = 0.52531232, grad/param norm = 1.8182e-01, time/batch = 17.4608s	
28536/29850 (epoch 47.799), train_loss = 0.58863863, grad/param norm = 1.7622e-01, time/batch = 16.4621s	
28537/29850 (epoch 47.801), train_loss = 0.58157499, grad/param norm = 1.8673e-01, time/batch = 16.0291s	
28538/29850 (epoch 47.802), train_loss = 0.57465989, grad/param norm = 2.3353e-01, time/batch = 18.3814s	
28539/29850 (epoch 47.804), train_loss = 0.61841573, grad/param norm = 1.9198e-01, time/batch = 16.3063s	
28540/29850 (epoch 47.806), train_loss = 0.54942016, grad/param norm = 2.1696e-01, time/batch = 19.1289s	
28541/29850 (epoch 47.807), train_loss = 0.60594569, grad/param norm = 1.8438e-01, time/batch = 17.5154s	
28542/29850 (epoch 47.809), train_loss = 0.58902719, grad/param norm = 2.0560e-01, time/batch = 17.1175s	
28543/29850 (epoch 47.811), train_loss = 0.76478465, grad/param norm = 2.5167e-01, time/batch = 19.5417s	
28544/29850 (epoch 47.812), train_loss = 0.72594546, grad/param norm = 2.4449e-01, time/batch = 16.9672s	
28545/29850 (epoch 47.814), train_loss = 0.76869456, grad/param norm = 2.8929e-01, time/batch = 18.8733s	
28546/29850 (epoch 47.816), train_loss = 0.83854665, grad/param norm = 2.7140e-01, time/batch = 17.5581s	
28547/29850 (epoch 47.817), train_loss = 0.71842286, grad/param norm = 2.7403e-01, time/batch = 16.6682s	
28548/29850 (epoch 47.819), train_loss = 0.55420633, grad/param norm = 2.1837e-01, time/batch = 18.9718s	
28549/29850 (epoch 47.821), train_loss = 0.80610096, grad/param norm = 2.9441e-01, time/batch = 16.3888s	
28550/29850 (epoch 47.822), train_loss = 0.82413569, grad/param norm = 2.1939e-01, time/batch = 16.3778s	
28551/29850 (epoch 47.824), train_loss = 0.70858697, grad/param norm = 2.5187e-01, time/batch = 18.0533s	
28552/29850 (epoch 47.826), train_loss = 0.60763194, grad/param norm = 2.0206e-01, time/batch = 17.3683s	
28553/29850 (epoch 47.827), train_loss = 0.53886903, grad/param norm = 2.0463e-01, time/batch = 15.3000s	
28554/29850 (epoch 47.829), train_loss = 0.72128850, grad/param norm = 2.6362e-01, time/batch = 18.9609s	
28555/29850 (epoch 47.831), train_loss = 0.82745797, grad/param norm = 2.6937e-01, time/batch = 19.1897s	
28556/29850 (epoch 47.832), train_loss = 0.71767690, grad/param norm = 2.1609e-01, time/batch = 15.6856s	
28557/29850 (epoch 47.834), train_loss = 0.54189204, grad/param norm = 1.8283e-01, time/batch = 19.6995s	
28558/29850 (epoch 47.836), train_loss = 0.54595274, grad/param norm = 2.1013e-01, time/batch = 17.2103s	
28559/29850 (epoch 47.838), train_loss = 0.65538171, grad/param norm = 2.8286e-01, time/batch = 17.0530s	
28560/29850 (epoch 47.839), train_loss = 0.53692043, grad/param norm = 2.0743e-01, time/batch = 16.9547s	
28561/29850 (epoch 47.841), train_loss = 0.62541140, grad/param norm = 1.8872e-01, time/batch = 19.6251s	
28562/29850 (epoch 47.843), train_loss = 0.56537009, grad/param norm = 2.1584e-01, time/batch = 18.2005s	
28563/29850 (epoch 47.844), train_loss = 0.59619783, grad/param norm = 1.9774e-01, time/batch = 18.6997s	
28564/29850 (epoch 47.846), train_loss = 0.66246349, grad/param norm = 1.9612e-01, time/batch = 17.3090s	
28565/29850 (epoch 47.848), train_loss = 0.74855850, grad/param norm = 2.9308e-01, time/batch = 19.2131s	
28566/29850 (epoch 47.849), train_loss = 0.68658554, grad/param norm = 2.5903e-01, time/batch = 16.3797s	
28567/29850 (epoch 47.851), train_loss = 0.85370384, grad/param norm = 2.6977e-01, time/batch = 17.1156s	
28568/29850 (epoch 47.853), train_loss = 0.65914310, grad/param norm = 2.5043e-01, time/batch = 17.9592s	
28569/29850 (epoch 47.854), train_loss = 0.84270877, grad/param norm = 2.6839e-01, time/batch = 16.6332s	
28570/29850 (epoch 47.856), train_loss = 0.81623081, grad/param norm = 2.7700e-01, time/batch = 17.8088s	
28571/29850 (epoch 47.858), train_loss = 0.71343460, grad/param norm = 2.3432e-01, time/batch = 18.3833s	
28572/29850 (epoch 47.859), train_loss = 0.62469306, grad/param norm = 2.2963e-01, time/batch = 17.2828s	
28573/29850 (epoch 47.861), train_loss = 0.78522929, grad/param norm = 2.5429e-01, time/batch = 16.5306s	
28574/29850 (epoch 47.863), train_loss = 0.80880719, grad/param norm = 2.7296e-01, time/batch = 17.5504s	
28575/29850 (epoch 47.864), train_loss = 0.82021473, grad/param norm = 2.6599e-01, time/batch = 16.7966s	
28576/29850 (epoch 47.866), train_loss = 0.74691142, grad/param norm = 2.7944e-01, time/batch = 18.6997s	
28577/29850 (epoch 47.868), train_loss = 0.88294453, grad/param norm = 2.5233e-01, time/batch = 17.9509s	
28578/29850 (epoch 47.869), train_loss = 0.79976140, grad/param norm = 2.4485e-01, time/batch = 19.7835s	
28579/29850 (epoch 47.871), train_loss = 0.82510593, grad/param norm = 3.0808e-01, time/batch = 17.0460s	
28580/29850 (epoch 47.873), train_loss = 0.76154162, grad/param norm = 2.5705e-01, time/batch = 19.2839s	
28581/29850 (epoch 47.874), train_loss = 0.76305861, grad/param norm = 2.3698e-01, time/batch = 17.2972s	
28582/29850 (epoch 47.876), train_loss = 0.77323569, grad/param norm = 3.0542e-01, time/batch = 17.0453s	
28583/29850 (epoch 47.878), train_loss = 0.74886123, grad/param norm = 2.2709e-01, time/batch = 16.7949s	
28584/29850 (epoch 47.879), train_loss = 0.78826676, grad/param norm = 2.3555e-01, time/batch = 17.6423s	
28585/29850 (epoch 47.881), train_loss = 0.82154011, grad/param norm = 3.3253e-01, time/batch = 17.5517s	
28586/29850 (epoch 47.883), train_loss = 0.74924446, grad/param norm = 2.2299e-01, time/batch = 16.2127s	
28587/29850 (epoch 47.884), train_loss = 0.64627698, grad/param norm = 2.3521e-01, time/batch = 17.9539s	
28588/29850 (epoch 47.886), train_loss = 0.80223114, grad/param norm = 3.1300e-01, time/batch = 17.9795s	
28589/29850 (epoch 47.888), train_loss = 0.73579948, grad/param norm = 2.3167e-01, time/batch = 17.6240s	
28590/29850 (epoch 47.889), train_loss = 0.71189109, grad/param norm = 2.2228e-01, time/batch = 17.2162s	
28591/29850 (epoch 47.891), train_loss = 0.66968365, grad/param norm = 2.1851e-01, time/batch = 17.8774s	
28592/29850 (epoch 47.893), train_loss = 0.71510348, grad/param norm = 2.4544e-01, time/batch = 16.5545s	
28593/29850 (epoch 47.894), train_loss = 0.70004979, grad/param norm = 2.6237e-01, time/batch = 17.5395s	
28594/29850 (epoch 47.896), train_loss = 0.75749025, grad/param norm = 2.7617e-01, time/batch = 15.6124s	
28595/29850 (epoch 47.898), train_loss = 0.86545871, grad/param norm = 2.2305e-01, time/batch = 16.4726s	
28596/29850 (epoch 47.899), train_loss = 0.65789026, grad/param norm = 2.3487e-01, time/batch = 17.5456s	
28597/29850 (epoch 47.901), train_loss = 0.90784027, grad/param norm = 3.1645e-01, time/batch = 19.5184s	
28598/29850 (epoch 47.903), train_loss = 0.82406917, grad/param norm = 4.2707e-01, time/batch = 17.7084s	
28599/29850 (epoch 47.905), train_loss = 0.99269283, grad/param norm = 2.7058e-01, time/batch = 19.2979s	
28600/29850 (epoch 47.906), train_loss = 0.76580896, grad/param norm = 2.6633e-01, time/batch = 15.6780s	
28601/29850 (epoch 47.908), train_loss = 0.89210250, grad/param norm = 2.5921e-01, time/batch = 16.3086s	
28602/29850 (epoch 47.910), train_loss = 0.80974929, grad/param norm = 2.3511e-01, time/batch = 16.5403s	
28603/29850 (epoch 47.911), train_loss = 0.93881752, grad/param norm = 2.3242e-01, time/batch = 17.8884s	
28604/29850 (epoch 47.913), train_loss = 0.89649105, grad/param norm = 2.4852e-01, time/batch = 15.3798s	
28605/29850 (epoch 47.915), train_loss = 0.90094141, grad/param norm = 2.5032e-01, time/batch = 18.2152s	
28606/29850 (epoch 47.916), train_loss = 0.84615944, grad/param norm = 2.5334e-01, time/batch = 19.9604s	
28607/29850 (epoch 47.918), train_loss = 0.69581895, grad/param norm = 2.1759e-01, time/batch = 15.4218s	
28608/29850 (epoch 47.920), train_loss = 0.86596168, grad/param norm = 2.3448e-01, time/batch = 19.9579s	
28609/29850 (epoch 47.921), train_loss = 0.73318178, grad/param norm = 2.7220e-01, time/batch = 16.8857s	
28610/29850 (epoch 47.923), train_loss = 0.77997705, grad/param norm = 2.5421e-01, time/batch = 17.7884s	
28611/29850 (epoch 47.925), train_loss = 0.91122397, grad/param norm = 2.7036e-01, time/batch = 17.1428s	
28612/29850 (epoch 47.926), train_loss = 0.95853381, grad/param norm = 4.1615e-01, time/batch = 18.3119s	
28613/29850 (epoch 47.928), train_loss = 0.78309731, grad/param norm = 2.3244e-01, time/batch = 17.7869s	
28614/29850 (epoch 47.930), train_loss = 0.78648062, grad/param norm = 2.5194e-01, time/batch = 19.2032s	
28615/29850 (epoch 47.931), train_loss = 0.77096386, grad/param norm = 2.5200e-01, time/batch = 18.1291s	
28616/29850 (epoch 47.933), train_loss = 0.89658608, grad/param norm = 2.8537e-01, time/batch = 18.7978s	
28617/29850 (epoch 47.935), train_loss = 0.83929783, grad/param norm = 2.7741e-01, time/batch = 30.6034s	
28618/29850 (epoch 47.936), train_loss = 0.81168715, grad/param norm = 2.7855e-01, time/batch = 18.1085s	
28619/29850 (epoch 47.938), train_loss = 0.67840862, grad/param norm = 1.9776e-01, time/batch = 16.0212s	
28620/29850 (epoch 47.940), train_loss = 0.70965846, grad/param norm = 2.3665e-01, time/batch = 17.1048s	
28621/29850 (epoch 47.941), train_loss = 0.67087594, grad/param norm = 2.5407e-01, time/batch = 15.8795s	
28622/29850 (epoch 47.943), train_loss = 0.72928065, grad/param norm = 2.5938e-01, time/batch = 18.8084s	
28623/29850 (epoch 47.945), train_loss = 0.68295432, grad/param norm = 3.0689e-01, time/batch = 16.1969s	
28624/29850 (epoch 47.946), train_loss = 0.66040483, grad/param norm = 2.5838e-01, time/batch = 18.9684s	
28625/29850 (epoch 47.948), train_loss = 0.75714254, grad/param norm = 2.0352e-01, time/batch = 17.2120s	
28626/29850 (epoch 47.950), train_loss = 0.72151174, grad/param norm = 1.8564e-01, time/batch = 15.4316s	
28627/29850 (epoch 47.951), train_loss = 0.62362298, grad/param norm = 1.9554e-01, time/batch = 18.3874s	
28628/29850 (epoch 47.953), train_loss = 0.71525145, grad/param norm = 2.4793e-01, time/batch = 18.3491s	
28629/29850 (epoch 47.955), train_loss = 0.62545549, grad/param norm = 1.9249e-01, time/batch = 18.3597s	
28630/29850 (epoch 47.956), train_loss = 0.61948296, grad/param norm = 2.1860e-01, time/batch = 17.1022s	
28631/29850 (epoch 47.958), train_loss = 0.59386676, grad/param norm = 1.9603e-01, time/batch = 18.9455s	
28632/29850 (epoch 47.960), train_loss = 0.83302129, grad/param norm = 2.6132e-01, time/batch = 18.5638s	
28633/29850 (epoch 47.961), train_loss = 0.61131449, grad/param norm = 2.3417e-01, time/batch = 17.2048s	
28634/29850 (epoch 47.963), train_loss = 0.59396737, grad/param norm = 2.0160e-01, time/batch = 16.8750s	
28635/29850 (epoch 47.965), train_loss = 0.66507552, grad/param norm = 2.4707e-01, time/batch = 18.2158s	
28636/29850 (epoch 47.966), train_loss = 0.63840023, grad/param norm = 2.1110e-01, time/batch = 17.4559s	
28637/29850 (epoch 47.968), train_loss = 0.65871435, grad/param norm = 2.4793e-01, time/batch = 16.7993s	
28638/29850 (epoch 47.970), train_loss = 0.68340745, grad/param norm = 2.2667e-01, time/batch = 17.3838s	
28639/29850 (epoch 47.972), train_loss = 0.66818110, grad/param norm = 2.0853e-01, time/batch = 19.0436s	
28640/29850 (epoch 47.973), train_loss = 0.64731026, grad/param norm = 2.0530e-01, time/batch = 17.4530s	
28641/29850 (epoch 47.975), train_loss = 0.58682884, grad/param norm = 2.1559e-01, time/batch = 16.0620s	
28642/29850 (epoch 47.977), train_loss = 0.67874017, grad/param norm = 2.0203e-01, time/batch = 17.1466s	
28643/29850 (epoch 47.978), train_loss = 0.58977194, grad/param norm = 2.1158e-01, time/batch = 17.2244s	
28644/29850 (epoch 47.980), train_loss = 0.65235817, grad/param norm = 1.7360e-01, time/batch = 17.6311s	
28645/29850 (epoch 47.982), train_loss = 0.64104586, grad/param norm = 2.0949e-01, time/batch = 18.1244s	
28646/29850 (epoch 47.983), train_loss = 0.65883169, grad/param norm = 2.2414e-01, time/batch = 17.5775s	
28647/29850 (epoch 47.985), train_loss = 0.78717785, grad/param norm = 2.5413e-01, time/batch = 19.4584s	
28648/29850 (epoch 47.987), train_loss = 0.75313481, grad/param norm = 2.5792e-01, time/batch = 16.7973s	
28649/29850 (epoch 47.988), train_loss = 0.71201741, grad/param norm = 2.5209e-01, time/batch = 20.0177s	
28650/29850 (epoch 47.990), train_loss = 0.76558636, grad/param norm = 2.2223e-01, time/batch = 15.7236s	
28651/29850 (epoch 47.992), train_loss = 0.73619288, grad/param norm = 2.1041e-01, time/batch = 18.7952s	
28652/29850 (epoch 47.993), train_loss = 0.74965969, grad/param norm = 2.4105e-01, time/batch = 16.4000s	
28653/29850 (epoch 47.995), train_loss = 0.71112475, grad/param norm = 2.0939e-01, time/batch = 15.2106s	
28654/29850 (epoch 47.997), train_loss = 0.76526788, grad/param norm = 2.7055e-01, time/batch = 17.1336s	
28655/29850 (epoch 47.998), train_loss = 0.78035369, grad/param norm = 2.5737e-01, time/batch = 18.9677s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
28656/29850 (epoch 48.000), train_loss = 0.60548229, grad/param norm = 2.1444e-01, time/batch = 17.8864s	
28657/29850 (epoch 48.002), train_loss = 0.83035867, grad/param norm = 2.2380e-01, time/batch = 16.7603s	
28658/29850 (epoch 48.003), train_loss = 0.60157478, grad/param norm = 2.4626e-01, time/batch = 16.8845s	
28659/29850 (epoch 48.005), train_loss = 0.80014131, grad/param norm = 2.5626e-01, time/batch = 17.2118s	
28660/29850 (epoch 48.007), train_loss = 0.82513003, grad/param norm = 2.6546e-01, time/batch = 18.0373s	
28661/29850 (epoch 48.008), train_loss = 0.95841238, grad/param norm = 3.0771e-01, time/batch = 16.4734s	
28662/29850 (epoch 48.010), train_loss = 0.66227122, grad/param norm = 2.0988e-01, time/batch = 16.5456s	
28663/29850 (epoch 48.012), train_loss = 0.70834766, grad/param norm = 2.2290e-01, time/batch = 17.8801s	
28664/29850 (epoch 48.013), train_loss = 0.73831011, grad/param norm = 2.6126e-01, time/batch = 16.6116s	
28665/29850 (epoch 48.015), train_loss = 0.83877964, grad/param norm = 2.5190e-01, time/batch = 19.6190s	
28666/29850 (epoch 48.017), train_loss = 0.78589011, grad/param norm = 3.2502e-01, time/batch = 18.8112s	
28667/29850 (epoch 48.018), train_loss = 0.86515855, grad/param norm = 2.4356e-01, time/batch = 16.2762s	
28668/29850 (epoch 48.020), train_loss = 0.76493479, grad/param norm = 2.4597e-01, time/batch = 16.3980s	
28669/29850 (epoch 48.022), train_loss = 0.83307112, grad/param norm = 2.4530e-01, time/batch = 17.1452s	
28670/29850 (epoch 48.023), train_loss = 0.78829748, grad/param norm = 2.0055e-01, time/batch = 18.3660s	
28671/29850 (epoch 48.025), train_loss = 0.74714856, grad/param norm = 1.9775e-01, time/batch = 18.1373s	
28672/29850 (epoch 48.027), train_loss = 0.54838122, grad/param norm = 2.0635e-01, time/batch = 17.3862s	
28673/29850 (epoch 48.028), train_loss = 0.68163566, grad/param norm = 2.1020e-01, time/batch = 19.0468s	
28674/29850 (epoch 48.030), train_loss = 0.69207850, grad/param norm = 2.7485e-01, time/batch = 18.0876s	
28675/29850 (epoch 48.032), train_loss = 0.79735441, grad/param norm = 2.4527e-01, time/batch = 19.1004s	
28676/29850 (epoch 48.034), train_loss = 0.67244847, grad/param norm = 2.3557e-01, time/batch = 16.5507s	
28677/29850 (epoch 48.035), train_loss = 0.57689545, grad/param norm = 1.9908e-01, time/batch = 18.5486s	
28678/29850 (epoch 48.037), train_loss = 0.73515548, grad/param norm = 2.7439e-01, time/batch = 16.9610s	
28679/29850 (epoch 48.039), train_loss = 0.64961953, grad/param norm = 1.8299e-01, time/batch = 18.6387s	
28680/29850 (epoch 48.040), train_loss = 0.61036233, grad/param norm = 1.9121e-01, time/batch = 17.7773s	
28681/29850 (epoch 48.042), train_loss = 0.68414815, grad/param norm = 2.5720e-01, time/batch = 17.2905s	
28682/29850 (epoch 48.044), train_loss = 0.73039692, grad/param norm = 2.0898e-01, time/batch = 19.3780s	
28683/29850 (epoch 48.045), train_loss = 0.80172996, grad/param norm = 2.4574e-01, time/batch = 18.6286s	
28684/29850 (epoch 48.047), train_loss = 0.63699572, grad/param norm = 2.0979e-01, time/batch = 17.9503s	
28685/29850 (epoch 48.049), train_loss = 0.76019376, grad/param norm = 2.0656e-01, time/batch = 15.4585s	
28686/29850 (epoch 48.050), train_loss = 0.70981874, grad/param norm = 2.4093e-01, time/batch = 17.8657s	
28687/29850 (epoch 48.052), train_loss = 0.84269181, grad/param norm = 2.7808e-01, time/batch = 17.6197s	
28688/29850 (epoch 48.054), train_loss = 0.72434785, grad/param norm = 2.1703e-01, time/batch = 19.6164s	
28689/29850 (epoch 48.055), train_loss = 0.71227466, grad/param norm = 2.0842e-01, time/batch = 17.3624s	
28690/29850 (epoch 48.057), train_loss = 0.78815599, grad/param norm = 2.0060e-01, time/batch = 18.5175s	
28691/29850 (epoch 48.059), train_loss = 0.76795641, grad/param norm = 2.6174e-01, time/batch = 19.2893s	
28692/29850 (epoch 48.060), train_loss = 0.74208789, grad/param norm = 2.3825e-01, time/batch = 19.0402s	
28693/29850 (epoch 48.062), train_loss = 0.83945925, grad/param norm = 3.2878e-01, time/batch = 16.7792s	
28694/29850 (epoch 48.064), train_loss = 0.84267438, grad/param norm = 2.8652e-01, time/batch = 19.0350s	
28695/29850 (epoch 48.065), train_loss = 0.62122390, grad/param norm = 2.2001e-01, time/batch = 19.0527s	
28696/29850 (epoch 48.067), train_loss = 0.79889767, grad/param norm = 2.2414e-01, time/batch = 16.5345s	
28697/29850 (epoch 48.069), train_loss = 0.76325774, grad/param norm = 2.1481e-01, time/batch = 16.9425s	
28698/29850 (epoch 48.070), train_loss = 0.80895898, grad/param norm = 2.1123e-01, time/batch = 17.6440s	
28699/29850 (epoch 48.072), train_loss = 0.75107124, grad/param norm = 2.2687e-01, time/batch = 18.9679s	
28700/29850 (epoch 48.074), train_loss = 0.82649789, grad/param norm = 2.2517e-01, time/batch = 16.8738s	
28701/29850 (epoch 48.075), train_loss = 0.69539657, grad/param norm = 2.4688e-01, time/batch = 16.5483s	
28702/29850 (epoch 48.077), train_loss = 0.80913745, grad/param norm = 2.4443e-01, time/batch = 17.9701s	
28703/29850 (epoch 48.079), train_loss = 0.98604408, grad/param norm = 3.3118e-01, time/batch = 16.6525s	
28704/29850 (epoch 48.080), train_loss = 0.94433450, grad/param norm = 3.0045e-01, time/batch = 17.3555s	
28705/29850 (epoch 48.082), train_loss = 0.82655641, grad/param norm = 2.9469e-01, time/batch = 15.1450s	
28706/29850 (epoch 48.084), train_loss = 0.90924875, grad/param norm = 2.3149e-01, time/batch = 14.5356s	
28707/29850 (epoch 48.085), train_loss = 0.94430020, grad/param norm = 3.2445e-01, time/batch = 16.2027s	
28708/29850 (epoch 48.087), train_loss = 0.85937887, grad/param norm = 2.3069e-01, time/batch = 18.3578s	
28709/29850 (epoch 48.089), train_loss = 0.80386332, grad/param norm = 2.0902e-01, time/batch = 18.6377s	
28710/29850 (epoch 48.090), train_loss = 0.78562161, grad/param norm = 2.5186e-01, time/batch = 15.9615s	
28711/29850 (epoch 48.092), train_loss = 0.69099533, grad/param norm = 2.1695e-01, time/batch = 17.2886s	
28712/29850 (epoch 48.094), train_loss = 0.90071028, grad/param norm = 2.4984e-01, time/batch = 18.7637s	
28713/29850 (epoch 48.095), train_loss = 0.85095860, grad/param norm = 2.7955e-01, time/batch = 17.6327s	
28714/29850 (epoch 48.097), train_loss = 0.59394246, grad/param norm = 1.8178e-01, time/batch = 18.4521s	
28715/29850 (epoch 48.099), train_loss = 0.60460346, grad/param norm = 1.9197e-01, time/batch = 18.4661s	
28716/29850 (epoch 48.101), train_loss = 0.79134591, grad/param norm = 2.1625e-01, time/batch = 18.2930s	
28717/29850 (epoch 48.102), train_loss = 0.80874813, grad/param norm = 2.8041e-01, time/batch = 18.7150s	
28718/29850 (epoch 48.104), train_loss = 0.73667736, grad/param norm = 2.8768e-01, time/batch = 16.3985s	
28719/29850 (epoch 48.106), train_loss = 0.84051186, grad/param norm = 2.4691e-01, time/batch = 15.9843s	
28720/29850 (epoch 48.107), train_loss = 0.73095319, grad/param norm = 2.1049e-01, time/batch = 18.5492s	
28721/29850 (epoch 48.109), train_loss = 0.76153484, grad/param norm = 2.2054e-01, time/batch = 15.7192s	
28722/29850 (epoch 48.111), train_loss = 0.78058727, grad/param norm = 2.2046e-01, time/batch = 15.9093s	
28723/29850 (epoch 48.112), train_loss = 0.67451481, grad/param norm = 2.1465e-01, time/batch = 16.6138s	
28724/29850 (epoch 48.114), train_loss = 0.71184748, grad/param norm = 2.4185e-01, time/batch = 18.7776s	
28725/29850 (epoch 48.116), train_loss = 0.69014157, grad/param norm = 2.4879e-01, time/batch = 18.0388s	
28726/29850 (epoch 48.117), train_loss = 0.71381540, grad/param norm = 2.4270e-01, time/batch = 15.8744s	
28727/29850 (epoch 48.119), train_loss = 0.70761886, grad/param norm = 2.1628e-01, time/batch = 16.7153s	
28728/29850 (epoch 48.121), train_loss = 0.62541680, grad/param norm = 4.2766e-01, time/batch = 17.7873s	
28729/29850 (epoch 48.122), train_loss = 0.66166805, grad/param norm = 1.8312e-01, time/batch = 19.0369s	
28730/29850 (epoch 48.124), train_loss = 0.68400633, grad/param norm = 2.3768e-01, time/batch = 17.3892s	
28731/29850 (epoch 48.126), train_loss = 0.74258132, grad/param norm = 2.3300e-01, time/batch = 17.4540s	
28732/29850 (epoch 48.127), train_loss = 0.77906235, grad/param norm = 3.0750e-01, time/batch = 18.6981s	
28733/29850 (epoch 48.129), train_loss = 0.76205805, grad/param norm = 2.2724e-01, time/batch = 16.7768s	
28734/29850 (epoch 48.131), train_loss = 0.76268426, grad/param norm = 2.1366e-01, time/batch = 19.8593s	
28735/29850 (epoch 48.132), train_loss = 0.65808367, grad/param norm = 2.8257e-01, time/batch = 16.6280s	
28736/29850 (epoch 48.134), train_loss = 0.72150836, grad/param norm = 2.3599e-01, time/batch = 17.3171s	
28737/29850 (epoch 48.136), train_loss = 0.83307720, grad/param norm = 2.3970e-01, time/batch = 17.6333s	
28738/29850 (epoch 48.137), train_loss = 0.62249704, grad/param norm = 2.4368e-01, time/batch = 16.8702s	
28739/29850 (epoch 48.139), train_loss = 0.74172973, grad/param norm = 2.0586e-01, time/batch = 19.6922s	
28740/29850 (epoch 48.141), train_loss = 0.66984908, grad/param norm = 2.4738e-01, time/batch = 19.1302s	
28741/29850 (epoch 48.142), train_loss = 0.84256662, grad/param norm = 2.5525e-01, time/batch = 16.4655s	
28742/29850 (epoch 48.144), train_loss = 0.98524904, grad/param norm = 2.7060e-01, time/batch = 16.9253s	
28743/29850 (epoch 48.146), train_loss = 0.95640741, grad/param norm = 2.8085e-01, time/batch = 17.8073s	
28744/29850 (epoch 48.147), train_loss = 0.87479320, grad/param norm = 2.9496e-01, time/batch = 16.7967s	
28745/29850 (epoch 48.149), train_loss = 0.81228144, grad/param norm = 2.5211e-01, time/batch = 17.5495s	
28746/29850 (epoch 48.151), train_loss = 0.80444475, grad/param norm = 2.4807e-01, time/batch = 18.0483s	
28747/29850 (epoch 48.152), train_loss = 0.75712403, grad/param norm = 2.3792e-01, time/batch = 18.4671s	
28748/29850 (epoch 48.154), train_loss = 0.71753965, grad/param norm = 2.4063e-01, time/batch = 16.0400s	
28749/29850 (epoch 48.156), train_loss = 0.69587239, grad/param norm = 2.4497e-01, time/batch = 16.6168s	
28750/29850 (epoch 48.157), train_loss = 0.80541548, grad/param norm = 2.3597e-01, time/batch = 17.8694s	
28751/29850 (epoch 48.159), train_loss = 0.72669645, grad/param norm = 3.1024e-01, time/batch = 18.9601s	
28752/29850 (epoch 48.161), train_loss = 0.74326321, grad/param norm = 2.4246e-01, time/batch = 15.3013s	
28753/29850 (epoch 48.162), train_loss = 0.88403182, grad/param norm = 3.1093e-01, time/batch = 18.6328s	
28754/29850 (epoch 48.164), train_loss = 0.80732377, grad/param norm = 2.6232e-01, time/batch = 18.8824s	
28755/29850 (epoch 48.166), train_loss = 0.73840345, grad/param norm = 2.5594e-01, time/batch = 16.8785s	
28756/29850 (epoch 48.168), train_loss = 0.66763863, grad/param norm = 2.1693e-01, time/batch = 17.3884s	
28757/29850 (epoch 48.169), train_loss = 0.87623172, grad/param norm = 2.9894e-01, time/batch = 16.9436s	
28758/29850 (epoch 48.171), train_loss = 0.83919417, grad/param norm = 2.6054e-01, time/batch = 17.4708s	
28759/29850 (epoch 48.173), train_loss = 0.65257542, grad/param norm = 2.0393e-01, time/batch = 18.2174s	
28760/29850 (epoch 48.174), train_loss = 0.72413698, grad/param norm = 2.7776e-01, time/batch = 19.6239s	
28761/29850 (epoch 48.176), train_loss = 0.79785654, grad/param norm = 2.5668e-01, time/batch = 17.8670s	
28762/29850 (epoch 48.178), train_loss = 0.81437959, grad/param norm = 2.6480e-01, time/batch = 16.3000s	
28763/29850 (epoch 48.179), train_loss = 0.61463435, grad/param norm = 2.0668e-01, time/batch = 17.6296s	
28764/29850 (epoch 48.181), train_loss = 0.76897919, grad/param norm = 2.7658e-01, time/batch = 18.7884s	
28765/29850 (epoch 48.183), train_loss = 0.76316626, grad/param norm = 2.1960e-01, time/batch = 17.2156s	
28766/29850 (epoch 48.184), train_loss = 0.85323248, grad/param norm = 2.8383e-01, time/batch = 16.3920s	
28767/29850 (epoch 48.186), train_loss = 0.80908692, grad/param norm = 2.4508e-01, time/batch = 19.4724s	
28768/29850 (epoch 48.188), train_loss = 0.91303234, grad/param norm = 2.7844e-01, time/batch = 17.7953s	
28769/29850 (epoch 48.189), train_loss = 0.81824627, grad/param norm = 2.5860e-01, time/batch = 16.8805s	
28770/29850 (epoch 48.191), train_loss = 0.82973053, grad/param norm = 2.1911e-01, time/batch = 17.1467s	
28771/29850 (epoch 48.193), train_loss = 0.74313152, grad/param norm = 2.1333e-01, time/batch = 17.5381s	
28772/29850 (epoch 48.194), train_loss = 0.85945686, grad/param norm = 2.4580e-01, time/batch = 16.6948s	
28773/29850 (epoch 48.196), train_loss = 0.73862095, grad/param norm = 2.4394e-01, time/batch = 17.4727s	
28774/29850 (epoch 48.198), train_loss = 0.67884675, grad/param norm = 2.2840e-01, time/batch = 18.6368s	
28775/29850 (epoch 48.199), train_loss = 0.93736015, grad/param norm = 2.5521e-01, time/batch = 16.4634s	
28776/29850 (epoch 48.201), train_loss = 0.71284571, grad/param norm = 2.3670e-01, time/batch = 19.0628s	
28777/29850 (epoch 48.203), train_loss = 0.54407153, grad/param norm = 2.2612e-01, time/batch = 15.9546s	
28778/29850 (epoch 48.204), train_loss = 0.72934136, grad/param norm = 2.5046e-01, time/batch = 16.6297s	
28779/29850 (epoch 48.206), train_loss = 0.66380545, grad/param norm = 2.4315e-01, time/batch = 16.4555s	
28780/29850 (epoch 48.208), train_loss = 0.88760923, grad/param norm = 2.9767e-01, time/batch = 19.3731s	
28781/29850 (epoch 48.209), train_loss = 0.67154358, grad/param norm = 2.1954e-01, time/batch = 19.0515s	
28782/29850 (epoch 48.211), train_loss = 0.74401820, grad/param norm = 2.2288e-01, time/batch = 17.2523s	
28783/29850 (epoch 48.213), train_loss = 0.78255809, grad/param norm = 2.2902e-01, time/batch = 18.2983s	
28784/29850 (epoch 48.214), train_loss = 0.62583935, grad/param norm = 1.9415e-01, time/batch = 17.3921s	
28785/29850 (epoch 48.216), train_loss = 0.67830597, grad/param norm = 2.6740e-01, time/batch = 18.0967s	
28786/29850 (epoch 48.218), train_loss = 0.76352475, grad/param norm = 2.1871e-01, time/batch = 17.0550s	
28787/29850 (epoch 48.219), train_loss = 0.75030598, grad/param norm = 2.5038e-01, time/batch = 17.4821s	
28788/29850 (epoch 48.221), train_loss = 0.74710444, grad/param norm = 2.5061e-01, time/batch = 18.1432s	
28789/29850 (epoch 48.223), train_loss = 0.58857475, grad/param norm = 2.0432e-01, time/batch = 16.2874s	
28790/29850 (epoch 48.224), train_loss = 0.61351312, grad/param norm = 2.0317e-01, time/batch = 19.0347s	
28791/29850 (epoch 48.226), train_loss = 0.67721377, grad/param norm = 2.7710e-01, time/batch = 19.0128s	
28792/29850 (epoch 48.228), train_loss = 0.73786838, grad/param norm = 2.5279e-01, time/batch = 18.1191s	
28793/29850 (epoch 48.229), train_loss = 0.62352733, grad/param norm = 1.9024e-01, time/batch = 20.1111s	
28794/29850 (epoch 48.231), train_loss = 0.76985986, grad/param norm = 2.2581e-01, time/batch = 17.6117s	
28795/29850 (epoch 48.233), train_loss = 0.73261903, grad/param norm = 2.8259e-01, time/batch = 16.1710s	
28796/29850 (epoch 48.235), train_loss = 0.67045799, grad/param norm = 2.1188e-01, time/batch = 17.9505s	
28797/29850 (epoch 48.236), train_loss = 0.89298366, grad/param norm = 3.2542e-01, time/batch = 17.2226s	
28798/29850 (epoch 48.238), train_loss = 0.64759365, grad/param norm = 2.2589e-01, time/batch = 19.0486s	
28799/29850 (epoch 48.240), train_loss = 0.65360091, grad/param norm = 2.3667e-01, time/batch = 16.1781s	
28800/29850 (epoch 48.241), train_loss = 0.76695996, grad/param norm = 3.2513e-01, time/batch = 18.2867s	
28801/29850 (epoch 48.243), train_loss = 0.80604124, grad/param norm = 2.5657e-01, time/batch = 18.9783s	
28802/29850 (epoch 48.245), train_loss = 0.64376327, grad/param norm = 2.0373e-01, time/batch = 16.6258s	
28803/29850 (epoch 48.246), train_loss = 0.70338472, grad/param norm = 2.0450e-01, time/batch = 15.6238s	
28804/29850 (epoch 48.248), train_loss = 0.64310390, grad/param norm = 1.9059e-01, time/batch = 17.8968s	
28805/29850 (epoch 48.250), train_loss = 0.70978833, grad/param norm = 1.9988e-01, time/batch = 18.9403s	
28806/29850 (epoch 48.251), train_loss = 0.58202982, grad/param norm = 2.1052e-01, time/batch = 18.2883s	
28807/29850 (epoch 48.253), train_loss = 0.60992484, grad/param norm = 2.5741e-01, time/batch = 18.3047s	
28808/29850 (epoch 48.255), train_loss = 0.66516203, grad/param norm = 2.3780e-01, time/batch = 18.3090s	
28809/29850 (epoch 48.256), train_loss = 0.78080186, grad/param norm = 2.5865e-01, time/batch = 15.0541s	
28810/29850 (epoch 48.258), train_loss = 0.79955311, grad/param norm = 2.4800e-01, time/batch = 18.8719s	
28811/29850 (epoch 48.260), train_loss = 0.72899884, grad/param norm = 2.0531e-01, time/batch = 18.2107s	
28812/29850 (epoch 48.261), train_loss = 0.66337419, grad/param norm = 2.7533e-01, time/batch = 18.0346s	
28813/29850 (epoch 48.263), train_loss = 0.65288872, grad/param norm = 2.0378e-01, time/batch = 16.7960s	
28814/29850 (epoch 48.265), train_loss = 0.71881675, grad/param norm = 2.7425e-01, time/batch = 18.4595s	
28815/29850 (epoch 48.266), train_loss = 0.73603394, grad/param norm = 2.0414e-01, time/batch = 18.1945s	
28816/29850 (epoch 48.268), train_loss = 0.70584811, grad/param norm = 2.0240e-01, time/batch = 18.4522s	
28817/29850 (epoch 48.270), train_loss = 0.65253116, grad/param norm = 2.1467e-01, time/batch = 19.2089s	
28818/29850 (epoch 48.271), train_loss = 0.75945139, grad/param norm = 2.2961e-01, time/batch = 18.3718s	
28819/29850 (epoch 48.273), train_loss = 0.64430853, grad/param norm = 2.5279e-01, time/batch = 30.2474s	
28820/29850 (epoch 48.275), train_loss = 0.63992510, grad/param norm = 1.8345e-01, time/batch = 16.2323s	
28821/29850 (epoch 48.276), train_loss = 0.64279725, grad/param norm = 2.1319e-01, time/batch = 16.3063s	
28822/29850 (epoch 48.278), train_loss = 0.67475773, grad/param norm = 1.9913e-01, time/batch = 17.9419s	
28823/29850 (epoch 48.280), train_loss = 0.89883544, grad/param norm = 3.9326e-01, time/batch = 17.0655s	
28824/29850 (epoch 48.281), train_loss = 0.75958496, grad/param norm = 2.3982e-01, time/batch = 17.0295s	
28825/29850 (epoch 48.283), train_loss = 0.79058713, grad/param norm = 2.4027e-01, time/batch = 17.5321s	
28826/29850 (epoch 48.285), train_loss = 0.81360953, grad/param norm = 2.4461e-01, time/batch = 19.3668s	
28827/29850 (epoch 48.286), train_loss = 0.84361724, grad/param norm = 2.4586e-01, time/batch = 17.2982s	
28828/29850 (epoch 48.288), train_loss = 0.75379040, grad/param norm = 3.0168e-01, time/batch = 17.6991s	
28829/29850 (epoch 48.290), train_loss = 0.77193629, grad/param norm = 2.5623e-01, time/batch = 19.2136s	
28830/29850 (epoch 48.291), train_loss = 0.94828447, grad/param norm = 2.6763e-01, time/batch = 18.2146s	
28831/29850 (epoch 48.293), train_loss = 0.86687625, grad/param norm = 2.7420e-01, time/batch = 18.4667s	
28832/29850 (epoch 48.295), train_loss = 0.94791343, grad/param norm = 2.8265e-01, time/batch = 17.7877s	
28833/29850 (epoch 48.296), train_loss = 0.70282688, grad/param norm = 2.2046e-01, time/batch = 16.9751s	
28834/29850 (epoch 48.298), train_loss = 0.58528497, grad/param norm = 2.4119e-01, time/batch = 15.5540s	
28835/29850 (epoch 48.300), train_loss = 0.63232620, grad/param norm = 2.0476e-01, time/batch = 15.4998s	
28836/29850 (epoch 48.302), train_loss = 0.63940340, grad/param norm = 1.9832e-01, time/batch = 16.4505s	
28837/29850 (epoch 48.303), train_loss = 0.67365727, grad/param norm = 2.2355e-01, time/batch = 15.3349s	
28838/29850 (epoch 48.305), train_loss = 0.83039937, grad/param norm = 2.3936e-01, time/batch = 17.2934s	
28839/29850 (epoch 48.307), train_loss = 0.79750543, grad/param norm = 2.3571e-01, time/batch = 16.7011s	
28840/29850 (epoch 48.308), train_loss = 0.63827406, grad/param norm = 2.6883e-01, time/batch = 18.5447s	
28841/29850 (epoch 48.310), train_loss = 0.80842015, grad/param norm = 2.5215e-01, time/batch = 19.1202s	
28842/29850 (epoch 48.312), train_loss = 0.86417222, grad/param norm = 2.3175e-01, time/batch = 15.3423s	
28843/29850 (epoch 48.313), train_loss = 0.77760831, grad/param norm = 2.9358e-01, time/batch = 15.4713s	
28844/29850 (epoch 48.315), train_loss = 0.79367780, grad/param norm = 2.3653e-01, time/batch = 19.0608s	
28845/29850 (epoch 48.317), train_loss = 0.76296753, grad/param norm = 2.2031e-01, time/batch = 17.5308s	
28846/29850 (epoch 48.318), train_loss = 0.70671744, grad/param norm = 2.3999e-01, time/batch = 15.5990s	
28847/29850 (epoch 48.320), train_loss = 0.69333126, grad/param norm = 2.1846e-01, time/batch = 16.8881s	
28848/29850 (epoch 48.322), train_loss = 0.84546571, grad/param norm = 2.5844e-01, time/batch = 18.8811s	
28849/29850 (epoch 48.323), train_loss = 0.77228906, grad/param norm = 2.4389e-01, time/batch = 17.3853s	
28850/29850 (epoch 48.325), train_loss = 0.82111549, grad/param norm = 2.4500e-01, time/batch = 17.1252s	
28851/29850 (epoch 48.327), train_loss = 0.94400466, grad/param norm = 2.3486e-01, time/batch = 17.6505s	
28852/29850 (epoch 48.328), train_loss = 0.85940753, grad/param norm = 2.7158e-01, time/batch = 18.8693s	
28853/29850 (epoch 48.330), train_loss = 0.84656016, grad/param norm = 2.2861e-01, time/batch = 17.3712s	
28854/29850 (epoch 48.332), train_loss = 0.74975339, grad/param norm = 2.5115e-01, time/batch = 16.9805s	
28855/29850 (epoch 48.333), train_loss = 0.79107314, grad/param norm = 3.0765e-01, time/batch = 19.0519s	
28856/29850 (epoch 48.335), train_loss = 0.85339984, grad/param norm = 2.4801e-01, time/batch = 16.6357s	
28857/29850 (epoch 48.337), train_loss = 0.78542560, grad/param norm = 2.6290e-01, time/batch = 18.0602s	
28858/29850 (epoch 48.338), train_loss = 0.81568883, grad/param norm = 2.1465e-01, time/batch = 17.7989s	
28859/29850 (epoch 48.340), train_loss = 0.66524359, grad/param norm = 2.2284e-01, time/batch = 18.6187s	
28860/29850 (epoch 48.342), train_loss = 0.75353840, grad/param norm = 2.5696e-01, time/batch = 17.8766s	
28861/29850 (epoch 48.343), train_loss = 0.75736379, grad/param norm = 2.6307e-01, time/batch = 18.5501s	
28862/29850 (epoch 48.345), train_loss = 0.82861590, grad/param norm = 2.8652e-01, time/batch = 17.2726s	
28863/29850 (epoch 48.347), train_loss = 0.83841872, grad/param norm = 2.2671e-01, time/batch = 15.6893s	
28864/29850 (epoch 48.348), train_loss = 0.69408912, grad/param norm = 2.0229e-01, time/batch = 17.3061s	
28865/29850 (epoch 48.350), train_loss = 0.79456745, grad/param norm = 3.0770e-01, time/batch = 17.1474s	
28866/29850 (epoch 48.352), train_loss = 0.71451048, grad/param norm = 1.9890e-01, time/batch = 16.2950s	
28867/29850 (epoch 48.353), train_loss = 0.79171090, grad/param norm = 2.5770e-01, time/batch = 19.2876s	
28868/29850 (epoch 48.355), train_loss = 0.70117461, grad/param norm = 2.4913e-01, time/batch = 17.7133s	
28869/29850 (epoch 48.357), train_loss = 0.85432259, grad/param norm = 2.1226e-01, time/batch = 17.7961s	
28870/29850 (epoch 48.358), train_loss = 0.69246743, grad/param norm = 2.0103e-01, time/batch = 16.1251s	
28871/29850 (epoch 48.360), train_loss = 0.74785768, grad/param norm = 2.3452e-01, time/batch = 15.9726s	
28872/29850 (epoch 48.362), train_loss = 0.76394312, grad/param norm = 2.5880e-01, time/batch = 17.8711s	
28873/29850 (epoch 48.363), train_loss = 0.79608342, grad/param norm = 2.5876e-01, time/batch = 16.8716s	
28874/29850 (epoch 48.365), train_loss = 0.88016217, grad/param norm = 3.0648e-01, time/batch = 19.1937s	
28875/29850 (epoch 48.367), train_loss = 0.68805671, grad/param norm = 2.0508e-01, time/batch = 16.8810s	
28876/29850 (epoch 48.369), train_loss = 0.59450633, grad/param norm = 2.7037e-01, time/batch = 17.9609s	
28877/29850 (epoch 48.370), train_loss = 0.63465278, grad/param norm = 2.2572e-01, time/batch = 16.8382s	
28878/29850 (epoch 48.372), train_loss = 0.85090080, grad/param norm = 2.4022e-01, time/batch = 19.6314s	
28879/29850 (epoch 48.374), train_loss = 0.83609204, grad/param norm = 2.2590e-01, time/batch = 17.1240s	
28880/29850 (epoch 48.375), train_loss = 0.78266726, grad/param norm = 2.7800e-01, time/batch = 17.6176s	
28881/29850 (epoch 48.377), train_loss = 0.64832491, grad/param norm = 2.1930e-01, time/batch = 17.6033s	
28882/29850 (epoch 48.379), train_loss = 0.85038610, grad/param norm = 2.6013e-01, time/batch = 18.0514s	
28883/29850 (epoch 48.380), train_loss = 0.81211201, grad/param norm = 2.4043e-01, time/batch = 17.2859s	
28884/29850 (epoch 48.382), train_loss = 0.76968520, grad/param norm = 2.4397e-01, time/batch = 18.2132s	
28885/29850 (epoch 48.384), train_loss = 0.81786360, grad/param norm = 2.4098e-01, time/batch = 17.2151s	
28886/29850 (epoch 48.385), train_loss = 0.81599452, grad/param norm = 2.7329e-01, time/batch = 17.0529s	
28887/29850 (epoch 48.387), train_loss = 0.78541850, grad/param norm = 2.6311e-01, time/batch = 17.4556s	
28888/29850 (epoch 48.389), train_loss = 0.88174630, grad/param norm = 3.1202e-01, time/batch = 16.2055s	
28889/29850 (epoch 48.390), train_loss = 0.84707779, grad/param norm = 2.6220e-01, time/batch = 17.0557s	
28890/29850 (epoch 48.392), train_loss = 0.79640555, grad/param norm = 2.7117e-01, time/batch = 16.2096s	
28891/29850 (epoch 48.394), train_loss = 0.79210687, grad/param norm = 2.2948e-01, time/batch = 18.5478s	
28892/29850 (epoch 48.395), train_loss = 0.73565117, grad/param norm = 3.0546e-01, time/batch = 18.4594s	
28893/29850 (epoch 48.397), train_loss = 0.65678894, grad/param norm = 2.4735e-01, time/batch = 15.6377s	
28894/29850 (epoch 48.399), train_loss = 0.69451194, grad/param norm = 2.5321e-01, time/batch = 17.8721s	
28895/29850 (epoch 48.400), train_loss = 1.03175997, grad/param norm = 2.7275e-01, time/batch = 15.5121s	
28896/29850 (epoch 48.402), train_loss = 0.86299970, grad/param norm = 2.4102e-01, time/batch = 15.2618s	
28897/29850 (epoch 48.404), train_loss = 0.76308320, grad/param norm = 2.1270e-01, time/batch = 17.3653s	
28898/29850 (epoch 48.405), train_loss = 0.70461003, grad/param norm = 2.2841e-01, time/batch = 19.7024s	
28899/29850 (epoch 48.407), train_loss = 0.68959178, grad/param norm = 2.6960e-01, time/batch = 17.3781s	
28900/29850 (epoch 48.409), train_loss = 0.76602972, grad/param norm = 2.2885e-01, time/batch = 17.4600s	
28901/29850 (epoch 48.410), train_loss = 0.83660882, grad/param norm = 2.6445e-01, time/batch = 17.8680s	
28902/29850 (epoch 48.412), train_loss = 0.84519574, grad/param norm = 2.6377e-01, time/batch = 18.8843s	
28903/29850 (epoch 48.414), train_loss = 0.78511837, grad/param norm = 2.6121e-01, time/batch = 16.4700s	
28904/29850 (epoch 48.415), train_loss = 0.76276216, grad/param norm = 2.3603e-01, time/batch = 18.0078s	
28905/29850 (epoch 48.417), train_loss = 0.87673330, grad/param norm = 2.6186e-01, time/batch = 17.9738s	
28906/29850 (epoch 48.419), train_loss = 0.75178682, grad/param norm = 2.3878e-01, time/batch = 17.0546s	
28907/29850 (epoch 48.420), train_loss = 0.74467681, grad/param norm = 2.4490e-01, time/batch = 16.4467s	
28908/29850 (epoch 48.422), train_loss = 0.75701864, grad/param norm = 2.2213e-01, time/batch = 17.7962s	
28909/29850 (epoch 48.424), train_loss = 0.65945277, grad/param norm = 2.2461e-01, time/batch = 18.9748s	
28910/29850 (epoch 48.425), train_loss = 0.82416245, grad/param norm = 3.0452e-01, time/batch = 17.8765s	
28911/29850 (epoch 48.427), train_loss = 0.58351879, grad/param norm = 2.3261e-01, time/batch = 16.2097s	
28912/29850 (epoch 48.429), train_loss = 0.68042832, grad/param norm = 2.3832e-01, time/batch = 18.4388s	
28913/29850 (epoch 48.430), train_loss = 0.63440597, grad/param norm = 2.2627e-01, time/batch = 15.3304s	
28914/29850 (epoch 48.432), train_loss = 0.72318807, grad/param norm = 2.6637e-01, time/batch = 16.5461s	
28915/29850 (epoch 48.434), train_loss = 0.69404423, grad/param norm = 1.9658e-01, time/batch = 18.8025s	
28916/29850 (epoch 48.436), train_loss = 0.73686900, grad/param norm = 2.6598e-01, time/batch = 17.3128s	
28917/29850 (epoch 48.437), train_loss = 0.83271359, grad/param norm = 2.2164e-01, time/batch = 15.3179s	
28918/29850 (epoch 48.439), train_loss = 0.83759327, grad/param norm = 2.4127e-01, time/batch = 18.2072s	
28919/29850 (epoch 48.441), train_loss = 0.74991807, grad/param norm = 2.3460e-01, time/batch = 17.1352s	
28920/29850 (epoch 48.442), train_loss = 0.73504112, grad/param norm = 2.1147e-01, time/batch = 19.7043s	
28921/29850 (epoch 48.444), train_loss = 0.78950963, grad/param norm = 2.6664e-01, time/batch = 16.2904s	
28922/29850 (epoch 48.446), train_loss = 0.83677957, grad/param norm = 2.4630e-01, time/batch = 17.1497s	
28923/29850 (epoch 48.447), train_loss = 0.87178012, grad/param norm = 3.3572e-01, time/batch = 16.8050s	
28924/29850 (epoch 48.449), train_loss = 0.78399964, grad/param norm = 2.7253e-01, time/batch = 17.7868s	
28925/29850 (epoch 48.451), train_loss = 0.60817278, grad/param norm = 2.1330e-01, time/batch = 17.1375s	
28926/29850 (epoch 48.452), train_loss = 0.51230221, grad/param norm = 1.9251e-01, time/batch = 16.7212s	
28927/29850 (epoch 48.454), train_loss = 0.61835153, grad/param norm = 1.9382e-01, time/batch = 16.3821s	
28928/29850 (epoch 48.456), train_loss = 0.81594599, grad/param norm = 2.5614e-01, time/batch = 16.7214s	
28929/29850 (epoch 48.457), train_loss = 0.85637728, grad/param norm = 3.3693e-01, time/batch = 18.1998s	
28930/29850 (epoch 48.459), train_loss = 0.87825878, grad/param norm = 2.5525e-01, time/batch = 17.2155s	
28931/29850 (epoch 48.461), train_loss = 0.91731284, grad/param norm = 2.9450e-01, time/batch = 17.3622s	
28932/29850 (epoch 48.462), train_loss = 0.92707607, grad/param norm = 2.6708e-01, time/batch = 18.1050s	
28933/29850 (epoch 48.464), train_loss = 0.82372903, grad/param norm = 2.4558e-01, time/batch = 18.6406s	
28934/29850 (epoch 48.466), train_loss = 0.67883985, grad/param norm = 2.6534e-01, time/batch = 17.8712s	
28935/29850 (epoch 48.467), train_loss = 0.70689776, grad/param norm = 2.4132e-01, time/batch = 15.8822s	
28936/29850 (epoch 48.469), train_loss = 0.74859712, grad/param norm = 2.1440e-01, time/batch = 17.6431s	
28937/29850 (epoch 48.471), train_loss = 0.75111446, grad/param norm = 2.7667e-01, time/batch = 17.9661s	
28938/29850 (epoch 48.472), train_loss = 0.70763381, grad/param norm = 2.1174e-01, time/batch = 17.2075s	
28939/29850 (epoch 48.474), train_loss = 0.83518562, grad/param norm = 2.5695e-01, time/batch = 18.1423s	
28940/29850 (epoch 48.476), train_loss = 0.78926112, grad/param norm = 2.2491e-01, time/batch = 15.4686s	
28941/29850 (epoch 48.477), train_loss = 0.80530799, grad/param norm = 2.5880e-01, time/batch = 15.7888s	
28942/29850 (epoch 48.479), train_loss = 0.91863189, grad/param norm = 2.1659e-01, time/batch = 15.4551s	
28943/29850 (epoch 48.481), train_loss = 0.79125479, grad/param norm = 2.3359e-01, time/batch = 20.0360s	
28944/29850 (epoch 48.482), train_loss = 0.70148738, grad/param norm = 1.9609e-01, time/batch = 15.1938s	
28945/29850 (epoch 48.484), train_loss = 0.73192949, grad/param norm = 2.2297e-01, time/batch = 17.7766s	
28946/29850 (epoch 48.486), train_loss = 0.80172320, grad/param norm = 3.3459e-01, time/batch = 19.1267s	
28947/29850 (epoch 48.487), train_loss = 0.76110105, grad/param norm = 2.8802e-01, time/batch = 17.5623s	
28948/29850 (epoch 48.489), train_loss = 0.77754051, grad/param norm = 2.7488e-01, time/batch = 17.4451s	
28949/29850 (epoch 48.491), train_loss = 0.69184437, grad/param norm = 2.0858e-01, time/batch = 15.1489s	
28950/29850 (epoch 48.492), train_loss = 0.78108160, grad/param norm = 2.5720e-01, time/batch = 17.3953s	
28951/29850 (epoch 48.494), train_loss = 0.83964390, grad/param norm = 2.5046e-01, time/batch = 17.7783s	
28952/29850 (epoch 48.496), train_loss = 0.89354377, grad/param norm = 2.7424e-01, time/batch = 17.8784s	
28953/29850 (epoch 48.497), train_loss = 0.79927980, grad/param norm = 2.3116e-01, time/batch = 17.3964s	
28954/29850 (epoch 48.499), train_loss = 0.77833344, grad/param norm = 2.5739e-01, time/batch = 19.6906s	
28955/29850 (epoch 48.501), train_loss = 0.66925726, grad/param norm = 2.6603e-01, time/batch = 16.5481s	
28956/29850 (epoch 48.503), train_loss = 0.86361934, grad/param norm = 2.4602e-01, time/batch = 17.0391s	
28957/29850 (epoch 48.504), train_loss = 1.01895057, grad/param norm = 2.6300e-01, time/batch = 16.5547s	
28958/29850 (epoch 48.506), train_loss = 0.97675026, grad/param norm = 2.6096e-01, time/batch = 17.7221s	
28959/29850 (epoch 48.508), train_loss = 0.79456049, grad/param norm = 2.0943e-01, time/batch = 16.0445s	
28960/29850 (epoch 48.509), train_loss = 0.60834016, grad/param norm = 2.1586e-01, time/batch = 19.4456s	
28961/29850 (epoch 48.511), train_loss = 0.81713249, grad/param norm = 2.8537e-01, time/batch = 19.3774s	
28962/29850 (epoch 48.513), train_loss = 0.76105551, grad/param norm = 3.1477e-01, time/batch = 16.2155s	
28963/29850 (epoch 48.514), train_loss = 0.67796303, grad/param norm = 2.3057e-01, time/batch = 16.1223s	
28964/29850 (epoch 48.516), train_loss = 0.72226674, grad/param norm = 2.0054e-01, time/batch = 19.0472s	
28965/29850 (epoch 48.518), train_loss = 0.62174073, grad/param norm = 2.1267e-01, time/batch = 17.1205s	
28966/29850 (epoch 48.519), train_loss = 0.62757083, grad/param norm = 2.0579e-01, time/batch = 16.0537s	
28967/29850 (epoch 48.521), train_loss = 0.58687495, grad/param norm = 1.7558e-01, time/batch = 17.3766s	
28968/29850 (epoch 48.523), train_loss = 0.62557967, grad/param norm = 1.8503e-01, time/batch = 19.3777s	
28969/29850 (epoch 48.524), train_loss = 0.64653267, grad/param norm = 2.2953e-01, time/batch = 16.1065s	
28970/29850 (epoch 48.526), train_loss = 0.67663913, grad/param norm = 2.4765e-01, time/batch = 19.1206s	
28971/29850 (epoch 48.528), train_loss = 0.81234662, grad/param norm = 2.7450e-01, time/batch = 18.2110s	
28972/29850 (epoch 48.529), train_loss = 0.77453647, grad/param norm = 2.2863e-01, time/batch = 17.9659s	
28973/29850 (epoch 48.531), train_loss = 0.74298526, grad/param norm = 3.1403e-01, time/batch = 17.6220s	
28974/29850 (epoch 48.533), train_loss = 0.78075623, grad/param norm = 2.5712e-01, time/batch = 16.3928s	
28975/29850 (epoch 48.534), train_loss = 0.80277047, grad/param norm = 2.6085e-01, time/batch = 19.2788s	
28976/29850 (epoch 48.536), train_loss = 0.71171273, grad/param norm = 2.2658e-01, time/batch = 18.9379s	
28977/29850 (epoch 48.538), train_loss = 0.89646101, grad/param norm = 2.6989e-01, time/batch = 17.1998s	
28978/29850 (epoch 48.539), train_loss = 0.88746498, grad/param norm = 2.6224e-01, time/batch = 19.3862s	
28979/29850 (epoch 48.541), train_loss = 0.53663277, grad/param norm = 1.9433e-01, time/batch = 17.2986s	
28980/29850 (epoch 48.543), train_loss = 0.71442025, grad/param norm = 2.2606e-01, time/batch = 17.6338s	
28981/29850 (epoch 48.544), train_loss = 0.85539307, grad/param norm = 2.5962e-01, time/batch = 15.5315s	
28982/29850 (epoch 48.546), train_loss = 0.85694232, grad/param norm = 2.8279e-01, time/batch = 16.8634s	
28983/29850 (epoch 48.548), train_loss = 0.61385575, grad/param norm = 1.9119e-01, time/batch = 16.1038s	
28984/29850 (epoch 48.549), train_loss = 0.72853602, grad/param norm = 2.2302e-01, time/batch = 16.8021s	
28985/29850 (epoch 48.551), train_loss = 0.68912125, grad/param norm = 2.2639e-01, time/batch = 18.6268s	
28986/29850 (epoch 48.553), train_loss = 0.75969370, grad/param norm = 2.1920e-01, time/batch = 15.9548s	
28987/29850 (epoch 48.554), train_loss = 0.60544108, grad/param norm = 1.9701e-01, time/batch = 18.4351s	
28988/29850 (epoch 48.556), train_loss = 0.64800848, grad/param norm = 1.9929e-01, time/batch = 18.5414s	
28989/29850 (epoch 48.558), train_loss = 0.65302710, grad/param norm = 1.9536e-01, time/batch = 17.2767s	
28990/29850 (epoch 48.559), train_loss = 0.66243741, grad/param norm = 2.0815e-01, time/batch = 15.8054s	
28991/29850 (epoch 48.561), train_loss = 0.75710060, grad/param norm = 2.3138e-01, time/batch = 18.1238s	
28992/29850 (epoch 48.563), train_loss = 0.79881061, grad/param norm = 2.4269e-01, time/batch = 16.7224s	
28993/29850 (epoch 48.564), train_loss = 0.72029580, grad/param norm = 2.1671e-01, time/batch = 15.9554s	
28994/29850 (epoch 48.566), train_loss = 0.74612410, grad/param norm = 2.2657e-01, time/batch = 18.4675s	
28995/29850 (epoch 48.568), train_loss = 0.89706168, grad/param norm = 2.6909e-01, time/batch = 16.9564s	
28996/29850 (epoch 48.570), train_loss = 0.76664286, grad/param norm = 2.4812e-01, time/batch = 16.9575s	
28997/29850 (epoch 48.571), train_loss = 0.81147359, grad/param norm = 2.0260e-01, time/batch = 17.7056s	
28998/29850 (epoch 48.573), train_loss = 0.87709382, grad/param norm = 2.6635e-01, time/batch = 19.1240s	
28999/29850 (epoch 48.575), train_loss = 0.93981407, grad/param norm = 2.4626e-01, time/batch = 15.7268s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch48.58_1.9584.t7	
29000/29850 (epoch 48.576), train_loss = 0.82718732, grad/param norm = 2.5925e-01, time/batch = 17.7056s	
29001/29850 (epoch 48.578), train_loss = 1.39367162, grad/param norm = 3.6386e-01, time/batch = 17.4756s	
29002/29850 (epoch 48.580), train_loss = 0.82359791, grad/param norm = 2.8111e-01, time/batch = 17.7931s	
29003/29850 (epoch 48.581), train_loss = 0.71290932, grad/param norm = 2.2730e-01, time/batch = 17.4809s	
29004/29850 (epoch 48.583), train_loss = 0.75924725, grad/param norm = 2.7200e-01, time/batch = 19.3443s	
29005/29850 (epoch 48.585), train_loss = 0.81436716, grad/param norm = 2.6707e-01, time/batch = 19.2900s	
29006/29850 (epoch 48.586), train_loss = 0.80001050, grad/param norm = 2.6067e-01, time/batch = 18.4469s	
29007/29850 (epoch 48.588), train_loss = 0.68477781, grad/param norm = 2.1535e-01, time/batch = 18.5614s	
29008/29850 (epoch 48.590), train_loss = 0.70798586, grad/param norm = 1.8595e-01, time/batch = 15.6012s	
29009/29850 (epoch 48.591), train_loss = 0.74775674, grad/param norm = 2.4543e-01, time/batch = 15.9438s	
29010/29850 (epoch 48.593), train_loss = 0.66168444, grad/param norm = 2.0809e-01, time/batch = 18.6242s	
29011/29850 (epoch 48.595), train_loss = 0.63156420, grad/param norm = 1.9048e-01, time/batch = 17.9727s	
29012/29850 (epoch 48.596), train_loss = 0.67113549, grad/param norm = 2.5422e-01, time/batch = 17.0458s	
29013/29850 (epoch 48.598), train_loss = 0.72367689, grad/param norm = 2.1161e-01, time/batch = 17.4673s	
29014/29850 (epoch 48.600), train_loss = 0.77120927, grad/param norm = 2.1729e-01, time/batch = 15.5208s	
29015/29850 (epoch 48.601), train_loss = 0.64662322, grad/param norm = 1.9011e-01, time/batch = 16.9444s	
29016/29850 (epoch 48.603), train_loss = 0.67297830, grad/param norm = 2.0701e-01, time/batch = 24.4540s	
29017/29850 (epoch 48.605), train_loss = 0.71225995, grad/param norm = 2.0938e-01, time/batch = 23.9920s	
29018/29850 (epoch 48.606), train_loss = 0.48718476, grad/param norm = 1.9019e-01, time/batch = 16.3770s	
29019/29850 (epoch 48.608), train_loss = 0.62813451, grad/param norm = 1.9498e-01, time/batch = 17.0474s	
29020/29850 (epoch 48.610), train_loss = 0.68625877, grad/param norm = 2.0350e-01, time/batch = 17.5491s	
29021/29850 (epoch 48.611), train_loss = 0.63677052, grad/param norm = 2.1266e-01, time/batch = 17.8042s	
29022/29850 (epoch 48.613), train_loss = 0.55389245, grad/param norm = 1.8084e-01, time/batch = 15.8868s	
29023/29850 (epoch 48.615), train_loss = 0.58637911, grad/param norm = 1.7529e-01, time/batch = 18.5444s	
29024/29850 (epoch 48.616), train_loss = 0.60962522, grad/param norm = 2.0760e-01, time/batch = 15.8669s	
29025/29850 (epoch 48.618), train_loss = 0.67194458, grad/param norm = 1.8740e-01, time/batch = 17.3707s	
29026/29850 (epoch 48.620), train_loss = 0.77148724, grad/param norm = 2.2320e-01, time/batch = 17.6332s	
29027/29850 (epoch 48.621), train_loss = 0.82284308, grad/param norm = 2.6779e-01, time/batch = 17.2057s	
29028/29850 (epoch 48.623), train_loss = 0.81980817, grad/param norm = 2.1890e-01, time/batch = 17.5587s	
29029/29850 (epoch 48.625), train_loss = 0.73408917, grad/param norm = 2.5482e-01, time/batch = 17.3679s	
29030/29850 (epoch 48.626), train_loss = 0.74420995, grad/param norm = 2.4694e-01, time/batch = 19.1807s	
29031/29850 (epoch 48.628), train_loss = 0.73433770, grad/param norm = 2.8525e-01, time/batch = 17.5559s	
29032/29850 (epoch 48.630), train_loss = 0.76877371, grad/param norm = 2.5305e-01, time/batch = 18.2813s	
29033/29850 (epoch 48.631), train_loss = 0.78557793, grad/param norm = 2.6079e-01, time/batch = 2.9911s	
29034/29850 (epoch 48.633), train_loss = 0.77236507, grad/param norm = 2.8257e-01, time/batch = 0.6784s	
29035/29850 (epoch 48.635), train_loss = 0.71956799, grad/param norm = 2.8651e-01, time/batch = 0.6725s	
29036/29850 (epoch 48.637), train_loss = 0.66995493, grad/param norm = 2.2308e-01, time/batch = 0.6741s	
29037/29850 (epoch 48.638), train_loss = 0.77737346, grad/param norm = 2.4768e-01, time/batch = 0.6639s	
29038/29850 (epoch 48.640), train_loss = 0.88239857, grad/param norm = 2.6668e-01, time/batch = 0.6689s	
29039/29850 (epoch 48.642), train_loss = 0.72964663, grad/param norm = 2.2263e-01, time/batch = 0.6634s	
29040/29850 (epoch 48.643), train_loss = 0.66058366, grad/param norm = 2.2926e-01, time/batch = 0.7785s	
29041/29850 (epoch 48.645), train_loss = 0.72661351, grad/param norm = 2.1665e-01, time/batch = 0.9683s	
29042/29850 (epoch 48.647), train_loss = 0.84415558, grad/param norm = 2.6621e-01, time/batch = 0.9946s	
29043/29850 (epoch 48.648), train_loss = 0.66442929, grad/param norm = 2.1367e-01, time/batch = 0.9879s	
29044/29850 (epoch 48.650), train_loss = 0.76534427, grad/param norm = 2.3157e-01, time/batch = 0.9808s	
29045/29850 (epoch 48.652), train_loss = 0.74951044, grad/param norm = 2.3578e-01, time/batch = 1.2500s	
29046/29850 (epoch 48.653), train_loss = 0.83574442, grad/param norm = 2.4963e-01, time/batch = 1.8228s	
29047/29850 (epoch 48.655), train_loss = 0.77278399, grad/param norm = 2.0527e-01, time/batch = 1.8019s	
29048/29850 (epoch 48.657), train_loss = 0.73579867, grad/param norm = 2.1234e-01, time/batch = 12.4922s	
29049/29850 (epoch 48.658), train_loss = 0.86381400, grad/param norm = 2.8345e-01, time/batch = 16.4530s	
29050/29850 (epoch 48.660), train_loss = 0.71885512, grad/param norm = 2.5511e-01, time/batch = 17.2797s	
29051/29850 (epoch 48.662), train_loss = 0.84274558, grad/param norm = 2.7439e-01, time/batch = 17.4408s	
29052/29850 (epoch 48.663), train_loss = 0.96139620, grad/param norm = 2.5099e-01, time/batch = 17.4661s	
29053/29850 (epoch 48.665), train_loss = 0.88549719, grad/param norm = 2.6786e-01, time/batch = 18.7870s	
29054/29850 (epoch 48.667), train_loss = 0.81072505, grad/param norm = 3.2718e-01, time/batch = 18.0227s	
29055/29850 (epoch 48.668), train_loss = 0.68998552, grad/param norm = 2.2461e-01, time/batch = 16.5386s	
29056/29850 (epoch 48.670), train_loss = 0.83042576, grad/param norm = 3.7544e-01, time/batch = 16.7120s	
29057/29850 (epoch 48.672), train_loss = 0.86298369, grad/param norm = 3.1731e-01, time/batch = 15.7950s	
29058/29850 (epoch 48.673), train_loss = 0.78165855, grad/param norm = 3.0053e-01, time/batch = 17.7239s	
29059/29850 (epoch 48.675), train_loss = 0.68229724, grad/param norm = 2.2050e-01, time/batch = 19.0366s	
29060/29850 (epoch 48.677), train_loss = 0.71405087, grad/param norm = 2.4022e-01, time/batch = 18.1366s	
29061/29850 (epoch 48.678), train_loss = 0.76645846, grad/param norm = 2.4566e-01, time/batch = 17.0527s	
29062/29850 (epoch 48.680), train_loss = 0.73777608, grad/param norm = 2.5838e-01, time/batch = 16.7230s	
29063/29850 (epoch 48.682), train_loss = 0.75599304, grad/param norm = 2.4647e-01, time/batch = 16.7884s	
29064/29850 (epoch 48.683), train_loss = 0.84307134, grad/param norm = 2.9460e-01, time/batch = 17.2031s	
29065/29850 (epoch 48.685), train_loss = 0.93773599, grad/param norm = 2.4447e-01, time/batch = 16.8905s	
29066/29850 (epoch 48.687), train_loss = 0.80659417, grad/param norm = 2.5033e-01, time/batch = 17.3134s	
29067/29850 (epoch 48.688), train_loss = 0.68648272, grad/param norm = 2.5119e-01, time/batch = 17.2983s	
29068/29850 (epoch 48.690), train_loss = 0.70905862, grad/param norm = 2.4579e-01, time/batch = 14.7232s	
29069/29850 (epoch 48.692), train_loss = 0.87810795, grad/param norm = 2.7896e-01, time/batch = 17.7232s	
29070/29850 (epoch 48.693), train_loss = 0.76061273, grad/param norm = 2.0431e-01, time/batch = 17.9764s	
29071/29850 (epoch 48.695), train_loss = 0.67073047, grad/param norm = 1.9066e-01, time/batch = 17.5420s	
29072/29850 (epoch 48.697), train_loss = 0.73544730, grad/param norm = 2.2014e-01, time/batch = 18.8801s	
29073/29850 (epoch 48.698), train_loss = 0.84762333, grad/param norm = 2.4154e-01, time/batch = 18.7889s	
29074/29850 (epoch 48.700), train_loss = 0.79698190, grad/param norm = 2.7248e-01, time/batch = 16.9325s	
29075/29850 (epoch 48.702), train_loss = 0.78864171, grad/param norm = 3.1502e-01, time/batch = 15.5501s	
29076/29850 (epoch 48.704), train_loss = 0.64457221, grad/param norm = 2.1116e-01, time/batch = 18.3800s	
29077/29850 (epoch 48.705), train_loss = 0.76025850, grad/param norm = 2.3038e-01, time/batch = 17.8041s	
29078/29850 (epoch 48.707), train_loss = 0.71276767, grad/param norm = 2.4188e-01, time/batch = 17.2820s	
29079/29850 (epoch 48.709), train_loss = 0.74715000, grad/param norm = 2.8160e-01, time/batch = 18.5529s	
29080/29850 (epoch 48.710), train_loss = 0.68779550, grad/param norm = 2.0815e-01, time/batch = 17.0533s	
29081/29850 (epoch 48.712), train_loss = 0.80898559, grad/param norm = 2.4879e-01, time/batch = 16.7621s	
29082/29850 (epoch 48.714), train_loss = 0.85854607, grad/param norm = 3.3488e-01, time/batch = 17.8604s	
29083/29850 (epoch 48.715), train_loss = 0.79641952, grad/param norm = 2.5032e-01, time/batch = 16.3966s	
29084/29850 (epoch 48.717), train_loss = 0.58103315, grad/param norm = 2.0621e-01, time/batch = 18.0296s	
29085/29850 (epoch 48.719), train_loss = 0.73293328, grad/param norm = 2.3290e-01, time/batch = 17.2053s	
29086/29850 (epoch 48.720), train_loss = 0.74713700, grad/param norm = 2.1741e-01, time/batch = 18.3789s	
29087/29850 (epoch 48.722), train_loss = 0.68534469, grad/param norm = 1.9963e-01, time/batch = 18.9714s	
29088/29850 (epoch 48.724), train_loss = 0.76591052, grad/param norm = 2.3919e-01, time/batch = 18.2827s	
29089/29850 (epoch 48.725), train_loss = 0.63797383, grad/param norm = 2.0085e-01, time/batch = 15.1323s	
29090/29850 (epoch 48.727), train_loss = 0.62354701, grad/param norm = 2.6328e-01, time/batch = 18.6301s	
29091/29850 (epoch 48.729), train_loss = 0.60859768, grad/param norm = 1.8390e-01, time/batch = 16.3691s	
29092/29850 (epoch 48.730), train_loss = 0.59506376, grad/param norm = 1.9611e-01, time/batch = 18.6257s	
29093/29850 (epoch 48.732), train_loss = 0.81091562, grad/param norm = 2.1721e-01, time/batch = 18.7259s	
29094/29850 (epoch 48.734), train_loss = 0.91334492, grad/param norm = 2.5845e-01, time/batch = 17.9687s	
29095/29850 (epoch 48.735), train_loss = 0.69431123, grad/param norm = 2.4163e-01, time/batch = 18.1973s	
29096/29850 (epoch 48.737), train_loss = 0.64849419, grad/param norm = 2.0219e-01, time/batch = 18.2152s	
29097/29850 (epoch 48.739), train_loss = 0.56154800, grad/param norm = 1.9601e-01, time/batch = 19.5259s	
29098/29850 (epoch 48.740), train_loss = 0.58786509, grad/param norm = 1.9582e-01, time/batch = 16.2154s	
29099/29850 (epoch 48.742), train_loss = 0.54814533, grad/param norm = 1.6848e-01, time/batch = 19.0370s	
29100/29850 (epoch 48.744), train_loss = 0.67593633, grad/param norm = 3.1363e-01, time/batch = 17.2746s	
29101/29850 (epoch 48.745), train_loss = 0.72081853, grad/param norm = 2.6419e-01, time/batch = 15.2996s	
29102/29850 (epoch 48.747), train_loss = 0.73493287, grad/param norm = 2.4911e-01, time/batch = 19.5269s	
29103/29850 (epoch 48.749), train_loss = 0.61645498, grad/param norm = 2.0637e-01, time/batch = 17.2057s	
29104/29850 (epoch 48.750), train_loss = 0.55860900, grad/param norm = 1.9608e-01, time/batch = 18.3788s	
29105/29850 (epoch 48.752), train_loss = 0.47520801, grad/param norm = 1.6802e-01, time/batch = 18.6267s	
29106/29850 (epoch 48.754), train_loss = 0.55587752, grad/param norm = 2.0452e-01, time/batch = 17.8004s	
29107/29850 (epoch 48.755), train_loss = 0.56215017, grad/param norm = 2.0375e-01, time/batch = 16.6316s	
29108/29850 (epoch 48.757), train_loss = 0.62227336, grad/param norm = 1.9519e-01, time/batch = 17.1985s	
29109/29850 (epoch 48.759), train_loss = 0.63491125, grad/param norm = 2.1244e-01, time/batch = 18.8692s	
29110/29850 (epoch 48.760), train_loss = 0.65391993, grad/param norm = 2.3149e-01, time/batch = 18.3745s	
29111/29850 (epoch 48.762), train_loss = 0.59327258, grad/param norm = 2.4925e-01, time/batch = 17.6195s	
29112/29850 (epoch 48.764), train_loss = 0.51296603, grad/param norm = 2.1849e-01, time/batch = 18.1411s	
29113/29850 (epoch 48.765), train_loss = 0.67731201, grad/param norm = 2.3203e-01, time/batch = 17.1293s	
29114/29850 (epoch 48.767), train_loss = 0.69304248, grad/param norm = 2.2296e-01, time/batch = 16.3014s	
29115/29850 (epoch 48.769), train_loss = 0.72120520, grad/param norm = 2.3005e-01, time/batch = 16.0927s	
29116/29850 (epoch 48.771), train_loss = 0.70545340, grad/param norm = 2.3476e-01, time/batch = 17.6442s	
29117/29850 (epoch 48.772), train_loss = 0.70423258, grad/param norm = 2.4304e-01, time/batch = 17.2165s	
29118/29850 (epoch 48.774), train_loss = 0.65046827, grad/param norm = 2.3728e-01, time/batch = 17.4661s	
29119/29850 (epoch 48.776), train_loss = 0.67916814, grad/param norm = 2.2677e-01, time/batch = 19.1304s	
29120/29850 (epoch 48.777), train_loss = 0.77858166, grad/param norm = 2.5020e-01, time/batch = 19.1310s	
29121/29850 (epoch 48.779), train_loss = 0.63200083, grad/param norm = 2.2972e-01, time/batch = 18.3686s	
29122/29850 (epoch 48.781), train_loss = 0.73856662, grad/param norm = 2.5254e-01, time/batch = 18.1233s	
29123/29850 (epoch 48.782), train_loss = 0.75818200, grad/param norm = 2.5756e-01, time/batch = 18.2023s	
29124/29850 (epoch 48.784), train_loss = 0.59711054, grad/param norm = 2.3435e-01, time/batch = 17.4616s	
29125/29850 (epoch 48.786), train_loss = 0.65188832, grad/param norm = 2.5311e-01, time/batch = 17.6920s	
29126/29850 (epoch 48.787), train_loss = 0.54617706, grad/param norm = 2.3466e-01, time/batch = 18.3904s	
29127/29850 (epoch 48.789), train_loss = 0.55679785, grad/param norm = 1.8212e-01, time/batch = 17.2143s	
29128/29850 (epoch 48.791), train_loss = 0.63370593, grad/param norm = 2.4713e-01, time/batch = 16.7161s	
29129/29850 (epoch 48.792), train_loss = 0.72853656, grad/param norm = 2.4033e-01, time/batch = 19.1381s	
29130/29850 (epoch 48.794), train_loss = 0.69827113, grad/param norm = 2.6156e-01, time/batch = 18.6315s	
29131/29850 (epoch 48.796), train_loss = 0.61520237, grad/param norm = 2.1163e-01, time/batch = 18.0140s	
29132/29850 (epoch 48.797), train_loss = 0.53548405, grad/param norm = 2.2954e-01, time/batch = 16.4376s	
29133/29850 (epoch 48.799), train_loss = 0.57040461, grad/param norm = 1.7492e-01, time/batch = 16.8118s	
29134/29850 (epoch 48.801), train_loss = 0.58138607, grad/param norm = 2.2150e-01, time/batch = 17.3047s	
29135/29850 (epoch 48.802), train_loss = 0.55550999, grad/param norm = 2.3191e-01, time/batch = 16.8856s	
29136/29850 (epoch 48.804), train_loss = 0.61653474, grad/param norm = 2.1627e-01, time/batch = 15.3605s	
29137/29850 (epoch 48.806), train_loss = 0.54752037, grad/param norm = 2.0945e-01, time/batch = 18.6500s	
29138/29850 (epoch 48.807), train_loss = 0.59934078, grad/param norm = 1.8301e-01, time/batch = 18.8507s	
29139/29850 (epoch 48.809), train_loss = 0.58669757, grad/param norm = 2.2637e-01, time/batch = 17.7256s	
29140/29850 (epoch 48.811), train_loss = 0.74981352, grad/param norm = 2.2727e-01, time/batch = 14.3383s	
29141/29850 (epoch 48.812), train_loss = 0.71767111, grad/param norm = 2.3482e-01, time/batch = 16.7207s	
29142/29850 (epoch 48.814), train_loss = 0.73749398, grad/param norm = 2.5688e-01, time/batch = 17.5445s	
29143/29850 (epoch 48.816), train_loss = 0.82780006, grad/param norm = 2.3147e-01, time/batch = 16.3975s	
29144/29850 (epoch 48.817), train_loss = 0.70473782, grad/param norm = 2.4604e-01, time/batch = 19.6280s	
29145/29850 (epoch 48.819), train_loss = 0.55650141, grad/param norm = 2.1869e-01, time/batch = 17.6286s	
29146/29850 (epoch 48.821), train_loss = 0.78880581, grad/param norm = 2.7453e-01, time/batch = 17.3060s	
29147/29850 (epoch 48.822), train_loss = 0.81823122, grad/param norm = 2.3548e-01, time/batch = 17.7124s	
29148/29850 (epoch 48.824), train_loss = 0.69962856, grad/param norm = 2.4039e-01, time/batch = 18.7960s	
29149/29850 (epoch 48.826), train_loss = 0.59367365, grad/param norm = 1.9873e-01, time/batch = 17.2028s	
29150/29850 (epoch 48.827), train_loss = 0.54655228, grad/param norm = 2.5832e-01, time/batch = 17.0542s	
29151/29850 (epoch 48.829), train_loss = 0.72965310, grad/param norm = 2.9930e-01, time/batch = 17.3904s	
29152/29850 (epoch 48.831), train_loss = 0.82314294, grad/param norm = 2.7017e-01, time/batch = 15.9598s	
29153/29850 (epoch 48.832), train_loss = 0.70460257, grad/param norm = 2.1308e-01, time/batch = 16.8669s	
29154/29850 (epoch 48.834), train_loss = 0.54121402, grad/param norm = 1.8434e-01, time/batch = 17.8131s	
29155/29850 (epoch 48.836), train_loss = 0.55122619, grad/param norm = 2.2456e-01, time/batch = 18.4533s	
29156/29850 (epoch 48.838), train_loss = 0.64860275, grad/param norm = 3.3195e-01, time/batch = 18.7806s	
29157/29850 (epoch 48.839), train_loss = 0.54058913, grad/param norm = 2.0677e-01, time/batch = 18.0402s	
29158/29850 (epoch 48.841), train_loss = 0.62850459, grad/param norm = 2.0434e-01, time/batch = 15.4307s	
29159/29850 (epoch 48.843), train_loss = 0.54724104, grad/param norm = 1.9050e-01, time/batch = 17.4490s	
29160/29850 (epoch 48.844), train_loss = 0.59430306, grad/param norm = 2.3557e-01, time/batch = 19.1179s	
29161/29850 (epoch 48.846), train_loss = 0.65694386, grad/param norm = 2.2172e-01, time/batch = 18.2040s	
29162/29850 (epoch 48.848), train_loss = 0.71465397, grad/param norm = 2.5114e-01, time/batch = 17.7965s	
29163/29850 (epoch 48.849), train_loss = 0.67480272, grad/param norm = 2.4986e-01, time/batch = 18.6325s	
29164/29850 (epoch 48.851), train_loss = 0.84870355, grad/param norm = 2.3051e-01, time/batch = 17.9640s	
29165/29850 (epoch 48.853), train_loss = 0.69463034, grad/param norm = 2.9372e-01, time/batch = 17.1373s	
29166/29850 (epoch 48.854), train_loss = 0.83367601, grad/param norm = 2.5671e-01, time/batch = 18.5090s	
29167/29850 (epoch 48.856), train_loss = 0.80451271, grad/param norm = 2.8886e-01, time/batch = 15.7291s	
29168/29850 (epoch 48.858), train_loss = 0.70286191, grad/param norm = 2.9680e-01, time/batch = 16.9452s	
29169/29850 (epoch 48.859), train_loss = 0.61465512, grad/param norm = 2.7973e-01, time/batch = 17.9535s	
29170/29850 (epoch 48.861), train_loss = 0.76212334, grad/param norm = 2.8021e-01, time/batch = 18.3719s	
29171/29850 (epoch 48.863), train_loss = 0.80187801, grad/param norm = 2.8029e-01, time/batch = 18.2970s	
29172/29850 (epoch 48.864), train_loss = 0.79165926, grad/param norm = 2.5700e-01, time/batch = 15.6216s	
29173/29850 (epoch 48.866), train_loss = 0.74268517, grad/param norm = 3.5797e-01, time/batch = 17.3634s	
29174/29850 (epoch 48.868), train_loss = 0.89097191, grad/param norm = 2.7421e-01, time/batch = 16.9741s	
29175/29850 (epoch 48.869), train_loss = 0.78804819, grad/param norm = 2.9043e-01, time/batch = 17.6141s	
29176/29850 (epoch 48.871), train_loss = 0.82434124, grad/param norm = 2.6814e-01, time/batch = 15.7976s	
29177/29850 (epoch 48.873), train_loss = 0.76239633, grad/param norm = 2.6382e-01, time/batch = 18.2036s	
29178/29850 (epoch 48.874), train_loss = 0.74773561, grad/param norm = 2.5586e-01, time/batch = 18.3011s	
29179/29850 (epoch 48.876), train_loss = 0.74941323, grad/param norm = 2.8047e-01, time/batch = 17.6274s	
29180/29850 (epoch 48.878), train_loss = 0.73407536, grad/param norm = 2.2293e-01, time/batch = 18.8612s	
29181/29850 (epoch 48.879), train_loss = 0.76944190, grad/param norm = 2.3016e-01, time/batch = 16.7782s	
29182/29850 (epoch 48.881), train_loss = 0.78948864, grad/param norm = 2.2462e-01, time/batch = 18.9592s	
29183/29850 (epoch 48.883), train_loss = 0.75661851, grad/param norm = 2.8376e-01, time/batch = 16.7133s	
29184/29850 (epoch 48.884), train_loss = 0.63416081, grad/param norm = 2.3566e-01, time/batch = 16.4494s	
29185/29850 (epoch 48.886), train_loss = 0.79890682, grad/param norm = 3.0262e-01, time/batch = 18.4573s	
29186/29850 (epoch 48.888), train_loss = 0.72939447, grad/param norm = 2.5696e-01, time/batch = 16.7739s	
29187/29850 (epoch 48.889), train_loss = 0.70033523, grad/param norm = 2.3106e-01, time/batch = 14.3801s	
29188/29850 (epoch 48.891), train_loss = 0.64166085, grad/param norm = 2.0010e-01, time/batch = 15.3338s	
29189/29850 (epoch 48.893), train_loss = 0.69464304, grad/param norm = 2.8214e-01, time/batch = 18.1364s	
29190/29850 (epoch 48.894), train_loss = 0.70986844, grad/param norm = 2.6159e-01, time/batch = 17.0556s	
29191/29850 (epoch 48.896), train_loss = 0.76988450, grad/param norm = 3.4141e-01, time/batch = 17.4735s	
29192/29850 (epoch 48.898), train_loss = 0.86548186, grad/param norm = 2.4505e-01, time/batch = 17.7191s	
29193/29850 (epoch 48.899), train_loss = 0.64227881, grad/param norm = 2.3866e-01, time/batch = 15.7005s	
29194/29850 (epoch 48.901), train_loss = 0.90932478, grad/param norm = 3.2853e-01, time/batch = 17.6232s	
29195/29850 (epoch 48.903), train_loss = 0.81504234, grad/param norm = 3.7701e-01, time/batch = 18.0546s	
29196/29850 (epoch 48.905), train_loss = 0.98256998, grad/param norm = 2.9837e-01, time/batch = 17.3704s	
29197/29850 (epoch 48.906), train_loss = 0.72908728, grad/param norm = 2.4236e-01, time/batch = 17.7078s	
29198/29850 (epoch 48.908), train_loss = 0.87791604, grad/param norm = 2.3486e-01, time/batch = 19.1299s	
29199/29850 (epoch 48.910), train_loss = 0.80906596, grad/param norm = 2.1622e-01, time/batch = 18.1343s	
29200/29850 (epoch 48.911), train_loss = 0.95376768, grad/param norm = 2.8127e-01, time/batch = 17.2122s	
29201/29850 (epoch 48.913), train_loss = 0.88068111, grad/param norm = 2.8204e-01, time/batch = 19.2873s	
29202/29850 (epoch 48.915), train_loss = 0.89310920, grad/param norm = 2.5547e-01, time/batch = 15.6449s	
29203/29850 (epoch 48.916), train_loss = 0.83444505, grad/param norm = 2.4670e-01, time/batch = 15.1240s	
29204/29850 (epoch 48.918), train_loss = 0.69052278, grad/param norm = 2.1589e-01, time/batch = 17.2715s	
29205/29850 (epoch 48.920), train_loss = 0.85099270, grad/param norm = 2.1910e-01, time/batch = 19.1170s	
29206/29850 (epoch 48.921), train_loss = 0.74383296, grad/param norm = 2.6488e-01, time/batch = 17.0521s	
29207/29850 (epoch 48.923), train_loss = 0.76968812, grad/param norm = 2.4884e-01, time/batch = 18.1911s	
29208/29850 (epoch 48.925), train_loss = 0.90496631, grad/param norm = 2.8070e-01, time/batch = 17.2310s	
29209/29850 (epoch 48.926), train_loss = 0.91724553, grad/param norm = 3.3025e-01, time/batch = 18.6975s	
29210/29850 (epoch 48.928), train_loss = 0.76533344, grad/param norm = 2.5843e-01, time/batch = 18.6116s	
29211/29850 (epoch 48.930), train_loss = 0.76485049, grad/param norm = 2.3676e-01, time/batch = 17.1947s	
29212/29850 (epoch 48.931), train_loss = 0.77321233, grad/param norm = 2.5909e-01, time/batch = 17.4574s	
29213/29850 (epoch 48.933), train_loss = 0.88730000, grad/param norm = 2.7149e-01, time/batch = 16.8747s	
29214/29850 (epoch 48.935), train_loss = 0.82516383, grad/param norm = 2.6139e-01, time/batch = 17.1883s	
29215/29850 (epoch 48.936), train_loss = 0.82037167, grad/param norm = 2.5770e-01, time/batch = 17.4603s	
29216/29850 (epoch 48.938), train_loss = 0.69804310, grad/param norm = 2.6574e-01, time/batch = 19.3007s	
29217/29850 (epoch 48.940), train_loss = 0.69391880, grad/param norm = 2.2938e-01, time/batch = 15.3944s	
29218/29850 (epoch 48.941), train_loss = 0.66291527, grad/param norm = 2.5114e-01, time/batch = 16.8009s	
29219/29850 (epoch 48.943), train_loss = 0.70183755, grad/param norm = 2.3393e-01, time/batch = 17.5516s	
29220/29850 (epoch 48.945), train_loss = 0.69052907, grad/param norm = 3.1039e-01, time/batch = 17.6418s	
29221/29850 (epoch 48.946), train_loss = 0.65729176, grad/param norm = 2.3144e-01, time/batch = 17.8781s	
29222/29850 (epoch 48.948), train_loss = 0.76364552, grad/param norm = 2.3283e-01, time/batch = 19.0417s	
29223/29850 (epoch 48.950), train_loss = 0.71611108, grad/param norm = 1.7646e-01, time/batch = 18.7194s	
29224/29850 (epoch 48.951), train_loss = 0.60965854, grad/param norm = 1.9064e-01, time/batch = 15.6873s	
29225/29850 (epoch 48.953), train_loss = 0.69522674, grad/param norm = 2.4101e-01, time/batch = 19.1137s	
29226/29850 (epoch 48.955), train_loss = 0.61091332, grad/param norm = 1.8924e-01, time/batch = 17.2119s	
29227/29850 (epoch 48.956), train_loss = 0.62232872, grad/param norm = 2.0508e-01, time/batch = 16.1888s	
29228/29850 (epoch 48.958), train_loss = 0.59801256, grad/param norm = 2.2627e-01, time/batch = 18.4615s	
29229/29850 (epoch 48.960), train_loss = 0.82872355, grad/param norm = 2.8307e-01, time/batch = 18.4408s	
29230/29850 (epoch 48.961), train_loss = 0.59644713, grad/param norm = 2.1154e-01, time/batch = 17.7946s	
29231/29850 (epoch 48.963), train_loss = 0.58162305, grad/param norm = 2.0304e-01, time/batch = 18.8084s	
29232/29850 (epoch 48.965), train_loss = 0.64227254, grad/param norm = 2.6546e-01, time/batch = 17.8874s	
29233/29850 (epoch 48.966), train_loss = 0.62366023, grad/param norm = 2.0468e-01, time/batch = 17.1405s	
29234/29850 (epoch 48.968), train_loss = 0.64140990, grad/param norm = 2.3922e-01, time/batch = 31.6096s	
29235/29850 (epoch 48.970), train_loss = 0.66855994, grad/param norm = 2.2761e-01, time/batch = 17.7008s	
29236/29850 (epoch 48.972), train_loss = 0.68370448, grad/param norm = 2.1956e-01, time/batch = 16.9388s	
29237/29850 (epoch 48.973), train_loss = 0.63023291, grad/param norm = 1.8909e-01, time/batch = 18.4529s	
29238/29850 (epoch 48.975), train_loss = 0.58672482, grad/param norm = 1.9122e-01, time/batch = 17.0639s	
29239/29850 (epoch 48.977), train_loss = 0.68154605, grad/param norm = 2.3302e-01, time/batch = 20.4418s	
29240/29850 (epoch 48.978), train_loss = 0.57608816, grad/param norm = 1.7653e-01, time/batch = 18.2036s	
29241/29850 (epoch 48.980), train_loss = 0.66204023, grad/param norm = 2.2150e-01, time/batch = 18.3858s	
29242/29850 (epoch 48.982), train_loss = 0.60015528, grad/param norm = 1.8277e-01, time/batch = 15.6282s	
29243/29850 (epoch 48.983), train_loss = 0.65693688, grad/param norm = 2.0559e-01, time/batch = 17.5375s	
29244/29850 (epoch 48.985), train_loss = 0.78579584, grad/param norm = 3.0785e-01, time/batch = 18.9633s	
29245/29850 (epoch 48.987), train_loss = 0.72996457, grad/param norm = 2.4553e-01, time/batch = 15.9562s	
29246/29850 (epoch 48.988), train_loss = 0.70657255, grad/param norm = 2.0177e-01, time/batch = 17.7126s	
29247/29850 (epoch 48.990), train_loss = 0.76044950, grad/param norm = 2.1474e-01, time/batch = 15.2741s	
29248/29850 (epoch 48.992), train_loss = 0.73809105, grad/param norm = 1.9664e-01, time/batch = 18.5362s	
29249/29850 (epoch 48.993), train_loss = 0.75373300, grad/param norm = 2.5021e-01, time/batch = 15.3968s	
29250/29850 (epoch 48.995), train_loss = 0.70884396, grad/param norm = 2.3389e-01, time/batch = 16.4718s	
29251/29850 (epoch 48.997), train_loss = 0.76098143, grad/param norm = 2.2252e-01, time/batch = 17.3010s	
29252/29850 (epoch 48.998), train_loss = 0.75480834, grad/param norm = 1.9769e-01, time/batch = 16.7870s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
29253/29850 (epoch 49.000), train_loss = 0.59736581, grad/param norm = 2.0441e-01, time/batch = 17.4620s	
29254/29850 (epoch 49.002), train_loss = 0.82437892, grad/param norm = 2.4376e-01, time/batch = 16.4386s	
29255/29850 (epoch 49.003), train_loss = 0.61587228, grad/param norm = 2.6232e-01, time/batch = 18.2108s	
29256/29850 (epoch 49.005), train_loss = 0.78239853, grad/param norm = 2.1699e-01, time/batch = 19.2035s	
29257/29850 (epoch 49.007), train_loss = 0.82251323, grad/param norm = 2.9157e-01, time/batch = 17.3664s	
29258/29850 (epoch 49.008), train_loss = 0.94505768, grad/param norm = 2.8551e-01, time/batch = 18.9309s	
29259/29850 (epoch 49.010), train_loss = 0.65180443, grad/param norm = 2.2568e-01, time/batch = 16.8153s	
29260/29850 (epoch 49.012), train_loss = 0.71190305, grad/param norm = 2.5785e-01, time/batch = 16.9409s	
29261/29850 (epoch 49.013), train_loss = 0.74228394, grad/param norm = 2.7211e-01, time/batch = 19.6330s	
29262/29850 (epoch 49.015), train_loss = 0.83109843, grad/param norm = 2.4849e-01, time/batch = 18.2967s	
29263/29850 (epoch 49.017), train_loss = 0.78702752, grad/param norm = 2.8180e-01, time/batch = 18.4617s	
29264/29850 (epoch 49.018), train_loss = 0.85588877, grad/param norm = 2.4197e-01, time/batch = 17.9756s	
29265/29850 (epoch 49.020), train_loss = 0.75780115, grad/param norm = 2.5940e-01, time/batch = 15.9555s	
29266/29850 (epoch 49.022), train_loss = 0.83015678, grad/param norm = 2.2886e-01, time/batch = 17.4588s	
29267/29850 (epoch 49.023), train_loss = 0.80143788, grad/param norm = 2.0446e-01, time/batch = 16.2019s	
29268/29850 (epoch 49.025), train_loss = 0.73067731, grad/param norm = 2.0406e-01, time/batch = 17.6470s	
29269/29850 (epoch 49.027), train_loss = 0.54427524, grad/param norm = 2.0363e-01, time/batch = 15.8164s	
29270/29850 (epoch 49.028), train_loss = 0.65965477, grad/param norm = 1.9154e-01, time/batch = 18.5388s	
29271/29850 (epoch 49.030), train_loss = 0.69193195, grad/param norm = 2.6354e-01, time/batch = 17.7121s	
29272/29850 (epoch 49.032), train_loss = 0.79702272, grad/param norm = 2.4572e-01, time/batch = 19.7824s	
29273/29850 (epoch 49.034), train_loss = 0.66969125, grad/param norm = 2.3725e-01, time/batch = 19.1426s	
29274/29850 (epoch 49.035), train_loss = 0.57252836, grad/param norm = 1.9039e-01, time/batch = 18.2114s	
29275/29850 (epoch 49.037), train_loss = 0.71800318, grad/param norm = 2.2892e-01, time/batch = 18.7872s	
29276/29850 (epoch 49.039), train_loss = 0.65950108, grad/param norm = 2.1065e-01, time/batch = 17.6993s	
29277/29850 (epoch 49.040), train_loss = 0.60547844, grad/param norm = 1.9275e-01, time/batch = 17.8618s	
29278/29850 (epoch 49.042), train_loss = 0.67111838, grad/param norm = 2.2495e-01, time/batch = 17.6265s	
29279/29850 (epoch 49.044), train_loss = 0.72555114, grad/param norm = 2.0601e-01, time/batch = 18.1250s	
29280/29850 (epoch 49.045), train_loss = 0.79857845, grad/param norm = 2.3429e-01, time/batch = 17.0348s	
29281/29850 (epoch 49.047), train_loss = 0.62916313, grad/param norm = 2.1763e-01, time/batch = 17.6174s	
29282/29850 (epoch 49.049), train_loss = 0.75551174, grad/param norm = 2.4098e-01, time/batch = 19.3588s	
29283/29850 (epoch 49.050), train_loss = 0.70567200, grad/param norm = 2.4771e-01, time/batch = 19.0212s	
29284/29850 (epoch 49.052), train_loss = 0.82495006, grad/param norm = 2.5309e-01, time/batch = 17.1312s	
29285/29850 (epoch 49.054), train_loss = 0.72205175, grad/param norm = 2.4335e-01, time/batch = 18.1270s	
29286/29850 (epoch 49.055), train_loss = 0.71058951, grad/param norm = 2.3263e-01, time/batch = 17.6142s	
29287/29850 (epoch 49.057), train_loss = 0.79249589, grad/param norm = 2.1335e-01, time/batch = 16.4394s	
29288/29850 (epoch 49.059), train_loss = 0.76827776, grad/param norm = 2.7830e-01, time/batch = 15.4504s	
29289/29850 (epoch 49.060), train_loss = 0.75413142, grad/param norm = 2.7538e-01, time/batch = 16.3035s	
29290/29850 (epoch 49.062), train_loss = 0.83975561, grad/param norm = 2.6896e-01, time/batch = 18.3389s	
29291/29850 (epoch 49.064), train_loss = 0.83918551, grad/param norm = 2.6262e-01, time/batch = 17.6281s	
29292/29850 (epoch 49.065), train_loss = 0.60951577, grad/param norm = 2.1593e-01, time/batch = 18.8661s	
29293/29850 (epoch 49.067), train_loss = 0.81074623, grad/param norm = 2.2228e-01, time/batch = 15.7213s	
29294/29850 (epoch 49.069), train_loss = 0.75564777, grad/param norm = 2.2635e-01, time/batch = 16.3896s	
29295/29850 (epoch 49.070), train_loss = 0.81390360, grad/param norm = 2.2927e-01, time/batch = 18.1278s	
29296/29850 (epoch 49.072), train_loss = 0.76127591, grad/param norm = 2.7028e-01, time/batch = 20.0253s	
29297/29850 (epoch 49.074), train_loss = 0.81843141, grad/param norm = 2.1783e-01, time/batch = 16.1209s	
29298/29850 (epoch 49.075), train_loss = 0.68968397, grad/param norm = 2.4258e-01, time/batch = 18.6152s	
29299/29850 (epoch 49.077), train_loss = 0.78684309, grad/param norm = 2.2465e-01, time/batch = 19.4609s	
29300/29850 (epoch 49.079), train_loss = 0.93515574, grad/param norm = 3.4822e-01, time/batch = 18.8551s	
29301/29850 (epoch 49.080), train_loss = 0.92533601, grad/param norm = 3.2063e-01, time/batch = 16.2688s	
29302/29850 (epoch 49.082), train_loss = 0.80152942, grad/param norm = 2.6515e-01, time/batch = 16.8824s	
29303/29850 (epoch 49.084), train_loss = 0.89721289, grad/param norm = 2.7186e-01, time/batch = 18.1406s	
29304/29850 (epoch 49.085), train_loss = 0.92464318, grad/param norm = 2.2126e-01, time/batch = 16.3868s	
29305/29850 (epoch 49.087), train_loss = 0.86706113, grad/param norm = 2.5394e-01, time/batch = 16.8763s	
29306/29850 (epoch 49.089), train_loss = 0.79980367, grad/param norm = 2.2614e-01, time/batch = 17.9473s	
29307/29850 (epoch 49.090), train_loss = 0.79092973, grad/param norm = 2.1963e-01, time/batch = 17.6869s	
29308/29850 (epoch 49.092), train_loss = 0.69500858, grad/param norm = 2.4303e-01, time/batch = 17.8660s	
29309/29850 (epoch 49.094), train_loss = 0.87143830, grad/param norm = 2.5634e-01, time/batch = 18.4783s	
29310/29850 (epoch 49.095), train_loss = 0.82220921, grad/param norm = 2.7410e-01, time/batch = 15.8841s	
29311/29850 (epoch 49.097), train_loss = 0.58944068, grad/param norm = 1.8180e-01, time/batch = 17.4653s	
29312/29850 (epoch 49.099), train_loss = 0.60527243, grad/param norm = 2.3891e-01, time/batch = 17.8842s	
29313/29850 (epoch 49.101), train_loss = 0.79687976, grad/param norm = 2.2510e-01, time/batch = 18.6198s	
29314/29850 (epoch 49.102), train_loss = 0.81612436, grad/param norm = 2.4053e-01, time/batch = 16.3343s	
29315/29850 (epoch 49.104), train_loss = 0.73426047, grad/param norm = 2.8541e-01, time/batch = 14.8264s	
29316/29850 (epoch 49.106), train_loss = 0.82904018, grad/param norm = 2.3970e-01, time/batch = 15.0044s	
29317/29850 (epoch 49.107), train_loss = 0.69413563, grad/param norm = 1.8534e-01, time/batch = 14.8415s	
29318/29850 (epoch 49.109), train_loss = 0.75339313, grad/param norm = 2.2564e-01, time/batch = 16.8591s	
29319/29850 (epoch 49.111), train_loss = 0.78060203, grad/param norm = 2.4994e-01, time/batch = 17.1047s	
29320/29850 (epoch 49.112), train_loss = 0.68180085, grad/param norm = 2.2850e-01, time/batch = 15.9500s	
29321/29850 (epoch 49.114), train_loss = 0.69208135, grad/param norm = 2.3671e-01, time/batch = 17.1864s	
29322/29850 (epoch 49.116), train_loss = 0.68230332, grad/param norm = 2.1613e-01, time/batch = 16.1692s	
29323/29850 (epoch 49.117), train_loss = 0.70937726, grad/param norm = 2.5948e-01, time/batch = 15.7472s	
29324/29850 (epoch 49.119), train_loss = 0.69174176, grad/param norm = 2.2574e-01, time/batch = 14.6920s	
29325/29850 (epoch 49.121), train_loss = 0.61607927, grad/param norm = 2.3537e-01, time/batch = 17.0987s	
29326/29850 (epoch 49.122), train_loss = 0.64516238, grad/param norm = 1.8364e-01, time/batch = 17.2199s	
29327/29850 (epoch 49.124), train_loss = 0.67709272, grad/param norm = 2.4695e-01, time/batch = 18.7992s	
29328/29850 (epoch 49.126), train_loss = 0.73216977, grad/param norm = 2.4749e-01, time/batch = 16.4715s	
29329/29850 (epoch 49.127), train_loss = 0.77867918, grad/param norm = 3.8126e-01, time/batch = 16.2155s	
29330/29850 (epoch 49.129), train_loss = 0.76992547, grad/param norm = 2.7202e-01, time/batch = 17.4742s	
29331/29850 (epoch 49.131), train_loss = 0.75742391, grad/param norm = 2.2770e-01, time/batch = 17.2213s	
29332/29850 (epoch 49.132), train_loss = 0.65476445, grad/param norm = 2.5389e-01, time/batch = 17.7025s	
29333/29850 (epoch 49.134), train_loss = 0.72959448, grad/param norm = 2.6188e-01, time/batch = 16.9740s	
29334/29850 (epoch 49.136), train_loss = 0.80716550, grad/param norm = 2.1642e-01, time/batch = 17.9733s	
29335/29850 (epoch 49.137), train_loss = 0.60710139, grad/param norm = 2.3203e-01, time/batch = 17.2186s	
29336/29850 (epoch 49.139), train_loss = 0.73531689, grad/param norm = 2.0996e-01, time/batch = 17.0948s	
29337/29850 (epoch 49.141), train_loss = 0.65776405, grad/param norm = 2.2569e-01, time/batch = 17.6329s	
29338/29850 (epoch 49.142), train_loss = 0.85164999, grad/param norm = 2.7706e-01, time/batch = 17.9694s	
29339/29850 (epoch 49.144), train_loss = 0.96965984, grad/param norm = 2.6399e-01, time/batch = 17.7778s	
29340/29850 (epoch 49.146), train_loss = 0.94467517, grad/param norm = 3.0712e-01, time/batch = 17.5440s	
29341/29850 (epoch 49.147), train_loss = 0.86627840, grad/param norm = 2.5375e-01, time/batch = 18.9698s	
29342/29850 (epoch 49.149), train_loss = 0.80601878, grad/param norm = 2.2645e-01, time/batch = 17.9589s	
29343/29850 (epoch 49.151), train_loss = 0.78653714, grad/param norm = 2.2976e-01, time/batch = 18.1411s	
29344/29850 (epoch 49.152), train_loss = 0.75519323, grad/param norm = 2.7532e-01, time/batch = 17.4777s	
29345/29850 (epoch 49.154), train_loss = 0.69847970, grad/param norm = 2.8983e-01, time/batch = 16.5518s	
29346/29850 (epoch 49.156), train_loss = 0.69643038, grad/param norm = 2.9369e-01, time/batch = 16.7856s	
29347/29850 (epoch 49.157), train_loss = 0.80416540, grad/param norm = 2.5219e-01, time/batch = 18.2982s	
29348/29850 (epoch 49.159), train_loss = 0.70739276, grad/param norm = 2.1259e-01, time/batch = 19.6071s	
29349/29850 (epoch 49.161), train_loss = 0.73284287, grad/param norm = 2.7038e-01, time/batch = 15.3490s	
29350/29850 (epoch 49.162), train_loss = 0.87593636, grad/param norm = 2.6523e-01, time/batch = 16.7049s	
29351/29850 (epoch 49.164), train_loss = 0.79449460, grad/param norm = 2.5264e-01, time/batch = 18.3702s	
29352/29850 (epoch 49.166), train_loss = 0.72471355, grad/param norm = 2.1581e-01, time/batch = 16.3710s	
29353/29850 (epoch 49.168), train_loss = 0.66836723, grad/param norm = 2.2960e-01, time/batch = 16.5455s	
29354/29850 (epoch 49.169), train_loss = 0.87206158, grad/param norm = 3.6048e-01, time/batch = 17.0423s	
29355/29850 (epoch 49.171), train_loss = 0.84991064, grad/param norm = 2.5614e-01, time/batch = 17.6733s	
29356/29850 (epoch 49.173), train_loss = 0.66785030, grad/param norm = 2.3142e-01, time/batch = 17.2880s	
29357/29850 (epoch 49.174), train_loss = 0.70714052, grad/param norm = 2.3839e-01, time/batch = 18.5272s	
29358/29850 (epoch 49.176), train_loss = 0.80045322, grad/param norm = 2.4582e-01, time/batch = 17.4540s	
29359/29850 (epoch 49.178), train_loss = 0.79805853, grad/param norm = 2.6737e-01, time/batch = 18.1449s	
29360/29850 (epoch 49.179), train_loss = 0.62890533, grad/param norm = 2.5470e-01, time/batch = 16.7182s	
29361/29850 (epoch 49.181), train_loss = 0.77993500, grad/param norm = 2.5811e-01, time/batch = 18.2247s	
29362/29850 (epoch 49.183), train_loss = 0.78201165, grad/param norm = 2.5476e-01, time/batch = 17.2962s	
29363/29850 (epoch 49.184), train_loss = 0.84982161, grad/param norm = 2.6695e-01, time/batch = 17.7871s	
29364/29850 (epoch 49.186), train_loss = 0.81202175, grad/param norm = 2.9014e-01, time/batch = 16.4007s	
29365/29850 (epoch 49.188), train_loss = 0.90914063, grad/param norm = 2.6173e-01, time/batch = 17.1983s	
29366/29850 (epoch 49.189), train_loss = 0.80730733, grad/param norm = 2.6031e-01, time/batch = 16.8576s	
29367/29850 (epoch 49.191), train_loss = 0.84854775, grad/param norm = 2.4312e-01, time/batch = 17.8937s	
29368/29850 (epoch 49.193), train_loss = 0.73939479, grad/param norm = 2.0757e-01, time/batch = 18.6394s	
29369/29850 (epoch 49.194), train_loss = 0.84469706, grad/param norm = 2.1708e-01, time/batch = 15.8625s	
29370/29850 (epoch 49.196), train_loss = 0.72054159, grad/param norm = 2.1405e-01, time/batch = 15.5538s	
29371/29850 (epoch 49.198), train_loss = 0.66917910, grad/param norm = 2.0435e-01, time/batch = 18.6216s	
29372/29850 (epoch 49.199), train_loss = 0.94047137, grad/param norm = 2.5660e-01, time/batch = 15.8182s	
29373/29850 (epoch 49.201), train_loss = 0.68534410, grad/param norm = 2.0460e-01, time/batch = 17.7142s	
29374/29850 (epoch 49.203), train_loss = 0.52995780, grad/param norm = 1.8717e-01, time/batch = 17.6299s	
29375/29850 (epoch 49.204), train_loss = 0.71442702, grad/param norm = 2.2491e-01, time/batch = 18.4653s	
29376/29850 (epoch 49.206), train_loss = 0.65700538, grad/param norm = 2.0835e-01, time/batch = 19.2082s	
29377/29850 (epoch 49.208), train_loss = 0.87248935, grad/param norm = 2.4438e-01, time/batch = 16.1252s	
29378/29850 (epoch 49.209), train_loss = 0.68576862, grad/param norm = 2.7341e-01, time/batch = 19.9556s	
29379/29850 (epoch 49.211), train_loss = 0.73673604, grad/param norm = 2.0101e-01, time/batch = 18.0348s	
29380/29850 (epoch 49.213), train_loss = 0.77632840, grad/param norm = 2.3250e-01, time/batch = 15.9403s	
29381/29850 (epoch 49.214), train_loss = 0.62527474, grad/param norm = 1.9581e-01, time/batch = 17.2156s	
29382/29850 (epoch 49.216), train_loss = 0.65456655, grad/param norm = 2.2818e-01, time/batch = 18.1331s	
29383/29850 (epoch 49.218), train_loss = 0.75991710, grad/param norm = 2.2236e-01, time/batch = 18.3057s	
29384/29850 (epoch 49.219), train_loss = 0.74052732, grad/param norm = 3.2002e-01, time/batch = 15.7278s	
29385/29850 (epoch 49.221), train_loss = 0.72974130, grad/param norm = 2.5700e-01, time/batch = 19.2143s	
29386/29850 (epoch 49.223), train_loss = 0.58926946, grad/param norm = 2.1018e-01, time/batch = 17.8021s	
29387/29850 (epoch 49.224), train_loss = 0.61317755, grad/param norm = 2.2615e-01, time/batch = 16.7761s	
29388/29850 (epoch 49.226), train_loss = 0.67619179, grad/param norm = 2.5633e-01, time/batch = 17.2873s	
29389/29850 (epoch 49.228), train_loss = 0.72374093, grad/param norm = 2.1507e-01, time/batch = 17.6421s	
29390/29850 (epoch 49.229), train_loss = 0.62090689, grad/param norm = 2.1867e-01, time/batch = 17.7191s	
29391/29850 (epoch 49.231), train_loss = 0.77143577, grad/param norm = 2.4066e-01, time/batch = 16.8993s	
29392/29850 (epoch 49.233), train_loss = 0.71088693, grad/param norm = 2.3215e-01, time/batch = 19.6348s	
29393/29850 (epoch 49.235), train_loss = 0.66558474, grad/param norm = 2.0642e-01, time/batch = 18.3672s	
29394/29850 (epoch 49.236), train_loss = 0.87948345, grad/param norm = 3.1253e-01, time/batch = 16.8788s	
29395/29850 (epoch 49.238), train_loss = 0.63792518, grad/param norm = 2.2116e-01, time/batch = 14.4913s	
29396/29850 (epoch 49.240), train_loss = 0.64248777, grad/param norm = 2.1977e-01, time/batch = 15.8501s	
29397/29850 (epoch 49.241), train_loss = 0.75614577, grad/param norm = 2.5049e-01, time/batch = 17.0977s	
29398/29850 (epoch 49.243), train_loss = 0.80134929, grad/param norm = 2.5744e-01, time/batch = 18.2997s	
29399/29850 (epoch 49.245), train_loss = 0.64964305, grad/param norm = 2.1493e-01, time/batch = 18.8700s	
29400/29850 (epoch 49.246), train_loss = 0.68226427, grad/param norm = 2.2417e-01, time/batch = 18.5168s	
29401/29850 (epoch 49.248), train_loss = 0.64477143, grad/param norm = 2.4086e-01, time/batch = 19.5396s	
29402/29850 (epoch 49.250), train_loss = 0.70186910, grad/param norm = 2.0511e-01, time/batch = 18.8801s	
29403/29850 (epoch 49.251), train_loss = 0.57644976, grad/param norm = 2.2022e-01, time/batch = 18.8040s	
29404/29850 (epoch 49.253), train_loss = 0.60090129, grad/param norm = 2.4824e-01, time/batch = 16.6968s	
29405/29850 (epoch 49.255), train_loss = 0.65370816, grad/param norm = 2.2270e-01, time/batch = 16.0994s	
29406/29850 (epoch 49.256), train_loss = 0.77103499, grad/param norm = 2.6591e-01, time/batch = 16.9594s	
29407/29850 (epoch 49.258), train_loss = 0.79407896, grad/param norm = 2.5299e-01, time/batch = 17.9530s	
29408/29850 (epoch 49.260), train_loss = 0.72920880, grad/param norm = 2.1011e-01, time/batch = 19.2891s	
29409/29850 (epoch 49.261), train_loss = 0.67620527, grad/param norm = 2.5034e-01, time/batch = 15.5386s	
29410/29850 (epoch 49.263), train_loss = 0.65995070, grad/param norm = 2.3196e-01, time/batch = 18.4488s	
29411/29850 (epoch 49.265), train_loss = 0.71129926, grad/param norm = 2.2633e-01, time/batch = 17.8080s	
29412/29850 (epoch 49.266), train_loss = 0.73083234, grad/param norm = 2.3834e-01, time/batch = 19.3057s	
29413/29850 (epoch 49.268), train_loss = 0.69325754, grad/param norm = 2.5644e-01, time/batch = 16.3777s	
29414/29850 (epoch 49.270), train_loss = 0.67134832, grad/param norm = 2.4258e-01, time/batch = 17.7824s	
29415/29850 (epoch 49.271), train_loss = 0.73604313, grad/param norm = 2.1782e-01, time/batch = 17.9737s	
29416/29850 (epoch 49.273), train_loss = 0.62841324, grad/param norm = 2.2614e-01, time/batch = 16.7016s	
29417/29850 (epoch 49.275), train_loss = 0.62589384, grad/param norm = 2.2571e-01, time/batch = 17.2848s	
29418/29850 (epoch 49.276), train_loss = 0.64155909, grad/param norm = 2.0746e-01, time/batch = 18.0229s	
29419/29850 (epoch 49.278), train_loss = 0.68028538, grad/param norm = 2.1664e-01, time/batch = 19.0550s	
29420/29850 (epoch 49.280), train_loss = 0.89026881, grad/param norm = 3.4546e-01, time/batch = 18.9531s	
29421/29850 (epoch 49.281), train_loss = 0.73784656, grad/param norm = 2.2533e-01, time/batch = 17.1211s	
29422/29850 (epoch 49.283), train_loss = 0.78884923, grad/param norm = 2.3840e-01, time/batch = 17.5603s	
29423/29850 (epoch 49.285), train_loss = 0.79723717, grad/param norm = 2.0937e-01, time/batch = 19.2084s	
29424/29850 (epoch 49.286), train_loss = 0.83416236, grad/param norm = 2.3174e-01, time/batch = 16.2975s	
29425/29850 (epoch 49.288), train_loss = 0.74271581, grad/param norm = 2.9796e-01, time/batch = 17.9618s	
29426/29850 (epoch 49.290), train_loss = 0.76396775, grad/param norm = 2.7714e-01, time/batch = 18.4562s	
29427/29850 (epoch 49.291), train_loss = 0.94087400, grad/param norm = 3.0267e-01, time/batch = 17.0411s	
29428/29850 (epoch 49.293), train_loss = 0.87331841, grad/param norm = 3.0903e-01, time/batch = 19.8657s	
29429/29850 (epoch 49.295), train_loss = 0.93711935, grad/param norm = 2.6163e-01, time/batch = 18.1941s	
29430/29850 (epoch 49.296), train_loss = 0.67389863, grad/param norm = 1.8657e-01, time/batch = 16.5442s	
29431/29850 (epoch 49.298), train_loss = 0.57295872, grad/param norm = 1.7737e-01, time/batch = 17.7152s	
29432/29850 (epoch 49.300), train_loss = 0.63067917, grad/param norm = 2.1130e-01, time/batch = 15.7945s	
29433/29850 (epoch 49.302), train_loss = 0.63555870, grad/param norm = 2.1337e-01, time/batch = 19.2121s	
29434/29850 (epoch 49.303), train_loss = 0.67138017, grad/param norm = 2.5056e-01, time/batch = 16.5443s	
29435/29850 (epoch 49.305), train_loss = 0.82600006, grad/param norm = 2.4176e-01, time/batch = 17.7115s	
29436/29850 (epoch 49.307), train_loss = 0.81169514, grad/param norm = 2.4211e-01, time/batch = 18.7183s	
29437/29850 (epoch 49.308), train_loss = 0.61897676, grad/param norm = 2.0716e-01, time/batch = 22.4732s	
29438/29850 (epoch 49.310), train_loss = 0.80635338, grad/param norm = 2.3709e-01, time/batch = 26.6999s	
29439/29850 (epoch 49.312), train_loss = 0.84581449, grad/param norm = 2.2634e-01, time/batch = 18.0283s	
29440/29850 (epoch 49.313), train_loss = 0.75239935, grad/param norm = 2.5856e-01, time/batch = 16.6866s	
29441/29850 (epoch 49.315), train_loss = 0.79501646, grad/param norm = 2.3961e-01, time/batch = 19.0478s	
29442/29850 (epoch 49.317), train_loss = 0.74476317, grad/param norm = 2.4622e-01, time/batch = 16.6979s	
29443/29850 (epoch 49.318), train_loss = 0.68974236, grad/param norm = 2.1317e-01, time/batch = 17.4521s	
29444/29850 (epoch 49.320), train_loss = 0.68598171, grad/param norm = 2.1078e-01, time/batch = 17.1953s	
29445/29850 (epoch 49.322), train_loss = 0.83745785, grad/param norm = 2.8549e-01, time/batch = 17.8082s	
29446/29850 (epoch 49.323), train_loss = 0.77307416, grad/param norm = 2.4900e-01, time/batch = 16.2967s	
29447/29850 (epoch 49.325), train_loss = 0.81324961, grad/param norm = 2.3589e-01, time/batch = 17.4564s	
29448/29850 (epoch 49.327), train_loss = 0.94917825, grad/param norm = 2.6257e-01, time/batch = 19.7881s	
29449/29850 (epoch 49.328), train_loss = 0.85848343, grad/param norm = 2.6127e-01, time/batch = 16.7212s	
29450/29850 (epoch 49.330), train_loss = 0.83762357, grad/param norm = 2.1567e-01, time/batch = 17.4694s	
29451/29850 (epoch 49.332), train_loss = 0.73669278, grad/param norm = 2.2552e-01, time/batch = 18.9526s	
29452/29850 (epoch 49.333), train_loss = 0.78770050, grad/param norm = 2.3290e-01, time/batch = 16.5582s	
29453/29850 (epoch 49.335), train_loss = 0.86802613, grad/param norm = 2.5112e-01, time/batch = 18.1177s	
29454/29850 (epoch 49.337), train_loss = 0.75431633, grad/param norm = 2.4767e-01, time/batch = 17.8812s	
29455/29850 (epoch 49.338), train_loss = 0.80793214, grad/param norm = 2.1029e-01, time/batch = 18.2116s	
29456/29850 (epoch 49.340), train_loss = 0.65596377, grad/param norm = 2.0674e-01, time/batch = 17.1326s	
29457/29850 (epoch 49.342), train_loss = 0.76395034, grad/param norm = 3.2210e-01, time/batch = 15.2913s	
29458/29850 (epoch 49.343), train_loss = 0.74012531, grad/param norm = 2.2873e-01, time/batch = 17.0373s	
29459/29850 (epoch 49.345), train_loss = 0.81327129, grad/param norm = 2.3401e-01, time/batch = 15.1112s	
29460/29850 (epoch 49.347), train_loss = 0.82143722, grad/param norm = 2.4923e-01, time/batch = 17.7031s	
29461/29850 (epoch 49.348), train_loss = 0.69680935, grad/param norm = 2.3893e-01, time/batch = 19.6269s	
29462/29850 (epoch 49.350), train_loss = 0.78744381, grad/param norm = 2.8272e-01, time/batch = 17.9637s	
29463/29850 (epoch 49.352), train_loss = 0.70981320, grad/param norm = 2.3239e-01, time/batch = 16.6361s	
29464/29850 (epoch 49.353), train_loss = 0.78389562, grad/param norm = 2.5169e-01, time/batch = 18.2940s	
29465/29850 (epoch 49.355), train_loss = 0.69375781, grad/param norm = 2.3611e-01, time/batch = 18.2909s	
29466/29850 (epoch 49.357), train_loss = 0.86192532, grad/param norm = 2.4274e-01, time/batch = 19.3090s	
29467/29850 (epoch 49.358), train_loss = 0.69012827, grad/param norm = 2.3494e-01, time/batch = 17.6333s	
29468/29850 (epoch 49.360), train_loss = 0.73725774, grad/param norm = 2.1317e-01, time/batch = 17.9778s	
29469/29850 (epoch 49.362), train_loss = 0.75508918, grad/param norm = 2.3492e-01, time/batch = 19.1326s	
29470/29850 (epoch 49.363), train_loss = 0.76446974, grad/param norm = 2.3865e-01, time/batch = 17.6886s	
29471/29850 (epoch 49.365), train_loss = 0.84512123, grad/param norm = 2.7375e-01, time/batch = 17.7102s	
29472/29850 (epoch 49.367), train_loss = 0.67999366, grad/param norm = 1.9248e-01, time/batch = 16.5630s	
29473/29850 (epoch 49.369), train_loss = 0.58662627, grad/param norm = 2.1717e-01, time/batch = 18.3957s	
29474/29850 (epoch 49.370), train_loss = 0.63433650, grad/param norm = 2.2704e-01, time/batch = 18.0265s	
29475/29850 (epoch 49.372), train_loss = 0.82886747, grad/param norm = 2.2370e-01, time/batch = 15.1826s	
29476/29850 (epoch 49.374), train_loss = 0.83415231, grad/param norm = 2.1810e-01, time/batch = 19.5461s	
29477/29850 (epoch 49.375), train_loss = 0.78716894, grad/param norm = 2.5234e-01, time/batch = 18.0462s	
29478/29850 (epoch 49.377), train_loss = 0.62921536, grad/param norm = 1.8912e-01, time/batch = 17.7140s	
29479/29850 (epoch 49.379), train_loss = 0.84411376, grad/param norm = 2.2666e-01, time/batch = 18.6184s	
29480/29850 (epoch 49.380), train_loss = 0.79507855, grad/param norm = 2.3639e-01, time/batch = 15.9602s	
29481/29850 (epoch 49.382), train_loss = 0.76071353, grad/param norm = 2.5115e-01, time/batch = 18.9582s	
29482/29850 (epoch 49.384), train_loss = 0.78735592, grad/param norm = 2.2562e-01, time/batch = 17.4682s	
29483/29850 (epoch 49.385), train_loss = 0.79830012, grad/param norm = 2.5666e-01, time/batch = 19.0507s	
29484/29850 (epoch 49.387), train_loss = 0.78213409, grad/param norm = 3.2480e-01, time/batch = 18.1058s	
29485/29850 (epoch 49.389), train_loss = 0.88513053, grad/param norm = 2.8179e-01, time/batch = 16.6312s	
29486/29850 (epoch 49.390), train_loss = 0.83815753, grad/param norm = 2.3472e-01, time/batch = 17.6277s	
29487/29850 (epoch 49.392), train_loss = 0.77944258, grad/param norm = 2.4177e-01, time/batch = 15.8733s	
29488/29850 (epoch 49.394), train_loss = 0.77458567, grad/param norm = 2.0593e-01, time/batch = 17.5463s	
29489/29850 (epoch 49.395), train_loss = 0.72101216, grad/param norm = 2.5115e-01, time/batch = 16.3494s	
29490/29850 (epoch 49.397), train_loss = 0.64562105, grad/param norm = 2.3662e-01, time/batch = 18.2897s	
29491/29850 (epoch 49.399), train_loss = 0.68756952, grad/param norm = 2.4261e-01, time/batch = 17.2982s	
29492/29850 (epoch 49.400), train_loss = 1.01207342, grad/param norm = 2.5524e-01, time/batch = 18.1446s	
29493/29850 (epoch 49.402), train_loss = 0.84738571, grad/param norm = 2.4698e-01, time/batch = 18.3082s	
29494/29850 (epoch 49.404), train_loss = 0.76586787, grad/param norm = 2.3311e-01, time/batch = 17.2128s	
29495/29850 (epoch 49.405), train_loss = 0.68541550, grad/param norm = 2.2718e-01, time/batch = 19.3752s	
29496/29850 (epoch 49.407), train_loss = 0.67840757, grad/param norm = 1.9551e-01, time/batch = 16.4744s	
29497/29850 (epoch 49.409), train_loss = 0.78906315, grad/param norm = 2.7517e-01, time/batch = 16.0352s	
29498/29850 (epoch 49.410), train_loss = 0.82201581, grad/param norm = 2.3255e-01, time/batch = 16.8827s	
29499/29850 (epoch 49.412), train_loss = 0.85338056, grad/param norm = 2.9574e-01, time/batch = 18.5580s	
29500/29850 (epoch 49.414), train_loss = 0.76961504, grad/param norm = 2.5062e-01, time/batch = 18.0463s	
29501/29850 (epoch 49.415), train_loss = 0.74141815, grad/param norm = 2.0635e-01, time/batch = 16.8688s	
29502/29850 (epoch 49.417), train_loss = 0.85718241, grad/param norm = 2.5429e-01, time/batch = 16.2000s	
29503/29850 (epoch 49.419), train_loss = 0.72991823, grad/param norm = 2.1812e-01, time/batch = 18.1154s	
29504/29850 (epoch 49.420), train_loss = 0.73996147, grad/param norm = 2.7244e-01, time/batch = 16.8053s	
29505/29850 (epoch 49.422), train_loss = 0.73924986, grad/param norm = 2.2821e-01, time/batch = 17.2118s	
29506/29850 (epoch 49.424), train_loss = 0.65437743, grad/param norm = 2.1744e-01, time/batch = 16.9747s	
29507/29850 (epoch 49.425), train_loss = 0.84242577, grad/param norm = 2.6880e-01, time/batch = 19.0527s	
29508/29850 (epoch 49.427), train_loss = 0.57360212, grad/param norm = 2.4162e-01, time/batch = 17.8626s	
29509/29850 (epoch 49.429), train_loss = 0.67100810, grad/param norm = 2.2238e-01, time/batch = 17.7973s	
29510/29850 (epoch 49.430), train_loss = 0.61268991, grad/param norm = 1.9118e-01, time/batch = 15.1670s	
29511/29850 (epoch 49.432), train_loss = 0.72588239, grad/param norm = 2.6068e-01, time/batch = 15.8120s	
29512/29850 (epoch 49.434), train_loss = 0.67306790, grad/param norm = 1.8618e-01, time/batch = 16.8076s	
29513/29850 (epoch 49.436), train_loss = 0.71604764, grad/param norm = 2.2908e-01, time/batch = 18.9625s	
29514/29850 (epoch 49.437), train_loss = 0.83249213, grad/param norm = 2.1822e-01, time/batch = 16.8869s	
29515/29850 (epoch 49.439), train_loss = 0.79907694, grad/param norm = 2.3500e-01, time/batch = 18.3419s	
29516/29850 (epoch 49.441), train_loss = 0.73755844, grad/param norm = 2.3761e-01, time/batch = 18.2148s	
29517/29850 (epoch 49.442), train_loss = 0.73417593, grad/param norm = 2.0746e-01, time/batch = 17.4630s	
29518/29850 (epoch 49.444), train_loss = 0.76646719, grad/param norm = 2.2632e-01, time/batch = 17.1902s	
29519/29850 (epoch 49.446), train_loss = 0.85053851, grad/param norm = 2.3892e-01, time/batch = 18.4768s	
29520/29850 (epoch 49.447), train_loss = 0.85805493, grad/param norm = 2.7564e-01, time/batch = 15.7048s	
29521/29850 (epoch 49.449), train_loss = 0.74910717, grad/param norm = 2.5071e-01, time/batch = 18.2790s	
29522/29850 (epoch 49.451), train_loss = 0.60000269, grad/param norm = 2.4237e-01, time/batch = 17.7007s	
29523/29850 (epoch 49.452), train_loss = 0.50693926, grad/param norm = 1.9580e-01, time/batch = 17.8851s	
29524/29850 (epoch 49.454), train_loss = 0.63093732, grad/param norm = 2.0453e-01, time/batch = 17.7098s	
29525/29850 (epoch 49.456), train_loss = 0.81024101, grad/param norm = 2.5836e-01, time/batch = 17.5367s	
29526/29850 (epoch 49.457), train_loss = 0.84744285, grad/param norm = 4.3206e-01, time/batch = 17.6934s	
29527/29850 (epoch 49.459), train_loss = 0.88447661, grad/param norm = 2.6549e-01, time/batch = 18.8052s	
29528/29850 (epoch 49.461), train_loss = 0.90787835, grad/param norm = 2.5420e-01, time/batch = 18.4537s	
29529/29850 (epoch 49.462), train_loss = 0.95365947, grad/param norm = 2.7910e-01, time/batch = 18.3137s	
29530/29850 (epoch 49.464), train_loss = 0.80701703, grad/param norm = 2.2332e-01, time/batch = 18.7836s	
29531/29850 (epoch 49.466), train_loss = 0.66340913, grad/param norm = 2.2668e-01, time/batch = 16.7790s	
29532/29850 (epoch 49.467), train_loss = 0.71509014, grad/param norm = 2.6521e-01, time/batch = 19.7768s	
29533/29850 (epoch 49.469), train_loss = 0.73006889, grad/param norm = 2.2284e-01, time/batch = 18.7956s	
29534/29850 (epoch 49.471), train_loss = 0.74057266, grad/param norm = 2.7388e-01, time/batch = 18.2953s	
29535/29850 (epoch 49.472), train_loss = 0.71671372, grad/param norm = 2.6091e-01, time/batch = 18.8635s	
29536/29850 (epoch 49.474), train_loss = 0.81825331, grad/param norm = 2.5897e-01, time/batch = 17.8028s	
29537/29850 (epoch 49.476), train_loss = 0.77922289, grad/param norm = 2.0956e-01, time/batch = 18.4779s	
29538/29850 (epoch 49.477), train_loss = 0.80748366, grad/param norm = 2.6456e-01, time/batch = 16.5898s	
29539/29850 (epoch 49.479), train_loss = 0.91913794, grad/param norm = 2.6724e-01, time/batch = 18.3672s	
29540/29850 (epoch 49.481), train_loss = 0.78679843, grad/param norm = 2.6824e-01, time/batch = 17.6362s	
29541/29850 (epoch 49.482), train_loss = 0.70608499, grad/param norm = 2.0961e-01, time/batch = 15.3736s	
29542/29850 (epoch 49.484), train_loss = 0.72864907, grad/param norm = 2.2892e-01, time/batch = 19.2751s	
29543/29850 (epoch 49.486), train_loss = 0.79006936, grad/param norm = 2.8915e-01, time/batch = 18.8793s	
29544/29850 (epoch 49.487), train_loss = 0.76863068, grad/param norm = 2.1353e-01, time/batch = 18.1249s	
29545/29850 (epoch 49.489), train_loss = 0.79122364, grad/param norm = 2.9085e-01, time/batch = 18.3776s	
29546/29850 (epoch 49.491), train_loss = 0.69621528, grad/param norm = 2.3728e-01, time/batch = 18.9713s	
29547/29850 (epoch 49.492), train_loss = 0.74713434, grad/param norm = 2.1967e-01, time/batch = 17.6969s	
29548/29850 (epoch 49.494), train_loss = 0.80217510, grad/param norm = 2.2026e-01, time/batch = 18.1996s	
29549/29850 (epoch 49.496), train_loss = 0.86750038, grad/param norm = 2.2278e-01, time/batch = 19.2017s	
29550/29850 (epoch 49.497), train_loss = 0.78525671, grad/param norm = 2.4628e-01, time/batch = 19.1177s	
29551/29850 (epoch 49.499), train_loss = 0.76801355, grad/param norm = 2.5287e-01, time/batch = 16.3077s	
29552/29850 (epoch 49.501), train_loss = 0.66001514, grad/param norm = 2.5803e-01, time/batch = 18.7066s	
29553/29850 (epoch 49.503), train_loss = 0.85588414, grad/param norm = 2.4240e-01, time/batch = 18.4651s	
29554/29850 (epoch 49.504), train_loss = 1.02682125, grad/param norm = 2.6950e-01, time/batch = 17.4294s	
29555/29850 (epoch 49.506), train_loss = 0.97356750, grad/param norm = 3.2016e-01, time/batch = 16.6295s	
29556/29850 (epoch 49.508), train_loss = 0.79254227, grad/param norm = 2.3603e-01, time/batch = 17.6270s	
29557/29850 (epoch 49.509), train_loss = 0.59472348, grad/param norm = 2.0270e-01, time/batch = 18.6375s	
29558/29850 (epoch 49.511), train_loss = 0.79838767, grad/param norm = 2.2448e-01, time/batch = 16.6061s	
29559/29850 (epoch 49.513), train_loss = 0.76016632, grad/param norm = 3.2225e-01, time/batch = 17.3480s	
29560/29850 (epoch 49.514), train_loss = 0.68225305, grad/param norm = 2.2954e-01, time/batch = 18.5376s	
29561/29850 (epoch 49.516), train_loss = 0.71684181, grad/param norm = 2.0689e-01, time/batch = 17.6022s	
29562/29850 (epoch 49.518), train_loss = 0.60703545, grad/param norm = 1.9183e-01, time/batch = 19.3735s	
29563/29850 (epoch 49.519), train_loss = 0.64053485, grad/param norm = 2.3028e-01, time/batch = 15.1304s	
29564/29850 (epoch 49.521), train_loss = 0.58601587, grad/param norm = 2.2564e-01, time/batch = 16.4411s	
29565/29850 (epoch 49.523), train_loss = 0.62036659, grad/param norm = 1.7147e-01, time/batch = 18.2188s	
29566/29850 (epoch 49.524), train_loss = 0.64030220, grad/param norm = 2.5179e-01, time/batch = 19.2104s	
29567/29850 (epoch 49.526), train_loss = 0.66391313, grad/param norm = 2.5473e-01, time/batch = 17.3702s	
29568/29850 (epoch 49.528), train_loss = 0.79510789, grad/param norm = 2.2443e-01, time/batch = 16.4560s	
29569/29850 (epoch 49.529), train_loss = 0.78453081, grad/param norm = 3.2076e-01, time/batch = 17.4657s	
29570/29850 (epoch 49.531), train_loss = 0.75969738, grad/param norm = 3.4831e-01, time/batch = 16.9052s	
29571/29850 (epoch 49.533), train_loss = 0.76815431, grad/param norm = 2.5296e-01, time/batch = 17.2921s	
29572/29850 (epoch 49.534), train_loss = 0.81842551, grad/param norm = 2.7183e-01, time/batch = 18.5317s	
29573/29850 (epoch 49.536), train_loss = 0.70256324, grad/param norm = 2.4800e-01, time/batch = 16.3927s	
29574/29850 (epoch 49.538), train_loss = 0.87370854, grad/param norm = 2.5752e-01, time/batch = 19.3762s	
29575/29850 (epoch 49.539), train_loss = 0.88170016, grad/param norm = 2.8165e-01, time/batch = 16.7090s	
29576/29850 (epoch 49.541), train_loss = 0.53226505, grad/param norm = 1.9703e-01, time/batch = 19.7088s	
29577/29850 (epoch 49.543), train_loss = 0.69854582, grad/param norm = 2.3384e-01, time/batch = 16.5454s	
29578/29850 (epoch 49.544), train_loss = 0.85718446, grad/param norm = 2.6455e-01, time/batch = 17.3000s	
29579/29850 (epoch 49.546), train_loss = 0.83738109, grad/param norm = 2.7063e-01, time/batch = 18.1163s	
29580/29850 (epoch 49.548), train_loss = 0.61227298, grad/param norm = 2.0712e-01, time/batch = 18.7105s	
29581/29850 (epoch 49.549), train_loss = 0.72010460, grad/param norm = 2.2672e-01, time/batch = 15.1821s	
29582/29850 (epoch 49.551), train_loss = 0.67077605, grad/param norm = 2.1013e-01, time/batch = 16.3779s	
29583/29850 (epoch 49.553), train_loss = 0.74782785, grad/param norm = 2.3285e-01, time/batch = 16.0585s	
29584/29850 (epoch 49.554), train_loss = 0.60932529, grad/param norm = 2.1108e-01, time/batch = 18.1240s	
29585/29850 (epoch 49.556), train_loss = 0.63770193, grad/param norm = 2.1027e-01, time/batch = 17.6019s	
29586/29850 (epoch 49.558), train_loss = 0.66177841, grad/param norm = 2.2204e-01, time/batch = 17.6174s	
29587/29850 (epoch 49.559), train_loss = 0.68475643, grad/param norm = 3.3100e-01, time/batch = 17.2896s	
29588/29850 (epoch 49.561), train_loss = 0.77301860, grad/param norm = 2.6785e-01, time/batch = 14.7975s	
29589/29850 (epoch 49.563), train_loss = 0.78949132, grad/param norm = 2.1527e-01, time/batch = 17.0372s	
29590/29850 (epoch 49.564), train_loss = 0.71962248, grad/param norm = 2.3114e-01, time/batch = 16.8059s	
29591/29850 (epoch 49.566), train_loss = 0.73549189, grad/param norm = 2.3341e-01, time/batch = 18.0431s	
29592/29850 (epoch 49.568), train_loss = 0.87795709, grad/param norm = 2.4601e-01, time/batch = 17.0402s	
29593/29850 (epoch 49.570), train_loss = 0.75064436, grad/param norm = 2.3353e-01, time/batch = 16.5596s	
29594/29850 (epoch 49.571), train_loss = 0.81758892, grad/param norm = 2.3321e-01, time/batch = 18.8739s	
29595/29850 (epoch 49.573), train_loss = 0.86960034, grad/param norm = 2.6337e-01, time/batch = 15.7846s	
29596/29850 (epoch 49.575), train_loss = 0.92434260, grad/param norm = 2.3461e-01, time/batch = 18.5488s	
29597/29850 (epoch 49.576), train_loss = 0.81424170, grad/param norm = 2.3537e-01, time/batch = 18.8765s	
29598/29850 (epoch 49.578), train_loss = 0.70713470, grad/param norm = 2.4613e-01, time/batch = 17.3775s	
29599/29850 (epoch 49.580), train_loss = 0.82334525, grad/param norm = 2.8468e-01, time/batch = 17.5446s	
29600/29850 (epoch 49.581), train_loss = 0.71293955, grad/param norm = 2.1246e-01, time/batch = 19.2158s	
29601/29850 (epoch 49.583), train_loss = 0.74578882, grad/param norm = 2.3857e-01, time/batch = 17.3900s	
29602/29850 (epoch 49.585), train_loss = 0.77800471, grad/param norm = 2.4306e-01, time/batch = 17.0483s	
29603/29850 (epoch 49.586), train_loss = 0.79878832, grad/param norm = 2.9694e-01, time/batch = 15.7783s	
29604/29850 (epoch 49.588), train_loss = 0.66948482, grad/param norm = 2.0650e-01, time/batch = 17.2918s	
29605/29850 (epoch 49.590), train_loss = 0.70621742, grad/param norm = 2.0563e-01, time/batch = 19.1876s	
29606/29850 (epoch 49.591), train_loss = 0.76059306, grad/param norm = 2.8279e-01, time/batch = 17.1174s	
29607/29850 (epoch 49.593), train_loss = 0.66927892, grad/param norm = 2.0846e-01, time/batch = 18.6213s	
29608/29850 (epoch 49.595), train_loss = 0.62806037, grad/param norm = 2.0282e-01, time/batch = 18.1408s	
29609/29850 (epoch 49.596), train_loss = 0.66041669, grad/param norm = 2.2013e-01, time/batch = 16.6272s	
29610/29850 (epoch 49.598), train_loss = 0.72206691, grad/param norm = 2.0774e-01, time/batch = 17.7856s	
29611/29850 (epoch 49.600), train_loss = 0.74537736, grad/param norm = 2.1583e-01, time/batch = 19.1283s	
29612/29850 (epoch 49.601), train_loss = 0.64716584, grad/param norm = 2.3974e-01, time/batch = 16.0436s	
29613/29850 (epoch 49.603), train_loss = 0.66779174, grad/param norm = 2.2112e-01, time/batch = 18.4513s	
29614/29850 (epoch 49.605), train_loss = 0.73507878, grad/param norm = 2.5742e-01, time/batch = 17.2121s	
29615/29850 (epoch 49.606), train_loss = 0.47840367, grad/param norm = 2.0509e-01, time/batch = 16.7910s	
29616/29850 (epoch 49.608), train_loss = 0.63432487, grad/param norm = 2.0888e-01, time/batch = 18.3669s	
29617/29850 (epoch 49.610), train_loss = 0.69290066, grad/param norm = 2.2599e-01, time/batch = 18.5215s	
29618/29850 (epoch 49.611), train_loss = 0.60822977, grad/param norm = 1.7972e-01, time/batch = 17.0735s	
29619/29850 (epoch 49.613), train_loss = 0.54200148, grad/param norm = 1.8308e-01, time/batch = 17.6125s	
29620/29850 (epoch 49.615), train_loss = 0.58524937, grad/param norm = 2.0337e-01, time/batch = 16.8810s	
29621/29850 (epoch 49.616), train_loss = 0.61135247, grad/param norm = 2.4802e-01, time/batch = 18.7212s	
29622/29850 (epoch 49.618), train_loss = 0.67814417, grad/param norm = 2.2743e-01, time/batch = 18.2775s	
29623/29850 (epoch 49.620), train_loss = 0.76768329, grad/param norm = 2.4871e-01, time/batch = 15.2815s	
29624/29850 (epoch 49.621), train_loss = 0.80977169, grad/param norm = 2.5068e-01, time/batch = 15.0372s	
29625/29850 (epoch 49.623), train_loss = 0.79872159, grad/param norm = 1.9736e-01, time/batch = 15.5302s	
29626/29850 (epoch 49.625), train_loss = 0.74021054, grad/param norm = 2.4206e-01, time/batch = 14.7732s	
29627/29850 (epoch 49.626), train_loss = 0.73108081, grad/param norm = 2.2814e-01, time/batch = 14.7062s	
29628/29850 (epoch 49.628), train_loss = 0.73044844, grad/param norm = 2.1995e-01, time/batch = 14.4686s	
29629/29850 (epoch 49.630), train_loss = 0.74544267, grad/param norm = 2.2630e-01, time/batch = 15.2872s	
29630/29850 (epoch 49.631), train_loss = 0.77760813, grad/param norm = 2.3937e-01, time/batch = 16.0382s	
29631/29850 (epoch 49.633), train_loss = 0.75375287, grad/param norm = 2.7173e-01, time/batch = 19.0376s	
29632/29850 (epoch 49.635), train_loss = 0.71068668, grad/param norm = 2.8967e-01, time/batch = 17.9510s	
29633/29850 (epoch 49.637), train_loss = 0.65163748, grad/param norm = 2.1536e-01, time/batch = 16.9716s	
29634/29850 (epoch 49.638), train_loss = 0.77635745, grad/param norm = 2.6625e-01, time/batch = 18.1233s	
29635/29850 (epoch 49.640), train_loss = 0.88409262, grad/param norm = 3.1663e-01, time/batch = 18.2970s	
29636/29850 (epoch 49.642), train_loss = 0.73792622, grad/param norm = 2.2995e-01, time/batch = 18.3923s	
29637/29850 (epoch 49.643), train_loss = 0.65693792, grad/param norm = 2.4469e-01, time/batch = 15.8125s	
29638/29850 (epoch 49.645), train_loss = 0.72152812, grad/param norm = 2.1761e-01, time/batch = 17.7962s	
29639/29850 (epoch 49.647), train_loss = 0.82344754, grad/param norm = 2.4343e-01, time/batch = 17.0330s	
29640/29850 (epoch 49.648), train_loss = 0.67438732, grad/param norm = 2.1337e-01, time/batch = 20.0899s	
29641/29850 (epoch 49.650), train_loss = 0.75599575, grad/param norm = 2.3499e-01, time/batch = 29.5788s	
29642/29850 (epoch 49.652), train_loss = 0.73951413, grad/param norm = 2.7393e-01, time/batch = 17.3937s	
29643/29850 (epoch 49.653), train_loss = 0.83268512, grad/param norm = 2.8886e-01, time/batch = 16.2896s	
29644/29850 (epoch 49.655), train_loss = 0.75873515, grad/param norm = 2.0085e-01, time/batch = 16.8878s	
29645/29850 (epoch 49.657), train_loss = 0.74179913, grad/param norm = 2.3195e-01, time/batch = 18.2234s	
29646/29850 (epoch 49.658), train_loss = 0.82705827, grad/param norm = 2.2239e-01, time/batch = 17.7936s	
29647/29850 (epoch 49.660), train_loss = 0.71059196, grad/param norm = 2.2730e-01, time/batch = 17.4704s	
29648/29850 (epoch 49.662), train_loss = 0.84023146, grad/param norm = 2.5468e-01, time/batch = 19.3721s	
29649/29850 (epoch 49.663), train_loss = 0.94396624, grad/param norm = 2.4519e-01, time/batch = 16.5133s	
29650/29850 (epoch 49.665), train_loss = 0.88895598, grad/param norm = 2.7161e-01, time/batch = 18.2046s	
29651/29850 (epoch 49.667), train_loss = 0.80362496, grad/param norm = 2.7466e-01, time/batch = 19.1283s	
29652/29850 (epoch 49.668), train_loss = 0.68653447, grad/param norm = 2.3927e-01, time/batch = 16.3086s	
29653/29850 (epoch 49.670), train_loss = 0.82244335, grad/param norm = 2.9792e-01, time/batch = 17.3851s	
29654/29850 (epoch 49.672), train_loss = 0.82511111, grad/param norm = 2.5616e-01, time/batch = 16.6225s	
29655/29850 (epoch 49.673), train_loss = 0.76519572, grad/param norm = 2.6458e-01, time/batch = 18.3776s	
29656/29850 (epoch 49.675), train_loss = 0.67618207, grad/param norm = 2.2729e-01, time/batch = 17.4629s	
29657/29850 (epoch 49.677), train_loss = 0.70868027, grad/param norm = 2.3459e-01, time/batch = 16.3130s	
29658/29850 (epoch 49.678), train_loss = 0.74693539, grad/param norm = 2.4338e-01, time/batch = 17.4609s	
29659/29850 (epoch 49.680), train_loss = 0.72147771, grad/param norm = 2.5745e-01, time/batch = 16.5449s	
29660/29850 (epoch 49.682), train_loss = 0.74767681, grad/param norm = 2.3662e-01, time/batch = 15.4273s	
29661/29850 (epoch 49.683), train_loss = 0.83297091, grad/param norm = 2.6618e-01, time/batch = 18.6162s	
29662/29850 (epoch 49.685), train_loss = 0.93892425, grad/param norm = 2.4642e-01, time/batch = 18.3473s	
29663/29850 (epoch 49.687), train_loss = 0.78878944, grad/param norm = 2.2833e-01, time/batch = 17.1287s	
29664/29850 (epoch 49.688), train_loss = 0.68173143, grad/param norm = 2.9996e-01, time/batch = 18.3752s	
29665/29850 (epoch 49.690), train_loss = 0.67940124, grad/param norm = 2.1270e-01, time/batch = 19.3774s	
29666/29850 (epoch 49.692), train_loss = 0.87061818, grad/param norm = 2.3632e-01, time/batch = 16.0514s	
29667/29850 (epoch 49.693), train_loss = 0.74823284, grad/param norm = 2.1455e-01, time/batch = 16.9520s	
29668/29850 (epoch 49.695), train_loss = 0.66853294, grad/param norm = 2.0325e-01, time/batch = 15.8790s	
29669/29850 (epoch 49.697), train_loss = 0.73688463, grad/param norm = 2.2401e-01, time/batch = 18.9589s	
29670/29850 (epoch 49.698), train_loss = 0.85581027, grad/param norm = 2.5574e-01, time/batch = 17.9519s	
29671/29850 (epoch 49.700), train_loss = 0.80879560, grad/param norm = 3.6093e-01, time/batch = 19.0438s	
29672/29850 (epoch 49.702), train_loss = 0.78322302, grad/param norm = 2.6586e-01, time/batch = 17.5506s	
29673/29850 (epoch 49.704), train_loss = 0.64437712, grad/param norm = 2.1281e-01, time/batch = 17.0473s	
29674/29850 (epoch 49.705), train_loss = 0.75786057, grad/param norm = 2.5778e-01, time/batch = 15.8894s	
29675/29850 (epoch 49.707), train_loss = 0.68277282, grad/param norm = 2.4500e-01, time/batch = 16.6480s	
29676/29850 (epoch 49.709), train_loss = 0.73971251, grad/param norm = 3.0086e-01, time/batch = 17.2992s	
29677/29850 (epoch 49.710), train_loss = 0.68555165, grad/param norm = 2.2837e-01, time/batch = 15.7922s	
29678/29850 (epoch 49.712), train_loss = 0.79175237, grad/param norm = 2.1087e-01, time/batch = 18.5307s	
29679/29850 (epoch 49.714), train_loss = 0.83291857, grad/param norm = 2.7639e-01, time/batch = 17.2798s	
29680/29850 (epoch 49.715), train_loss = 0.79422243, grad/param norm = 2.6779e-01, time/batch = 17.5558s	
29681/29850 (epoch 49.717), train_loss = 0.56551017, grad/param norm = 2.0373e-01, time/batch = 18.3832s	
29682/29850 (epoch 49.719), train_loss = 0.73476371, grad/param norm = 2.4582e-01, time/batch = 18.8024s	
29683/29850 (epoch 49.720), train_loss = 0.73426780, grad/param norm = 2.1022e-01, time/batch = 16.2921s	
29684/29850 (epoch 49.722), train_loss = 0.67631664, grad/param norm = 1.7604e-01, time/batch = 17.0455s	
29685/29850 (epoch 49.724), train_loss = 0.76110150, grad/param norm = 2.6953e-01, time/batch = 16.8098s	
29686/29850 (epoch 49.725), train_loss = 0.62333578, grad/param norm = 1.9324e-01, time/batch = 17.5472s	
29687/29850 (epoch 49.727), train_loss = 0.60332719, grad/param norm = 2.2152e-01, time/batch = 17.4415s	
29688/29850 (epoch 49.729), train_loss = 0.61380022, grad/param norm = 1.7658e-01, time/batch = 17.4491s	
29689/29850 (epoch 49.730), train_loss = 0.59041948, grad/param norm = 2.2762e-01, time/batch = 18.0567s	
29690/29850 (epoch 49.732), train_loss = 0.80422397, grad/param norm = 2.1639e-01, time/batch = 19.2936s	
29691/29850 (epoch 49.734), train_loss = 0.90019709, grad/param norm = 2.5574e-01, time/batch = 6.5642s	
29692/29850 (epoch 49.735), train_loss = 0.68326489, grad/param norm = 2.0457e-01, time/batch = 0.6572s	
29693/29850 (epoch 49.737), train_loss = 0.63653198, grad/param norm = 1.8327e-01, time/batch = 0.6548s	
29694/29850 (epoch 49.739), train_loss = 0.56194959, grad/param norm = 2.4095e-01, time/batch = 0.6715s	
29695/29850 (epoch 49.740), train_loss = 0.58887599, grad/param norm = 2.0972e-01, time/batch = 0.6676s	
29696/29850 (epoch 49.742), train_loss = 0.52367260, grad/param norm = 1.7165e-01, time/batch = 0.6741s	
29697/29850 (epoch 49.744), train_loss = 0.66625824, grad/param norm = 2.2337e-01, time/batch = 0.6751s	
29698/29850 (epoch 49.745), train_loss = 0.72085715, grad/param norm = 3.2757e-01, time/batch = 0.7204s	
29699/29850 (epoch 49.747), train_loss = 0.72767204, grad/param norm = 2.2008e-01, time/batch = 0.9971s	
29700/29850 (epoch 49.749), train_loss = 0.60853897, grad/param norm = 2.1841e-01, time/batch = 0.9930s	
29701/29850 (epoch 49.750), train_loss = 0.54982270, grad/param norm = 2.0323e-01, time/batch = 0.9689s	
29702/29850 (epoch 49.752), train_loss = 0.48295807, grad/param norm = 1.9482e-01, time/batch = 0.9677s	
29703/29850 (epoch 49.754), train_loss = 0.55393161, grad/param norm = 2.2564e-01, time/batch = 1.0373s	
29704/29850 (epoch 49.755), train_loss = 0.54640652, grad/param norm = 2.1589e-01, time/batch = 1.8298s	
29705/29850 (epoch 49.757), train_loss = 0.60523928, grad/param norm = 1.9619e-01, time/batch = 1.8220s	
29706/29850 (epoch 49.759), train_loss = 0.62526833, grad/param norm = 2.2754e-01, time/batch = 6.9196s	
29707/29850 (epoch 49.760), train_loss = 0.65324218, grad/param norm = 2.2114e-01, time/batch = 17.4703s	
29708/29850 (epoch 49.762), train_loss = 0.59905868, grad/param norm = 2.2296e-01, time/batch = 14.8237s	
29709/29850 (epoch 49.764), train_loss = 0.52532964, grad/param norm = 2.4737e-01, time/batch = 17.3397s	
29710/29850 (epoch 49.765), train_loss = 0.65547580, grad/param norm = 2.2751e-01, time/batch = 18.7917s	
29711/29850 (epoch 49.767), train_loss = 0.67554374, grad/param norm = 2.3771e-01, time/batch = 19.2919s	
29712/29850 (epoch 49.769), train_loss = 0.71438010, grad/param norm = 2.1268e-01, time/batch = 17.1319s	
29713/29850 (epoch 49.771), train_loss = 0.69681771, grad/param norm = 2.2499e-01, time/batch = 17.6453s	
29714/29850 (epoch 49.772), train_loss = 0.69063825, grad/param norm = 2.5419e-01, time/batch = 17.4044s	
29715/29850 (epoch 49.774), train_loss = 0.64220311, grad/param norm = 2.2492e-01, time/batch = 16.4679s	
29716/29850 (epoch 49.776), train_loss = 0.66742469, grad/param norm = 2.0836e-01, time/batch = 16.6427s	
29717/29850 (epoch 49.777), train_loss = 0.78256059, grad/param norm = 2.4742e-01, time/batch = 18.1330s	
29718/29850 (epoch 49.779), train_loss = 0.61652697, grad/param norm = 2.3114e-01, time/batch = 17.9785s	
29719/29850 (epoch 49.781), train_loss = 0.73463909, grad/param norm = 2.4789e-01, time/batch = 16.2910s	
29720/29850 (epoch 49.782), train_loss = 0.73354934, grad/param norm = 2.4730e-01, time/batch = 19.3029s	
29721/29850 (epoch 49.784), train_loss = 0.59140739, grad/param norm = 3.9782e-01, time/batch = 18.8778s	
29722/29850 (epoch 49.786), train_loss = 0.64379419, grad/param norm = 2.5740e-01, time/batch = 16.4512s	
29723/29850 (epoch 49.787), train_loss = 0.54786003, grad/param norm = 2.4139e-01, time/batch = 15.1994s	
29724/29850 (epoch 49.789), train_loss = 0.56936088, grad/param norm = 2.0360e-01, time/batch = 15.8229s	
29725/29850 (epoch 49.791), train_loss = 0.62156288, grad/param norm = 3.8336e-01, time/batch = 17.6480s	
29726/29850 (epoch 49.792), train_loss = 0.76305593, grad/param norm = 2.3546e-01, time/batch = 16.0561s	
29727/29850 (epoch 49.794), train_loss = 0.68208625, grad/param norm = 2.0779e-01, time/batch = 20.2850s	
29728/29850 (epoch 49.796), train_loss = 0.61309185, grad/param norm = 2.3353e-01, time/batch = 18.4600s	
29729/29850 (epoch 49.797), train_loss = 0.52201161, grad/param norm = 1.9788e-01, time/batch = 17.0495s	
29730/29850 (epoch 49.799), train_loss = 0.56696741, grad/param norm = 1.8646e-01, time/batch = 19.1995s	
29731/29850 (epoch 49.801), train_loss = 0.57486234, grad/param norm = 1.9027e-01, time/batch = 17.2030s	
29732/29850 (epoch 49.802), train_loss = 0.56383820, grad/param norm = 2.4584e-01, time/batch = 17.1953s	
29733/29850 (epoch 49.804), train_loss = 0.59656187, grad/param norm = 1.7865e-01, time/batch = 18.2096s	
29734/29850 (epoch 49.806), train_loss = 0.51823329, grad/param norm = 1.7653e-01, time/batch = 19.7090s	
29735/29850 (epoch 49.807), train_loss = 0.59804254, grad/param norm = 2.0705e-01, time/batch = 16.1239s	
29736/29850 (epoch 49.809), train_loss = 0.58083465, grad/param norm = 2.5200e-01, time/batch = 17.3671s	
29737/29850 (epoch 49.811), train_loss = 0.75879166, grad/param norm = 2.4353e-01, time/batch = 16.6081s	
29738/29850 (epoch 49.812), train_loss = 0.71736582, grad/param norm = 2.6250e-01, time/batch = 18.6201s	
29739/29850 (epoch 49.814), train_loss = 0.74669307, grad/param norm = 2.6206e-01, time/batch = 17.8668s	
29740/29850 (epoch 49.816), train_loss = 0.82792973, grad/param norm = 2.3500e-01, time/batch = 17.5439s	
29741/29850 (epoch 49.817), train_loss = 0.70867289, grad/param norm = 3.2040e-01, time/batch = 18.2151s	
29742/29850 (epoch 49.819), train_loss = 0.57005378, grad/param norm = 2.8799e-01, time/batch = 18.2826s	
29743/29850 (epoch 49.821), train_loss = 0.78043093, grad/param norm = 2.9503e-01, time/batch = 17.2003s	
29744/29850 (epoch 49.822), train_loss = 0.80408876, grad/param norm = 2.4556e-01, time/batch = 19.3743s	
29745/29850 (epoch 49.824), train_loss = 0.69296811, grad/param norm = 2.3175e-01, time/batch = 18.6374s	
29746/29850 (epoch 49.826), train_loss = 0.61516158, grad/param norm = 2.3653e-01, time/batch = 18.7763s	
29747/29850 (epoch 49.827), train_loss = 0.54813411, grad/param norm = 2.5463e-01, time/batch = 18.2014s	
29748/29850 (epoch 49.829), train_loss = 0.71362620, grad/param norm = 2.7402e-01, time/batch = 17.0537s	
29749/29850 (epoch 49.831), train_loss = 0.80362023, grad/param norm = 2.8552e-01, time/batch = 16.5297s	
29750/29850 (epoch 49.832), train_loss = 0.69584103, grad/param norm = 2.2329e-01, time/batch = 16.3886s	
29751/29850 (epoch 49.834), train_loss = 0.54359131, grad/param norm = 2.0390e-01, time/batch = 18.8778s	
29752/29850 (epoch 49.836), train_loss = 0.53319765, grad/param norm = 2.0892e-01, time/batch = 17.3701s	
29753/29850 (epoch 49.838), train_loss = 0.64332632, grad/param norm = 2.3585e-01, time/batch = 18.4577s	
29754/29850 (epoch 49.839), train_loss = 0.52286683, grad/param norm = 1.8927e-01, time/batch = 17.8734s	
29755/29850 (epoch 49.841), train_loss = 0.62021422, grad/param norm = 1.9440e-01, time/batch = 15.0455s	
29756/29850 (epoch 49.843), train_loss = 0.54471090, grad/param norm = 2.0515e-01, time/batch = 15.4772s	
29757/29850 (epoch 49.844), train_loss = 0.58010627, grad/param norm = 2.3065e-01, time/batch = 18.5319s	
29758/29850 (epoch 49.846), train_loss = 0.66012407, grad/param norm = 2.3641e-01, time/batch = 16.7225s	
29759/29850 (epoch 49.848), train_loss = 0.73152449, grad/param norm = 2.6557e-01, time/batch = 16.9523s	
29760/29850 (epoch 49.849), train_loss = 0.65858387, grad/param norm = 2.2396e-01, time/batch = 17.8786s	
29761/29850 (epoch 49.851), train_loss = 0.84019561, grad/param norm = 2.2852e-01, time/batch = 17.5237s	
29762/29850 (epoch 49.853), train_loss = 0.65640090, grad/param norm = 3.1198e-01, time/batch = 18.6277s	
29763/29850 (epoch 49.854), train_loss = 0.82324651, grad/param norm = 2.5539e-01, time/batch = 18.2081s	
29764/29850 (epoch 49.856), train_loss = 0.80243127, grad/param norm = 2.8681e-01, time/batch = 18.0321s	
29765/29850 (epoch 49.858), train_loss = 0.72609236, grad/param norm = 3.0265e-01, time/batch = 18.8720s	
29766/29850 (epoch 49.859), train_loss = 0.61919653, grad/param norm = 2.5414e-01, time/batch = 17.1181s	
29767/29850 (epoch 49.861), train_loss = 0.76323161, grad/param norm = 2.5325e-01, time/batch = 15.2223s	
29768/29850 (epoch 49.863), train_loss = 0.80995207, grad/param norm = 2.9478e-01, time/batch = 18.5419s	
29769/29850 (epoch 49.864), train_loss = 0.77558960, grad/param norm = 2.5485e-01, time/batch = 18.3764s	
29770/29850 (epoch 49.866), train_loss = 0.74946613, grad/param norm = 3.5526e-01, time/batch = 19.2905s	
29771/29850 (epoch 49.868), train_loss = 0.86894007, grad/param norm = 2.6965e-01, time/batch = 18.4673s	
29772/29850 (epoch 49.869), train_loss = 0.80497115, grad/param norm = 2.8859e-01, time/batch = 18.6255s	
29773/29850 (epoch 49.871), train_loss = 0.79848399, grad/param norm = 2.6426e-01, time/batch = 17.7810s	
29774/29850 (epoch 49.873), train_loss = 0.75173823, grad/param norm = 2.6590e-01, time/batch = 18.7987s	
29775/29850 (epoch 49.874), train_loss = 0.74346726, grad/param norm = 2.2523e-01, time/batch = 16.1130s	
29776/29850 (epoch 49.876), train_loss = 0.74598903, grad/param norm = 3.4755e-01, time/batch = 16.5420s	
29777/29850 (epoch 49.878), train_loss = 0.73026626, grad/param norm = 2.1692e-01, time/batch = 18.6220s	
29778/29850 (epoch 49.879), train_loss = 0.78395156, grad/param norm = 2.3062e-01, time/batch = 17.9634s	
29779/29850 (epoch 49.881), train_loss = 0.79367434, grad/param norm = 2.6096e-01, time/batch = 17.4572s	
29780/29850 (epoch 49.883), train_loss = 0.73964328, grad/param norm = 2.2923e-01, time/batch = 16.8720s	
29781/29850 (epoch 49.884), train_loss = 0.62795141, grad/param norm = 2.1680e-01, time/batch = 18.1317s	
29782/29850 (epoch 49.886), train_loss = 0.78103534, grad/param norm = 2.5820e-01, time/batch = 17.4563s	
29783/29850 (epoch 49.888), train_loss = 0.73656499, grad/param norm = 2.4285e-01, time/batch = 16.9335s	
29784/29850 (epoch 49.889), train_loss = 0.69166996, grad/param norm = 2.0714e-01, time/batch = 18.7091s	
29785/29850 (epoch 49.891), train_loss = 0.65217689, grad/param norm = 2.2409e-01, time/batch = 17.0212s	
29786/29850 (epoch 49.893), train_loss = 0.70950966, grad/param norm = 2.4704e-01, time/batch = 17.3748s	
29787/29850 (epoch 49.894), train_loss = 0.69876647, grad/param norm = 2.6316e-01, time/batch = 18.6926s	
29788/29850 (epoch 49.896), train_loss = 0.74904568, grad/param norm = 2.9129e-01, time/batch = 17.3885s	
29789/29850 (epoch 49.898), train_loss = 0.87471982, grad/param norm = 2.7304e-01, time/batch = 17.8071s	
29790/29850 (epoch 49.899), train_loss = 0.64881913, grad/param norm = 2.9425e-01, time/batch = 16.2141s	
29791/29850 (epoch 49.901), train_loss = 0.92723231, grad/param norm = 3.6254e-01, time/batch = 17.7254s	
29792/29850 (epoch 49.903), train_loss = 0.79257017, grad/param norm = 3.6501e-01, time/batch = 16.3013s	
29793/29850 (epoch 49.905), train_loss = 0.96110719, grad/param norm = 2.8128e-01, time/batch = 17.7962s	
29794/29850 (epoch 49.906), train_loss = 0.73526433, grad/param norm = 3.1636e-01, time/batch = 18.6441s	
29795/29850 (epoch 49.908), train_loss = 0.89195993, grad/param norm = 3.0991e-01, time/batch = 16.3471s	
29796/29850 (epoch 49.910), train_loss = 0.80812408, grad/param norm = 2.2761e-01, time/batch = 18.6200s	
29797/29850 (epoch 49.911), train_loss = 0.93965007, grad/param norm = 2.6425e-01, time/batch = 19.6227s	
29798/29850 (epoch 49.913), train_loss = 0.87437207, grad/param norm = 2.7339e-01, time/batch = 17.8868s	
29799/29850 (epoch 49.915), train_loss = 0.87862541, grad/param norm = 2.5186e-01, time/batch = 16.0206s	
29800/29850 (epoch 49.916), train_loss = 0.84379617, grad/param norm = 2.6653e-01, time/batch = 17.6075s	
29801/29850 (epoch 49.918), train_loss = 0.68108868, grad/param norm = 2.2910e-01, time/batch = 17.3034s	
29802/29850 (epoch 49.920), train_loss = 0.86725929, grad/param norm = 2.5037e-01, time/batch = 18.6299s	
29803/29850 (epoch 49.921), train_loss = 0.71093754, grad/param norm = 2.3376e-01, time/batch = 16.9501s	
29804/29850 (epoch 49.923), train_loss = 0.75250041, grad/param norm = 2.3566e-01, time/batch = 16.0370s	
29805/29850 (epoch 49.925), train_loss = 0.88608450, grad/param norm = 2.7812e-01, time/batch = 17.6299s	
29806/29850 (epoch 49.926), train_loss = 0.89723011, grad/param norm = 2.8983e-01, time/batch = 18.1387s	
29807/29850 (epoch 49.928), train_loss = 0.76596017, grad/param norm = 2.4803e-01, time/batch = 17.9486s	
29808/29850 (epoch 49.930), train_loss = 0.76311997, grad/param norm = 2.2720e-01, time/batch = 15.9524s	
29809/29850 (epoch 49.931), train_loss = 0.75079821, grad/param norm = 2.3059e-01, time/batch = 17.8001s	
29810/29850 (epoch 49.933), train_loss = 0.88461758, grad/param norm = 3.4837e-01, time/batch = 17.4546s	
29811/29850 (epoch 49.935), train_loss = 0.79837405, grad/param norm = 2.6674e-01, time/batch = 17.0598s	
29812/29850 (epoch 49.936), train_loss = 0.81717462, grad/param norm = 2.9057e-01, time/batch = 20.1217s	
29813/29850 (epoch 49.938), train_loss = 0.68903794, grad/param norm = 2.3440e-01, time/batch = 17.4505s	
29814/29850 (epoch 49.940), train_loss = 0.69211415, grad/param norm = 2.3198e-01, time/batch = 18.4450s	
29815/29850 (epoch 49.941), train_loss = 0.63972444, grad/param norm = 2.5934e-01, time/batch = 19.3850s	
29816/29850 (epoch 49.943), train_loss = 0.71146023, grad/param norm = 2.4763e-01, time/batch = 16.6285s	
29817/29850 (epoch 49.945), train_loss = 0.65106681, grad/param norm = 2.5027e-01, time/batch = 17.2520s	
29818/29850 (epoch 49.946), train_loss = 0.64077621, grad/param norm = 2.0893e-01, time/batch = 19.2058s	
29819/29850 (epoch 49.948), train_loss = 0.75917183, grad/param norm = 2.4504e-01, time/batch = 18.9610s	
29820/29850 (epoch 49.950), train_loss = 0.71182437, grad/param norm = 1.7607e-01, time/batch = 15.7891s	
29821/29850 (epoch 49.951), train_loss = 0.60980374, grad/param norm = 2.0667e-01, time/batch = 19.4709s	
29822/29850 (epoch 49.953), train_loss = 0.69477621, grad/param norm = 2.4815e-01, time/batch = 16.3968s	
29823/29850 (epoch 49.955), train_loss = 0.62748886, grad/param norm = 2.0491e-01, time/batch = 16.2917s	
29824/29850 (epoch 49.956), train_loss = 0.62041210, grad/param norm = 2.1122e-01, time/batch = 17.2890s	
29825/29850 (epoch 49.958), train_loss = 0.60193358, grad/param norm = 2.5982e-01, time/batch = 16.3590s	
29826/29850 (epoch 49.960), train_loss = 0.81887391, grad/param norm = 2.7360e-01, time/batch = 17.1423s	
29827/29850 (epoch 49.961), train_loss = 0.58840536, grad/param norm = 2.2092e-01, time/batch = 15.6325s	
29828/29850 (epoch 49.963), train_loss = 0.56810207, grad/param norm = 2.1212e-01, time/batch = 17.8931s	
29829/29850 (epoch 49.965), train_loss = 0.64199396, grad/param norm = 2.3369e-01, time/batch = 19.5404s	
29830/29850 (epoch 49.966), train_loss = 0.63837299, grad/param norm = 2.8466e-01, time/batch = 17.0363s	
29831/29850 (epoch 49.968), train_loss = 0.65598029, grad/param norm = 3.1650e-01, time/batch = 16.5300s	
29832/29850 (epoch 49.970), train_loss = 0.66550912, grad/param norm = 2.3369e-01, time/batch = 18.4612s	
29833/29850 (epoch 49.972), train_loss = 0.66966364, grad/param norm = 2.1305e-01, time/batch = 16.9678s	
29834/29850 (epoch 49.973), train_loss = 0.63835363, grad/param norm = 2.2992e-01, time/batch = 17.8492s	
29835/29850 (epoch 49.975), train_loss = 0.58273957, grad/param norm = 2.3405e-01, time/batch = 18.7243s	
29836/29850 (epoch 49.977), train_loss = 0.66005406, grad/param norm = 1.9544e-01, time/batch = 19.6313s	
29837/29850 (epoch 49.978), train_loss = 0.56578598, grad/param norm = 1.8638e-01, time/batch = 17.3743s	
29838/29850 (epoch 49.980), train_loss = 0.64828430, grad/param norm = 2.2689e-01, time/batch = 18.6211s	
29839/29850 (epoch 49.982), train_loss = 0.61180111, grad/param norm = 2.4692e-01, time/batch = 19.4516s	
29840/29850 (epoch 49.983), train_loss = 0.65478189, grad/param norm = 1.9368e-01, time/batch = 17.4575s	
29841/29850 (epoch 49.985), train_loss = 0.76368934, grad/param norm = 2.3363e-01, time/batch = 18.8767s	
29842/29850 (epoch 49.987), train_loss = 0.74031009, grad/param norm = 2.5997e-01, time/batch = 16.4610s	
29843/29850 (epoch 49.988), train_loss = 0.69310135, grad/param norm = 1.9817e-01, time/batch = 18.7016s	
29844/29850 (epoch 49.990), train_loss = 0.75907272, grad/param norm = 2.2732e-01, time/batch = 17.7879s	
29845/29850 (epoch 49.992), train_loss = 0.73078517, grad/param norm = 2.1868e-01, time/batch = 19.8748s	
29846/29850 (epoch 49.993), train_loss = 0.74176418, grad/param norm = 2.5462e-01, time/batch = 17.4555s	
29847/29850 (epoch 49.995), train_loss = 0.72229349, grad/param norm = 2.4798e-01, time/batch = 15.6247s	
29848/29850 (epoch 49.997), train_loss = 0.76176763, grad/param norm = 2.1373e-01, time/batch = 17.5632s	
29849/29850 (epoch 49.998), train_loss = 0.76470262, grad/param norm = 2.3432e-01, time/batch = 18.2265s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_wiredscience_epoch50.00_1.9425.t7	
29850/29850 (epoch 50.000), train_loss = 0.59974322, grad/param norm = 2.1774e-01, time/batch = 16.4344s	

real	6870m23.863s
user	6821m18.160s
sys	7m3.584s
