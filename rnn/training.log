tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 570, val: 30, test: 0	
vocab size: 144	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 290960	
cloning rnn	
cloning criterion	
1/28500 (epoch 0.002), train_loss = 4.97659627, grad/param norm = 5.6992e-01, time/batch = 0.7243s	
2/28500 (epoch 0.004), train_loss = 4.73031704, grad/param norm = 1.4875e+00, time/batch = 0.6859s	
3/28500 (epoch 0.005), train_loss = 3.85942993, grad/param norm = 1.6025e+00, time/batch = 0.6829s	
4/28500 (epoch 0.007), train_loss = 3.39351314, grad/param norm = 9.9938e-01, time/batch = 0.6815s	
5/28500 (epoch 0.009), train_loss = 3.51547386, grad/param norm = 7.1065e-01, time/batch = 0.6816s	
6/28500 (epoch 0.011), train_loss = 3.69060927, grad/param norm = 8.5438e-01, time/batch = 0.6782s	
7/28500 (epoch 0.012), train_loss = 3.54524334, grad/param norm = 6.6374e-01, time/batch = 0.6753s	
8/28500 (epoch 0.014), train_loss = 3.61503980, grad/param norm = 8.0610e-01, time/batch = 0.6772s	
9/28500 (epoch 0.016), train_loss = 3.61040502, grad/param norm = 6.8455e-01, time/batch = 0.6768s	
10/28500 (epoch 0.018), train_loss = 3.53022901, grad/param norm = 8.3092e-01, time/batch = 0.6751s	
11/28500 (epoch 0.019), train_loss = 3.53975355, grad/param norm = 7.1217e-01, time/batch = 0.6751s	
12/28500 (epoch 0.021), train_loss = 3.35527989, grad/param norm = 6.7907e-01, time/batch = 0.6751s	
13/28500 (epoch 0.023), train_loss = 3.43773733, grad/param norm = 5.8377e-01, time/batch = 0.6760s	
14/28500 (epoch 0.025), train_loss = 3.30774363, grad/param norm = 6.7490e-01, time/batch = 0.6744s	
15/28500 (epoch 0.026), train_loss = 3.49532604, grad/param norm = 7.6345e-01, time/batch = 0.6745s	
16/28500 (epoch 0.028), train_loss = 3.41780409, grad/param norm = 7.3376e-01, time/batch = 0.6749s	
17/28500 (epoch 0.030), train_loss = 3.33483958, grad/param norm = 9.3560e-01, time/batch = 0.6748s	
18/28500 (epoch 0.032), train_loss = 3.31170722, grad/param norm = 5.9258e-01, time/batch = 0.6745s	
19/28500 (epoch 0.033), train_loss = 3.62498398, grad/param norm = 9.4371e-01, time/batch = 0.6747s	
20/28500 (epoch 0.035), train_loss = 3.63471495, grad/param norm = 8.1136e-01, time/batch = 0.6767s	
21/28500 (epoch 0.037), train_loss = 3.47687610, grad/param norm = 7.1475e-01, time/batch = 0.6765s	
22/28500 (epoch 0.039), train_loss = 3.45486239, grad/param norm = 5.5371e-01, time/batch = 0.6769s	
23/28500 (epoch 0.040), train_loss = 3.43728679, grad/param norm = 5.4841e-01, time/batch = 0.6759s	
24/28500 (epoch 0.042), train_loss = 3.48444686, grad/param norm = 6.7819e-01, time/batch = 0.6801s	
25/28500 (epoch 0.044), train_loss = 3.52724017, grad/param norm = 8.0759e-01, time/batch = 0.6925s	
26/28500 (epoch 0.046), train_loss = 3.36108430, grad/param norm = 5.7876e-01, time/batch = 0.6830s	
27/28500 (epoch 0.047), train_loss = 3.42281461, grad/param norm = 6.4730e-01, time/batch = 0.6816s	
28/28500 (epoch 0.049), train_loss = 3.46918898, grad/param norm = 5.9253e-01, time/batch = 0.6802s	
29/28500 (epoch 0.051), train_loss = 3.39295855, grad/param norm = 5.9747e-01, time/batch = 0.6877s	
30/28500 (epoch 0.053), train_loss = 3.43570854, grad/param norm = 6.4981e-01, time/batch = 0.6760s	
31/28500 (epoch 0.054), train_loss = 3.28906669, grad/param norm = 6.9690e-01, time/batch = 0.6790s	
32/28500 (epoch 0.056), train_loss = 3.43806397, grad/param norm = 6.9348e-01, time/batch = 0.6779s	
33/28500 (epoch 0.058), train_loss = 3.40625593, grad/param norm = 5.2224e-01, time/batch = 0.6764s	
34/28500 (epoch 0.060), train_loss = 3.31085159, grad/param norm = 7.6409e-01, time/batch = 0.6743s	
35/28500 (epoch 0.061), train_loss = 3.46855626, grad/param norm = 7.5748e-01, time/batch = 0.6748s	
36/28500 (epoch 0.063), train_loss = 3.41477321, grad/param norm = 4.7219e-01, time/batch = 0.6747s	
37/28500 (epoch 0.065), train_loss = 3.53812493, grad/param norm = 5.6581e-01, time/batch = 0.6751s	
38/28500 (epoch 0.067), train_loss = 3.30436374, grad/param norm = 7.2330e-01, time/batch = 0.6747s	
39/28500 (epoch 0.068), train_loss = 3.38066403, grad/param norm = 6.7952e-01, time/batch = 0.6744s	
40/28500 (epoch 0.070), train_loss = 3.37570453, grad/param norm = 5.8712e-01, time/batch = 0.6745s	
41/28500 (epoch 0.072), train_loss = 3.32348756, grad/param norm = 6.4873e-01, time/batch = 0.6784s	
42/28500 (epoch 0.074), train_loss = 3.59900373, grad/param norm = 9.2456e-01, time/batch = 0.6780s	
43/28500 (epoch 0.075), train_loss = 3.46385792, grad/param norm = 5.7312e-01, time/batch = 0.6757s	
44/28500 (epoch 0.077), train_loss = 3.30054279, grad/param norm = 6.5499e-01, time/batch = 0.6744s	
45/28500 (epoch 0.079), train_loss = 3.34873514, grad/param norm = 7.3685e-01, time/batch = 0.6743s	
46/28500 (epoch 0.081), train_loss = 3.30133065, grad/param norm = 6.1288e-01, time/batch = 0.6741s	
47/28500 (epoch 0.082), train_loss = 3.37626951, grad/param norm = 5.7592e-01, time/batch = 0.6739s	
48/28500 (epoch 0.084), train_loss = 3.36080964, grad/param norm = 5.0673e-01, time/batch = 0.6738s	
49/28500 (epoch 0.086), train_loss = 3.31115326, grad/param norm = 7.3302e-01, time/batch = 0.6742s	
50/28500 (epoch 0.088), train_loss = 3.28749552, grad/param norm = 6.2968e-01, time/batch = 0.6742s	
51/28500 (epoch 0.089), train_loss = 3.49497609, grad/param norm = 6.4878e-01, time/batch = 0.6801s	
52/28500 (epoch 0.091), train_loss = 3.34875290, grad/param norm = 9.1288e-01, time/batch = 0.6751s	
53/28500 (epoch 0.093), train_loss = 3.30200556, grad/param norm = 7.1274e-01, time/batch = 0.6743s	
54/28500 (epoch 0.095), train_loss = 3.38540824, grad/param norm = 5.8519e-01, time/batch = 0.6763s	
55/28500 (epoch 0.096), train_loss = 3.47000151, grad/param norm = 6.5213e-01, time/batch = 0.6755s	
56/28500 (epoch 0.098), train_loss = 3.48047260, grad/param norm = 6.5812e-01, time/batch = 0.6781s	
57/28500 (epoch 0.100), train_loss = 3.42424132, grad/param norm = 5.9109e-01, time/batch = 0.6778s	
58/28500 (epoch 0.102), train_loss = 3.39742979, grad/param norm = 4.8906e-01, time/batch = 0.6806s	
59/28500 (epoch 0.104), train_loss = 3.33609594, grad/param norm = 5.0560e-01, time/batch = 0.6797s	
60/28500 (epoch 0.105), train_loss = 3.21929523, grad/param norm = 7.9650e-01, time/batch = 0.6792s	
61/28500 (epoch 0.107), train_loss = 3.40651120, grad/param norm = 5.9553e-01, time/batch = 0.6819s	
62/28500 (epoch 0.109), train_loss = 3.32650875, grad/param norm = 6.7482e-01, time/batch = 0.6801s	
63/28500 (epoch 0.111), train_loss = 3.39104237, grad/param norm = 6.0046e-01, time/batch = 0.6784s	
64/28500 (epoch 0.112), train_loss = 3.36905075, grad/param norm = 6.1765e-01, time/batch = 0.6768s	
65/28500 (epoch 0.114), train_loss = 3.31246534, grad/param norm = 4.5326e-01, time/batch = 0.6742s	
66/28500 (epoch 0.116), train_loss = 3.24534331, grad/param norm = 6.9609e-01, time/batch = 0.6745s	
67/28500 (epoch 0.118), train_loss = 3.30056000, grad/param norm = 5.5344e-01, time/batch = 0.6748s	
68/28500 (epoch 0.119), train_loss = 3.48006190, grad/param norm = 5.4310e-01, time/batch = 0.6758s	
69/28500 (epoch 0.121), train_loss = 3.42256268, grad/param norm = 5.6741e-01, time/batch = 0.6753s	
70/28500 (epoch 0.123), train_loss = 3.26833660, grad/param norm = 6.6734e-01, time/batch = 0.6752s	
71/28500 (epoch 0.125), train_loss = 3.38915806, grad/param norm = 6.3240e-01, time/batch = 0.6813s	
72/28500 (epoch 0.126), train_loss = 3.42607712, grad/param norm = 5.9277e-01, time/batch = 0.6867s	
73/28500 (epoch 0.128), train_loss = 3.58239584, grad/param norm = 7.1977e-01, time/batch = 0.6806s	
74/28500 (epoch 0.130), train_loss = 3.55642978, grad/param norm = 5.2668e-01, time/batch = 0.6759s	
75/28500 (epoch 0.132), train_loss = 3.49208728, grad/param norm = 5.3064e-01, time/batch = 0.6754s	
76/28500 (epoch 0.133), train_loss = 3.48762566, grad/param norm = 5.1013e-01, time/batch = 0.6753s	
77/28500 (epoch 0.135), train_loss = 3.34455989, grad/param norm = 5.7594e-01, time/batch = 0.6754s	
78/28500 (epoch 0.137), train_loss = 3.60153400, grad/param norm = 7.8282e-01, time/batch = 0.6769s	
79/28500 (epoch 0.139), train_loss = 3.37714640, grad/param norm = 5.8459e-01, time/batch = 0.6794s	
80/28500 (epoch 0.140), train_loss = 3.30301688, grad/param norm = 4.9517e-01, time/batch = 0.6795s	
81/28500 (epoch 0.142), train_loss = 3.45170090, grad/param norm = 6.7271e-01, time/batch = 0.6854s	
82/28500 (epoch 0.144), train_loss = 3.38427369, grad/param norm = 4.8423e-01, time/batch = 0.6815s	
83/28500 (epoch 0.146), train_loss = 3.25973715, grad/param norm = 5.3472e-01, time/batch = 0.6793s	
84/28500 (epoch 0.147), train_loss = 3.43705443, grad/param norm = 4.9601e-01, time/batch = 0.6788s	
85/28500 (epoch 0.149), train_loss = 3.32463081, grad/param norm = 5.8317e-01, time/batch = 0.6933s	
86/28500 (epoch 0.151), train_loss = 3.49926628, grad/param norm = 4.5149e-01, time/batch = 0.6906s	
87/28500 (epoch 0.153), train_loss = 3.46488970, grad/param norm = 5.9412e-01, time/batch = 0.6800s	
88/28500 (epoch 0.154), train_loss = 3.43647844, grad/param norm = 5.5796e-01, time/batch = 0.6855s	
89/28500 (epoch 0.156), train_loss = 3.39603794, grad/param norm = 4.7995e-01, time/batch = 0.6830s	
90/28500 (epoch 0.158), train_loss = 3.41503915, grad/param norm = 4.8536e-01, time/batch = 0.6780s	
91/28500 (epoch 0.160), train_loss = 3.34376785, grad/param norm = 4.6218e-01, time/batch = 0.6846s	
92/28500 (epoch 0.161), train_loss = 3.36217672, grad/param norm = 6.3012e-01, time/batch = 0.6819s	
93/28500 (epoch 0.163), train_loss = 3.45783243, grad/param norm = 7.1481e-01, time/batch = 0.6855s	
94/28500 (epoch 0.165), train_loss = 3.32088403, grad/param norm = 5.3500e-01, time/batch = 0.6799s	
95/28500 (epoch 0.167), train_loss = 3.29705046, grad/param norm = 5.5511e-01, time/batch = 0.6794s	
96/28500 (epoch 0.168), train_loss = 3.34390107, grad/param norm = 5.8490e-01, time/batch = 0.6792s	
97/28500 (epoch 0.170), train_loss = 3.36869358, grad/param norm = 6.1304e-01, time/batch = 0.6778s	
98/28500 (epoch 0.172), train_loss = 3.39337492, grad/param norm = 5.4607e-01, time/batch = 0.6789s	
99/28500 (epoch 0.174), train_loss = 3.50618861, grad/param norm = 6.3868e-01, time/batch = 0.6788s	
100/28500 (epoch 0.175), train_loss = 3.37411357, grad/param norm = 5.2004e-01, time/batch = 0.6802s	
101/28500 (epoch 0.177), train_loss = 3.44492884, grad/param norm = 4.7668e-01, time/batch = 0.6839s	
102/28500 (epoch 0.179), train_loss = 3.30839690, grad/param norm = 4.5720e-01, time/batch = 0.6795s	
103/28500 (epoch 0.181), train_loss = 3.45814365, grad/param norm = 5.9038e-01, time/batch = 0.6802s	
104/28500 (epoch 0.182), train_loss = 3.36388202, grad/param norm = 8.4054e-01, time/batch = 0.6781s	
105/28500 (epoch 0.184), train_loss = 3.31903931, grad/param norm = 7.4799e-01, time/batch = 0.6796s	
106/28500 (epoch 0.186), train_loss = 3.24670448, grad/param norm = 3.8110e-01, time/batch = 0.6801s	
107/28500 (epoch 0.188), train_loss = 3.55586446, grad/param norm = 4.0748e-01, time/batch = 0.7008s	
108/28500 (epoch 0.189), train_loss = 3.29613900, grad/param norm = 7.1337e-01, time/batch = 0.6820s	
109/28500 (epoch 0.191), train_loss = 3.33809002, grad/param norm = 4.9708e-01, time/batch = 0.6786s	
110/28500 (epoch 0.193), train_loss = 3.29680748, grad/param norm = 4.3254e-01, time/batch = 0.6801s	
111/28500 (epoch 0.195), train_loss = 3.47681362, grad/param norm = 5.4228e-01, time/batch = 0.6810s	
112/28500 (epoch 0.196), train_loss = 3.45091488, grad/param norm = 5.2463e-01, time/batch = 0.6794s	
113/28500 (epoch 0.198), train_loss = 3.25183924, grad/param norm = 4.7961e-01, time/batch = 0.6794s	
114/28500 (epoch 0.200), train_loss = 3.37839697, grad/param norm = 8.3593e-01, time/batch = 0.6782s	
115/28500 (epoch 0.202), train_loss = 3.47812398, grad/param norm = 8.4653e-01, time/batch = 0.6801s	
116/28500 (epoch 0.204), train_loss = 3.20384216, grad/param norm = 4.7808e-01, time/batch = 0.6799s	
117/28500 (epoch 0.205), train_loss = 3.32253695, grad/param norm = 4.1223e-01, time/batch = 0.6802s	
118/28500 (epoch 0.207), train_loss = 3.37251433, grad/param norm = 4.8537e-01, time/batch = 0.6804s	
119/28500 (epoch 0.209), train_loss = 3.33486991, grad/param norm = 3.6764e-01, time/batch = 0.6780s	
120/28500 (epoch 0.211), train_loss = 3.44676729, grad/param norm = 3.8321e-01, time/batch = 0.6812s	
121/28500 (epoch 0.212), train_loss = 3.23289959, grad/param norm = 5.1843e-01, time/batch = 0.6820s	
122/28500 (epoch 0.214), train_loss = 3.30980110, grad/param norm = 7.9125e-01, time/batch = 0.6807s	
123/28500 (epoch 0.216), train_loss = 3.34062287, grad/param norm = 1.0327e+00, time/batch = 0.6797s	
124/28500 (epoch 0.218), train_loss = 3.30208043, grad/param norm = 9.0310e-01, time/batch = 0.6801s	
125/28500 (epoch 0.219), train_loss = 3.30873210, grad/param norm = 6.9709e-01, time/batch = 0.6829s	
126/28500 (epoch 0.221), train_loss = 3.26616912, grad/param norm = 4.1859e-01, time/batch = 0.6813s	
127/28500 (epoch 0.223), train_loss = 3.26345251, grad/param norm = 4.4642e-01, time/batch = 0.6794s	
128/28500 (epoch 0.225), train_loss = 3.37604041, grad/param norm = 5.1346e-01, time/batch = 0.6778s	
129/28500 (epoch 0.226), train_loss = 3.26687380, grad/param norm = 4.2760e-01, time/batch = 0.6754s	
130/28500 (epoch 0.228), train_loss = 3.32324273, grad/param norm = 6.2257e-01, time/batch = 0.6771s	
131/28500 (epoch 0.230), train_loss = 3.25972029, grad/param norm = 1.1443e+00, time/batch = 0.6829s	
132/28500 (epoch 0.232), train_loss = 3.27297709, grad/param norm = 1.2936e+00, time/batch = 0.6799s	
133/28500 (epoch 0.233), train_loss = 3.23605190, grad/param norm = 5.6380e-01, time/batch = 0.6790s	
134/28500 (epoch 0.235), train_loss = 3.17592101, grad/param norm = 4.0999e-01, time/batch = 0.6772s	
135/28500 (epoch 0.237), train_loss = 3.26470217, grad/param norm = 3.4578e-01, time/batch = 0.6802s	
136/28500 (epoch 0.239), train_loss = 3.17285131, grad/param norm = 4.8789e-01, time/batch = 0.6790s	
137/28500 (epoch 0.240), train_loss = 3.14459479, grad/param norm = 6.2748e-01, time/batch = 0.6763s	
138/28500 (epoch 0.242), train_loss = 3.18572568, grad/param norm = 6.5978e-01, time/batch = 0.6799s	
139/28500 (epoch 0.244), train_loss = 3.09938843, grad/param norm = 6.9805e-01, time/batch = 0.6850s	
140/28500 (epoch 0.246), train_loss = 3.16190117, grad/param norm = 7.2894e-01, time/batch = 0.6786s	
141/28500 (epoch 0.247), train_loss = 3.22742734, grad/param norm = 1.1377e+00, time/batch = 0.6817s	
142/28500 (epoch 0.249), train_loss = 3.26249764, grad/param norm = 1.1331e+00, time/batch = 0.6777s	
143/28500 (epoch 0.251), train_loss = 3.16636432, grad/param norm = 8.0904e-01, time/batch = 0.6837s	
144/28500 (epoch 0.253), train_loss = 3.07517215, grad/param norm = 7.2265e-01, time/batch = 0.6832s	
145/28500 (epoch 0.254), train_loss = 3.12653811, grad/param norm = 6.4361e-01, time/batch = 0.6823s	
146/28500 (epoch 0.256), train_loss = 3.10652593, grad/param norm = 5.4059e-01, time/batch = 0.6783s	
147/28500 (epoch 0.258), train_loss = 3.21345161, grad/param norm = 5.7212e-01, time/batch = 0.6771s	
148/28500 (epoch 0.260), train_loss = 3.07305363, grad/param norm = 8.1992e-01, time/batch = 0.6788s	
149/28500 (epoch 0.261), train_loss = 3.07421840, grad/param norm = 9.8495e-01, time/batch = 0.6772s	
150/28500 (epoch 0.263), train_loss = 3.09165853, grad/param norm = 6.7922e-01, time/batch = 0.6816s	
151/28500 (epoch 0.265), train_loss = 3.19058019, grad/param norm = 3.3962e-01, time/batch = 0.6816s	
152/28500 (epoch 0.267), train_loss = 3.07870941, grad/param norm = 4.0585e-01, time/batch = 0.6810s	
153/28500 (epoch 0.268), train_loss = 3.03519012, grad/param norm = 4.7876e-01, time/batch = 0.6766s	
154/28500 (epoch 0.270), train_loss = 3.10189126, grad/param norm = 7.8268e-01, time/batch = 0.6772s	
155/28500 (epoch 0.272), train_loss = 2.97907366, grad/param norm = 1.0732e+00, time/batch = 0.6796s	
156/28500 (epoch 0.274), train_loss = 3.17474728, grad/param norm = 1.0549e+00, time/batch = 0.6783s	
157/28500 (epoch 0.275), train_loss = 3.05833555, grad/param norm = 9.2039e-01, time/batch = 0.6757s	
158/28500 (epoch 0.277), train_loss = 3.07483673, grad/param norm = 6.7265e-01, time/batch = 0.6771s	
159/28500 (epoch 0.279), train_loss = 3.00574273, grad/param norm = 6.0340e-01, time/batch = 0.6792s	
160/28500 (epoch 0.281), train_loss = 2.96499312, grad/param norm = 8.9133e-01, time/batch = 0.6967s	
161/28500 (epoch 0.282), train_loss = 2.93457243, grad/param norm = 1.0918e+00, time/batch = 0.6883s	
162/28500 (epoch 0.284), train_loss = 2.99687412, grad/param norm = 7.8203e-01, time/batch = 0.6779s	
163/28500 (epoch 0.286), train_loss = 3.14439091, grad/param norm = 6.0055e-01, time/batch = 0.6879s	
164/28500 (epoch 0.288), train_loss = 3.04229621, grad/param norm = 5.5255e-01, time/batch = 0.6881s	
165/28500 (epoch 0.289), train_loss = 3.14223806, grad/param norm = 4.2736e-01, time/batch = 0.6822s	
166/28500 (epoch 0.291), train_loss = 2.85537492, grad/param norm = 4.4143e-01, time/batch = 0.6792s	
167/28500 (epoch 0.293), train_loss = 2.91797713, grad/param norm = 6.1940e-01, time/batch = 0.6794s	
168/28500 (epoch 0.295), train_loss = 2.96756192, grad/param norm = 5.6483e-01, time/batch = 0.6765s	
169/28500 (epoch 0.296), train_loss = 2.98642264, grad/param norm = 7.6196e-01, time/batch = 0.6789s	
170/28500 (epoch 0.298), train_loss = 2.96352656, grad/param norm = 8.8678e-01, time/batch = 0.6792s	
171/28500 (epoch 0.300), train_loss = 2.91086343, grad/param norm = 8.7365e-01, time/batch = 0.6816s	
172/28500 (epoch 0.302), train_loss = 2.93283333, grad/param norm = 8.9803e-01, time/batch = 0.6764s	
173/28500 (epoch 0.304), train_loss = 2.99239784, grad/param norm = 8.5390e-01, time/batch = 0.6798s	
174/28500 (epoch 0.305), train_loss = 2.93598630, grad/param norm = 8.9119e-01, time/batch = 0.6819s	
175/28500 (epoch 0.307), train_loss = 3.00918046, grad/param norm = 9.3094e-01, time/batch = 0.6762s	
176/28500 (epoch 0.309), train_loss = 3.05881875, grad/param norm = 9.3099e-01, time/batch = 0.6756s	
177/28500 (epoch 0.311), train_loss = 2.96140154, grad/param norm = 1.0615e+00, time/batch = 0.6758s	
178/28500 (epoch 0.312), train_loss = 2.79899549, grad/param norm = 8.4864e-01, time/batch = 0.6781s	
179/28500 (epoch 0.314), train_loss = 2.88548370, grad/param norm = 7.2745e-01, time/batch = 0.7007s	
180/28500 (epoch 0.316), train_loss = 2.86206083, grad/param norm = 5.1377e-01, time/batch = 0.6847s	
181/28500 (epoch 0.318), train_loss = 2.76501616, grad/param norm = 5.2578e-01, time/batch = 0.6788s	
182/28500 (epoch 0.319), train_loss = 2.87661841, grad/param norm = 7.2084e-01, time/batch = 0.6823s	
183/28500 (epoch 0.321), train_loss = 3.00570335, grad/param norm = 5.7690e-01, time/batch = 0.6792s	
184/28500 (epoch 0.323), train_loss = 2.87623622, grad/param norm = 5.0191e-01, time/batch = 0.6772s	
185/28500 (epoch 0.325), train_loss = 3.00809936, grad/param norm = 6.5176e-01, time/batch = 0.6811s	
186/28500 (epoch 0.326), train_loss = 2.95927234, grad/param norm = 6.4712e-01, time/batch = 0.6790s	
187/28500 (epoch 0.328), train_loss = 3.08862448, grad/param norm = 5.5180e-01, time/batch = 0.6811s	
188/28500 (epoch 0.330), train_loss = 2.87912882, grad/param norm = 9.3928e-01, time/batch = 0.6838s	
189/28500 (epoch 0.332), train_loss = 2.87004376, grad/param norm = 8.7418e-01, time/batch = 0.6836s	
190/28500 (epoch 0.333), train_loss = 2.91270652, grad/param norm = 6.8564e-01, time/batch = 0.6846s	
191/28500 (epoch 0.335), train_loss = 2.83801293, grad/param norm = 5.0344e-01, time/batch = 0.6979s	
192/28500 (epoch 0.337), train_loss = 2.94548869, grad/param norm = 3.7148e-01, time/batch = 0.6872s	
193/28500 (epoch 0.339), train_loss = 2.93246083, grad/param norm = 4.2712e-01, time/batch = 0.6854s	
194/28500 (epoch 0.340), train_loss = 2.88098904, grad/param norm = 6.2341e-01, time/batch = 0.6791s	
195/28500 (epoch 0.342), train_loss = 2.81683520, grad/param norm = 8.3002e-01, time/batch = 0.6796s	
196/28500 (epoch 0.344), train_loss = 2.88490696, grad/param norm = 1.0519e+00, time/batch = 0.6766s	
197/28500 (epoch 0.346), train_loss = 2.78896891, grad/param norm = 9.5825e-01, time/batch = 0.6947s	
198/28500 (epoch 0.347), train_loss = 2.84669480, grad/param norm = 5.9616e-01, time/batch = 0.7009s	
199/28500 (epoch 0.349), train_loss = 2.88411800, grad/param norm = 5.5763e-01, time/batch = 0.6862s	
200/28500 (epoch 0.351), train_loss = 2.77833418, grad/param norm = 6.2865e-01, time/batch = 0.6849s	
201/28500 (epoch 0.353), train_loss = 2.87386332, grad/param norm = 7.4834e-01, time/batch = 0.6783s	
202/28500 (epoch 0.354), train_loss = 2.94480318, grad/param norm = 1.0261e+00, time/batch = 0.6765s	
203/28500 (epoch 0.356), train_loss = 2.99657304, grad/param norm = 1.5118e+00, time/batch = 0.6767s	
204/28500 (epoch 0.358), train_loss = 2.93795462, grad/param norm = 8.5958e-01, time/batch = 0.6794s	
205/28500 (epoch 0.360), train_loss = 3.00429803, grad/param norm = 4.9819e-01, time/batch = 0.6809s	
206/28500 (epoch 0.361), train_loss = 2.93931757, grad/param norm = 6.1810e-01, time/batch = 0.6793s	
207/28500 (epoch 0.363), train_loss = 2.94919675, grad/param norm = 7.8802e-01, time/batch = 0.6837s	
208/28500 (epoch 0.365), train_loss = 2.79913781, grad/param norm = 6.3998e-01, time/batch = 0.6796s	
209/28500 (epoch 0.367), train_loss = 2.81440999, grad/param norm = 6.7870e-01, time/batch = 0.6820s	
210/28500 (epoch 0.368), train_loss = 2.74034000, grad/param norm = 8.1522e-01, time/batch = 0.6810s	
211/28500 (epoch 0.370), train_loss = 2.89837945, grad/param norm = 1.0067e+00, time/batch = 0.6858s	
212/28500 (epoch 0.372), train_loss = 2.77695309, grad/param norm = 5.3967e-01, time/batch = 0.6799s	
213/28500 (epoch 0.374), train_loss = 2.86113884, grad/param norm = 3.8251e-01, time/batch = 0.6834s	
214/28500 (epoch 0.375), train_loss = 2.84604375, grad/param norm = 4.9954e-01, time/batch = 0.6848s	
215/28500 (epoch 0.377), train_loss = 3.13365256, grad/param norm = 6.6615e-01, time/batch = 0.6811s	
216/28500 (epoch 0.379), train_loss = 2.78345894, grad/param norm = 1.5179e+00, time/batch = 0.6800s	
217/28500 (epoch 0.381), train_loss = 2.88149703, grad/param norm = 7.2815e-01, time/batch = 0.6830s	
218/28500 (epoch 0.382), train_loss = 2.92571160, grad/param norm = 6.6485e-01, time/batch = 0.6817s	
219/28500 (epoch 0.384), train_loss = 2.99361479, grad/param norm = 5.8683e-01, time/batch = 0.6807s	
220/28500 (epoch 0.386), train_loss = 2.75788611, grad/param norm = 4.6840e-01, time/batch = 0.6815s	
221/28500 (epoch 0.388), train_loss = 2.88882612, grad/param norm = 4.8477e-01, time/batch = 0.6851s	
222/28500 (epoch 0.389), train_loss = 2.83308080, grad/param norm = 4.1014e-01, time/batch = 0.6811s	
223/28500 (epoch 0.391), train_loss = 2.87456289, grad/param norm = 2.9993e-01, time/batch = 0.6812s	
224/28500 (epoch 0.393), train_loss = 2.64578375, grad/param norm = 4.4857e-01, time/batch = 0.6790s	
225/28500 (epoch 0.395), train_loss = 2.98113547, grad/param norm = 6.2166e-01, time/batch = 0.6819s	
226/28500 (epoch 0.396), train_loss = 2.94909818, grad/param norm = 7.7994e-01, time/batch = 0.6791s	
227/28500 (epoch 0.398), train_loss = 3.21338140, grad/param norm = 1.0075e+00, time/batch = 0.6796s	
228/28500 (epoch 0.400), train_loss = 3.13507319, grad/param norm = 1.9615e+00, time/batch = 0.6787s	
229/28500 (epoch 0.402), train_loss = 2.94095298, grad/param norm = 1.0564e+00, time/batch = 0.6796s	
230/28500 (epoch 0.404), train_loss = 2.90836186, grad/param norm = 5.5077e-01, time/batch = 0.6779s	
231/28500 (epoch 0.405), train_loss = 2.78528024, grad/param norm = 4.2174e-01, time/batch = 0.6890s	
232/28500 (epoch 0.407), train_loss = 2.85891918, grad/param norm = 4.4076e-01, time/batch = 0.6810s	
233/28500 (epoch 0.409), train_loss = 2.82786538, grad/param norm = 4.0528e-01, time/batch = 0.6844s	
234/28500 (epoch 0.411), train_loss = 2.80585665, grad/param norm = 5.1438e-01, time/batch = 0.6805s	
235/28500 (epoch 0.412), train_loss = 2.77203185, grad/param norm = 6.5912e-01, time/batch = 0.6862s	
236/28500 (epoch 0.414), train_loss = 2.91804934, grad/param norm = 7.8220e-01, time/batch = 0.6901s	
237/28500 (epoch 0.416), train_loss = 2.73618867, grad/param norm = 8.2209e-01, time/batch = 0.6912s	
238/28500 (epoch 0.418), train_loss = 2.86202426, grad/param norm = 6.6436e-01, time/batch = 0.6887s	
239/28500 (epoch 0.419), train_loss = 2.73002530, grad/param norm = 6.8478e-01, time/batch = 0.6871s	
240/28500 (epoch 0.421), train_loss = 2.70856484, grad/param norm = 6.7746e-01, time/batch = 0.6869s	
241/28500 (epoch 0.423), train_loss = 2.95143759, grad/param norm = 8.7125e-01, time/batch = 0.6860s	
242/28500 (epoch 0.425), train_loss = 2.83818360, grad/param norm = 7.1883e-01, time/batch = 0.6809s	
243/28500 (epoch 0.426), train_loss = 2.77947941, grad/param norm = 4.7606e-01, time/batch = 0.6784s	
244/28500 (epoch 0.428), train_loss = 2.85973649, grad/param norm = 6.1292e-01, time/batch = 0.6799s	
245/28500 (epoch 0.430), train_loss = 2.79060766, grad/param norm = 4.9410e-01, time/batch = 0.6802s	
246/28500 (epoch 0.432), train_loss = 2.96983164, grad/param norm = 4.5917e-01, time/batch = 0.6817s	
247/28500 (epoch 0.433), train_loss = 2.74247452, grad/param norm = 7.7155e-01, time/batch = 0.6887s	
248/28500 (epoch 0.435), train_loss = 2.75996202, grad/param norm = 9.0481e-01, time/batch = 0.6898s	
249/28500 (epoch 0.437), train_loss = 2.68461160, grad/param norm = 7.8772e-01, time/batch = 0.6823s	
250/28500 (epoch 0.439), train_loss = 2.77564649, grad/param norm = 7.4624e-01, time/batch = 0.6824s	
251/28500 (epoch 0.440), train_loss = 2.73285878, grad/param norm = 6.3986e-01, time/batch = 0.6849s	
252/28500 (epoch 0.442), train_loss = 2.70739335, grad/param norm = 5.0696e-01, time/batch = 0.6864s	
253/28500 (epoch 0.444), train_loss = 2.81679623, grad/param norm = 5.1396e-01, time/batch = 0.7022s	
254/28500 (epoch 0.446), train_loss = 2.67006222, grad/param norm = 7.7407e-01, time/batch = 0.6807s	
255/28500 (epoch 0.447), train_loss = 2.78817934, grad/param norm = 7.4317e-01, time/batch = 0.6823s	
256/28500 (epoch 0.449), train_loss = 2.75403758, grad/param norm = 6.9248e-01, time/batch = 0.6837s	
257/28500 (epoch 0.451), train_loss = 2.75762832, grad/param norm = 5.1237e-01, time/batch = 0.6819s	
258/28500 (epoch 0.453), train_loss = 2.73827349, grad/param norm = 3.0473e-01, time/batch = 0.6843s	
259/28500 (epoch 0.454), train_loss = 2.64272207, grad/param norm = 4.5090e-01, time/batch = 0.6808s	
260/28500 (epoch 0.456), train_loss = 2.98467914, grad/param norm = 8.4397e-01, time/batch = 0.6808s	
261/28500 (epoch 0.458), train_loss = 2.79325636, grad/param norm = 1.0567e+00, time/batch = 0.6838s	
262/28500 (epoch 0.460), train_loss = 2.89777376, grad/param norm = 8.6103e-01, time/batch = 0.6807s	
263/28500 (epoch 0.461), train_loss = 2.73369287, grad/param norm = 1.0512e+00, time/batch = 0.6821s	
264/28500 (epoch 0.463), train_loss = 2.67487684, grad/param norm = 8.2777e-01, time/batch = 0.6820s	
265/28500 (epoch 0.465), train_loss = 2.65921121, grad/param norm = 6.5869e-01, time/batch = 0.6810s	
266/28500 (epoch 0.467), train_loss = 2.80207749, grad/param norm = 6.1564e-01, time/batch = 0.6790s	
267/28500 (epoch 0.468), train_loss = 2.69426350, grad/param norm = 4.5212e-01, time/batch = 0.6803s	
268/28500 (epoch 0.470), train_loss = 2.69294761, grad/param norm = 5.6803e-01, time/batch = 0.6818s	
269/28500 (epoch 0.472), train_loss = 2.68815853, grad/param norm = 6.6545e-01, time/batch = 0.6801s	
270/28500 (epoch 0.474), train_loss = 2.81264620, grad/param norm = 6.1929e-01, time/batch = 0.6800s	
271/28500 (epoch 0.475), train_loss = 2.69870245, grad/param norm = 5.3064e-01, time/batch = 0.6822s	
272/28500 (epoch 0.477), train_loss = 2.61305224, grad/param norm = 4.2794e-01, time/batch = 0.6807s	
273/28500 (epoch 0.479), train_loss = 2.74886498, grad/param norm = 4.7770e-01, time/batch = 0.6789s	
274/28500 (epoch 0.481), train_loss = 2.70485291, grad/param norm = 4.5611e-01, time/batch = 0.6804s	
275/28500 (epoch 0.482), train_loss = 2.72246861, grad/param norm = 4.6407e-01, time/batch = 0.6795s	
276/28500 (epoch 0.484), train_loss = 2.66748292, grad/param norm = 8.3930e-01, time/batch = 0.6803s	
277/28500 (epoch 0.486), train_loss = 2.82499049, grad/param norm = 9.6319e-01, time/batch = 0.6806s	
278/28500 (epoch 0.488), train_loss = 2.66619020, grad/param norm = 9.4688e-01, time/batch = 0.6799s	
279/28500 (epoch 0.489), train_loss = 2.75629674, grad/param norm = 8.3786e-01, time/batch = 0.6866s	
280/28500 (epoch 0.491), train_loss = 2.60677907, grad/param norm = 5.4834e-01, time/batch = 0.6801s	
281/28500 (epoch 0.493), train_loss = 2.69093131, grad/param norm = 3.5415e-01, time/batch = 0.6852s	
282/28500 (epoch 0.495), train_loss = 2.65850815, grad/param norm = 4.3072e-01, time/batch = 0.6813s	
283/28500 (epoch 0.496), train_loss = 2.89031043, grad/param norm = 7.2405e-01, time/batch = 0.6802s	
284/28500 (epoch 0.498), train_loss = 2.72507379, grad/param norm = 8.1978e-01, time/batch = 0.6807s	
285/28500 (epoch 0.500), train_loss = 2.70223940, grad/param norm = 4.4213e-01, time/batch = 0.6780s	
286/28500 (epoch 0.502), train_loss = 2.62467687, grad/param norm = 4.1816e-01, time/batch = 0.6758s	
287/28500 (epoch 0.504), train_loss = 2.62209725, grad/param norm = 3.6298e-01, time/batch = 0.6755s	
288/28500 (epoch 0.505), train_loss = 2.69414361, grad/param norm = 4.5518e-01, time/batch = 0.6758s	
289/28500 (epoch 0.507), train_loss = 2.85971991, grad/param norm = 4.4030e-01, time/batch = 0.6830s	
290/28500 (epoch 0.509), train_loss = 2.73153520, grad/param norm = 6.3891e-01, time/batch = 0.6935s	
291/28500 (epoch 0.511), train_loss = 2.86761250, grad/param norm = 7.9644e-01, time/batch = 0.6793s	
292/28500 (epoch 0.512), train_loss = 2.75748628, grad/param norm = 8.5566e-01, time/batch = 0.6856s	
293/28500 (epoch 0.514), train_loss = 2.70112100, grad/param norm = 6.0319e-01, time/batch = 0.6829s	
294/28500 (epoch 0.516), train_loss = 2.73033491, grad/param norm = 4.4322e-01, time/batch = 0.6811s	
295/28500 (epoch 0.518), train_loss = 2.64554067, grad/param norm = 3.4624e-01, time/batch = 0.6797s	
296/28500 (epoch 0.519), train_loss = 2.82606046, grad/param norm = 4.3803e-01, time/batch = 0.6824s	
297/28500 (epoch 0.521), train_loss = 2.74735605, grad/param norm = 4.8554e-01, time/batch = 0.6866s	
298/28500 (epoch 0.523), train_loss = 2.66212236, grad/param norm = 5.3349e-01, time/batch = 0.6932s	
299/28500 (epoch 0.525), train_loss = 2.66754318, grad/param norm = 7.2872e-01, time/batch = 0.6928s	
300/28500 (epoch 0.526), train_loss = 2.60120475, grad/param norm = 6.2490e-01, time/batch = 0.6935s	
301/28500 (epoch 0.528), train_loss = 2.81561138, grad/param norm = 6.0292e-01, time/batch = 0.6949s	
302/28500 (epoch 0.530), train_loss = 2.72070586, grad/param norm = 7.4588e-01, time/batch = 0.6954s	
303/28500 (epoch 0.532), train_loss = 2.70055960, grad/param norm = 8.4016e-01, time/batch = 0.6929s	
304/28500 (epoch 0.533), train_loss = 2.68407834, grad/param norm = 6.5367e-01, time/batch = 0.6924s	
305/28500 (epoch 0.535), train_loss = 2.55833133, grad/param norm = 5.4187e-01, time/batch = 0.6933s	
306/28500 (epoch 0.537), train_loss = 2.63437495, grad/param norm = 6.8565e-01, time/batch = 0.6939s	
307/28500 (epoch 0.539), train_loss = 2.73247383, grad/param norm = 7.8940e-01, time/batch = 0.6923s	
308/28500 (epoch 0.540), train_loss = 2.61855124, grad/param norm = 9.2101e-01, time/batch = 0.6921s	
309/28500 (epoch 0.542), train_loss = 2.92062090, grad/param norm = 1.0183e+00, time/batch = 0.6923s	
310/28500 (epoch 0.544), train_loss = 2.80341444, grad/param norm = 7.2129e-01, time/batch = 0.6926s	
311/28500 (epoch 0.546), train_loss = 2.65702386, grad/param norm = 4.2318e-01, time/batch = 0.6934s	
312/28500 (epoch 0.547), train_loss = 2.69848215, grad/param norm = 3.5690e-01, time/batch = 0.6940s	
313/28500 (epoch 0.549), train_loss = 2.69106890, grad/param norm = 3.6020e-01, time/batch = 0.6946s	
314/28500 (epoch 0.551), train_loss = 2.94255117, grad/param norm = 5.7773e-01, time/batch = 0.6944s	
315/28500 (epoch 0.553), train_loss = 2.80910308, grad/param norm = 7.9017e-01, time/batch = 0.6929s	
316/28500 (epoch 0.554), train_loss = 2.71676109, grad/param norm = 6.2990e-01, time/batch = 0.6932s	
317/28500 (epoch 0.556), train_loss = 2.76289796, grad/param norm = 3.2189e-01, time/batch = 0.6941s	
318/28500 (epoch 0.558), train_loss = 2.68720758, grad/param norm = 3.6971e-01, time/batch = 0.6910s	
319/28500 (epoch 0.560), train_loss = 2.63351613, grad/param norm = 4.9304e-01, time/batch = 0.6932s	
320/28500 (epoch 0.561), train_loss = 2.68500250, grad/param norm = 4.5640e-01, time/batch = 0.6914s	
321/28500 (epoch 0.563), train_loss = 2.61509211, grad/param norm = 4.4500e-01, time/batch = 0.6947s	
322/28500 (epoch 0.565), train_loss = 2.67935362, grad/param norm = 4.5558e-01, time/batch = 0.6947s	
323/28500 (epoch 0.567), train_loss = 2.59530775, grad/param norm = 6.3699e-01, time/batch = 0.6927s	
324/28500 (epoch 0.568), train_loss = 2.78588212, grad/param norm = 5.3979e-01, time/batch = 0.6934s	
325/28500 (epoch 0.570), train_loss = 2.74114754, grad/param norm = 6.4421e-01, time/batch = 0.6928s	
326/28500 (epoch 0.572), train_loss = 2.66462657, grad/param norm = 7.3310e-01, time/batch = 0.6936s	
327/28500 (epoch 0.574), train_loss = 2.78089170, grad/param norm = 5.2277e-01, time/batch = 0.6924s	
328/28500 (epoch 0.575), train_loss = 2.53971368, grad/param norm = 7.2769e-01, time/batch = 0.6949s	
329/28500 (epoch 0.577), train_loss = 2.55879381, grad/param norm = 8.1897e-01, time/batch = 0.6947s	
330/28500 (epoch 0.579), train_loss = 2.92996296, grad/param norm = 7.0129e-01, time/batch = 0.6922s	
331/28500 (epoch 0.581), train_loss = 2.67436951, grad/param norm = 6.6999e-01, time/batch = 0.6953s	
332/28500 (epoch 0.582), train_loss = 2.63698051, grad/param norm = 5.9990e-01, time/batch = 0.6952s	
333/28500 (epoch 0.584), train_loss = 2.51482438, grad/param norm = 3.9337e-01, time/batch = 0.6948s	
334/28500 (epoch 0.586), train_loss = 2.49308596, grad/param norm = 4.1887e-01, time/batch = 0.6957s	
335/28500 (epoch 0.588), train_loss = 2.65415225, grad/param norm = 4.1917e-01, time/batch = 0.7094s	
336/28500 (epoch 0.589), train_loss = 2.88549833, grad/param norm = 5.1786e-01, time/batch = 0.6988s	
337/28500 (epoch 0.591), train_loss = 2.70340261, grad/param norm = 3.9698e-01, time/batch = 0.7084s	
338/28500 (epoch 0.593), train_loss = 2.50970312, grad/param norm = 3.2683e-01, time/batch = 0.7013s	
339/28500 (epoch 0.595), train_loss = 2.66594829, grad/param norm = 4.3190e-01, time/batch = 0.7033s	
340/28500 (epoch 0.596), train_loss = 2.59402157, grad/param norm = 5.6299e-01, time/batch = 0.6940s	
341/28500 (epoch 0.598), train_loss = 2.63277258, grad/param norm = 4.6026e-01, time/batch = 0.6909s	
342/28500 (epoch 0.600), train_loss = 2.69957504, grad/param norm = 4.5850e-01, time/batch = 0.6908s	
343/28500 (epoch 0.602), train_loss = 2.70615847, grad/param norm = 4.9829e-01, time/batch = 0.6896s	
344/28500 (epoch 0.604), train_loss = 2.58559334, grad/param norm = 6.3077e-01, time/batch = 0.6901s	
345/28500 (epoch 0.605), train_loss = 2.59311399, grad/param norm = 6.1880e-01, time/batch = 0.7016s	
346/28500 (epoch 0.607), train_loss = 2.57462510, grad/param norm = 7.4527e-01, time/batch = 0.7000s	
347/28500 (epoch 0.609), train_loss = 2.64501014, grad/param norm = 5.8106e-01, time/batch = 0.6898s	
348/28500 (epoch 0.611), train_loss = 2.70152322, grad/param norm = 3.7053e-01, time/batch = 0.6921s	
349/28500 (epoch 0.612), train_loss = 2.73936667, grad/param norm = 3.9707e-01, time/batch = 0.6908s	
350/28500 (epoch 0.614), train_loss = 2.57825323, grad/param norm = 3.7345e-01, time/batch = 0.6891s	
351/28500 (epoch 0.616), train_loss = 2.52481022, grad/param norm = 3.7841e-01, time/batch = 0.6921s	
352/28500 (epoch 0.618), train_loss = 2.42858412, grad/param norm = 4.0597e-01, time/batch = 0.6899s	
353/28500 (epoch 0.619), train_loss = 2.59637676, grad/param norm = 4.7129e-01, time/batch = 0.6904s	
354/28500 (epoch 0.621), train_loss = 2.52251082, grad/param norm = 6.6321e-01, time/batch = 0.6907s	
355/28500 (epoch 0.623), train_loss = 2.66051478, grad/param norm = 9.4802e-01, time/batch = 0.6901s	
356/28500 (epoch 0.625), train_loss = 2.60306581, grad/param norm = 8.3230e-01, time/batch = 0.6892s	
357/28500 (epoch 0.626), train_loss = 2.46961077, grad/param norm = 5.8675e-01, time/batch = 0.6894s	
358/28500 (epoch 0.628), train_loss = 2.51864933, grad/param norm = 4.8849e-01, time/batch = 0.6980s	
359/28500 (epoch 0.630), train_loss = 2.52636232, grad/param norm = 3.5189e-01, time/batch = 0.7043s	
360/28500 (epoch 0.632), train_loss = 2.64347439, grad/param norm = 3.5399e-01, time/batch = 0.6976s	
361/28500 (epoch 0.633), train_loss = 2.51043307, grad/param norm = 3.5147e-01, time/batch = 0.6992s	
362/28500 (epoch 0.635), train_loss = 2.76543924, grad/param norm = 4.9531e-01, time/batch = 0.6933s	
363/28500 (epoch 0.637), train_loss = 2.63505312, grad/param norm = 6.7707e-01, time/batch = 0.6902s	
364/28500 (epoch 0.639), train_loss = 2.50677142, grad/param norm = 4.9160e-01, time/batch = 0.6914s	
365/28500 (epoch 0.640), train_loss = 2.58700903, grad/param norm = 4.6683e-01, time/batch = 0.6934s	
366/28500 (epoch 0.642), train_loss = 2.69570981, grad/param norm = 4.6431e-01, time/batch = 0.6917s	
367/28500 (epoch 0.644), train_loss = 2.86410431, grad/param norm = 4.8936e-01, time/batch = 0.6921s	
368/28500 (epoch 0.646), train_loss = 2.60390524, grad/param norm = 6.0177e-01, time/batch = 0.6910s	
369/28500 (epoch 0.647), train_loss = 2.62193239, grad/param norm = 5.4747e-01, time/batch = 0.6923s	
370/28500 (epoch 0.649), train_loss = 2.61793206, grad/param norm = 4.5143e-01, time/batch = 0.6926s	
371/28500 (epoch 0.651), train_loss = 2.62623595, grad/param norm = 5.7807e-01, time/batch = 0.6941s	
372/28500 (epoch 0.653), train_loss = 2.60494693, grad/param norm = 5.3747e-01, time/batch = 0.6787s	
373/28500 (epoch 0.654), train_loss = 2.67495494, grad/param norm = 3.4720e-01, time/batch = 0.6789s	
374/28500 (epoch 0.656), train_loss = 2.61778348, grad/param norm = 3.3996e-01, time/batch = 0.6838s	
375/28500 (epoch 0.658), train_loss = 2.62784150, grad/param norm = 3.6325e-01, time/batch = 0.6833s	
376/28500 (epoch 0.660), train_loss = 2.68273077, grad/param norm = 4.5928e-01, time/batch = 0.7006s	
377/28500 (epoch 0.661), train_loss = 2.63266001, grad/param norm = 4.2711e-01, time/batch = 0.6957s	
378/28500 (epoch 0.663), train_loss = 2.61495657, grad/param norm = 3.5689e-01, time/batch = 0.6966s	
379/28500 (epoch 0.665), train_loss = 2.60330072, grad/param norm = 4.3162e-01, time/batch = 0.6960s	
380/28500 (epoch 0.667), train_loss = 2.43317967, grad/param norm = 6.6360e-01, time/batch = 0.6937s	
381/28500 (epoch 0.668), train_loss = 2.51578568, grad/param norm = 6.2872e-01, time/batch = 0.6965s	
382/28500 (epoch 0.670), train_loss = 2.48391927, grad/param norm = 4.7821e-01, time/batch = 0.6970s	
383/28500 (epoch 0.672), train_loss = 2.50909801, grad/param norm = 4.8986e-01, time/batch = 0.6947s	
384/28500 (epoch 0.674), train_loss = 2.53158775, grad/param norm = 3.8302e-01, time/batch = 0.6928s	
385/28500 (epoch 0.675), train_loss = 2.38285506, grad/param norm = 2.9516e-01, time/batch = 0.6799s	
386/28500 (epoch 0.677), train_loss = 2.55861555, grad/param norm = 3.5722e-01, time/batch = 0.6860s	
387/28500 (epoch 0.679), train_loss = 2.55588566, grad/param norm = 3.4996e-01, time/batch = 0.7014s	
388/28500 (epoch 0.681), train_loss = 2.66736031, grad/param norm = 4.7535e-01, time/batch = 0.6916s	
389/28500 (epoch 0.682), train_loss = 2.48234977, grad/param norm = 4.9445e-01, time/batch = 0.6915s	
390/28500 (epoch 0.684), train_loss = 2.60852206, grad/param norm = 6.7046e-01, time/batch = 0.6926s	
391/28500 (epoch 0.686), train_loss = 2.51539919, grad/param norm = 9.8678e-01, time/batch = 0.6954s	
392/28500 (epoch 0.688), train_loss = 2.48024731, grad/param norm = 7.3939e-01, time/batch = 0.6913s	
393/28500 (epoch 0.689), train_loss = 2.61283275, grad/param norm = 4.8766e-01, time/batch = 0.6914s	
394/28500 (epoch 0.691), train_loss = 2.48252140, grad/param norm = 4.0022e-01, time/batch = 0.6908s	
395/28500 (epoch 0.693), train_loss = 2.49565190, grad/param norm = 5.0409e-01, time/batch = 0.6910s	
396/28500 (epoch 0.695), train_loss = 2.58304625, grad/param norm = 4.4644e-01, time/batch = 0.6923s	
397/28500 (epoch 0.696), train_loss = 2.59380757, grad/param norm = 3.5032e-01, time/batch = 0.6890s	
398/28500 (epoch 0.698), train_loss = 2.47098389, grad/param norm = 3.2315e-01, time/batch = 0.6903s	
399/28500 (epoch 0.700), train_loss = 2.42383042, grad/param norm = 3.4917e-01, time/batch = 0.6901s	
400/28500 (epoch 0.702), train_loss = 2.50423155, grad/param norm = 3.4198e-01, time/batch = 0.6895s	
401/28500 (epoch 0.704), train_loss = 2.37241307, grad/param norm = 4.5406e-01, time/batch = 0.6951s	
402/28500 (epoch 0.705), train_loss = 2.48548471, grad/param norm = 5.0735e-01, time/batch = 0.6948s	
403/28500 (epoch 0.707), train_loss = 2.64758290, grad/param norm = 5.0516e-01, time/batch = 0.6929s	
404/28500 (epoch 0.709), train_loss = 2.55168470, grad/param norm = 5.7720e-01, time/batch = 0.6892s	
405/28500 (epoch 0.711), train_loss = 2.42931599, grad/param norm = 5.6880e-01, time/batch = 0.6956s	
406/28500 (epoch 0.712), train_loss = 2.40112035, grad/param norm = 5.6622e-01, time/batch = 0.7063s	
407/28500 (epoch 0.714), train_loss = 2.48955750, grad/param norm = 4.7958e-01, time/batch = 0.6972s	
408/28500 (epoch 0.716), train_loss = 2.58556517, grad/param norm = 3.4700e-01, time/batch = 0.6897s	
409/28500 (epoch 0.718), train_loss = 2.47351350, grad/param norm = 3.3152e-01, time/batch = 0.6905s	
410/28500 (epoch 0.719), train_loss = 2.49024090, grad/param norm = 3.7668e-01, time/batch = 0.6895s	
411/28500 (epoch 0.721), train_loss = 2.44904010, grad/param norm = 4.5845e-01, time/batch = 0.6919s	
412/28500 (epoch 0.723), train_loss = 2.48719879, grad/param norm = 4.1685e-01, time/batch = 0.6917s	
413/28500 (epoch 0.725), train_loss = 2.63397084, grad/param norm = 3.5153e-01, time/batch = 0.6911s	
414/28500 (epoch 0.726), train_loss = 2.51099625, grad/param norm = 3.7775e-01, time/batch = 0.6894s	
415/28500 (epoch 0.728), train_loss = 2.46640653, grad/param norm = 3.7795e-01, time/batch = 0.6906s	
416/28500 (epoch 0.730), train_loss = 2.54745697, grad/param norm = 3.2815e-01, time/batch = 0.6905s	
417/28500 (epoch 0.732), train_loss = 2.42707984, grad/param norm = 3.5244e-01, time/batch = 0.6894s	
418/28500 (epoch 0.733), train_loss = 2.48472197, grad/param norm = 5.9341e-01, time/batch = 0.6895s	
419/28500 (epoch 0.735), train_loss = 2.58481303, grad/param norm = 7.6319e-01, time/batch = 0.6949s	
420/28500 (epoch 0.737), train_loss = 2.48707351, grad/param norm = 7.7277e-01, time/batch = 0.7001s	
421/28500 (epoch 0.739), train_loss = 2.47986400, grad/param norm = 6.5972e-01, time/batch = 0.7217s	
422/28500 (epoch 0.740), train_loss = 2.52723456, grad/param norm = 4.6356e-01, time/batch = 0.7124s	
423/28500 (epoch 0.742), train_loss = 2.49099912, grad/param norm = 3.3752e-01, time/batch = 0.7001s	
424/28500 (epoch 0.744), train_loss = 2.46638382, grad/param norm = 2.9492e-01, time/batch = 0.7021s	
425/28500 (epoch 0.746), train_loss = 2.40958741, grad/param norm = 3.9130e-01, time/batch = 0.7026s	
426/28500 (epoch 0.747), train_loss = 2.45988387, grad/param norm = 3.8431e-01, time/batch = 0.7040s	
427/28500 (epoch 0.749), train_loss = 2.71064200, grad/param norm = 5.0372e-01, time/batch = 0.7124s	
428/28500 (epoch 0.751), train_loss = 2.45921277, grad/param norm = 4.4424e-01, time/batch = 0.7076s	
429/28500 (epoch 0.753), train_loss = 2.32778659, grad/param norm = 5.7352e-01, time/batch = 0.7006s	
430/28500 (epoch 0.754), train_loss = 2.50744202, grad/param norm = 5.5961e-01, time/batch = 0.6942s	
431/28500 (epoch 0.756), train_loss = 2.64413814, grad/param norm = 4.8254e-01, time/batch = 0.6959s	
432/28500 (epoch 0.758), train_loss = 2.49108188, grad/param norm = 4.2215e-01, time/batch = 0.7026s	
433/28500 (epoch 0.760), train_loss = 2.50289557, grad/param norm = 4.6651e-01, time/batch = 0.7009s	
434/28500 (epoch 0.761), train_loss = 2.58590568, grad/param norm = 5.1205e-01, time/batch = 0.6939s	
435/28500 (epoch 0.763), train_loss = 2.42383251, grad/param norm = 6.5093e-01, time/batch = 0.6957s	
436/28500 (epoch 0.765), train_loss = 2.42398923, grad/param norm = 4.2667e-01, time/batch = 0.6974s	
437/28500 (epoch 0.767), train_loss = 2.44629226, grad/param norm = 3.5235e-01, time/batch = 0.6967s	
438/28500 (epoch 0.768), train_loss = 2.50391027, grad/param norm = 4.7238e-01, time/batch = 0.6928s	
439/28500 (epoch 0.770), train_loss = 2.46675669, grad/param norm = 4.4144e-01, time/batch = 0.6927s	
440/28500 (epoch 0.772), train_loss = 2.39831456, grad/param norm = 3.8668e-01, time/batch = 0.6944s	
441/28500 (epoch 0.774), train_loss = 2.40132659, grad/param norm = 3.5948e-01, time/batch = 0.7029s	
442/28500 (epoch 0.775), train_loss = 2.54312846, grad/param norm = 3.4709e-01, time/batch = 0.6986s	
443/28500 (epoch 0.777), train_loss = 2.39517412, grad/param norm = 3.7354e-01, time/batch = 0.6940s	
444/28500 (epoch 0.779), train_loss = 2.54603878, grad/param norm = 5.4490e-01, time/batch = 0.6981s	
445/28500 (epoch 0.781), train_loss = 2.54289109, grad/param norm = 5.2849e-01, time/batch = 0.6959s	
446/28500 (epoch 0.782), train_loss = 2.53849547, grad/param norm = 4.6157e-01, time/batch = 0.6942s	
447/28500 (epoch 0.784), train_loss = 2.42784189, grad/param norm = 4.0161e-01, time/batch = 0.6980s	
448/28500 (epoch 0.786), train_loss = 2.50667029, grad/param norm = 3.9590e-01, time/batch = 0.6964s	
449/28500 (epoch 0.788), train_loss = 2.68100645, grad/param norm = 3.0870e-01, time/batch = 0.6997s	
450/28500 (epoch 0.789), train_loss = 2.46294818, grad/param norm = 5.8342e-01, time/batch = 0.6932s	
451/28500 (epoch 0.791), train_loss = 2.43552643, grad/param norm = 6.1578e-01, time/batch = 0.6987s	
452/28500 (epoch 0.793), train_loss = 2.26012175, grad/param norm = 5.5747e-01, time/batch = 0.6970s	
453/28500 (epoch 0.795), train_loss = 2.49618551, grad/param norm = 5.1213e-01, time/batch = 0.6977s	
454/28500 (epoch 0.796), train_loss = 2.37434950, grad/param norm = 4.9283e-01, time/batch = 0.7035s	
455/28500 (epoch 0.798), train_loss = 2.47437925, grad/param norm = 4.8705e-01, time/batch = 0.6976s	
456/28500 (epoch 0.800), train_loss = 2.44563429, grad/param norm = 4.4980e-01, time/batch = 0.6986s	
457/28500 (epoch 0.802), train_loss = 2.56826940, grad/param norm = 3.8025e-01, time/batch = 0.6935s	
458/28500 (epoch 0.804), train_loss = 2.42528101, grad/param norm = 3.8566e-01, time/batch = 0.6958s	
459/28500 (epoch 0.805), train_loss = 2.50326746, grad/param norm = 3.4393e-01, time/batch = 0.6956s	
460/28500 (epoch 0.807), train_loss = 2.62990907, grad/param norm = 3.6660e-01, time/batch = 0.7023s	
461/28500 (epoch 0.809), train_loss = 2.47306691, grad/param norm = 3.9465e-01, time/batch = 0.6947s	
462/28500 (epoch 0.811), train_loss = 2.55672055, grad/param norm = 3.4126e-01, time/batch = 0.6945s	
463/28500 (epoch 0.812), train_loss = 2.55682912, grad/param norm = 3.5025e-01, time/batch = 0.7031s	
464/28500 (epoch 0.814), train_loss = 2.48346953, grad/param norm = 4.2691e-01, time/batch = 0.7002s	
465/28500 (epoch 0.816), train_loss = 2.51899521, grad/param norm = 4.2797e-01, time/batch = 0.6964s	
466/28500 (epoch 0.818), train_loss = 2.41564434, grad/param norm = 5.5494e-01, time/batch = 0.6955s	
467/28500 (epoch 0.819), train_loss = 2.48797749, grad/param norm = 6.1505e-01, time/batch = 0.6963s	
468/28500 (epoch 0.821), train_loss = 2.46989712, grad/param norm = 5.9317e-01, time/batch = 0.6951s	
469/28500 (epoch 0.823), train_loss = 2.61152971, grad/param norm = 4.4314e-01, time/batch = 0.6968s	
470/28500 (epoch 0.825), train_loss = 2.40734943, grad/param norm = 3.8013e-01, time/batch = 0.6958s	
471/28500 (epoch 0.826), train_loss = 2.44917725, grad/param norm = 3.4874e-01, time/batch = 0.7024s	
472/28500 (epoch 0.828), train_loss = 2.31310300, grad/param norm = 2.6148e-01, time/batch = 0.7020s	
473/28500 (epoch 0.830), train_loss = 2.38517707, grad/param norm = 3.0434e-01, time/batch = 0.7004s	
474/28500 (epoch 0.832), train_loss = 2.50325040, grad/param norm = 3.5008e-01, time/batch = 0.6985s	
475/28500 (epoch 0.833), train_loss = 2.51520144, grad/param norm = 4.1893e-01, time/batch = 0.6991s	
476/28500 (epoch 0.835), train_loss = 2.38214512, grad/param norm = 4.5905e-01, time/batch = 0.6990s	
477/28500 (epoch 0.837), train_loss = 2.44805990, grad/param norm = 4.8502e-01, time/batch = 0.6989s	
478/28500 (epoch 0.839), train_loss = 2.49857705, grad/param norm = 4.0328e-01, time/batch = 0.6978s	
479/28500 (epoch 0.840), train_loss = 2.51525946, grad/param norm = 4.6219e-01, time/batch = 0.6964s	
480/28500 (epoch 0.842), train_loss = 2.58045985, grad/param norm = 4.6529e-01, time/batch = 0.6976s	
481/28500 (epoch 0.844), train_loss = 2.48588568, grad/param norm = 3.5323e-01, time/batch = 0.6986s	
482/28500 (epoch 0.846), train_loss = 2.47516509, grad/param norm = 3.2782e-01, time/batch = 0.6954s	
483/28500 (epoch 0.847), train_loss = 2.36500984, grad/param norm = 3.0231e-01, time/batch = 0.6966s	
484/28500 (epoch 0.849), train_loss = 2.40340264, grad/param norm = 3.3437e-01, time/batch = 0.6951s	
485/28500 (epoch 0.851), train_loss = 2.30928980, grad/param norm = 3.7483e-01, time/batch = 0.6996s	
486/28500 (epoch 0.853), train_loss = 2.47269970, grad/param norm = 3.6422e-01, time/batch = 0.6987s	
487/28500 (epoch 0.854), train_loss = 2.36740009, grad/param norm = 3.6353e-01, time/batch = 0.6995s	
488/28500 (epoch 0.856), train_loss = 2.55146200, grad/param norm = 4.3584e-01, time/batch = 0.7008s	
489/28500 (epoch 0.858), train_loss = 2.34277086, grad/param norm = 3.8519e-01, time/batch = 0.7068s	
490/28500 (epoch 0.860), train_loss = 2.41632123, grad/param norm = 3.0464e-01, time/batch = 0.7123s	
491/28500 (epoch 0.861), train_loss = 2.35545210, grad/param norm = 3.9889e-01, time/batch = 0.7158s	
492/28500 (epoch 0.863), train_loss = 2.53502893, grad/param norm = 3.5553e-01, time/batch = 0.6995s	
493/28500 (epoch 0.865), train_loss = 2.39856167, grad/param norm = 4.5864e-01, time/batch = 0.6966s	
494/28500 (epoch 0.867), train_loss = 2.47047136, grad/param norm = 5.4341e-01, time/batch = 0.6936s	
495/28500 (epoch 0.868), train_loss = 2.17179805, grad/param norm = 3.7308e-01, time/batch = 0.6960s	
496/28500 (epoch 0.870), train_loss = 2.31515647, grad/param norm = 3.4731e-01, time/batch = 0.7044s	
497/28500 (epoch 0.872), train_loss = 2.59544333, grad/param norm = 3.5703e-01, time/batch = 0.7073s	
498/28500 (epoch 0.874), train_loss = 2.40422248, grad/param norm = 3.1533e-01, time/batch = 0.6980s	
499/28500 (epoch 0.875), train_loss = 2.42795984, grad/param norm = 3.5620e-01, time/batch = 0.6933s	
500/28500 (epoch 0.877), train_loss = 2.39003389, grad/param norm = 3.7489e-01, time/batch = 0.6941s	
501/28500 (epoch 0.879), train_loss = 2.38796752, grad/param norm = 3.6178e-01, time/batch = 0.7027s	
502/28500 (epoch 0.881), train_loss = 2.46416338, grad/param norm = 3.5155e-01, time/batch = 0.6950s	
503/28500 (epoch 0.882), train_loss = 2.31756670, grad/param norm = 4.2114e-01, time/batch = 0.6942s	
504/28500 (epoch 0.884), train_loss = 2.42172444, grad/param norm = 5.2602e-01, time/batch = 0.6972s	
505/28500 (epoch 0.886), train_loss = 2.30597228, grad/param norm = 5.9018e-01, time/batch = 0.6995s	
506/28500 (epoch 0.888), train_loss = 2.27899006, grad/param norm = 5.2035e-01, time/batch = 0.7119s	
507/28500 (epoch 0.889), train_loss = 2.22751247, grad/param norm = 4.5459e-01, time/batch = 0.6986s	
508/28500 (epoch 0.891), train_loss = 2.43018784, grad/param norm = 5.5239e-01, time/batch = 0.6950s	
509/28500 (epoch 0.893), train_loss = 2.61099417, grad/param norm = 4.2323e-01, time/batch = 0.6945s	
510/28500 (epoch 0.895), train_loss = 2.50146794, grad/param norm = 3.6740e-01, time/batch = 0.6939s	
511/28500 (epoch 0.896), train_loss = 2.44858752, grad/param norm = 3.5455e-01, time/batch = 0.6994s	
512/28500 (epoch 0.898), train_loss = 2.29484366, grad/param norm = 2.7807e-01, time/batch = 0.7009s	
513/28500 (epoch 0.900), train_loss = 2.31066960, grad/param norm = 3.2063e-01, time/batch = 0.6993s	
514/28500 (epoch 0.902), train_loss = 2.36857005, grad/param norm = 3.0924e-01, time/batch = 0.6969s	
515/28500 (epoch 0.904), train_loss = 2.31909058, grad/param norm = 3.0148e-01, time/batch = 0.7035s	
516/28500 (epoch 0.905), train_loss = 2.51458656, grad/param norm = 3.8406e-01, time/batch = 0.6937s	
517/28500 (epoch 0.907), train_loss = 2.56885418, grad/param norm = 3.8532e-01, time/batch = 0.6937s	
518/28500 (epoch 0.909), train_loss = 2.50442098, grad/param norm = 4.3929e-01, time/batch = 0.6943s	
519/28500 (epoch 0.911), train_loss = 2.35675582, grad/param norm = 3.4390e-01, time/batch = 0.6959s	
520/28500 (epoch 0.912), train_loss = 2.14772161, grad/param norm = 3.3127e-01, time/batch = 0.6940s	
521/28500 (epoch 0.914), train_loss = 2.50288860, grad/param norm = 5.0835e-01, time/batch = 0.7215s	
522/28500 (epoch 0.916), train_loss = 2.39688333, grad/param norm = 5.9766e-01, time/batch = 0.7058s	
523/28500 (epoch 0.918), train_loss = 2.50208820, grad/param norm = 4.4847e-01, time/batch = 0.7010s	
524/28500 (epoch 0.919), train_loss = 2.26365766, grad/param norm = 3.2876e-01, time/batch = 0.6985s	
525/28500 (epoch 0.921), train_loss = 2.46544741, grad/param norm = 4.0142e-01, time/batch = 0.6979s	
526/28500 (epoch 0.923), train_loss = 2.57923428, grad/param norm = 5.0099e-01, time/batch = 0.6980s	
527/28500 (epoch 0.925), train_loss = 2.34079174, grad/param norm = 4.3795e-01, time/batch = 0.6951s	
528/28500 (epoch 0.926), train_loss = 2.46446974, grad/param norm = 4.3531e-01, time/batch = 0.7028s	
529/28500 (epoch 0.928), train_loss = 2.33273867, grad/param norm = 3.5453e-01, time/batch = 0.6935s	
530/28500 (epoch 0.930), train_loss = 2.14678792, grad/param norm = 3.2252e-01, time/batch = 0.6934s	
531/28500 (epoch 0.932), train_loss = 2.23427166, grad/param norm = 3.9831e-01, time/batch = 0.6950s	
532/28500 (epoch 0.933), train_loss = 2.37029719, grad/param norm = 4.7539e-01, time/batch = 0.6941s	
533/28500 (epoch 0.935), train_loss = 2.29678294, grad/param norm = 3.9154e-01, time/batch = 0.6941s	
534/28500 (epoch 0.937), train_loss = 2.43242610, grad/param norm = 4.1467e-01, time/batch = 0.6933s	
535/28500 (epoch 0.939), train_loss = 2.49511845, grad/param norm = 4.7294e-01, time/batch = 0.6983s	
536/28500 (epoch 0.940), train_loss = 2.44712881, grad/param norm = 4.8915e-01, time/batch = 0.6929s	
537/28500 (epoch 0.942), train_loss = 2.50221997, grad/param norm = 5.0772e-01, time/batch = 0.6924s	
538/28500 (epoch 0.944), train_loss = 2.38969203, grad/param norm = 5.2228e-01, time/batch = 0.6925s	
539/28500 (epoch 0.946), train_loss = 2.47286507, grad/param norm = 4.2057e-01, time/batch = 0.6944s	
540/28500 (epoch 0.947), train_loss = 2.54914473, grad/param norm = 3.4395e-01, time/batch = 0.6970s	
541/28500 (epoch 0.949), train_loss = 2.31952074, grad/param norm = 3.5208e-01, time/batch = 0.6976s	
542/28500 (epoch 0.951), train_loss = 2.42602336, grad/param norm = 3.1872e-01, time/batch = 0.6973s	
543/28500 (epoch 0.953), train_loss = 2.35398467, grad/param norm = 3.4479e-01, time/batch = 0.6966s	
544/28500 (epoch 0.954), train_loss = 2.35984527, grad/param norm = 2.9618e-01, time/batch = 0.6974s	
545/28500 (epoch 0.956), train_loss = 2.40120981, grad/param norm = 3.4448e-01, time/batch = 0.6967s	
546/28500 (epoch 0.958), train_loss = 2.27572088, grad/param norm = 3.2075e-01, time/batch = 0.6961s	
547/28500 (epoch 0.960), train_loss = 2.37652581, grad/param norm = 4.6953e-01, time/batch = 0.6944s	
548/28500 (epoch 0.961), train_loss = 2.48440771, grad/param norm = 4.9992e-01, time/batch = 0.6939s	
549/28500 (epoch 0.963), train_loss = 2.53028881, grad/param norm = 4.2102e-01, time/batch = 0.6932s	
550/28500 (epoch 0.965), train_loss = 2.42632304, grad/param norm = 8.1391e-01, time/batch = 0.7033s	
551/28500 (epoch 0.967), train_loss = 2.21759485, grad/param norm = 2.9462e-01, time/batch = 0.7090s	
552/28500 (epoch 0.968), train_loss = 2.23601245, grad/param norm = 2.9669e-01, time/batch = 0.6946s	
553/28500 (epoch 0.970), train_loss = 2.70361275, grad/param norm = 6.0619e-01, time/batch = 0.6981s	
554/28500 (epoch 0.972), train_loss = 2.71768358, grad/param norm = 4.8536e-01, time/batch = 0.7012s	
555/28500 (epoch 0.974), train_loss = 2.49942987, grad/param norm = 3.7289e-01, time/batch = 0.6934s	
556/28500 (epoch 0.975), train_loss = 2.33601120, grad/param norm = 4.2905e-01, time/batch = 0.6945s	
557/28500 (epoch 0.977), train_loss = 2.63423391, grad/param norm = 7.9043e-01, time/batch = 0.6968s	
558/28500 (epoch 0.979), train_loss = 2.35370404, grad/param norm = 5.4370e-01, time/batch = 0.6988s	
559/28500 (epoch 0.981), train_loss = 2.30899769, grad/param norm = 3.3972e-01, time/batch = 0.6948s	
560/28500 (epoch 0.982), train_loss = 2.19798620, grad/param norm = 3.1476e-01, time/batch = 0.6938s	
561/28500 (epoch 0.984), train_loss = 2.40367872, grad/param norm = 2.8025e-01, time/batch = 0.6968s	
562/28500 (epoch 0.986), train_loss = 2.33581500, grad/param norm = 2.6249e-01, time/batch = 0.6977s	
563/28500 (epoch 0.988), train_loss = 2.20267053, grad/param norm = 3.1377e-01, time/batch = 0.6975s	
564/28500 (epoch 0.989), train_loss = 2.38578817, grad/param norm = 3.5700e-01, time/batch = 0.6939s	
565/28500 (epoch 0.991), train_loss = 2.42758038, grad/param norm = 3.5471e-01, time/batch = 0.6932s	
566/28500 (epoch 0.993), train_loss = 2.48236350, grad/param norm = 3.3134e-01, time/batch = 0.6933s	
567/28500 (epoch 0.995), train_loss = 2.22238775, grad/param norm = 3.1449e-01, time/batch = 0.6930s	
568/28500 (epoch 0.996), train_loss = 2.31132835, grad/param norm = 3.6476e-01, time/batch = 0.6958s	
569/28500 (epoch 0.998), train_loss = 2.40817197, grad/param norm = 3.6764e-01, time/batch = 0.6961s	
570/28500 (epoch 1.000), train_loss = 2.27893997, grad/param norm = 3.0149e-01, time/batch = 0.6947s	
571/28500 (epoch 1.002), train_loss = 2.36529799, grad/param norm = 2.7590e-01, time/batch = 0.6951s	
572/28500 (epoch 1.004), train_loss = 2.31511300, grad/param norm = 3.4451e-01, time/batch = 0.6940s	
573/28500 (epoch 1.005), train_loss = 2.31175308, grad/param norm = 3.4416e-01, time/batch = 0.6937s	
574/28500 (epoch 1.007), train_loss = 2.19334990, grad/param norm = 3.1636e-01, time/batch = 0.6929s	
575/28500 (epoch 1.009), train_loss = 2.40191013, grad/param norm = 3.7101e-01, time/batch = 0.6953s	
576/28500 (epoch 1.011), train_loss = 2.39415323, grad/param norm = 4.6376e-01, time/batch = 0.6936s	
577/28500 (epoch 1.012), train_loss = 2.31321598, grad/param norm = 3.5970e-01, time/batch = 0.6943s	
578/28500 (epoch 1.014), train_loss = 2.28960407, grad/param norm = 3.2320e-01, time/batch = 0.6954s	
579/28500 (epoch 1.016), train_loss = 2.28884256, grad/param norm = 3.2277e-01, time/batch = 0.6935s	
580/28500 (epoch 1.018), train_loss = 2.28718485, grad/param norm = 4.1595e-01, time/batch = 0.6931s	
581/28500 (epoch 1.019), train_loss = 2.29016426, grad/param norm = 4.6749e-01, time/batch = 0.6983s	
582/28500 (epoch 1.021), train_loss = 2.19677228, grad/param norm = 4.9661e-01, time/batch = 0.6935s	
583/28500 (epoch 1.023), train_loss = 2.24608606, grad/param norm = 3.8727e-01, time/batch = 0.6934s	
584/28500 (epoch 1.025), train_loss = 2.10377686, grad/param norm = 3.3003e-01, time/batch = 0.6926s	
585/28500 (epoch 1.026), train_loss = 2.40683615, grad/param norm = 4.0641e-01, time/batch = 0.6922s	
586/28500 (epoch 1.028), train_loss = 2.31398087, grad/param norm = 4.0752e-01, time/batch = 0.6936s	
587/28500 (epoch 1.030), train_loss = 2.33963264, grad/param norm = 5.5521e-01, time/batch = 0.6944s	
588/28500 (epoch 1.032), train_loss = 2.39076458, grad/param norm = 7.7847e-01, time/batch = 0.6923s	
589/28500 (epoch 1.033), train_loss = 2.49502651, grad/param norm = 4.9114e-01, time/batch = 0.6921s	
590/28500 (epoch 1.035), train_loss = 2.31396007, grad/param norm = 3.1209e-01, time/batch = 0.6950s	
591/28500 (epoch 1.037), train_loss = 2.36116514, grad/param norm = 2.9245e-01, time/batch = 0.6981s	
592/28500 (epoch 1.039), train_loss = 2.41759865, grad/param norm = 3.0822e-01, time/batch = 0.7121s	
593/28500 (epoch 1.040), train_loss = 2.29229615, grad/param norm = 3.0147e-01, time/batch = 0.6974s	
594/28500 (epoch 1.042), train_loss = 2.49906577, grad/param norm = 3.4844e-01, time/batch = 0.6974s	
595/28500 (epoch 1.044), train_loss = 2.33300173, grad/param norm = 3.9364e-01, time/batch = 0.6955s	
596/28500 (epoch 1.046), train_loss = 2.39709176, grad/param norm = 3.2238e-01, time/batch = 0.6955s	
597/28500 (epoch 1.047), train_loss = 2.38612931, grad/param norm = 2.9729e-01, time/batch = 0.7177s	
598/28500 (epoch 1.049), train_loss = 2.31955342, grad/param norm = 3.3825e-01, time/batch = 0.7080s	
599/28500 (epoch 1.051), train_loss = 2.33292519, grad/param norm = 3.8046e-01, time/batch = 0.7012s	
600/28500 (epoch 1.053), train_loss = 2.43052538, grad/param norm = 4.4819e-01, time/batch = 0.7051s	
601/28500 (epoch 1.054), train_loss = 2.27735784, grad/param norm = 3.7945e-01, time/batch = 0.6968s	
602/28500 (epoch 1.056), train_loss = 2.29658006, grad/param norm = 3.2641e-01, time/batch = 0.6929s	
603/28500 (epoch 1.058), train_loss = 2.30280191, grad/param norm = 3.0633e-01, time/batch = 0.6960s	
604/28500 (epoch 1.060), train_loss = 2.21300226, grad/param norm = 3.3720e-01, time/batch = 0.6949s	
605/28500 (epoch 1.061), train_loss = 2.45557425, grad/param norm = 4.2360e-01, time/batch = 0.6947s	
606/28500 (epoch 1.063), train_loss = 2.48573858, grad/param norm = 3.5287e-01, time/batch = 0.6921s	
607/28500 (epoch 1.065), train_loss = 2.52709554, grad/param norm = 3.7395e-01, time/batch = 0.6929s	
608/28500 (epoch 1.067), train_loss = 2.30322333, grad/param norm = 5.0010e-01, time/batch = 0.7047s	
609/28500 (epoch 1.068), train_loss = 2.21600625, grad/param norm = 3.4554e-01, time/batch = 0.6955s	
610/28500 (epoch 1.070), train_loss = 2.38252050, grad/param norm = 3.4666e-01, time/batch = 0.6925s	
611/28500 (epoch 1.072), train_loss = 2.53169080, grad/param norm = 3.7561e-01, time/batch = 0.6967s	
612/28500 (epoch 1.074), train_loss = 2.36190355, grad/param norm = 3.4349e-01, time/batch = 0.6955s	
613/28500 (epoch 1.075), train_loss = 2.27196835, grad/param norm = 3.1977e-01, time/batch = 0.6928s	
614/28500 (epoch 1.077), train_loss = 2.32105269, grad/param norm = 3.2538e-01, time/batch = 0.6992s	
615/28500 (epoch 1.079), train_loss = 2.24418206, grad/param norm = 3.2070e-01, time/batch = 0.6970s	
616/28500 (epoch 1.081), train_loss = 2.35917275, grad/param norm = 2.9976e-01, time/batch = 0.6994s	
617/28500 (epoch 1.082), train_loss = 2.37471108, grad/param norm = 3.8657e-01, time/batch = 0.6925s	
618/28500 (epoch 1.084), train_loss = 2.38676213, grad/param norm = 3.3676e-01, time/batch = 0.6984s	
619/28500 (epoch 1.086), train_loss = 2.16758513, grad/param norm = 2.8855e-01, time/batch = 0.6966s	
620/28500 (epoch 1.088), train_loss = 2.18424696, grad/param norm = 3.1454e-01, time/batch = 0.6994s	
621/28500 (epoch 1.089), train_loss = 2.45591400, grad/param norm = 3.1981e-01, time/batch = 0.7006s	
622/28500 (epoch 1.091), train_loss = 2.25430768, grad/param norm = 3.9657e-01, time/batch = 0.6979s	
623/28500 (epoch 1.093), train_loss = 2.29852733, grad/param norm = 5.4665e-01, time/batch = 0.6962s	
624/28500 (epoch 1.095), train_loss = 2.41080476, grad/param norm = 5.7840e-01, time/batch = 0.6973s	
625/28500 (epoch 1.096), train_loss = 2.33287962, grad/param norm = 3.9223e-01, time/batch = 0.6968s	
626/28500 (epoch 1.098), train_loss = 2.47168503, grad/param norm = 2.9738e-01, time/batch = 0.6983s	
627/28500 (epoch 1.100), train_loss = 2.28411979, grad/param norm = 3.1810e-01, time/batch = 0.6989s	
628/28500 (epoch 1.102), train_loss = 2.40446294, grad/param norm = 2.5797e-01, time/batch = 0.6977s	
629/28500 (epoch 1.104), train_loss = 2.29006369, grad/param norm = 2.8928e-01, time/batch = 0.6968s	
630/28500 (epoch 1.105), train_loss = 2.25437640, grad/param norm = 4.2725e-01, time/batch = 0.6990s	
631/28500 (epoch 1.107), train_loss = 2.19526628, grad/param norm = 4.3065e-01, time/batch = 0.6996s	
632/28500 (epoch 1.109), train_loss = 2.24123585, grad/param norm = 3.3039e-01, time/batch = 0.6975s	
633/28500 (epoch 1.111), train_loss = 2.32780315, grad/param norm = 3.1175e-01, time/batch = 0.6976s	
634/28500 (epoch 1.112), train_loss = 2.36262628, grad/param norm = 2.7914e-01, time/batch = 0.6984s	
635/28500 (epoch 1.114), train_loss = 2.14678329, grad/param norm = 3.4256e-01, time/batch = 0.6967s	
636/28500 (epoch 1.116), train_loss = 2.37055999, grad/param norm = 4.0716e-01, time/batch = 0.6980s	
637/28500 (epoch 1.118), train_loss = 2.23107162, grad/param norm = 3.9944e-01, time/batch = 0.6954s	
638/28500 (epoch 1.119), train_loss = 2.39039720, grad/param norm = 3.8849e-01, time/batch = 0.6958s	
639/28500 (epoch 1.121), train_loss = 2.47999320, grad/param norm = 2.9390e-01, time/batch = 0.6955s	
640/28500 (epoch 1.123), train_loss = 2.25864451, grad/param norm = 3.8496e-01, time/batch = 0.6968s	
641/28500 (epoch 1.125), train_loss = 2.48118675, grad/param norm = 3.4035e-01, time/batch = 0.7006s	
642/28500 (epoch 1.126), train_loss = 2.29436970, grad/param norm = 3.4358e-01, time/batch = 0.6981s	
643/28500 (epoch 1.128), train_loss = 2.38198263, grad/param norm = 3.7550e-01, time/batch = 0.6974s	
644/28500 (epoch 1.130), train_loss = 2.40942489, grad/param norm = 3.2231e-01, time/batch = 0.6972s	
645/28500 (epoch 1.132), train_loss = 2.41506189, grad/param norm = 4.3488e-01, time/batch = 0.6989s	
646/28500 (epoch 1.133), train_loss = 2.27524011, grad/param norm = 2.9164e-01, time/batch = 0.6966s	
647/28500 (epoch 1.135), train_loss = 2.25621810, grad/param norm = 3.0765e-01, time/batch = 0.6975s	
648/28500 (epoch 1.137), train_loss = 2.21346459, grad/param norm = 3.6129e-01, time/batch = 0.6979s	
649/28500 (epoch 1.139), train_loss = 2.26780691, grad/param norm = 3.6147e-01, time/batch = 0.6969s	
650/28500 (epoch 1.140), train_loss = 2.25854118, grad/param norm = 3.8893e-01, time/batch = 0.6970s	
651/28500 (epoch 1.142), train_loss = 2.37882388, grad/param norm = 3.4521e-01, time/batch = 0.7065s	
652/28500 (epoch 1.144), train_loss = 2.24201241, grad/param norm = 3.4357e-01, time/batch = 0.6966s	
653/28500 (epoch 1.146), train_loss = 2.20679580, grad/param norm = 3.8793e-01, time/batch = 0.6977s	
654/28500 (epoch 1.147), train_loss = 2.17799851, grad/param norm = 2.6974e-01, time/batch = 0.6981s	
655/28500 (epoch 1.149), train_loss = 2.19609899, grad/param norm = 2.6865e-01, time/batch = 0.6973s	
656/28500 (epoch 1.151), train_loss = 2.19999388, grad/param norm = 2.9231e-01, time/batch = 0.6959s	
657/28500 (epoch 1.153), train_loss = 2.27221050, grad/param norm = 3.7438e-01, time/batch = 0.7006s	
658/28500 (epoch 1.154), train_loss = 2.25825243, grad/param norm = 3.1871e-01, time/batch = 0.6969s	
659/28500 (epoch 1.156), train_loss = 2.46198675, grad/param norm = 2.7296e-01, time/batch = 0.7002s	
660/28500 (epoch 1.158), train_loss = 2.26672700, grad/param norm = 2.8729e-01, time/batch = 0.7000s	
661/28500 (epoch 1.160), train_loss = 2.15479864, grad/param norm = 3.1899e-01, time/batch = 0.7067s	
662/28500 (epoch 1.161), train_loss = 2.32340343, grad/param norm = 3.5270e-01, time/batch = 0.7072s	
663/28500 (epoch 1.163), train_loss = 2.20661723, grad/param norm = 3.6989e-01, time/batch = 0.7026s	
664/28500 (epoch 1.165), train_loss = 2.35853548, grad/param norm = 3.0044e-01, time/batch = 0.6960s	
665/28500 (epoch 1.167), train_loss = 2.34937318, grad/param norm = 2.9405e-01, time/batch = 0.6950s	
666/28500 (epoch 1.168), train_loss = 2.33537573, grad/param norm = 3.0729e-01, time/batch = 0.6962s	
667/28500 (epoch 1.170), train_loss = 2.43223677, grad/param norm = 3.2537e-01, time/batch = 0.6938s	
668/28500 (epoch 1.172), train_loss = 2.28594293, grad/param norm = 2.9700e-01, time/batch = 0.6938s	
669/28500 (epoch 1.174), train_loss = 2.36604143, grad/param norm = 2.8518e-01, time/batch = 0.6926s	
670/28500 (epoch 1.175), train_loss = 2.27405091, grad/param norm = 2.7032e-01, time/batch = 0.6923s	
671/28500 (epoch 1.177), train_loss = 2.34006069, grad/param norm = 2.7206e-01, time/batch = 0.6994s	
672/28500 (epoch 1.179), train_loss = 2.23499191, grad/param norm = 3.3013e-01, time/batch = 0.6933s	
673/28500 (epoch 1.181), train_loss = 2.37399233, grad/param norm = 3.5060e-01, time/batch = 0.6923s	
674/28500 (epoch 1.182), train_loss = 2.28841361, grad/param norm = 4.1383e-01, time/batch = 0.6931s	
675/28500 (epoch 1.184), train_loss = 2.29370042, grad/param norm = 4.4482e-01, time/batch = 0.6934s	
676/28500 (epoch 1.186), train_loss = 2.30878967, grad/param norm = 4.1899e-01, time/batch = 0.6975s	
677/28500 (epoch 1.188), train_loss = 2.26951117, grad/param norm = 3.3161e-01, time/batch = 0.7019s	
678/28500 (epoch 1.189), train_loss = 2.41324404, grad/param norm = 3.4532e-01, time/batch = 0.6984s	
679/28500 (epoch 1.191), train_loss = 2.38739724, grad/param norm = 3.1061e-01, time/batch = 0.6943s	
680/28500 (epoch 1.193), train_loss = 2.25354711, grad/param norm = 2.6500e-01, time/batch = 0.6995s	
681/28500 (epoch 1.195), train_loss = 2.31946966, grad/param norm = 3.3502e-01, time/batch = 0.6960s	
682/28500 (epoch 1.196), train_loss = 2.27849641, grad/param norm = 3.7056e-01, time/batch = 0.6949s	
683/28500 (epoch 1.198), train_loss = 2.20855958, grad/param norm = 4.6690e-01, time/batch = 0.6931s	
684/28500 (epoch 1.200), train_loss = 2.29414196, grad/param norm = 3.7562e-01, time/batch = 0.6928s	
685/28500 (epoch 1.202), train_loss = 2.33830032, grad/param norm = 3.2138e-01, time/batch = 0.6937s	
686/28500 (epoch 1.204), train_loss = 2.07848012, grad/param norm = 2.8492e-01, time/batch = 0.6951s	
687/28500 (epoch 1.205), train_loss = 2.17493936, grad/param norm = 2.9121e-01, time/batch = 0.7016s	
688/28500 (epoch 1.207), train_loss = 2.30237642, grad/param norm = 2.6914e-01, time/batch = 0.7061s	
689/28500 (epoch 1.209), train_loss = 2.20272808, grad/param norm = 2.8192e-01, time/batch = 0.6957s	
690/28500 (epoch 1.211), train_loss = 2.27543512, grad/param norm = 2.6477e-01, time/batch = 0.6937s	
691/28500 (epoch 1.212), train_loss = 2.14819135, grad/param norm = 3.0042e-01, time/batch = 0.6982s	
692/28500 (epoch 1.214), train_loss = 2.32718452, grad/param norm = 3.0708e-01, time/batch = 0.6956s	
693/28500 (epoch 1.216), train_loss = 2.20187432, grad/param norm = 2.8554e-01, time/batch = 0.6944s	
694/28500 (epoch 1.218), train_loss = 2.18995037, grad/param norm = 3.0565e-01, time/batch = 0.6934s	
695/28500 (epoch 1.219), train_loss = 2.19230086, grad/param norm = 3.1461e-01, time/batch = 0.7033s	
696/28500 (epoch 1.221), train_loss = 2.15090017, grad/param norm = 2.7165e-01, time/batch = 0.6965s	
697/28500 (epoch 1.223), train_loss = 2.30931058, grad/param norm = 3.3827e-01, time/batch = 0.6971s	
698/28500 (epoch 1.225), train_loss = 2.40206507, grad/param norm = 3.8931e-01, time/batch = 0.6975s	
699/28500 (epoch 1.226), train_loss = 2.32313893, grad/param norm = 3.0699e-01, time/batch = 0.6970s	
700/28500 (epoch 1.228), train_loss = 2.32928434, grad/param norm = 3.1507e-01, time/batch = 0.6960s	
701/28500 (epoch 1.230), train_loss = 2.20634632, grad/param norm = 3.4050e-01, time/batch = 0.6988s	
702/28500 (epoch 1.232), train_loss = 2.28532135, grad/param norm = 3.9441e-01, time/batch = 0.6963s	
703/28500 (epoch 1.233), train_loss = 2.28017093, grad/param norm = 5.2951e-01, time/batch = 0.6957s	
704/28500 (epoch 1.235), train_loss = 2.21871858, grad/param norm = 4.2654e-01, time/batch = 0.6961s	
705/28500 (epoch 1.237), train_loss = 2.15959660, grad/param norm = 2.9170e-01, time/batch = 0.6968s	
706/28500 (epoch 1.239), train_loss = 2.18163256, grad/param norm = 3.2089e-01, time/batch = 0.6958s	
707/28500 (epoch 1.240), train_loss = 2.22581712, grad/param norm = 3.0316e-01, time/batch = 0.6970s	
708/28500 (epoch 1.242), train_loss = 2.29685861, grad/param norm = 3.3048e-01, time/batch = 0.6963s	
709/28500 (epoch 1.244), train_loss = 2.28665298, grad/param norm = 3.4197e-01, time/batch = 0.6996s	
710/28500 (epoch 1.246), train_loss = 2.21420367, grad/param norm = 3.7317e-01, time/batch = 0.6971s	
711/28500 (epoch 1.247), train_loss = 2.34867382, grad/param norm = 4.0731e-01, time/batch = 0.6989s	
712/28500 (epoch 1.249), train_loss = 2.26352658, grad/param norm = 3.7978e-01, time/batch = 0.7001s	
713/28500 (epoch 1.251), train_loss = 2.06255949, grad/param norm = 3.6021e-01, time/batch = 0.6981s	
714/28500 (epoch 1.253), train_loss = 2.27236213, grad/param norm = 3.6977e-01, time/batch = 0.6979s	
715/28500 (epoch 1.254), train_loss = 2.27021110, grad/param norm = 3.2146e-01, time/batch = 0.6963s	
716/28500 (epoch 1.256), train_loss = 2.24958986, grad/param norm = 3.4672e-01, time/batch = 0.6968s	
717/28500 (epoch 1.258), train_loss = 2.23776634, grad/param norm = 3.4386e-01, time/batch = 0.7056s	
718/28500 (epoch 1.260), train_loss = 2.19323486, grad/param norm = 2.7847e-01, time/batch = 0.7181s	
719/28500 (epoch 1.261), train_loss = 2.17999655, grad/param norm = 2.8525e-01, time/batch = 0.7035s	
720/28500 (epoch 1.263), train_loss = 2.31243519, grad/param norm = 3.0552e-01, time/batch = 0.6995s	
721/28500 (epoch 1.265), train_loss = 2.38226766, grad/param norm = 3.0620e-01, time/batch = 0.7024s	
722/28500 (epoch 1.267), train_loss = 2.32019006, grad/param norm = 3.0693e-01, time/batch = 0.6981s	
723/28500 (epoch 1.268), train_loss = 2.23680538, grad/param norm = 2.8329e-01, time/batch = 0.6984s	
724/28500 (epoch 1.270), train_loss = 2.17902764, grad/param norm = 2.6947e-01, time/batch = 0.7138s	
725/28500 (epoch 1.272), train_loss = 2.19755570, grad/param norm = 3.0256e-01, time/batch = 0.6983s	
726/28500 (epoch 1.274), train_loss = 2.28929538, grad/param norm = 2.8344e-01, time/batch = 0.6983s	
727/28500 (epoch 1.275), train_loss = 2.22681632, grad/param norm = 2.5362e-01, time/batch = 0.6959s	
728/28500 (epoch 1.277), train_loss = 2.26025614, grad/param norm = 2.8604e-01, time/batch = 0.6970s	
729/28500 (epoch 1.279), train_loss = 2.21887350, grad/param norm = 3.1074e-01, time/batch = 0.6964s	
730/28500 (epoch 1.281), train_loss = 2.21405155, grad/param norm = 3.9979e-01, time/batch = 0.6970s	
731/28500 (epoch 1.282), train_loss = 2.13909156, grad/param norm = 3.7968e-01, time/batch = 0.6998s	
732/28500 (epoch 1.284), train_loss = 2.26457314, grad/param norm = 3.4171e-01, time/batch = 0.6980s	
733/28500 (epoch 1.286), train_loss = 2.34643841, grad/param norm = 3.5747e-01, time/batch = 0.6964s	
734/28500 (epoch 1.288), train_loss = 2.16088143, grad/param norm = 3.0232e-01, time/batch = 0.6970s	
735/28500 (epoch 1.289), train_loss = 2.43036267, grad/param norm = 2.7870e-01, time/batch = 0.6966s	
736/28500 (epoch 1.291), train_loss = 2.06641258, grad/param norm = 3.0212e-01, time/batch = 0.6960s	
737/28500 (epoch 1.293), train_loss = 2.16624477, grad/param norm = 3.0371e-01, time/batch = 0.6963s	
738/28500 (epoch 1.295), train_loss = 2.18920198, grad/param norm = 3.3479e-01, time/batch = 0.6961s	
739/28500 (epoch 1.296), train_loss = 2.18336812, grad/param norm = 4.0034e-01, time/batch = 0.6970s	
740/28500 (epoch 1.298), train_loss = 2.17542974, grad/param norm = 4.3131e-01, time/batch = 0.6965s	
741/28500 (epoch 1.300), train_loss = 2.11095644, grad/param norm = 4.0567e-01, time/batch = 0.7012s	
742/28500 (epoch 1.302), train_loss = 2.18168778, grad/param norm = 3.7329e-01, time/batch = 0.6997s	
743/28500 (epoch 1.304), train_loss = 2.08576096, grad/param norm = 2.7669e-01, time/batch = 0.6981s	
744/28500 (epoch 1.305), train_loss = 2.22842166, grad/param norm = 2.6491e-01, time/batch = 0.6966s	
745/28500 (epoch 1.307), train_loss = 2.28943961, grad/param norm = 3.4737e-01, time/batch = 0.7004s	
746/28500 (epoch 1.309), train_loss = 2.29615717, grad/param norm = 3.3777e-01, time/batch = 0.6967s	
747/28500 (epoch 1.311), train_loss = 2.12983340, grad/param norm = 3.2048e-01, time/batch = 0.6975s	
748/28500 (epoch 1.312), train_loss = 1.98979549, grad/param norm = 2.7892e-01, time/batch = 0.6939s	
749/28500 (epoch 1.314), train_loss = 2.12006604, grad/param norm = 3.2534e-01, time/batch = 0.6928s	
750/28500 (epoch 1.316), train_loss = 2.16238927, grad/param norm = 2.9859e-01, time/batch = 0.6930s	
751/28500 (epoch 1.318), train_loss = 2.17332217, grad/param norm = 3.2270e-01, time/batch = 0.6966s	
752/28500 (epoch 1.319), train_loss = 2.19288287, grad/param norm = 3.5244e-01, time/batch = 0.6935s	
753/28500 (epoch 1.321), train_loss = 2.29195602, grad/param norm = 2.9939e-01, time/batch = 0.6929s	
754/28500 (epoch 1.323), train_loss = 2.22253732, grad/param norm = 2.7380e-01, time/batch = 0.6931s	
755/28500 (epoch 1.325), train_loss = 2.37114564, grad/param norm = 3.2135e-01, time/batch = 0.6953s	
756/28500 (epoch 1.326), train_loss = 2.39555701, grad/param norm = 3.7473e-01, time/batch = 0.6936s	
757/28500 (epoch 1.328), train_loss = 2.10070539, grad/param norm = 3.6313e-01, time/batch = 0.6948s	
758/28500 (epoch 1.330), train_loss = 2.13530916, grad/param norm = 2.9908e-01, time/batch = 0.6948s	
759/28500 (epoch 1.332), train_loss = 2.12235494, grad/param norm = 2.7231e-01, time/batch = 0.6924s	
760/28500 (epoch 1.333), train_loss = 2.06991005, grad/param norm = 2.9913e-01, time/batch = 0.6928s	
761/28500 (epoch 1.335), train_loss = 2.02643150, grad/param norm = 2.9974e-01, time/batch = 0.6968s	
762/28500 (epoch 1.337), train_loss = 2.22953906, grad/param norm = 3.6172e-01, time/batch = 0.6986s	
763/28500 (epoch 1.339), train_loss = 2.20249475, grad/param norm = 3.3132e-01, time/batch = 0.7116s	
764/28500 (epoch 1.340), train_loss = 2.21488287, grad/param norm = 3.6876e-01, time/batch = 0.6932s	
765/28500 (epoch 1.342), train_loss = 2.08716249, grad/param norm = 4.7581e-01, time/batch = 0.6962s	
766/28500 (epoch 1.344), train_loss = 2.15145540, grad/param norm = 4.7045e-01, time/batch = 0.6969s	
767/28500 (epoch 1.346), train_loss = 1.99680852, grad/param norm = 5.5206e-01, time/batch = 0.7002s	
768/28500 (epoch 1.347), train_loss = 2.18456904, grad/param norm = 3.1193e-01, time/batch = 0.7000s	
769/28500 (epoch 1.349), train_loss = 2.08861783, grad/param norm = 2.7406e-01, time/batch = 0.6930s	
770/28500 (epoch 1.351), train_loss = 2.04503591, grad/param norm = 2.6010e-01, time/batch = 0.6940s	
771/28500 (epoch 1.353), train_loss = 2.22306004, grad/param norm = 2.5439e-01, time/batch = 0.6976s	
772/28500 (epoch 1.354), train_loss = 2.15339447, grad/param norm = 2.6225e-01, time/batch = 0.6970s	
773/28500 (epoch 1.356), train_loss = 2.11227008, grad/param norm = 3.0106e-01, time/batch = 0.6965s	
774/28500 (epoch 1.358), train_loss = 2.20653086, grad/param norm = 2.8024e-01, time/batch = 0.6965s	
775/28500 (epoch 1.360), train_loss = 2.22973230, grad/param norm = 2.9303e-01, time/batch = 0.6951s	
776/28500 (epoch 1.361), train_loss = 2.20393563, grad/param norm = 3.0331e-01, time/batch = 0.6947s	
777/28500 (epoch 1.363), train_loss = 2.02512253, grad/param norm = 3.0624e-01, time/batch = 0.6966s	
778/28500 (epoch 1.365), train_loss = 2.10264372, grad/param norm = 2.4402e-01, time/batch = 0.6957s	
779/28500 (epoch 1.367), train_loss = 2.18132981, grad/param norm = 3.3397e-01, time/batch = 0.6960s	
780/28500 (epoch 1.368), train_loss = 2.10631775, grad/param norm = 3.2458e-01, time/batch = 0.6974s	
781/28500 (epoch 1.370), train_loss = 2.17645084, grad/param norm = 2.9256e-01, time/batch = 0.7037s	
782/28500 (epoch 1.372), train_loss = 2.12597400, grad/param norm = 2.8696e-01, time/batch = 0.6902s	
783/28500 (epoch 1.374), train_loss = 2.22484971, grad/param norm = 3.2808e-01, time/batch = 0.7032s	
784/28500 (epoch 1.375), train_loss = 2.21662409, grad/param norm = 3.2813e-01, time/batch = 0.7071s	
785/28500 (epoch 1.377), train_loss = 2.20594444, grad/param norm = 3.0835e-01, time/batch = 0.6857s	
786/28500 (epoch 1.379), train_loss = 1.96399245, grad/param norm = 2.9088e-01, time/batch = 0.6802s	
787/28500 (epoch 1.381), train_loss = 2.09035385, grad/param norm = 2.9855e-01, time/batch = 0.6827s	
788/28500 (epoch 1.382), train_loss = 2.15593320, grad/param norm = 3.0178e-01, time/batch = 0.6782s	
789/28500 (epoch 1.384), train_loss = 2.20739989, grad/param norm = 3.4656e-01, time/batch = 0.6936s	
790/28500 (epoch 1.386), train_loss = 1.99839935, grad/param norm = 2.7954e-01, time/batch = 0.6964s	
791/28500 (epoch 1.388), train_loss = 2.21582231, grad/param norm = 3.2890e-01, time/batch = 0.6851s	
792/28500 (epoch 1.389), train_loss = 2.14377121, grad/param norm = 3.5426e-01, time/batch = 0.6791s	
793/28500 (epoch 1.391), train_loss = 2.14654849, grad/param norm = 3.5948e-01, time/batch = 0.6847s	
794/28500 (epoch 1.393), train_loss = 1.98235815, grad/param norm = 3.7261e-01, time/batch = 0.6807s	
795/28500 (epoch 1.395), train_loss = 2.33377404, grad/param norm = 3.4624e-01, time/batch = 0.6827s	
796/28500 (epoch 1.396), train_loss = 2.28226073, grad/param norm = 3.3839e-01, time/batch = 0.6789s	
797/28500 (epoch 1.398), train_loss = 2.13643446, grad/param norm = 3.5123e-01, time/batch = 0.6777s	
798/28500 (epoch 1.400), train_loss = 2.19984412, grad/param norm = 2.6224e-01, time/batch = 0.6864s	
799/28500 (epoch 1.402), train_loss = 2.14505945, grad/param norm = 2.6613e-01, time/batch = 0.6867s	
800/28500 (epoch 1.404), train_loss = 2.27395580, grad/param norm = 2.9549e-01, time/batch = 0.6815s	
801/28500 (epoch 1.405), train_loss = 2.21236257, grad/param norm = 3.2010e-01, time/batch = 0.6807s	
802/28500 (epoch 1.407), train_loss = 2.18509022, grad/param norm = 2.6448e-01, time/batch = 0.6799s	
803/28500 (epoch 1.409), train_loss = 2.19594704, grad/param norm = 2.7466e-01, time/batch = 0.6774s	
804/28500 (epoch 1.411), train_loss = 2.19435908, grad/param norm = 2.7714e-01, time/batch = 0.6778s	
805/28500 (epoch 1.412), train_loss = 2.25513659, grad/param norm = 3.2596e-01, time/batch = 0.6815s	
806/28500 (epoch 1.414), train_loss = 2.24247786, grad/param norm = 3.5561e-01, time/batch = 0.6799s	
807/28500 (epoch 1.416), train_loss = 2.07059575, grad/param norm = 4.2362e-01, time/batch = 0.6804s	
808/28500 (epoch 1.418), train_loss = 2.20494936, grad/param norm = 3.7306e-01, time/batch = 0.6781s	
809/28500 (epoch 1.419), train_loss = 2.22240890, grad/param norm = 3.0433e-01, time/batch = 0.6891s	
810/28500 (epoch 1.421), train_loss = 2.14906677, grad/param norm = 2.8012e-01, time/batch = 0.6928s	
811/28500 (epoch 1.423), train_loss = 2.29009904, grad/param norm = 3.1213e-01, time/batch = 0.6805s	
812/28500 (epoch 1.425), train_loss = 2.22322651, grad/param norm = 2.8958e-01, time/batch = 0.6797s	
813/28500 (epoch 1.426), train_loss = 2.22433436, grad/param norm = 3.2169e-01, time/batch = 0.6801s	
814/28500 (epoch 1.428), train_loss = 2.29601880, grad/param norm = 3.0012e-01, time/batch = 0.6770s	
815/28500 (epoch 1.430), train_loss = 2.16454646, grad/param norm = 3.0274e-01, time/batch = 0.6770s	
816/28500 (epoch 1.432), train_loss = 2.30297253, grad/param norm = 3.3306e-01, time/batch = 0.6776s	
817/28500 (epoch 1.433), train_loss = 2.09859151, grad/param norm = 3.5177e-01, time/batch = 0.6789s	
818/28500 (epoch 1.435), train_loss = 2.07041802, grad/param norm = 3.3264e-01, time/batch = 0.6768s	
819/28500 (epoch 1.437), train_loss = 2.01963954, grad/param norm = 3.5324e-01, time/batch = 0.6774s	
820/28500 (epoch 1.439), train_loss = 2.10783459, grad/param norm = 3.5907e-01, time/batch = 0.6779s	
821/28500 (epoch 1.440), train_loss = 2.13814805, grad/param norm = 2.9345e-01, time/batch = 0.6793s	
822/28500 (epoch 1.442), train_loss = 2.08577125, grad/param norm = 3.0607e-01, time/batch = 0.6783s	
823/28500 (epoch 1.444), train_loss = 2.10438637, grad/param norm = 2.9590e-01, time/batch = 0.6789s	
824/28500 (epoch 1.446), train_loss = 1.98072758, grad/param norm = 3.2411e-01, time/batch = 0.6786s	
825/28500 (epoch 1.447), train_loss = 2.02214493, grad/param norm = 2.6001e-01, time/batch = 0.6770s	
826/28500 (epoch 1.449), train_loss = 2.14253979, grad/param norm = 3.7672e-01, time/batch = 0.6766s	
827/28500 (epoch 1.451), train_loss = 2.19934205, grad/param norm = 3.5924e-01, time/batch = 0.6776s	
828/28500 (epoch 1.453), train_loss = 2.15109413, grad/param norm = 3.0363e-01, time/batch = 0.6775s	
829/28500 (epoch 1.454), train_loss = 2.04677389, grad/param norm = 3.1520e-01, time/batch = 0.6823s	
830/28500 (epoch 1.456), train_loss = 2.31101052, grad/param norm = 3.9740e-01, time/batch = 0.6783s	
831/28500 (epoch 1.458), train_loss = 2.13737604, grad/param norm = 3.7473e-01, time/batch = 0.6781s	
832/28500 (epoch 1.460), train_loss = 2.23028651, grad/param norm = 3.1327e-01, time/batch = 0.6762s	
833/28500 (epoch 1.461), train_loss = 2.17064284, grad/param norm = 2.8538e-01, time/batch = 0.6858s	
834/28500 (epoch 1.463), train_loss = 2.07036703, grad/param norm = 2.7839e-01, time/batch = 0.6913s	
835/28500 (epoch 1.465), train_loss = 1.99954994, grad/param norm = 2.9859e-01, time/batch = 0.6821s	
836/28500 (epoch 1.467), train_loss = 2.27620898, grad/param norm = 3.0546e-01, time/batch = 0.6813s	
837/28500 (epoch 1.468), train_loss = 2.01493499, grad/param norm = 2.6269e-01, time/batch = 0.6774s	
838/28500 (epoch 1.470), train_loss = 2.18674676, grad/param norm = 2.8681e-01, time/batch = 0.6764s	
839/28500 (epoch 1.472), train_loss = 2.07320706, grad/param norm = 3.4593e-01, time/batch = 0.6768s	
840/28500 (epoch 1.474), train_loss = 2.30635941, grad/param norm = 4.4077e-01, time/batch = 0.6794s	
841/28500 (epoch 1.475), train_loss = 2.15020507, grad/param norm = 4.5980e-01, time/batch = 0.6826s	
842/28500 (epoch 1.477), train_loss = 2.10340892, grad/param norm = 4.1174e-01, time/batch = 0.6787s	
843/28500 (epoch 1.479), train_loss = 2.18197242, grad/param norm = 2.9148e-01, time/batch = 0.6765s	
844/28500 (epoch 1.481), train_loss = 2.15122154, grad/param norm = 2.4907e-01, time/batch = 0.6773s	
845/28500 (epoch 1.482), train_loss = 2.15870030, grad/param norm = 2.8295e-01, time/batch = 0.6815s	
846/28500 (epoch 1.484), train_loss = 2.01678380, grad/param norm = 3.6706e-01, time/batch = 0.6784s	
847/28500 (epoch 1.486), train_loss = 2.13474536, grad/param norm = 3.4796e-01, time/batch = 0.6755s	
848/28500 (epoch 1.488), train_loss = 2.04978755, grad/param norm = 3.9640e-01, time/batch = 0.6793s	
849/28500 (epoch 1.489), train_loss = 2.18758499, grad/param norm = 4.2802e-01, time/batch = 0.6888s	
850/28500 (epoch 1.491), train_loss = 2.07595264, grad/param norm = 3.9122e-01, time/batch = 0.6970s	
851/28500 (epoch 1.493), train_loss = 2.04125314, grad/param norm = 2.7246e-01, time/batch = 0.6962s	
852/28500 (epoch 1.495), train_loss = 2.06899446, grad/param norm = 2.4739e-01, time/batch = 0.6919s	
853/28500 (epoch 1.496), train_loss = 2.23957544, grad/param norm = 2.8774e-01, time/batch = 0.6985s	
854/28500 (epoch 1.498), train_loss = 2.15001449, grad/param norm = 3.0339e-01, time/batch = 0.6904s	
855/28500 (epoch 1.500), train_loss = 2.12977219, grad/param norm = 2.6517e-01, time/batch = 0.7062s	
856/28500 (epoch 1.502), train_loss = 2.15506529, grad/param norm = 2.7430e-01, time/batch = 0.7137s	
857/28500 (epoch 1.504), train_loss = 2.09603840, grad/param norm = 2.6188e-01, time/batch = 0.7080s	
858/28500 (epoch 1.505), train_loss = 2.08875981, grad/param norm = 2.8523e-01, time/batch = 0.6945s	
859/28500 (epoch 1.507), train_loss = 2.36657894, grad/param norm = 3.0561e-01, time/batch = 0.6947s	
860/28500 (epoch 1.509), train_loss = 2.09955842, grad/param norm = 3.3903e-01, time/batch = 0.6945s	
861/28500 (epoch 1.511), train_loss = 2.31172760, grad/param norm = 3.5351e-01, time/batch = 0.6978s	
862/28500 (epoch 1.512), train_loss = 2.12873663, grad/param norm = 3.3276e-01, time/batch = 0.6984s	
863/28500 (epoch 1.514), train_loss = 2.05508127, grad/param norm = 2.5043e-01, time/batch = 0.6936s	
864/28500 (epoch 1.516), train_loss = 2.09544213, grad/param norm = 2.7114e-01, time/batch = 0.6959s	
865/28500 (epoch 1.518), train_loss = 2.04631697, grad/param norm = 2.4859e-01, time/batch = 0.6922s	
866/28500 (epoch 1.519), train_loss = 2.27236691, grad/param norm = 3.3633e-01, time/batch = 0.6939s	
867/28500 (epoch 1.521), train_loss = 2.25469274, grad/param norm = 3.4851e-01, time/batch = 0.6931s	
868/28500 (epoch 1.523), train_loss = 2.13493603, grad/param norm = 3.3994e-01, time/batch = 0.6947s	
869/28500 (epoch 1.525), train_loss = 2.17167884, grad/param norm = 2.8295e-01, time/batch = 0.6941s	
870/28500 (epoch 1.526), train_loss = 2.03235305, grad/param norm = 2.8130e-01, time/batch = 0.6936s	
871/28500 (epoch 1.528), train_loss = 2.24520642, grad/param norm = 3.4445e-01, time/batch = 0.6966s	
872/28500 (epoch 1.530), train_loss = 2.12212006, grad/param norm = 2.9014e-01, time/batch = 0.7066s	
873/28500 (epoch 1.532), train_loss = 2.06399738, grad/param norm = 3.5370e-01, time/batch = 0.7054s	
874/28500 (epoch 1.533), train_loss = 2.23478470, grad/param norm = 3.0733e-01, time/batch = 0.6934s	
875/28500 (epoch 1.535), train_loss = 1.97378675, grad/param norm = 2.4650e-01, time/batch = 0.6941s	
876/28500 (epoch 1.537), train_loss = 1.90458249, grad/param norm = 2.6303e-01, time/batch = 0.6953s	
877/28500 (epoch 1.539), train_loss = 2.08414226, grad/param norm = 2.5191e-01, time/batch = 0.6939s	
878/28500 (epoch 1.540), train_loss = 2.08116434, grad/param norm = 3.0974e-01, time/batch = 0.6952s	
879/28500 (epoch 1.542), train_loss = 2.39946973, grad/param norm = 4.1594e-01, time/batch = 0.6942s	
880/28500 (epoch 1.544), train_loss = 2.23067704, grad/param norm = 4.7217e-01, time/batch = 0.6964s	
881/28500 (epoch 1.546), train_loss = 2.22947536, grad/param norm = 3.7740e-01, time/batch = 0.7149s	
882/28500 (epoch 1.547), train_loss = 2.17932723, grad/param norm = 3.0522e-01, time/batch = 0.6981s	
883/28500 (epoch 1.549), train_loss = 2.04672303, grad/param norm = 2.6226e-01, time/batch = 0.6971s	
884/28500 (epoch 1.551), train_loss = 2.32293674, grad/param norm = 2.9704e-01, time/batch = 0.6946s	
885/28500 (epoch 1.553), train_loss = 2.28612678, grad/param norm = 2.6393e-01, time/batch = 0.7032s	
886/28500 (epoch 1.554), train_loss = 2.13842933, grad/param norm = 2.5775e-01, time/batch = 0.6934s	
887/28500 (epoch 1.556), train_loss = 2.18840442, grad/param norm = 2.7741e-01, time/batch = 0.6934s	
888/28500 (epoch 1.558), train_loss = 2.16754517, grad/param norm = 2.7777e-01, time/batch = 0.6940s	
889/28500 (epoch 1.560), train_loss = 2.13738098, grad/param norm = 2.6562e-01, time/batch = 0.6938s	
890/28500 (epoch 1.561), train_loss = 2.18957261, grad/param norm = 2.6294e-01, time/batch = 0.7055s	
891/28500 (epoch 1.563), train_loss = 2.14273064, grad/param norm = 2.7298e-01, time/batch = 0.7072s	
892/28500 (epoch 1.565), train_loss = 2.12895548, grad/param norm = 3.3114e-01, time/batch = 0.6968s	
893/28500 (epoch 1.567), train_loss = 2.02613146, grad/param norm = 3.5105e-01, time/batch = 0.6991s	
894/28500 (epoch 1.568), train_loss = 2.22250569, grad/param norm = 2.9140e-01, time/batch = 0.6959s	
895/28500 (epoch 1.570), train_loss = 2.11036568, grad/param norm = 3.9613e-01, time/batch = 0.6931s	
896/28500 (epoch 1.572), train_loss = 2.12845730, grad/param norm = 3.5374e-01, time/batch = 0.6941s	
897/28500 (epoch 1.574), train_loss = 2.20326853, grad/param norm = 2.8502e-01, time/batch = 0.6899s	
898/28500 (epoch 1.575), train_loss = 1.99117318, grad/param norm = 2.8617e-01, time/batch = 0.6817s	
899/28500 (epoch 1.577), train_loss = 2.01453332, grad/param norm = 3.3838e-01, time/batch = 0.6819s	
900/28500 (epoch 1.579), train_loss = 2.35888368, grad/param norm = 3.5859e-01, time/batch = 0.6996s	
901/28500 (epoch 1.581), train_loss = 2.04201380, grad/param norm = 3.3042e-01, time/batch = 0.6896s	
902/28500 (epoch 1.582), train_loss = 2.15708611, grad/param norm = 3.3089e-01, time/batch = 0.6863s	
903/28500 (epoch 1.584), train_loss = 2.03660053, grad/param norm = 2.7802e-01, time/batch = 0.6830s	
904/28500 (epoch 1.586), train_loss = 1.87250256, grad/param norm = 2.6280e-01, time/batch = 0.6820s	
905/28500 (epoch 1.588), train_loss = 2.04274917, grad/param norm = 3.2983e-01, time/batch = 0.6829s	
906/28500 (epoch 1.589), train_loss = 2.45566124, grad/param norm = 3.1652e-01, time/batch = 0.6849s	
907/28500 (epoch 1.591), train_loss = 2.16757009, grad/param norm = 2.5968e-01, time/batch = 0.6811s	
908/28500 (epoch 1.593), train_loss = 2.03394327, grad/param norm = 2.9316e-01, time/batch = 0.6817s	
909/28500 (epoch 1.595), train_loss = 2.29245609, grad/param norm = 3.3190e-01, time/batch = 0.6964s	
910/28500 (epoch 1.596), train_loss = 2.16495744, grad/param norm = 4.1138e-01, time/batch = 0.6940s	
911/28500 (epoch 1.598), train_loss = 2.11013254, grad/param norm = 3.1877e-01, time/batch = 0.6849s	
912/28500 (epoch 1.600), train_loss = 2.12335028, grad/param norm = 2.6744e-01, time/batch = 0.6837s	
913/28500 (epoch 1.602), train_loss = 2.25654842, grad/param norm = 2.9692e-01, time/batch = 0.6960s	
914/28500 (epoch 1.604), train_loss = 2.09993780, grad/param norm = 3.2660e-01, time/batch = 0.6962s	
915/28500 (epoch 1.605), train_loss = 2.10256818, grad/param norm = 2.6848e-01, time/batch = 0.7034s	
916/28500 (epoch 1.607), train_loss = 2.03552100, grad/param norm = 2.3867e-01, time/batch = 0.6985s	
917/28500 (epoch 1.609), train_loss = 2.08206565, grad/param norm = 3.0187e-01, time/batch = 0.6965s	
918/28500 (epoch 1.611), train_loss = 2.09360300, grad/param norm = 3.2320e-01, time/batch = 0.7066s	
919/28500 (epoch 1.612), train_loss = 2.13439336, grad/param norm = 2.7878e-01, time/batch = 0.7068s	
920/28500 (epoch 1.614), train_loss = 2.03339529, grad/param norm = 3.0642e-01, time/batch = 0.7031s	
921/28500 (epoch 1.616), train_loss = 2.01643658, grad/param norm = 3.4778e-01, time/batch = 0.6946s	
922/28500 (epoch 1.618), train_loss = 1.85616905, grad/param norm = 2.9978e-01, time/batch = 0.6958s	
923/28500 (epoch 1.619), train_loss = 2.15166298, grad/param norm = 3.4293e-01, time/batch = 0.6976s	
924/28500 (epoch 1.621), train_loss = 1.88672494, grad/param norm = 3.2600e-01, time/batch = 0.6974s	
925/28500 (epoch 1.623), train_loss = 2.09883444, grad/param norm = 2.9166e-01, time/batch = 0.6913s	
926/28500 (epoch 1.625), train_loss = 2.04104906, grad/param norm = 2.8871e-01, time/batch = 0.6892s	
927/28500 (epoch 1.626), train_loss = 1.90484783, grad/param norm = 2.9995e-01, time/batch = 0.6896s	
928/28500 (epoch 1.628), train_loss = 1.95097657, grad/param norm = 3.0330e-01, time/batch = 0.6903s	
929/28500 (epoch 1.630), train_loss = 1.99779039, grad/param norm = 3.1279e-01, time/batch = 0.6898s	
930/28500 (epoch 1.632), train_loss = 2.15751453, grad/param norm = 3.7164e-01, time/batch = 0.6897s	
931/28500 (epoch 1.633), train_loss = 2.07068277, grad/param norm = 3.0669e-01, time/batch = 0.6930s	
932/28500 (epoch 1.635), train_loss = 2.21178338, grad/param norm = 3.1436e-01, time/batch = 0.6920s	
933/28500 (epoch 1.637), train_loss = 2.04973486, grad/param norm = 2.8332e-01, time/batch = 0.6915s	
934/28500 (epoch 1.639), train_loss = 1.85539517, grad/param norm = 3.0593e-01, time/batch = 0.6918s	
935/28500 (epoch 1.640), train_loss = 2.05755738, grad/param norm = 2.6995e-01, time/batch = 0.6983s	
936/28500 (epoch 1.642), train_loss = 2.18176183, grad/param norm = 2.8904e-01, time/batch = 0.7116s	
937/28500 (epoch 1.644), train_loss = 2.12974289, grad/param norm = 2.6556e-01, time/batch = 0.6949s	
938/28500 (epoch 1.646), train_loss = 2.08445534, grad/param norm = 2.9176e-01, time/batch = 0.6937s	
939/28500 (epoch 1.647), train_loss = 2.04588367, grad/param norm = 2.8456e-01, time/batch = 0.6941s	
940/28500 (epoch 1.649), train_loss = 2.03942397, grad/param norm = 2.5892e-01, time/batch = 0.7050s	
941/28500 (epoch 1.651), train_loss = 2.00431257, grad/param norm = 2.9267e-01, time/batch = 0.7062s	
942/28500 (epoch 1.653), train_loss = 2.01496241, grad/param norm = 3.3848e-01, time/batch = 0.7003s	
943/28500 (epoch 1.654), train_loss = 2.06385461, grad/param norm = 3.6715e-01, time/batch = 0.6965s	
944/28500 (epoch 1.656), train_loss = 2.12547874, grad/param norm = 3.7041e-01, time/batch = 0.6988s	
945/28500 (epoch 1.658), train_loss = 2.10531991, grad/param norm = 2.8693e-01, time/batch = 0.6960s	
946/28500 (epoch 1.660), train_loss = 2.03403888, grad/param norm = 2.6307e-01, time/batch = 0.6972s	
947/28500 (epoch 1.661), train_loss = 2.14278157, grad/param norm = 2.3783e-01, time/batch = 0.6984s	
948/28500 (epoch 1.663), train_loss = 2.14386492, grad/param norm = 2.6570e-01, time/batch = 0.6989s	
949/28500 (epoch 1.665), train_loss = 2.10023966, grad/param norm = 3.1236e-01, time/batch = 0.7005s	
950/28500 (epoch 1.667), train_loss = 1.99211408, grad/param norm = 3.0484e-01, time/batch = 0.6988s	
951/28500 (epoch 1.668), train_loss = 2.02744625, grad/param norm = 2.7626e-01, time/batch = 0.7002s	
952/28500 (epoch 1.670), train_loss = 1.98015415, grad/param norm = 3.0362e-01, time/batch = 0.6994s	
953/28500 (epoch 1.672), train_loss = 2.01681714, grad/param norm = 2.8859e-01, time/batch = 0.6988s	
954/28500 (epoch 1.674), train_loss = 1.95606501, grad/param norm = 2.8674e-01, time/batch = 0.7004s	
955/28500 (epoch 1.675), train_loss = 1.89237469, grad/param norm = 2.9112e-01, time/batch = 0.6964s	
956/28500 (epoch 1.677), train_loss = 1.98348489, grad/param norm = 2.9743e-01, time/batch = 0.6984s	
957/28500 (epoch 1.679), train_loss = 2.05572031, grad/param norm = 2.3440e-01, time/batch = 0.6976s	
958/28500 (epoch 1.681), train_loss = 2.17778600, grad/param norm = 2.9417e-01, time/batch = 0.7021s	
959/28500 (epoch 1.682), train_loss = 1.93004291, grad/param norm = 2.8972e-01, time/batch = 0.6914s	
960/28500 (epoch 1.684), train_loss = 2.07026102, grad/param norm = 2.4086e-01, time/batch = 0.6928s	
961/28500 (epoch 1.686), train_loss = 1.97256610, grad/param norm = 2.7234e-01, time/batch = 0.6940s	
962/28500 (epoch 1.688), train_loss = 1.99183723, grad/param norm = 3.1438e-01, time/batch = 0.6971s	
963/28500 (epoch 1.689), train_loss = 2.20441576, grad/param norm = 3.7558e-01, time/batch = 0.6940s	
964/28500 (epoch 1.691), train_loss = 2.01370738, grad/param norm = 2.9236e-01, time/batch = 0.6934s	
965/28500 (epoch 1.693), train_loss = 2.07132324, grad/param norm = 2.9377e-01, time/batch = 0.6929s	
966/28500 (epoch 1.695), train_loss = 2.08931258, grad/param norm = 2.7637e-01, time/batch = 0.6956s	
967/28500 (epoch 1.696), train_loss = 2.13407616, grad/param norm = 3.6984e-01, time/batch = 0.6973s	
968/28500 (epoch 1.698), train_loss = 1.97055277, grad/param norm = 2.9294e-01, time/batch = 0.6946s	
969/28500 (epoch 1.700), train_loss = 1.97773198, grad/param norm = 2.6438e-01, time/batch = 0.6937s	
970/28500 (epoch 1.702), train_loss = 2.13343944, grad/param norm = 2.7001e-01, time/batch = 0.6944s	
971/28500 (epoch 1.704), train_loss = 1.97108350, grad/param norm = 2.8574e-01, time/batch = 0.6937s	
972/28500 (epoch 1.705), train_loss = 2.04341608, grad/param norm = 3.0733e-01, time/batch = 0.6961s	
973/28500 (epoch 1.707), train_loss = 2.10597558, grad/param norm = 3.1874e-01, time/batch = 0.7020s	
974/28500 (epoch 1.709), train_loss = 2.10625905, grad/param norm = 2.7834e-01, time/batch = 0.7012s	
975/28500 (epoch 1.711), train_loss = 1.90047958, grad/param norm = 2.9355e-01, time/batch = 0.6937s	
976/28500 (epoch 1.712), train_loss = 2.01293817, grad/param norm = 3.0253e-01, time/batch = 0.6904s	
977/28500 (epoch 1.714), train_loss = 2.04519144, grad/param norm = 2.8646e-01, time/batch = 0.6896s	
978/28500 (epoch 1.716), train_loss = 2.13132907, grad/param norm = 2.6267e-01, time/batch = 0.6919s	
979/28500 (epoch 1.718), train_loss = 1.94879094, grad/param norm = 2.5418e-01, time/batch = 0.6898s	
980/28500 (epoch 1.719), train_loss = 1.95414936, grad/param norm = 2.4917e-01, time/batch = 0.6903s	
981/28500 (epoch 1.721), train_loss = 1.82998514, grad/param norm = 2.7800e-01, time/batch = 0.6941s	
982/28500 (epoch 1.723), train_loss = 2.04245768, grad/param norm = 2.8542e-01, time/batch = 0.6921s	
983/28500 (epoch 1.725), train_loss = 2.09756087, grad/param norm = 2.8573e-01, time/batch = 0.6902s	
984/28500 (epoch 1.726), train_loss = 2.01928662, grad/param norm = 2.7504e-01, time/batch = 0.6895s	
985/28500 (epoch 1.728), train_loss = 1.92942082, grad/param norm = 2.5368e-01, time/batch = 0.6899s	
986/28500 (epoch 1.730), train_loss = 2.12320874, grad/param norm = 3.3120e-01, time/batch = 0.6899s	
987/28500 (epoch 1.732), train_loss = 1.91812573, grad/param norm = 4.6190e-01, time/batch = 0.6924s	
988/28500 (epoch 1.733), train_loss = 2.00068985, grad/param norm = 4.1274e-01, time/batch = 0.6947s	
989/28500 (epoch 1.735), train_loss = 1.92545513, grad/param norm = 3.1182e-01, time/batch = 0.6915s	
990/28500 (epoch 1.737), train_loss = 1.92384064, grad/param norm = 2.6382e-01, time/batch = 0.6926s	
991/28500 (epoch 1.739), train_loss = 2.05146762, grad/param norm = 2.5928e-01, time/batch = 0.6954s	
992/28500 (epoch 1.740), train_loss = 1.96318781, grad/param norm = 2.7573e-01, time/batch = 0.6974s	
993/28500 (epoch 1.742), train_loss = 2.02720695, grad/param norm = 2.4534e-01, time/batch = 0.6942s	
994/28500 (epoch 1.744), train_loss = 2.04933443, grad/param norm = 2.7842e-01, time/batch = 0.6937s	
995/28500 (epoch 1.746), train_loss = 1.90310463, grad/param norm = 2.9415e-01, time/batch = 0.6963s	
996/28500 (epoch 1.747), train_loss = 1.87353791, grad/param norm = 3.0801e-01, time/batch = 0.6923s	
997/28500 (epoch 1.749), train_loss = 2.27797018, grad/param norm = 3.3523e-01, time/batch = 0.6930s	
998/28500 (epoch 1.751), train_loss = 1.95761698, grad/param norm = 2.6696e-01, time/batch = 0.6936s	
999/28500 (epoch 1.753), train_loss = 1.80889810, grad/param norm = 2.3430e-01, time/batch = 0.7111s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch1.75_2.0663.t7	
1000/28500 (epoch 1.754), train_loss = 1.90517108, grad/param norm = 2.5138e-01, time/batch = 0.6999s	
1001/28500 (epoch 1.756), train_loss = 2.16762270, grad/param norm = 2.5890e-01, time/batch = 0.7059s	
1002/28500 (epoch 1.758), train_loss = 2.00095698, grad/param norm = 2.3825e-01, time/batch = 0.6951s	
1003/28500 (epoch 1.760), train_loss = 1.94437323, grad/param norm = 3.1386e-01, time/batch = 0.6949s	
1004/28500 (epoch 1.761), train_loss = 2.06604328, grad/param norm = 3.4788e-01, time/batch = 0.7013s	
1005/28500 (epoch 1.763), train_loss = 1.87909806, grad/param norm = 3.3947e-01, time/batch = 0.6970s	
1006/28500 (epoch 1.765), train_loss = 1.90502338, grad/param norm = 2.8086e-01, time/batch = 0.7015s	
1007/28500 (epoch 1.767), train_loss = 1.81740042, grad/param norm = 2.6415e-01, time/batch = 0.6999s	
1008/28500 (epoch 1.768), train_loss = 2.11476654, grad/param norm = 2.7077e-01, time/batch = 0.6985s	
1009/28500 (epoch 1.770), train_loss = 1.95134782, grad/param norm = 2.7709e-01, time/batch = 0.6924s	
1010/28500 (epoch 1.772), train_loss = 1.89255984, grad/param norm = 3.1573e-01, time/batch = 0.6934s	
1011/28500 (epoch 1.774), train_loss = 1.95703125, grad/param norm = 3.1465e-01, time/batch = 0.6957s	
1012/28500 (epoch 1.775), train_loss = 2.13131607, grad/param norm = 2.6408e-01, time/batch = 0.6961s	
1013/28500 (epoch 1.777), train_loss = 1.95955184, grad/param norm = 2.5239e-01, time/batch = 0.6956s	
1014/28500 (epoch 1.779), train_loss = 2.00452179, grad/param norm = 3.0715e-01, time/batch = 0.7051s	
1015/28500 (epoch 1.781), train_loss = 2.03980564, grad/param norm = 3.3295e-01, time/batch = 0.6883s	
1016/28500 (epoch 1.782), train_loss = 2.13573212, grad/param norm = 3.2904e-01, time/batch = 0.6900s	
1017/28500 (epoch 1.784), train_loss = 1.88198887, grad/param norm = 2.4044e-01, time/batch = 0.6883s	
1018/28500 (epoch 1.786), train_loss = 2.02740587, grad/param norm = 2.4935e-01, time/batch = 0.6949s	
1019/28500 (epoch 1.788), train_loss = 2.13396463, grad/param norm = 2.9040e-01, time/batch = 0.6948s	
1020/28500 (epoch 1.789), train_loss = 1.96619868, grad/param norm = 4.2318e-01, time/batch = 0.6927s	
1021/28500 (epoch 1.791), train_loss = 1.98593430, grad/param norm = 3.8300e-01, time/batch = 0.6915s	
1022/28500 (epoch 1.793), train_loss = 1.89492371, grad/param norm = 3.0716e-01, time/batch = 0.6929s	
1023/28500 (epoch 1.795), train_loss = 2.04501045, grad/param norm = 3.1831e-01, time/batch = 0.6949s	
1024/28500 (epoch 1.796), train_loss = 1.92172992, grad/param norm = 3.0560e-01, time/batch = 0.6942s	
1025/28500 (epoch 1.798), train_loss = 1.96248652, grad/param norm = 3.2563e-01, time/batch = 0.7126s	
1026/28500 (epoch 1.800), train_loss = 1.96327178, grad/param norm = 3.2440e-01, time/batch = 0.6957s	
1027/28500 (epoch 1.802), train_loss = 2.09553872, grad/param norm = 3.3743e-01, time/batch = 0.7036s	
1028/28500 (epoch 1.804), train_loss = 1.96665785, grad/param norm = 2.8368e-01, time/batch = 0.6967s	
1029/28500 (epoch 1.805), train_loss = 2.03881778, grad/param norm = 2.6978e-01, time/batch = 0.7014s	
1030/28500 (epoch 1.807), train_loss = 2.15624983, grad/param norm = 2.4197e-01, time/batch = 0.6901s	
1031/28500 (epoch 1.809), train_loss = 1.89873892, grad/param norm = 2.4618e-01, time/batch = 0.6910s	
1032/28500 (epoch 1.811), train_loss = 2.15943931, grad/param norm = 2.7817e-01, time/batch = 0.6898s	
1033/28500 (epoch 1.812), train_loss = 2.05786164, grad/param norm = 2.8277e-01, time/batch = 0.6897s	
1034/28500 (epoch 1.814), train_loss = 2.00103317, grad/param norm = 3.0395e-01, time/batch = 0.6933s	
1035/28500 (epoch 1.816), train_loss = 2.06263425, grad/param norm = 2.3936e-01, time/batch = 0.6957s	
1036/28500 (epoch 1.818), train_loss = 1.94699670, grad/param norm = 2.5206e-01, time/batch = 0.6935s	
1037/28500 (epoch 1.819), train_loss = 1.96991670, grad/param norm = 2.9551e-01, time/batch = 0.6914s	
1038/28500 (epoch 1.821), train_loss = 2.01492921, grad/param norm = 3.3642e-01, time/batch = 0.7020s	
1039/28500 (epoch 1.823), train_loss = 2.22480138, grad/param norm = 3.1915e-01, time/batch = 0.7044s	
1040/28500 (epoch 1.825), train_loss = 1.93391454, grad/param norm = 2.6926e-01, time/batch = 0.6945s	
1041/28500 (epoch 1.826), train_loss = 2.02232980, grad/param norm = 3.0418e-01, time/batch = 0.6942s	
1042/28500 (epoch 1.828), train_loss = 1.85632937, grad/param norm = 2.6269e-01, time/batch = 0.6915s	
1043/28500 (epoch 1.830), train_loss = 1.90323189, grad/param norm = 2.6137e-01, time/batch = 0.6914s	
1044/28500 (epoch 1.832), train_loss = 2.07399717, grad/param norm = 2.8445e-01, time/batch = 0.6911s	
1045/28500 (epoch 1.833), train_loss = 2.09739192, grad/param norm = 2.8685e-01, time/batch = 0.6894s	
1046/28500 (epoch 1.835), train_loss = 1.97481153, grad/param norm = 3.4432e-01, time/batch = 0.6895s	
1047/28500 (epoch 1.837), train_loss = 1.93281569, grad/param norm = 2.9733e-01, time/batch = 0.6901s	
1048/28500 (epoch 1.839), train_loss = 2.09142721, grad/param norm = 2.6913e-01, time/batch = 0.6890s	
1049/28500 (epoch 1.840), train_loss = 2.07689661, grad/param norm = 2.6993e-01, time/batch = 0.6888s	
1050/28500 (epoch 1.842), train_loss = 1.98695224, grad/param norm = 2.7644e-01, time/batch = 0.6887s	
1051/28500 (epoch 1.844), train_loss = 2.00653737, grad/param norm = 2.8316e-01, time/batch = 0.6905s	
1052/28500 (epoch 1.846), train_loss = 2.08486826, grad/param norm = 2.8094e-01, time/batch = 0.6888s	
1053/28500 (epoch 1.847), train_loss = 1.94634822, grad/param norm = 2.4555e-01, time/batch = 0.6894s	
1054/28500 (epoch 1.849), train_loss = 1.89064433, grad/param norm = 2.3819e-01, time/batch = 0.6889s	
1055/28500 (epoch 1.851), train_loss = 1.84681464, grad/param norm = 2.4058e-01, time/batch = 0.6894s	
1056/28500 (epoch 1.853), train_loss = 2.06839684, grad/param norm = 2.5295e-01, time/batch = 0.6921s	
1057/28500 (epoch 1.854), train_loss = 1.91121265, grad/param norm = 2.3250e-01, time/batch = 0.6922s	
1058/28500 (epoch 1.856), train_loss = 2.08218293, grad/param norm = 3.1031e-01, time/batch = 0.6895s	
1059/28500 (epoch 1.858), train_loss = 1.84319086, grad/param norm = 2.4243e-01, time/batch = 0.6889s	
1060/28500 (epoch 1.860), train_loss = 2.01802933, grad/param norm = 2.4765e-01, time/batch = 0.6908s	
1061/28500 (epoch 1.861), train_loss = 1.89949013, grad/param norm = 2.3690e-01, time/batch = 0.6924s	
1062/28500 (epoch 1.863), train_loss = 2.12653981, grad/param norm = 2.7834e-01, time/batch = 0.6923s	
1063/28500 (epoch 1.865), train_loss = 1.97072165, grad/param norm = 2.7245e-01, time/batch = 0.6927s	
1064/28500 (epoch 1.867), train_loss = 2.04360478, grad/param norm = 2.4352e-01, time/batch = 0.7065s	
1065/28500 (epoch 1.868), train_loss = 1.78309495, grad/param norm = 2.9691e-01, time/batch = 0.6926s	
1066/28500 (epoch 1.870), train_loss = 1.78983253, grad/param norm = 2.9070e-01, time/batch = 0.6936s	
1067/28500 (epoch 1.872), train_loss = 2.15199529, grad/param norm = 3.4878e-01, time/batch = 0.6931s	
1068/28500 (epoch 1.874), train_loss = 1.96957099, grad/param norm = 3.3603e-01, time/batch = 0.6923s	
1069/28500 (epoch 1.875), train_loss = 2.04705708, grad/param norm = 3.2322e-01, time/batch = 0.7140s	
1070/28500 (epoch 1.877), train_loss = 1.97383050, grad/param norm = 2.7703e-01, time/batch = 0.6982s	
1071/28500 (epoch 1.879), train_loss = 1.97219269, grad/param norm = 2.4454e-01, time/batch = 0.7191s	
1072/28500 (epoch 1.881), train_loss = 2.02948225, grad/param norm = 2.5511e-01, time/batch = 0.7223s	
1073/28500 (epoch 1.882), train_loss = 1.92744637, grad/param norm = 2.8798e-01, time/batch = 0.7257s	
1074/28500 (epoch 1.884), train_loss = 2.04286768, grad/param norm = 3.1864e-01, time/batch = 0.7152s	
1075/28500 (epoch 1.886), train_loss = 1.83809271, grad/param norm = 3.3063e-01, time/batch = 0.7020s	
1076/28500 (epoch 1.888), train_loss = 1.80149160, grad/param norm = 2.5658e-01, time/batch = 0.7012s	
1077/28500 (epoch 1.889), train_loss = 1.80963862, grad/param norm = 2.3890e-01, time/batch = 0.6955s	
1078/28500 (epoch 1.891), train_loss = 1.98564411, grad/param norm = 2.6813e-01, time/batch = 0.6972s	
1079/28500 (epoch 1.893), train_loss = 1.98890518, grad/param norm = 2.5554e-01, time/batch = 0.7009s	
1080/28500 (epoch 1.895), train_loss = 2.12862772, grad/param norm = 3.2541e-01, time/batch = 0.6942s	
1081/28500 (epoch 1.896), train_loss = 2.10821633, grad/param norm = 2.8885e-01, time/batch = 0.6987s	
1082/28500 (epoch 1.898), train_loss = 1.86182507, grad/param norm = 2.3982e-01, time/batch = 0.6946s	
1083/28500 (epoch 1.900), train_loss = 1.85357778, grad/param norm = 2.4561e-01, time/batch = 0.6950s	
1084/28500 (epoch 1.902), train_loss = 1.90676712, grad/param norm = 2.6428e-01, time/batch = 0.6987s	
1085/28500 (epoch 1.904), train_loss = 1.88310162, grad/param norm = 2.4706e-01, time/batch = 0.6939s	
1086/28500 (epoch 1.905), train_loss = 2.05663030, grad/param norm = 2.6015e-01, time/batch = 0.6892s	
1087/28500 (epoch 1.907), train_loss = 2.19428380, grad/param norm = 2.8769e-01, time/batch = 0.6923s	
1088/28500 (epoch 1.909), train_loss = 1.90266353, grad/param norm = 3.0420e-01, time/batch = 0.6883s	
1089/28500 (epoch 1.911), train_loss = 1.94879075, grad/param norm = 2.8123e-01, time/batch = 0.6881s	
1090/28500 (epoch 1.912), train_loss = 1.73875772, grad/param norm = 3.0456e-01, time/batch = 0.6883s	
1091/28500 (epoch 1.914), train_loss = 2.11448966, grad/param norm = 3.7884e-01, time/batch = 0.6909s	
1092/28500 (epoch 1.916), train_loss = 2.01404817, grad/param norm = 3.2751e-01, time/batch = 0.6897s	
1093/28500 (epoch 1.918), train_loss = 2.14185110, grad/param norm = 2.7578e-01, time/batch = 0.6896s	
1094/28500 (epoch 1.919), train_loss = 1.83564738, grad/param norm = 2.4891e-01, time/batch = 0.6899s	
1095/28500 (epoch 1.921), train_loss = 2.11339105, grad/param norm = 2.6781e-01, time/batch = 0.6911s	
1096/28500 (epoch 1.923), train_loss = 2.09883070, grad/param norm = 2.9470e-01, time/batch = 0.6906s	
1097/28500 (epoch 1.925), train_loss = 1.89135528, grad/param norm = 2.5838e-01, time/batch = 0.6915s	
1098/28500 (epoch 1.926), train_loss = 2.03677338, grad/param norm = 2.9176e-01, time/batch = 0.6973s	
1099/28500 (epoch 1.928), train_loss = 1.87306967, grad/param norm = 2.5175e-01, time/batch = 0.7005s	
1100/28500 (epoch 1.930), train_loss = 1.68101544, grad/param norm = 2.3970e-01, time/batch = 0.7092s	
1101/28500 (epoch 1.932), train_loss = 1.83108815, grad/param norm = 2.3908e-01, time/batch = 0.7097s	
1102/28500 (epoch 1.933), train_loss = 1.97031597, grad/param norm = 2.5970e-01, time/batch = 0.7074s	
1103/28500 (epoch 1.935), train_loss = 1.88671099, grad/param norm = 2.5097e-01, time/batch = 0.7026s	
1104/28500 (epoch 1.937), train_loss = 2.04119306, grad/param norm = 2.5465e-01, time/batch = 0.6979s	
1105/28500 (epoch 1.939), train_loss = 2.19743688, grad/param norm = 2.8113e-01, time/batch = 0.6979s	
1106/28500 (epoch 1.940), train_loss = 2.01001473, grad/param norm = 2.7142e-01, time/batch = 0.6990s	
1107/28500 (epoch 1.942), train_loss = 2.05586214, grad/param norm = 3.6097e-01, time/batch = 0.7013s	
1108/28500 (epoch 1.944), train_loss = 2.00247545, grad/param norm = 2.9730e-01, time/batch = 0.6972s	
1109/28500 (epoch 1.946), train_loss = 2.08861857, grad/param norm = 3.0382e-01, time/batch = 0.6994s	
1110/28500 (epoch 1.947), train_loss = 2.27338305, grad/param norm = 2.9960e-01, time/batch = 0.6987s	
1111/28500 (epoch 1.949), train_loss = 1.84579796, grad/param norm = 3.1534e-01, time/batch = 0.7005s	
1112/28500 (epoch 1.951), train_loss = 2.11868656, grad/param norm = 2.6551e-01, time/batch = 0.6985s	
1113/28500 (epoch 1.953), train_loss = 2.02720498, grad/param norm = 2.8744e-01, time/batch = 0.6977s	
1114/28500 (epoch 1.954), train_loss = 2.01160650, grad/param norm = 2.7676e-01, time/batch = 0.7009s	
1115/28500 (epoch 1.956), train_loss = 2.01227593, grad/param norm = 2.9652e-01, time/batch = 0.6970s	
1116/28500 (epoch 1.958), train_loss = 1.96368675, grad/param norm = 2.6577e-01, time/batch = 0.6981s	
1117/28500 (epoch 1.960), train_loss = 1.87113645, grad/param norm = 3.1231e-01, time/batch = 0.6962s	
1118/28500 (epoch 1.961), train_loss = 2.10286304, grad/param norm = 3.1064e-01, time/batch = 0.6975s	
1119/28500 (epoch 1.963), train_loss = 2.00743181, grad/param norm = 2.4669e-01, time/batch = 0.6976s	
1120/28500 (epoch 1.965), train_loss = 1.89983929, grad/param norm = 2.4654e-01, time/batch = 0.6993s	
1121/28500 (epoch 1.967), train_loss = 1.76784944, grad/param norm = 2.3448e-01, time/batch = 0.7023s	
1122/28500 (epoch 1.968), train_loss = 1.79888460, grad/param norm = 2.5552e-01, time/batch = 0.6965s	
1123/28500 (epoch 1.970), train_loss = 2.11394170, grad/param norm = 3.2916e-01, time/batch = 0.6978s	
1124/28500 (epoch 1.972), train_loss = 2.24956990, grad/param norm = 3.1539e-01, time/batch = 0.6990s	
1125/28500 (epoch 1.974), train_loss = 2.13993224, grad/param norm = 2.8354e-01, time/batch = 0.6973s	
1126/28500 (epoch 1.975), train_loss = 1.95593769, grad/param norm = 2.3848e-01, time/batch = 0.6979s	
1127/28500 (epoch 1.977), train_loss = 2.14737189, grad/param norm = 2.7746e-01, time/batch = 0.6974s	
1128/28500 (epoch 1.979), train_loss = 1.95311048, grad/param norm = 2.5815e-01, time/batch = 0.6978s	
1129/28500 (epoch 1.981), train_loss = 1.90191077, grad/param norm = 2.5916e-01, time/batch = 0.6990s	
1130/28500 (epoch 1.982), train_loss = 1.78712532, grad/param norm = 2.4790e-01, time/batch = 0.7000s	
1131/28500 (epoch 1.984), train_loss = 2.01740088, grad/param norm = 2.4892e-01, time/batch = 0.7011s	
1132/28500 (epoch 1.986), train_loss = 2.03026754, grad/param norm = 2.3223e-01, time/batch = 0.7016s	
1133/28500 (epoch 1.988), train_loss = 1.77069950, grad/param norm = 2.2513e-01, time/batch = 0.6999s	
1134/28500 (epoch 1.989), train_loss = 1.97205203, grad/param norm = 2.7001e-01, time/batch = 0.6979s	
1135/28500 (epoch 1.991), train_loss = 1.94317675, grad/param norm = 2.9305e-01, time/batch = 0.6973s	
1136/28500 (epoch 1.993), train_loss = 2.00976079, grad/param norm = 3.1051e-01, time/batch = 0.6963s	
1137/28500 (epoch 1.995), train_loss = 1.84605119, grad/param norm = 2.4734e-01, time/batch = 0.6974s	
1138/28500 (epoch 1.996), train_loss = 1.86445325, grad/param norm = 2.8854e-01, time/batch = 0.6987s	
1139/28500 (epoch 1.998), train_loss = 2.02884137, grad/param norm = 3.0286e-01, time/batch = 0.6987s	
1140/28500 (epoch 2.000), train_loss = 1.93078620, grad/param norm = 2.6956e-01, time/batch = 0.6974s	
1141/28500 (epoch 2.002), train_loss = 1.98143257, grad/param norm = 2.4971e-01, time/batch = 0.7011s	
1142/28500 (epoch 2.004), train_loss = 1.86434693, grad/param norm = 3.0379e-01, time/batch = 0.6983s	
1143/28500 (epoch 2.005), train_loss = 1.96392416, grad/param norm = 2.5411e-01, time/batch = 0.6971s	
1144/28500 (epoch 2.007), train_loss = 1.76806995, grad/param norm = 2.3772e-01, time/batch = 0.6990s	
1145/28500 (epoch 2.009), train_loss = 2.06594244, grad/param norm = 2.9686e-01, time/batch = 0.6976s	
1146/28500 (epoch 2.011), train_loss = 1.92408678, grad/param norm = 3.0993e-01, time/batch = 0.6993s	
1147/28500 (epoch 2.012), train_loss = 1.80330458, grad/param norm = 2.6000e-01, time/batch = 0.6971s	
1148/28500 (epoch 2.014), train_loss = 1.82038914, grad/param norm = 2.5087e-01, time/batch = 0.6978s	
1149/28500 (epoch 2.016), train_loss = 1.86884986, grad/param norm = 2.5495e-01, time/batch = 0.6984s	
1150/28500 (epoch 2.018), train_loss = 1.91132163, grad/param norm = 3.5272e-01, time/batch = 0.6979s	
1151/28500 (epoch 2.019), train_loss = 1.89465644, grad/param norm = 2.8350e-01, time/batch = 0.7028s	
1152/28500 (epoch 2.021), train_loss = 1.83738166, grad/param norm = 2.5236e-01, time/batch = 0.7048s	
1153/28500 (epoch 2.023), train_loss = 1.92439726, grad/param norm = 2.7430e-01, time/batch = 0.7095s	
1154/28500 (epoch 2.025), train_loss = 1.77703828, grad/param norm = 2.2568e-01, time/batch = 0.6964s	
1155/28500 (epoch 2.026), train_loss = 2.00430239, grad/param norm = 3.2897e-01, time/batch = 0.6983s	
1156/28500 (epoch 2.028), train_loss = 1.98332558, grad/param norm = 3.4414e-01, time/batch = 0.6987s	
1157/28500 (epoch 2.030), train_loss = 2.02019562, grad/param norm = 2.7955e-01, time/batch = 0.6988s	
1158/28500 (epoch 2.032), train_loss = 2.01975643, grad/param norm = 2.9601e-01, time/batch = 0.7003s	
1159/28500 (epoch 2.033), train_loss = 2.12259280, grad/param norm = 2.8462e-01, time/batch = 0.7072s	
1160/28500 (epoch 2.035), train_loss = 1.98121266, grad/param norm = 3.0469e-01, time/batch = 0.7132s	
1161/28500 (epoch 2.037), train_loss = 2.02827855, grad/param norm = 2.9769e-01, time/batch = 0.6967s	
1162/28500 (epoch 2.039), train_loss = 2.08338976, grad/param norm = 2.7184e-01, time/batch = 0.6938s	
1163/28500 (epoch 2.040), train_loss = 2.01142608, grad/param norm = 2.6220e-01, time/batch = 0.6935s	
1164/28500 (epoch 2.042), train_loss = 2.13958364, grad/param norm = 2.9406e-01, time/batch = 0.6950s	
1165/28500 (epoch 2.044), train_loss = 1.95739571, grad/param norm = 2.9675e-01, time/batch = 0.6954s	
1166/28500 (epoch 2.046), train_loss = 2.06792487, grad/param norm = 2.6635e-01, time/batch = 0.6950s	
1167/28500 (epoch 2.047), train_loss = 2.08024007, grad/param norm = 2.6557e-01, time/batch = 0.6934s	
1168/28500 (epoch 2.049), train_loss = 2.01173319, grad/param norm = 2.9778e-01, time/batch = 0.6950s	
1169/28500 (epoch 2.051), train_loss = 1.95311396, grad/param norm = 2.3750e-01, time/batch = 0.6931s	
1170/28500 (epoch 2.053), train_loss = 2.07739757, grad/param norm = 2.7089e-01, time/batch = 0.6930s	
1171/28500 (epoch 2.054), train_loss = 2.00266473, grad/param norm = 2.5903e-01, time/batch = 0.6951s	
1172/28500 (epoch 2.056), train_loss = 1.84611173, grad/param norm = 2.2502e-01, time/batch = 0.6939s	
1173/28500 (epoch 2.058), train_loss = 1.89905931, grad/param norm = 2.5146e-01, time/batch = 0.6936s	
1174/28500 (epoch 2.060), train_loss = 1.92148437, grad/param norm = 2.9540e-01, time/batch = 0.6948s	
1175/28500 (epoch 2.061), train_loss = 2.09231912, grad/param norm = 3.1583e-01, time/batch = 0.6942s	
1176/28500 (epoch 2.063), train_loss = 2.14139252, grad/param norm = 2.3844e-01, time/batch = 0.6938s	
1177/28500 (epoch 2.065), train_loss = 2.21689880, grad/param norm = 2.6798e-01, time/batch = 0.6932s	
1178/28500 (epoch 2.067), train_loss = 1.96178388, grad/param norm = 3.0212e-01, time/batch = 0.6951s	
1179/28500 (epoch 2.068), train_loss = 1.82393028, grad/param norm = 2.3939e-01, time/batch = 0.6963s	
1180/28500 (epoch 2.070), train_loss = 2.05345006, grad/param norm = 2.6176e-01, time/batch = 0.6942s	
1181/28500 (epoch 2.072), train_loss = 2.19263975, grad/param norm = 2.7471e-01, time/batch = 0.6965s	
1182/28500 (epoch 2.074), train_loss = 2.01745441, grad/param norm = 2.8870e-01, time/batch = 0.6946s	
1183/28500 (epoch 2.075), train_loss = 1.91423293, grad/param norm = 2.8934e-01, time/batch = 0.6947s	
1184/28500 (epoch 2.077), train_loss = 2.00984983, grad/param norm = 2.5936e-01, time/batch = 0.6974s	
1185/28500 (epoch 2.079), train_loss = 1.93276815, grad/param norm = 2.4413e-01, time/batch = 0.7141s	
1186/28500 (epoch 2.081), train_loss = 2.07178265, grad/param norm = 2.6157e-01, time/batch = 0.6945s	
1187/28500 (epoch 2.082), train_loss = 2.06494747, grad/param norm = 3.1923e-01, time/batch = 0.6937s	
1188/28500 (epoch 2.084), train_loss = 2.06439404, grad/param norm = 2.6817e-01, time/batch = 0.6934s	
1189/28500 (epoch 2.086), train_loss = 1.83535399, grad/param norm = 2.4083e-01, time/batch = 0.6973s	
1190/28500 (epoch 2.088), train_loss = 1.82564092, grad/param norm = 2.4660e-01, time/batch = 0.6969s	
1191/28500 (epoch 2.089), train_loss = 2.10319064, grad/param norm = 2.4631e-01, time/batch = 0.6990s	
1192/28500 (epoch 2.091), train_loss = 1.83073942, grad/param norm = 2.3073e-01, time/batch = 0.7010s	
1193/28500 (epoch 2.093), train_loss = 1.94696783, grad/param norm = 2.4569e-01, time/batch = 0.6972s	
1194/28500 (epoch 2.095), train_loss = 2.00312990, grad/param norm = 2.5348e-01, time/batch = 0.6974s	
1195/28500 (epoch 2.096), train_loss = 2.01753255, grad/param norm = 2.4537e-01, time/batch = 0.6969s	
1196/28500 (epoch 2.098), train_loss = 2.11698264, grad/param norm = 2.6248e-01, time/batch = 0.7014s	
1197/28500 (epoch 2.100), train_loss = 1.88932663, grad/param norm = 2.7070e-01, time/batch = 0.6973s	
1198/28500 (epoch 2.102), train_loss = 2.08831199, grad/param norm = 2.2831e-01, time/batch = 0.6972s	
1199/28500 (epoch 2.104), train_loss = 1.96318812, grad/param norm = 2.5498e-01, time/batch = 0.7003s	
1200/28500 (epoch 2.105), train_loss = 1.99896001, grad/param norm = 3.1825e-01, time/batch = 0.7000s	
1201/28500 (epoch 2.107), train_loss = 1.88119876, grad/param norm = 3.6996e-01, time/batch = 0.7023s	
1202/28500 (epoch 2.109), train_loss = 1.89604335, grad/param norm = 2.7278e-01, time/batch = 0.6987s	
1203/28500 (epoch 2.111), train_loss = 1.97084970, grad/param norm = 2.5920e-01, time/batch = 0.7006s	
1204/28500 (epoch 2.112), train_loss = 2.01892137, grad/param norm = 2.4989e-01, time/batch = 0.6940s	
1205/28500 (epoch 2.114), train_loss = 1.86519868, grad/param norm = 2.5182e-01, time/batch = 0.6937s	
1206/28500 (epoch 2.116), train_loss = 2.08793669, grad/param norm = 2.7978e-01, time/batch = 0.6946s	
1207/28500 (epoch 2.118), train_loss = 1.84138938, grad/param norm = 3.1302e-01, time/batch = 0.6935s	
1208/28500 (epoch 2.119), train_loss = 2.05421869, grad/param norm = 3.0559e-01, time/batch = 0.6931s	
1209/28500 (epoch 2.121), train_loss = 2.16439010, grad/param norm = 2.6772e-01, time/batch = 0.6943s	
1210/28500 (epoch 2.123), train_loss = 1.97481375, grad/param norm = 2.8125e-01, time/batch = 0.6940s	
1211/28500 (epoch 2.125), train_loss = 2.11708095, grad/param norm = 2.5192e-01, time/batch = 0.6950s	
1212/28500 (epoch 2.126), train_loss = 1.99645243, grad/param norm = 2.5341e-01, time/batch = 0.6941s	
1213/28500 (epoch 2.128), train_loss = 1.94670059, grad/param norm = 3.0376e-01, time/batch = 0.6936s	
1214/28500 (epoch 2.130), train_loss = 2.01074536, grad/param norm = 2.4910e-01, time/batch = 0.6929s	
1215/28500 (epoch 2.132), train_loss = 2.03937339, grad/param norm = 2.8144e-01, time/batch = 0.6947s	
1216/28500 (epoch 2.133), train_loss = 1.88051560, grad/param norm = 2.2501e-01, time/batch = 0.6951s	
1217/28500 (epoch 2.135), train_loss = 1.92672439, grad/param norm = 2.2161e-01, time/batch = 0.6944s	
1218/28500 (epoch 2.137), train_loss = 1.84997289, grad/param norm = 2.7772e-01, time/batch = 0.6924s	
1219/28500 (epoch 2.139), train_loss = 1.90134010, grad/param norm = 2.6279e-01, time/batch = 0.6929s	
1220/28500 (epoch 2.140), train_loss = 1.93229591, grad/param norm = 2.4116e-01, time/batch = 0.6995s	
1221/28500 (epoch 2.142), train_loss = 1.98146307, grad/param norm = 2.5456e-01, time/batch = 0.6955s	
1222/28500 (epoch 2.144), train_loss = 1.86641869, grad/param norm = 2.8343e-01, time/batch = 0.6941s	
1223/28500 (epoch 2.146), train_loss = 1.87614023, grad/param norm = 3.2721e-01, time/batch = 0.6925s	
1224/28500 (epoch 2.147), train_loss = 1.79017453, grad/param norm = 2.3244e-01, time/batch = 0.6924s	
1225/28500 (epoch 2.149), train_loss = 1.88158557, grad/param norm = 2.4286e-01, time/batch = 0.6926s	
1226/28500 (epoch 2.151), train_loss = 1.83983920, grad/param norm = 2.3983e-01, time/batch = 0.6924s	
1227/28500 (epoch 2.153), train_loss = 1.87344893, grad/param norm = 2.7617e-01, time/batch = 0.6933s	
1228/28500 (epoch 2.154), train_loss = 1.88052322, grad/param norm = 2.5252e-01, time/batch = 0.6928s	
1229/28500 (epoch 2.156), train_loss = 2.15272556, grad/param norm = 2.6872e-01, time/batch = 0.6930s	
1230/28500 (epoch 2.158), train_loss = 1.89201687, grad/param norm = 2.5567e-01, time/batch = 0.6947s	
1231/28500 (epoch 2.160), train_loss = 1.83502696, grad/param norm = 2.9412e-01, time/batch = 0.6953s	
1232/28500 (epoch 2.161), train_loss = 2.02045305, grad/param norm = 3.1826e-01, time/batch = 0.6938s	
1233/28500 (epoch 2.163), train_loss = 1.87410327, grad/param norm = 3.1024e-01, time/batch = 0.6958s	
1234/28500 (epoch 2.165), train_loss = 2.06115747, grad/param norm = 2.3225e-01, time/batch = 0.6947s	
1235/28500 (epoch 2.167), train_loss = 2.08007719, grad/param norm = 2.3489e-01, time/batch = 0.6956s	
1236/28500 (epoch 2.168), train_loss = 2.02071997, grad/param norm = 3.1536e-01, time/batch = 0.6940s	
1237/28500 (epoch 2.170), train_loss = 2.12149350, grad/param norm = 2.9531e-01, time/batch = 0.6932s	
1238/28500 (epoch 2.172), train_loss = 1.95224744, grad/param norm = 3.2743e-01, time/batch = 0.6945s	
1239/28500 (epoch 2.174), train_loss = 2.12331457, grad/param norm = 2.4352e-01, time/batch = 0.6927s	
1240/28500 (epoch 2.175), train_loss = 1.92558857, grad/param norm = 2.4726e-01, time/batch = 0.6928s	
1241/28500 (epoch 2.177), train_loss = 2.05319192, grad/param norm = 2.5070e-01, time/batch = 0.6955s	
1242/28500 (epoch 2.179), train_loss = 1.88804439, grad/param norm = 2.7640e-01, time/batch = 0.6944s	
1243/28500 (epoch 2.181), train_loss = 2.06507567, grad/param norm = 2.5454e-01, time/batch = 0.6947s	
1244/28500 (epoch 2.182), train_loss = 1.98339486, grad/param norm = 3.0995e-01, time/batch = 0.6978s	
1245/28500 (epoch 2.184), train_loss = 2.08647884, grad/param norm = 2.9323e-01, time/batch = 0.6996s	
1246/28500 (epoch 2.186), train_loss = 2.05386699, grad/param norm = 2.7702e-01, time/batch = 0.7110s	
1247/28500 (epoch 2.188), train_loss = 1.92162885, grad/param norm = 2.5461e-01, time/batch = 0.7018s	
1248/28500 (epoch 2.189), train_loss = 2.09009003, grad/param norm = 2.7942e-01, time/batch = 0.6959s	
1249/28500 (epoch 2.191), train_loss = 2.12765328, grad/param norm = 2.5049e-01, time/batch = 0.6965s	
1250/28500 (epoch 2.193), train_loss = 1.97536798, grad/param norm = 2.7904e-01, time/batch = 0.6955s	
1251/28500 (epoch 2.195), train_loss = 2.03748917, grad/param norm = 2.9338e-01, time/batch = 0.6987s	
1252/28500 (epoch 2.196), train_loss = 1.93426015, grad/param norm = 2.5750e-01, time/batch = 0.6955s	
1253/28500 (epoch 2.198), train_loss = 1.91882075, grad/param norm = 2.6216e-01, time/batch = 0.6975s	
1254/28500 (epoch 2.200), train_loss = 1.93392644, grad/param norm = 2.2536e-01, time/batch = 0.6934s	
1255/28500 (epoch 2.202), train_loss = 2.02159145, grad/param norm = 2.6075e-01, time/batch = 0.6933s	
1256/28500 (epoch 2.204), train_loss = 1.77059880, grad/param norm = 2.3481e-01, time/batch = 0.6936s	
1257/28500 (epoch 2.205), train_loss = 1.82051907, grad/param norm = 2.2995e-01, time/batch = 0.6928s	
1258/28500 (epoch 2.207), train_loss = 2.00597831, grad/param norm = 2.5865e-01, time/batch = 0.6937s	
1259/28500 (epoch 2.209), train_loss = 1.88915412, grad/param norm = 2.6677e-01, time/batch = 0.6940s	
1260/28500 (epoch 2.211), train_loss = 1.85895235, grad/param norm = 2.2247e-01, time/batch = 0.6940s	
1261/28500 (epoch 2.212), train_loss = 1.82481319, grad/param norm = 2.4239e-01, time/batch = 0.6956s	
1262/28500 (epoch 2.214), train_loss = 2.05837527, grad/param norm = 2.4951e-01, time/batch = 0.6978s	
1263/28500 (epoch 2.216), train_loss = 1.84197204, grad/param norm = 2.1878e-01, time/batch = 0.7102s	
1264/28500 (epoch 2.218), train_loss = 1.91907709, grad/param norm = 2.2486e-01, time/batch = 0.6994s	
1265/28500 (epoch 2.219), train_loss = 1.84652512, grad/param norm = 2.2478e-01, time/batch = 0.6962s	
1266/28500 (epoch 2.221), train_loss = 1.81185259, grad/param norm = 2.2023e-01, time/batch = 0.6968s	
1267/28500 (epoch 2.223), train_loss = 2.01785497, grad/param norm = 2.4866e-01, time/batch = 0.6952s	
1268/28500 (epoch 2.225), train_loss = 2.08785160, grad/param norm = 2.7939e-01, time/batch = 0.6928s	
1269/28500 (epoch 2.226), train_loss = 2.00122403, grad/param norm = 2.7421e-01, time/batch = 0.7025s	
1270/28500 (epoch 2.228), train_loss = 1.94179822, grad/param norm = 2.8377e-01, time/batch = 0.7087s	
1271/28500 (epoch 2.230), train_loss = 1.90901089, grad/param norm = 2.4428e-01, time/batch = 0.7344s	
1272/28500 (epoch 2.232), train_loss = 1.98504747, grad/param norm = 2.5867e-01, time/batch = 0.7158s	
1273/28500 (epoch 2.233), train_loss = 1.96445292, grad/param norm = 3.3192e-01, time/batch = 0.7046s	
1274/28500 (epoch 2.235), train_loss = 1.85742781, grad/param norm = 3.1334e-01, time/batch = 0.7032s	
1275/28500 (epoch 2.237), train_loss = 1.79791930, grad/param norm = 2.2728e-01, time/batch = 0.6996s	
1276/28500 (epoch 2.239), train_loss = 1.85767721, grad/param norm = 2.6024e-01, time/batch = 0.7017s	
1277/28500 (epoch 2.240), train_loss = 1.84124778, grad/param norm = 2.6937e-01, time/batch = 0.6941s	
1278/28500 (epoch 2.242), train_loss = 1.98171513, grad/param norm = 2.7635e-01, time/batch = 0.6974s	
1279/28500 (epoch 2.244), train_loss = 2.03381833, grad/param norm = 2.4811e-01, time/batch = 0.6992s	
1280/28500 (epoch 2.246), train_loss = 1.90303937, grad/param norm = 2.4119e-01, time/batch = 0.7123s	
1281/28500 (epoch 2.247), train_loss = 2.07008673, grad/param norm = 2.4129e-01, time/batch = 0.7064s	
1282/28500 (epoch 2.249), train_loss = 1.94836928, grad/param norm = 2.5131e-01, time/batch = 0.7012s	
1283/28500 (epoch 2.251), train_loss = 1.67079470, grad/param norm = 2.1540e-01, time/batch = 0.6982s	
1284/28500 (epoch 2.253), train_loss = 1.98448125, grad/param norm = 2.4557e-01, time/batch = 0.6963s	
1285/28500 (epoch 2.254), train_loss = 1.96391879, grad/param norm = 2.3268e-01, time/batch = 0.6964s	
1286/28500 (epoch 2.256), train_loss = 1.88509794, grad/param norm = 2.3017e-01, time/batch = 0.6932s	
1287/28500 (epoch 2.258), train_loss = 1.90268913, grad/param norm = 2.7370e-01, time/batch = 0.6995s	
1288/28500 (epoch 2.260), train_loss = 1.91385999, grad/param norm = 2.6302e-01, time/batch = 0.6986s	
1289/28500 (epoch 2.261), train_loss = 1.86893988, grad/param norm = 2.7841e-01, time/batch = 0.7003s	
1290/28500 (epoch 2.263), train_loss = 2.09667450, grad/param norm = 2.8174e-01, time/batch = 0.6929s	
1291/28500 (epoch 2.265), train_loss = 2.02012690, grad/param norm = 2.5042e-01, time/batch = 0.6950s	
1292/28500 (epoch 2.267), train_loss = 2.05891205, grad/param norm = 2.6102e-01, time/batch = 0.7013s	
1293/28500 (epoch 2.268), train_loss = 1.97912893, grad/param norm = 2.5961e-01, time/batch = 0.7065s	
1294/28500 (epoch 2.270), train_loss = 1.82962435, grad/param norm = 2.2647e-01, time/batch = 0.6920s	
1295/28500 (epoch 2.272), train_loss = 1.90480616, grad/param norm = 2.9754e-01, time/batch = 0.6917s	
1296/28500 (epoch 2.274), train_loss = 2.06384351, grad/param norm = 2.8824e-01, time/batch = 0.6920s	
1297/28500 (epoch 2.275), train_loss = 1.98011688, grad/param norm = 2.7037e-01, time/batch = 0.6921s	
1298/28500 (epoch 2.277), train_loss = 1.89540577, grad/param norm = 2.6768e-01, time/batch = 0.6923s	
1299/28500 (epoch 2.279), train_loss = 1.92244961, grad/param norm = 2.6419e-01, time/batch = 0.6929s	
1300/28500 (epoch 2.281), train_loss = 1.92841441, grad/param norm = 2.6648e-01, time/batch = 0.7042s	
1301/28500 (epoch 2.282), train_loss = 1.84431144, grad/param norm = 2.4349e-01, time/batch = 0.7058s	
1302/28500 (epoch 2.284), train_loss = 1.95724287, grad/param norm = 2.4908e-01, time/batch = 0.6934s	
1303/28500 (epoch 2.286), train_loss = 2.05302349, grad/param norm = 2.6763e-01, time/batch = 0.6924s	
1304/28500 (epoch 2.288), train_loss = 1.90864886, grad/param norm = 2.5838e-01, time/batch = 0.6931s	
1305/28500 (epoch 2.289), train_loss = 2.12937721, grad/param norm = 2.5099e-01, time/batch = 0.6922s	
1306/28500 (epoch 2.291), train_loss = 1.78855671, grad/param norm = 2.4643e-01, time/batch = 0.6924s	
1307/28500 (epoch 2.293), train_loss = 1.86934124, grad/param norm = 2.5192e-01, time/batch = 0.6933s	
1308/28500 (epoch 2.295), train_loss = 1.84764343, grad/param norm = 2.3845e-01, time/batch = 0.7087s	
1309/28500 (epoch 2.296), train_loss = 1.78725089, grad/param norm = 2.2964e-01, time/batch = 0.7007s	
1310/28500 (epoch 2.298), train_loss = 1.88275440, grad/param norm = 2.3654e-01, time/batch = 0.6919s	
1311/28500 (epoch 2.300), train_loss = 1.78259922, grad/param norm = 2.5231e-01, time/batch = 0.6972s	
1312/28500 (epoch 2.302), train_loss = 1.81066423, grad/param norm = 2.5595e-01, time/batch = 0.6970s	
1313/28500 (epoch 2.304), train_loss = 1.77815151, grad/param norm = 2.0972e-01, time/batch = 0.6970s	
1314/28500 (epoch 2.305), train_loss = 1.94125645, grad/param norm = 2.3754e-01, time/batch = 0.6952s	
1315/28500 (epoch 2.307), train_loss = 2.00804339, grad/param norm = 3.1364e-01, time/batch = 0.6969s	
1316/28500 (epoch 2.309), train_loss = 2.03220544, grad/param norm = 2.9557e-01, time/batch = 0.7084s	
1317/28500 (epoch 2.311), train_loss = 1.87390093, grad/param norm = 2.8940e-01, time/batch = 0.6951s	
1318/28500 (epoch 2.312), train_loss = 1.72760808, grad/param norm = 2.5308e-01, time/batch = 0.6919s	
1319/28500 (epoch 2.314), train_loss = 1.89914560, grad/param norm = 2.7318e-01, time/batch = 0.6964s	
1320/28500 (epoch 2.316), train_loss = 1.89579806, grad/param norm = 2.3483e-01, time/batch = 0.6965s	
1321/28500 (epoch 2.318), train_loss = 1.91583193, grad/param norm = 2.6045e-01, time/batch = 0.6976s	
1322/28500 (epoch 2.319), train_loss = 1.88495872, grad/param norm = 2.6316e-01, time/batch = 0.6934s	
1323/28500 (epoch 2.321), train_loss = 1.99246758, grad/param norm = 2.5917e-01, time/batch = 0.6939s	
1324/28500 (epoch 2.323), train_loss = 1.91880561, grad/param norm = 2.5854e-01, time/batch = 0.6944s	
1325/28500 (epoch 2.325), train_loss = 2.11005678, grad/param norm = 2.8183e-01, time/batch = 0.7056s	
1326/28500 (epoch 2.326), train_loss = 2.10325851, grad/param norm = 2.9838e-01, time/batch = 0.7087s	
1327/28500 (epoch 2.328), train_loss = 1.72505397, grad/param norm = 2.8591e-01, time/batch = 0.6958s	
1328/28500 (epoch 2.330), train_loss = 1.85131808, grad/param norm = 2.6371e-01, time/batch = 0.6930s	
1329/28500 (epoch 2.332), train_loss = 1.81831058, grad/param norm = 2.2496e-01, time/batch = 0.6963s	
1330/28500 (epoch 2.333), train_loss = 1.73980418, grad/param norm = 2.2128e-01, time/batch = 0.6982s	
1331/28500 (epoch 2.335), train_loss = 1.71927216, grad/param norm = 2.4942e-01, time/batch = 0.6987s	
1332/28500 (epoch 2.337), train_loss = 1.94417339, grad/param norm = 2.8262e-01, time/batch = 0.6978s	
1333/28500 (epoch 2.339), train_loss = 1.87336875, grad/param norm = 2.4620e-01, time/batch = 0.6964s	
1334/28500 (epoch 2.340), train_loss = 1.98037868, grad/param norm = 2.7759e-01, time/batch = 0.6981s	
1335/28500 (epoch 2.342), train_loss = 1.78888750, grad/param norm = 2.9375e-01, time/batch = 0.6965s	
1336/28500 (epoch 2.344), train_loss = 1.86539905, grad/param norm = 3.0943e-01, time/batch = 0.6994s	
1337/28500 (epoch 2.346), train_loss = 1.61398855, grad/param norm = 2.7171e-01, time/batch = 0.6979s	
1338/28500 (epoch 2.347), train_loss = 1.89675209, grad/param norm = 2.6792e-01, time/batch = 0.6983s	
1339/28500 (epoch 2.349), train_loss = 1.77794432, grad/param norm = 2.2190e-01, time/batch = 0.6992s	
1340/28500 (epoch 2.351), train_loss = 1.71035301, grad/param norm = 2.3988e-01, time/batch = 0.6997s	
1341/28500 (epoch 2.353), train_loss = 1.94525702, grad/param norm = 2.3268e-01, time/batch = 0.7056s	
1342/28500 (epoch 2.354), train_loss = 1.81244786, grad/param norm = 2.5002e-01, time/batch = 0.7009s	
1343/28500 (epoch 2.356), train_loss = 1.78549198, grad/param norm = 2.3359e-01, time/batch = 0.7028s	
1344/28500 (epoch 2.358), train_loss = 1.91995589, grad/param norm = 2.3255e-01, time/batch = 0.7003s	
1345/28500 (epoch 2.360), train_loss = 1.87923106, grad/param norm = 2.4740e-01, time/batch = 0.6971s	
1346/28500 (epoch 2.361), train_loss = 1.88991917, grad/param norm = 2.5566e-01, time/batch = 0.6971s	
1347/28500 (epoch 2.363), train_loss = 1.77111617, grad/param norm = 2.2808e-01, time/batch = 0.6956s	
1348/28500 (epoch 2.365), train_loss = 1.80158949, grad/param norm = 2.3926e-01, time/batch = 0.7035s	
1349/28500 (epoch 2.367), train_loss = 1.89298457, grad/param norm = 3.1163e-01, time/batch = 0.7020s	
1350/28500 (epoch 2.368), train_loss = 1.85145768, grad/param norm = 2.6209e-01, time/batch = 0.6999s	
1351/28500 (epoch 2.370), train_loss = 1.87402287, grad/param norm = 2.4230e-01, time/batch = 0.7051s	
1352/28500 (epoch 2.372), train_loss = 1.82646174, grad/param norm = 2.4975e-01, time/batch = 0.6981s	
1353/28500 (epoch 2.374), train_loss = 1.96607085, grad/param norm = 2.6560e-01, time/batch = 0.6930s	
1354/28500 (epoch 2.375), train_loss = 1.97371265, grad/param norm = 2.7621e-01, time/batch = 0.6940s	
1355/28500 (epoch 2.377), train_loss = 1.86496220, grad/param norm = 2.8432e-01, time/batch = 0.6961s	
1356/28500 (epoch 2.379), train_loss = 1.70314632, grad/param norm = 2.9104e-01, time/batch = 0.6989s	
1357/28500 (epoch 2.381), train_loss = 1.79554646, grad/param norm = 2.4424e-01, time/batch = 0.7034s	
1358/28500 (epoch 2.382), train_loss = 1.85529166, grad/param norm = 2.2881e-01, time/batch = 0.6948s	
1359/28500 (epoch 2.384), train_loss = 1.79629144, grad/param norm = 2.3641e-01, time/batch = 0.6945s	
1360/28500 (epoch 2.386), train_loss = 1.70800786, grad/param norm = 2.6096e-01, time/batch = 0.6929s	
1361/28500 (epoch 2.388), train_loss = 1.94614007, grad/param norm = 2.6059e-01, time/batch = 0.7024s	
1362/28500 (epoch 2.389), train_loss = 1.82975088, grad/param norm = 2.3947e-01, time/batch = 0.7089s	
1363/28500 (epoch 2.391), train_loss = 1.79351768, grad/param norm = 2.2723e-01, time/batch = 0.6998s	
1364/28500 (epoch 2.393), train_loss = 1.69910770, grad/param norm = 2.3414e-01, time/batch = 0.6950s	
1365/28500 (epoch 2.395), train_loss = 2.06133212, grad/param norm = 2.2560e-01, time/batch = 0.6974s	
1366/28500 (epoch 2.396), train_loss = 1.95842370, grad/param norm = 2.3902e-01, time/batch = 0.7014s	
1367/28500 (epoch 2.398), train_loss = 1.78518367, grad/param norm = 2.7505e-01, time/batch = 0.7018s	
1368/28500 (epoch 2.400), train_loss = 1.95120948, grad/param norm = 2.3149e-01, time/batch = 0.7082s	
1369/28500 (epoch 2.402), train_loss = 1.84417615, grad/param norm = 2.5868e-01, time/batch = 0.7046s	
1370/28500 (epoch 2.404), train_loss = 1.98120484, grad/param norm = 2.4277e-01, time/batch = 0.7143s	
1371/28500 (epoch 2.405), train_loss = 1.92255373, grad/param norm = 2.2919e-01, time/batch = 0.7037s	
1372/28500 (epoch 2.407), train_loss = 1.91940114, grad/param norm = 2.2379e-01, time/batch = 0.7035s	
1373/28500 (epoch 2.409), train_loss = 1.91314357, grad/param norm = 2.6314e-01, time/batch = 0.6968s	
1374/28500 (epoch 2.411), train_loss = 1.91534642, grad/param norm = 2.5399e-01, time/batch = 0.6986s	
1375/28500 (epoch 2.412), train_loss = 2.01958250, grad/param norm = 2.6081e-01, time/batch = 0.7019s	
1376/28500 (epoch 2.414), train_loss = 1.90184676, grad/param norm = 2.2855e-01, time/batch = 0.7049s	
1377/28500 (epoch 2.416), train_loss = 1.78212305, grad/param norm = 2.6950e-01, time/batch = 0.7002s	
1378/28500 (epoch 2.418), train_loss = 1.93429466, grad/param norm = 2.6664e-01, time/batch = 0.6966s	
1379/28500 (epoch 2.419), train_loss = 1.97742440, grad/param norm = 2.5768e-01, time/batch = 0.6969s	
1380/28500 (epoch 2.421), train_loss = 1.94315560, grad/param norm = 2.8105e-01, time/batch = 0.6958s	
1381/28500 (epoch 2.423), train_loss = 2.06583896, grad/param norm = 2.8337e-01, time/batch = 0.7005s	
1382/28500 (epoch 2.425), train_loss = 1.97503203, grad/param norm = 2.8606e-01, time/batch = 0.7005s	
1383/28500 (epoch 2.426), train_loss = 1.94533700, grad/param norm = 2.8043e-01, time/batch = 0.6984s	
1384/28500 (epoch 2.428), train_loss = 2.06795825, grad/param norm = 2.5652e-01, time/batch = 0.7040s	
1385/28500 (epoch 2.430), train_loss = 1.88665518, grad/param norm = 2.4177e-01, time/batch = 0.6974s	
1386/28500 (epoch 2.432), train_loss = 1.99763476, grad/param norm = 3.2233e-01, time/batch = 0.6982s	
1387/28500 (epoch 2.433), train_loss = 1.85602440, grad/param norm = 2.5820e-01, time/batch = 0.6987s	
1388/28500 (epoch 2.435), train_loss = 1.79978640, grad/param norm = 2.3740e-01, time/batch = 0.6985s	
1389/28500 (epoch 2.437), train_loss = 1.70084235, grad/param norm = 2.3195e-01, time/batch = 0.6972s	
1390/28500 (epoch 2.439), train_loss = 1.77995222, grad/param norm = 2.4924e-01, time/batch = 0.6959s	
1391/28500 (epoch 2.440), train_loss = 1.88290869, grad/param norm = 2.3269e-01, time/batch = 0.7008s	
1392/28500 (epoch 2.442), train_loss = 1.79870315, grad/param norm = 2.4910e-01, time/batch = 0.6976s	
1393/28500 (epoch 2.444), train_loss = 1.76053529, grad/param norm = 2.4470e-01, time/batch = 0.6968s	
1394/28500 (epoch 2.446), train_loss = 1.67758977, grad/param norm = 2.8706e-01, time/batch = 0.6997s	
1395/28500 (epoch 2.447), train_loss = 1.76634025, grad/param norm = 2.6339e-01, time/batch = 0.6970s	
1396/28500 (epoch 2.449), train_loss = 1.84202194, grad/param norm = 3.0107e-01, time/batch = 0.6972s	
1397/28500 (epoch 2.451), train_loss = 1.90108280, grad/param norm = 2.9246e-01, time/batch = 0.6987s	
1398/28500 (epoch 2.453), train_loss = 1.88743262, grad/param norm = 2.5816e-01, time/batch = 0.6993s	
1399/28500 (epoch 2.454), train_loss = 1.74624455, grad/param norm = 2.7165e-01, time/batch = 0.6969s	
1400/28500 (epoch 2.456), train_loss = 1.99117632, grad/param norm = 2.9467e-01, time/batch = 0.6981s	
1401/28500 (epoch 2.458), train_loss = 1.80710042, grad/param norm = 2.6691e-01, time/batch = 0.6999s	
1402/28500 (epoch 2.460), train_loss = 1.95790735, grad/param norm = 2.3601e-01, time/batch = 0.6995s	
1403/28500 (epoch 2.461), train_loss = 1.85762438, grad/param norm = 2.5009e-01, time/batch = 0.6993s	
1404/28500 (epoch 2.463), train_loss = 1.75006093, grad/param norm = 2.5927e-01, time/batch = 0.6973s	
1405/28500 (epoch 2.465), train_loss = 1.67400540, grad/param norm = 2.7778e-01, time/batch = 0.6974s	
1406/28500 (epoch 2.467), train_loss = 1.97480886, grad/param norm = 2.6177e-01, time/batch = 0.6970s	
1407/28500 (epoch 2.468), train_loss = 1.67778815, grad/param norm = 2.1967e-01, time/batch = 0.6976s	
1408/28500 (epoch 2.470), train_loss = 1.93164612, grad/param norm = 2.5884e-01, time/batch = 0.6975s	
1409/28500 (epoch 2.472), train_loss = 1.80991089, grad/param norm = 2.2521e-01, time/batch = 0.6980s	
1410/28500 (epoch 2.474), train_loss = 2.02857803, grad/param norm = 2.4755e-01, time/batch = 0.6971s	
1411/28500 (epoch 2.475), train_loss = 1.83773383, grad/param norm = 2.6363e-01, time/batch = 0.7002s	
1412/28500 (epoch 2.477), train_loss = 1.81054631, grad/param norm = 2.7231e-01, time/batch = 0.6992s	
1413/28500 (epoch 2.479), train_loss = 1.88509218, grad/param norm = 2.3257e-01, time/batch = 0.6974s	
1414/28500 (epoch 2.481), train_loss = 1.89002565, grad/param norm = 2.5310e-01, time/batch = 0.6996s	
1415/28500 (epoch 2.482), train_loss = 1.83701993, grad/param norm = 2.8902e-01, time/batch = 0.7027s	
1416/28500 (epoch 2.484), train_loss = 1.75620625, grad/param norm = 2.6823e-01, time/batch = 0.6959s	
1417/28500 (epoch 2.486), train_loss = 1.80413698, grad/param norm = 2.5283e-01, time/batch = 0.6974s	
1418/28500 (epoch 2.488), train_loss = 1.75959149, grad/param norm = 3.1237e-01, time/batch = 0.6970s	
1419/28500 (epoch 2.489), train_loss = 1.93260542, grad/param norm = 3.1507e-01, time/batch = 0.6967s	
1420/28500 (epoch 2.491), train_loss = 1.78429392, grad/param norm = 2.6203e-01, time/batch = 0.7148s	
1421/28500 (epoch 2.493), train_loss = 1.74415385, grad/param norm = 2.2712e-01, time/batch = 0.6959s	
1422/28500 (epoch 2.495), train_loss = 1.80491683, grad/param norm = 2.2690e-01, time/batch = 0.6968s	
1423/28500 (epoch 2.496), train_loss = 1.94965330, grad/param norm = 2.4368e-01, time/batch = 0.6961s	
1424/28500 (epoch 2.498), train_loss = 1.85524095, grad/param norm = 2.4946e-01, time/batch = 0.6946s	
1425/28500 (epoch 2.500), train_loss = 1.89000196, grad/param norm = 2.5674e-01, time/batch = 0.6941s	
1426/28500 (epoch 2.502), train_loss = 1.90050684, grad/param norm = 2.3015e-01, time/batch = 0.6964s	
1427/28500 (epoch 2.504), train_loss = 1.86029336, grad/param norm = 2.2345e-01, time/batch = 0.7060s	
1428/28500 (epoch 2.505), train_loss = 1.80089874, grad/param norm = 2.1517e-01, time/batch = 0.6969s	
1429/28500 (epoch 2.507), train_loss = 2.06520603, grad/param norm = 2.4390e-01, time/batch = 0.6971s	
1430/28500 (epoch 2.509), train_loss = 1.79179943, grad/param norm = 2.5474e-01, time/batch = 0.6930s	
1431/28500 (epoch 2.511), train_loss = 1.95268308, grad/param norm = 2.5251e-01, time/batch = 0.6953s	
1432/28500 (epoch 2.512), train_loss = 1.79695571, grad/param norm = 2.2685e-01, time/batch = 0.6990s	
1433/28500 (epoch 2.514), train_loss = 1.73703381, grad/param norm = 2.4339e-01, time/batch = 0.6972s	
1434/28500 (epoch 2.516), train_loss = 1.76564842, grad/param norm = 2.2590e-01, time/batch = 0.6939s	
1435/28500 (epoch 2.518), train_loss = 1.77660760, grad/param norm = 2.0966e-01, time/batch = 0.6950s	
1436/28500 (epoch 2.519), train_loss = 1.98138769, grad/param norm = 2.5529e-01, time/batch = 0.6984s	
1437/28500 (epoch 2.521), train_loss = 2.00839440, grad/param norm = 2.5884e-01, time/batch = 0.6935s	
1438/28500 (epoch 2.523), train_loss = 1.89326452, grad/param norm = 2.7601e-01, time/batch = 0.6934s	
1439/28500 (epoch 2.525), train_loss = 1.96056913, grad/param norm = 2.6475e-01, time/batch = 0.6928s	
1440/28500 (epoch 2.526), train_loss = 1.82037671, grad/param norm = 2.5511e-01, time/batch = 0.6982s	
1441/28500 (epoch 2.528), train_loss = 1.94734901, grad/param norm = 2.6317e-01, time/batch = 0.7017s	
1442/28500 (epoch 2.530), train_loss = 1.91424205, grad/param norm = 2.4072e-01, time/batch = 0.7163s	
1443/28500 (epoch 2.532), train_loss = 1.79130114, grad/param norm = 2.5898e-01, time/batch = 0.7014s	
1444/28500 (epoch 2.533), train_loss = 1.97577624, grad/param norm = 2.6275e-01, time/batch = 0.6932s	
1445/28500 (epoch 2.535), train_loss = 1.70059826, grad/param norm = 2.5264e-01, time/batch = 0.6927s	
1446/28500 (epoch 2.537), train_loss = 1.60777248, grad/param norm = 2.3287e-01, time/batch = 0.6989s	
1447/28500 (epoch 2.539), train_loss = 1.76466987, grad/param norm = 2.3250e-01, time/batch = 0.7039s	
1448/28500 (epoch 2.540), train_loss = 1.86338953, grad/param norm = 2.5700e-01, time/batch = 0.6984s	
1449/28500 (epoch 2.542), train_loss = 2.14825299, grad/param norm = 3.2153e-01, time/batch = 0.6960s	
1450/28500 (epoch 2.544), train_loss = 1.95460864, grad/param norm = 2.9554e-01, time/batch = 0.6931s	
1451/28500 (epoch 2.546), train_loss = 1.94298893, grad/param norm = 2.6468e-01, time/batch = 0.6991s	
1452/28500 (epoch 2.547), train_loss = 1.87342373, grad/param norm = 2.3571e-01, time/batch = 0.7012s	
1453/28500 (epoch 2.549), train_loss = 1.71629174, grad/param norm = 2.2947e-01, time/batch = 0.7125s	
1454/28500 (epoch 2.551), train_loss = 2.06879132, grad/param norm = 2.6201e-01, time/batch = 0.6820s	
1455/28500 (epoch 2.553), train_loss = 2.07770533, grad/param norm = 2.4300e-01, time/batch = 0.6840s	
1456/28500 (epoch 2.554), train_loss = 1.84684659, grad/param norm = 2.3182e-01, time/batch = 0.6809s	
1457/28500 (epoch 2.556), train_loss = 1.89944286, grad/param norm = 2.6808e-01, time/batch = 0.6775s	
1458/28500 (epoch 2.558), train_loss = 1.89638962, grad/param norm = 2.4194e-01, time/batch = 0.6891s	
1459/28500 (epoch 2.560), train_loss = 1.90129670, grad/param norm = 2.4889e-01, time/batch = 0.6768s	
1460/28500 (epoch 2.561), train_loss = 1.95159957, grad/param norm = 2.6431e-01, time/batch = 0.6755s	
1461/28500 (epoch 2.563), train_loss = 1.92585432, grad/param norm = 2.4439e-01, time/batch = 0.6825s	
1462/28500 (epoch 2.565), train_loss = 1.82158131, grad/param norm = 2.5950e-01, time/batch = 0.6766s	
1463/28500 (epoch 2.567), train_loss = 1.76263483, grad/param norm = 2.4071e-01, time/batch = 0.6765s	
1464/28500 (epoch 2.568), train_loss = 1.92191377, grad/param norm = 2.4881e-01, time/batch = 0.6769s	
1465/28500 (epoch 2.570), train_loss = 1.77194209, grad/param norm = 3.0135e-01, time/batch = 0.6768s	
1466/28500 (epoch 2.572), train_loss = 1.86455694, grad/param norm = 2.8511e-01, time/batch = 0.6759s	
1467/28500 (epoch 2.574), train_loss = 1.92559595, grad/param norm = 2.4203e-01, time/batch = 0.6764s	
1468/28500 (epoch 2.575), train_loss = 1.76024184, grad/param norm = 2.3750e-01, time/batch = 0.6762s	
1469/28500 (epoch 2.577), train_loss = 1.75198189, grad/param norm = 2.3600e-01, time/batch = 0.6756s	
1470/28500 (epoch 2.579), train_loss = 2.05896809, grad/param norm = 2.6786e-01, time/batch = 0.6757s	
1471/28500 (epoch 2.581), train_loss = 1.77289302, grad/param norm = 2.5623e-01, time/batch = 0.6780s	
1472/28500 (epoch 2.582), train_loss = 1.89786043, grad/param norm = 2.7157e-01, time/batch = 0.6761s	
1473/28500 (epoch 2.584), train_loss = 1.78323730, grad/param norm = 2.3872e-01, time/batch = 0.6779s	
1474/28500 (epoch 2.586), train_loss = 1.62013453, grad/param norm = 2.1747e-01, time/batch = 0.6758s	
1475/28500 (epoch 2.588), train_loss = 1.76007653, grad/param norm = 2.6406e-01, time/batch = 0.6770s	
1476/28500 (epoch 2.589), train_loss = 2.17676111, grad/param norm = 2.6245e-01, time/batch = 0.6758s	
1477/28500 (epoch 2.591), train_loss = 1.91636368, grad/param norm = 2.2273e-01, time/batch = 0.6774s	
1478/28500 (epoch 2.593), train_loss = 1.78674533, grad/param norm = 2.4821e-01, time/batch = 0.6788s	
1479/28500 (epoch 2.595), train_loss = 2.08564412, grad/param norm = 2.9169e-01, time/batch = 0.6815s	
1480/28500 (epoch 2.596), train_loss = 1.95688196, grad/param norm = 3.3265e-01, time/batch = 0.6775s	
1481/28500 (epoch 2.598), train_loss = 1.84049511, grad/param norm = 2.4789e-01, time/batch = 0.6786s	
1482/28500 (epoch 2.600), train_loss = 1.88169115, grad/param norm = 2.2308e-01, time/batch = 0.6792s	
1483/28500 (epoch 2.602), train_loss = 2.03072836, grad/param norm = 2.6933e-01, time/batch = 0.6853s	
1484/28500 (epoch 2.604), train_loss = 1.88319939, grad/param norm = 2.5297e-01, time/batch = 0.6771s	
1485/28500 (epoch 2.605), train_loss = 1.85384450, grad/param norm = 2.3271e-01, time/batch = 0.6764s	
1486/28500 (epoch 2.607), train_loss = 1.80523041, grad/param norm = 2.1911e-01, time/batch = 0.6761s	
1487/28500 (epoch 2.609), train_loss = 1.82563417, grad/param norm = 2.4837e-01, time/batch = 0.6794s	
1488/28500 (epoch 2.611), train_loss = 1.82977926, grad/param norm = 2.2974e-01, time/batch = 0.6792s	
1489/28500 (epoch 2.612), train_loss = 1.87371287, grad/param norm = 2.3919e-01, time/batch = 0.6756s	
1490/28500 (epoch 2.614), train_loss = 1.79781235, grad/param norm = 2.4564e-01, time/batch = 0.6756s	
1491/28500 (epoch 2.616), train_loss = 1.79930701, grad/param norm = 2.5628e-01, time/batch = 0.6775s	
1492/28500 (epoch 2.618), train_loss = 1.66265597, grad/param norm = 2.3435e-01, time/batch = 0.6764s	
1493/28500 (epoch 2.619), train_loss = 1.94403380, grad/param norm = 2.5357e-01, time/batch = 0.6791s	
1494/28500 (epoch 2.621), train_loss = 1.58467883, grad/param norm = 2.1578e-01, time/batch = 0.6792s	
1495/28500 (epoch 2.623), train_loss = 1.84916824, grad/param norm = 2.3283e-01, time/batch = 0.6784s	
1496/28500 (epoch 2.625), train_loss = 1.76180656, grad/param norm = 2.5524e-01, time/batch = 0.6762s	
1497/28500 (epoch 2.626), train_loss = 1.60490914, grad/param norm = 2.3820e-01, time/batch = 0.6790s	
1498/28500 (epoch 2.628), train_loss = 1.69601429, grad/param norm = 2.4649e-01, time/batch = 0.6817s	
1499/28500 (epoch 2.630), train_loss = 1.72512256, grad/param norm = 2.6510e-01, time/batch = 0.6820s	
1500/28500 (epoch 2.632), train_loss = 1.91515727, grad/param norm = 2.9175e-01, time/batch = 0.6814s	
1501/28500 (epoch 2.633), train_loss = 1.81108686, grad/param norm = 2.1112e-01, time/batch = 0.6874s	
1502/28500 (epoch 2.635), train_loss = 1.94187274, grad/param norm = 2.5296e-01, time/batch = 0.6839s	
1503/28500 (epoch 2.637), train_loss = 1.80870432, grad/param norm = 2.5762e-01, time/batch = 0.6768s	
1504/28500 (epoch 2.639), train_loss = 1.57789930, grad/param norm = 2.4717e-01, time/batch = 0.6803s	
1505/28500 (epoch 2.640), train_loss = 1.81384657, grad/param norm = 2.3700e-01, time/batch = 0.6790s	
1506/28500 (epoch 2.642), train_loss = 1.89205318, grad/param norm = 2.2261e-01, time/batch = 0.6810s	
1507/28500 (epoch 2.644), train_loss = 1.85407124, grad/param norm = 2.1184e-01, time/batch = 0.6801s	
1508/28500 (epoch 2.646), train_loss = 1.77150162, grad/param norm = 2.2577e-01, time/batch = 0.6774s	
1509/28500 (epoch 2.647), train_loss = 1.74351076, grad/param norm = 2.5715e-01, time/batch = 0.6771s	
1510/28500 (epoch 2.649), train_loss = 1.75143228, grad/param norm = 2.1511e-01, time/batch = 0.6766s	
1511/28500 (epoch 2.651), train_loss = 1.75365192, grad/param norm = 2.4175e-01, time/batch = 0.6779s	
1512/28500 (epoch 2.653), train_loss = 1.71407795, grad/param norm = 2.3492e-01, time/batch = 0.6782s	
1513/28500 (epoch 2.654), train_loss = 1.73488793, grad/param norm = 2.5033e-01, time/batch = 0.6859s	
1514/28500 (epoch 2.656), train_loss = 1.84920370, grad/param norm = 2.2851e-01, time/batch = 0.6766s	
1515/28500 (epoch 2.658), train_loss = 1.85973281, grad/param norm = 2.3816e-01, time/batch = 0.6759s	
1516/28500 (epoch 2.660), train_loss = 1.76831121, grad/param norm = 1.9766e-01, time/batch = 0.6759s	
1517/28500 (epoch 2.661), train_loss = 1.93895338, grad/param norm = 2.1894e-01, time/batch = 0.6759s	
1518/28500 (epoch 2.663), train_loss = 1.95079835, grad/param norm = 2.4312e-01, time/batch = 0.6757s	
1519/28500 (epoch 2.665), train_loss = 1.80122451, grad/param norm = 2.4344e-01, time/batch = 0.6767s	
1520/28500 (epoch 2.667), train_loss = 1.80538687, grad/param norm = 2.4941e-01, time/batch = 0.6759s	
1521/28500 (epoch 2.668), train_loss = 1.79161558, grad/param norm = 2.5540e-01, time/batch = 0.6817s	
1522/28500 (epoch 2.670), train_loss = 1.76095425, grad/param norm = 2.5776e-01, time/batch = 0.6765s	
1523/28500 (epoch 2.672), train_loss = 1.78638238, grad/param norm = 2.4212e-01, time/batch = 0.6761s	
1524/28500 (epoch 2.674), train_loss = 1.68383957, grad/param norm = 2.6121e-01, time/batch = 0.6757s	
1525/28500 (epoch 2.675), train_loss = 1.65514834, grad/param norm = 2.4562e-01, time/batch = 0.6752s	
1526/28500 (epoch 2.677), train_loss = 1.71210221, grad/param norm = 2.4586e-01, time/batch = 0.6757s	
1527/28500 (epoch 2.679), train_loss = 1.84180121, grad/param norm = 2.1794e-01, time/batch = 0.6756s	
1528/28500 (epoch 2.681), train_loss = 1.91808371, grad/param norm = 2.6319e-01, time/batch = 0.6791s	
1529/28500 (epoch 2.682), train_loss = 1.66845371, grad/param norm = 2.1592e-01, time/batch = 0.6831s	
1530/28500 (epoch 2.684), train_loss = 1.83441378, grad/param norm = 2.2764e-01, time/batch = 0.6908s	
1531/28500 (epoch 2.686), train_loss = 1.73131235, grad/param norm = 2.4118e-01, time/batch = 0.6840s	
1532/28500 (epoch 2.688), train_loss = 1.77923135, grad/param norm = 2.4262e-01, time/batch = 0.6849s	
1533/28500 (epoch 2.689), train_loss = 1.92938395, grad/param norm = 2.9583e-01, time/batch = 0.6821s	
1534/28500 (epoch 2.691), train_loss = 1.80872581, grad/param norm = 2.6360e-01, time/batch = 0.6802s	
1535/28500 (epoch 2.693), train_loss = 1.83028498, grad/param norm = 2.4256e-01, time/batch = 0.6804s	
1536/28500 (epoch 2.695), train_loss = 1.83298722, grad/param norm = 2.6022e-01, time/batch = 0.6800s	
1537/28500 (epoch 2.696), train_loss = 1.90211263, grad/param norm = 3.1189e-01, time/batch = 0.6848s	
1538/28500 (epoch 2.698), train_loss = 1.74070963, grad/param norm = 2.2852e-01, time/batch = 0.6816s	
1539/28500 (epoch 2.700), train_loss = 1.76024254, grad/param norm = 2.4580e-01, time/batch = 0.6822s	
1540/28500 (epoch 2.702), train_loss = 1.92596364, grad/param norm = 2.3817e-01, time/batch = 0.6793s	
1541/28500 (epoch 2.704), train_loss = 1.79446438, grad/param norm = 2.4478e-01, time/batch = 0.6826s	
1542/28500 (epoch 2.705), train_loss = 1.83295850, grad/param norm = 2.5894e-01, time/batch = 0.6805s	
1543/28500 (epoch 2.707), train_loss = 1.81133585, grad/param norm = 2.8703e-01, time/batch = 0.6808s	
1544/28500 (epoch 2.709), train_loss = 1.89933058, grad/param norm = 2.7168e-01, time/batch = 0.6855s	
1545/28500 (epoch 2.711), train_loss = 1.68727132, grad/param norm = 2.4815e-01, time/batch = 0.6894s	
1546/28500 (epoch 2.712), train_loss = 1.84006483, grad/param norm = 2.5140e-01, time/batch = 0.6827s	
1547/28500 (epoch 2.714), train_loss = 1.84874491, grad/param norm = 2.4405e-01, time/batch = 0.6802s	
1548/28500 (epoch 2.716), train_loss = 1.86612884, grad/param norm = 2.3080e-01, time/batch = 0.6803s	
1549/28500 (epoch 2.718), train_loss = 1.67821890, grad/param norm = 2.3087e-01, time/batch = 0.6810s	
1550/28500 (epoch 2.719), train_loss = 1.69357646, grad/param norm = 2.3179e-01, time/batch = 0.6803s	
1551/28500 (epoch 2.721), train_loss = 1.56308669, grad/param norm = 2.3467e-01, time/batch = 0.6830s	
1552/28500 (epoch 2.723), train_loss = 1.80205668, grad/param norm = 2.2560e-01, time/batch = 0.6807s	
1553/28500 (epoch 2.725), train_loss = 1.88554924, grad/param norm = 2.4233e-01, time/batch = 0.6806s	
1554/28500 (epoch 2.726), train_loss = 1.79905403, grad/param norm = 2.4260e-01, time/batch = 0.6799s	
1555/28500 (epoch 2.728), train_loss = 1.66779630, grad/param norm = 2.1204e-01, time/batch = 0.6801s	
1556/28500 (epoch 2.730), train_loss = 1.87007730, grad/param norm = 2.4177e-01, time/batch = 0.6819s	
1557/28500 (epoch 2.732), train_loss = 1.60021399, grad/param norm = 2.5391e-01, time/batch = 0.6806s	
1558/28500 (epoch 2.733), train_loss = 1.71609200, grad/param norm = 2.6625e-01, time/batch = 0.6786s	
1559/28500 (epoch 2.735), train_loss = 1.65180599, grad/param norm = 2.4670e-01, time/batch = 0.6804s	
1560/28500 (epoch 2.737), train_loss = 1.64926521, grad/param norm = 2.1618e-01, time/batch = 0.6789s	
1561/28500 (epoch 2.739), train_loss = 1.83428197, grad/param norm = 2.3420e-01, time/batch = 0.6842s	
1562/28500 (epoch 2.740), train_loss = 1.73954363, grad/param norm = 2.3200e-01, time/batch = 0.6811s	
1563/28500 (epoch 2.742), train_loss = 1.78819334, grad/param norm = 2.3436e-01, time/batch = 0.6839s	
1564/28500 (epoch 2.744), train_loss = 1.86363726, grad/param norm = 2.3700e-01, time/batch = 0.6820s	
1565/28500 (epoch 2.746), train_loss = 1.69047641, grad/param norm = 2.2986e-01, time/batch = 0.6821s	
1566/28500 (epoch 2.747), train_loss = 1.67027785, grad/param norm = 2.4200e-01, time/batch = 0.6817s	
1567/28500 (epoch 2.749), train_loss = 2.06041284, grad/param norm = 2.6773e-01, time/batch = 0.6803s	
1568/28500 (epoch 2.751), train_loss = 1.70267130, grad/param norm = 2.2697e-01, time/batch = 0.6801s	
1569/28500 (epoch 2.753), train_loss = 1.60659838, grad/param norm = 2.0132e-01, time/batch = 0.6807s	
1570/28500 (epoch 2.754), train_loss = 1.61221632, grad/param norm = 2.1569e-01, time/batch = 0.6800s	
1571/28500 (epoch 2.756), train_loss = 1.86159871, grad/param norm = 2.3096e-01, time/batch = 0.6837s	
1572/28500 (epoch 2.758), train_loss = 1.74111633, grad/param norm = 2.1583e-01, time/batch = 0.6824s	
1573/28500 (epoch 2.760), train_loss = 1.69978133, grad/param norm = 2.7535e-01, time/batch = 0.6807s	
1574/28500 (epoch 2.761), train_loss = 1.81170327, grad/param norm = 2.3729e-01, time/batch = 0.6790s	
1575/28500 (epoch 2.763), train_loss = 1.56447735, grad/param norm = 2.3582e-01, time/batch = 0.6798s	
1576/28500 (epoch 2.765), train_loss = 1.67391213, grad/param norm = 2.2202e-01, time/batch = 0.6788s	
1577/28500 (epoch 2.767), train_loss = 1.53822434, grad/param norm = 2.3389e-01, time/batch = 0.6801s	
1578/28500 (epoch 2.768), train_loss = 1.94118990, grad/param norm = 2.7259e-01, time/batch = 0.6895s	
1579/28500 (epoch 2.770), train_loss = 1.66049973, grad/param norm = 2.3878e-01, time/batch = 0.6849s	
1580/28500 (epoch 2.772), train_loss = 1.61891186, grad/param norm = 2.6369e-01, time/batch = 0.6811s	
1581/28500 (epoch 2.774), train_loss = 1.74872521, grad/param norm = 2.4290e-01, time/batch = 0.6835s	
1582/28500 (epoch 2.775), train_loss = 1.86515734, grad/param norm = 2.1763e-01, time/batch = 0.6807s	
1583/28500 (epoch 2.777), train_loss = 1.75563787, grad/param norm = 2.1620e-01, time/batch = 0.6820s	
1584/28500 (epoch 2.779), train_loss = 1.72145416, grad/param norm = 2.4136e-01, time/batch = 0.6935s	
1585/28500 (epoch 2.781), train_loss = 1.83201363, grad/param norm = 2.6509e-01, time/batch = 0.6803s	
1586/28500 (epoch 2.782), train_loss = 1.94394951, grad/param norm = 2.6053e-01, time/batch = 0.6790s	
1587/28500 (epoch 2.784), train_loss = 1.60449326, grad/param norm = 2.0848e-01, time/batch = 0.6806s	
1588/28500 (epoch 2.786), train_loss = 1.79539791, grad/param norm = 2.3326e-01, time/batch = 0.6789s	
1589/28500 (epoch 2.788), train_loss = 1.87564272, grad/param norm = 2.2264e-01, time/batch = 0.6799s	
1590/28500 (epoch 2.789), train_loss = 1.63371534, grad/param norm = 2.5595e-01, time/batch = 0.6832s	
1591/28500 (epoch 2.791), train_loss = 1.74217766, grad/param norm = 2.3752e-01, time/batch = 0.6810s	
1592/28500 (epoch 2.793), train_loss = 1.66890829, grad/param norm = 2.5508e-01, time/batch = 0.6807s	
1593/28500 (epoch 2.795), train_loss = 1.77951025, grad/param norm = 2.4999e-01, time/batch = 0.6790s	
1594/28500 (epoch 2.796), train_loss = 1.66123836, grad/param norm = 2.1654e-01, time/batch = 0.6803s	
1595/28500 (epoch 2.798), train_loss = 1.68968478, grad/param norm = 2.4461e-01, time/batch = 0.6802s	
1596/28500 (epoch 2.800), train_loss = 1.71404684, grad/param norm = 2.3932e-01, time/batch = 0.6811s	
1597/28500 (epoch 2.802), train_loss = 1.82415065, grad/param norm = 2.7024e-01, time/batch = 0.6792s	
1598/28500 (epoch 2.804), train_loss = 1.75898676, grad/param norm = 2.2437e-01, time/batch = 0.6801s	
1599/28500 (epoch 2.805), train_loss = 1.81258740, grad/param norm = 2.4078e-01, time/batch = 0.6804s	
1600/28500 (epoch 2.807), train_loss = 1.93448435, grad/param norm = 2.3051e-01, time/batch = 0.6792s	
1601/28500 (epoch 2.809), train_loss = 1.71328789, grad/param norm = 2.3530e-01, time/batch = 0.6812s	
1602/28500 (epoch 2.811), train_loss = 1.93393108, grad/param norm = 2.5040e-01, time/batch = 0.6807s	
1603/28500 (epoch 2.812), train_loss = 1.82737262, grad/param norm = 2.3013e-01, time/batch = 0.6788s	
1604/28500 (epoch 2.814), train_loss = 1.73601665, grad/param norm = 2.4361e-01, time/batch = 0.6804s	
1605/28500 (epoch 2.816), train_loss = 1.85273802, grad/param norm = 2.3482e-01, time/batch = 0.6804s	
1606/28500 (epoch 2.818), train_loss = 1.73452119, grad/param norm = 2.3738e-01, time/batch = 0.6795s	
1607/28500 (epoch 2.819), train_loss = 1.74811000, grad/param norm = 2.5796e-01, time/batch = 0.6789s	
1608/28500 (epoch 2.821), train_loss = 1.73677885, grad/param norm = 2.5413e-01, time/batch = 0.6788s	
1609/28500 (epoch 2.823), train_loss = 2.03963204, grad/param norm = 2.8363e-01, time/batch = 0.6791s	
1610/28500 (epoch 2.825), train_loss = 1.73183199, grad/param norm = 2.4492e-01, time/batch = 0.6800s	
1611/28500 (epoch 2.826), train_loss = 1.81838859, grad/param norm = 2.6333e-01, time/batch = 0.6824s	
1612/28500 (epoch 2.828), train_loss = 1.62667973, grad/param norm = 2.3310e-01, time/batch = 0.6809s	
1613/28500 (epoch 2.830), train_loss = 1.68568949, grad/param norm = 2.2166e-01, time/batch = 0.6782s	
1614/28500 (epoch 2.832), train_loss = 1.84296236, grad/param norm = 2.5716e-01, time/batch = 0.6792s	
1615/28500 (epoch 2.833), train_loss = 1.90207892, grad/param norm = 2.4373e-01, time/batch = 0.6829s	
1616/28500 (epoch 2.835), train_loss = 1.74879141, grad/param norm = 2.5446e-01, time/batch = 0.6851s	
1617/28500 (epoch 2.837), train_loss = 1.67627456, grad/param norm = 2.2836e-01, time/batch = 0.7082s	
1618/28500 (epoch 2.839), train_loss = 1.92061497, grad/param norm = 2.5041e-01, time/batch = 0.6862s	
1619/28500 (epoch 2.840), train_loss = 1.88071123, grad/param norm = 2.3524e-01, time/batch = 0.6847s	
1620/28500 (epoch 2.842), train_loss = 1.76079812, grad/param norm = 2.3084e-01, time/batch = 0.6949s	
1621/28500 (epoch 2.844), train_loss = 1.77040431, grad/param norm = 2.3314e-01, time/batch = 0.7163s	
1622/28500 (epoch 2.846), train_loss = 1.88301213, grad/param norm = 2.3753e-01, time/batch = 0.7184s	
1623/28500 (epoch 2.847), train_loss = 1.72635988, grad/param norm = 2.1386e-01, time/batch = 0.7027s	
1624/28500 (epoch 2.849), train_loss = 1.66420160, grad/param norm = 1.9960e-01, time/batch = 0.6938s	
1625/28500 (epoch 2.851), train_loss = 1.62326436, grad/param norm = 2.2522e-01, time/batch = 0.6934s	
1626/28500 (epoch 2.853), train_loss = 1.83597677, grad/param norm = 2.3242e-01, time/batch = 0.7043s	
1627/28500 (epoch 2.854), train_loss = 1.70927457, grad/param norm = 2.1876e-01, time/batch = 0.7085s	
1628/28500 (epoch 2.856), train_loss = 1.83089409, grad/param norm = 2.5364e-01, time/batch = 0.7015s	
1629/28500 (epoch 2.858), train_loss = 1.63059374, grad/param norm = 2.3026e-01, time/batch = 0.6952s	
1630/28500 (epoch 2.860), train_loss = 1.85453350, grad/param norm = 2.5918e-01, time/batch = 0.6946s	
1631/28500 (epoch 2.861), train_loss = 1.70796912, grad/param norm = 2.2003e-01, time/batch = 0.6999s	
1632/28500 (epoch 2.863), train_loss = 1.90315499, grad/param norm = 2.3761e-01, time/batch = 0.6959s	
1633/28500 (epoch 2.865), train_loss = 1.77487096, grad/param norm = 2.4466e-01, time/batch = 0.6948s	
1634/28500 (epoch 2.867), train_loss = 1.86411737, grad/param norm = 2.3916e-01, time/batch = 0.6978s	
1635/28500 (epoch 2.868), train_loss = 1.60688346, grad/param norm = 2.7057e-01, time/batch = 0.6962s	
1636/28500 (epoch 2.870), train_loss = 1.54167575, grad/param norm = 2.2622e-01, time/batch = 0.7017s	
1637/28500 (epoch 2.872), train_loss = 1.89413608, grad/param norm = 2.7115e-01, time/batch = 0.6983s	
1638/28500 (epoch 2.874), train_loss = 1.76167090, grad/param norm = 2.6340e-01, time/batch = 0.6981s	
1639/28500 (epoch 2.875), train_loss = 1.83458357, grad/param norm = 2.5301e-01, time/batch = 0.7035s	
1640/28500 (epoch 2.877), train_loss = 1.77111894, grad/param norm = 2.3305e-01, time/batch = 0.7054s	
1641/28500 (epoch 2.879), train_loss = 1.75015272, grad/param norm = 2.1649e-01, time/batch = 0.7021s	
1642/28500 (epoch 2.881), train_loss = 1.82609939, grad/param norm = 2.3923e-01, time/batch = 0.6975s	
1643/28500 (epoch 2.882), train_loss = 1.72505404, grad/param norm = 2.4289e-01, time/batch = 0.6992s	
1644/28500 (epoch 2.884), train_loss = 1.81687447, grad/param norm = 2.5065e-01, time/batch = 0.6984s	
1645/28500 (epoch 2.886), train_loss = 1.63050648, grad/param norm = 2.6620e-01, time/batch = 0.6981s	
1646/28500 (epoch 2.888), train_loss = 1.58162673, grad/param norm = 2.2416e-01, time/batch = 0.6976s	
1647/28500 (epoch 2.889), train_loss = 1.61762189, grad/param norm = 2.0431e-01, time/batch = 0.6975s	
1648/28500 (epoch 2.891), train_loss = 1.76005507, grad/param norm = 2.1405e-01, time/batch = 0.6995s	
1649/28500 (epoch 2.893), train_loss = 1.75073950, grad/param norm = 2.2412e-01, time/batch = 0.6978s	
1650/28500 (epoch 2.895), train_loss = 1.94171530, grad/param norm = 2.5577e-01, time/batch = 0.6999s	
1651/28500 (epoch 2.896), train_loss = 1.90474701, grad/param norm = 2.5265e-01, time/batch = 0.7043s	
1652/28500 (epoch 2.898), train_loss = 1.64250657, grad/param norm = 2.0497e-01, time/batch = 0.6983s	
1653/28500 (epoch 2.900), train_loss = 1.61913687, grad/param norm = 2.3602e-01, time/batch = 0.6982s	
1654/28500 (epoch 2.902), train_loss = 1.65952491, grad/param norm = 2.2589e-01, time/batch = 0.6995s	
1655/28500 (epoch 2.904), train_loss = 1.65659948, grad/param norm = 2.1632e-01, time/batch = 0.6985s	
1656/28500 (epoch 2.905), train_loss = 1.81059666, grad/param norm = 2.0936e-01, time/batch = 0.6968s	
1657/28500 (epoch 2.907), train_loss = 1.96376417, grad/param norm = 2.6586e-01, time/batch = 0.6966s	
1658/28500 (epoch 2.909), train_loss = 1.67058078, grad/param norm = 2.2092e-01, time/batch = 0.6999s	
1659/28500 (epoch 2.911), train_loss = 1.71936716, grad/param norm = 2.2277e-01, time/batch = 0.6980s	
1660/28500 (epoch 2.912), train_loss = 1.49094052, grad/param norm = 2.5241e-01, time/batch = 0.6979s	
1661/28500 (epoch 2.914), train_loss = 1.88542517, grad/param norm = 2.7500e-01, time/batch = 0.7007s	
1662/28500 (epoch 2.916), train_loss = 1.80413460, grad/param norm = 2.5585e-01, time/batch = 0.6999s	
1663/28500 (epoch 2.918), train_loss = 1.88804681, grad/param norm = 2.4448e-01, time/batch = 0.7052s	
1664/28500 (epoch 2.919), train_loss = 1.63973900, grad/param norm = 2.0412e-01, time/batch = 0.7050s	
1665/28500 (epoch 2.921), train_loss = 1.93049261, grad/param norm = 2.4343e-01, time/batch = 0.7063s	
1666/28500 (epoch 2.923), train_loss = 1.90478359, grad/param norm = 2.7260e-01, time/batch = 0.6970s	
1667/28500 (epoch 2.925), train_loss = 1.69225743, grad/param norm = 2.3811e-01, time/batch = 0.7039s	
1668/28500 (epoch 2.926), train_loss = 1.81242925, grad/param norm = 2.4954e-01, time/batch = 0.6929s	
1669/28500 (epoch 2.928), train_loss = 1.63556631, grad/param norm = 2.2476e-01, time/batch = 0.7018s	
1670/28500 (epoch 2.930), train_loss = 1.43885914, grad/param norm = 2.0246e-01, time/batch = 0.6956s	
1671/28500 (epoch 2.932), train_loss = 1.59553135, grad/param norm = 1.9307e-01, time/batch = 0.7010s	
1672/28500 (epoch 2.933), train_loss = 1.76616064, grad/param norm = 1.9989e-01, time/batch = 0.6952s	
1673/28500 (epoch 2.935), train_loss = 1.69396897, grad/param norm = 2.4404e-01, time/batch = 0.7084s	
1674/28500 (epoch 2.937), train_loss = 1.86210108, grad/param norm = 2.3231e-01, time/batch = 0.6935s	
1675/28500 (epoch 2.939), train_loss = 2.01261728, grad/param norm = 2.6826e-01, time/batch = 0.6859s	
1676/28500 (epoch 2.940), train_loss = 1.75008528, grad/param norm = 2.2216e-01, time/batch = 0.6824s	
1677/28500 (epoch 2.942), train_loss = 1.82688896, grad/param norm = 2.4653e-01, time/batch = 0.6851s	
1678/28500 (epoch 2.944), train_loss = 1.78950516, grad/param norm = 2.1548e-01, time/batch = 0.6779s	
1679/28500 (epoch 2.946), train_loss = 1.86206389, grad/param norm = 2.0538e-01, time/batch = 0.6769s	
1680/28500 (epoch 2.947), train_loss = 2.10718195, grad/param norm = 2.4806e-01, time/batch = 0.6812s	
1681/28500 (epoch 2.949), train_loss = 1.64079934, grad/param norm = 2.4349e-01, time/batch = 0.6837s	
1682/28500 (epoch 2.951), train_loss = 1.93111465, grad/param norm = 2.2363e-01, time/batch = 0.6884s	
1683/28500 (epoch 2.953), train_loss = 1.85653945, grad/param norm = 2.6329e-01, time/batch = 0.6799s	
1684/28500 (epoch 2.954), train_loss = 1.83179862, grad/param norm = 2.3724e-01, time/batch = 0.6770s	
1685/28500 (epoch 2.956), train_loss = 1.81687765, grad/param norm = 2.6068e-01, time/batch = 0.6774s	
1686/28500 (epoch 2.958), train_loss = 1.78965384, grad/param norm = 2.4965e-01, time/batch = 0.6793s	
1687/28500 (epoch 2.960), train_loss = 1.66228417, grad/param norm = 2.7962e-01, time/batch = 0.6765s	
1688/28500 (epoch 2.961), train_loss = 1.94929721, grad/param norm = 2.7237e-01, time/batch = 0.6816s	
1689/28500 (epoch 2.963), train_loss = 1.81093707, grad/param norm = 2.0715e-01, time/batch = 0.6796s	
1690/28500 (epoch 2.965), train_loss = 1.67197106, grad/param norm = 2.1161e-01, time/batch = 0.6802s	
1691/28500 (epoch 2.967), train_loss = 1.57491200, grad/param norm = 2.1123e-01, time/batch = 0.6791s	
1692/28500 (epoch 2.968), train_loss = 1.54744313, grad/param norm = 2.1025e-01, time/batch = 0.6800s	
1693/28500 (epoch 2.970), train_loss = 1.85915729, grad/param norm = 2.4127e-01, time/batch = 0.6806s	
1694/28500 (epoch 2.972), train_loss = 2.01633066, grad/param norm = 2.5964e-01, time/batch = 0.6840s	
1695/28500 (epoch 2.974), train_loss = 1.98838430, grad/param norm = 2.4485e-01, time/batch = 0.6809s	
1696/28500 (epoch 2.975), train_loss = 1.75028290, grad/param norm = 2.1242e-01, time/batch = 0.6805s	
1697/28500 (epoch 2.977), train_loss = 1.94609558, grad/param norm = 2.2447e-01, time/batch = 0.6786s	
1698/28500 (epoch 2.979), train_loss = 1.71395701, grad/param norm = 2.2257e-01, time/batch = 0.6775s	
1699/28500 (epoch 2.981), train_loss = 1.71081551, grad/param norm = 2.2241e-01, time/batch = 0.6769s	
1700/28500 (epoch 2.982), train_loss = 1.60247085, grad/param norm = 2.1848e-01, time/batch = 0.6771s	
1701/28500 (epoch 2.984), train_loss = 1.80782701, grad/param norm = 2.2622e-01, time/batch = 0.6832s	
1702/28500 (epoch 2.986), train_loss = 1.87465974, grad/param norm = 2.2445e-01, time/batch = 0.6870s	
1703/28500 (epoch 2.988), train_loss = 1.54802198, grad/param norm = 2.0705e-01, time/batch = 0.7000s	
1704/28500 (epoch 2.989), train_loss = 1.76138802, grad/param norm = 2.3966e-01, time/batch = 0.7047s	
1705/28500 (epoch 2.991), train_loss = 1.71131233, grad/param norm = 2.5685e-01, time/batch = 0.6982s	
1706/28500 (epoch 2.993), train_loss = 1.75535942, grad/param norm = 2.5041e-01, time/batch = 0.7048s	
1707/28500 (epoch 2.995), train_loss = 1.67431781, grad/param norm = 2.0909e-01, time/batch = 0.6865s	
1708/28500 (epoch 2.996), train_loss = 1.63045200, grad/param norm = 2.2785e-01, time/batch = 0.7018s	
1709/28500 (epoch 2.998), train_loss = 1.81732698, grad/param norm = 2.6379e-01, time/batch = 0.6929s	
1710/28500 (epoch 3.000), train_loss = 1.69834074, grad/param norm = 2.1381e-01, time/batch = 0.6871s	
1711/28500 (epoch 3.002), train_loss = 1.79085038, grad/param norm = 2.3075e-01, time/batch = 0.7012s	
1712/28500 (epoch 3.004), train_loss = 1.64918207, grad/param norm = 2.7511e-01, time/batch = 0.6979s	
1713/28500 (epoch 3.005), train_loss = 1.77095661, grad/param norm = 2.2297e-01, time/batch = 0.6952s	
1714/28500 (epoch 3.007), train_loss = 1.54813254, grad/param norm = 2.0775e-01, time/batch = 0.6933s	
1715/28500 (epoch 3.009), train_loss = 1.86310569, grad/param norm = 2.5334e-01, time/batch = 0.6777s	
1716/28500 (epoch 3.011), train_loss = 1.72770800, grad/param norm = 2.6344e-01, time/batch = 0.6772s	
1717/28500 (epoch 3.012), train_loss = 1.55820801, grad/param norm = 2.1008e-01, time/batch = 0.6797s	
1718/28500 (epoch 3.014), train_loss = 1.61371843, grad/param norm = 2.2983e-01, time/batch = 0.6822s	
1719/28500 (epoch 3.016), train_loss = 1.65987712, grad/param norm = 2.3953e-01, time/batch = 0.6802s	
1720/28500 (epoch 3.018), train_loss = 1.71189736, grad/param norm = 2.7439e-01, time/batch = 0.6777s	
1721/28500 (epoch 3.019), train_loss = 1.72281835, grad/param norm = 2.3138e-01, time/batch = 0.6818s	
1722/28500 (epoch 3.021), train_loss = 1.67411083, grad/param norm = 2.1713e-01, time/batch = 0.6815s	
1723/28500 (epoch 3.023), train_loss = 1.75664709, grad/param norm = 2.3190e-01, time/batch = 0.6810s	
1724/28500 (epoch 3.025), train_loss = 1.65271109, grad/param norm = 2.1665e-01, time/batch = 0.6789s	
1725/28500 (epoch 3.026), train_loss = 1.77164360, grad/param norm = 2.6845e-01, time/batch = 0.6908s	
1726/28500 (epoch 3.028), train_loss = 1.79677888, grad/param norm = 2.7488e-01, time/batch = 0.6828s	
1727/28500 (epoch 3.030), train_loss = 1.83944113, grad/param norm = 2.6060e-01, time/batch = 0.6807s	
1728/28500 (epoch 3.032), train_loss = 1.83394982, grad/param norm = 2.4943e-01, time/batch = 0.6799s	
1729/28500 (epoch 3.033), train_loss = 1.94344402, grad/param norm = 2.5475e-01, time/batch = 0.6776s	
1730/28500 (epoch 3.035), train_loss = 1.78022607, grad/param norm = 2.3991e-01, time/batch = 0.6777s	
1731/28500 (epoch 3.037), train_loss = 1.81891288, grad/param norm = 2.3894e-01, time/batch = 0.6803s	
1732/28500 (epoch 3.039), train_loss = 1.88273664, grad/param norm = 2.2650e-01, time/batch = 0.6801s	
1733/28500 (epoch 3.040), train_loss = 1.87581470, grad/param norm = 2.2521e-01, time/batch = 0.6805s	
1734/28500 (epoch 3.042), train_loss = 1.93830372, grad/param norm = 2.5221e-01, time/batch = 0.6805s	
1735/28500 (epoch 3.044), train_loss = 1.79496355, grad/param norm = 2.5184e-01, time/batch = 0.6791s	
1736/28500 (epoch 3.046), train_loss = 1.89097243, grad/param norm = 2.2169e-01, time/batch = 0.6772s	
1737/28500 (epoch 3.047), train_loss = 1.89686319, grad/param norm = 2.2961e-01, time/batch = 0.6778s	
1738/28500 (epoch 3.049), train_loss = 1.82344105, grad/param norm = 2.5594e-01, time/batch = 0.6769s	
1739/28500 (epoch 3.051), train_loss = 1.76584276, grad/param norm = 2.0680e-01, time/batch = 0.6793s	
1740/28500 (epoch 3.053), train_loss = 1.86928181, grad/param norm = 2.3706e-01, time/batch = 0.6901s	
1741/28500 (epoch 3.054), train_loss = 1.86615528, grad/param norm = 2.2929e-01, time/batch = 0.6787s	
1742/28500 (epoch 3.056), train_loss = 1.61982877, grad/param norm = 2.0358e-01, time/batch = 0.6777s	
1743/28500 (epoch 3.058), train_loss = 1.68303601, grad/param norm = 2.4317e-01, time/batch = 0.6775s	
1744/28500 (epoch 3.060), train_loss = 1.76376727, grad/param norm = 2.5955e-01, time/batch = 0.6773s	
1745/28500 (epoch 3.061), train_loss = 1.85973039, grad/param norm = 2.4829e-01, time/batch = 0.6774s	
1746/28500 (epoch 3.063), train_loss = 1.91828191, grad/param norm = 2.2123e-01, time/batch = 0.6776s	
1747/28500 (epoch 3.065), train_loss = 2.01016536, grad/param norm = 2.3666e-01, time/batch = 0.6771s	
1748/28500 (epoch 3.067), train_loss = 1.73907849, grad/param norm = 2.5157e-01, time/batch = 0.6775s	
1749/28500 (epoch 3.068), train_loss = 1.62375293, grad/param norm = 2.0939e-01, time/batch = 0.6893s	
1750/28500 (epoch 3.070), train_loss = 1.83355097, grad/param norm = 2.2942e-01, time/batch = 0.6785s	
1751/28500 (epoch 3.072), train_loss = 2.01938391, grad/param norm = 2.3861e-01, time/batch = 0.6879s	
1752/28500 (epoch 3.074), train_loss = 1.82398383, grad/param norm = 2.3991e-01, time/batch = 0.6893s	
1753/28500 (epoch 3.075), train_loss = 1.69823212, grad/param norm = 2.1691e-01, time/batch = 0.6777s	
1754/28500 (epoch 3.077), train_loss = 1.80791326, grad/param norm = 2.0941e-01, time/batch = 0.6852s	
1755/28500 (epoch 3.079), train_loss = 1.78152575, grad/param norm = 2.3022e-01, time/batch = 0.6809s	
1756/28500 (epoch 3.081), train_loss = 1.90834945, grad/param norm = 2.3835e-01, time/batch = 0.6769s	
1757/28500 (epoch 3.082), train_loss = 1.85567038, grad/param norm = 2.6664e-01, time/batch = 0.6925s	
1758/28500 (epoch 3.084), train_loss = 1.85134200, grad/param norm = 2.1921e-01, time/batch = 0.6826s	
1759/28500 (epoch 3.086), train_loss = 1.65917899, grad/param norm = 2.2625e-01, time/batch = 0.6781s	
1760/28500 (epoch 3.088), train_loss = 1.64954654, grad/param norm = 2.3040e-01, time/batch = 0.6779s	
1761/28500 (epoch 3.089), train_loss = 1.92169675, grad/param norm = 2.1680e-01, time/batch = 0.6782s	
1762/28500 (epoch 3.091), train_loss = 1.59219157, grad/param norm = 2.0809e-01, time/batch = 0.6770s	
1763/28500 (epoch 3.093), train_loss = 1.75954971, grad/param norm = 2.1502e-01, time/batch = 0.6765s	
1764/28500 (epoch 3.095), train_loss = 1.76268388, grad/param norm = 2.3579e-01, time/batch = 0.6764s	
1765/28500 (epoch 3.096), train_loss = 1.87316923, grad/param norm = 2.2816e-01, time/batch = 0.6803s	
1766/28500 (epoch 3.098), train_loss = 1.94936957, grad/param norm = 2.4906e-01, time/batch = 0.6896s	
1767/28500 (epoch 3.100), train_loss = 1.66266645, grad/param norm = 2.4116e-01, time/batch = 0.6767s	
1768/28500 (epoch 3.102), train_loss = 1.93332107, grad/param norm = 2.1593e-01, time/batch = 0.6762s	
1769/28500 (epoch 3.104), train_loss = 1.77649141, grad/param norm = 2.2937e-01, time/batch = 0.6762s	
1770/28500 (epoch 3.105), train_loss = 1.79460798, grad/param norm = 2.3532e-01, time/batch = 0.6762s	
1771/28500 (epoch 3.107), train_loss = 1.69603062, grad/param norm = 2.5761e-01, time/batch = 0.6781s	
1772/28500 (epoch 3.109), train_loss = 1.66100449, grad/param norm = 2.1967e-01, time/batch = 0.6783s	
1773/28500 (epoch 3.111), train_loss = 1.76061098, grad/param norm = 2.2406e-01, time/batch = 0.6766s	
1774/28500 (epoch 3.112), train_loss = 1.84078758, grad/param norm = 2.1912e-01, time/batch = 0.6766s	
1775/28500 (epoch 3.114), train_loss = 1.71459254, grad/param norm = 2.1779e-01, time/batch = 0.6772s	
1776/28500 (epoch 3.116), train_loss = 1.91655929, grad/param norm = 2.4316e-01, time/batch = 0.6766s	
1777/28500 (epoch 3.118), train_loss = 1.61597659, grad/param norm = 2.2582e-01, time/batch = 0.6763s	
1778/28500 (epoch 3.119), train_loss = 1.83110264, grad/param norm = 2.4274e-01, time/batch = 0.6849s	
1779/28500 (epoch 3.121), train_loss = 1.96410713, grad/param norm = 2.2646e-01, time/batch = 0.6851s	
1780/28500 (epoch 3.123), train_loss = 1.83404961, grad/param norm = 2.6408e-01, time/batch = 0.6798s	
1781/28500 (epoch 3.125), train_loss = 1.88426165, grad/param norm = 2.2125e-01, time/batch = 0.6801s	
1782/28500 (epoch 3.126), train_loss = 1.79367353, grad/param norm = 2.2680e-01, time/batch = 0.6791s	
1783/28500 (epoch 3.128), train_loss = 1.70785054, grad/param norm = 2.7927e-01, time/batch = 0.6784s	
1784/28500 (epoch 3.130), train_loss = 1.78595001, grad/param norm = 2.3676e-01, time/batch = 0.6783s	
1785/28500 (epoch 3.132), train_loss = 1.84213623, grad/param norm = 2.4353e-01, time/batch = 0.6782s	
1786/28500 (epoch 3.133), train_loss = 1.70261099, grad/param norm = 2.1487e-01, time/batch = 0.6789s	
1787/28500 (epoch 3.135), train_loss = 1.75652306, grad/param norm = 2.0998e-01, time/batch = 0.6838s	
1788/28500 (epoch 3.137), train_loss = 1.67770710, grad/param norm = 2.3762e-01, time/batch = 0.6878s	
1789/28500 (epoch 3.139), train_loss = 1.69852452, grad/param norm = 2.0614e-01, time/batch = 0.6884s	
1790/28500 (epoch 3.140), train_loss = 1.73736048, grad/param norm = 2.1594e-01, time/batch = 0.6893s	
1791/28500 (epoch 3.142), train_loss = 1.80999698, grad/param norm = 2.4371e-01, time/batch = 0.6873s	
1792/28500 (epoch 3.144), train_loss = 1.65170933, grad/param norm = 2.2603e-01, time/batch = 0.6863s	
1793/28500 (epoch 3.146), train_loss = 1.66390870, grad/param norm = 2.3395e-01, time/batch = 0.6821s	
1794/28500 (epoch 3.147), train_loss = 1.57500038, grad/param norm = 2.0071e-01, time/batch = 0.6796s	
1795/28500 (epoch 3.149), train_loss = 1.66712017, grad/param norm = 2.1213e-01, time/batch = 0.6788s	
1796/28500 (epoch 3.151), train_loss = 1.61864323, grad/param norm = 2.2601e-01, time/batch = 0.6800s	
1797/28500 (epoch 3.153), train_loss = 1.68231750, grad/param norm = 2.4728e-01, time/batch = 0.6807s	
1798/28500 (epoch 3.154), train_loss = 1.66040033, grad/param norm = 2.1068e-01, time/batch = 0.6807s	
1799/28500 (epoch 3.156), train_loss = 1.95112852, grad/param norm = 2.4034e-01, time/batch = 0.6841s	
1800/28500 (epoch 3.158), train_loss = 1.68268324, grad/param norm = 2.1643e-01, time/batch = 0.6855s	
1801/28500 (epoch 3.160), train_loss = 1.64319630, grad/param norm = 2.4209e-01, time/batch = 0.6875s	
1802/28500 (epoch 3.161), train_loss = 1.82419648, grad/param norm = 2.6483e-01, time/batch = 0.6831s	
1803/28500 (epoch 3.163), train_loss = 1.68853271, grad/param norm = 2.6247e-01, time/batch = 0.6798s	
1804/28500 (epoch 3.165), train_loss = 1.92958485, grad/param norm = 2.3111e-01, time/batch = 0.6804s	
1805/28500 (epoch 3.167), train_loss = 1.96757698, grad/param norm = 2.2194e-01, time/batch = 0.6864s	
1806/28500 (epoch 3.168), train_loss = 1.83403219, grad/param norm = 2.6319e-01, time/batch = 0.6958s	
1807/28500 (epoch 3.170), train_loss = 1.90763697, grad/param norm = 2.6538e-01, time/batch = 0.6867s	
1808/28500 (epoch 3.172), train_loss = 1.73799295, grad/param norm = 3.1062e-01, time/batch = 0.6840s	
1809/28500 (epoch 3.174), train_loss = 1.94887684, grad/param norm = 2.1496e-01, time/batch = 0.7792s	
1810/28500 (epoch 3.175), train_loss = 1.70897744, grad/param norm = 2.0196e-01, time/batch = 0.6809s	
1811/28500 (epoch 3.177), train_loss = 1.84436160, grad/param norm = 2.1858e-01, time/batch = 0.6838s	
1812/28500 (epoch 3.179), train_loss = 1.70113687, grad/param norm = 2.3733e-01, time/batch = 0.6832s	
1813/28500 (epoch 3.181), train_loss = 1.89086487, grad/param norm = 2.4841e-01, time/batch = 0.6899s	
1814/28500 (epoch 3.182), train_loss = 1.77657089, grad/param norm = 2.5535e-01, time/batch = 0.6755s	
1815/28500 (epoch 3.184), train_loss = 1.95697386, grad/param norm = 2.4339e-01, time/batch = 0.6765s	
1816/28500 (epoch 3.186), train_loss = 1.89407143, grad/param norm = 2.5562e-01, time/batch = 0.6782s	
1817/28500 (epoch 3.188), train_loss = 1.72043381, grad/param norm = 2.2564e-01, time/batch = 0.6756s	
1818/28500 (epoch 3.189), train_loss = 1.87865926, grad/param norm = 2.3256e-01, time/batch = 0.6758s	
1819/28500 (epoch 3.191), train_loss = 1.99592609, grad/param norm = 2.3589e-01, time/batch = 0.6779s	
1820/28500 (epoch 3.193), train_loss = 1.82286517, grad/param norm = 2.4338e-01, time/batch = 0.6762s	
1821/28500 (epoch 3.195), train_loss = 1.85953304, grad/param norm = 2.4414e-01, time/batch = 0.6789s	
1822/28500 (epoch 3.196), train_loss = 1.77796498, grad/param norm = 2.4096e-01, time/batch = 0.6768s	
1823/28500 (epoch 3.198), train_loss = 1.76016360, grad/param norm = 2.2896e-01, time/batch = 0.6764s	
1824/28500 (epoch 3.200), train_loss = 1.72707646, grad/param norm = 1.9675e-01, time/batch = 0.6759s	
1825/28500 (epoch 3.202), train_loss = 1.82208869, grad/param norm = 2.4355e-01, time/batch = 0.6763s	
1826/28500 (epoch 3.204), train_loss = 1.58176118, grad/param norm = 1.9558e-01, time/batch = 0.6758s	
1827/28500 (epoch 3.205), train_loss = 1.65534878, grad/param norm = 2.1308e-01, time/batch = 0.6767s	
1828/28500 (epoch 3.207), train_loss = 1.80626932, grad/param norm = 2.4180e-01, time/batch = 0.6775s	
1829/28500 (epoch 3.209), train_loss = 1.72954130, grad/param norm = 2.4969e-01, time/batch = 0.6761s	
1830/28500 (epoch 3.211), train_loss = 1.61695072, grad/param norm = 2.0969e-01, time/batch = 0.6752s	
1831/28500 (epoch 3.212), train_loss = 1.63562874, grad/param norm = 2.2250e-01, time/batch = 0.6802s	
1832/28500 (epoch 3.214), train_loss = 1.85265543, grad/param norm = 2.4406e-01, time/batch = 0.6767s	
1833/28500 (epoch 3.216), train_loss = 1.61698366, grad/param norm = 1.9670e-01, time/batch = 0.6769s	
1834/28500 (epoch 3.218), train_loss = 1.76272829, grad/param norm = 1.9886e-01, time/batch = 0.6782s	
1835/28500 (epoch 3.219), train_loss = 1.69823258, grad/param norm = 2.0944e-01, time/batch = 0.6813s	
1836/28500 (epoch 3.221), train_loss = 1.64158597, grad/param norm = 2.0774e-01, time/batch = 0.6792s	
1837/28500 (epoch 3.223), train_loss = 1.87139695, grad/param norm = 2.5478e-01, time/batch = 0.6798s	
1838/28500 (epoch 3.225), train_loss = 1.92152258, grad/param norm = 2.4535e-01, time/batch = 0.6798s	
1839/28500 (epoch 3.226), train_loss = 1.79318618, grad/param norm = 2.4920e-01, time/batch = 0.6797s	
1840/28500 (epoch 3.228), train_loss = 1.76109743, grad/param norm = 2.2624e-01, time/batch = 0.6804s	
1841/28500 (epoch 3.230), train_loss = 1.74149392, grad/param norm = 2.1602e-01, time/batch = 0.6823s	
1842/28500 (epoch 3.232), train_loss = 1.81607414, grad/param norm = 2.2376e-01, time/batch = 0.6791s	
1843/28500 (epoch 3.233), train_loss = 1.78556429, grad/param norm = 2.4085e-01, time/batch = 0.6818s	
1844/28500 (epoch 3.235), train_loss = 1.63774907, grad/param norm = 2.1305e-01, time/batch = 0.6863s	
1845/28500 (epoch 3.237), train_loss = 1.58498357, grad/param norm = 1.9250e-01, time/batch = 0.6808s	
1846/28500 (epoch 3.239), train_loss = 1.66206161, grad/param norm = 2.1098e-01, time/batch = 0.6823s	
1847/28500 (epoch 3.240), train_loss = 1.60310391, grad/param norm = 2.0505e-01, time/batch = 0.6825s	
1848/28500 (epoch 3.242), train_loss = 1.79878936, grad/param norm = 2.1791e-01, time/batch = 0.6826s	
1849/28500 (epoch 3.244), train_loss = 1.85109353, grad/param norm = 2.1831e-01, time/batch = 0.6804s	
1850/28500 (epoch 3.246), train_loss = 1.76251528, grad/param norm = 2.1649e-01, time/batch = 0.6802s	
1851/28500 (epoch 3.247), train_loss = 1.92168931, grad/param norm = 2.2733e-01, time/batch = 0.6822s	
1852/28500 (epoch 3.249), train_loss = 1.78373952, grad/param norm = 2.5967e-01, time/batch = 0.6797s	
1853/28500 (epoch 3.251), train_loss = 1.50685080, grad/param norm = 2.0317e-01, time/batch = 0.6806s	
1854/28500 (epoch 3.253), train_loss = 1.82546537, grad/param norm = 2.1596e-01, time/batch = 0.6797s	
1855/28500 (epoch 3.254), train_loss = 1.80163756, grad/param norm = 2.1382e-01, time/batch = 0.6815s	
1856/28500 (epoch 3.256), train_loss = 1.68255140, grad/param norm = 2.2005e-01, time/batch = 0.6810s	
1857/28500 (epoch 3.258), train_loss = 1.72210090, grad/param norm = 2.5104e-01, time/batch = 0.6799s	
1858/28500 (epoch 3.260), train_loss = 1.70818194, grad/param norm = 2.2220e-01, time/batch = 0.6795s	
1859/28500 (epoch 3.261), train_loss = 1.67414349, grad/param norm = 2.1820e-01, time/batch = 0.6796s	
1860/28500 (epoch 3.263), train_loss = 1.92033586, grad/param norm = 2.4668e-01, time/batch = 0.6799s	
1861/28500 (epoch 3.265), train_loss = 1.82609446, grad/param norm = 2.4243e-01, time/batch = 0.6836s	
1862/28500 (epoch 3.267), train_loss = 1.89043711, grad/param norm = 2.3661e-01, time/batch = 0.6827s	
1863/28500 (epoch 3.268), train_loss = 1.83288314, grad/param norm = 2.5311e-01, time/batch = 0.6805s	
1864/28500 (epoch 3.270), train_loss = 1.66115004, grad/param norm = 1.9753e-01, time/batch = 0.6804s	
1865/28500 (epoch 3.272), train_loss = 1.72751159, grad/param norm = 2.6199e-01, time/batch = 0.6797s	
1866/28500 (epoch 3.274), train_loss = 1.93155374, grad/param norm = 2.5563e-01, time/batch = 0.6812s	
1867/28500 (epoch 3.275), train_loss = 1.81483493, grad/param norm = 2.1494e-01, time/batch = 0.6794s	
1868/28500 (epoch 3.277), train_loss = 1.67953583, grad/param norm = 2.1908e-01, time/batch = 0.6809s	
1869/28500 (epoch 3.279), train_loss = 1.75951137, grad/param norm = 2.2763e-01, time/batch = 0.6813s	
1870/28500 (epoch 3.281), train_loss = 1.76384572, grad/param norm = 2.1972e-01, time/batch = 0.6800s	
1871/28500 (epoch 3.282), train_loss = 1.64788643, grad/param norm = 2.1614e-01, time/batch = 0.6822s	
1872/28500 (epoch 3.284), train_loss = 1.76146617, grad/param norm = 2.2424e-01, time/batch = 0.6822s	
1873/28500 (epoch 3.286), train_loss = 1.89583399, grad/param norm = 2.5184e-01, time/batch = 0.6801s	
1874/28500 (epoch 3.288), train_loss = 1.74613904, grad/param norm = 2.2873e-01, time/batch = 0.6797s	
1875/28500 (epoch 3.289), train_loss = 1.91590671, grad/param norm = 2.2326e-01, time/batch = 0.6805s	
1876/28500 (epoch 3.291), train_loss = 1.64773447, grad/param norm = 2.3121e-01, time/batch = 0.6813s	
1877/28500 (epoch 3.293), train_loss = 1.67098010, grad/param norm = 2.2991e-01, time/batch = 0.6831s	
1878/28500 (epoch 3.295), train_loss = 1.66065124, grad/param norm = 2.1909e-01, time/batch = 0.6923s	
1879/28500 (epoch 3.296), train_loss = 1.59264721, grad/param norm = 1.9708e-01, time/batch = 0.6891s	
1880/28500 (epoch 3.298), train_loss = 1.74111324, grad/param norm = 2.2350e-01, time/batch = 0.6813s	
1881/28500 (epoch 3.300), train_loss = 1.60579883, grad/param norm = 2.1144e-01, time/batch = 0.6825s	
1882/28500 (epoch 3.302), train_loss = 1.59913009, grad/param norm = 2.1272e-01, time/batch = 0.6821s	
1883/28500 (epoch 3.304), train_loss = 1.63679148, grad/param norm = 1.8885e-01, time/batch = 0.6831s	
1884/28500 (epoch 3.305), train_loss = 1.78587666, grad/param norm = 2.1669e-01, time/batch = 0.6828s	
1885/28500 (epoch 3.307), train_loss = 1.83512359, grad/param norm = 2.8268e-01, time/batch = 0.6848s	
1886/28500 (epoch 3.309), train_loss = 1.84521180, grad/param norm = 2.4928e-01, time/batch = 0.6827s	
1887/28500 (epoch 3.311), train_loss = 1.72873960, grad/param norm = 2.8397e-01, time/batch = 0.6831s	
1888/28500 (epoch 3.312), train_loss = 1.57900263, grad/param norm = 2.1605e-01, time/batch = 0.6869s	
1889/28500 (epoch 3.314), train_loss = 1.75874014, grad/param norm = 2.4763e-01, time/batch = 0.6799s	
1890/28500 (epoch 3.316), train_loss = 1.71803065, grad/param norm = 1.9722e-01, time/batch = 0.6803s	
1891/28500 (epoch 3.318), train_loss = 1.75682162, grad/param norm = 2.4142e-01, time/batch = 0.6842s	
1892/28500 (epoch 3.319), train_loss = 1.69277111, grad/param norm = 2.3624e-01, time/batch = 0.6853s	
1893/28500 (epoch 3.321), train_loss = 1.80229474, grad/param norm = 2.1514e-01, time/batch = 0.6800s	
1894/28500 (epoch 3.323), train_loss = 1.70753484, grad/param norm = 2.2016e-01, time/batch = 0.6791s	
1895/28500 (epoch 3.325), train_loss = 1.93797533, grad/param norm = 2.1976e-01, time/batch = 0.6806s	
1896/28500 (epoch 3.326), train_loss = 1.89146589, grad/param norm = 2.5635e-01, time/batch = 0.6790s	
1897/28500 (epoch 3.328), train_loss = 1.51921749, grad/param norm = 2.3451e-01, time/batch = 0.6872s	
1898/28500 (epoch 3.330), train_loss = 1.65756120, grad/param norm = 2.1766e-01, time/batch = 0.6818s	
1899/28500 (epoch 3.332), train_loss = 1.65931486, grad/param norm = 2.0467e-01, time/batch = 0.6822s	
1900/28500 (epoch 3.333), train_loss = 1.55507337, grad/param norm = 2.0792e-01, time/batch = 0.6785s	
1901/28500 (epoch 3.335), train_loss = 1.56403309, grad/param norm = 2.1048e-01, time/batch = 0.6826s	
1902/28500 (epoch 3.337), train_loss = 1.74669484, grad/param norm = 2.4818e-01, time/batch = 0.6809s	
1903/28500 (epoch 3.339), train_loss = 1.69893214, grad/param norm = 2.3794e-01, time/batch = 0.6802s	
1904/28500 (epoch 3.340), train_loss = 1.83853835, grad/param norm = 2.6150e-01, time/batch = 0.6832s	
1905/28500 (epoch 3.342), train_loss = 1.65174691, grad/param norm = 2.7034e-01, time/batch = 0.6813s	
1906/28500 (epoch 3.344), train_loss = 1.65956172, grad/param norm = 2.5739e-01, time/batch = 0.6806s	
1907/28500 (epoch 3.346), train_loss = 1.40655364, grad/param norm = 2.2193e-01, time/batch = 0.6761s	
1908/28500 (epoch 3.347), train_loss = 1.71128564, grad/param norm = 2.3785e-01, time/batch = 0.6766s	
1909/28500 (epoch 3.349), train_loss = 1.59596249, grad/param norm = 1.9769e-01, time/batch = 0.6762s	
1910/28500 (epoch 3.351), train_loss = 1.53391418, grad/param norm = 1.9434e-01, time/batch = 0.6759s	
1911/28500 (epoch 3.353), train_loss = 1.79794817, grad/param norm = 2.1505e-01, time/batch = 0.6780s	
1912/28500 (epoch 3.354), train_loss = 1.61737827, grad/param norm = 2.3214e-01, time/batch = 0.6773s	
1913/28500 (epoch 3.356), train_loss = 1.60682729, grad/param norm = 2.0833e-01, time/batch = 0.6804s	
1914/28500 (epoch 3.358), train_loss = 1.76551615, grad/param norm = 1.9515e-01, time/batch = 0.6794s	
1915/28500 (epoch 3.360), train_loss = 1.72199310, grad/param norm = 2.3015e-01, time/batch = 0.6782s	
1916/28500 (epoch 3.361), train_loss = 1.69974543, grad/param norm = 2.1851e-01, time/batch = 0.6798s	
1917/28500 (epoch 3.363), train_loss = 1.60386892, grad/param norm = 2.0946e-01, time/batch = 0.6801s	
1918/28500 (epoch 3.365), train_loss = 1.65034881, grad/param norm = 2.2326e-01, time/batch = 0.6826s	
1919/28500 (epoch 3.367), train_loss = 1.70655354, grad/param norm = 2.3438e-01, time/batch = 0.6802s	
1920/28500 (epoch 3.368), train_loss = 1.67130684, grad/param norm = 2.1754e-01, time/batch = 0.6773s	
1921/28500 (epoch 3.370), train_loss = 1.72986616, grad/param norm = 2.1962e-01, time/batch = 0.6826s	
1922/28500 (epoch 3.372), train_loss = 1.61031637, grad/param norm = 2.2751e-01, time/batch = 0.6816s	
1923/28500 (epoch 3.374), train_loss = 1.80980982, grad/param norm = 2.4200e-01, time/batch = 0.6806s	
1924/28500 (epoch 3.375), train_loss = 1.85472252, grad/param norm = 2.3999e-01, time/batch = 0.6778s	
1925/28500 (epoch 3.377), train_loss = 1.69047832, grad/param norm = 2.4061e-01, time/batch = 0.6768s	
1926/28500 (epoch 3.379), train_loss = 1.52139468, grad/param norm = 2.3546e-01, time/batch = 0.6762s	
1927/28500 (epoch 3.381), train_loss = 1.61800102, grad/param norm = 2.0013e-01, time/batch = 0.6781s	
1928/28500 (epoch 3.382), train_loss = 1.69193182, grad/param norm = 2.3651e-01, time/batch = 0.6814s	
1929/28500 (epoch 3.384), train_loss = 1.59047390, grad/param norm = 2.1173e-01, time/batch = 0.6798s	
1930/28500 (epoch 3.386), train_loss = 1.55807114, grad/param norm = 2.2614e-01, time/batch = 0.6793s	
1931/28500 (epoch 3.388), train_loss = 1.81397276, grad/param norm = 2.2760e-01, time/batch = 0.6782s	
1932/28500 (epoch 3.389), train_loss = 1.67081933, grad/param norm = 2.0902e-01, time/batch = 0.6769s	
1933/28500 (epoch 3.391), train_loss = 1.62080829, grad/param norm = 2.0098e-01, time/batch = 0.6790s	
1934/28500 (epoch 3.393), train_loss = 1.55175037, grad/param norm = 2.1345e-01, time/batch = 0.6796s	
1935/28500 (epoch 3.395), train_loss = 1.89744164, grad/param norm = 2.2001e-01, time/batch = 0.6803s	
1936/28500 (epoch 3.396), train_loss = 1.79377568, grad/param norm = 2.1553e-01, time/batch = 0.6767s	
1937/28500 (epoch 3.398), train_loss = 1.59817863, grad/param norm = 2.3727e-01, time/batch = 0.6763s	
1938/28500 (epoch 3.400), train_loss = 1.81437611, grad/param norm = 2.3640e-01, time/batch = 0.6763s	
1939/28500 (epoch 3.402), train_loss = 1.68364158, grad/param norm = 2.4598e-01, time/batch = 0.6779s	
1940/28500 (epoch 3.404), train_loss = 1.80666183, grad/param norm = 2.1879e-01, time/batch = 0.6762s	
1941/28500 (epoch 3.405), train_loss = 1.75590978, grad/param norm = 2.0573e-01, time/batch = 0.6778s	
1942/28500 (epoch 3.407), train_loss = 1.75235819, grad/param norm = 2.0774e-01, time/batch = 0.6766s	
1943/28500 (epoch 3.409), train_loss = 1.73261359, grad/param norm = 2.2764e-01, time/batch = 0.6761s	
1944/28500 (epoch 3.411), train_loss = 1.75537791, grad/param norm = 2.2951e-01, time/batch = 0.6761s	
1945/28500 (epoch 3.412), train_loss = 1.86420125, grad/param norm = 2.2803e-01, time/batch = 0.6760s	
1946/28500 (epoch 3.414), train_loss = 1.70622394, grad/param norm = 2.0754e-01, time/batch = 0.6758s	
1947/28500 (epoch 3.416), train_loss = 1.61629824, grad/param norm = 2.1619e-01, time/batch = 0.6757s	
1948/28500 (epoch 3.418), train_loss = 1.75547138, grad/param norm = 2.2320e-01, time/batch = 0.6763s	
1949/28500 (epoch 3.419), train_loss = 1.82573941, grad/param norm = 2.3118e-01, time/batch = 0.6776s	
1950/28500 (epoch 3.421), train_loss = 1.79265486, grad/param norm = 2.3432e-01, time/batch = 0.6821s	
1951/28500 (epoch 3.423), train_loss = 1.95213049, grad/param norm = 2.6655e-01, time/batch = 0.6837s	
1952/28500 (epoch 3.425), train_loss = 1.79774825, grad/param norm = 2.6056e-01, time/batch = 0.6819s	
1953/28500 (epoch 3.426), train_loss = 1.77184948, grad/param norm = 2.5579e-01, time/batch = 0.6774s	
1954/28500 (epoch 3.428), train_loss = 1.95381988, grad/param norm = 2.5024e-01, time/batch = 0.6764s	
1955/28500 (epoch 3.430), train_loss = 1.75977062, grad/param norm = 2.2923e-01, time/batch = 0.6780s	
1956/28500 (epoch 3.432), train_loss = 1.82058949, grad/param norm = 2.6441e-01, time/batch = 0.6772s	
1957/28500 (epoch 3.433), train_loss = 1.72312154, grad/param norm = 2.2958e-01, time/batch = 0.6773s	
1958/28500 (epoch 3.435), train_loss = 1.67141641, grad/param norm = 2.3306e-01, time/batch = 0.6774s	
1959/28500 (epoch 3.437), train_loss = 1.52633642, grad/param norm = 1.9529e-01, time/batch = 0.6807s	
1960/28500 (epoch 3.439), train_loss = 1.59859780, grad/param norm = 2.1163e-01, time/batch = 0.6818s	
1961/28500 (epoch 3.440), train_loss = 1.73481419, grad/param norm = 1.9764e-01, time/batch = 0.6908s	
1962/28500 (epoch 3.442), train_loss = 1.62297240, grad/param norm = 2.1954e-01, time/batch = 0.6766s	
1963/28500 (epoch 3.444), train_loss = 1.55577127, grad/param norm = 2.1383e-01, time/batch = 0.6783s	
1964/28500 (epoch 3.446), train_loss = 1.48752727, grad/param norm = 2.2165e-01, time/batch = 0.6817s	
1965/28500 (epoch 3.447), train_loss = 1.61101768, grad/param norm = 2.1092e-01, time/batch = 0.6835s	
1966/28500 (epoch 3.449), train_loss = 1.65139731, grad/param norm = 2.3700e-01, time/batch = 0.6930s	
1967/28500 (epoch 3.451), train_loss = 1.69431200, grad/param norm = 2.1565e-01, time/batch = 0.6924s	
1968/28500 (epoch 3.453), train_loss = 1.70802035, grad/param norm = 2.1782e-01, time/batch = 0.6934s	
1969/28500 (epoch 3.454), train_loss = 1.58461424, grad/param norm = 2.2662e-01, time/batch = 0.6860s	
1970/28500 (epoch 3.456), train_loss = 1.78067545, grad/param norm = 2.4995e-01, time/batch = 0.6797s	
1971/28500 (epoch 3.458), train_loss = 1.65324327, grad/param norm = 2.4086e-01, time/batch = 0.6830s	
1972/28500 (epoch 3.460), train_loss = 1.78905734, grad/param norm = 2.1003e-01, time/batch = 0.6863s	
1973/28500 (epoch 3.461), train_loss = 1.66421947, grad/param norm = 2.1744e-01, time/batch = 0.6799s	
1974/28500 (epoch 3.463), train_loss = 1.56511156, grad/param norm = 1.9739e-01, time/batch = 0.6787s	
1975/28500 (epoch 3.465), train_loss = 1.49147418, grad/param norm = 2.2828e-01, time/batch = 0.6872s	
1976/28500 (epoch 3.467), train_loss = 1.78292529, grad/param norm = 2.3261e-01, time/batch = 0.6860s	
1977/28500 (epoch 3.468), train_loss = 1.49328391, grad/param norm = 1.7845e-01, time/batch = 0.6826s	
1978/28500 (epoch 3.470), train_loss = 1.73092468, grad/param norm = 2.4375e-01, time/batch = 0.6950s	
1979/28500 (epoch 3.472), train_loss = 1.64334690, grad/param norm = 2.1576e-01, time/batch = 0.6806s	
1980/28500 (epoch 3.474), train_loss = 1.88482064, grad/param norm = 2.3174e-01, time/batch = 0.6790s	
1981/28500 (epoch 3.475), train_loss = 1.65974856, grad/param norm = 2.2968e-01, time/batch = 0.6888s	
1982/28500 (epoch 3.477), train_loss = 1.63633031, grad/param norm = 2.2776e-01, time/batch = 0.6783s	
1983/28500 (epoch 3.479), train_loss = 1.70972171, grad/param norm = 2.1148e-01, time/batch = 0.6853s	
1984/28500 (epoch 3.481), train_loss = 1.71718943, grad/param norm = 2.4708e-01, time/batch = 0.6759s	
1985/28500 (epoch 3.482), train_loss = 1.61802374, grad/param norm = 2.3021e-01, time/batch = 0.6819s	
1986/28500 (epoch 3.484), train_loss = 1.59793029, grad/param norm = 2.4128e-01, time/batch = 0.6878s	
1987/28500 (epoch 3.486), train_loss = 1.61359981, grad/param norm = 2.2920e-01, time/batch = 0.6818s	
1988/28500 (epoch 3.488), train_loss = 1.62650124, grad/param norm = 2.5460e-01, time/batch = 0.6775s	
1989/28500 (epoch 3.489), train_loss = 1.78510140, grad/param norm = 2.6452e-01, time/batch = 0.6786s	
1990/28500 (epoch 3.491), train_loss = 1.63185282, grad/param norm = 2.3717e-01, time/batch = 0.6766s	
1991/28500 (epoch 3.493), train_loss = 1.57356926, grad/param norm = 2.0232e-01, time/batch = 0.6775s	
1992/28500 (epoch 3.495), train_loss = 1.65713487, grad/param norm = 2.0988e-01, time/batch = 0.6765s	
1993/28500 (epoch 3.496), train_loss = 1.74527027, grad/param norm = 2.2317e-01, time/batch = 0.6767s	
1994/28500 (epoch 3.498), train_loss = 1.72919929, grad/param norm = 2.2445e-01, time/batch = 0.6768s	
1995/28500 (epoch 3.500), train_loss = 1.72056978, grad/param norm = 2.2977e-01, time/batch = 0.6784s	
1996/28500 (epoch 3.502), train_loss = 1.75098133, grad/param norm = 2.2566e-01, time/batch = 0.6773s	
1997/28500 (epoch 3.504), train_loss = 1.72381122, grad/param norm = 2.0381e-01, time/batch = 0.6759s	
1998/28500 (epoch 3.505), train_loss = 1.61684318, grad/param norm = 1.9828e-01, time/batch = 0.6757s	
1999/28500 (epoch 3.507), train_loss = 1.89704530, grad/param norm = 2.4232e-01, time/batch = 0.6755s	
evaluating loss over split index 2	
1/30...	
2/30...	
3/30...	
4/30...	
5/30...	
6/30...	
7/30...	
8/30...	
9/30...	
10/30...	
11/30...	
12/30...	
13/30...	
14/30...	
15/30...	
16/30...	
17/30...	
18/30...	
19/30...	
20/30...	
21/30...	
22/30...	
23/30...	
24/30...	
25/30...	
26/30...	
27/30...	
28/30...	
29/30...	
30/30...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_scottwalker_epoch3.51_1.7862.t7	
2000/28500 (epoch 3.509), train_loss = 1.65340210, grad/param norm = 2.3805e-01, time/batch = 0.6755s	
2001/28500 (epoch 3.511), train_loss = 1.86142190, grad/param norm = 2.2377e-01, time/batch = 0.6861s	
2002/28500 (epoch 3.512), train_loss = 1.62563573, grad/param norm = 1.9307e-01, time/batch = 0.6768s	
2003/28500 (epoch 3.514), train_loss = 1.54594583, grad/param norm = 2.1438e-01, time/batch = 0.6770s	
2004/28500 (epoch 3.516), train_loss = 1.57402103, grad/param norm = 2.0192e-01, time/batch = 0.6861s	
2005/28500 (epoch 3.518), train_loss = 1.63162846, grad/param norm = 1.9449e-01, time/batch = 0.6795s	
2006/28500 (epoch 3.519), train_loss = 1.78407071, grad/param norm = 2.2988e-01, time/batch = 0.6827s	
2007/28500 (epoch 3.521), train_loss = 1.85866699, grad/param norm = 2.2988e-01, time/batch = 0.6839s	
2008/28500 (epoch 3.523), train_loss = 1.75634294, grad/param norm = 2.3742e-01, time/batch = 0.6804s	
2009/28500 (epoch 3.525), train_loss = 1.82456974, grad/param norm = 2.3098e-01, time/batch = 0.6757s	
2010/28500 (epoch 3.526), train_loss = 1.67233449, grad/param norm = 2.0692e-01, time/batch = 0.6763s	
2011/28500 (epoch 3.528), train_loss = 1.78149049, grad/param norm = 2.3459e-01, time/batch = 0.6767s	
2012/28500 (epoch 3.530), train_loss = 1.79846538, grad/param norm = 2.2198e-01, time/batch = 0.6774s	
2013/28500 (epoch 3.532), train_loss = 1.62664719, grad/param norm = 2.1238e-01, time/batch = 0.6772s	
2014/28500 (epoch 3.533), train_loss = 1.82592303, grad/param norm = 2.2522e-01, time/batch = 0.6763s	
2015/28500 (epoch 3.535), train_loss = 1.52580868, grad/param norm = 2.1919e-01, time/batch = 0.6764s	
2016/28500 (epoch 3.537), train_loss = 1.45449050, grad/param norm = 1.9996e-01, time/batch = 0.6766s	
2017/28500 (epoch 3.539), train_loss = 1.59688288, grad/param norm = 2.0932e-01, time/batch = 0.6752s	
2018/28500 (epoch 3.540), train_loss = 1.72109434, grad/param norm = 2.2384e-01, time/batch = 0.6753s	
2019/28500 (epoch 3.542), train_loss = 1.96919291, grad/param norm = 2.7312e-01, time/batch = 0.6756s	
2020/28500 (epoch 3.544), train_loss = 1.80021902, grad/param norm = 2.1971e-01, time/batch = 0.6763s	
2021/28500 (epoch 3.546), train_loss = 1.75306826, grad/param norm = 2.2566e-01, time/batch = 0.6859s	
2022/28500 (epoch 3.547), train_loss = 1.72005941, grad/param norm = 2.1412e-01, time/batch = 0.6853s	
2023/28500 (epoch 3.549), train_loss = 1.52572324, grad/param norm = 2.0335e-01, time/batch = 0.6875s	
2024/28500 (epoch 3.551), train_loss = 1.89270894, grad/param norm = 2.3184e-01, time/batch = 0.6757s	
2025/28500 (epoch 3.553), train_loss = 1.92000145, grad/param norm = 2.2128e-01, time/batch = 0.6795s	
2026/28500 (epoch 3.554), train_loss = 1.66672740, grad/param norm = 2.1539e-01, time/batch = 0.6779s	
2027/28500 (epoch 3.556), train_loss = 1.73191885, grad/param norm = 2.2125e-01, time/batch = 0.6776s	
2028/28500 (epoch 3.558), train_loss = 1.71416635, grad/param norm = 2.1228e-01, time/batch = 0.6797s	
2029/28500 (epoch 3.560), train_loss = 1.74950419, grad/param norm = 2.3541e-01, time/batch = 0.6793s	
2030/28500 (epoch 3.561), train_loss = 1.78852281, grad/param norm = 2.5643e-01, time/batch = 0.6804s	
2031/28500 (epoch 3.563), train_loss = 1.79070546, grad/param norm = 2.3972e-01, time/batch = 0.6818s	
2032/28500 (epoch 3.565), train_loss = 1.66159143, grad/param norm = 2.4873e-01, time/batch = 0.6818s	
2033/28500 (epoch 3.567), train_loss = 1.59580523, grad/param norm = 2.1871e-01, time/batch = 0.6798s	
2034/28500 (epoch 3.568), train_loss = 1.76080163, grad/param norm = 2.2348e-01, time/batch = 0.6791s	
2035/28500 (epoch 3.570), train_loss = 1.58488492, grad/param norm = 2.4375e-01, time/batch = 0.6788s	
2036/28500 (epoch 3.572), train_loss = 1.68928177, grad/param norm = 2.3602e-01, time/batch = 0.6791s	
2037/28500 (epoch 3.574), train_loss = 1.73840098, grad/param norm = 2.1634e-01, time/batch = 0.6790s	
2038/28500 (epoch 3.575), train_loss = 1.59883729, grad/param norm = 2.2368e-01, time/batch = 0.6787s	
2039/28500 (epoch 3.577), train_loss = 1.62085689, grad/param norm = 1.9888e-01, time/batch = 0.6788s	
2040/28500 (epoch 3.579), train_loss = 1.88161369, grad/param norm = 2.4890e-01, time/batch = 0.6782s	
2041/28500 (epoch 3.581), train_loss = 1.61182312, grad/param norm = 2.0757e-01, time/batch = 0.6819s	
2042/28500 (epoch 3.582), train_loss = 1.75070051, grad/param norm = 2.1860e-01, time/batch = 0.6795s	
2043/28500 (epoch 3.584), train_loss = 1.61752667, grad/param norm = 1.9292e-01, time/batch = 0.6799s	
2044/28500 (epoch 3.586), train_loss = 1.48778155, grad/param norm = 1.7896e-01, time/batch = 0.6790s	
2045/28500 (epoch 3.588), train_loss = 1.59364292, grad/param norm = 2.1481e-01, time/batch = 0.6927s	
2046/28500 (epoch 3.589), train_loss = 1.99324787, grad/param norm = 2.3005e-01, time/batch = 0.6842s	
2047/28500 (epoch 3.591), train_loss = 1.75484624, grad/param norm = 2.0696e-01, time/batch = 0.6773s	
2048/28500 (epoch 3.593), train_loss = 1.62202095, grad/param norm = 2.0706e-01, time/batch = 0.6802s	
2049/28500 (epoch 3.595), train_loss = 1.94334494, grad/param norm = 2.6539e-01, time/batch = 0.6798s	
2050/28500 (epoch 3.596), train_loss = 1.82581282, grad/param norm = 2.7810e-01, time/batch = 0.6788s	
2051/28500 (epoch 3.598), train_loss = 1.67244535, grad/param norm = 2.0909e-01, time/batch = 0.6833s	
2052/28500 (epoch 3.600), train_loss = 1.72392791, grad/param norm = 2.1346e-01, time/batch = 0.6802s	
2053/28500 (epoch 3.602), train_loss = 1.87579446, grad/param norm = 2.2160e-01, time/batch = 0.6801s	
2054/28500 (epoch 3.604), train_loss = 1.73569734, grad/param norm = 2.2246e-01, time/batch = 0.6791s	
2055/28500 (epoch 3.605), train_loss = 1.69185130, grad/param norm = 2.2175e-01, time/batch = 0.6801s	
2056/28500 (epoch 3.607), train_loss = 1.67915593, grad/param norm = 2.1198e-01, time/batch = 0.6789s	
2057/28500 (epoch 3.609), train_loss = 1.68461290, grad/param norm = 2.2267e-01, time/batch = 0.6821s	
2058/28500 (epoch 3.611), train_loss = 1.69803893, grad/param norm = 2.1038e-01, time/batch = 0.6815s	
2059/28500 (epoch 3.612), train_loss = 1.72082924, grad/param norm = 2.1191e-01, time/batch = 0.6799s	
2060/28500 (epoch 3.614), train_loss = 1.65968727, grad/param norm = 2.0692e-01, time/batch = 0.6834s	
2061/28500 (epoch 3.616), train_loss = 1.65393600, grad/param norm = 2.1464e-01, time/batch = 0.6835s	
2062/28500 (epoch 3.618), train_loss = 1.55263382, grad/param norm = 2.0871e-01, time/batch = 0.6811s	
2063/28500 (epoch 3.619), train_loss = 1.83015227, grad/param norm = 2.2900e-01, time/batch = 0.6811s	
2064/28500 (epoch 3.621), train_loss = 1.41715964, grad/param norm = 1.9603e-01, time/batch = 0.6849s	
2065/28500 (epoch 3.623), train_loss = 1.70368594, grad/param norm = 2.0890e-01, time/batch = 0.6809s	
2066/28500 (epoch 3.625), train_loss = 1.56547986, grad/param norm = 2.2769e-01, time/batch = 0.6810s	
2067/28500 (epoch 3.626), train_loss = 1.42905816, grad/param norm = 1.9977e-01, time/batch = 0.6788s	
2068/28500 (epoch 3.628), train_loss = 1.55039126, grad/param norm = 2.1247e-01, time/batch = 0.6847s	
2069/28500 (epoch 3.630), train_loss = 1.54977460, grad/param norm = 2.1416e-01, time/batch = 0.6796s	
2070/28500 (epoch 3.632), train_loss = 1.76365578, grad/param norm = 2.4020e-01, time/batch = 0.6789s	
2071/28500 (epoch 3.633), train_loss = 1.67896113, grad/param norm = 1.9031e-01, time/batch = 0.6814s	
2072/28500 (epoch 3.635), train_loss = 1.79882119, grad/param norm = 2.2793e-01, time/batch = 0.6787s	
2073/28500 (epoch 3.637), train_loss = 1.66607830, grad/param norm = 2.2351e-01, time/batch = 0.6801s	
2074/28500 (epoch 3.639), train_loss = 1.43943695, grad/param norm = 2.2107e-01, time/batch = 0.6792s	
2075/28500 (epoch 3.640), train_loss = 1.62674441, grad/param norm = 2.1940e-01, time/batch = 0.6794s	
2076/28500 (epoch 3.642), train_loss = 1.71845054, grad/param norm = 1.9321e-01, time/batch = 0.6791s	
2077/28500 (epoch 3.644), train_loss = 1.71049848, grad/param norm = 2.0386e-01, time/batch = 0.6801s	
2078/28500 (epoch 3.646), train_loss = 1.59053222, grad/param norm = 1.8577e-01, time/batch = 0.6792s	
2079/28500 (epoch 3.647), train_loss = 1.55919203, grad/param norm = 2.1986e-01, time/batch = 0.6789s	
2080/28500 (epoch 3.649), train_loss = 1.60399255, grad/param norm = 2.0606e-01, time/batch = 0.6793s	
2081/28500 (epoch 3.651), train_loss = 1.59332707, grad/param norm = 2.0981e-01, time/batch = 0.6829s	
2082/28500 (epoch 3.653), train_loss = 1.54382086, grad/param norm = 2.0676e-01, time/batch = 0.6803s	
2083/28500 (epoch 3.654), train_loss = 1.58226696, grad/param norm = 2.2588e-01, time/batch = 0.6786s	
2084/28500 (epoch 3.656), train_loss = 1.67780248, grad/param norm = 2.0609e-01, time/batch = 0.6814s	
2085/28500 (epoch 3.658), train_loss = 1.70112713, grad/param norm = 2.2334e-01, time/batch = 0.6791s	
2086/28500 (epoch 3.660), train_loss = 1.60965019, grad/param norm = 1.8568e-01, time/batch = 0.6802s	
2087/28500 (epoch 3.661), train_loss = 1.79158727, grad/param norm = 2.1539e-01, time/batch = 0.6940s	
2088/28500 (epoch 3.663), train_loss = 1.82907449, grad/param norm = 2.2030e-01, time/batch = 0.6881s	
2089/28500 (epoch 3.665), train_loss = 1.64022347, grad/param norm = 2.1798e-01, time/batch = 0.6837s	
2090/28500 (epoch 3.667), train_loss = 1.69634086, grad/param norm = 2.2054e-01, time/batch = 0.6811s	
2091/28500 (epoch 3.668), train_loss = 1.63091616, grad/param norm = 2.1764e-01, time/batch = 0.6823s	
2092/28500 (epoch 3.670), train_loss = 1.61198813, grad/param norm = 2.2083e-01, time/batch = 0.6803s	
2093/28500 (epoch 3.672), train_loss = 1.63933320, grad/param norm = 2.0824e-01, time/batch = 0.6811s	
2094/28500 (epoch 3.674), train_loss = 1.52421588, grad/param norm = 2.2044e-01, time/batch = 0.6923s	
2095/28500 (epoch 3.675), train_loss = 1.49393597, grad/param norm = 2.0580e-01, time/batch = 0.6812s	
2096/28500 (epoch 3.677), train_loss = 1.57792011, grad/param norm = 2.1489e-01, time/batch = 0.6800s	
2097/28500 (epoch 3.679), train_loss = 1.70970199, grad/param norm = 2.2594e-01, time/batch = 0.6795s	
2098/28500 (epoch 3.681), train_loss = 1.76567037, grad/param norm = 2.4216e-01, time/batch = 0.6799s	
2099/28500 (epoch 3.682), train_loss = 1.54019031, grad/param norm = 1.9180e-01, time/batch = 0.6799s	
2100/28500 (epoch 3.684), train_loss = 1.67866216, grad/param norm = 2.0721e-01, time/batch = 0.6822s	
2101/28500 (epoch 3.686), train_loss = 1.57297805, grad/param norm = 2.2070e-01, time/batch = 0.6839s	
2102/28500 (epoch 3.688), train_loss = 1.63379342, grad/param norm = 2.1766e-01, time/batch = 0.6800s	
2103/28500 (epoch 3.689), train_loss = 1.74063701, grad/param norm = 2.4426e-01, time/batch = 0.6807s	
2104/28500 (epoch 3.691), train_loss = 1.65719260, grad/param norm = 2.2548e-01, time/batch = 0.6804s	
2105/28500 (epoch 3.693), train_loss = 1.66893637, grad/param norm = 2.1312e-01, time/batch = 0.6797s	
2106/28500 (epoch 3.695), train_loss = 1.65625466, grad/param norm = 2.4195e-01, time/batch = 0.6784s	
2107/28500 (epoch 3.696), train_loss = 1.72345981, grad/param norm = 2.8067e-01, time/batch = 0.6792s	
2108/28500 (epoch 3.698), train_loss = 1.61619576, grad/param norm = 2.0120e-01, time/batch = 0.6788s	
2109/28500 (epoch 3.700), train_loss = 1.62380469, grad/param norm = 2.1965e-01, time/batch = 0.6792s	
2110/28500 (epoch 3.702), train_loss = 1.82141431, grad/param norm = 2.2046e-01, time/batch = 0.6782s	
2111/28500 (epoch 3.704), train_loss = 1.68869368, grad/param norm = 2.2881e-01, time/batch = 0.6817s	
2112/28500 (epoch 3.705), train_loss = 1.71206245, grad/param norm = 2.0749e-01, time/batch = 0.6789s	
2113/28500 (epoch 3.707), train_loss = 1.64566821, grad/param norm = 2.4818e-01, time/batch = 0.6803s	
2114/28500 (epoch 3.709), train_loss = 1.75765617, grad/param norm = 2.3470e-01, time/batch = 0.6780s	
2115/28500 (epoch 3.711), train_loss = 1.57044379, grad/param norm = 2.3125e-01, time/batch = 0.6803s	
2116/28500 (epoch 3.712), train_loss = 1.73336532, grad/param norm = 2.3454e-01, time/batch = 0.6797s	
2117/28500 (epoch 3.714), train_loss = 1.72449262, grad/param norm = 2.2451e-01, time/batch = 0.6842s	
2118/28500 (epoch 3.716), train_loss = 1.67727579, grad/param norm = 2.1197e-01, time/batch = 0.6793s	
2119/28500 (epoch 3.718), train_loss = 1.54721365, grad/param norm = 2.1128e-01, time/batch = 0.6815s	
2120/28500 (epoch 3.719), train_loss = 1.55792168, grad/param norm = 2.0576e-01, time/batch = 0.6806s	
2121/28500 (epoch 3.721), train_loss = 1.40189680, grad/param norm = 2.1008e-01, time/batch = 0.6826s	
2122/28500 (epoch 3.723), train_loss = 1.65137113, grad/param norm = 2.0564e-01, time/batch = 0.6805s	
2123/28500 (epoch 3.725), train_loss = 1.73623101, grad/param norm = 2.1397e-01, time/batch = 0.6810s	
2124/28500 (epoch 3.726), train_loss = 1.65684546, grad/param norm = 2.2363e-01, time/batch = 0.6801s	
2125/28500 (epoch 3.728), train_loss = 1.52241465, grad/param norm = 1.9941e-01, time/batch = 0.6813s	
2126/28500 (epoch 3.730), train_loss = 1.69701751, grad/param norm = 2.2256e-01, time/batch = 0.6806s	
2127/28500 (epoch 3.732), train_loss = 1.44831930, grad/param norm = 2.1170e-01, time/batch = 0.6800s	
2128/28500 (epoch 3.733), train_loss = 1.53456159, grad/param norm = 2.2792e-01, time/batch = 0.6811s	
2129/28500 (epoch 3.735), train_loss = 1.48943966, grad/param norm = 1.9343e-01, time/batch = 0.6819s	
2130/28500 (epoch 3.737), train_loss = 1.46517931, grad/param norm = 1.9192e-01, time/batch = 0.6802s	
2131/28500 (epoch 3.739), train_loss = 1.68918060, grad/param norm = 2.1938e-01, time/batch = 0.6858s	
2132/28500 (epoch 3.740), train_loss = 1.61212524, grad/param norm = 2.0229e-01, time/batch = 0.6905s	
2133/28500 (epoch 3.742), train_loss = 1.63625989, grad/param norm = 2.1339e-01, time/batch = 0.7060s	
2134/28500 (epoch 3.744), train_loss = 1.75146976, grad/param norm = 2.1270e-01, time/batch = 0.6828s	
2135/28500 (epoch 3.746), train_loss = 1.54728536, grad/param norm = 1.9590e-01, time/batch = 0.6822s	
2136/28500 (epoch 3.747), train_loss = 1.53542987, grad/param norm = 2.1116e-01, time/batch = 0.6851s	
2137/28500 (epoch 3.749), train_loss = 1.90604397, grad/param norm = 2.2768e-01, time/batch = 0.6793s	
2138/28500 (epoch 3.751), train_loss = 1.56846335, grad/param norm = 2.0350e-01, time/batch = 0.6883s	
2139/28500 (epoch 3.753), train_loss = 1.47122389, grad/param norm = 1.8486e-01, time/batch = 0.6869s	
2140/28500 (epoch 3.754), train_loss = 1.45972905, grad/param norm = 1.9347e-01, time/batch = 0.6766s	
2141/28500 (epoch 3.756), train_loss = 1.72602478, grad/param norm = 2.0612e-01, time/batch = 0.6784s	
2142/28500 (epoch 3.758), train_loss = 1.61950271, grad/param norm = 2.0595e-01, time/batch = 0.6780s	
2143/28500 (epoch 3.760), train_loss = 1.54201872, grad/param norm = 2.2200e-01, time/batch = 0.6819s	
2144/28500 (epoch 3.761), train_loss = 1.63135244, grad/param norm = 2.1289e-01, time/batch = 0.7004s	
2145/28500 (epoch 3.763), train_loss = 1.39639636, grad/param norm = 1.9300e-01, time/batch = 0.6898s	
2146/28500 (epoch 3.765), train_loss = 1.54305923, grad/param norm = 1.9311e-01, time/batch = 0.6875s	
2147/28500 (epoch 3.767), train_loss = 1.38827681, grad/param norm = 2.1244e-01, time/batch = 0.6809s	
2148/28500 (epoch 3.768), train_loss = 1.79719860, grad/param norm = 2.5203e-01, time/batch = 0.6963s	
2149/28500 (epoch 3.770), train_loss = 1.49334647, grad/param norm = 2.1717e-01, time/batch = 0.6907s	
2150/28500 (epoch 3.772), train_loss = 1.44564420, grad/param norm = 2.3540e-01, time/batch = 0.6822s	
2151/28500 (epoch 3.774), train_loss = 1.63348439, grad/param norm = 2.2057e-01, time/batch = 0.6799s	
2152/28500 (epoch 3.775), train_loss = 1.73254323, grad/param norm = 2.1839e-01, time/batch = 0.6802s	
2153/28500 (epoch 3.777), train_loss = 1.62975875, grad/param norm = 2.0593e-01, time/batch = 0.6926s	
2154/28500 (epoch 3.779), train_loss = 1.55025275, grad/param norm = 2.0761e-01, time/batch = 0.6912s	
2155/28500 (epoch 3.781), train_loss = 1.68145733, grad/param norm = 2.3046e-01, time/batch = 0.6797s	
2156/28500 (epoch 3.782), train_loss = 1.81242256, grad/param norm = 2.3438e-01, time/batch = 0.6770s	
2157/28500 (epoch 3.784), train_loss = 1.43476596, grad/param norm = 1.9033e-01, time/batch = 0.6832s	
2158/28500 (epoch 3.786), train_loss = 1.61528061, grad/param norm = 2.0280e-01, time/batch = 0.6798s	
2159/28500 (epoch 3.788), train_loss = 1.72929311, grad/param norm = 2.1135e-01, time/batch = 0.6796s	
2160/28500 (epoch 3.789), train_loss = 1.44663518, grad/param norm = 2.2221e-01, time/batch = 0.6777s	
2161/28500 (epoch 3.791), train_loss = 1.61424731, grad/param norm = 2.2204e-01, time/batch = 0.6926s	
2162/28500 (epoch 3.793), train_loss = 1.50339111, grad/param norm = 2.1895e-01, time/batch = 0.6955s	
2163/28500 (epoch 3.795), train_loss = 1.63594630, grad/param norm = 2.4937e-01, time/batch = 0.6799s	
2164/28500 (epoch 3.796), train_loss = 1.51929616, grad/param norm = 2.0145e-01, time/batch = 0.6758s	
2165/28500 (epoch 3.798), train_loss = 1.53062231, grad/param norm = 2.1401e-01, time/batch = 0.6756s	
2166/28500 (epoch 3.800), train_loss = 1.56793462, grad/param norm = 2.0920e-01, time/batch = 0.6799s	
2167/28500 (epoch 3.802), train_loss = 1.67012657, grad/param norm = 2.2770e-01, time/batch = 0.6785s	
2168/28500 (epoch 3.804), train_loss = 1.63913090, grad/param norm = 1.9666e-01, time/batch = 0.6754s	
2169/28500 (epoch 3.805), train_loss = 1.67770003, grad/param norm = 2.1643e-01, time/batch = 0.6756s	
2170/28500 (epoch 3.807), train_loss = 1.79415715, grad/param norm = 2.1201e-01, time/batch = 0.6756s	
2171/28500 (epoch 3.809), train_loss = 1.56380167, grad/param norm = 1.9569e-01, time/batch = 0.6776s	
2172/28500 (epoch 3.811), train_loss = 1.78185285, grad/param norm = 2.3721e-01, time/batch = 0.6794s	
2173/28500 (epoch 3.812), train_loss = 1.69037662, grad/param norm = 2.1108e-01, time/batch = 0.6989s	
2174/28500 (epoch 3.814), train_loss = 1.56380438, grad/param norm = 2.0585e-01, time/batch = 0.6874s	
2175/28500 (epoch 3.816), train_loss = 1.73870501, grad/param norm = 2.1854e-01, time/batch = 0.6765s	
2176/28500 (epoch 3.818), train_loss = 1.62340744, grad/param norm = 2.1990e-01, time/batch = 0.6771s	
2177/28500 (epoch 3.819), train_loss = 1.60920232, grad/param norm = 2.1252e-01, time/batch = 0.6820s	
2178/28500 (epoch 3.821), train_loss = 1.56020807, grad/param norm = 1.9996e-01, time/batch = 0.6801s	
2179/28500 (epoch 3.823), train_loss = 1.91632278, grad/param norm = 2.7277e-01, time/batch = 0.6791s	
2180/28500 (epoch 3.825), train_loss = 1.60967593, grad/param norm = 2.3298e-01, time/batch = 0.6771s	
2181/28500 (epoch 3.826), train_loss = 1.69574965, grad/param norm = 2.3822e-01, time/batch = 0.6786s	
2182/28500 (epoch 3.828), train_loss = 1.48727058, grad/param norm = 2.1462e-01, time/batch = 0.6765s	
2183/28500 (epoch 3.830), train_loss = 1.55258975, grad/param norm = 1.9920e-01, time/batch = 0.6762s	
2184/28500 (epoch 3.832), train_loss = 1.68851596, grad/param norm = 2.3073e-01, time/batch = 0.6765s	
2185/28500 (epoch 3.833), train_loss = 1.78013430, grad/param norm = 2.0772e-01, time/batch = 0.6759s	
2186/28500 (epoch 3.835), train_loss = 1.60192906, grad/param norm = 2.1272e-01, time/batch = 0.6780s	
2187/28500 (epoch 3.837), train_loss = 1.52585926, grad/param norm = 2.0801e-01, time/batch = 0.6778s	
2188/28500 (epoch 3.839), train_loss = 1.77501133, grad/param norm = 2.1938e-01, time/batch = 0.6909s	
2189/28500 (epoch 3.840), train_loss = 1.74037703, grad/param norm = 2.1136e-01, time/batch = 0.6759s	
2190/28500 (epoch 3.842), train_loss = 1.65217611, grad/param norm = 2.0884e-01, time/batch = 0.6758s	
2191/28500 (epoch 3.844), train_loss = 1.64642588, grad/param norm = 2.0572e-01, time/batch = 0.6776s	
2192/28500 (epoch 3.846), train_loss = 1.74309793, grad/param norm = 2.1468e-01, time/batch = 0.6760s	
2193/28500 (epoch 3.847), train_loss = 1.57676388, grad/param norm = 2.0158e-01, time/batch = 0.6774s	
2194/28500 (epoch 3.849), train_loss = 1.53132351, grad/param norm = 1.8701e-01, time/batch = 0.6761s	
2195/28500 (epoch 3.851), train_loss = 1.47850841, grad/param norm = 2.0202e-01, time/batch = 0.6752s	
2196/28500 (epoch 3.853), train_loss = 1.67145247, grad/param norm = 2.1662e-01, time/batch = 0.6759s	
2197/28500 (epoch 3.854), train_loss = 1.59306584, grad/param norm = 2.1035e-01, time/batch = 0.6888s	
2198/28500 (epoch 3.856), train_loss = 1.68225202, grad/param norm = 2.1656e-01, time/batch = 0.6872s	
2199/28500 (epoch 3.858), train_loss = 1.47133499, grad/param norm = 2.0106e-01, time/batch = 0.6752s	
2200/28500 (epoch 3.860), train_loss = 1.73425466, grad/param norm = 2.2375e-01, time/batch = 0.6757s	
2201/28500 (epoch 3.861), train_loss = 1.58514935, grad/param norm = 2.0728e-01, time/batch = 0.6810s	
2202/28500 (epoch 3.863), train_loss = 1.75628263, grad/param norm = 2.1355e-01, time/batch = 0.6764s	
2203/28500 (epoch 3.865), train_loss = 1.64121513, grad/param norm = 2.3342e-01, time/batch = 0.6760s	
2204/28500 (epoch 3.867), train_loss = 1.72071950, grad/param norm = 2.1466e-01, time/batch = 0.6801s	
2205/28500 (epoch 3.868), train_loss = 1.49168250, grad/param norm = 2.4946e-01, time/batch = 0.6777s	
2206/28500 (epoch 3.870), train_loss = 1.39103478, grad/param norm = 1.9945e-01, time/batch = 0.6882s	
2207/28500 (epoch 3.872), train_loss = 1.73328562, grad/param norm = 2.2557e-01, time/batch = 0.6877s	
2208/28500 (epoch 3.874), train_loss = 1.62067004, grad/param norm = 2.3105e-01, time/batch = 0.6778s	
2209/28500 (epoch 3.875), train_loss = 1.70476436, grad/param norm = 2.2060e-01, time/batch = 0.6756s	
2210/28500 (epoch 3.877), train_loss = 1.62621034, grad/param norm = 2.2230e-01, time/batch = 0.6747s	
2211/28500 (epoch 3.879), train_loss = 1.59496387, grad/param norm = 2.0367e-01, time/batch = 0.6770s	
2212/28500 (epoch 3.881), train_loss = 1.67892301, grad/param norm = 2.0798e-01, time/batch = 0.6780s	
2213/28500 (epoch 3.882), train_loss = 1.58507235, grad/param norm = 1.9986e-01, time/batch = 0.6791s	
2214/28500 (epoch 3.884), train_loss = 1.68439962, grad/param norm = 2.2026e-01, time/batch = 0.6795s	
2215/28500 (epoch 3.886), train_loss = 1.49412473, grad/param norm = 2.1350e-01, time/batch = 0.6765s	
2216/28500 (epoch 3.888), train_loss = 1.45035393, grad/param norm = 1.9614e-01, time/batch = 0.6918s	
2217/28500 (epoch 3.889), train_loss = 1.50042903, grad/param norm = 1.8541e-01, time/batch = 0.6756s	
2218/28500 (epoch 3.891), train_loss = 1.62915776, grad/param norm = 1.9392e-01, time/batch = 0.6759s	
2219/28500 (epoch 3.893), train_loss = 1.59939885, grad/param norm = 2.0899e-01, time/batch = 0.6947s	
2220/28500 (epoch 3.895), train_loss = 1.82973372, grad/param norm = 2.4038e-01, time/batch = 0.7152s	
2221/28500 (epoch 3.896), train_loss = 1.76279789, grad/param norm = 2.2039e-01, time/batch = 0.7151s	
2222/28500 (epoch 3.898), train_loss = 1.53548164, grad/param norm = 1.9756e-01, time/batch = 0.6916s	
2223/28500 (epoch 3.900), train_loss = 1.46474331, grad/param norm = 2.0749e-01, time/batch = 0.6910s	
2224/28500 (epoch 3.902), train_loss = 1.51217126, grad/param norm = 2.0582e-01, time/batch = 0.6915s	
2225/28500 (epoch 3.904), train_loss = 1.50021046, grad/param norm = 1.9567e-01, time/batch = 0.7069s	
2226/28500 (epoch 3.905), train_loss = 1.64377324, grad/param norm = 1.9257e-01, time/batch = 0.7081s	
2227/28500 (epoch 3.907), train_loss = 1.79089507, grad/param norm = 2.4032e-01, time/batch = 0.6944s	
2228/28500 (epoch 3.909), train_loss = 1.53892123, grad/param norm = 1.9895e-01, time/batch = 0.6909s	
2229/28500 (epoch 3.911), train_loss = 1.56237709, grad/param norm = 2.0656e-01, time/batch = 0.6904s	
2230/28500 (epoch 3.912), train_loss = 1.32420086, grad/param norm = 2.1579e-01, time/batch = 0.6887s	
2231/28500 (epoch 3.914), train_loss = 1.73702764, grad/param norm = 2.2272e-01, time/batch = 0.6920s	
2232/28500 (epoch 3.916), train_loss = 1.66795235, grad/param norm = 2.2013e-01, time/batch = 0.7001s	
2233/28500 (epoch 3.918), train_loss = 1.69680842, grad/param norm = 2.2589e-01, time/batch = 0.6988s	
2234/28500 (epoch 3.919), train_loss = 1.51626355, grad/param norm = 1.8967e-01, time/batch = 0.7121s	
2235/28500 (epoch 3.921), train_loss = 1.80937400, grad/param norm = 2.2784e-01, time/batch = 0.7116s	
2236/28500 (epoch 3.923), train_loss = 1.74566650, grad/param norm = 2.5364e-01, time/batch = 0.7057s	
2237/28500 (epoch 3.925), train_loss = 1.53209114, grad/param norm = 2.1705e-01, time/batch = 0.6951s	
2238/28500 (epoch 3.926), train_loss = 1.66265881, grad/param norm = 2.1455e-01, time/batch = 0.6946s	
2239/28500 (epoch 3.928), train_loss = 1.49890148, grad/param norm = 2.1063e-01, time/batch = 0.6945s	
2240/28500 (epoch 3.930), train_loss = 1.28706116, grad/param norm = 1.9048e-01, time/batch = 0.6933s	
2241/28500 (epoch 3.932), train_loss = 1.44517183, grad/param norm = 1.7436e-01, time/batch = 0.7019s	
2242/28500 (epoch 3.933), train_loss = 1.64283740, grad/param norm = 1.8757e-01, time/batch = 0.6967s	
2243/28500 (epoch 3.935), train_loss = 1.57741423, grad/param norm = 2.2450e-01, time/batch = 0.7065s	
2244/28500 (epoch 3.937), train_loss = 1.75712074, grad/param norm = 2.1736e-01, time/batch = 0.7011s	
2245/28500 (epoch 3.939), train_loss = 1.87766208, grad/param norm = 2.3382e-01, time/batch = 0.6965s	
2246/28500 (epoch 3.940), train_loss = 1.56376964, grad/param norm = 1.9466e-01, time/batch = 0.6928s	
2247/28500 (epoch 3.942), train_loss = 1.68390682, grad/param norm = 2.0483e-01, time/batch = 0.6932s	
2248/28500 (epoch 3.944), train_loss = 1.65509891, grad/param norm = 2.0223e-01, time/batch = 0.6939s	
2249/28500 (epoch 3.946), train_loss = 1.72766235, grad/param norm = 1.9493e-01, time/batch = 0.6920s	
2250/28500 (epoch 3.947), train_loss = 1.99960765, grad/param norm = 2.3715e-01, time/batch = 0.6941s	
2251/28500 (epoch 3.949), train_loss = 1.51351275, grad/param norm = 2.2854e-01, time/batch = 0.7023s	
2252/28500 (epoch 3.951), train_loss = 1.80860070, grad/param norm = 2.1732e-01, time/batch = 0.6967s	
2253/28500 (epoch 3.953), train_loss = 1.76986807, grad/param norm = 2.4745e-01, time/batch = 0.6934s	
2254/28500 (epoch 3.954), train_loss = 1.69100851, grad/param norm = 2.1044e-01, time/batch = 0.6980s	
2255/28500 (epoch 3.956), train_loss = 1.69753514, grad/param norm = 2.4885e-01, time/batch = 0.6927s	
2256/28500 (epoch 3.958), train_loss = 1.67329978, grad/param norm = 2.3309e-01, time/batch = 0.6981s	
2257/28500 (epoch 3.960), train_loss = 1.52999925, grad/param norm = 2.2825e-01, time/batch = 0.6952s	
2258/28500 (epoch 3.961), train_loss = 1.84101620, grad/param norm = 2.3035e-01, time/batch = 0.6990s	
2259/28500 (epoch 3.963), train_loss = 1.68369126, grad/param norm = 1.8604e-01, time/batch = 0.6987s	
2260/28500 (epoch 3.965), train_loss = 1.51453583, grad/param norm = 1.9311e-01, time/batch = 0.7140s	
2261/28500 (epoch 3.967), train_loss = 1.44771245, grad/param norm = 1.9629e-01, time/batch = 0.7016s	
2262/28500 (epoch 3.968), train_loss = 1.40255845, grad/param norm = 1.8934e-01, time/batch = 0.6980s	
2263/28500 (epoch 3.970), train_loss = 1.71599106, grad/param norm = 2.1953e-01, time/batch = 0.6964s	
2264/28500 (epoch 3.972), train_loss = 1.88468068, grad/param norm = 2.3711e-01, time/batch = 0.6975s	
2265/28500 (epoch 3.974), train_loss = 1.87566866, grad/param norm = 2.1471e-01, time/batch = 0.6907s	
2266/28500 (epoch 3.975), train_loss = 1.59302542, grad/param norm = 2.0805e-01, time/batch = 0.7124s	
2267/28500 (epoch 3.977), train_loss = 1.83265832, grad/param norm = 2.1465e-01, time/batch = 0.7093s	
2268/28500 (epoch 3.979), train_loss = 1.55758618, grad/param norm = 1.9943e-01, time/batch = 0.6943s	
2269/28500 (epoch 3.981), train_loss = 1.58544122, grad/param norm = 2.0918e-01, time/batch = 0.6969s	
2270/28500 (epoch 3.982), train_loss = 1.47517371, grad/param norm = 1.9429e-01, time/batch = 0.6931s	
2271/28500 (epoch 3.984), train_loss = 1.67706966, grad/param norm = 2.0477e-01, time/batch = 0.6963s	
2272/28500 (epoch 3.986), train_loss = 1.77926291, grad/param norm = 2.1927e-01, time/batch = 0.6945s	
2273/28500 (epoch 3.988), train_loss = 1.40229948, grad/param norm = 1.9870e-01, time/batch = 0.6944s	
2274/28500 (epoch 3.989), train_loss = 1.64607227, grad/param norm = 2.1489e-01, time/batch = 0.6970s	
2275/28500 (epoch 3.991), train_loss = 1.56959911, grad/param norm = 2.2396e-01, time/batch = 0.7062s	
2276/28500 (epoch 3.993), train_loss = 1.59513711, grad/param norm = 2.2122e-01, time/batch = 0.7043s	
2277/28500 (epoch 3.995), train_loss = 1.55821291, grad/param norm = 1.9383e-01, time/batch = 0.7004s	
2278/28500 (epoch 3.996), train_loss = 1.49358376, grad/param norm = 1.9845e-01, time/batch = 0.6945s	
2279/28500 (epoch 3.998), train_loss = 1.69659942, grad/param norm = 2.2717e-01, time/batch = 0.6959s	
2280/28500 (epoch 4.000), train_loss = 1.56243207, grad/param norm = 2.0050e-01, time/batch = 0.6942s	
2281/28500 (epoch 4.002), train_loss = 1.68671296, grad/param norm = 2.1425e-01, time/batch = 0.6974s	
2282/28500 (epoch 4.004), train_loss = 1.52004846, grad/param norm = 2.3036e-01, time/batch = 0.6942s	
2283/28500 (epoch 4.005), train_loss = 1.66121633, grad/param norm = 2.0783e-01, time/batch = 0.6985s	
2284/28500 (epoch 4.007), train_loss = 1.40397598, grad/param norm = 1.8273e-01, time/batch = 0.6984s	
2285/28500 (epoch 4.009), train_loss = 1.70994404, grad/param norm = 2.2379e-01, time/batch = 0.6944s	
2286/28500 (epoch 4.011), train_loss = 1.61098570, grad/param norm = 2.3546e-01, time/batch = 0.6961s	
2287/28500 (epoch 4.012), train_loss = 1.40922364, grad/param norm = 1.8205e-01, time/batch = 0.6939s	
2288/28500 (epoch 4.014), train_loss = 1.47837020, grad/param norm = 1.9782e-01, time/batch = 0.6947s	
2289/28500 (epoch 4.016), train_loss = 1.52835794, grad/param norm = 2.0284e-01, time/batch = 0.6928s	
2290/28500 (epoch 4.018), train_loss = 1.57053413, grad/param norm = 2.1986e-01, time/batch = 0.6985s	
2291/28500 (epoch 4.019), train_loss = 1.62470496, grad/param norm = 2.2765e-01, time/batch = 0.6972s	
2292/28500 (epoch 4.021), train_loss = 1.56188470, grad/param norm = 1.9179e-01, time/batch = 0.6955s	
2293/28500 (epoch 4.023), train_loss = 1.63873228, grad/param norm = 2.1214e-01, time/batch = 0.6953s	
2294/28500 (epoch 4.025), train_loss = 1.55400790, grad/param norm = 1.9617e-01, time/batch = 0.6952s	
2295/28500 (epoch 4.026), train_loss = 1.63731381, grad/param norm = 2.2014e-01, time/batch = 0.6943s	
2296/28500 (epoch 4.028), train_loss = 1.68027227, grad/param norm = 2.3018e-01, time/batch = 0.6921s	
2297/28500 (epoch 4.030), train_loss = 1.73380132, grad/param norm = 2.6167e-01, time/batch = 0.6935s	
2298/28500 (epoch 4.032), train_loss = 1.69466397, grad/param norm = 2.2643e-01, time/batch = 0.6923s	
2299/28500 (epoch 4.033), train_loss = 1.80007916, grad/param norm = 2.2422e-01, time/batch = 0.6934s	
2300/28500 (epoch 4.035), train_loss = 1.66224459, grad/param norm = 2.1856e-01, time/batch = 0.6942s	
2301/28500 (epoch 4.037), train_loss = 1.68480646, grad/param norm = 2.1259e-01, time/batch = 0.6952s	
2302/28500 (epoch 4.039), train_loss = 1.77259924, grad/param norm = 2.3086e-01, time/batch = 0.6959s	
2303/28500 (epoch 4.040), train_loss = 1.76476521, grad/param norm = 2.1213e-01, time/batch = 0.6953s	
2304/28500 (epoch 4.042), train_loss = 1.78848864, grad/param norm = 2.1950e-01, time/batch = 0.6983s	
2305/28500 (epoch 4.044), train_loss = 1.66205056, grad/param norm = 2.2559e-01, time/batch = 0.6958s	
2306/28500 (epoch 4.046), train_loss = 1.77499245, grad/param norm = 1.9701e-01, time/batch = 0.7014s	
2307/28500 (epoch 4.047), train_loss = 1.76257207, grad/param norm = 2.0940e-01, time/batch = 0.6990s	
2308/28500 (epoch 4.049), train_loss = 1.68634782, grad/param norm = 2.2610e-01, time/batch = 0.6921s	
2309/28500 (epoch 4.051), train_loss = 1.63111003, grad/param norm = 1.9203e-01, time/batch = 0.6958s	
2310/28500 (epoch 4.053), train_loss = 1.72306080, grad/param norm = 2.1133e-01, time/batch = 0.6935s	
2311/28500 (epoch 4.054), train_loss = 1.73065547, grad/param norm = 2.0066e-01, time/batch = 0.7037s	
2312/28500 (epoch 4.056), train_loss = 1.47699207, grad/param norm = 1.8999e-01, time/batch = 0.6938s	
2313/28500 (epoch 4.058), train_loss = 1.52383372, grad/param norm = 2.1370e-01, time/batch = 0.6938s	
2314/28500 (epoch 4.060), train_loss = 1.64354469, grad/param norm = 2.2671e-01, time/batch = 0.7001s	
2315/28500 (epoch 4.061), train_loss = 1.71055212, grad/param norm = 2.1813e-01, time/batch = 0.6936s	
2316/28500 (epoch 4.063), train_loss = 1.76692756, grad/param norm = 2.0266e-01, time/batch = 0.6935s	
2317/28500 (epoch 4.065), train_loss = 1.85973137, grad/param norm = 2.1285e-01, time/batch = 0.6929s	
2318/28500 (epoch 4.067), train_loss = 1.57168285, grad/param norm = 2.1424e-01, time/batch = 0.7048s	
2319/28500 (epoch 4.068), train_loss = 1.50280881, grad/param norm = 1.9045e-01, time/batch = 0.6988s	
2320/28500 (epoch 4.070), train_loss = 1.68899527, grad/param norm = 2.0431e-01, time/batch = 0.6979s	
2321/28500 (epoch 4.072), train_loss = 1.86781500, grad/param norm = 2.2117e-01, time/batch = 0.7033s	
2322/28500 (epoch 4.074), train_loss = 1.69186439, grad/param norm = 2.2143e-01, time/batch = 0.7048s	
2323/28500 (epoch 4.075), train_loss = 1.56433181, grad/param norm = 1.8619e-01, time/batch = 0.6960s	
2324/28500 (epoch 4.077), train_loss = 1.68214659, grad/param norm = 1.9738e-01, time/batch = 0.6952s	
2325/28500 (epoch 4.079), train_loss = 1.64350199, grad/param norm = 2.1779e-01, time/batch = 0.6956s	
2326/28500 (epoch 4.081), train_loss = 1.80185900, grad/param norm = 2.3455e-01, time/batch = 0.6905s	
2327/28500 (epoch 4.082), train_loss = 1.70085123, grad/param norm = 2.2195e-01, time/batch = 0.6898s	
2328/28500 (epoch 4.084), train_loss = 1.70758508, grad/param norm = 1.9495e-01, time/batch = 0.6934s	
2329/28500 (epoch 4.086), train_loss = 1.56059926, grad/param norm = 2.1737e-01, time/batch = 0.6947s	
2330/28500 (epoch 4.088), train_loss = 1.51278365, grad/param norm = 2.0542e-01, time/batch = 0.6898s	
2331/28500 (epoch 4.089), train_loss = 1.79546184, grad/param norm = 1.9696e-01, time/batch = 0.6911s	
2332/28500 (epoch 4.091), train_loss = 1.43911903, grad/param norm = 1.9940e-01, time/batch = 0.6899s	
2333/28500 (epoch 4.093), train_loss = 1.63054663, grad/param norm = 1.9522e-01, time/batch = 0.6947s	
2334/28500 (epoch 4.095), train_loss = 1.59312040, grad/param norm = 2.1335e-01, time/batch = 0.6937s	
2335/28500 (epoch 4.096), train_loss = 1.77569204, grad/param norm = 2.1244e-01, time/batch = 0.6897s	
2336/28500 (epoch 4.098), train_loss = 1.81980887, grad/param norm = 2.3077e-01, time/batch = 0.6904s	
2337/28500 (epoch 4.100), train_loss = 1.52152017, grad/param norm = 2.0685e-01, time/batch = 0.6893s	
2338/28500 (epoch 4.102), train_loss = 1.81123590, grad/param norm = 1.9939e-01, time/batch = 0.6896s	
2339/28500 (epoch 4.104), train_loss = 1.63695205, grad/param norm = 2.0847e-01, time/batch = 0.6965s	
2340/28500 (epoch 4.105), train_loss = 1.64858815, grad/param norm = 2.1937e-01, time/batch = 0.6986s	
2341/28500 (epoch 4.107), train_loss = 1.56528692, grad/param norm = 2.3719e-01, time/batch = 0.6972s	
2342/28500 (epoch 4.109), train_loss = 1.51129206, grad/param norm = 2.0466e-01, time/batch = 0.6922s	
2343/28500 (epoch 4.111), train_loss = 1.62239215, grad/param norm = 2.0897e-01, time/batch = 0.6940s	
2344/28500 (epoch 4.112), train_loss = 1.71248423, grad/param norm = 2.0132e-01, time/batch = 0.6912s	
2345/28500 (epoch 4.114), train_loss = 1.60772524, grad/param norm = 2.1297e-01, time/batch = 0.6961s	
2346/28500 (epoch 4.116), train_loss = 1.81348784, grad/param norm = 2.2282e-01, time/batch = 0.6939s	
2347/28500 (epoch 4.118), train_loss = 1.47630884, grad/param norm = 1.9945e-01, time/batch = 0.6927s	
2348/28500 (epoch 4.119), train_loss = 1.69942569, grad/param norm = 2.1851e-01, time/batch = 0.6890s	
2349/28500 (epoch 4.121), train_loss = 1.83276571, grad/param norm = 2.1560e-01, time/batch = 0.6890s	
2350/28500 (epoch 4.123), train_loss = 1.72049187, grad/param norm = 2.4762e-01, time/batch = 0.6908s	
2351/28500 (epoch 4.125), train_loss = 1.72239746, grad/param norm = 2.1295e-01, time/batch = 0.6924s	
2352/28500 (epoch 4.126), train_loss = 1.64898419, grad/param norm = 2.0616e-01, time/batch = 0.6896s	
2353/28500 (epoch 4.128), train_loss = 1.55953009, grad/param norm = 2.4219e-01, time/batch = 0.6896s	
2354/28500 (epoch 4.130), train_loss = 1.62685707, grad/param norm = 2.1567e-01, time/batch = 0.6892s	
2355/28500 (epoch 4.132), train_loss = 1.70569257, grad/param norm = 2.2142e-01, time/batch = 0.6912s	
2356/28500 (epoch 4.133), train_loss = 1.58668112, grad/param norm = 1.9787e-01, time/batch = 0.6905s	
2357/28500 (epoch 4.135), train_loss = 1.63525049, grad/param norm = 1.8957e-01, time/batch = 0.6897s	
2358/28500 (epoch 4.137), train_loss = 1.57720673, grad/param norm = 2.1827e-01, time/batch = 0.6891s	
2359/28500 (epoch 4.139), train_loss = 1.57218712, grad/param norm = 1.7850e-01, time/batch = 0.6906s	
2360/28500 (epoch 4.140), train_loss = 1.60102305, grad/param norm = 1.9220e-01, time/batch = 0.6913s	
2361/28500 (epoch 4.142), train_loss = 1.67497826, grad/param norm = 2.1462e-01, time/batch = 0.6918s	
2362/28500 (epoch 4.144), train_loss = 1.51252502, grad/param norm = 1.9661e-01, time/batch = 0.6917s	
2363/28500 (epoch 4.146), train_loss = 1.52115852, grad/param norm = 2.0087e-01, time/batch = 0.6906s	
2364/28500 (epoch 4.147), train_loss = 1.44551224, grad/param norm = 1.9350e-01, time/batch = 0.6900s	
2365/28500 (epoch 4.149), train_loss = 1.49672405, grad/param norm = 1.9587e-01, time/batch = 0.6898s	
2366/28500 (epoch 4.151), train_loss = 1.48162785, grad/param norm = 2.1166e-01, time/batch = 0.6916s	
2367/28500 (epoch 4.153), train_loss = 1.55634914, grad/param norm = 2.1247e-01, time/batch = 0.6965s	
2368/28500 (epoch 4.154), train_loss = 1.52405072, grad/param norm = 2.0809e-01, time/batch = 0.6988s	
2369/28500 (epoch 4.156), train_loss = 1.82896318, grad/param norm = 2.2409e-01, time/batch = 0.6933s	
2370/28500 (epoch 4.158), train_loss = 1.55532143, grad/param norm = 1.9966e-01, time/batch = 0.6955s	
2371/28500 (epoch 4.160), train_loss = 1.50373672, grad/param norm = 2.0715e-01, time/batch = 0.6945s	
2372/28500 (epoch 4.161), train_loss = 1.70840241, grad/param norm = 2.4101e-01, time/batch = 0.6926s	
2373/28500 (epoch 4.163), train_loss = 1.53399735, grad/param norm = 2.2263e-01, time/batch = 0.6907s	
2374/28500 (epoch 4.165), train_loss = 1.82882593, grad/param norm = 2.1158e-01, time/batch = 0.6958s	
2375/28500 (epoch 4.167), train_loss = 1.88357283, grad/param norm = 2.1701e-01, time/batch = 0.6916s	
2376/28500 (epoch 4.168), train_loss = 1.70713611, grad/param norm = 2.2461e-01, time/batch = 0.6916s	
2377/28500 (epoch 4.170), train_loss = 1.76660586, grad/param norm = 2.2668e-01, time/batch = 0.6925s	
2378/28500 (epoch 4.172), train_loss = 1.59151990, grad/param norm = 2.3319e-01, time/batch = 0.6892s	
2379/28500 (epoch 4.174), train_loss = 1.84487289, grad/param norm = 2.0696e-01, time/batch = 0.6924s	
2380/28500 (epoch 4.175), train_loss = 1.56571239, grad/param norm = 1.9397e-01, time/batch = 0.6919s	
2381/28500 (epoch 4.177), train_loss = 1.71366307, grad/param norm = 2.1010e-01, time/batch = 0.6908s	
2382/28500 (epoch 4.179), train_loss = 1.57623190, grad/param norm = 2.1576e-01, time/batch = 0.6895s	
2383/28500 (epoch 4.181), train_loss = 1.73369084, grad/param norm = 2.1395e-01, time/batch = 0.6895s	
2384/28500 (epoch 4.182), train_loss = 1.62730173, grad/param norm = 2.2818e-01, time/batch = 0.6892s	
2385/28500 (epoch 4.184), train_loss = 1.85409486, grad/param norm = 2.2667e-01, time/batch = 0.6911s	
2386/28500 (epoch 4.186), train_loss = 1.77348357, grad/param norm = 2.4073e-01, time/batch = 0.6981s	
2387/28500 (epoch 4.188), train_loss = 1.58568458, grad/param norm = 2.0078e-01, time/batch = 0.6954s	
2388/28500 (epoch 4.189), train_loss = 1.72856759, grad/param norm = 2.1025e-01, time/batch = 0.6894s	
2389/28500 (epoch 4.191), train_loss = 1.91231843, grad/param norm = 2.1772e-01, time/batch = 0.6937s	
2390/28500 (epoch 4.193), train_loss = 1.71886141, grad/param norm = 2.1651e-01, time/batch = 0.6943s	
2391/28500 (epoch 4.195), train_loss = 1.73521761, grad/param norm = 2.2039e-01, time/batch = 0.7014s	
2392/28500 (epoch 4.196), train_loss = 1.66562514, grad/param norm = 2.1662e-01, time/batch = 0.7054s	
2393/28500 (epoch 4.198), train_loss = 1.64060337, grad/param norm = 2.2378e-01, time/batch = 0.6976s	
2394/28500 (epoch 4.200), train_loss = 1.59545966, grad/param norm = 1.7945e-01, time/batch = 0.6999s	
2395/28500 (epoch 4.202), train_loss = 1.68833663, grad/param norm = 2.2576e-01, time/batch = 0.6946s	
2396/28500 (epoch 4.204), train_loss = 1.45205952, grad/param norm = 1.7925e-01, time/batch = 0.6929s	
2397/28500 (epoch 4.205), train_loss = 1.54823671, grad/param norm = 2.0129e-01, time/batch = 0.6981s	
2398/28500 (epoch 4.207), train_loss = 1.65558882, grad/param norm = 2.2203e-01, time/batch = 0.7085s	
2399/28500 (epoch 4.209), train_loss = 1.62216273, grad/param norm = 2.2591e-01, time/batch = 0.6945s	
2400/28500 (epoch 4.211), train_loss = 1.47211718, grad/param norm = 1.9373e-01, time/batch = 0.6940s	
2401/28500 (epoch 4.212), train_loss = 1.48964139, grad/param norm = 1.9819e-01, time/batch = 0.6997s	
2402/28500 (epoch 4.214), train_loss = 1.70080192, grad/param norm = 2.2392e-01, time/batch = 0.6937s	
2403/28500 (epoch 4.216), train_loss = 1.47608825, grad/param norm = 1.8559e-01, time/batch = 0.7107s	
2404/28500 (epoch 4.218), train_loss = 1.65277113, grad/param norm = 1.8809e-01, time/batch = 0.7090s	
2405/28500 (epoch 4.219), train_loss = 1.59655872, grad/param norm = 2.0174e-01, time/batch = 0.6971s	
2406/28500 (epoch 4.221), train_loss = 1.51382213, grad/param norm = 1.9704e-01, time/batch = 0.6945s	
2407/28500 (epoch 4.223), train_loss = 1.76239033, grad/param norm = 2.4155e-01, time/batch = 0.6925s	
2408/28500 (epoch 4.225), train_loss = 1.80393007, grad/param norm = 2.3385e-01, time/batch = 0.6923s	
2409/28500 (epoch 4.226), train_loss = 1.64970357, grad/param norm = 2.2377e-01, time/batch = 0.6926s	
2410/28500 (epoch 4.228), train_loss = 1.63560653, grad/param norm = 2.0458e-01, time/batch = 0.6925s	
2411/28500 (epoch 4.230), train_loss = 1.63966664, grad/param norm = 2.0438e-01, time/batch = 0.6948s	
2412/28500 (epoch 4.232), train_loss = 1.68059528, grad/param norm = 1.9835e-01, time/batch = 0.6934s	
2413/28500 (epoch 4.233), train_loss = 1.65747022, grad/param norm = 2.1128e-01, time/batch = 0.6916s	
2414/28500 (epoch 4.235), train_loss = 1.52088745, grad/param norm = 1.9116e-01, time/batch = 0.6937s	
2415/28500 (epoch 4.237), train_loss = 1.44386876, grad/param norm = 1.7182e-01, time/batch = 0.6914s	
2416/28500 (epoch 4.239), train_loss = 1.53305054, grad/param norm = 1.9378e-01, time/batch = 0.6917s	
2417/28500 (epoch 4.240), train_loss = 1.45698141, grad/param norm = 1.9117e-01, time/batch = 0.6908s	
2418/28500 (epoch 4.242), train_loss = 1.67592188, grad/param norm = 2.0608e-01, time/batch = 0.6919s	
2419/28500 (epoch 4.244), train_loss = 1.72634568, grad/param norm = 2.0739e-01, time/batch = 0.6921s	
2420/28500 (epoch 4.246), train_loss = 1.67386883, grad/param norm = 2.0530e-01, time/batch = 0.6927s	
2421/28500 (epoch 4.247), train_loss = 1.81344629, grad/param norm = 2.1198e-01, time/batch = 0.6973s	
2422/28500 (epoch 4.249), train_loss = 1.66022837, grad/param norm = 2.4084e-01, time/batch = 0.6944s	
2423/28500 (epoch 4.251), train_loss = 1.40563789, grad/param norm = 1.8337e-01, time/batch = 0.6936s	
2424/28500 (epoch 4.253), train_loss = 1.73752305, grad/param norm = 2.0365e-01, time/batch = 0.6910s	
2425/28500 (epoch 4.254), train_loss = 1.70228315, grad/param norm = 2.0823e-01, time/batch = 0.6937s	
2426/28500 (epoch 4.256), train_loss = 1.53826396, grad/param norm = 1.9939e-01, time/batch = 0.6927s	
2427/28500 (epoch 4.258), train_loss = 1.59467903, grad/param norm = 2.2048e-01, time/batch = 0.6932s	
2428/28500 (epoch 4.260), train_loss = 1.57317943, grad/param norm = 1.9554e-01, time/batch = 0.6927s	
2429/28500 (epoch 4.261), train_loss = 1.54106244, grad/param norm = 2.0068e-01, time/batch = 0.6927s	
2430/28500 (epoch 4.263), train_loss = 1.80074217, grad/param norm = 2.3032e-01, time/batch = 0.6952s	
2431/28500 (epoch 4.265), train_loss = 1.68254971, grad/param norm = 2.2159e-01, time/batch = 0.7026s	
2432/28500 (epoch 4.267), train_loss = 1.77020430, grad/param norm = 2.3019e-01, time/batch = 0.6937s	
2433/28500 (epoch 4.268), train_loss = 1.70308784, grad/param norm = 2.1988e-01, time/batch = 0.6915s	
2434/28500 (epoch 4.270), train_loss = 1.57462239, grad/param norm = 1.9536e-01, time/batch = 0.6948s	
2435/28500 (epoch 4.272), train_loss = 1.60754582, grad/param norm = 2.2583e-01, time/batch = 0.6940s	
2436/28500 (epoch 4.274), train_loss = 1.81028581, grad/param norm = 2.1924e-01, time/batch = 0.6943s	
2437/28500 (epoch 4.275), train_loss = 1.69960657, grad/param norm = 1.9502e-01, time/batch = 0.6978s	
2438/28500 (epoch 4.277), train_loss = 1.54595937, grad/param norm = 1.9629e-01, time/batch = 0.6928s	
2439/28500 (epoch 4.279), train_loss = 1.66041171, grad/param norm = 2.1331e-01, time/batch = 0.6924s	
2440/28500 (epoch 4.281), train_loss = 1.66442515, grad/param norm = 2.0134e-01, time/batch = 0.6923s	
2441/28500 (epoch 4.282), train_loss = 1.51208708, grad/param norm = 2.0005e-01, time/batch = 0.6950s	
2442/28500 (epoch 4.284), train_loss = 1.64745188, grad/param norm = 2.0308e-01, time/batch = 0.6932s	
2443/28500 (epoch 4.286), train_loss = 1.76384167, grad/param norm = 2.2855e-01, time/batch = 0.6933s	
2444/28500 (epoch 4.288), train_loss = 1.64770661, grad/param norm = 2.0688e-01, time/batch = 0.6913s	
2445/28500 (epoch 4.289), train_loss = 1.77634005, grad/param norm = 1.9925e-01, time/batch = 0.6924s	
2446/28500 (epoch 4.291), train_loss = 1.55066378, grad/param norm = 1.9989e-01, time/batch = 0.6922s	
2447/28500 (epoch 4.293), train_loss = 1.54373841, grad/param norm = 2.0803e-01, time/batch = 0.6922s	
2448/28500 (epoch 4.295), train_loss = 1.53321709, grad/param norm = 1.9996e-01, time/batch = 0.6939s	
2449/28500 (epoch 4.296), train_loss = 1.47522542, grad/param norm = 1.8900e-01, time/batch = 0.6945s	
2450/28500 (epoch 4.298), train_loss = 1.64962923, grad/param norm = 2.1119e-01, time/batch = 0.6946s	
2451/28500 (epoch 4.300), train_loss = 1.50390661, grad/param norm = 1.8980e-01, time/batch = 0.6979s	
2452/28500 (epoch 4.302), train_loss = 1.46483035, grad/param norm = 1.9258e-01, time/batch = 0.6893s	
2453/28500 (epoch 4.304), train_loss = 1.55873891, grad/param norm = 1.7430e-01, time/batch = 0.6910s	
2454/28500 (epoch 4.305), train_loss = 1.68452958, grad/param norm = 2.0509e-01, time/batch = 0.6932s	
2455/28500 (epoch 4.307), train_loss = 1.70204236, grad/param norm = 2.4696e-01, time/batch = 0.6929s	
2456/28500 (epoch 4.309), train_loss = 1.71589943, grad/param norm = 2.2913e-01, time/batch = 0.6937s	
2457/28500 (epoch 4.311), train_loss = 1.62279782, grad/param norm = 2.5584e-01, time/batch = 0.6940s	
2458/28500 (epoch 4.312), train_loss = 1.48797853, grad/param norm = 1.8801e-01, time/batch = 0.6935s	
2459/28500 (epoch 4.314), train_loss = 1.65744250, grad/param norm = 2.2411e-01, time/batch = 0.6918s	
2460/28500 (epoch 4.316), train_loss = 1.61035148, grad/param norm = 1.9029e-01, time/batch = 0.6936s	
2461/28500 (epoch 4.318), train_loss = 1.65633671, grad/param norm = 2.3379e-01, time/batch = 0.6956s	
2462/28500 (epoch 4.319), train_loss = 1.57889260, grad/param norm = 2.1746e-01, time/batch = 0.6919s	
2463/28500 (epoch 4.321), train_loss = 1.68653499, grad/param norm = 2.0813e-01, time/batch = 0.6933s	
2464/28500 (epoch 4.323), train_loss = 1.58369030, grad/param norm = 2.0603e-01, time/batch = 0.6911s	
2465/28500 (epoch 4.325), train_loss = 1.81529290, grad/param norm = 1.9896e-01, time/batch = 0.6932s	
2466/28500 (epoch 4.326), train_loss = 1.73922760, grad/param norm = 2.3564e-01, time/batch = 0.6948s	
2467/28500 (epoch 4.328), train_loss = 1.38826289, grad/param norm = 2.0534e-01, time/batch = 0.6929s	
2468/28500 (epoch 4.330), train_loss = 1.53866144, grad/param norm = 1.9716e-01, time/batch = 0.6929s	
2469/28500 (epoch 4.332), train_loss = 1.54638856, grad/param norm = 1.8742e-01, time/batch = 0.6894s	
2470/28500 (epoch 4.333), train_loss = 1.43382642, grad/param norm = 1.9435e-01, time/batch = 0.6886s	
2471/28500 (epoch 4.335), train_loss = 1.45983302, grad/param norm = 1.8868e-01, time/batch = 0.6929s	
2472/28500 (epoch 4.337), train_loss = 1.61302567, grad/param norm = 2.1233e-01, time/batch = 0.6915s	
2473/28500 (epoch 4.339), train_loss = 1.55478450, grad/param norm = 2.1081e-01, time/batch = 0.6892s	
2474/28500 (epoch 4.340), train_loss = 1.70942619, grad/param norm = 2.2412e-01, time/batch = 0.6889s	
2475/28500 (epoch 4.342), train_loss = 1.54965054, grad/param norm = 2.2851e-01, time/batch = 0.6890s	
2476/28500 (epoch 4.344), train_loss = 1.53465476, grad/param norm = 2.2554e-01, time/batch = 0.6912s	
2477/28500 (epoch 4.346), train_loss = 1.27861675, grad/param norm = 1.9772e-01, time/batch = 0.6922s	
2478/28500 (epoch 4.347), train_loss = 1.60355582, grad/param norm = 2.1214e-01, time/batch = 0.6947s	
2479/28500 (epoch 4.349), train_loss = 1.48017513, grad/param norm = 1.7963e-01, time/batch = 0.7006s	
2480/28500 (epoch 4.351), train_loss = 1.44480098, grad/param norm = 1.8065e-01, time/batch = 0.6890s	
2481/28500 (epoch 4.353), train_loss = 1.69127132, grad/param norm = 2.0216e-01, time/batch = 0.6922s	
2482/28500 (epoch 4.354), train_loss = 1.49194059, grad/param norm = 2.0904e-01, time/batch = 0.6927s	
2483/28500 (epoch 4.356), train_loss = 1.49334687, grad/param norm = 1.7946e-01, time/batch = 0.6886s	
2484/28500 (epoch 4.358), train_loss = 1.64534799, grad/param norm = 1.7999e-01, time/batch = 0.6888s	
2485/28500 (epoch 4.360), train_loss = 1.61005007, grad/param norm = 2.1968e-01, time/batch = 0.6938s	
2486/28500 (epoch 4.361), train_loss = 1.56494630, grad/param norm = 1.9568e-01, time/batch = 0.7046s	
2487/28500 (epoch 4.363), train_loss = 1.47964050, grad/param norm = 1.9370e-01, time/batch = 0.6898s	
2488/28500 (epoch 4.365), train_loss = 1.53921772, grad/param norm = 2.0398e-01, time/batch = 0.6906s	
2489/28500 (epoch 4.367), train_loss = 1.59344072, grad/param norm = 2.1221e-01, time/batch = 0.6911s	
2490/28500 (epoch 4.368), train_loss = 1.54976043, grad/param norm = 1.9248e-01, time/batch = 0.6889s	
2491/28500 (epoch 4.370), train_loss = 1.63662633, grad/param norm = 2.1082e-01, time/batch = 0.6923s	
2492/28500 (epoch 4.372), train_loss = 1.47216733, grad/param norm = 2.1063e-01, time/batch = 0.6946s	
2493/28500 (epoch 4.374), train_loss = 1.69717105, grad/param norm = 2.2285e-01, time/batch = 0.6927s	
2494/28500 (epoch 4.375), train_loss = 1.76241583, grad/param norm = 2.1746e-01, time/batch = 0.6893s	
2495/28500 (epoch 4.377), train_loss = 1.55904605, grad/param norm = 2.0375e-01, time/batch = 0.6893s	
2496/28500 (epoch 4.379), train_loss = 1.37585982, grad/param norm = 1.9913e-01, time/batch = 0.6886s	
2497/28500 (epoch 4.381), train_loss = 1.51129117, grad/param norm = 1.8319e-01, time/batch = 0.6898s	
2498/28500 (epoch 4.382), train_loss = 1.56790928, grad/param norm = 2.1954e-01, time/batch = 0.6893s	
2499/28500 (epoch 4.384), train_loss = 1.46353791, grad/param norm = 1.9454e-01, time/batch = 0.6889s	
2500/28500 (epoch 4.386), train_loss = 1.45223423, grad/param norm = 2.1227e-01, time/batch = 0.6888s	
2501/28500 (epoch 4.388), train_loss = 1.72836776, grad/param norm = 2.0767e-01, time/batch = 0.6918s	
2502/28500 (epoch 4.389), train_loss = 1.55426724, grad/param norm = 1.9371e-01, time/batch = 0.6916s	
2503/28500 (epoch 4.391), train_loss = 1.50806936, grad/param norm = 1.8561e-01, time/batch = 0.6906s	
2504/28500 (epoch 4.393), train_loss = 1.42746152, grad/param norm = 1.9173e-01, time/batch = 0.6919s	
2505/28500 (epoch 4.395), train_loss = 1.79364346, grad/param norm = 2.0814e-01, time/batch = 0.6891s	
2506/28500 (epoch 4.396), train_loss = 1.67232510, grad/param norm = 2.0519e-01, time/batch = 0.6894s	
2507/28500 (epoch 4.398), train_loss = 1.47073185, grad/param norm = 2.1638e-01, time/batch = 0.6889s	
2508/28500 (epoch 4.400), train_loss = 1.69972741, grad/param norm = 2.3894e-01, time/batch = 0.6902s	
2509/28500 (epoch 4.402), train_loss = 1.56534081, grad/param norm = 2.2337e-01, time/batch = 0.7053s	
2510/28500 (epoch 4.404), train_loss = 1.69891570, grad/param norm = 2.0773e-01, time/batch = 0.6946s	
2511/28500 (epoch 4.405), train_loss = 1.64889766, grad/param norm = 1.9304e-01, time/batch = 0.6952s	
2512/28500 (epoch 4.407), train_loss = 1.63682354, grad/param norm = 1.9917e-01, time/batch = 0.6960s	
2513/28500 (epoch 4.409), train_loss = 1.62862414, grad/param norm = 2.0481e-01, time/batch = 0.6910s	
2514/28500 (epoch 4.411), train_loss = 1.64554880, grad/param norm = 1.9048e-01, time/batch = 0.6944s	
2515/28500 (epoch 4.412), train_loss = 1.76024503, grad/param norm = 2.1267e-01, time/batch = 0.6930s	
2516/28500 (epoch 4.414), train_loss = 1.58801685, grad/param norm = 1.9415e-01, time/batch = 0.6970s	
2517/28500 (epoch 4.416), train_loss = 1.51599954, grad/param norm = 2.0291e-01, time/batch = 0.6924s	
2518/28500 (epoch 4.418), train_loss = 1.63892213, grad/param norm = 1.9662e-01, time/batch = 0.6928s	
2519/28500 (epoch 4.419), train_loss = 1.74330854, grad/param norm = 2.2075e-01, time/batch = 0.6932s	
2520/28500 (epoch 4.421), train_loss = 1.69239848, grad/param norm = 2.0789e-01, time/batch = 0.6943s	
2521/28500 (epoch 4.423), train_loss = 1.83867523, grad/param norm = 2.3704e-01, time/batch = 0.6957s	
2522/28500 (epoch 4.425), train_loss = 1.67046403, grad/param norm = 2.2312e-01, time/batch = 0.6932s	
2523/28500 (epoch 4.426), train_loss = 1.64516482, grad/param norm = 2.1847e-01, time/batch = 0.6938s	
2524/28500 (epoch 4.428), train_loss = 1.85820063, grad/param norm = 2.2860e-01, time/batch = 0.6910s	
2525/28500 (epoch 4.430), train_loss = 1.65961837, grad/param norm = 2.0161e-01, time/batch = 0.6927s	
2526/28500 (epoch 4.432), train_loss = 1.70430979, grad/param norm = 2.4296e-01, time/batch = 0.6928s	
2527/28500 (epoch 4.433), train_loss = 1.64414167, grad/param norm = 2.1057e-01, time/batch = 0.6935s	
2528/28500 (epoch 4.435), train_loss = 1.57151512, grad/param norm = 2.1231e-01, time/batch = 0.6958s	
2529/28500 (epoch 4.437), train_loss = 1.41864051, grad/param norm = 1.7166e-01, time/batch = 0.6931s	
2530/28500 (epoch 4.439), train_loss = 1.47265283, grad/param norm = 1.8743e-01, time/batch = 0.6929s	
2531/28500 (epoch 4.440), train_loss = 1.63753120, grad/param norm = 1.8578e-01, time/batch = 0.6962s	
2532/28500 (epoch 4.442), train_loss = 1.50457641, grad/param norm = 2.0711e-01, time/batch = 0.6935s	
2533/28500 (epoch 4.444), train_loss = 1.43419509, grad/param norm = 1.9559e-01, time/batch = 0.6930s	
2534/28500 (epoch 4.446), train_loss = 1.36989825, grad/param norm = 1.9955e-01, time/batch = 0.6939s	
2535/28500 (epoch 4.447), train_loss = 1.49660420, grad/param norm = 1.9218e-01, time/batch = 0.6955s	
2536/28500 (epoch 4.449), train_loss = 1.50977350, grad/param norm = 2.0159e-01, time/batch = 0.7013s	
2537/28500 (epoch 4.451), train_loss = 1.56948849, grad/param norm = 1.9369e-01, time/batch = 0.6926s	
2538/28500 (epoch 4.453), train_loss = 1.59726799, grad/param norm = 2.1188e-01, time/batch = 0.6928s	
2539/28500 (epoch 4.454), train_loss = 1.48811591, grad/param norm = 2.0636e-01, time/batch = 0.6932s	
2540/28500 (epoch 4.456), train_loss = 1.66241550, grad/param norm = 2.2294e-01, time/batch = 0.6938s	
2541/28500 (epoch 4.458), train_loss = 1.52434062, grad/param norm = 2.0840e-01, time/batch = 0.6911s	
2542/28500 (epoch 4.460), train_loss = 1.68153666, grad/param norm = 1.9656e-01, time/batch = 0.6896s	
2543/28500 (epoch 4.461), train_loss = 1.55017798, grad/param norm = 2.1150e-01, time/batch = 0.6896s	
2544/28500 (epoch 4.463), train_loss = 1.44419462, grad/param norm = 1.8447e-01, time/batch = 0.6888s	
2545/28500 (epoch 4.465), train_loss = 1.38511556, grad/param norm = 2.0550e-01, time/batch = 0.6893s	
2546/28500 (epoch 4.467), train_loss = 1.66046172, grad/param norm = 2.1023e-01, time/batch = 0.6886s	
2547/28500 (epoch 4.468), train_loss = 1.37376054, grad/param norm = 1.6063e-01, time/batch = 0.6896s	
2548/28500 (epoch 4.470), train_loss = 1.60772098, grad/param norm = 2.2012e-01, time/batch = 0.6897s	
2549/28500 (epoch 4.472), train_loss = 1.51444016, grad/param norm = 1.8650e-01, time/batch = 0.6885s	
2550/28500 (epoch 4.474), train_loss = 1.80303020, grad/param norm = 2.2446e-01, time/batch = 0.6893s	
2551/28500 (epoch 4.475), train_loss = 1.54266734, grad/param norm = 2.1976e-01, time/batch = 0.6908s	
2552/28500 (epoch 4.477), train_loss = 1.53164516, grad/param norm = 1.9963e-01, time/batch = 0.6907s	
2553/28500 (epoch 4.479), train_loss = 1.57715757, grad/param norm = 1.9259e-01, time/batch = 0.6954s	
2554/28500 (epoch 4.481), train_loss = 1.58935511, grad/param norm = 2.2259e-01, time/batch = 0.6969s	
2555/28500 (epoch 4.482), train_loss = 1.48414853, grad/param norm = 2.0353e-01, time/batch = 0.7100s	
2556/28500 (epoch 4.484), train_loss = 1.48823831, grad/param norm = 2.2175e-01, time/batch = 0.7104s	
2557/28500 (epoch 4.486), train_loss = 1.48485655, grad/param norm = 2.0382e-01, time/batch = 0.6986s	
2558/28500 (epoch 4.488), train_loss = 1.53425224, grad/param norm = 2.0486e-01, time/batch = 0.7002s	
2559/28500 (epoch 4.489), train_loss = 1.65282979, grad/param norm = 2.2063e-01, time/batch = 0.6969s	
2560/28500 (epoch 4.491), train_loss = 1.51771182, grad/param norm = 2.0983e-01, time/batch = 0.6943s	
2561/28500 (epoch 4.493), train_loss = 1.45633355, grad/param norm = 1.7719e-01, time/batch = 0.6968s	
2562/28500 (epoch 4.495), train_loss = 1.54662287, grad/param norm = 2.0168e-01, time/batch = 0.6943s	
2563/28500 (epoch 4.496), train_loss = 1.61566827, grad/param norm = 2.1850e-01, time/batch = 0.6980s	
2564/28500 (epoch 4.498), train_loss = 1.63734342, grad/param norm = 2.1800e-01, time/batch = 0.7559s	
2565/28500 (epoch 4.500), train_loss = 1.59509788, grad/param norm = 2.1097e-01, time/batch = 1.4171s	
2566/28500 (epoch 4.502), train_loss = 1.63636796, grad/param norm = 2.0354e-01, time/batch = 0.7105s	
2567/28500 (epoch 4.504), train_loss = 1.63242744, grad/param norm = 1.9121e-01, time/batch = 0.7049s	
2568/28500 (epoch 4.505), train_loss = 1.49680720, grad/param norm = 1.8426e-01, time/batch = 0.7020s	
2569/28500 (epoch 4.507), train_loss = 1.77424477, grad/param norm = 2.2939e-01, time/batch = 0.7011s	
2570/28500 (epoch 4.509), train_loss = 1.56791200, grad/param norm = 2.2587e-01, time/batch = 0.7008s	
