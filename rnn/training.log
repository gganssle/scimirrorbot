tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 333, val: 18, test: 0	
vocab size: 113	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 271089	
cloning rnn	
cloning criterion	
1/16650 (epoch 0.003), train_loss = 4.72148324, grad/param norm = 5.3424e-01, time/batch = 0.7096s	
2/16650 (epoch 0.006), train_loss = 4.35773922, grad/param norm = 1.5637e+00, time/batch = 0.6419s	
3/16650 (epoch 0.009), train_loss = 3.67199718, grad/param norm = 1.3680e+00, time/batch = 0.6283s	
4/16650 (epoch 0.012), train_loss = 3.52526947, grad/param norm = 7.0494e-01, time/batch = 0.6186s	
5/16650 (epoch 0.015), train_loss = 3.64673201, grad/param norm = 9.2885e-01, time/batch = 0.6296s	
6/16650 (epoch 0.018), train_loss = 3.46877254, grad/param norm = 6.0388e-01, time/batch = 0.6557s	
7/16650 (epoch 0.021), train_loss = 3.61761404, grad/param norm = 8.2078e-01, time/batch = 0.6240s	
8/16650 (epoch 0.024), train_loss = 3.37961549, grad/param norm = 7.5610e-01, time/batch = 0.6168s	
9/16650 (epoch 0.027), train_loss = 3.59541113, grad/param norm = 6.4977e-01, time/batch = 0.6203s	
10/16650 (epoch 0.030), train_loss = 3.36921221, grad/param norm = 6.7446e-01, time/batch = 0.6164s	
11/16650 (epoch 0.033), train_loss = 3.57754266, grad/param norm = 7.8945e-01, time/batch = 0.6223s	
12/16650 (epoch 0.036), train_loss = 3.52800230, grad/param norm = 8.9849e-01, time/batch = 0.6218s	
13/16650 (epoch 0.039), train_loss = 3.48441120, grad/param norm = 7.0371e-01, time/batch = 0.6231s	
14/16650 (epoch 0.042), train_loss = 3.45167082, grad/param norm = 7.3346e-01, time/batch = 0.6175s	
15/16650 (epoch 0.045), train_loss = 3.57871990, grad/param norm = 7.1937e-01, time/batch = 0.6194s	
16/16650 (epoch 0.048), train_loss = 3.51055505, grad/param norm = 6.6355e-01, time/batch = 0.6165s	
17/16650 (epoch 0.051), train_loss = 3.49824337, grad/param norm = 6.3713e-01, time/batch = 0.6168s	
18/16650 (epoch 0.054), train_loss = 3.45270763, grad/param norm = 5.8860e-01, time/batch = 0.6177s	
19/16650 (epoch 0.057), train_loss = 3.49529975, grad/param norm = 7.8018e-01, time/batch = 0.6171s	
20/16650 (epoch 0.060), train_loss = 3.43979567, grad/param norm = 6.9731e-01, time/batch = 0.6165s	
21/16650 (epoch 0.063), train_loss = 3.43509029, grad/param norm = 7.1473e-01, time/batch = 0.6203s	
22/16650 (epoch 0.066), train_loss = 3.47636555, grad/param norm = 6.2783e-01, time/batch = 0.6189s	
23/16650 (epoch 0.069), train_loss = 3.69575134, grad/param norm = 7.5469e-01, time/batch = 0.6174s	
24/16650 (epoch 0.072), train_loss = 3.45058221, grad/param norm = 7.5504e-01, time/batch = 0.6163s	
25/16650 (epoch 0.075), train_loss = 3.57251683, grad/param norm = 6.0239e-01, time/batch = 0.6180s	
26/16650 (epoch 0.078), train_loss = 3.43636030, grad/param norm = 7.1675e-01, time/batch = 0.6197s	
27/16650 (epoch 0.081), train_loss = 3.51184181, grad/param norm = 7.5938e-01, time/batch = 0.6177s	
28/16650 (epoch 0.084), train_loss = 3.49552977, grad/param norm = 6.3184e-01, time/batch = 0.6155s	
29/16650 (epoch 0.087), train_loss = 3.57352851, grad/param norm = 6.6701e-01, time/batch = 0.6157s	
30/16650 (epoch 0.090), train_loss = 3.53727248, grad/param norm = 7.4715e-01, time/batch = 0.6161s	
31/16650 (epoch 0.093), train_loss = 3.63015656, grad/param norm = 6.2459e-01, time/batch = 0.6197s	
32/16650 (epoch 0.096), train_loss = 3.56850107, grad/param norm = 5.7024e-01, time/batch = 0.6185s	
33/16650 (epoch 0.099), train_loss = 3.49891204, grad/param norm = 5.4987e-01, time/batch = 0.6256s	
34/16650 (epoch 0.102), train_loss = 3.51440479, grad/param norm = 5.0171e-01, time/batch = 0.6263s	
35/16650 (epoch 0.105), train_loss = 3.42118434, grad/param norm = 6.4686e-01, time/batch = 0.6357s	
36/16650 (epoch 0.108), train_loss = 3.58900553, grad/param norm = 5.8451e-01, time/batch = 0.6329s	
37/16650 (epoch 0.111), train_loss = 3.51349857, grad/param norm = 4.6167e-01, time/batch = 0.6424s	
38/16650 (epoch 0.114), train_loss = 3.48751077, grad/param norm = 4.9564e-01, time/batch = 0.6455s	
39/16650 (epoch 0.117), train_loss = 3.50020766, grad/param norm = 5.6942e-01, time/batch = 0.6435s	
40/16650 (epoch 0.120), train_loss = 3.50812492, grad/param norm = 5.3052e-01, time/batch = 0.6445s	
41/16650 (epoch 0.123), train_loss = 3.53616291, grad/param norm = 7.1859e-01, time/batch = 0.6429s	
42/16650 (epoch 0.126), train_loss = 3.49221233, grad/param norm = 1.1013e+00, time/batch = 0.6455s	
43/16650 (epoch 0.129), train_loss = 3.51599953, grad/param norm = 6.8305e-01, time/batch = 0.6424s	
44/16650 (epoch 0.132), train_loss = 3.56158261, grad/param norm = 5.3935e-01, time/batch = 0.6403s	
45/16650 (epoch 0.135), train_loss = 3.49856759, grad/param norm = 6.2977e-01, time/batch = 0.6432s	
46/16650 (epoch 0.138), train_loss = 3.52067163, grad/param norm = 5.9004e-01, time/batch = 0.6547s	
47/16650 (epoch 0.141), train_loss = 3.57732420, grad/param norm = 5.5309e-01, time/batch = 0.6148s	
48/16650 (epoch 0.144), train_loss = 3.42586013, grad/param norm = 6.6866e-01, time/batch = 0.6139s	
49/16650 (epoch 0.147), train_loss = 3.64381347, grad/param norm = 6.6975e-01, time/batch = 0.6134s	
50/16650 (epoch 0.150), train_loss = 3.70398254, grad/param norm = 5.9214e-01, time/batch = 0.6159s	
51/16650 (epoch 0.153), train_loss = 3.67626604, grad/param norm = 6.4565e-01, time/batch = 0.6191s	
52/16650 (epoch 0.156), train_loss = 3.48563832, grad/param norm = 5.2239e-01, time/batch = 0.6203s	
53/16650 (epoch 0.159), train_loss = 3.60110063, grad/param norm = 6.1143e-01, time/batch = 0.6183s	
54/16650 (epoch 0.162), train_loss = 3.33853721, grad/param norm = 8.0172e-01, time/batch = 0.6153s	
55/16650 (epoch 0.165), train_loss = 3.46203944, grad/param norm = 9.0256e-01, time/batch = 0.6148s	
56/16650 (epoch 0.168), train_loss = 3.37939456, grad/param norm = 6.6037e-01, time/batch = 0.6145s	
57/16650 (epoch 0.171), train_loss = 3.49560858, grad/param norm = 6.5601e-01, time/batch = 0.6133s	
58/16650 (epoch 0.174), train_loss = 3.47265157, grad/param norm = 4.9135e-01, time/batch = 0.6182s	
59/16650 (epoch 0.177), train_loss = 3.42407645, grad/param norm = 5.4820e-01, time/batch = 0.6158s	
60/16650 (epoch 0.180), train_loss = 3.53917991, grad/param norm = 5.6869e-01, time/batch = 0.6191s	
61/16650 (epoch 0.183), train_loss = 3.52547785, grad/param norm = 4.2632e-01, time/batch = 0.6185s	
62/16650 (epoch 0.186), train_loss = 3.54963312, grad/param norm = 5.8516e-01, time/batch = 0.6178s	
63/16650 (epoch 0.189), train_loss = 3.50342053, grad/param norm = 6.3251e-01, time/batch = 0.6169s	
64/16650 (epoch 0.192), train_loss = 3.46380140, grad/param norm = 6.9748e-01, time/batch = 0.6162s	
65/16650 (epoch 0.195), train_loss = 3.42629447, grad/param norm = 5.6140e-01, time/batch = 0.6183s	
66/16650 (epoch 0.198), train_loss = 3.47203454, grad/param norm = 7.9278e-01, time/batch = 0.6164s	
67/16650 (epoch 0.201), train_loss = 3.55765331, grad/param norm = 5.8484e-01, time/batch = 0.6231s	
68/16650 (epoch 0.204), train_loss = 3.34339036, grad/param norm = 6.7242e-01, time/batch = 0.6546s	
69/16650 (epoch 0.207), train_loss = 3.43163450, grad/param norm = 9.0877e-01, time/batch = 0.6374s	
70/16650 (epoch 0.210), train_loss = 3.47683368, grad/param norm = 6.6100e-01, time/batch = 0.6162s	
71/16650 (epoch 0.213), train_loss = 3.44835577, grad/param norm = 6.3312e-01, time/batch = 0.6195s	
72/16650 (epoch 0.216), train_loss = 3.48502998, grad/param norm = 4.7549e-01, time/batch = 0.6168s	
73/16650 (epoch 0.219), train_loss = 3.44575715, grad/param norm = 5.5530e-01, time/batch = 0.6166s	
74/16650 (epoch 0.222), train_loss = 3.45897639, grad/param norm = 6.5649e-01, time/batch = 0.6167s	
75/16650 (epoch 0.225), train_loss = 3.46601298, grad/param norm = 6.1577e-01, time/batch = 0.6176s	
76/16650 (epoch 0.228), train_loss = 3.43431215, grad/param norm = 7.0202e-01, time/batch = 0.6169s	
77/16650 (epoch 0.231), train_loss = 3.54100084, grad/param norm = 5.9000e-01, time/batch = 0.6193s	
78/16650 (epoch 0.234), train_loss = 3.53147427, grad/param norm = 7.1526e-01, time/batch = 0.6175s	
79/16650 (epoch 0.237), train_loss = 3.42445468, grad/param norm = 6.1793e-01, time/batch = 0.6176s	
80/16650 (epoch 0.240), train_loss = 3.56559466, grad/param norm = 5.8625e-01, time/batch = 0.6175s	
81/16650 (epoch 0.243), train_loss = 3.52215274, grad/param norm = 5.6734e-01, time/batch = 0.6243s	
82/16650 (epoch 0.246), train_loss = 3.60491048, grad/param norm = 8.3571e-01, time/batch = 0.6258s	
83/16650 (epoch 0.249), train_loss = 3.43660157, grad/param norm = 7.6624e-01, time/batch = 0.6287s	
84/16650 (epoch 0.252), train_loss = 3.54230233, grad/param norm = 6.1952e-01, time/batch = 0.6232s	
85/16650 (epoch 0.255), train_loss = 3.35921868, grad/param norm = 7.2405e-01, time/batch = 0.6290s	
86/16650 (epoch 0.258), train_loss = 3.42126957, grad/param norm = 6.2968e-01, time/batch = 0.6444s	
87/16650 (epoch 0.261), train_loss = 3.43824074, grad/param norm = 4.7666e-01, time/batch = 0.6450s	
88/16650 (epoch 0.264), train_loss = 3.45190517, grad/param norm = 5.4817e-01, time/batch = 0.6199s	
89/16650 (epoch 0.267), train_loss = 3.47589473, grad/param norm = 4.8348e-01, time/batch = 0.6196s	
90/16650 (epoch 0.270), train_loss = 3.40259169, grad/param norm = 4.6117e-01, time/batch = 0.6198s	
91/16650 (epoch 0.273), train_loss = 3.48083614, grad/param norm = 4.3807e-01, time/batch = 0.6218s	
92/16650 (epoch 0.276), train_loss = 3.44005674, grad/param norm = 9.9461e-01, time/batch = 0.6229s	
93/16650 (epoch 0.279), train_loss = 3.44589552, grad/param norm = 1.0398e+00, time/batch = 0.6310s	
94/16650 (epoch 0.282), train_loss = 3.46916563, grad/param norm = 4.8201e-01, time/batch = 0.6235s	
95/16650 (epoch 0.285), train_loss = 3.42005268, grad/param norm = 4.0939e-01, time/batch = 0.6567s	
96/16650 (epoch 0.288), train_loss = 3.44293553, grad/param norm = 4.8132e-01, time/batch = 0.6372s	
97/16650 (epoch 0.291), train_loss = 3.43154415, grad/param norm = 4.0499e-01, time/batch = 0.6177s	
98/16650 (epoch 0.294), train_loss = 3.44313373, grad/param norm = 5.6001e-01, time/batch = 0.6193s	
99/16650 (epoch 0.297), train_loss = 3.30354379, grad/param norm = 6.5623e-01, time/batch = 0.6180s	
100/16650 (epoch 0.300), train_loss = 3.44027703, grad/param norm = 1.3426e+00, time/batch = 0.6169s	
101/16650 (epoch 0.303), train_loss = 3.26333752, grad/param norm = 1.0770e+00, time/batch = 0.6225s	
102/16650 (epoch 0.306), train_loss = 3.37533253, grad/param norm = 5.5816e-01, time/batch = 0.6225s	
103/16650 (epoch 0.309), train_loss = 3.60905444, grad/param norm = 6.2130e-01, time/batch = 0.6225s	
104/16650 (epoch 0.312), train_loss = 3.38273962, grad/param norm = 7.0260e-01, time/batch = 0.6180s	
105/16650 (epoch 0.315), train_loss = 3.41710926, grad/param norm = 6.3538e-01, time/batch = 0.6161s	
106/16650 (epoch 0.318), train_loss = 3.42883038, grad/param norm = 6.9761e-01, time/batch = 0.6167s	
107/16650 (epoch 0.321), train_loss = 3.39109506, grad/param norm = 6.3835e-01, time/batch = 0.6165s	
108/16650 (epoch 0.324), train_loss = 3.55103651, grad/param norm = 4.7593e-01, time/batch = 0.6160s	
109/16650 (epoch 0.327), train_loss = 3.32813098, grad/param norm = 6.3200e-01, time/batch = 0.6194s	
110/16650 (epoch 0.330), train_loss = 3.30455967, grad/param norm = 7.2825e-01, time/batch = 0.6183s	
111/16650 (epoch 0.333), train_loss = 3.35814824, grad/param norm = 8.6384e-01, time/batch = 0.6234s	
112/16650 (epoch 0.336), train_loss = 3.25004910, grad/param norm = 9.2431e-01, time/batch = 0.6175s	
113/16650 (epoch 0.339), train_loss = 3.24717110, grad/param norm = 1.0511e+00, time/batch = 0.6155s	
114/16650 (epoch 0.342), train_loss = 3.37887920, grad/param norm = 1.0746e+00, time/batch = 0.6160s	
115/16650 (epoch 0.345), train_loss = 3.34748002, grad/param norm = 1.2163e+00, time/batch = 0.6158s	
116/16650 (epoch 0.348), train_loss = 3.31388632, grad/param norm = 7.7383e-01, time/batch = 0.6148s	
117/16650 (epoch 0.351), train_loss = 3.22967059, grad/param norm = 4.8024e-01, time/batch = 0.6233s	
118/16650 (epoch 0.354), train_loss = 3.33330044, grad/param norm = 7.1196e-01, time/batch = 0.6210s	
119/16650 (epoch 0.357), train_loss = 3.29150526, grad/param norm = 1.0964e+00, time/batch = 0.6306s	
120/16650 (epoch 0.360), train_loss = 3.23481285, grad/param norm = 5.8374e-01, time/batch = 0.6221s	
121/16650 (epoch 0.363), train_loss = 3.31835941, grad/param norm = 4.9970e-01, time/batch = 0.6203s	
122/16650 (epoch 0.366), train_loss = 3.13685279, grad/param norm = 5.3169e-01, time/batch = 0.6179s	
123/16650 (epoch 0.369), train_loss = 3.26782913, grad/param norm = 6.2626e-01, time/batch = 0.6189s	
124/16650 (epoch 0.372), train_loss = 3.15914177, grad/param norm = 8.1572e-01, time/batch = 0.6182s	
125/16650 (epoch 0.375), train_loss = 3.14865712, grad/param norm = 9.5073e-01, time/batch = 0.6400s	
126/16650 (epoch 0.378), train_loss = 3.11310432, grad/param norm = 1.0888e+00, time/batch = 0.6552s	
127/16650 (epoch 0.381), train_loss = 3.43291789, grad/param norm = 1.3596e+00, time/batch = 0.6192s	
128/16650 (epoch 0.384), train_loss = 3.11272133, grad/param norm = 1.2083e+00, time/batch = 0.6202s	
129/16650 (epoch 0.387), train_loss = 3.43854795, grad/param norm = 1.4812e+00, time/batch = 0.6199s	
130/16650 (epoch 0.390), train_loss = 3.24154039, grad/param norm = 1.0522e+00, time/batch = 0.6174s	
131/16650 (epoch 0.393), train_loss = 3.11485993, grad/param norm = 5.2901e-01, time/batch = 0.6227s	
132/16650 (epoch 0.396), train_loss = 3.32168636, grad/param norm = 5.1569e-01, time/batch = 0.6179s	
133/16650 (epoch 0.399), train_loss = 3.19053087, grad/param norm = 6.2918e-01, time/batch = 0.6302s	
134/16650 (epoch 0.402), train_loss = 3.12846447, grad/param norm = 6.1000e-01, time/batch = 0.6338s	
135/16650 (epoch 0.405), train_loss = 3.23885991, grad/param norm = 5.8763e-01, time/batch = 0.6232s	
136/16650 (epoch 0.408), train_loss = 3.10719381, grad/param norm = 3.9992e-01, time/batch = 0.6204s	
137/16650 (epoch 0.411), train_loss = 3.13131849, grad/param norm = 3.4608e-01, time/batch = 0.6183s	
138/16650 (epoch 0.414), train_loss = 3.05817878, grad/param norm = 3.7345e-01, time/batch = 0.6193s	
139/16650 (epoch 0.417), train_loss = 3.21223239, grad/param norm = 6.3247e-01, time/batch = 0.6160s	
140/16650 (epoch 0.420), train_loss = 3.14318661, grad/param norm = 1.1359e+00, time/batch = 0.6174s	
141/16650 (epoch 0.423), train_loss = 3.11898667, grad/param norm = 1.4113e+00, time/batch = 0.6186s	
142/16650 (epoch 0.426), train_loss = 3.17331653, grad/param norm = 1.0966e+00, time/batch = 0.6177s	
143/16650 (epoch 0.429), train_loss = 3.05749300, grad/param norm = 5.4332e-01, time/batch = 0.6186s	
144/16650 (epoch 0.432), train_loss = 3.02152155, grad/param norm = 4.5122e-01, time/batch = 0.6164s	
145/16650 (epoch 0.435), train_loss = 3.19493301, grad/param norm = 5.0640e-01, time/batch = 0.6164s	
146/16650 (epoch 0.438), train_loss = 3.06927727, grad/param norm = 5.3239e-01, time/batch = 0.6208s	
147/16650 (epoch 0.441), train_loss = 3.18586591, grad/param norm = 7.5609e-01, time/batch = 0.6213s	
148/16650 (epoch 0.444), train_loss = 3.20696476, grad/param norm = 9.7558e-01, time/batch = 0.6194s	
149/16650 (epoch 0.447), train_loss = 3.12943174, grad/param norm = 7.3599e-01, time/batch = 0.6192s	
150/16650 (epoch 0.450), train_loss = 3.07837284, grad/param norm = 7.6139e-01, time/batch = 0.6194s	
151/16650 (epoch 0.453), train_loss = 3.14472468, grad/param norm = 8.6521e-01, time/batch = 0.6210s	
152/16650 (epoch 0.456), train_loss = 3.17583429, grad/param norm = 7.5472e-01, time/batch = 0.6197s	
153/16650 (epoch 0.459), train_loss = 3.04720252, grad/param norm = 5.9880e-01, time/batch = 0.6180s	
154/16650 (epoch 0.462), train_loss = 3.07121578, grad/param norm = 6.1008e-01, time/batch = 0.6208s	
155/16650 (epoch 0.465), train_loss = 3.03292157, grad/param norm = 8.1892e-01, time/batch = 0.6195s	
156/16650 (epoch 0.468), train_loss = 2.93635707, grad/param norm = 8.0571e-01, time/batch = 0.6177s	
157/16650 (epoch 0.471), train_loss = 3.06577978, grad/param norm = 6.8702e-01, time/batch = 0.6174s	
158/16650 (epoch 0.474), train_loss = 2.97940505, grad/param norm = 5.5211e-01, time/batch = 0.6186s	
159/16650 (epoch 0.477), train_loss = 2.98965481, grad/param norm = 6.6642e-01, time/batch = 0.6174s	
160/16650 (epoch 0.480), train_loss = 3.03997512, grad/param norm = 9.9357e-01, time/batch = 0.6305s	
161/16650 (epoch 0.483), train_loss = 3.16475825, grad/param norm = 1.1446e+00, time/batch = 0.6346s	
162/16650 (epoch 0.486), train_loss = 2.91895148, grad/param norm = 8.9373e-01, time/batch = 0.6285s	
163/16650 (epoch 0.489), train_loss = 3.15771770, grad/param norm = 1.1198e+00, time/batch = 0.6298s	
164/16650 (epoch 0.492), train_loss = 3.01829415, grad/param norm = 9.5429e-01, time/batch = 0.6186s	
165/16650 (epoch 0.495), train_loss = 2.91281090, grad/param norm = 6.6256e-01, time/batch = 0.6274s	
166/16650 (epoch 0.498), train_loss = 3.07791708, grad/param norm = 4.6541e-01, time/batch = 0.6160s	
167/16650 (epoch 0.502), train_loss = 3.01828006, grad/param norm = 3.2395e-01, time/batch = 0.6205s	
168/16650 (epoch 0.505), train_loss = 3.08551874, grad/param norm = 4.0544e-01, time/batch = 0.6205s	
169/16650 (epoch 0.508), train_loss = 3.04128918, grad/param norm = 4.6201e-01, time/batch = 0.6191s	
170/16650 (epoch 0.511), train_loss = 3.00865688, grad/param norm = 5.7068e-01, time/batch = 0.6205s	
171/16650 (epoch 0.514), train_loss = 2.96341893, grad/param norm = 7.0897e-01, time/batch = 0.6240s	
172/16650 (epoch 0.517), train_loss = 2.96562584, grad/param norm = 7.9113e-01, time/batch = 0.6182s	
173/16650 (epoch 0.520), train_loss = 3.02172970, grad/param norm = 7.5327e-01, time/batch = 0.6168s	
174/16650 (epoch 0.523), train_loss = 3.00545768, grad/param norm = 5.9168e-01, time/batch = 0.6164s	
175/16650 (epoch 0.526), train_loss = 2.93944115, grad/param norm = 5.4754e-01, time/batch = 0.6560s	
176/16650 (epoch 0.529), train_loss = 2.95236088, grad/param norm = 5.5636e-01, time/batch = 0.6381s	
177/16650 (epoch 0.532), train_loss = 2.93790069, grad/param norm = 5.5898e-01, time/batch = 0.6177s	
178/16650 (epoch 0.535), train_loss = 2.93883528, grad/param norm = 4.8628e-01, time/batch = 0.6173s	
179/16650 (epoch 0.538), train_loss = 2.99030878, grad/param norm = 5.6168e-01, time/batch = 0.6303s	
180/16650 (epoch 0.541), train_loss = 2.88650284, grad/param norm = 5.5623e-01, time/batch = 0.6576s	
181/16650 (epoch 0.544), train_loss = 3.08497749, grad/param norm = 6.5910e-01, time/batch = 0.6391s	
182/16650 (epoch 0.547), train_loss = 2.90467056, grad/param norm = 6.9448e-01, time/batch = 0.6510s	
183/16650 (epoch 0.550), train_loss = 2.98957368, grad/param norm = 7.4748e-01, time/batch = 0.6752s	
184/16650 (epoch 0.553), train_loss = 3.05094297, grad/param norm = 8.8125e-01, time/batch = 0.6467s	
185/16650 (epoch 0.556), train_loss = 2.96337646, grad/param norm = 7.4668e-01, time/batch = 0.6361s	
186/16650 (epoch 0.559), train_loss = 2.88226449, grad/param norm = 7.8157e-01, time/batch = 0.6377s	
187/16650 (epoch 0.562), train_loss = 2.94888509, grad/param norm = 8.1288e-01, time/batch = 0.6356s	
188/16650 (epoch 0.565), train_loss = 2.91076435, grad/param norm = 7.5791e-01, time/batch = 0.6345s	
189/16650 (epoch 0.568), train_loss = 2.98832617, grad/param norm = 7.1085e-01, time/batch = 0.6350s	
190/16650 (epoch 0.571), train_loss = 2.95259533, grad/param norm = 5.4442e-01, time/batch = 0.6424s	
191/16650 (epoch 0.574), train_loss = 2.89186130, grad/param norm = 3.8051e-01, time/batch = 0.6428s	
192/16650 (epoch 0.577), train_loss = 2.89760537, grad/param norm = 3.8504e-01, time/batch = 0.6389s	
193/16650 (epoch 0.580), train_loss = 2.97874028, grad/param norm = 4.6776e-01, time/batch = 0.6405s	
194/16650 (epoch 0.583), train_loss = 2.89317104, grad/param norm = 7.4447e-01, time/batch = 0.6327s	
195/16650 (epoch 0.586), train_loss = 3.02751015, grad/param norm = 6.2688e-01, time/batch = 0.6321s	
196/16650 (epoch 0.589), train_loss = 2.82310269, grad/param norm = 3.4312e-01, time/batch = 0.6363s	
197/16650 (epoch 0.592), train_loss = 2.95536086, grad/param norm = 5.0542e-01, time/batch = 0.6471s	
198/16650 (epoch 0.595), train_loss = 2.86553514, grad/param norm = 6.2115e-01, time/batch = 0.6396s	
199/16650 (epoch 0.598), train_loss = 2.80660655, grad/param norm = 6.8615e-01, time/batch = 0.6343s	
200/16650 (epoch 0.601), train_loss = 3.05233604, grad/param norm = 1.2198e+00, time/batch = 0.6391s	
201/16650 (epoch 0.604), train_loss = 2.95406782, grad/param norm = 1.2114e+00, time/batch = 0.6428s	
202/16650 (epoch 0.607), train_loss = 2.90357517, grad/param norm = 8.4295e-01, time/batch = 0.6434s	
203/16650 (epoch 0.610), train_loss = 2.94155149, grad/param norm = 6.8759e-01, time/batch = 0.6453s	
204/16650 (epoch 0.613), train_loss = 3.01355279, grad/param norm = 3.4127e-01, time/batch = 0.6547s	
205/16650 (epoch 0.616), train_loss = 2.93508874, grad/param norm = 4.1638e-01, time/batch = 0.6621s	
206/16650 (epoch 0.619), train_loss = 2.93219858, grad/param norm = 4.4957e-01, time/batch = 0.6641s	
207/16650 (epoch 0.622), train_loss = 2.80834250, grad/param norm = 5.5674e-01, time/batch = 0.6621s	
208/16650 (epoch 0.625), train_loss = 2.92358770, grad/param norm = 5.7134e-01, time/batch = 0.6633s	
209/16650 (epoch 0.628), train_loss = 2.77647793, grad/param norm = 4.5017e-01, time/batch = 0.6737s	
210/16650 (epoch 0.631), train_loss = 2.97691403, grad/param norm = 5.5327e-01, time/batch = 0.6612s	
211/16650 (epoch 0.634), train_loss = 2.81351583, grad/param norm = 6.7375e-01, time/batch = 0.6453s	
212/16650 (epoch 0.637), train_loss = 2.86910886, grad/param norm = 5.1249e-01, time/batch = 0.6467s	
213/16650 (epoch 0.640), train_loss = 2.92805225, grad/param norm = 4.9743e-01, time/batch = 0.6391s	
214/16650 (epoch 0.643), train_loss = 2.89994183, grad/param norm = 4.8791e-01, time/batch = 0.6349s	
215/16650 (epoch 0.646), train_loss = 2.99948142, grad/param norm = 6.0839e-01, time/batch = 0.6339s	
216/16650 (epoch 0.649), train_loss = 2.90757480, grad/param norm = 7.6242e-01, time/batch = 0.6332s	
217/16650 (epoch 0.652), train_loss = 2.92600025, grad/param norm = 1.1610e+00, time/batch = 0.6338s	
218/16650 (epoch 0.655), train_loss = 3.11725905, grad/param norm = 8.2382e-01, time/batch = 0.6366s	
219/16650 (epoch 0.658), train_loss = 2.88621936, grad/param norm = 5.6613e-01, time/batch = 0.6362s	
220/16650 (epoch 0.661), train_loss = 2.98705503, grad/param norm = 5.4053e-01, time/batch = 0.6380s	
221/16650 (epoch 0.664), train_loss = 2.94008458, grad/param norm = 6.7930e-01, time/batch = 0.6439s	
222/16650 (epoch 0.667), train_loss = 2.86115673, grad/param norm = 6.0375e-01, time/batch = 0.6603s	
223/16650 (epoch 0.670), train_loss = 2.83396405, grad/param norm = 6.6093e-01, time/batch = 0.6451s	
224/16650 (epoch 0.673), train_loss = 2.83693929, grad/param norm = 4.1208e-01, time/batch = 0.6467s	
225/16650 (epoch 0.676), train_loss = 2.74919176, grad/param norm = 4.1211e-01, time/batch = 0.6435s	
226/16650 (epoch 0.679), train_loss = 2.87130517, grad/param norm = 5.7032e-01, time/batch = 0.6369s	
227/16650 (epoch 0.682), train_loss = 3.00593203, grad/param norm = 6.9259e-01, time/batch = 0.6377s	
228/16650 (epoch 0.685), train_loss = 2.80842999, grad/param norm = 4.6184e-01, time/batch = 0.6382s	
229/16650 (epoch 0.688), train_loss = 2.90597930, grad/param norm = 4.8147e-01, time/batch = 0.6381s	
230/16650 (epoch 0.691), train_loss = 2.80123526, grad/param norm = 7.5104e-01, time/batch = 0.6384s	
231/16650 (epoch 0.694), train_loss = 2.80198603, grad/param norm = 7.8044e-01, time/batch = 0.6375s	
232/16650 (epoch 0.697), train_loss = 2.73176791, grad/param norm = 6.2780e-01, time/batch = 0.6359s	
233/16650 (epoch 0.700), train_loss = 2.96118090, grad/param norm = 4.5224e-01, time/batch = 0.6397s	
234/16650 (epoch 0.703), train_loss = 2.80406801, grad/param norm = 5.5790e-01, time/batch = 0.6372s	
235/16650 (epoch 0.706), train_loss = 2.77892331, grad/param norm = 4.5644e-01, time/batch = 0.6336s	
236/16650 (epoch 0.709), train_loss = 2.83248490, grad/param norm = 3.7750e-01, time/batch = 0.6341s	
237/16650 (epoch 0.712), train_loss = 2.78545417, grad/param norm = 4.2431e-01, time/batch = 0.6348s	
238/16650 (epoch 0.715), train_loss = 2.80330398, grad/param norm = 5.5677e-01, time/batch = 0.6517s	
239/16650 (epoch 0.718), train_loss = 2.84418419, grad/param norm = 5.8865e-01, time/batch = 0.6730s	
240/16650 (epoch 0.721), train_loss = 2.81729511, grad/param norm = 7.3674e-01, time/batch = 0.6439s	
241/16650 (epoch 0.724), train_loss = 2.85941365, grad/param norm = 7.7842e-01, time/batch = 0.6426s	
242/16650 (epoch 0.727), train_loss = 2.75835163, grad/param norm = 6.9295e-01, time/batch = 0.6369s	
243/16650 (epoch 0.730), train_loss = 2.73514852, grad/param norm = 8.8741e-01, time/batch = 0.6431s	
244/16650 (epoch 0.733), train_loss = 2.91924261, grad/param norm = 9.1690e-01, time/batch = 0.6405s	
245/16650 (epoch 0.736), train_loss = 2.78824562, grad/param norm = 5.1201e-01, time/batch = 0.6395s	
246/16650 (epoch 0.739), train_loss = 2.71198911, grad/param norm = 3.8071e-01, time/batch = 0.6555s	
247/16650 (epoch 0.742), train_loss = 2.84259679, grad/param norm = 4.4801e-01, time/batch = 0.6402s	
248/16650 (epoch 0.745), train_loss = 2.76774730, grad/param norm = 3.8882e-01, time/batch = 0.6422s	
249/16650 (epoch 0.748), train_loss = 2.67245898, grad/param norm = 4.1734e-01, time/batch = 0.6385s	
250/16650 (epoch 0.751), train_loss = 2.93823465, grad/param norm = 4.8763e-01, time/batch = 0.6387s	
251/16650 (epoch 0.754), train_loss = 2.80974769, grad/param norm = 5.2949e-01, time/batch = 0.6390s	
252/16650 (epoch 0.757), train_loss = 2.79201165, grad/param norm = 5.5470e-01, time/batch = 0.6380s	
253/16650 (epoch 0.760), train_loss = 2.83499766, grad/param norm = 5.6799e-01, time/batch = 0.6383s	
254/16650 (epoch 0.763), train_loss = 2.78202485, grad/param norm = 6.8926e-01, time/batch = 0.6423s	
255/16650 (epoch 0.766), train_loss = 2.87023362, grad/param norm = 8.9698e-01, time/batch = 0.6403s	
256/16650 (epoch 0.769), train_loss = 2.75568570, grad/param norm = 7.1513e-01, time/batch = 0.6388s	
257/16650 (epoch 0.772), train_loss = 2.87295997, grad/param norm = 5.9794e-01, time/batch = 0.6336s	
258/16650 (epoch 0.775), train_loss = 2.82089427, grad/param norm = 5.4022e-01, time/batch = 0.6338s	
259/16650 (epoch 0.778), train_loss = 2.77819104, grad/param norm = 6.0317e-01, time/batch = 0.6327s	
260/16650 (epoch 0.781), train_loss = 2.73537444, grad/param norm = 5.2608e-01, time/batch = 0.6365s	
261/16650 (epoch 0.784), train_loss = 2.85090711, grad/param norm = 6.7738e-01, time/batch = 0.6367s	
262/16650 (epoch 0.787), train_loss = 2.86056566, grad/param norm = 7.7282e-01, time/batch = 0.6335s	
263/16650 (epoch 0.790), train_loss = 2.64222932, grad/param norm = 5.3075e-01, time/batch = 0.6335s	
264/16650 (epoch 0.793), train_loss = 2.64516239, grad/param norm = 5.2970e-01, time/batch = 0.6349s	
265/16650 (epoch 0.796), train_loss = 2.93247486, grad/param norm = 6.6815e-01, time/batch = 0.6346s	
266/16650 (epoch 0.799), train_loss = 2.83203879, grad/param norm = 6.6684e-01, time/batch = 0.6324s	
267/16650 (epoch 0.802), train_loss = 2.77491353, grad/param norm = 6.2021e-01, time/batch = 0.6315s	
268/16650 (epoch 0.805), train_loss = 2.74832827, grad/param norm = 8.2341e-01, time/batch = 0.6342s	
269/16650 (epoch 0.808), train_loss = 2.76510429, grad/param norm = 6.3783e-01, time/batch = 0.6327s	
270/16650 (epoch 0.811), train_loss = 2.80828295, grad/param norm = 3.5723e-01, time/batch = 0.6321s	
271/16650 (epoch 0.814), train_loss = 2.68537304, grad/param norm = 3.4700e-01, time/batch = 0.6427s	
272/16650 (epoch 0.817), train_loss = 2.70882949, grad/param norm = 4.3712e-01, time/batch = 0.6467s	
273/16650 (epoch 0.820), train_loss = 2.67362826, grad/param norm = 5.4455e-01, time/batch = 0.6739s	
274/16650 (epoch 0.823), train_loss = 2.60650292, grad/param norm = 6.2929e-01, time/batch = 0.6570s	
275/16650 (epoch 0.826), train_loss = 2.76991894, grad/param norm = 7.9972e-01, time/batch = 0.6642s	
276/16650 (epoch 0.829), train_loss = 2.82474061, grad/param norm = 5.4738e-01, time/batch = 0.6644s	
277/16650 (epoch 0.832), train_loss = 2.80273253, grad/param norm = 4.0161e-01, time/batch = 0.6421s	
278/16650 (epoch 0.835), train_loss = 2.65847623, grad/param norm = 5.1438e-01, time/batch = 0.6356s	
279/16650 (epoch 0.838), train_loss = 2.68032173, grad/param norm = 5.9387e-01, time/batch = 0.6373s	
280/16650 (epoch 0.841), train_loss = 2.62364517, grad/param norm = 5.8772e-01, time/batch = 0.6368s	
281/16650 (epoch 0.844), train_loss = 2.68162289, grad/param norm = 6.3936e-01, time/batch = 0.6416s	
282/16650 (epoch 0.847), train_loss = 2.81377454, grad/param norm = 3.8434e-01, time/batch = 0.6550s	
283/16650 (epoch 0.850), train_loss = 2.68226996, grad/param norm = 3.8508e-01, time/batch = 0.6456s	
284/16650 (epoch 0.853), train_loss = 2.67996394, grad/param norm = 4.9453e-01, time/batch = 0.6386s	
285/16650 (epoch 0.856), train_loss = 2.66664819, grad/param norm = 6.5671e-01, time/batch = 0.6397s	
286/16650 (epoch 0.859), train_loss = 2.68253628, grad/param norm = 8.3137e-01, time/batch = 0.6360s	
287/16650 (epoch 0.862), train_loss = 2.88950825, grad/param norm = 8.3795e-01, time/batch = 0.6431s	
288/16650 (epoch 0.865), train_loss = 2.60375664, grad/param norm = 6.1354e-01, time/batch = 0.6368s	
289/16650 (epoch 0.868), train_loss = 2.58003248, grad/param norm = 3.0500e-01, time/batch = 0.6453s	
290/16650 (epoch 0.871), train_loss = 2.65067154, grad/param norm = 4.4658e-01, time/batch = 0.6586s	
291/16650 (epoch 0.874), train_loss = 2.67874269, grad/param norm = 5.9539e-01, time/batch = 0.6389s	
292/16650 (epoch 0.877), train_loss = 2.60369692, grad/param norm = 5.9462e-01, time/batch = 0.6365s	
293/16650 (epoch 0.880), train_loss = 2.65913638, grad/param norm = 8.2325e-01, time/batch = 0.6350s	
294/16650 (epoch 0.883), train_loss = 2.72606092, grad/param norm = 7.7858e-01, time/batch = 0.6341s	
295/16650 (epoch 0.886), train_loss = 2.68755109, grad/param norm = 5.3897e-01, time/batch = 0.6346s	
296/16650 (epoch 0.889), train_loss = 2.57495554, grad/param norm = 4.4899e-01, time/batch = 0.6360s	
297/16650 (epoch 0.892), train_loss = 2.69808479, grad/param norm = 4.8385e-01, time/batch = 0.6468s	
298/16650 (epoch 0.895), train_loss = 2.76188619, grad/param norm = 4.2498e-01, time/batch = 0.6386s	
299/16650 (epoch 0.898), train_loss = 2.57866917, grad/param norm = 4.0745e-01, time/batch = 0.6356s	
300/16650 (epoch 0.901), train_loss = 2.57504789, grad/param norm = 5.6152e-01, time/batch = 0.6366s	
301/16650 (epoch 0.904), train_loss = 2.61433948, grad/param norm = 6.0170e-01, time/batch = 0.6358s	
302/16650 (epoch 0.907), train_loss = 2.63904156, grad/param norm = 5.2505e-01, time/batch = 0.6343s	
303/16650 (epoch 0.910), train_loss = 2.69020178, grad/param norm = 4.3602e-01, time/batch = 0.6338s	
304/16650 (epoch 0.913), train_loss = 2.70451295, grad/param norm = 5.9832e-01, time/batch = 0.6340s	
305/16650 (epoch 0.916), train_loss = 2.70091064, grad/param norm = 7.1400e-01, time/batch = 0.6358s	
306/16650 (epoch 0.919), train_loss = 2.76418746, grad/param norm = 5.9695e-01, time/batch = 0.6415s	
307/16650 (epoch 0.922), train_loss = 2.76799845, grad/param norm = 4.4654e-01, time/batch = 0.6353s	
308/16650 (epoch 0.925), train_loss = 2.75797937, grad/param norm = 4.1230e-01, time/batch = 0.6351s	
309/16650 (epoch 0.928), train_loss = 2.66129763, grad/param norm = 4.0884e-01, time/batch = 0.6339s	
310/16650 (epoch 0.931), train_loss = 2.65634524, grad/param norm = 4.4428e-01, time/batch = 0.6358s	
311/16650 (epoch 0.934), train_loss = 2.65355705, grad/param norm = 3.3018e-01, time/batch = 0.6375s	
312/16650 (epoch 0.937), train_loss = 2.64529724, grad/param norm = 4.1497e-01, time/batch = 0.6364s	
313/16650 (epoch 0.940), train_loss = 2.73232854, grad/param norm = 4.5634e-01, time/batch = 0.6369s	
314/16650 (epoch 0.943), train_loss = 2.78651597, grad/param norm = 5.9289e-01, time/batch = 0.6403s	
315/16650 (epoch 0.946), train_loss = 2.71442798, grad/param norm = 7.8512e-01, time/batch = 0.6383s	
316/16650 (epoch 0.949), train_loss = 2.75012576, grad/param norm = 6.6242e-01, time/batch = 0.6350s	
317/16650 (epoch 0.952), train_loss = 2.60281812, grad/param norm = 6.0129e-01, time/batch = 0.6358s	
318/16650 (epoch 0.955), train_loss = 2.85987465, grad/param norm = 4.8849e-01, time/batch = 0.6374s	
319/16650 (epoch 0.958), train_loss = 2.69244211, grad/param norm = 4.8713e-01, time/batch = 0.6361s	
320/16650 (epoch 0.961), train_loss = 2.61166444, grad/param norm = 6.5457e-01, time/batch = 0.6374s	
321/16650 (epoch 0.964), train_loss = 2.66378748, grad/param norm = 9.1164e-01, time/batch = 0.6764s	
322/16650 (epoch 0.967), train_loss = 2.76470978, grad/param norm = 6.6809e-01, time/batch = 0.6534s	
323/16650 (epoch 0.970), train_loss = 2.67458661, grad/param norm = 4.0227e-01, time/batch = 0.6400s	
324/16650 (epoch 0.973), train_loss = 2.58237189, grad/param norm = 3.8822e-01, time/batch = 0.6349s	
325/16650 (epoch 0.976), train_loss = 2.55201643, grad/param norm = 3.6302e-01, time/batch = 0.6519s	
326/16650 (epoch 0.979), train_loss = 2.70951036, grad/param norm = 3.5515e-01, time/batch = 0.6727s	
327/16650 (epoch 0.982), train_loss = 2.57471030, grad/param norm = 3.9193e-01, time/batch = 0.6348s	
328/16650 (epoch 0.985), train_loss = 2.51600780, grad/param norm = 6.8545e-01, time/batch = 0.6352s	
329/16650 (epoch 0.988), train_loss = 2.83710487, grad/param norm = 6.4935e-01, time/batch = 0.6350s	
330/16650 (epoch 0.991), train_loss = 2.61775551, grad/param norm = 5.8906e-01, time/batch = 0.6413s	
331/16650 (epoch 0.994), train_loss = 2.73279112, grad/param norm = 5.6233e-01, time/batch = 0.6404s	
332/16650 (epoch 0.997), train_loss = 2.67414834, grad/param norm = 5.9018e-01, time/batch = 0.6344s	
333/16650 (epoch 1.000), train_loss = 2.74260614, grad/param norm = 6.4894e-01, time/batch = 0.6340s	
334/16650 (epoch 1.003), train_loss = 2.62241281, grad/param norm = 4.9383e-01, time/batch = 0.6342s	
335/16650 (epoch 1.006), train_loss = 2.72095494, grad/param norm = 6.4270e-01, time/batch = 0.6359s	
336/16650 (epoch 1.009), train_loss = 2.73223434, grad/param norm = 6.4467e-01, time/batch = 0.6351s	
337/16650 (epoch 1.012), train_loss = 2.79438102, grad/param norm = 3.9337e-01, time/batch = 0.6354s	
338/16650 (epoch 1.015), train_loss = 2.75903253, grad/param norm = 4.5695e-01, time/batch = 0.6361s	
339/16650 (epoch 1.018), train_loss = 2.61359228, grad/param norm = 4.5469e-01, time/batch = 0.6372s	
340/16650 (epoch 1.021), train_loss = 2.78523897, grad/param norm = 6.1454e-01, time/batch = 0.6362s	
341/16650 (epoch 1.024), train_loss = 2.51926186, grad/param norm = 6.3502e-01, time/batch = 0.6376s	
342/16650 (epoch 1.027), train_loss = 2.59680726, grad/param norm = 4.4286e-01, time/batch = 0.6362s	
343/16650 (epoch 1.030), train_loss = 2.59173379, grad/param norm = 3.3234e-01, time/batch = 0.6354s	
344/16650 (epoch 1.033), train_loss = 2.53679372, grad/param norm = 3.0103e-01, time/batch = 0.6363s	
345/16650 (epoch 1.036), train_loss = 2.69299692, grad/param norm = 3.5665e-01, time/batch = 0.6369s	
346/16650 (epoch 1.039), train_loss = 2.61167863, grad/param norm = 3.7513e-01, time/batch = 0.6363s	
347/16650 (epoch 1.042), train_loss = 2.63984456, grad/param norm = 3.9475e-01, time/batch = 0.6367s	
348/16650 (epoch 1.045), train_loss = 2.56032135, grad/param norm = 4.6014e-01, time/batch = 0.6374s	
349/16650 (epoch 1.048), train_loss = 2.56656023, grad/param norm = 4.8645e-01, time/batch = 0.6363s	
350/16650 (epoch 1.051), train_loss = 2.57520037, grad/param norm = 5.0866e-01, time/batch = 0.6359s	
351/16650 (epoch 1.054), train_loss = 2.59976296, grad/param norm = 9.4039e-01, time/batch = 0.6387s	
352/16650 (epoch 1.057), train_loss = 2.72716197, grad/param norm = 1.1397e+00, time/batch = 0.6377s	
353/16650 (epoch 1.060), train_loss = 2.63938051, grad/param norm = 7.3314e-01, time/batch = 0.6378s	
354/16650 (epoch 1.063), train_loss = 2.55287673, grad/param norm = 3.7847e-01, time/batch = 0.6359s	
355/16650 (epoch 1.066), train_loss = 2.63418486, grad/param norm = 3.5595e-01, time/batch = 0.6358s	
356/16650 (epoch 1.069), train_loss = 2.73372435, grad/param norm = 3.0682e-01, time/batch = 0.6373s	
357/16650 (epoch 1.072), train_loss = 2.62931424, grad/param norm = 3.4515e-01, time/batch = 0.6357s	
358/16650 (epoch 1.075), train_loss = 2.55611501, grad/param norm = 4.0493e-01, time/batch = 0.6366s	
359/16650 (epoch 1.078), train_loss = 2.56817778, grad/param norm = 4.7938e-01, time/batch = 0.6470s	
360/16650 (epoch 1.081), train_loss = 2.61374513, grad/param norm = 4.1659e-01, time/batch = 0.6730s	
361/16650 (epoch 1.084), train_loss = 2.57841957, grad/param norm = 3.3296e-01, time/batch = 0.6484s	
362/16650 (epoch 1.087), train_loss = 2.63157241, grad/param norm = 3.7860e-01, time/batch = 0.6353s	
363/16650 (epoch 1.090), train_loss = 2.59600355, grad/param norm = 3.4984e-01, time/batch = 0.6355s	
364/16650 (epoch 1.093), train_loss = 2.78870469, grad/param norm = 5.5726e-01, time/batch = 0.6350s	
365/16650 (epoch 1.096), train_loss = 2.60323215, grad/param norm = 6.9841e-01, time/batch = 0.6410s	
366/16650 (epoch 1.099), train_loss = 2.59946752, grad/param norm = 5.6021e-01, time/batch = 0.6392s	
367/16650 (epoch 1.102), train_loss = 2.55748005, grad/param norm = 5.5111e-01, time/batch = 0.6510s	
368/16650 (epoch 1.105), train_loss = 2.63007857, grad/param norm = 6.1303e-01, time/batch = 0.6524s	
369/16650 (epoch 1.108), train_loss = 2.78881656, grad/param norm = 6.4561e-01, time/batch = 0.6745s	
370/16650 (epoch 1.111), train_loss = 2.55131603, grad/param norm = 5.1548e-01, time/batch = 0.6661s	
371/16650 (epoch 1.114), train_loss = 2.69696396, grad/param norm = 4.5392e-01, time/batch = 0.6695s	
372/16650 (epoch 1.117), train_loss = 2.48177511, grad/param norm = 3.6360e-01, time/batch = 0.6492s	
373/16650 (epoch 1.120), train_loss = 2.56004515, grad/param norm = 3.5488e-01, time/batch = 0.6514s	
374/16650 (epoch 1.123), train_loss = 2.49809139, grad/param norm = 5.4351e-01, time/batch = 0.6444s	
375/16650 (epoch 1.126), train_loss = 2.59675404, grad/param norm = 6.2813e-01, time/batch = 0.6359s	
376/16650 (epoch 1.129), train_loss = 2.57947961, grad/param norm = 4.4865e-01, time/batch = 0.6377s	
377/16650 (epoch 1.132), train_loss = 2.74517608, grad/param norm = 3.8946e-01, time/batch = 0.6386s	
378/16650 (epoch 1.135), train_loss = 2.49938982, grad/param norm = 4.6609e-01, time/batch = 0.6480s	
379/16650 (epoch 1.138), train_loss = 2.63813330, grad/param norm = 5.1266e-01, time/batch = 0.6445s	
380/16650 (epoch 1.141), train_loss = 2.64337655, grad/param norm = 6.3086e-01, time/batch = 0.6407s	
381/16650 (epoch 1.144), train_loss = 2.63160086, grad/param norm = 4.3959e-01, time/batch = 0.6373s	
382/16650 (epoch 1.147), train_loss = 2.63535187, grad/param norm = 4.4109e-01, time/batch = 0.6399s	
383/16650 (epoch 1.150), train_loss = 2.63768887, grad/param norm = 3.6046e-01, time/batch = 0.6444s	
384/16650 (epoch 1.153), train_loss = 2.51372145, grad/param norm = 2.8991e-01, time/batch = 0.6339s	
385/16650 (epoch 1.156), train_loss = 2.41875469, grad/param norm = 3.0768e-01, time/batch = 0.6356s	
386/16650 (epoch 1.159), train_loss = 2.63134239, grad/param norm = 3.3886e-01, time/batch = 0.6355s	
387/16650 (epoch 1.162), train_loss = 2.49248960, grad/param norm = 4.3846e-01, time/batch = 0.6368s	
388/16650 (epoch 1.165), train_loss = 2.46312674, grad/param norm = 5.2242e-01, time/batch = 0.6438s	
389/16650 (epoch 1.168), train_loss = 2.32168753, grad/param norm = 4.9345e-01, time/batch = 0.6511s	
390/16650 (epoch 1.171), train_loss = 2.55466004, grad/param norm = 3.7389e-01, time/batch = 0.6532s	
391/16650 (epoch 1.174), train_loss = 2.45479388, grad/param norm = 3.2086e-01, time/batch = 0.6487s	
392/16650 (epoch 1.177), train_loss = 2.57715150, grad/param norm = 4.4385e-01, time/batch = 0.6458s	
393/16650 (epoch 1.180), train_loss = 2.64354552, grad/param norm = 4.2676e-01, time/batch = 0.6460s	
394/16650 (epoch 1.183), train_loss = 2.61228619, grad/param norm = 4.0138e-01, time/batch = 0.6412s	
395/16650 (epoch 1.186), train_loss = 2.62508321, grad/param norm = 3.7046e-01, time/batch = 0.6422s	
396/16650 (epoch 1.189), train_loss = 2.50946682, grad/param norm = 3.5545e-01, time/batch = 0.6460s	
397/16650 (epoch 1.192), train_loss = 2.46765846, grad/param norm = 5.8576e-01, time/batch = 0.6439s	
398/16650 (epoch 1.195), train_loss = 2.54549200, grad/param norm = 7.9032e-01, time/batch = 0.6390s	
399/16650 (epoch 1.198), train_loss = 2.44359254, grad/param norm = 6.2650e-01, time/batch = 0.6318s	
400/16650 (epoch 1.201), train_loss = 2.59549431, grad/param norm = 5.8337e-01, time/batch = 0.6328s	
401/16650 (epoch 1.204), train_loss = 2.58983749, grad/param norm = 6.7689e-01, time/batch = 0.6362s	
402/16650 (epoch 1.207), train_loss = 2.57782222, grad/param norm = 6.4515e-01, time/batch = 0.6328s	
403/16650 (epoch 1.210), train_loss = 2.50395252, grad/param norm = 5.6932e-01, time/batch = 0.6342s	
404/16650 (epoch 1.213), train_loss = 2.47499675, grad/param norm = 3.5698e-01, time/batch = 0.6357s	
405/16650 (epoch 1.216), train_loss = 2.51169892, grad/param norm = 2.8139e-01, time/batch = 0.6325s	
406/16650 (epoch 1.219), train_loss = 2.50003602, grad/param norm = 3.7086e-01, time/batch = 0.6377s	
407/16650 (epoch 1.222), train_loss = 2.55601554, grad/param norm = 4.1381e-01, time/batch = 0.6352s	
408/16650 (epoch 1.225), train_loss = 2.51642915, grad/param norm = 4.5342e-01, time/batch = 0.6343s	
409/16650 (epoch 1.228), train_loss = 2.48091857, grad/param norm = 3.8457e-01, time/batch = 0.6331s	
410/16650 (epoch 1.231), train_loss = 2.52256581, grad/param norm = 4.1137e-01, time/batch = 0.6339s	
411/16650 (epoch 1.234), train_loss = 2.56957068, grad/param norm = 3.6884e-01, time/batch = 0.6345s	
412/16650 (epoch 1.237), train_loss = 2.42090684, grad/param norm = 3.7529e-01, time/batch = 0.6341s	
413/16650 (epoch 1.240), train_loss = 2.54689653, grad/param norm = 4.1658e-01, time/batch = 0.6392s	
414/16650 (epoch 1.243), train_loss = 2.51211736, grad/param norm = 4.8951e-01, time/batch = 0.6354s	
415/16650 (epoch 1.246), train_loss = 2.69388471, grad/param norm = 5.5518e-01, time/batch = 0.6349s	
416/16650 (epoch 1.249), train_loss = 2.45359814, grad/param norm = 5.0213e-01, time/batch = 0.6439s	
417/16650 (epoch 1.252), train_loss = 2.52064909, grad/param norm = 4.6230e-01, time/batch = 0.6428s	
418/16650 (epoch 1.255), train_loss = 2.50782358, grad/param norm = 5.0520e-01, time/batch = 0.6415s	
419/16650 (epoch 1.258), train_loss = 2.58061475, grad/param norm = 4.7126e-01, time/batch = 0.6362s	
420/16650 (epoch 1.261), train_loss = 2.59746489, grad/param norm = 5.0850e-01, time/batch = 0.6480s	
421/16650 (epoch 1.264), train_loss = 2.57062516, grad/param norm = 4.8447e-01, time/batch = 0.6543s	
422/16650 (epoch 1.267), train_loss = 2.47109222, grad/param norm = 3.8454e-01, time/batch = 0.6494s	
423/16650 (epoch 1.270), train_loss = 2.29983152, grad/param norm = 3.1793e-01, time/batch = 0.6491s	
424/16650 (epoch 1.273), train_loss = 2.52373347, grad/param norm = 4.2973e-01, time/batch = 0.6446s	
425/16650 (epoch 1.276), train_loss = 2.49080683, grad/param norm = 3.9952e-01, time/batch = 0.6497s	
426/16650 (epoch 1.279), train_loss = 2.47056192, grad/param norm = 3.7751e-01, time/batch = 0.6692s	
427/16650 (epoch 1.282), train_loss = 2.44860838, grad/param norm = 3.5678e-01, time/batch = 0.6506s	
428/16650 (epoch 1.285), train_loss = 2.41969723, grad/param norm = 3.6499e-01, time/batch = 0.6527s	
429/16650 (epoch 1.288), train_loss = 2.47538882, grad/param norm = 6.0472e-01, time/batch = 0.6387s	
430/16650 (epoch 1.291), train_loss = 2.53931870, grad/param norm = 7.9915e-01, time/batch = 0.6363s	
431/16650 (epoch 1.294), train_loss = 2.44716022, grad/param norm = 6.5001e-01, time/batch = 0.6453s	
432/16650 (epoch 1.297), train_loss = 2.31890805, grad/param norm = 4.3822e-01, time/batch = 0.6359s	
433/16650 (epoch 1.300), train_loss = 2.40208510, grad/param norm = 4.2403e-01, time/batch = 0.6366s	
434/16650 (epoch 1.303), train_loss = 2.32324831, grad/param norm = 6.1858e-01, time/batch = 0.6381s	
435/16650 (epoch 1.306), train_loss = 2.63772130, grad/param norm = 6.0406e-01, time/batch = 0.6410s	
436/16650 (epoch 1.309), train_loss = 2.61755358, grad/param norm = 3.7572e-01, time/batch = 0.6431s	
437/16650 (epoch 1.312), train_loss = 2.46010702, grad/param norm = 4.2471e-01, time/batch = 0.6396s	
438/16650 (epoch 1.315), train_loss = 2.34760847, grad/param norm = 3.8111e-01, time/batch = 0.6350s	
439/16650 (epoch 1.318), train_loss = 2.49097345, grad/param norm = 3.5113e-01, time/batch = 0.6331s	
440/16650 (epoch 1.321), train_loss = 2.62446991, grad/param norm = 4.1539e-01, time/batch = 0.6314s	
441/16650 (epoch 1.324), train_loss = 2.64179717, grad/param norm = 6.0742e-01, time/batch = 0.6361s	
442/16650 (epoch 1.327), train_loss = 2.50676583, grad/param norm = 7.1870e-01, time/batch = 0.6417s	
443/16650 (epoch 1.330), train_loss = 2.55528725, grad/param norm = 6.1091e-01, time/batch = 0.6373s	
444/16650 (epoch 1.333), train_loss = 2.56792407, grad/param norm = 4.4291e-01, time/batch = 0.6389s	
445/16650 (epoch 1.336), train_loss = 2.25894017, grad/param norm = 4.0335e-01, time/batch = 0.6415s	
446/16650 (epoch 1.339), train_loss = 2.47159030, grad/param norm = 4.5894e-01, time/batch = 0.6368s	
447/16650 (epoch 1.342), train_loss = 2.46608338, grad/param norm = 3.2298e-01, time/batch = 0.6397s	
448/16650 (epoch 1.345), train_loss = 2.38962172, grad/param norm = 3.9367e-01, time/batch = 0.6349s	
449/16650 (epoch 1.348), train_loss = 2.44741988, grad/param norm = 5.1162e-01, time/batch = 0.6339s	
450/16650 (epoch 1.351), train_loss = 2.54950031, grad/param norm = 5.2476e-01, time/batch = 0.6336s	
451/16650 (epoch 1.354), train_loss = 2.52744129, grad/param norm = 3.6752e-01, time/batch = 0.6371s	
452/16650 (epoch 1.357), train_loss = 2.48970991, grad/param norm = 3.0996e-01, time/batch = 0.6355s	
453/16650 (epoch 1.360), train_loss = 2.46657055, grad/param norm = 3.7432e-01, time/batch = 0.6342s	
454/16650 (epoch 1.363), train_loss = 2.55713346, grad/param norm = 4.5634e-01, time/batch = 0.6369s	
455/16650 (epoch 1.366), train_loss = 2.49366997, grad/param norm = 3.8488e-01, time/batch = 0.6349s	
456/16650 (epoch 1.369), train_loss = 2.51242047, grad/param norm = 3.3098e-01, time/batch = 0.6351s	
457/16650 (epoch 1.372), train_loss = 2.43147753, grad/param norm = 4.3017e-01, time/batch = 0.6330s	
458/16650 (epoch 1.375), train_loss = 2.27453613, grad/param norm = 3.2047e-01, time/batch = 0.6455s	
459/16650 (epoch 1.378), train_loss = 2.27073054, grad/param norm = 3.8957e-01, time/batch = 0.6470s	
460/16650 (epoch 1.381), train_loss = 2.64823070, grad/param norm = 5.4165e-01, time/batch = 0.6527s	
461/16650 (epoch 1.384), train_loss = 2.36428313, grad/param norm = 3.4024e-01, time/batch = 0.6721s	
462/16650 (epoch 1.387), train_loss = 2.44704732, grad/param norm = 4.4626e-01, time/batch = 0.6780s	
463/16650 (epoch 1.390), train_loss = 2.48350971, grad/param norm = 4.3087e-01, time/batch = 0.6570s	
464/16650 (epoch 1.393), train_loss = 2.27585187, grad/param norm = 3.5279e-01, time/batch = 0.6526s	
465/16650 (epoch 1.396), train_loss = 2.59255717, grad/param norm = 3.0912e-01, time/batch = 0.6435s	
466/16650 (epoch 1.399), train_loss = 2.52069631, grad/param norm = 3.4970e-01, time/batch = 0.6380s	
467/16650 (epoch 1.402), train_loss = 2.38073532, grad/param norm = 4.1017e-01, time/batch = 0.6407s	
468/16650 (epoch 1.405), train_loss = 2.39327911, grad/param norm = 3.7766e-01, time/batch = 0.6350s	
469/16650 (epoch 1.408), train_loss = 2.44148329, grad/param norm = 3.5792e-01, time/batch = 0.6378s	
470/16650 (epoch 1.411), train_loss = 2.40605681, grad/param norm = 4.9624e-01, time/batch = 0.6403s	
471/16650 (epoch 1.414), train_loss = 2.32778972, grad/param norm = 6.4059e-01, time/batch = 0.6414s	
472/16650 (epoch 1.417), train_loss = 2.41814121, grad/param norm = 7.9012e-01, time/batch = 0.6383s	
473/16650 (epoch 1.420), train_loss = 2.37780705, grad/param norm = 6.2675e-01, time/batch = 0.6368s	
474/16650 (epoch 1.423), train_loss = 2.19887392, grad/param norm = 4.2151e-01, time/batch = 0.6440s	
475/16650 (epoch 1.426), train_loss = 2.44497616, grad/param norm = 3.1516e-01, time/batch = 0.6415s	
476/16650 (epoch 1.429), train_loss = 2.41798733, grad/param norm = 3.1852e-01, time/batch = 0.6381s	
477/16650 (epoch 1.432), train_loss = 2.33977639, grad/param norm = 3.0583e-01, time/batch = 0.6365s	
478/16650 (epoch 1.435), train_loss = 2.60925742, grad/param norm = 4.6264e-01, time/batch = 0.6331s	
479/16650 (epoch 1.438), train_loss = 2.48222349, grad/param norm = 4.0181e-01, time/batch = 0.6331s	
480/16650 (epoch 1.441), train_loss = 2.49775162, grad/param norm = 2.9682e-01, time/batch = 0.6369s	
481/16650 (epoch 1.444), train_loss = 2.40303793, grad/param norm = 2.8990e-01, time/batch = 0.6386s	
482/16650 (epoch 1.447), train_loss = 2.41948008, grad/param norm = 3.5220e-01, time/batch = 0.6354s	
483/16650 (epoch 1.450), train_loss = 2.39697182, grad/param norm = 3.9469e-01, time/batch = 0.6342s	
484/16650 (epoch 1.453), train_loss = 2.48546428, grad/param norm = 5.4985e-01, time/batch = 0.6317s	
485/16650 (epoch 1.456), train_loss = 2.38156603, grad/param norm = 6.2172e-01, time/batch = 0.6321s	
486/16650 (epoch 1.459), train_loss = 2.43566712, grad/param norm = 5.0497e-01, time/batch = 0.6315s	
487/16650 (epoch 1.462), train_loss = 2.51985064, grad/param norm = 3.7414e-01, time/batch = 0.6322s	
488/16650 (epoch 1.465), train_loss = 2.33561039, grad/param norm = 3.5793e-01, time/batch = 0.6337s	
489/16650 (epoch 1.468), train_loss = 2.09812892, grad/param norm = 3.7628e-01, time/batch = 0.6381s	
490/16650 (epoch 1.471), train_loss = 2.26366739, grad/param norm = 3.6614e-01, time/batch = 0.6368s	
491/16650 (epoch 1.474), train_loss = 2.20870103, grad/param norm = 4.0325e-01, time/batch = 0.6402s	
492/16650 (epoch 1.477), train_loss = 2.34273043, grad/param norm = 4.2326e-01, time/batch = 0.6344s	
493/16650 (epoch 1.480), train_loss = 2.48323896, grad/param norm = 4.1836e-01, time/batch = 0.6356s	
494/16650 (epoch 1.483), train_loss = 2.50653828, grad/param norm = 3.3440e-01, time/batch = 0.6338s	
495/16650 (epoch 1.486), train_loss = 2.21675635, grad/param norm = 4.5021e-01, time/batch = 0.6338s	
496/16650 (epoch 1.489), train_loss = 2.42966699, grad/param norm = 6.0127e-01, time/batch = 0.6429s	
497/16650 (epoch 1.492), train_loss = 2.38653188, grad/param norm = 5.7465e-01, time/batch = 0.6459s	
498/16650 (epoch 1.495), train_loss = 2.26814433, grad/param norm = 3.4718e-01, time/batch = 0.6448s	
499/16650 (epoch 1.498), train_loss = 2.55418905, grad/param norm = 3.4714e-01, time/batch = 0.6340s	
500/16650 (epoch 1.502), train_loss = 2.57201474, grad/param norm = 3.5030e-01, time/batch = 0.6344s	
501/16650 (epoch 1.505), train_loss = 2.44470305, grad/param norm = 3.3444e-01, time/batch = 0.6354s	
502/16650 (epoch 1.508), train_loss = 2.37801230, grad/param norm = 3.5913e-01, time/batch = 0.6357s	
503/16650 (epoch 1.511), train_loss = 2.53649348, grad/param norm = 4.8232e-01, time/batch = 0.6344s	
504/16650 (epoch 1.514), train_loss = 2.42280986, grad/param norm = 4.4919e-01, time/batch = 0.6346s	
505/16650 (epoch 1.517), train_loss = 2.35060418, grad/param norm = 3.8865e-01, time/batch = 0.6384s	
506/16650 (epoch 1.520), train_loss = 2.45453423, grad/param norm = 3.2760e-01, time/batch = 0.6391s	
507/16650 (epoch 1.523), train_loss = 2.47010000, grad/param norm = 3.5362e-01, time/batch = 0.6441s	
508/16650 (epoch 1.526), train_loss = 2.40658967, grad/param norm = 3.7859e-01, time/batch = 0.6370s	
509/16650 (epoch 1.529), train_loss = 2.48259245, grad/param norm = 3.1974e-01, time/batch = 0.6347s	
510/16650 (epoch 1.532), train_loss = 2.38988525, grad/param norm = 3.5056e-01, time/batch = 0.6364s	
511/16650 (epoch 1.535), train_loss = 2.28927278, grad/param norm = 4.1128e-01, time/batch = 0.6364s	
512/16650 (epoch 1.538), train_loss = 2.45888584, grad/param norm = 4.1627e-01, time/batch = 0.6396s	
513/16650 (epoch 1.541), train_loss = 2.47167265, grad/param norm = 5.7607e-01, time/batch = 0.6365s	
514/16650 (epoch 1.544), train_loss = 2.58735982, grad/param norm = 6.9390e-01, time/batch = 0.6434s	
515/16650 (epoch 1.547), train_loss = 2.27399422, grad/param norm = 6.7012e-01, time/batch = 0.6378s	
516/16650 (epoch 1.550), train_loss = 2.37301243, grad/param norm = 5.0333e-01, time/batch = 0.6361s	
517/16650 (epoch 1.553), train_loss = 2.50253156, grad/param norm = 4.3550e-01, time/batch = 0.6338s	
518/16650 (epoch 1.556), train_loss = 2.25437842, grad/param norm = 3.7471e-01, time/batch = 0.6382s	
519/16650 (epoch 1.559), train_loss = 2.27924718, grad/param norm = 3.5270e-01, time/batch = 0.6368s	
520/16650 (epoch 1.562), train_loss = 2.40283529, grad/param norm = 3.2013e-01, time/batch = 0.6350s	
521/16650 (epoch 1.565), train_loss = 2.20898713, grad/param norm = 3.5347e-01, time/batch = 0.6383s	
522/16650 (epoch 1.568), train_loss = 2.26812166, grad/param norm = 4.0660e-01, time/batch = 0.6460s	
523/16650 (epoch 1.571), train_loss = 2.33670346, grad/param norm = 4.0691e-01, time/batch = 0.6377s	
524/16650 (epoch 1.574), train_loss = 2.35022369, grad/param norm = 3.9653e-01, time/batch = 0.6349s	
525/16650 (epoch 1.577), train_loss = 2.33448233, grad/param norm = 3.3064e-01, time/batch = 0.6343s	
526/16650 (epoch 1.580), train_loss = 2.36553853, grad/param norm = 3.2512e-01, time/batch = 0.6347s	
527/16650 (epoch 1.583), train_loss = 2.26835522, grad/param norm = 3.0632e-01, time/batch = 0.6378s	
528/16650 (epoch 1.586), train_loss = 2.42896707, grad/param norm = 3.3012e-01, time/batch = 0.6421s	
529/16650 (epoch 1.589), train_loss = 2.22674652, grad/param norm = 4.2624e-01, time/batch = 0.6343s	
530/16650 (epoch 1.592), train_loss = 2.37077066, grad/param norm = 5.6200e-01, time/batch = 0.6381s	
531/16650 (epoch 1.595), train_loss = 2.24188526, grad/param norm = 4.6463e-01, time/batch = 0.6396s	
532/16650 (epoch 1.598), train_loss = 2.27954563, grad/param norm = 4.0688e-01, time/batch = 0.6393s	
533/16650 (epoch 1.601), train_loss = 2.37642821, grad/param norm = 3.7758e-01, time/batch = 0.6415s	
534/16650 (epoch 1.604), train_loss = 2.36224268, grad/param norm = 3.8584e-01, time/batch = 0.6391s	
535/16650 (epoch 1.607), train_loss = 2.37765285, grad/param norm = 4.1391e-01, time/batch = 0.6358s	
536/16650 (epoch 1.610), train_loss = 2.41039521, grad/param norm = 4.1698e-01, time/batch = 0.6341s	
537/16650 (epoch 1.613), train_loss = 2.49877362, grad/param norm = 3.3252e-01, time/batch = 0.6335s	
538/16650 (epoch 1.616), train_loss = 2.51449079, grad/param norm = 3.5113e-01, time/batch = 0.6377s	
539/16650 (epoch 1.619), train_loss = 2.38869791, grad/param norm = 3.0368e-01, time/batch = 0.6370s	
540/16650 (epoch 1.622), train_loss = 2.23314301, grad/param norm = 3.7562e-01, time/batch = 0.6352s	
541/16650 (epoch 1.625), train_loss = 2.40143116, grad/param norm = 3.5913e-01, time/batch = 0.6347s	
542/16650 (epoch 1.628), train_loss = 2.20156865, grad/param norm = 3.1292e-01, time/batch = 0.6361s	
543/16650 (epoch 1.631), train_loss = 2.40028111, grad/param norm = 3.5568e-01, time/batch = 0.6416s	
544/16650 (epoch 1.634), train_loss = 2.25695469, grad/param norm = 4.0480e-01, time/batch = 0.6400s	
545/16650 (epoch 1.637), train_loss = 2.42063008, grad/param norm = 4.4769e-01, time/batch = 0.6388s	
546/16650 (epoch 1.640), train_loss = 2.37063576, grad/param norm = 4.6412e-01, time/batch = 0.6348s	
547/16650 (epoch 1.643), train_loss = 2.43674062, grad/param norm = 5.0603e-01, time/batch = 0.6377s	
548/16650 (epoch 1.646), train_loss = 2.60454234, grad/param norm = 4.0061e-01, time/batch = 0.6357s	
549/16650 (epoch 1.649), train_loss = 2.35897337, grad/param norm = 3.5228e-01, time/batch = 0.6342s	
550/16650 (epoch 1.652), train_loss = 2.47026312, grad/param norm = 4.0965e-01, time/batch = 0.6336s	
551/16650 (epoch 1.655), train_loss = 2.51644288, grad/param norm = 3.6206e-01, time/batch = 0.6414s	
552/16650 (epoch 1.658), train_loss = 2.27993046, grad/param norm = 3.4374e-01, time/batch = 0.6479s	
553/16650 (epoch 1.661), train_loss = 2.43187871, grad/param norm = 2.9197e-01, time/batch = 0.6456s	
554/16650 (epoch 1.664), train_loss = 2.42132588, grad/param norm = 3.8422e-01, time/batch = 0.6493s	
555/16650 (epoch 1.667), train_loss = 2.49523104, grad/param norm = 5.1569e-01, time/batch = 0.6671s	
556/16650 (epoch 1.670), train_loss = 2.29525643, grad/param norm = 6.5237e-01, time/batch = 0.6559s	
557/16650 (epoch 1.673), train_loss = 2.21221272, grad/param norm = 5.2658e-01, time/batch = 0.6381s	
558/16650 (epoch 1.676), train_loss = 2.25982581, grad/param norm = 3.1525e-01, time/batch = 0.6378s	
559/16650 (epoch 1.679), train_loss = 2.27841379, grad/param norm = 3.2197e-01, time/batch = 0.6400s	
560/16650 (epoch 1.682), train_loss = 2.45018824, grad/param norm = 3.7280e-01, time/batch = 0.6353s	
561/16650 (epoch 1.685), train_loss = 2.29309013, grad/param norm = 3.2257e-01, time/batch = 0.6451s	
562/16650 (epoch 1.688), train_loss = 2.38455216, grad/param norm = 3.6858e-01, time/batch = 0.6359s	
563/16650 (epoch 1.691), train_loss = 2.36336902, grad/param norm = 4.6351e-01, time/batch = 0.6383s	
564/16650 (epoch 1.694), train_loss = 2.29264177, grad/param norm = 3.4075e-01, time/batch = 0.6387s	
565/16650 (epoch 1.697), train_loss = 2.16208269, grad/param norm = 4.0498e-01, time/batch = 0.6498s	
566/16650 (epoch 1.700), train_loss = 2.40841194, grad/param norm = 4.3167e-01, time/batch = 0.6404s	
567/16650 (epoch 1.703), train_loss = 2.27630560, grad/param norm = 3.8867e-01, time/batch = 0.6349s	
568/16650 (epoch 1.706), train_loss = 2.35984037, grad/param norm = 3.4925e-01, time/batch = 0.6360s	
569/16650 (epoch 1.709), train_loss = 2.35552867, grad/param norm = 3.7374e-01, time/batch = 0.6375s	
570/16650 (epoch 1.712), train_loss = 2.21499920, grad/param norm = 3.2502e-01, time/batch = 0.6362s	
571/16650 (epoch 1.715), train_loss = 2.36104809, grad/param norm = 3.5762e-01, time/batch = 0.6389s	
572/16650 (epoch 1.718), train_loss = 2.39275834, grad/param norm = 4.0983e-01, time/batch = 0.6431s	
573/16650 (epoch 1.721), train_loss = 2.34628557, grad/param norm = 3.4922e-01, time/batch = 0.6402s	
574/16650 (epoch 1.724), train_loss = 2.36385445, grad/param norm = 4.0429e-01, time/batch = 0.6364s	
575/16650 (epoch 1.727), train_loss = 2.25204564, grad/param norm = 4.4942e-01, time/batch = 0.6367s	
576/16650 (epoch 1.730), train_loss = 2.25470725, grad/param norm = 5.3049e-01, time/batch = 0.6427s	
577/16650 (epoch 1.733), train_loss = 2.42595783, grad/param norm = 5.2343e-01, time/batch = 0.6375s	
578/16650 (epoch 1.736), train_loss = 2.30809887, grad/param norm = 3.5054e-01, time/batch = 0.6342s	
579/16650 (epoch 1.739), train_loss = 2.25404918, grad/param norm = 3.5246e-01, time/batch = 0.6359s	
580/16650 (epoch 1.742), train_loss = 2.35846962, grad/param norm = 4.9479e-01, time/batch = 0.6363s	
581/16650 (epoch 1.745), train_loss = 2.12753425, grad/param norm = 4.7686e-01, time/batch = 0.6390s	
582/16650 (epoch 1.748), train_loss = 2.19658051, grad/param norm = 3.6708e-01, time/batch = 0.6385s	
583/16650 (epoch 1.751), train_loss = 2.47878619, grad/param norm = 3.2282e-01, time/batch = 0.6362s	
584/16650 (epoch 1.754), train_loss = 2.43417532, grad/param norm = 3.4619e-01, time/batch = 0.6423s	
585/16650 (epoch 1.757), train_loss = 2.33108192, grad/param norm = 3.6356e-01, time/batch = 0.6431s	
586/16650 (epoch 1.760), train_loss = 2.39066191, grad/param norm = 3.2081e-01, time/batch = 0.6384s	
587/16650 (epoch 1.763), train_loss = 2.14060114, grad/param norm = 3.6622e-01, time/batch = 0.6343s	
588/16650 (epoch 1.766), train_loss = 2.35920879, grad/param norm = 3.9761e-01, time/batch = 0.6391s	
589/16650 (epoch 1.769), train_loss = 2.24500511, grad/param norm = 3.4765e-01, time/batch = 0.6428s	
590/16650 (epoch 1.772), train_loss = 2.27761499, grad/param norm = 2.7770e-01, time/batch = 0.6435s	
591/16650 (epoch 1.775), train_loss = 2.30512125, grad/param norm = 3.6126e-01, time/batch = 0.6406s	
592/16650 (epoch 1.778), train_loss = 2.26179302, grad/param norm = 5.1059e-01, time/batch = 0.6456s	
593/16650 (epoch 1.781), train_loss = 2.33841049, grad/param norm = 4.6563e-01, time/batch = 0.6453s	
594/16650 (epoch 1.784), train_loss = 2.37790857, grad/param norm = 4.3235e-01, time/batch = 0.6510s	
595/16650 (epoch 1.787), train_loss = 2.35822927, grad/param norm = 3.8120e-01, time/batch = 0.6395s	
596/16650 (epoch 1.790), train_loss = 2.19194866, grad/param norm = 3.2964e-01, time/batch = 0.6475s	
597/16650 (epoch 1.793), train_loss = 2.18740309, grad/param norm = 3.5508e-01, time/batch = 0.6419s	
598/16650 (epoch 1.796), train_loss = 2.51950353, grad/param norm = 4.8960e-01, time/batch = 0.6548s	
599/16650 (epoch 1.799), train_loss = 2.41164911, grad/param norm = 4.0631e-01, time/batch = 0.6553s	
600/16650 (epoch 1.802), train_loss = 2.26404158, grad/param norm = 3.7968e-01, time/batch = 0.6487s	
601/16650 (epoch 1.805), train_loss = 2.23745478, grad/param norm = 4.5881e-01, time/batch = 0.6443s	
602/16650 (epoch 1.808), train_loss = 2.34490032, grad/param norm = 4.2526e-01, time/batch = 0.6363s	
603/16650 (epoch 1.811), train_loss = 2.35506589, grad/param norm = 2.9546e-01, time/batch = 0.6428s	
604/16650 (epoch 1.814), train_loss = 2.20528134, grad/param norm = 2.7279e-01, time/batch = 0.6382s	
605/16650 (epoch 1.817), train_loss = 2.19559787, grad/param norm = 3.1736e-01, time/batch = 0.6384s	
606/16650 (epoch 1.820), train_loss = 2.31010751, grad/param norm = 3.5493e-01, time/batch = 0.6376s	
607/16650 (epoch 1.823), train_loss = 2.11225664, grad/param norm = 3.0366e-01, time/batch = 0.6334s	
608/16650 (epoch 1.826), train_loss = 2.23519854, grad/param norm = 3.4586e-01, time/batch = 0.6383s	
609/16650 (epoch 1.829), train_loss = 2.47555326, grad/param norm = 3.4740e-01, time/batch = 0.6348s	
610/16650 (epoch 1.832), train_loss = 2.38818495, grad/param norm = 3.1162e-01, time/batch = 0.6414s	
611/16650 (epoch 1.835), train_loss = 2.30976022, grad/param norm = 3.4601e-01, time/batch = 0.6468s	
612/16650 (epoch 1.838), train_loss = 2.18218368, grad/param norm = 3.7060e-01, time/batch = 0.6546s	
613/16650 (epoch 1.841), train_loss = 2.14843041, grad/param norm = 4.0674e-01, time/batch = 0.6610s	
614/16650 (epoch 1.844), train_loss = 2.22254005, grad/param norm = 3.6900e-01, time/batch = 0.6675s	
615/16650 (epoch 1.847), train_loss = 2.41898626, grad/param norm = 2.9716e-01, time/batch = 0.6618s	
616/16650 (epoch 1.850), train_loss = 2.27950210, grad/param norm = 3.3795e-01, time/batch = 0.6627s	
617/16650 (epoch 1.853), train_loss = 2.28885194, grad/param norm = 3.1761e-01, time/batch = 0.6614s	
618/16650 (epoch 1.856), train_loss = 2.18669215, grad/param norm = 2.9603e-01, time/batch = 0.6501s	
619/16650 (epoch 1.859), train_loss = 2.16235042, grad/param norm = 2.9605e-01, time/batch = 0.6504s	
620/16650 (epoch 1.862), train_loss = 2.25449535, grad/param norm = 3.1908e-01, time/batch = 0.6439s	
621/16650 (epoch 1.865), train_loss = 2.02165475, grad/param norm = 3.5272e-01, time/batch = 0.6366s	
622/16650 (epoch 1.868), train_loss = 2.18579001, grad/param norm = 3.8428e-01, time/batch = 0.6398s	
623/16650 (epoch 1.871), train_loss = 2.22554373, grad/param norm = 4.0012e-01, time/batch = 0.6397s	
624/16650 (epoch 1.874), train_loss = 2.29171946, grad/param norm = 3.6018e-01, time/batch = 0.6349s	
625/16650 (epoch 1.877), train_loss = 2.11499684, grad/param norm = 3.4957e-01, time/batch = 0.6316s	
626/16650 (epoch 1.880), train_loss = 2.17444429, grad/param norm = 4.1684e-01, time/batch = 0.6313s	
627/16650 (epoch 1.883), train_loss = 2.29004324, grad/param norm = 4.3632e-01, time/batch = 0.6320s	
628/16650 (epoch 1.886), train_loss = 2.28925911, grad/param norm = 3.5746e-01, time/batch = 0.6332s	
629/16650 (epoch 1.889), train_loss = 2.17854142, grad/param norm = 3.7820e-01, time/batch = 0.6378s	
630/16650 (epoch 1.892), train_loss = 2.15756836, grad/param norm = 3.5861e-01, time/batch = 0.6527s	
631/16650 (epoch 1.895), train_loss = 2.35483976, grad/param norm = 3.9848e-01, time/batch = 0.6494s	
632/16650 (epoch 1.898), train_loss = 2.20999132, grad/param norm = 4.3884e-01, time/batch = 0.6405s	
633/16650 (epoch 1.901), train_loss = 2.07950750, grad/param norm = 3.6874e-01, time/batch = 0.6325s	
634/16650 (epoch 1.904), train_loss = 2.14116003, grad/param norm = 3.1776e-01, time/batch = 0.6313s	
635/16650 (epoch 1.907), train_loss = 2.23824790, grad/param norm = 3.2923e-01, time/batch = 0.6309s	
636/16650 (epoch 1.910), train_loss = 2.34139878, grad/param norm = 3.1198e-01, time/batch = 0.6318s	
637/16650 (epoch 1.913), train_loss = 2.20921282, grad/param norm = 3.9431e-01, time/batch = 0.6330s	
638/16650 (epoch 1.916), train_loss = 2.31655853, grad/param norm = 5.0615e-01, time/batch = 0.6340s	
639/16650 (epoch 1.919), train_loss = 2.39680825, grad/param norm = 4.5502e-01, time/batch = 0.6358s	
640/16650 (epoch 1.922), train_loss = 2.40332180, grad/param norm = 3.6828e-01, time/batch = 0.6325s	
641/16650 (epoch 1.925), train_loss = 2.33174203, grad/param norm = 3.2475e-01, time/batch = 0.6339s	
642/16650 (epoch 1.928), train_loss = 2.21147622, grad/param norm = 2.6813e-01, time/batch = 0.6321s	
643/16650 (epoch 1.931), train_loss = 2.24695416, grad/param norm = 3.3387e-01, time/batch = 0.6325s	
644/16650 (epoch 1.934), train_loss = 2.23327732, grad/param norm = 3.0328e-01, time/batch = 0.6330s	
645/16650 (epoch 1.937), train_loss = 2.23937164, grad/param norm = 3.4313e-01, time/batch = 0.6433s	
646/16650 (epoch 1.940), train_loss = 2.20099121, grad/param norm = 3.6656e-01, time/batch = 0.6565s	
647/16650 (epoch 1.943), train_loss = 2.25045821, grad/param norm = 3.8401e-01, time/batch = 0.6577s	
648/16650 (epoch 1.946), train_loss = 2.17545766, grad/param norm = 4.6284e-01, time/batch = 0.6675s	
649/16650 (epoch 1.949), train_loss = 2.27791226, grad/param norm = 3.5502e-01, time/batch = 0.6606s	
650/16650 (epoch 1.952), train_loss = 1.97826684, grad/param norm = 3.8026e-01, time/batch = 0.6491s	
651/16650 (epoch 1.955), train_loss = 2.32731308, grad/param norm = 3.4996e-01, time/batch = 0.6384s	
652/16650 (epoch 1.958), train_loss = 2.30065074, grad/param norm = 3.5333e-01, time/batch = 0.6386s	
653/16650 (epoch 1.961), train_loss = 2.13127307, grad/param norm = 3.5623e-01, time/batch = 0.6387s	
654/16650 (epoch 1.964), train_loss = 2.18734498, grad/param norm = 4.0249e-01, time/batch = 0.6343s	
655/16650 (epoch 1.967), train_loss = 2.35599476, grad/param norm = 3.1401e-01, time/batch = 0.6372s	
656/16650 (epoch 1.970), train_loss = 2.09510371, grad/param norm = 2.8619e-01, time/batch = 0.6426s	
657/16650 (epoch 1.973), train_loss = 2.21622493, grad/param norm = 3.8865e-01, time/batch = 0.6420s	
658/16650 (epoch 1.976), train_loss = 2.12672888, grad/param norm = 3.5400e-01, time/batch = 0.6341s	
659/16650 (epoch 1.979), train_loss = 2.32210992, grad/param norm = 3.0013e-01, time/batch = 0.6322s	
660/16650 (epoch 1.982), train_loss = 2.13693387, grad/param norm = 2.9538e-01, time/batch = 0.6319s	
661/16650 (epoch 1.985), train_loss = 2.09235589, grad/param norm = 3.7144e-01, time/batch = 0.6358s	
662/16650 (epoch 1.988), train_loss = 2.51449782, grad/param norm = 3.2656e-01, time/batch = 0.6352s	
663/16650 (epoch 1.991), train_loss = 2.20487459, grad/param norm = 3.6964e-01, time/batch = 0.6382s	
664/16650 (epoch 1.994), train_loss = 2.27229060, grad/param norm = 3.7221e-01, time/batch = 0.6376s	
665/16650 (epoch 1.997), train_loss = 2.24515220, grad/param norm = 3.1636e-01, time/batch = 0.6332s	
666/16650 (epoch 2.000), train_loss = 2.29100932, grad/param norm = 3.3805e-01, time/batch = 0.6330s	
667/16650 (epoch 2.003), train_loss = 2.28165133, grad/param norm = 3.2195e-01, time/batch = 0.6330s	
668/16650 (epoch 2.006), train_loss = 2.32537806, grad/param norm = 3.8202e-01, time/batch = 0.6307s	
669/16650 (epoch 2.009), train_loss = 2.44417981, grad/param norm = 4.9693e-01, time/batch = 0.6356s	
670/16650 (epoch 2.012), train_loss = 2.47003852, grad/param norm = 3.5591e-01, time/batch = 0.6341s	
671/16650 (epoch 2.015), train_loss = 2.37775254, grad/param norm = 3.2775e-01, time/batch = 0.6377s	
672/16650 (epoch 2.018), train_loss = 2.10312972, grad/param norm = 3.2109e-01, time/batch = 0.6494s	
673/16650 (epoch 2.021), train_loss = 2.37323125, grad/param norm = 3.6067e-01, time/batch = 0.6425s	
674/16650 (epoch 2.024), train_loss = 2.17015811, grad/param norm = 3.2918e-01, time/batch = 0.6378s	
675/16650 (epoch 2.027), train_loss = 2.21160363, grad/param norm = 3.0125e-01, time/batch = 0.6344s	
676/16650 (epoch 2.030), train_loss = 2.21294984, grad/param norm = 3.3225e-01, time/batch = 0.6348s	
677/16650 (epoch 2.033), train_loss = 2.15662320, grad/param norm = 3.9722e-01, time/batch = 0.6346s	
678/16650 (epoch 2.036), train_loss = 2.21449391, grad/param norm = 3.6782e-01, time/batch = 0.6350s	
679/16650 (epoch 2.039), train_loss = 2.27453425, grad/param norm = 3.3047e-01, time/batch = 0.6405s	
680/16650 (epoch 2.042), train_loss = 2.31789926, grad/param norm = 3.3770e-01, time/batch = 0.6364s	
681/16650 (epoch 2.045), train_loss = 2.13939938, grad/param norm = 3.4491e-01, time/batch = 0.6363s	
682/16650 (epoch 2.048), train_loss = 2.17907562, grad/param norm = 3.3302e-01, time/batch = 0.6334s	
683/16650 (epoch 2.051), train_loss = 2.21427796, grad/param norm = 3.6631e-01, time/batch = 0.6335s	
684/16650 (epoch 2.054), train_loss = 2.19371103, grad/param norm = 3.6519e-01, time/batch = 0.6333s	
685/16650 (epoch 2.057), train_loss = 2.19813252, grad/param norm = 3.0882e-01, time/batch = 0.6336s	
686/16650 (epoch 2.060), train_loss = 2.11500961, grad/param norm = 3.3441e-01, time/batch = 0.6426s	
687/16650 (epoch 2.063), train_loss = 2.12681301, grad/param norm = 3.2886e-01, time/batch = 0.6380s	
688/16650 (epoch 2.066), train_loss = 2.27262850, grad/param norm = 3.2440e-01, time/batch = 0.6358s	
689/16650 (epoch 2.069), train_loss = 2.36931363, grad/param norm = 2.9968e-01, time/batch = 0.6369s	
690/16650 (epoch 2.072), train_loss = 2.24971985, grad/param norm = 3.2129e-01, time/batch = 0.6333s	
691/16650 (epoch 2.075), train_loss = 2.15789547, grad/param norm = 3.0689e-01, time/batch = 0.6356s	
692/16650 (epoch 2.078), train_loss = 2.14924557, grad/param norm = 3.0241e-01, time/batch = 0.6345s	
693/16650 (epoch 2.081), train_loss = 2.27620278, grad/param norm = 3.6765e-01, time/batch = 0.6361s	
694/16650 (epoch 2.084), train_loss = 2.25441719, grad/param norm = 2.8677e-01, time/batch = 0.6342s	
695/16650 (epoch 2.087), train_loss = 2.24122335, grad/param norm = 3.3089e-01, time/batch = 0.6550s	
696/16650 (epoch 2.090), train_loss = 2.17336764, grad/param norm = 3.6728e-01, time/batch = 0.6734s	
697/16650 (epoch 2.093), train_loss = 2.48108407, grad/param norm = 3.8735e-01, time/batch = 0.6398s	
698/16650 (epoch 2.096), train_loss = 2.20891614, grad/param norm = 3.2561e-01, time/batch = 0.6408s	
699/16650 (epoch 2.099), train_loss = 2.14184541, grad/param norm = 3.2555e-01, time/batch = 0.6356s	
700/16650 (epoch 2.102), train_loss = 2.16534117, grad/param norm = 3.4641e-01, time/batch = 0.6367s	
701/16650 (epoch 2.105), train_loss = 2.25033441, grad/param norm = 3.0161e-01, time/batch = 0.6466s	
702/16650 (epoch 2.108), train_loss = 2.42011261, grad/param norm = 3.3371e-01, time/batch = 0.6401s	
703/16650 (epoch 2.111), train_loss = 2.12484145, grad/param norm = 3.2276e-01, time/batch = 0.6368s	
704/16650 (epoch 2.114), train_loss = 2.38684164, grad/param norm = 3.0417e-01, time/batch = 0.6349s	
705/16650 (epoch 2.117), train_loss = 2.18584885, grad/param norm = 2.9510e-01, time/batch = 0.6386s	
706/16650 (epoch 2.120), train_loss = 2.16540180, grad/param norm = 3.4263e-01, time/batch = 0.6368s	
707/16650 (epoch 2.123), train_loss = 2.10693774, grad/param norm = 3.5054e-01, time/batch = 0.6321s	
708/16650 (epoch 2.126), train_loss = 2.21360145, grad/param norm = 4.7636e-01, time/batch = 0.6335s	
709/16650 (epoch 2.129), train_loss = 2.24232804, grad/param norm = 3.7585e-01, time/batch = 0.6321s	
710/16650 (epoch 2.132), train_loss = 2.39537037, grad/param norm = 3.2504e-01, time/batch = 0.6332s	
711/16650 (epoch 2.135), train_loss = 2.16104745, grad/param norm = 2.7748e-01, time/batch = 0.6372s	
712/16650 (epoch 2.138), train_loss = 2.21463259, grad/param norm = 3.5677e-01, time/batch = 0.6363s	
713/16650 (epoch 2.141), train_loss = 2.30167974, grad/param norm = 3.8120e-01, time/batch = 0.6342s	
714/16650 (epoch 2.144), train_loss = 2.26952653, grad/param norm = 2.8524e-01, time/batch = 0.6348s	
715/16650 (epoch 2.147), train_loss = 2.25933764, grad/param norm = 3.5694e-01, time/batch = 0.6355s	
716/16650 (epoch 2.150), train_loss = 2.30965321, grad/param norm = 3.2234e-01, time/batch = 0.6326s	
717/16650 (epoch 2.153), train_loss = 2.12287671, grad/param norm = 2.7962e-01, time/batch = 0.6335s	
718/16650 (epoch 2.156), train_loss = 2.00668675, grad/param norm = 2.8139e-01, time/batch = 0.6337s	
719/16650 (epoch 2.159), train_loss = 2.31640041, grad/param norm = 3.0109e-01, time/batch = 0.6341s	
720/16650 (epoch 2.162), train_loss = 2.14798507, grad/param norm = 3.6171e-01, time/batch = 0.6354s	
721/16650 (epoch 2.165), train_loss = 2.16893574, grad/param norm = 3.7697e-01, time/batch = 0.6366s	
722/16650 (epoch 2.168), train_loss = 1.92335221, grad/param norm = 3.4496e-01, time/batch = 0.6373s	
723/16650 (epoch 2.171), train_loss = 2.23198019, grad/param norm = 2.5662e-01, time/batch = 0.6404s	
724/16650 (epoch 2.174), train_loss = 2.03236075, grad/param norm = 3.2750e-01, time/batch = 0.6344s	
725/16650 (epoch 2.177), train_loss = 2.22525044, grad/param norm = 3.4182e-01, time/batch = 0.6359s	
726/16650 (epoch 2.180), train_loss = 2.29866508, grad/param norm = 2.8062e-01, time/batch = 0.6352s	
727/16650 (epoch 2.183), train_loss = 2.30661559, grad/param norm = 2.6545e-01, time/batch = 0.6345s	
728/16650 (epoch 2.186), train_loss = 2.31638467, grad/param norm = 2.8811e-01, time/batch = 0.6330s	
729/16650 (epoch 2.189), train_loss = 2.12811409, grad/param norm = 2.6486e-01, time/batch = 0.6344s	
730/16650 (epoch 2.192), train_loss = 2.10467112, grad/param norm = 3.0692e-01, time/batch = 0.6354s	
731/16650 (epoch 2.195), train_loss = 2.18732213, grad/param norm = 3.3307e-01, time/batch = 0.6370s	
732/16650 (epoch 2.198), train_loss = 2.02840773, grad/param norm = 2.9907e-01, time/batch = 0.6394s	
733/16650 (epoch 2.201), train_loss = 2.22846151, grad/param norm = 2.9706e-01, time/batch = 0.6339s	
734/16650 (epoch 2.204), train_loss = 2.18974889, grad/param norm = 3.8254e-01, time/batch = 0.6339s	
735/16650 (epoch 2.207), train_loss = 2.28648614, grad/param norm = 5.5255e-01, time/batch = 0.6348s	
736/16650 (epoch 2.210), train_loss = 2.19821399, grad/param norm = 5.4424e-01, time/batch = 0.6340s	
737/16650 (epoch 2.213), train_loss = 2.16392022, grad/param norm = 3.5543e-01, time/batch = 0.6339s	
738/16650 (epoch 2.216), train_loss = 2.16678488, grad/param norm = 2.7601e-01, time/batch = 0.6425s	
739/16650 (epoch 2.219), train_loss = 2.12431408, grad/param norm = 3.2429e-01, time/batch = 0.6524s	
740/16650 (epoch 2.222), train_loss = 2.23426557, grad/param norm = 3.4298e-01, time/batch = 0.6523s	
741/16650 (epoch 2.225), train_loss = 2.13534492, grad/param norm = 3.5015e-01, time/batch = 0.6560s	
742/16650 (epoch 2.228), train_loss = 2.12150824, grad/param norm = 2.9165e-01, time/batch = 0.6709s	
743/16650 (epoch 2.231), train_loss = 2.16289254, grad/param norm = 2.6649e-01, time/batch = 0.6460s	
744/16650 (epoch 2.234), train_loss = 2.20843637, grad/param norm = 2.9198e-01, time/batch = 0.6513s	
745/16650 (epoch 2.237), train_loss = 2.05261588, grad/param norm = 2.9520e-01, time/batch = 0.6385s	
746/16650 (epoch 2.240), train_loss = 2.20685101, grad/param norm = 2.8813e-01, time/batch = 0.6357s	
747/16650 (epoch 2.243), train_loss = 2.18396018, grad/param norm = 3.1794e-01, time/batch = 0.6404s	
748/16650 (epoch 2.246), train_loss = 2.39355826, grad/param norm = 4.0956e-01, time/batch = 0.6392s	
749/16650 (epoch 2.249), train_loss = 2.06759464, grad/param norm = 3.9328e-01, time/batch = 0.6424s	
750/16650 (epoch 2.252), train_loss = 2.19240679, grad/param norm = 3.0667e-01, time/batch = 0.6417s	
751/16650 (epoch 2.255), train_loss = 2.19927232, grad/param norm = 3.4631e-01, time/batch = 0.6347s	
752/16650 (epoch 2.258), train_loss = 2.26553711, grad/param norm = 3.4710e-01, time/batch = 0.6322s	
753/16650 (epoch 2.261), train_loss = 2.27965512, grad/param norm = 3.7394e-01, time/batch = 0.6321s	
754/16650 (epoch 2.264), train_loss = 2.18465692, grad/param norm = 3.5663e-01, time/batch = 0.6324s	
755/16650 (epoch 2.267), train_loss = 2.07666663, grad/param norm = 3.1651e-01, time/batch = 0.6331s	
756/16650 (epoch 2.270), train_loss = 2.00884858, grad/param norm = 3.2125e-01, time/batch = 0.6408s	
757/16650 (epoch 2.273), train_loss = 2.21097384, grad/param norm = 3.4362e-01, time/batch = 0.6322s	
758/16650 (epoch 2.276), train_loss = 2.15780280, grad/param norm = 3.4581e-01, time/batch = 0.6321s	
759/16650 (epoch 2.279), train_loss = 2.16396136, grad/param norm = 3.7676e-01, time/batch = 0.6316s	
760/16650 (epoch 2.282), train_loss = 2.09192260, grad/param norm = 3.5776e-01, time/batch = 0.6377s	
761/16650 (epoch 2.285), train_loss = 2.04059688, grad/param norm = 3.0793e-01, time/batch = 0.6345s	
762/16650 (epoch 2.288), train_loss = 2.13669480, grad/param norm = 3.1126e-01, time/batch = 0.6341s	
763/16650 (epoch 2.291), train_loss = 2.02807706, grad/param norm = 3.3073e-01, time/batch = 0.6333s	
764/16650 (epoch 2.294), train_loss = 2.00299964, grad/param norm = 2.8760e-01, time/batch = 0.6343s	
765/16650 (epoch 2.297), train_loss = 1.95213378, grad/param norm = 3.2548e-01, time/batch = 0.6410s	
766/16650 (epoch 2.300), train_loss = 2.01335242, grad/param norm = 3.4525e-01, time/batch = 0.6339s	
767/16650 (epoch 2.303), train_loss = 1.92590496, grad/param norm = 3.9877e-01, time/batch = 0.6352s	
768/16650 (epoch 2.306), train_loss = 2.31779992, grad/param norm = 3.9254e-01, time/batch = 0.6347s	
769/16650 (epoch 2.309), train_loss = 2.29074959, grad/param norm = 3.1245e-01, time/batch = 0.6341s	
770/16650 (epoch 2.312), train_loss = 2.12902450, grad/param norm = 4.1051e-01, time/batch = 0.6345s	
771/16650 (epoch 2.315), train_loss = 1.94871377, grad/param norm = 3.1492e-01, time/batch = 0.6404s	
772/16650 (epoch 2.318), train_loss = 2.04721929, grad/param norm = 3.0148e-01, time/batch = 0.6360s	
773/16650 (epoch 2.321), train_loss = 2.34462958, grad/param norm = 4.0021e-01, time/batch = 0.6409s	
774/16650 (epoch 2.324), train_loss = 2.30313306, grad/param norm = 4.1465e-01, time/batch = 0.6337s	
775/16650 (epoch 2.327), train_loss = 2.25675767, grad/param norm = 3.7147e-01, time/batch = 0.6334s	
776/16650 (epoch 2.330), train_loss = 2.22197099, grad/param norm = 3.7257e-01, time/batch = 0.6391s	
777/16650 (epoch 2.333), train_loss = 2.24522772, grad/param norm = 3.2920e-01, time/batch = 0.6365s	
778/16650 (epoch 2.336), train_loss = 1.89221470, grad/param norm = 2.6232e-01, time/batch = 0.6367s	
779/16650 (epoch 2.339), train_loss = 2.12478427, grad/param norm = 3.1183e-01, time/batch = 0.6364s	
780/16650 (epoch 2.342), train_loss = 2.11874509, grad/param norm = 2.8301e-01, time/batch = 0.6393s	
781/16650 (epoch 2.345), train_loss = 2.02058692, grad/param norm = 3.1627e-01, time/batch = 0.6383s	
782/16650 (epoch 2.348), train_loss = 2.10457572, grad/param norm = 3.6387e-01, time/batch = 0.6342s	
783/16650 (epoch 2.351), train_loss = 2.26514849, grad/param norm = 3.4760e-01, time/batch = 0.6330s	
784/16650 (epoch 2.354), train_loss = 2.23758196, grad/param norm = 2.6690e-01, time/batch = 0.6362s	
785/16650 (epoch 2.357), train_loss = 2.18019349, grad/param norm = 2.5890e-01, time/batch = 0.6344s	
786/16650 (epoch 2.360), train_loss = 2.16596343, grad/param norm = 2.9635e-01, time/batch = 0.6344s	
787/16650 (epoch 2.363), train_loss = 2.28773344, grad/param norm = 4.2645e-01, time/batch = 0.6353s	
788/16650 (epoch 2.366), train_loss = 2.25317830, grad/param norm = 3.3220e-01, time/batch = 0.6344s	
789/16650 (epoch 2.369), train_loss = 2.17959168, grad/param norm = 3.0901e-01, time/batch = 0.6353s	
790/16650 (epoch 2.372), train_loss = 2.13645593, grad/param norm = 3.4532e-01, time/batch = 0.6362s	
791/16650 (epoch 2.375), train_loss = 1.98688282, grad/param norm = 2.6549e-01, time/batch = 0.6343s	
792/16650 (epoch 2.378), train_loss = 1.91614832, grad/param norm = 3.1873e-01, time/batch = 0.6336s	
793/16650 (epoch 2.381), train_loss = 2.27504716, grad/param norm = 4.2058e-01, time/batch = 0.6370s	
794/16650 (epoch 2.384), train_loss = 2.11658686, grad/param norm = 2.9917e-01, time/batch = 0.6427s	
795/16650 (epoch 2.387), train_loss = 2.06008895, grad/param norm = 3.2158e-01, time/batch = 0.6473s	
796/16650 (epoch 2.390), train_loss = 2.14045633, grad/param norm = 3.0168e-01, time/batch = 0.6477s	
797/16650 (epoch 2.393), train_loss = 2.00606921, grad/param norm = 2.9584e-01, time/batch = 0.6398s	
798/16650 (epoch 2.396), train_loss = 2.31413516, grad/param norm = 3.1096e-01, time/batch = 0.6392s	
799/16650 (epoch 2.399), train_loss = 2.21678530, grad/param norm = 3.5433e-01, time/batch = 0.6329s	
800/16650 (epoch 2.402), train_loss = 2.06532183, grad/param norm = 3.8189e-01, time/batch = 0.6440s	
801/16650 (epoch 2.405), train_loss = 1.97674865, grad/param norm = 2.8988e-01, time/batch = 0.6372s	
802/16650 (epoch 2.408), train_loss = 2.21539144, grad/param norm = 3.6203e-01, time/batch = 0.6362s	
803/16650 (epoch 2.411), train_loss = 2.09491954, grad/param norm = 4.1112e-01, time/batch = 0.6338s	
804/16650 (epoch 2.414), train_loss = 1.94786882, grad/param norm = 4.0527e-01, time/batch = 0.6365s	
805/16650 (epoch 2.417), train_loss = 1.98446211, grad/param norm = 4.2233e-01, time/batch = 0.6364s	
806/16650 (epoch 2.420), train_loss = 1.98850356, grad/param norm = 3.5662e-01, time/batch = 0.6382s	
807/16650 (epoch 2.423), train_loss = 1.73564114, grad/param norm = 2.9442e-01, time/batch = 0.6353s	
808/16650 (epoch 2.426), train_loss = 2.13175142, grad/param norm = 2.8595e-01, time/batch = 0.6331s	
809/16650 (epoch 2.429), train_loss = 2.14298031, grad/param norm = 2.8791e-01, time/batch = 0.6395s	
810/16650 (epoch 2.432), train_loss = 2.06024330, grad/param norm = 2.8945e-01, time/batch = 0.6354s	
811/16650 (epoch 2.435), train_loss = 2.29961005, grad/param norm = 3.8492e-01, time/batch = 0.6341s	
812/16650 (epoch 2.438), train_loss = 2.26262685, grad/param norm = 3.1868e-01, time/batch = 0.6357s	
813/16650 (epoch 2.441), train_loss = 2.21842279, grad/param norm = 2.8122e-01, time/batch = 0.6349s	
814/16650 (epoch 2.444), train_loss = 2.07366283, grad/param norm = 2.8809e-01, time/batch = 0.6364s	
815/16650 (epoch 2.447), train_loss = 2.14693985, grad/param norm = 4.1759e-01, time/batch = 0.6384s	
816/16650 (epoch 2.450), train_loss = 2.08600804, grad/param norm = 3.7409e-01, time/batch = 0.6321s	
817/16650 (epoch 2.453), train_loss = 2.17549068, grad/param norm = 3.4883e-01, time/batch = 0.6329s	
818/16650 (epoch 2.456), train_loss = 1.99814191, grad/param norm = 3.5620e-01, time/batch = 0.6342s	
819/16650 (epoch 2.459), train_loss = 2.09967312, grad/param norm = 3.2132e-01, time/batch = 0.6395s	
820/16650 (epoch 2.462), train_loss = 2.27286308, grad/param norm = 3.0611e-01, time/batch = 0.6377s	
821/16650 (epoch 2.465), train_loss = 2.04255309, grad/param norm = 2.9342e-01, time/batch = 0.6393s	
822/16650 (epoch 2.468), train_loss = 1.73372144, grad/param norm = 3.0933e-01, time/batch = 0.6334s	
823/16650 (epoch 2.471), train_loss = 1.85432450, grad/param norm = 3.5190e-01, time/batch = 0.6354s	
824/16650 (epoch 2.474), train_loss = 1.88057555, grad/param norm = 3.9717e-01, time/batch = 0.6369s	
825/16650 (epoch 2.477), train_loss = 2.07429762, grad/param norm = 3.0931e-01, time/batch = 0.6320s	
826/16650 (epoch 2.480), train_loss = 2.19322684, grad/param norm = 3.0010e-01, time/batch = 0.6318s	
827/16650 (epoch 2.483), train_loss = 2.23715029, grad/param norm = 2.5868e-01, time/batch = 0.6322s	
828/16650 (epoch 2.486), train_loss = 1.89855079, grad/param norm = 3.5228e-01, time/batch = 0.6337s	
829/16650 (epoch 2.489), train_loss = 2.12867099, grad/param norm = 4.3161e-01, time/batch = 0.6347s	
830/16650 (epoch 2.492), train_loss = 2.10871279, grad/param norm = 3.5390e-01, time/batch = 0.6324s	
831/16650 (epoch 2.495), train_loss = 1.98235690, grad/param norm = 2.9492e-01, time/batch = 0.6375s	
832/16650 (epoch 2.498), train_loss = 2.26874444, grad/param norm = 3.1844e-01, time/batch = 0.6453s	
833/16650 (epoch 2.502), train_loss = 2.33512792, grad/param norm = 2.9774e-01, time/batch = 0.6396s	
834/16650 (epoch 2.505), train_loss = 2.11301936, grad/param norm = 2.8100e-01, time/batch = 0.6529s	
835/16650 (epoch 2.508), train_loss = 2.08786774, grad/param norm = 2.7941e-01, time/batch = 0.6660s	
836/16650 (epoch 2.511), train_loss = 2.29867800, grad/param norm = 4.0153e-01, time/batch = 0.6755s	
837/16650 (epoch 2.514), train_loss = 2.06394108, grad/param norm = 3.4512e-01, time/batch = 0.6575s	
838/16650 (epoch 2.517), train_loss = 2.09776731, grad/param norm = 3.1209e-01, time/batch = 0.6464s	
839/16650 (epoch 2.520), train_loss = 2.20094333, grad/param norm = 3.0522e-01, time/batch = 0.6421s	
840/16650 (epoch 2.523), train_loss = 2.18720892, grad/param norm = 3.1309e-01, time/batch = 0.6460s	
841/16650 (epoch 2.526), train_loss = 2.11069747, grad/param norm = 3.0034e-01, time/batch = 0.6572s	
842/16650 (epoch 2.529), train_loss = 2.23589915, grad/param norm = 2.7383e-01, time/batch = 0.6379s	
843/16650 (epoch 2.532), train_loss = 2.09395898, grad/param norm = 3.3004e-01, time/batch = 0.6384s	
844/16650 (epoch 2.535), train_loss = 1.95347652, grad/param norm = 2.9641e-01, time/batch = 0.6406s	
845/16650 (epoch 2.538), train_loss = 2.16077428, grad/param norm = 3.0530e-01, time/batch = 0.6442s	
846/16650 (epoch 2.541), train_loss = 2.20933118, grad/param norm = 3.0278e-01, time/batch = 0.6620s	
847/16650 (epoch 2.544), train_loss = 2.28612673, grad/param norm = 3.4527e-01, time/batch = 0.6413s	
848/16650 (epoch 2.547), train_loss = 1.93056352, grad/param norm = 3.4146e-01, time/batch = 0.6383s	
849/16650 (epoch 2.550), train_loss = 2.06246778, grad/param norm = 3.1291e-01, time/batch = 0.6328s	
850/16650 (epoch 2.553), train_loss = 2.23154167, grad/param norm = 3.9757e-01, time/batch = 0.6316s	
851/16650 (epoch 2.556), train_loss = 1.97428909, grad/param norm = 3.8112e-01, time/batch = 0.6354s	
852/16650 (epoch 2.559), train_loss = 1.94725955, grad/param norm = 3.3115e-01, time/batch = 0.6342s	
853/16650 (epoch 2.562), train_loss = 2.10827338, grad/param norm = 2.8841e-01, time/batch = 0.6330s	
854/16650 (epoch 2.565), train_loss = 1.86663499, grad/param norm = 2.9073e-01, time/batch = 0.6341s	
855/16650 (epoch 2.568), train_loss = 1.90976678, grad/param norm = 2.8439e-01, time/batch = 0.6371s	
856/16650 (epoch 2.571), train_loss = 2.00970590, grad/param norm = 3.3770e-01, time/batch = 0.6361s	
857/16650 (epoch 2.574), train_loss = 2.07284079, grad/param norm = 3.5093e-01, time/batch = 0.6351s	
858/16650 (epoch 2.577), train_loss = 2.06740600, grad/param norm = 3.2272e-01, time/batch = 0.6326s	
859/16650 (epoch 2.580), train_loss = 2.04276698, grad/param norm = 3.3176e-01, time/batch = 0.6339s	
860/16650 (epoch 2.583), train_loss = 1.94250664, grad/param norm = 3.1304e-01, time/batch = 0.6333s	
861/16650 (epoch 2.586), train_loss = 2.16225010, grad/param norm = 3.1154e-01, time/batch = 0.6347s	
862/16650 (epoch 2.589), train_loss = 1.91511872, grad/param norm = 2.4880e-01, time/batch = 0.6359s	
863/16650 (epoch 2.592), train_loss = 2.04480031, grad/param norm = 2.9486e-01, time/batch = 0.6457s	
864/16650 (epoch 2.595), train_loss = 1.93778409, grad/param norm = 3.5412e-01, time/batch = 0.6453s	
865/16650 (epoch 2.598), train_loss = 1.97479328, grad/param norm = 3.4091e-01, time/batch = 0.6487s	
866/16650 (epoch 2.601), train_loss = 2.04955964, grad/param norm = 3.3708e-01, time/batch = 0.6432s	
867/16650 (epoch 2.604), train_loss = 2.12175688, grad/param norm = 3.3463e-01, time/batch = 0.6430s	
868/16650 (epoch 2.607), train_loss = 2.07389796, grad/param norm = 3.2173e-01, time/batch = 0.6448s	
869/16650 (epoch 2.610), train_loss = 2.09124195, grad/param norm = 3.5465e-01, time/batch = 0.6439s	
870/16650 (epoch 2.613), train_loss = 2.21988776, grad/param norm = 3.0657e-01, time/batch = 0.6373s	
871/16650 (epoch 2.616), train_loss = 2.27162239, grad/param norm = 2.9175e-01, time/batch = 0.6451s	
872/16650 (epoch 2.619), train_loss = 2.07497527, grad/param norm = 3.0747e-01, time/batch = 0.6401s	
873/16650 (epoch 2.622), train_loss = 1.90395301, grad/param norm = 3.2876e-01, time/batch = 0.6383s	
874/16650 (epoch 2.625), train_loss = 2.11323798, grad/param norm = 3.3167e-01, time/batch = 0.6541s	
875/16650 (epoch 2.628), train_loss = 1.92227446, grad/param norm = 2.7242e-01, time/batch = 0.6727s	
876/16650 (epoch 2.631), train_loss = 2.05910863, grad/param norm = 3.1700e-01, time/batch = 0.6389s	
877/16650 (epoch 2.634), train_loss = 2.07056602, grad/param norm = 3.3540e-01, time/batch = 0.6318s	
878/16650 (epoch 2.637), train_loss = 2.19879707, grad/param norm = 3.8174e-01, time/batch = 0.6320s	
879/16650 (epoch 2.640), train_loss = 2.07503412, grad/param norm = 3.6697e-01, time/batch = 0.6320s	
880/16650 (epoch 2.643), train_loss = 2.16311326, grad/param norm = 3.4555e-01, time/batch = 0.6340s	
881/16650 (epoch 2.646), train_loss = 2.35536107, grad/param norm = 3.2583e-01, time/batch = 0.6354s	
882/16650 (epoch 2.649), train_loss = 2.07025337, grad/param norm = 2.7460e-01, time/batch = 0.6354s	
883/16650 (epoch 2.652), train_loss = 2.21766680, grad/param norm = 3.1429e-01, time/batch = 0.6362s	
884/16650 (epoch 2.655), train_loss = 2.23701669, grad/param norm = 3.1118e-01, time/batch = 0.6331s	
885/16650 (epoch 2.658), train_loss = 1.98553336, grad/param norm = 3.7608e-01, time/batch = 0.6345s	
886/16650 (epoch 2.661), train_loss = 2.17528271, grad/param norm = 2.7048e-01, time/batch = 0.6339s	
887/16650 (epoch 2.664), train_loss = 2.11209126, grad/param norm = 3.0540e-01, time/batch = 0.6409s	
888/16650 (epoch 2.667), train_loss = 2.22561880, grad/param norm = 2.9664e-01, time/batch = 0.6409s	
889/16650 (epoch 2.670), train_loss = 1.94532988, grad/param norm = 2.9531e-01, time/batch = 0.6346s	
890/16650 (epoch 2.673), train_loss = 1.81969001, grad/param norm = 2.6138e-01, time/batch = 0.6352s	
891/16650 (epoch 2.676), train_loss = 2.00062163, grad/param norm = 2.7226e-01, time/batch = 0.6393s	
892/16650 (epoch 2.679), train_loss = 1.98145448, grad/param norm = 2.9318e-01, time/batch = 0.6339s	
893/16650 (epoch 2.682), train_loss = 2.15591191, grad/param norm = 2.9802e-01, time/batch = 0.6341s	
894/16650 (epoch 2.685), train_loss = 2.02464650, grad/param norm = 3.2772e-01, time/batch = 0.6346s	
895/16650 (epoch 2.688), train_loss = 2.12454962, grad/param norm = 3.3682e-01, time/batch = 0.6329s	
896/16650 (epoch 2.691), train_loss = 2.09381208, grad/param norm = 3.5670e-01, time/batch = 0.6354s	
897/16650 (epoch 2.694), train_loss = 1.99878763, grad/param norm = 3.4958e-01, time/batch = 0.6345s	
898/16650 (epoch 2.697), train_loss = 1.84259218, grad/param norm = 3.2218e-01, time/batch = 0.6351s	
899/16650 (epoch 2.700), train_loss = 2.10720156, grad/param norm = 3.0422e-01, time/batch = 0.6335s	
900/16650 (epoch 2.703), train_loss = 2.00725938, grad/param norm = 2.8774e-01, time/batch = 0.6314s	
901/16650 (epoch 2.706), train_loss = 2.11023434, grad/param norm = 3.3769e-01, time/batch = 0.6356s	
902/16650 (epoch 2.709), train_loss = 2.07668550, grad/param norm = 3.7916e-01, time/batch = 0.6438s	
903/16650 (epoch 2.712), train_loss = 1.91226234, grad/param norm = 2.9493e-01, time/batch = 0.6427s	
904/16650 (epoch 2.715), train_loss = 2.14448117, grad/param norm = 2.9992e-01, time/batch = 0.6469s	
905/16650 (epoch 2.718), train_loss = 2.19151202, grad/param norm = 3.0440e-01, time/batch = 0.6441s	
906/16650 (epoch 2.721), train_loss = 2.12266992, grad/param norm = 2.9839e-01, time/batch = 0.6393s	
907/16650 (epoch 2.724), train_loss = 2.16283992, grad/param norm = 3.5460e-01, time/batch = 0.6358s	
908/16650 (epoch 2.727), train_loss = 2.04130290, grad/param norm = 3.9972e-01, time/batch = 0.6326s	
909/16650 (epoch 2.730), train_loss = 1.98025621, grad/param norm = 4.1892e-01, time/batch = 0.6343s	
910/16650 (epoch 2.733), train_loss = 2.19249120, grad/param norm = 3.6434e-01, time/batch = 0.6401s	
911/16650 (epoch 2.736), train_loss = 1.99134443, grad/param norm = 2.8632e-01, time/batch = 0.6401s	
912/16650 (epoch 2.739), train_loss = 2.04162364, grad/param norm = 2.9922e-01, time/batch = 0.6354s	
913/16650 (epoch 2.742), train_loss = 2.11298594, grad/param norm = 3.5236e-01, time/batch = 0.6335s	
914/16650 (epoch 2.745), train_loss = 1.78976309, grad/param norm = 3.1979e-01, time/batch = 0.6336s	
915/16650 (epoch 2.748), train_loss = 1.94517091, grad/param norm = 2.9570e-01, time/batch = 0.6343s	
916/16650 (epoch 2.751), train_loss = 2.14884545, grad/param norm = 3.0703e-01, time/batch = 0.6376s	
917/16650 (epoch 2.754), train_loss = 2.24719868, grad/param norm = 3.7402e-01, time/batch = 0.6316s	
918/16650 (epoch 2.757), train_loss = 2.11750934, grad/param norm = 3.4076e-01, time/batch = 0.6309s	
919/16650 (epoch 2.760), train_loss = 2.12236480, grad/param norm = 2.9764e-01, time/batch = 0.6322s	
920/16650 (epoch 2.763), train_loss = 1.87182891, grad/param norm = 3.2501e-01, time/batch = 0.6322s	
921/16650 (epoch 2.766), train_loss = 2.09400942, grad/param norm = 3.2315e-01, time/batch = 0.6351s	
922/16650 (epoch 2.769), train_loss = 1.98417402, grad/param norm = 2.8336e-01, time/batch = 0.6332s	
923/16650 (epoch 2.772), train_loss = 1.97232195, grad/param norm = 2.6439e-01, time/batch = 0.6383s	
924/16650 (epoch 2.775), train_loss = 2.04783031, grad/param norm = 3.0261e-01, time/batch = 0.6421s	
925/16650 (epoch 2.778), train_loss = 1.95764115, grad/param norm = 3.3123e-01, time/batch = 0.6348s	
926/16650 (epoch 2.781), train_loss = 2.09023555, grad/param norm = 3.2325e-01, time/batch = 0.6467s	
927/16650 (epoch 2.784), train_loss = 2.11237801, grad/param norm = 2.8946e-01, time/batch = 0.6429s	
928/16650 (epoch 2.787), train_loss = 2.11489997, grad/param norm = 2.6749e-01, time/batch = 0.6542s	
929/16650 (epoch 2.790), train_loss = 1.95701326, grad/param norm = 3.1319e-01, time/batch = 0.6576s	
930/16650 (epoch 2.793), train_loss = 1.95998078, grad/param norm = 3.4711e-01, time/batch = 0.6727s	
931/16650 (epoch 2.796), train_loss = 2.35354747, grad/param norm = 4.5757e-01, time/batch = 0.6587s	
932/16650 (epoch 2.799), train_loss = 2.20176644, grad/param norm = 3.5797e-01, time/batch = 0.6462s	
933/16650 (epoch 2.802), train_loss = 2.01841446, grad/param norm = 3.2154e-01, time/batch = 0.6479s	
934/16650 (epoch 2.805), train_loss = 1.95141809, grad/param norm = 3.2804e-01, time/batch = 0.6352s	
935/16650 (epoch 2.808), train_loss = 2.07951556, grad/param norm = 2.9538e-01, time/batch = 0.6370s	
936/16650 (epoch 2.811), train_loss = 2.10425052, grad/param norm = 2.5898e-01, time/batch = 0.6413s	
937/16650 (epoch 2.814), train_loss = 1.98618457, grad/param norm = 2.8710e-01, time/batch = 0.6355s	
938/16650 (epoch 2.817), train_loss = 1.97732146, grad/param norm = 2.8659e-01, time/batch = 0.6448s	
939/16650 (epoch 2.820), train_loss = 2.09725680, grad/param norm = 3.0764e-01, time/batch = 0.6438s	
940/16650 (epoch 2.823), train_loss = 1.87577687, grad/param norm = 2.5750e-01, time/batch = 0.6712s	
941/16650 (epoch 2.826), train_loss = 1.96384406, grad/param norm = 2.6759e-01, time/batch = 0.6723s	
942/16650 (epoch 2.829), train_loss = 2.27758883, grad/param norm = 2.9355e-01, time/batch = 0.6668s	
943/16650 (epoch 2.832), train_loss = 2.17186728, grad/param norm = 3.0072e-01, time/batch = 0.6600s	
944/16650 (epoch 2.835), train_loss = 2.15020625, grad/param norm = 3.0171e-01, time/batch = 0.6691s	
945/16650 (epoch 2.838), train_loss = 1.91569402, grad/param norm = 3.4300e-01, time/batch = 0.6573s	
946/16650 (epoch 2.841), train_loss = 1.88896465, grad/param norm = 3.4327e-01, time/batch = 0.6458s	
947/16650 (epoch 2.844), train_loss = 2.00491108, grad/param norm = 2.7107e-01, time/batch = 0.6386s	
948/16650 (epoch 2.847), train_loss = 2.23841271, grad/param norm = 2.7159e-01, time/batch = 0.6373s	
949/16650 (epoch 2.850), train_loss = 2.00441414, grad/param norm = 3.2578e-01, time/batch = 0.6328s	
950/16650 (epoch 2.853), train_loss = 2.06708902, grad/param norm = 2.8302e-01, time/batch = 0.6318s	
951/16650 (epoch 2.856), train_loss = 1.94963527, grad/param norm = 2.6066e-01, time/batch = 0.6668s	
952/16650 (epoch 2.859), train_loss = 1.97646795, grad/param norm = 2.5599e-01, time/batch = 0.6524s	
953/16650 (epoch 2.862), train_loss = 1.99386213, grad/param norm = 2.9642e-01, time/batch = 0.6350s	
954/16650 (epoch 2.865), train_loss = 1.73628544, grad/param norm = 2.6715e-01, time/batch = 0.6332s	
955/16650 (epoch 2.868), train_loss = 1.96338549, grad/param norm = 2.9219e-01, time/batch = 0.6329s	
956/16650 (epoch 2.871), train_loss = 1.98969913, grad/param norm = 2.6847e-01, time/batch = 0.6350s	
957/16650 (epoch 2.874), train_loss = 2.05777402, grad/param norm = 2.7900e-01, time/batch = 0.6353s	
958/16650 (epoch 2.877), train_loss = 1.85038990, grad/param norm = 3.1765e-01, time/batch = 0.6403s	
959/16650 (epoch 2.880), train_loss = 1.95597288, grad/param norm = 3.4022e-01, time/batch = 0.6333s	
960/16650 (epoch 2.883), train_loss = 2.06315642, grad/param norm = 2.7642e-01, time/batch = 0.6351s	
961/16650 (epoch 2.886), train_loss = 2.04939046, grad/param norm = 2.7395e-01, time/batch = 0.6359s	
962/16650 (epoch 2.889), train_loss = 1.95964727, grad/param norm = 3.1397e-01, time/batch = 0.6366s	
963/16650 (epoch 2.892), train_loss = 1.88073694, grad/param norm = 2.8300e-01, time/batch = 0.6339s	
964/16650 (epoch 2.895), train_loss = 2.11394824, grad/param norm = 3.0989e-01, time/batch = 0.6380s	
965/16650 (epoch 2.898), train_loss = 2.00691972, grad/param norm = 3.5145e-01, time/batch = 0.6351s	
966/16650 (epoch 2.901), train_loss = 1.89655145, grad/param norm = 2.6553e-01, time/batch = 0.6366s	
967/16650 (epoch 2.904), train_loss = 1.90127218, grad/param norm = 2.4824e-01, time/batch = 0.6386s	
968/16650 (epoch 2.907), train_loss = 2.01738600, grad/param norm = 2.7451e-01, time/batch = 0.6327s	
969/16650 (epoch 2.910), train_loss = 2.11151676, grad/param norm = 3.0097e-01, time/batch = 0.6328s	
970/16650 (epoch 2.913), train_loss = 1.93546685, grad/param norm = 3.3400e-01, time/batch = 0.6338s	
971/16650 (epoch 2.916), train_loss = 2.08071233, grad/param norm = 3.1672e-01, time/batch = 0.6374s	
972/16650 (epoch 2.919), train_loss = 2.13183850, grad/param norm = 3.1243e-01, time/batch = 0.6354s	
973/16650 (epoch 2.922), train_loss = 2.17437299, grad/param norm = 3.0662e-01, time/batch = 0.6356s	
974/16650 (epoch 2.925), train_loss = 2.06479356, grad/param norm = 2.9433e-01, time/batch = 0.6611s	
975/16650 (epoch 2.928), train_loss = 1.96372179, grad/param norm = 2.6401e-01, time/batch = 0.6429s	
976/16650 (epoch 2.931), train_loss = 2.02318578, grad/param norm = 2.9107e-01, time/batch = 0.6358s	
977/16650 (epoch 2.934), train_loss = 1.97633344, grad/param norm = 2.8138e-01, time/batch = 0.6363s	
978/16650 (epoch 2.937), train_loss = 2.01786784, grad/param norm = 2.8626e-01, time/batch = 0.6337s	
979/16650 (epoch 2.940), train_loss = 1.91867138, grad/param norm = 2.8948e-01, time/batch = 0.6331s	
980/16650 (epoch 2.943), train_loss = 1.94230754, grad/param norm = 2.8829e-01, time/batch = 0.6349s	
981/16650 (epoch 2.946), train_loss = 1.91524151, grad/param norm = 2.9158e-01, time/batch = 0.6359s	
982/16650 (epoch 2.949), train_loss = 2.03760090, grad/param norm = 2.7387e-01, time/batch = 0.6393s	
983/16650 (epoch 2.952), train_loss = 1.68199401, grad/param norm = 3.1018e-01, time/batch = 0.6400s	
984/16650 (epoch 2.955), train_loss = 2.01452053, grad/param norm = 3.2025e-01, time/batch = 0.6326s	
985/16650 (epoch 2.958), train_loss = 2.08159339, grad/param norm = 3.0178e-01, time/batch = 0.6342s	
986/16650 (epoch 2.961), train_loss = 1.90836134, grad/param norm = 2.8831e-01, time/batch = 0.6342s	
987/16650 (epoch 2.964), train_loss = 1.91860623, grad/param norm = 3.4700e-01, time/batch = 0.6376s	
988/16650 (epoch 2.967), train_loss = 2.15312717, grad/param norm = 3.0638e-01, time/batch = 0.6386s	
989/16650 (epoch 2.970), train_loss = 1.79089739, grad/param norm = 2.6041e-01, time/batch = 0.6435s	
990/16650 (epoch 2.973), train_loss = 2.00795801, grad/param norm = 3.3022e-01, time/batch = 0.6414s	
991/16650 (epoch 2.976), train_loss = 1.88844383, grad/param norm = 2.7803e-01, time/batch = 0.6462s	
992/16650 (epoch 2.979), train_loss = 2.08471584, grad/param norm = 2.9096e-01, time/batch = 0.6501s	
993/16650 (epoch 2.982), train_loss = 1.93441683, grad/param norm = 2.7844e-01, time/batch = 0.6629s	
994/16650 (epoch 2.985), train_loss = 1.87259696, grad/param norm = 3.1821e-01, time/batch = 0.6606s	
995/16650 (epoch 2.988), train_loss = 2.31309993, grad/param norm = 3.1164e-01, time/batch = 0.6624s	
996/16650 (epoch 2.991), train_loss = 1.93886484, grad/param norm = 2.8414e-01, time/batch = 0.6554s	
997/16650 (epoch 2.994), train_loss = 2.01618167, grad/param norm = 2.6832e-01, time/batch = 0.6471s	
998/16650 (epoch 2.997), train_loss = 2.04650467, grad/param norm = 2.9669e-01, time/batch = 0.6467s	
999/16650 (epoch 3.000), train_loss = 2.08097459, grad/param norm = 3.5934e-01, time/batch = 0.6405s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch3.00_2.1118.t7	
1000/16650 (epoch 3.003), train_loss = 2.10110522, grad/param norm = 3.4544e-01, time/batch = 0.6345s	
1001/16650 (epoch 3.006), train_loss = 2.19174959, grad/param norm = 3.6098e-01, time/batch = 0.6437s	
1002/16650 (epoch 3.009), train_loss = 2.23595230, grad/param norm = 3.6621e-01, time/batch = 0.6353s	
1003/16650 (epoch 3.012), train_loss = 2.25638040, grad/param norm = 2.8366e-01, time/batch = 0.6444s	
1004/16650 (epoch 3.015), train_loss = 2.18417492, grad/param norm = 3.2278e-01, time/batch = 0.6423s	
1005/16650 (epoch 3.018), train_loss = 1.82347910, grad/param norm = 3.0539e-01, time/batch = 0.6390s	
1006/16650 (epoch 3.021), train_loss = 2.17142378, grad/param norm = 3.1784e-01, time/batch = 0.6405s	
1007/16650 (epoch 3.024), train_loss = 1.98947574, grad/param norm = 2.9307e-01, time/batch = 0.6372s	
1008/16650 (epoch 3.027), train_loss = 2.03751975, grad/param norm = 2.7587e-01, time/batch = 0.6333s	
1009/16650 (epoch 3.030), train_loss = 1.97056737, grad/param norm = 2.8158e-01, time/batch = 0.6481s	
1010/16650 (epoch 3.033), train_loss = 1.94911695, grad/param norm = 2.8324e-01, time/batch = 0.6747s	
1011/16650 (epoch 3.036), train_loss = 1.95799259, grad/param norm = 3.0153e-01, time/batch = 0.6389s	
1012/16650 (epoch 3.039), train_loss = 2.07632304, grad/param norm = 3.0833e-01, time/batch = 0.6420s	
1013/16650 (epoch 3.042), train_loss = 2.13923655, grad/param norm = 3.1852e-01, time/batch = 0.6363s	
1014/16650 (epoch 3.045), train_loss = 1.92439379, grad/param norm = 3.0198e-01, time/batch = 0.6422s	
1015/16650 (epoch 3.048), train_loss = 1.96631181, grad/param norm = 2.9052e-01, time/batch = 0.6464s	
1016/16650 (epoch 3.051), train_loss = 1.99646242, grad/param norm = 3.0448e-01, time/batch = 0.6574s	
1017/16650 (epoch 3.054), train_loss = 1.99722414, grad/param norm = 3.0662e-01, time/batch = 0.6730s	
1018/16650 (epoch 3.057), train_loss = 1.95920551, grad/param norm = 2.7791e-01, time/batch = 0.6363s	
1019/16650 (epoch 3.060), train_loss = 1.87231322, grad/param norm = 2.7445e-01, time/batch = 0.6424s	
1020/16650 (epoch 3.063), train_loss = 1.92023236, grad/param norm = 2.6464e-01, time/batch = 0.6384s	
1021/16650 (epoch 3.066), train_loss = 2.09058085, grad/param norm = 3.2852e-01, time/batch = 0.6401s	
1022/16650 (epoch 3.069), train_loss = 2.18254211, grad/param norm = 2.9434e-01, time/batch = 0.6415s	
1023/16650 (epoch 3.072), train_loss = 2.01299469, grad/param norm = 2.9594e-01, time/batch = 0.6485s	
1024/16650 (epoch 3.075), train_loss = 1.95003144, grad/param norm = 3.2770e-01, time/batch = 0.6445s	
1025/16650 (epoch 3.078), train_loss = 1.96115186, grad/param norm = 2.7656e-01, time/batch = 0.6366s	
1026/16650 (epoch 3.081), train_loss = 2.05734929, grad/param norm = 2.8301e-01, time/batch = 0.6357s	
1027/16650 (epoch 3.084), train_loss = 2.05272548, grad/param norm = 2.3308e-01, time/batch = 0.6349s	
1028/16650 (epoch 3.087), train_loss = 2.02228483, grad/param norm = 2.9357e-01, time/batch = 0.6364s	
1029/16650 (epoch 3.090), train_loss = 1.92661560, grad/param norm = 2.9460e-01, time/batch = 0.6414s	
1030/16650 (epoch 3.093), train_loss = 2.29146381, grad/param norm = 2.8524e-01, time/batch = 0.6464s	
1031/16650 (epoch 3.096), train_loss = 1.99889427, grad/param norm = 2.7102e-01, time/batch = 0.6433s	
1032/16650 (epoch 3.099), train_loss = 1.91545996, grad/param norm = 2.7114e-01, time/batch = 0.6367s	
1033/16650 (epoch 3.102), train_loss = 1.96549909, grad/param norm = 2.9167e-01, time/batch = 0.6356s	
1034/16650 (epoch 3.105), train_loss = 2.05825283, grad/param norm = 3.0447e-01, time/batch = 0.6354s	
1035/16650 (epoch 3.108), train_loss = 2.19190579, grad/param norm = 2.8833e-01, time/batch = 0.6352s	
1036/16650 (epoch 3.111), train_loss = 1.93897166, grad/param norm = 2.3999e-01, time/batch = 0.6359s	
1037/16650 (epoch 3.114), train_loss = 2.16984016, grad/param norm = 2.6615e-01, time/batch = 0.6439s	
1038/16650 (epoch 3.117), train_loss = 2.03220791, grad/param norm = 2.6706e-01, time/batch = 0.6352s	
1039/16650 (epoch 3.120), train_loss = 1.93069436, grad/param norm = 2.9426e-01, time/batch = 0.6359s	
1040/16650 (epoch 3.123), train_loss = 1.92710038, grad/param norm = 2.7991e-01, time/batch = 0.6320s	
1041/16650 (epoch 3.126), train_loss = 2.01274200, grad/param norm = 3.5253e-01, time/batch = 0.6377s	
1042/16650 (epoch 3.129), train_loss = 2.06162677, grad/param norm = 2.8553e-01, time/batch = 0.6353s	
1043/16650 (epoch 3.132), train_loss = 2.19131976, grad/param norm = 2.6501e-01, time/batch = 0.6332s	
1044/16650 (epoch 3.135), train_loss = 1.99821351, grad/param norm = 2.9408e-01, time/batch = 0.6350s	
1045/16650 (epoch 3.138), train_loss = 1.99973289, grad/param norm = 3.2113e-01, time/batch = 0.6365s	
1046/16650 (epoch 3.141), train_loss = 2.08359662, grad/param norm = 2.9532e-01, time/batch = 0.6356s	
1047/16650 (epoch 3.144), train_loss = 2.03635451, grad/param norm = 2.5794e-01, time/batch = 0.6378s	
1048/16650 (epoch 3.147), train_loss = 2.08014727, grad/param norm = 3.1004e-01, time/batch = 0.6344s	
1049/16650 (epoch 3.150), train_loss = 2.15637254, grad/param norm = 2.9135e-01, time/batch = 0.6327s	
1050/16650 (epoch 3.153), train_loss = 1.94192444, grad/param norm = 2.6633e-01, time/batch = 0.6321s	
1051/16650 (epoch 3.156), train_loss = 1.80149102, grad/param norm = 2.5656e-01, time/batch = 0.6353s	
1052/16650 (epoch 3.159), train_loss = 2.15467881, grad/param norm = 3.0627e-01, time/batch = 0.6338s	
1053/16650 (epoch 3.162), train_loss = 1.96086770, grad/param norm = 3.4454e-01, time/batch = 0.6351s	
1054/16650 (epoch 3.165), train_loss = 1.99249644, grad/param norm = 3.1732e-01, time/batch = 0.6347s	
1055/16650 (epoch 3.168), train_loss = 1.72010951, grad/param norm = 3.0647e-01, time/batch = 0.6337s	
1056/16650 (epoch 3.171), train_loss = 2.05683802, grad/param norm = 2.3825e-01, time/batch = 0.6363s	
1057/16650 (epoch 3.174), train_loss = 1.82188363, grad/param norm = 2.6770e-01, time/batch = 0.6365s	
1058/16650 (epoch 3.177), train_loss = 1.99314238, grad/param norm = 2.6904e-01, time/batch = 0.6339s	
1059/16650 (epoch 3.180), train_loss = 2.11305257, grad/param norm = 2.6196e-01, time/batch = 0.6337s	
1060/16650 (epoch 3.183), train_loss = 2.15586685, grad/param norm = 2.6888e-01, time/batch = 0.6361s	
1061/16650 (epoch 3.186), train_loss = 2.11581995, grad/param norm = 2.6412e-01, time/batch = 0.6368s	
1062/16650 (epoch 3.189), train_loss = 1.90838103, grad/param norm = 2.4665e-01, time/batch = 0.6380s	
1063/16650 (epoch 3.192), train_loss = 1.90070230, grad/param norm = 2.5535e-01, time/batch = 0.6377s	
1064/16650 (epoch 3.195), train_loss = 1.99077571, grad/param norm = 2.8332e-01, time/batch = 0.6341s	
1065/16650 (epoch 3.198), train_loss = 1.81334619, grad/param norm = 3.1420e-01, time/batch = 0.6410s	
1066/16650 (epoch 3.201), train_loss = 2.03579230, grad/param norm = 2.9259e-01, time/batch = 0.6356s	
1067/16650 (epoch 3.204), train_loss = 1.98749628, grad/param norm = 2.9391e-01, time/batch = 0.6340s	
1068/16650 (epoch 3.207), train_loss = 2.05198124, grad/param norm = 3.3029e-01, time/batch = 0.6348s	
1069/16650 (epoch 3.210), train_loss = 1.93689913, grad/param norm = 3.0129e-01, time/batch = 0.6361s	
1070/16650 (epoch 3.213), train_loss = 1.98957504, grad/param norm = 3.1403e-01, time/batch = 0.6381s	
1071/16650 (epoch 3.216), train_loss = 1.96392113, grad/param norm = 3.1509e-01, time/batch = 0.6428s	
1072/16650 (epoch 3.219), train_loss = 1.94106440, grad/param norm = 2.9167e-01, time/batch = 0.6362s	
1073/16650 (epoch 3.222), train_loss = 2.01522471, grad/param norm = 3.0295e-01, time/batch = 0.6372s	
1074/16650 (epoch 3.225), train_loss = 1.92517517, grad/param norm = 2.9810e-01, time/batch = 0.6356s	
1075/16650 (epoch 3.228), train_loss = 1.90962693, grad/param norm = 2.7583e-01, time/batch = 0.6363s	
1076/16650 (epoch 3.231), train_loss = 1.97397189, grad/param norm = 2.5110e-01, time/batch = 0.6343s	
1077/16650 (epoch 3.234), train_loss = 2.02880310, grad/param norm = 2.6031e-01, time/batch = 0.6349s	
1078/16650 (epoch 3.237), train_loss = 1.87368022, grad/param norm = 2.8110e-01, time/batch = 0.6349s	
1079/16650 (epoch 3.240), train_loss = 2.00048910, grad/param norm = 2.7656e-01, time/batch = 0.6365s	
1080/16650 (epoch 3.243), train_loss = 2.01586089, grad/param norm = 2.8095e-01, time/batch = 0.6341s	
1081/16650 (epoch 3.246), train_loss = 2.22482846, grad/param norm = 3.2656e-01, time/batch = 0.6357s	
1082/16650 (epoch 3.249), train_loss = 1.83410854, grad/param norm = 3.3540e-01, time/batch = 0.6407s	
1083/16650 (epoch 3.252), train_loss = 1.99297203, grad/param norm = 2.7517e-01, time/batch = 0.6456s	
1084/16650 (epoch 3.255), train_loss = 2.03829454, grad/param norm = 3.5053e-01, time/batch = 0.6397s	
1085/16650 (epoch 3.258), train_loss = 2.04902107, grad/param norm = 3.1951e-01, time/batch = 0.6346s	
1086/16650 (epoch 3.261), train_loss = 2.06141805, grad/param norm = 3.2208e-01, time/batch = 0.6329s	
1087/16650 (epoch 3.264), train_loss = 1.97169342, grad/param norm = 3.0262e-01, time/batch = 0.6442s	
1088/16650 (epoch 3.267), train_loss = 1.83613585, grad/param norm = 2.5862e-01, time/batch = 0.6395s	
1089/16650 (epoch 3.270), train_loss = 1.83760866, grad/param norm = 2.7906e-01, time/batch = 0.6366s	
1090/16650 (epoch 3.273), train_loss = 2.05097725, grad/param norm = 2.8355e-01, time/batch = 0.6341s	
1091/16650 (epoch 3.276), train_loss = 1.94477673, grad/param norm = 3.0990e-01, time/batch = 0.6335s	
1092/16650 (epoch 3.279), train_loss = 1.98116762, grad/param norm = 3.2299e-01, time/batch = 0.6333s	
1093/16650 (epoch 3.282), train_loss = 1.83825379, grad/param norm = 2.7434e-01, time/batch = 0.6342s	
1094/16650 (epoch 3.285), train_loss = 1.79843672, grad/param norm = 2.3424e-01, time/batch = 0.6342s	
1095/16650 (epoch 3.288), train_loss = 1.92729837, grad/param norm = 2.3162e-01, time/batch = 0.6364s	
1096/16650 (epoch 3.291), train_loss = 1.73542405, grad/param norm = 2.5605e-01, time/batch = 0.6373s	
1097/16650 (epoch 3.294), train_loss = 1.76898807, grad/param norm = 2.3225e-01, time/batch = 0.6331s	
1098/16650 (epoch 3.297), train_loss = 1.75715559, grad/param norm = 2.5545e-01, time/batch = 0.6336s	
1099/16650 (epoch 3.300), train_loss = 1.77388385, grad/param norm = 2.9239e-01, time/batch = 0.6329s	
1100/16650 (epoch 3.303), train_loss = 1.69740081, grad/param norm = 2.9657e-01, time/batch = 0.6340s	
1101/16650 (epoch 3.306), train_loss = 2.10685942, grad/param norm = 3.2557e-01, time/batch = 0.6362s	
1102/16650 (epoch 3.309), train_loss = 2.10270481, grad/param norm = 3.0141e-01, time/batch = 0.6346s	
1103/16650 (epoch 3.312), train_loss = 1.90146103, grad/param norm = 3.2567e-01, time/batch = 0.6350s	
1104/16650 (epoch 3.315), train_loss = 1.72249106, grad/param norm = 2.6497e-01, time/batch = 0.6343s	
1105/16650 (epoch 3.318), train_loss = 1.83407471, grad/param norm = 3.0453e-01, time/batch = 0.6341s	
1106/16650 (epoch 3.321), train_loss = 2.17532478, grad/param norm = 3.9472e-01, time/batch = 0.6341s	
1107/16650 (epoch 3.324), train_loss = 2.06688439, grad/param norm = 3.2771e-01, time/batch = 0.6413s	
1108/16650 (epoch 3.327), train_loss = 2.09027586, grad/param norm = 3.0822e-01, time/batch = 0.6379s	
1109/16650 (epoch 3.330), train_loss = 2.03414968, grad/param norm = 2.9402e-01, time/batch = 0.6559s	
1110/16650 (epoch 3.333), train_loss = 2.06127403, grad/param norm = 2.8417e-01, time/batch = 0.6567s	
1111/16650 (epoch 3.336), train_loss = 1.73453323, grad/param norm = 2.5845e-01, time/batch = 0.6667s	
1112/16650 (epoch 3.339), train_loss = 1.93941034, grad/param norm = 2.7798e-01, time/batch = 0.6424s	
1113/16650 (epoch 3.342), train_loss = 1.93960702, grad/param norm = 2.7152e-01, time/batch = 0.6582s	
1114/16650 (epoch 3.345), train_loss = 1.81743323, grad/param norm = 2.7245e-01, time/batch = 0.6416s	
1115/16650 (epoch 3.348), train_loss = 1.89727683, grad/param norm = 3.0440e-01, time/batch = 0.6346s	
1116/16650 (epoch 3.351), train_loss = 2.07409689, grad/param norm = 3.0991e-01, time/batch = 0.6322s	
1117/16650 (epoch 3.354), train_loss = 2.07744499, grad/param norm = 2.6199e-01, time/batch = 0.6374s	
1118/16650 (epoch 3.357), train_loss = 2.00267024, grad/param norm = 2.6976e-01, time/batch = 0.6433s	
1119/16650 (epoch 3.360), train_loss = 1.99508768, grad/param norm = 2.7358e-01, time/batch = 0.6358s	
1120/16650 (epoch 3.363), train_loss = 2.12941356, grad/param norm = 3.7410e-01, time/batch = 0.6384s	
1121/16650 (epoch 3.366), train_loss = 2.08891802, grad/param norm = 2.8405e-01, time/batch = 0.6363s	
1122/16650 (epoch 3.369), train_loss = 1.97408732, grad/param norm = 2.7960e-01, time/batch = 0.6410s	
1123/16650 (epoch 3.372), train_loss = 1.97072737, grad/param norm = 2.7764e-01, time/batch = 0.6334s	
1124/16650 (epoch 3.375), train_loss = 1.84975289, grad/param norm = 2.6771e-01, time/batch = 0.6337s	
1125/16650 (epoch 3.378), train_loss = 1.74404789, grad/param norm = 3.4814e-01, time/batch = 0.6359s	
1126/16650 (epoch 3.381), train_loss = 2.04846960, grad/param norm = 3.6929e-01, time/batch = 0.6344s	
1127/16650 (epoch 3.384), train_loss = 1.96822988, grad/param norm = 2.7589e-01, time/batch = 0.6339s	
1128/16650 (epoch 3.387), train_loss = 1.82858440, grad/param norm = 2.7955e-01, time/batch = 0.6338s	
1129/16650 (epoch 3.390), train_loss = 1.96141871, grad/param norm = 2.8678e-01, time/batch = 0.6393s	
1130/16650 (epoch 3.393), train_loss = 1.87506109, grad/param norm = 3.2832e-01, time/batch = 0.6355s	
1131/16650 (epoch 3.396), train_loss = 2.13130910, grad/param norm = 3.1431e-01, time/batch = 0.6422s	
1132/16650 (epoch 3.399), train_loss = 2.03086513, grad/param norm = 3.1120e-01, time/batch = 0.6343s	
1133/16650 (epoch 3.402), train_loss = 1.83519615, grad/param norm = 3.0271e-01, time/batch = 0.6339s	
1134/16650 (epoch 3.405), train_loss = 1.75658655, grad/param norm = 2.4785e-01, time/batch = 0.6347s	
1135/16650 (epoch 3.408), train_loss = 2.07751079, grad/param norm = 3.4938e-01, time/batch = 0.6339s	
1136/16650 (epoch 3.411), train_loss = 1.88937798, grad/param norm = 3.3544e-01, time/batch = 0.6340s	
1137/16650 (epoch 3.414), train_loss = 1.72121934, grad/param norm = 2.6980e-01, time/batch = 0.6350s	
1138/16650 (epoch 3.417), train_loss = 1.75406689, grad/param norm = 2.6244e-01, time/batch = 0.6372s	
1139/16650 (epoch 3.420), train_loss = 1.78961425, grad/param norm = 2.7933e-01, time/batch = 0.6380s	
1140/16650 (epoch 3.423), train_loss = 1.49469412, grad/param norm = 2.6428e-01, time/batch = 0.6346s	
1141/16650 (epoch 3.426), train_loss = 1.92896646, grad/param norm = 2.8070e-01, time/batch = 0.6387s	
1142/16650 (epoch 3.429), train_loss = 1.97352544, grad/param norm = 2.8959e-01, time/batch = 0.6423s	
1143/16650 (epoch 3.432), train_loss = 1.88471659, grad/param norm = 2.6598e-01, time/batch = 0.6376s	
1144/16650 (epoch 3.435), train_loss = 2.11092546, grad/param norm = 2.8674e-01, time/batch = 0.6344s	
1145/16650 (epoch 3.438), train_loss = 2.11311018, grad/param norm = 3.0537e-01, time/batch = 0.6337s	
1146/16650 (epoch 3.441), train_loss = 2.03380187, grad/param norm = 3.1130e-01, time/batch = 0.6347s	
1147/16650 (epoch 3.444), train_loss = 1.87379091, grad/param norm = 2.4472e-01, time/batch = 0.6343s	
1148/16650 (epoch 3.447), train_loss = 1.95554682, grad/param norm = 3.1014e-01, time/batch = 0.6320s	
1149/16650 (epoch 3.450), train_loss = 1.85746195, grad/param norm = 2.9271e-01, time/batch = 0.6350s	
1150/16650 (epoch 3.453), train_loss = 1.97872620, grad/param norm = 2.8970e-01, time/batch = 0.6343s	
1151/16650 (epoch 3.456), train_loss = 1.79102804, grad/param norm = 3.1136e-01, time/batch = 0.6546s	
1152/16650 (epoch 3.459), train_loss = 1.90702343, grad/param norm = 2.7997e-01, time/batch = 0.6517s	
1153/16650 (epoch 3.462), train_loss = 2.12029085, grad/param norm = 2.8891e-01, time/batch = 0.6693s	
1154/16650 (epoch 3.465), train_loss = 1.86762606, grad/param norm = 2.6392e-01, time/batch = 0.6480s	
1155/16650 (epoch 3.468), train_loss = 1.54037740, grad/param norm = 2.6167e-01, time/batch = 0.6503s	
1156/16650 (epoch 3.471), train_loss = 1.62699686, grad/param norm = 3.0801e-01, time/batch = 0.6338s	
1157/16650 (epoch 3.474), train_loss = 1.69312361, grad/param norm = 2.9870e-01, time/batch = 0.6386s	
1158/16650 (epoch 3.477), train_loss = 1.90194237, grad/param norm = 2.5529e-01, time/batch = 0.6351s	
1159/16650 (epoch 3.480), train_loss = 2.01049652, grad/param norm = 2.6658e-01, time/batch = 0.6340s	
1160/16650 (epoch 3.483), train_loss = 2.06939495, grad/param norm = 2.6906e-01, time/batch = 0.6340s	
1161/16650 (epoch 3.486), train_loss = 1.70952347, grad/param norm = 3.2049e-01, time/batch = 0.6376s	
1162/16650 (epoch 3.489), train_loss = 1.93082996, grad/param norm = 3.4732e-01, time/batch = 0.6393s	
1163/16650 (epoch 3.492), train_loss = 1.93830499, grad/param norm = 2.9440e-01, time/batch = 0.6443s	
1164/16650 (epoch 3.495), train_loss = 1.79304320, grad/param norm = 2.8690e-01, time/batch = 0.6346s	
1165/16650 (epoch 3.498), train_loss = 2.06585774, grad/param norm = 2.7884e-01, time/batch = 0.6371s	
1166/16650 (epoch 3.502), train_loss = 2.17172059, grad/param norm = 2.7010e-01, time/batch = 0.6360s	
1167/16650 (epoch 3.505), train_loss = 1.92139721, grad/param norm = 2.5964e-01, time/batch = 0.6345s	
1168/16650 (epoch 3.508), train_loss = 1.92695234, grad/param norm = 2.5227e-01, time/batch = 0.6364s	
1169/16650 (epoch 3.511), train_loss = 2.13221704, grad/param norm = 3.5303e-01, time/batch = 0.6359s	
1170/16650 (epoch 3.514), train_loss = 1.83074778, grad/param norm = 2.7196e-01, time/batch = 0.6396s	
1171/16650 (epoch 3.517), train_loss = 1.93599278, grad/param norm = 2.8295e-01, time/batch = 0.6484s	
1172/16650 (epoch 3.520), train_loss = 2.02979251, grad/param norm = 2.8061e-01, time/batch = 0.6414s	
1173/16650 (epoch 3.523), train_loss = 2.00432170, grad/param norm = 2.8893e-01, time/batch = 0.6490s	
1174/16650 (epoch 3.526), train_loss = 1.91859808, grad/param norm = 2.7855e-01, time/batch = 0.6450s	
1175/16650 (epoch 3.529), train_loss = 2.10019085, grad/param norm = 2.5707e-01, time/batch = 0.6483s	
1176/16650 (epoch 3.532), train_loss = 1.88108390, grad/param norm = 3.0089e-01, time/batch = 0.6436s	
1177/16650 (epoch 3.535), train_loss = 1.75265302, grad/param norm = 2.3620e-01, time/batch = 0.6410s	
1178/16650 (epoch 3.538), train_loss = 1.95135155, grad/param norm = 2.9438e-01, time/batch = 0.6404s	
1179/16650 (epoch 3.541), train_loss = 2.06096566, grad/param norm = 2.7299e-01, time/batch = 0.6582s	
1180/16650 (epoch 3.544), train_loss = 2.14255648, grad/param norm = 3.2706e-01, time/batch = 0.6435s	
1181/16650 (epoch 3.547), train_loss = 1.74268991, grad/param norm = 2.9663e-01, time/batch = 0.6444s	
1182/16650 (epoch 3.550), train_loss = 1.85629580, grad/param norm = 2.4864e-01, time/batch = 0.6438s	
1183/16650 (epoch 3.553), train_loss = 2.01642157, grad/param norm = 2.8841e-01, time/batch = 0.6437s	
1184/16650 (epoch 3.556), train_loss = 1.77751855, grad/param norm = 2.5813e-01, time/batch = 0.6411s	
1185/16650 (epoch 3.559), train_loss = 1.69670738, grad/param norm = 2.3696e-01, time/batch = 0.6450s	
1186/16650 (epoch 3.562), train_loss = 1.92145008, grad/param norm = 2.5037e-01, time/batch = 0.6402s	
1187/16650 (epoch 3.565), train_loss = 1.64300776, grad/param norm = 2.6209e-01, time/batch = 0.6447s	
1188/16650 (epoch 3.568), train_loss = 1.70392526, grad/param norm = 2.6616e-01, time/batch = 0.6407s	
1189/16650 (epoch 3.571), train_loss = 1.80656590, grad/param norm = 3.5474e-01, time/batch = 0.6414s	
1190/16650 (epoch 3.574), train_loss = 1.89437846, grad/param norm = 3.6086e-01, time/batch = 0.6351s	
1191/16650 (epoch 3.577), train_loss = 1.88193796, grad/param norm = 3.3281e-01, time/batch = 0.6428s	
1192/16650 (epoch 3.580), train_loss = 1.83654510, grad/param norm = 3.1123e-01, time/batch = 0.6339s	
1193/16650 (epoch 3.583), train_loss = 1.74326162, grad/param norm = 2.7637e-01, time/batch = 0.6326s	
1194/16650 (epoch 3.586), train_loss = 1.99570361, grad/param norm = 3.0366e-01, time/batch = 0.6343s	
1195/16650 (epoch 3.589), train_loss = 1.70154641, grad/param norm = 2.3707e-01, time/batch = 0.6341s	
1196/16650 (epoch 3.592), train_loss = 1.86943062, grad/param norm = 2.9600e-01, time/batch = 0.6367s	
1197/16650 (epoch 3.595), train_loss = 1.76282612, grad/param norm = 3.5173e-01, time/batch = 0.6341s	
1198/16650 (epoch 3.598), train_loss = 1.77348077, grad/param norm = 3.1175e-01, time/batch = 0.6328s	
1199/16650 (epoch 3.601), train_loss = 1.83312557, grad/param norm = 3.0301e-01, time/batch = 0.6327s	
1200/16650 (epoch 3.604), train_loss = 1.98208120, grad/param norm = 3.0928e-01, time/batch = 0.6400s	
1201/16650 (epoch 3.607), train_loss = 1.88473847, grad/param norm = 2.9214e-01, time/batch = 0.6373s	
1202/16650 (epoch 3.610), train_loss = 1.86081239, grad/param norm = 3.1664e-01, time/batch = 0.6475s	
1203/16650 (epoch 3.613), train_loss = 2.05070106, grad/param norm = 3.0993e-01, time/batch = 0.6557s	
1204/16650 (epoch 3.616), train_loss = 2.11252686, grad/param norm = 2.9248e-01, time/batch = 0.6729s	
1205/16650 (epoch 3.619), train_loss = 1.86341251, grad/param norm = 3.0784e-01, time/batch = 0.6402s	
1206/16650 (epoch 3.622), train_loss = 1.68173737, grad/param norm = 2.9721e-01, time/batch = 0.6378s	
1207/16650 (epoch 3.625), train_loss = 1.87865180, grad/param norm = 2.8039e-01, time/batch = 0.6380s	
1208/16650 (epoch 3.628), train_loss = 1.77305727, grad/param norm = 2.7253e-01, time/batch = 0.6364s	
1209/16650 (epoch 3.631), train_loss = 1.86905304, grad/param norm = 2.9253e-01, time/batch = 0.6356s	
1210/16650 (epoch 3.634), train_loss = 1.95825242, grad/param norm = 2.9471e-01, time/batch = 0.6419s	
1211/16650 (epoch 3.637), train_loss = 2.05804577, grad/param norm = 2.9872e-01, time/batch = 0.6514s	
1212/16650 (epoch 3.640), train_loss = 1.88204093, grad/param norm = 2.8531e-01, time/batch = 0.6431s	
1213/16650 (epoch 3.643), train_loss = 1.98378416, grad/param norm = 3.1060e-01, time/batch = 0.6417s	
1214/16650 (epoch 3.646), train_loss = 2.15444032, grad/param norm = 3.4870e-01, time/batch = 0.6365s	
1215/16650 (epoch 3.649), train_loss = 1.87203314, grad/param norm = 2.6947e-01, time/batch = 0.6511s	
1216/16650 (epoch 3.652), train_loss = 2.07815822, grad/param norm = 2.9769e-01, time/batch = 0.6408s	
1217/16650 (epoch 3.655), train_loss = 2.01663872, grad/param norm = 2.8287e-01, time/batch = 0.6375s	
1218/16650 (epoch 3.658), train_loss = 1.78489354, grad/param norm = 3.0312e-01, time/batch = 0.6370s	
1219/16650 (epoch 3.661), train_loss = 1.99003736, grad/param norm = 2.5049e-01, time/batch = 0.6380s	
1220/16650 (epoch 3.664), train_loss = 1.92473351, grad/param norm = 2.6631e-01, time/batch = 0.6413s	
1221/16650 (epoch 3.667), train_loss = 2.04056166, grad/param norm = 2.6055e-01, time/batch = 0.6423s	
1222/16650 (epoch 3.670), train_loss = 1.75042109, grad/param norm = 2.5341e-01, time/batch = 0.6372s	
1223/16650 (epoch 3.673), train_loss = 1.64612364, grad/param norm = 2.3541e-01, time/batch = 0.6358s	
1224/16650 (epoch 3.676), train_loss = 1.85176335, grad/param norm = 2.5926e-01, time/batch = 0.6379s	
1225/16650 (epoch 3.679), train_loss = 1.78542778, grad/param norm = 2.6623e-01, time/batch = 0.6364s	
1226/16650 (epoch 3.682), train_loss = 1.97740055, grad/param norm = 2.6654e-01, time/batch = 0.6345s	
1227/16650 (epoch 3.685), train_loss = 1.82327552, grad/param norm = 2.8312e-01, time/batch = 0.6354s	
1228/16650 (epoch 3.688), train_loss = 1.93311682, grad/param norm = 3.1031e-01, time/batch = 0.6332s	
1229/16650 (epoch 3.691), train_loss = 1.90945611, grad/param norm = 2.8388e-01, time/batch = 0.6354s	
1230/16650 (epoch 3.694), train_loss = 1.76368067, grad/param norm = 2.8717e-01, time/batch = 0.6363s	
1231/16650 (epoch 3.697), train_loss = 1.65471152, grad/param norm = 2.6197e-01, time/batch = 0.6347s	
1232/16650 (epoch 3.700), train_loss = 1.94961606, grad/param norm = 2.5867e-01, time/batch = 0.6339s	
1233/16650 (epoch 3.703), train_loss = 1.82491337, grad/param norm = 2.8389e-01, time/batch = 0.6344s	
1234/16650 (epoch 3.706), train_loss = 1.95431634, grad/param norm = 3.4457e-01, time/batch = 0.6324s	
1235/16650 (epoch 3.709), train_loss = 1.86375021, grad/param norm = 3.5791e-01, time/batch = 0.6344s	
1236/16650 (epoch 3.712), train_loss = 1.74314251, grad/param norm = 2.5853e-01, time/batch = 0.6326s	
1237/16650 (epoch 3.715), train_loss = 2.00717642, grad/param norm = 2.7971e-01, time/batch = 0.6339s	
1238/16650 (epoch 3.718), train_loss = 2.05517184, grad/param norm = 2.7732e-01, time/batch = 0.6360s	
1239/16650 (epoch 3.721), train_loss = 1.97865401, grad/param norm = 2.8217e-01, time/batch = 0.6377s	
1240/16650 (epoch 3.724), train_loss = 2.03859446, grad/param norm = 2.9149e-01, time/batch = 0.6322s	
1241/16650 (epoch 3.727), train_loss = 1.90623845, grad/param norm = 3.1332e-01, time/batch = 0.6358s	
1242/16650 (epoch 3.730), train_loss = 1.80642642, grad/param norm = 3.1562e-01, time/batch = 0.6342s	
1243/16650 (epoch 3.733), train_loss = 2.02217849, grad/param norm = 2.8904e-01, time/batch = 0.6346s	
1244/16650 (epoch 3.736), train_loss = 1.78783919, grad/param norm = 2.6906e-01, time/batch = 0.6349s	
1245/16650 (epoch 3.739), train_loss = 1.90353548, grad/param norm = 2.8345e-01, time/batch = 0.6304s	
1246/16650 (epoch 3.742), train_loss = 1.93582083, grad/param norm = 3.0553e-01, time/batch = 0.6324s	
1247/16650 (epoch 3.745), train_loss = 1.59532283, grad/param norm = 2.6680e-01, time/batch = 0.6367s	
1248/16650 (epoch 3.748), train_loss = 1.79771566, grad/param norm = 2.7743e-01, time/batch = 0.6332s	
1249/16650 (epoch 3.751), train_loss = 1.96808871, grad/param norm = 2.9981e-01, time/batch = 0.6345s	
1250/16650 (epoch 3.754), train_loss = 2.08507467, grad/param norm = 3.2440e-01, time/batch = 0.6330s	
1251/16650 (epoch 3.757), train_loss = 1.96743188, grad/param norm = 3.0398e-01, time/batch = 0.6363s	
1252/16650 (epoch 3.760), train_loss = 1.93339297, grad/param norm = 2.9463e-01, time/batch = 0.6347s	
1253/16650 (epoch 3.763), train_loss = 1.75323516, grad/param norm = 2.8826e-01, time/batch = 0.6349s	
1254/16650 (epoch 3.766), train_loss = 1.91024262, grad/param norm = 2.8299e-01, time/batch = 0.6341s	
1255/16650 (epoch 3.769), train_loss = 1.81622644, grad/param norm = 2.5030e-01, time/batch = 0.6345s	
1256/16650 (epoch 3.772), train_loss = 1.80149319, grad/param norm = 2.4659e-01, time/batch = 0.6368s	
1257/16650 (epoch 3.775), train_loss = 1.87079937, grad/param norm = 2.7584e-01, time/batch = 0.6335s	
1258/16650 (epoch 3.778), train_loss = 1.74639182, grad/param norm = 2.7810e-01, time/batch = 0.6362s	
1259/16650 (epoch 3.781), train_loss = 1.92397305, grad/param norm = 2.7401e-01, time/batch = 0.6381s	
1260/16650 (epoch 3.784), train_loss = 1.96056420, grad/param norm = 2.7247e-01, time/batch = 0.6490s	
1261/16650 (epoch 3.787), train_loss = 1.96791981, grad/param norm = 2.5460e-01, time/batch = 0.6452s	
1262/16650 (epoch 3.790), train_loss = 1.79257391, grad/param norm = 3.1498e-01, time/batch = 0.6402s	
1263/16650 (epoch 3.793), train_loss = 1.79573433, grad/param norm = 3.3390e-01, time/batch = 0.6398s	
1264/16650 (epoch 3.796), train_loss = 2.22404119, grad/param norm = 3.8924e-01, time/batch = 0.6406s	
1265/16650 (epoch 3.799), train_loss = 2.05907753, grad/param norm = 3.0413e-01, time/batch = 0.6364s	
1266/16650 (epoch 3.802), train_loss = 1.84482938, grad/param norm = 2.8253e-01, time/batch = 0.6355s	
1267/16650 (epoch 3.805), train_loss = 1.78203621, grad/param norm = 2.7174e-01, time/batch = 0.6324s	
1268/16650 (epoch 3.808), train_loss = 1.89298495, grad/param norm = 2.5953e-01, time/batch = 0.6321s	
1269/16650 (epoch 3.811), train_loss = 1.94694899, grad/param norm = 2.5864e-01, time/batch = 0.6316s	
1270/16650 (epoch 3.814), train_loss = 1.80064654, grad/param norm = 2.8017e-01, time/batch = 0.6317s	
1271/16650 (epoch 3.817), train_loss = 1.83902042, grad/param norm = 2.8618e-01, time/batch = 0.6371s	
1272/16650 (epoch 3.820), train_loss = 1.94125023, grad/param norm = 2.9089e-01, time/batch = 0.6363s	
1273/16650 (epoch 3.823), train_loss = 1.70889342, grad/param norm = 2.4001e-01, time/batch = 0.6311s	
1274/16650 (epoch 3.826), train_loss = 1.79573702, grad/param norm = 2.3779e-01, time/batch = 0.6337s	
1275/16650 (epoch 3.829), train_loss = 2.12425873, grad/param norm = 2.7787e-01, time/batch = 0.6333s	
1276/16650 (epoch 3.832), train_loss = 2.02857271, grad/param norm = 2.7305e-01, time/batch = 0.6374s	
1277/16650 (epoch 3.835), train_loss = 2.01403741, grad/param norm = 2.9102e-01, time/batch = 0.6389s	
1278/16650 (epoch 3.838), train_loss = 1.74931339, grad/param norm = 3.2548e-01, time/batch = 0.6366s	
1279/16650 (epoch 3.841), train_loss = 1.70213301, grad/param norm = 2.7508e-01, time/batch = 0.6349s	
1280/16650 (epoch 3.844), train_loss = 1.84615786, grad/param norm = 2.4866e-01, time/batch = 0.6390s	
1281/16650 (epoch 3.847), train_loss = 2.07525958, grad/param norm = 2.7752e-01, time/batch = 0.6373s	
1282/16650 (epoch 3.850), train_loss = 1.80076158, grad/param norm = 2.9501e-01, time/batch = 0.6380s	
1283/16650 (epoch 3.853), train_loss = 1.90188985, grad/param norm = 2.4631e-01, time/batch = 0.6511s	
1284/16650 (epoch 3.856), train_loss = 1.77906038, grad/param norm = 2.6612e-01, time/batch = 0.6396s	
1285/16650 (epoch 3.859), train_loss = 1.84732729, grad/param norm = 2.5079e-01, time/batch = 0.6577s	
1286/16650 (epoch 3.862), train_loss = 1.83018381, grad/param norm = 2.6998e-01, time/batch = 0.6704s	
1287/16650 (epoch 3.865), train_loss = 1.56808939, grad/param norm = 2.5553e-01, time/batch = 0.6355s	
1288/16650 (epoch 3.868), train_loss = 1.84389446, grad/param norm = 2.6381e-01, time/batch = 0.6397s	
1289/16650 (epoch 3.871), train_loss = 1.85947674, grad/param norm = 2.5145e-01, time/batch = 0.6373s	
1290/16650 (epoch 3.874), train_loss = 1.90456260, grad/param norm = 2.7776e-01, time/batch = 0.6355s	
1291/16650 (epoch 3.877), train_loss = 1.68700545, grad/param norm = 2.7468e-01, time/batch = 0.6350s	
1292/16650 (epoch 3.880), train_loss = 1.80518643, grad/param norm = 3.2338e-01, time/batch = 0.6344s	
1293/16650 (epoch 3.883), train_loss = 1.91357387, grad/param norm = 2.7701e-01, time/batch = 0.6351s	
1294/16650 (epoch 3.886), train_loss = 1.91077040, grad/param norm = 2.6288e-01, time/batch = 0.6480s	
1295/16650 (epoch 3.889), train_loss = 1.80472560, grad/param norm = 2.8139e-01, time/batch = 0.6404s	
1296/16650 (epoch 3.892), train_loss = 1.72169312, grad/param norm = 2.4390e-01, time/batch = 0.6561s	
1297/16650 (epoch 3.895), train_loss = 1.96920178, grad/param norm = 2.9517e-01, time/batch = 0.6614s	
1298/16650 (epoch 3.898), train_loss = 1.87846429, grad/param norm = 2.9342e-01, time/batch = 0.6713s	
1299/16650 (epoch 3.901), train_loss = 1.78636318, grad/param norm = 2.2601e-01, time/batch = 0.6477s	
1300/16650 (epoch 3.904), train_loss = 1.75646966, grad/param norm = 2.4736e-01, time/batch = 0.6419s	
1301/16650 (epoch 3.907), train_loss = 1.85577740, grad/param norm = 2.6067e-01, time/batch = 0.6360s	
1302/16650 (epoch 3.910), train_loss = 1.91860839, grad/param norm = 2.7717e-01, time/batch = 0.6362s	
1303/16650 (epoch 3.913), train_loss = 1.76778928, grad/param norm = 2.8212e-01, time/batch = 0.6373s	
1304/16650 (epoch 3.916), train_loss = 1.91233339, grad/param norm = 2.7686e-01, time/batch = 0.6378s	
1305/16650 (epoch 3.919), train_loss = 1.97235093, grad/param norm = 2.7167e-01, time/batch = 0.6408s	
1306/16650 (epoch 3.922), train_loss = 1.99978045, grad/param norm = 2.7307e-01, time/batch = 0.6399s	
1307/16650 (epoch 3.925), train_loss = 1.86775789, grad/param norm = 2.8495e-01, time/batch = 0.6375s	
1308/16650 (epoch 3.928), train_loss = 1.79714427, grad/param norm = 2.3529e-01, time/batch = 0.6424s	
1309/16650 (epoch 3.931), train_loss = 1.86074025, grad/param norm = 2.7065e-01, time/batch = 0.6324s	
1310/16650 (epoch 3.934), train_loss = 1.77823021, grad/param norm = 2.6135e-01, time/batch = 0.6341s	
1311/16650 (epoch 3.937), train_loss = 1.84869910, grad/param norm = 2.7742e-01, time/batch = 0.6444s	
1312/16650 (epoch 3.940), train_loss = 1.76269039, grad/param norm = 2.6120e-01, time/batch = 0.6374s	
1313/16650 (epoch 3.943), train_loss = 1.75613069, grad/param norm = 2.5513e-01, time/batch = 0.6374s	
1314/16650 (epoch 3.946), train_loss = 1.74657709, grad/param norm = 2.6982e-01, time/batch = 0.6335s	
1315/16650 (epoch 3.949), train_loss = 1.86747359, grad/param norm = 2.7280e-01, time/batch = 0.6342s	
1316/16650 (epoch 3.952), train_loss = 1.51088316, grad/param norm = 2.7599e-01, time/batch = 0.6348s	
1317/16650 (epoch 3.955), train_loss = 1.81141982, grad/param norm = 2.9651e-01, time/batch = 0.6341s	
1318/16650 (epoch 3.958), train_loss = 1.93866477, grad/param norm = 3.0963e-01, time/batch = 0.6342s	
1319/16650 (epoch 3.961), train_loss = 1.77420292, grad/param norm = 2.8048e-01, time/batch = 0.6370s	
1320/16650 (epoch 3.964), train_loss = 1.75466668, grad/param norm = 3.1158e-01, time/batch = 0.6351s	
1321/16650 (epoch 3.967), train_loss = 1.99937683, grad/param norm = 2.8760e-01, time/batch = 0.6410s	
1322/16650 (epoch 3.970), train_loss = 1.60769423, grad/param norm = 2.4240e-01, time/batch = 0.6369s	
1323/16650 (epoch 3.973), train_loss = 1.85700943, grad/param norm = 3.1000e-01, time/batch = 0.6363s	
1324/16650 (epoch 3.976), train_loss = 1.73077173, grad/param norm = 2.5763e-01, time/batch = 0.6359s	
1325/16650 (epoch 3.979), train_loss = 1.93389820, grad/param norm = 2.7566e-01, time/batch = 0.6348s	
1326/16650 (epoch 3.982), train_loss = 1.82483855, grad/param norm = 2.8409e-01, time/batch = 0.6345s	
1327/16650 (epoch 3.985), train_loss = 1.73007170, grad/param norm = 2.8740e-01, time/batch = 0.6377s	
1328/16650 (epoch 3.988), train_loss = 2.13539993, grad/param norm = 3.0496e-01, time/batch = 0.6348s	
1329/16650 (epoch 3.991), train_loss = 1.77230818, grad/param norm = 2.7322e-01, time/batch = 0.6359s	
1330/16650 (epoch 3.994), train_loss = 1.84311035, grad/param norm = 2.4553e-01, time/batch = 0.6382s	
1331/16650 (epoch 3.997), train_loss = 1.90740092, grad/param norm = 2.7924e-01, time/batch = 0.6428s	
1332/16650 (epoch 4.000), train_loss = 1.94356029, grad/param norm = 3.2036e-01, time/batch = 0.6518s	
1333/16650 (epoch 4.003), train_loss = 1.93930752, grad/param norm = 2.9275e-01, time/batch = 0.6457s	
1334/16650 (epoch 4.006), train_loss = 1.98483971, grad/param norm = 3.0778e-01, time/batch = 0.6453s	
1335/16650 (epoch 4.009), train_loss = 2.07187051, grad/param norm = 3.0173e-01, time/batch = 0.6474s	
1336/16650 (epoch 4.012), train_loss = 2.12213456, grad/param norm = 2.9304e-01, time/batch = 0.6485s	
1337/16650 (epoch 4.015), train_loss = 2.02605647, grad/param norm = 3.0907e-01, time/batch = 0.6461s	
1338/16650 (epoch 4.018), train_loss = 1.63047917, grad/param norm = 2.7246e-01, time/batch = 0.6382s	
1339/16650 (epoch 4.021), train_loss = 2.01164572, grad/param norm = 2.9841e-01, time/batch = 0.6333s	
1340/16650 (epoch 4.024), train_loss = 1.83766629, grad/param norm = 2.6468e-01, time/batch = 0.6333s	
1341/16650 (epoch 4.027), train_loss = 1.93222470, grad/param norm = 2.6185e-01, time/batch = 0.6366s	
1342/16650 (epoch 4.030), train_loss = 1.77572797, grad/param norm = 2.6347e-01, time/batch = 0.6360s	
1343/16650 (epoch 4.033), train_loss = 1.82022305, grad/param norm = 2.5289e-01, time/batch = 0.6341s	
1344/16650 (epoch 4.036), train_loss = 1.77605822, grad/param norm = 2.9453e-01, time/batch = 0.6355s	
1345/16650 (epoch 4.039), train_loss = 1.93808869, grad/param norm = 3.1855e-01, time/batch = 0.6361s	
1346/16650 (epoch 4.042), train_loss = 1.98780598, grad/param norm = 2.9780e-01, time/batch = 0.6435s	
1347/16650 (epoch 4.045), train_loss = 1.76226566, grad/param norm = 2.6440e-01, time/batch = 0.6360s	
1348/16650 (epoch 4.048), train_loss = 1.82732343, grad/param norm = 2.4492e-01, time/batch = 0.6505s	
1349/16650 (epoch 4.051), train_loss = 1.84982002, grad/param norm = 2.6484e-01, time/batch = 0.6521s	
1350/16650 (epoch 4.054), train_loss = 1.85471884, grad/param norm = 2.6029e-01, time/batch = 0.6524s	
1351/16650 (epoch 4.057), train_loss = 1.77269895, grad/param norm = 2.4916e-01, time/batch = 0.6526s	
1352/16650 (epoch 4.060), train_loss = 1.71694132, grad/param norm = 2.8215e-01, time/batch = 0.6479s	
1353/16650 (epoch 4.063), train_loss = 1.79096229, grad/param norm = 2.5038e-01, time/batch = 0.6417s	
1354/16650 (epoch 4.066), train_loss = 1.98589746, grad/param norm = 3.1539e-01, time/batch = 0.6408s	
1355/16650 (epoch 4.069), train_loss = 2.02389341, grad/param norm = 2.7877e-01, time/batch = 0.6362s	
1356/16650 (epoch 4.072), train_loss = 1.83407363, grad/param norm = 2.8217e-01, time/batch = 0.6337s	
1357/16650 (epoch 4.075), train_loss = 1.80404457, grad/param norm = 2.5897e-01, time/batch = 0.6342s	
1358/16650 (epoch 4.078), train_loss = 1.82496457, grad/param norm = 2.3612e-01, time/batch = 0.6347s	
1359/16650 (epoch 4.081), train_loss = 1.87692854, grad/param norm = 2.6484e-01, time/batch = 0.6342s	
1360/16650 (epoch 4.084), train_loss = 1.91001900, grad/param norm = 2.4484e-01, time/batch = 0.6345s	
1361/16650 (epoch 4.087), train_loss = 1.86902260, grad/param norm = 2.8239e-01, time/batch = 0.6375s	
1362/16650 (epoch 4.090), train_loss = 1.74597201, grad/param norm = 2.6457e-01, time/batch = 0.6374s	
1363/16650 (epoch 4.093), train_loss = 2.15396140, grad/param norm = 2.7049e-01, time/batch = 0.6374s	
1364/16650 (epoch 4.096), train_loss = 1.82518398, grad/param norm = 2.7059e-01, time/batch = 0.6407s	
1365/16650 (epoch 4.099), train_loss = 1.76282233, grad/param norm = 2.5154e-01, time/batch = 0.6421s	
1366/16650 (epoch 4.102), train_loss = 1.80897774, grad/param norm = 2.6058e-01, time/batch = 0.6390s	
1367/16650 (epoch 4.105), train_loss = 1.92276169, grad/param norm = 2.7509e-01, time/batch = 0.6395s	
1368/16650 (epoch 4.108), train_loss = 2.01475582, grad/param norm = 2.7048e-01, time/batch = 0.6355s	
1369/16650 (epoch 4.111), train_loss = 1.81254704, grad/param norm = 2.3154e-01, time/batch = 0.6360s	
1370/16650 (epoch 4.114), train_loss = 2.01764710, grad/param norm = 2.6524e-01, time/batch = 0.6368s	
1371/16650 (epoch 4.117), train_loss = 1.90693365, grad/param norm = 2.5287e-01, time/batch = 0.6485s	
1372/16650 (epoch 4.120), train_loss = 1.74639312, grad/param norm = 2.7382e-01, time/batch = 0.6427s	
1373/16650 (epoch 4.123), train_loss = 1.80351836, grad/param norm = 2.6058e-01, time/batch = 0.6346s	
1374/16650 (epoch 4.126), train_loss = 1.88842881, grad/param norm = 3.1336e-01, time/batch = 0.6360s	
1375/16650 (epoch 4.129), train_loss = 1.92090781, grad/param norm = 2.5749e-01, time/batch = 0.6340s	
1376/16650 (epoch 4.132), train_loss = 2.03368465, grad/param norm = 2.6034e-01, time/batch = 0.6324s	
1377/16650 (epoch 4.135), train_loss = 1.86266396, grad/param norm = 2.6783e-01, time/batch = 0.6369s	
1378/16650 (epoch 4.138), train_loss = 1.84958638, grad/param norm = 2.9888e-01, time/batch = 0.6382s	
1379/16650 (epoch 4.141), train_loss = 1.93522990, grad/param norm = 2.6782e-01, time/batch = 0.6406s	
1380/16650 (epoch 4.144), train_loss = 1.86796599, grad/param norm = 2.5275e-01, time/batch = 0.6355s	
1381/16650 (epoch 4.147), train_loss = 1.94649484, grad/param norm = 2.7987e-01, time/batch = 0.6348s	
1382/16650 (epoch 4.150), train_loss = 2.03694936, grad/param norm = 2.6505e-01, time/batch = 0.6345s	
1383/16650 (epoch 4.153), train_loss = 1.80835693, grad/param norm = 2.5357e-01, time/batch = 0.6339s	
1384/16650 (epoch 4.156), train_loss = 1.65315080, grad/param norm = 2.3544e-01, time/batch = 0.6336s	
1385/16650 (epoch 4.159), train_loss = 2.00922695, grad/param norm = 2.8430e-01, time/batch = 0.6331s	
1386/16650 (epoch 4.162), train_loss = 1.82567548, grad/param norm = 3.0503e-01, time/batch = 0.6338s	
1387/16650 (epoch 4.165), train_loss = 1.86719928, grad/param norm = 2.9417e-01, time/batch = 0.6375s	
1388/16650 (epoch 4.168), train_loss = 1.57528035, grad/param norm = 2.8127e-01, time/batch = 0.6435s	
1389/16650 (epoch 4.171), train_loss = 1.92507054, grad/param norm = 2.3505e-01, time/batch = 0.6406s	
1390/16650 (epoch 4.174), train_loss = 1.68878294, grad/param norm = 2.4895e-01, time/batch = 0.6623s	
1391/16650 (epoch 4.177), train_loss = 1.84126323, grad/param norm = 2.5128e-01, time/batch = 0.6709s	
1392/16650 (epoch 4.180), train_loss = 1.97273477, grad/param norm = 2.3955e-01, time/batch = 0.6622s	
1393/16650 (epoch 4.183), train_loss = 2.04867140, grad/param norm = 2.4151e-01, time/batch = 0.6478s	
1394/16650 (epoch 4.186), train_loss = 1.96436520, grad/param norm = 2.6515e-01, time/batch = 0.6468s	
1395/16650 (epoch 4.189), train_loss = 1.73990157, grad/param norm = 2.3095e-01, time/batch = 0.6373s	
1396/16650 (epoch 4.192), train_loss = 1.76172362, grad/param norm = 2.6362e-01, time/batch = 0.6385s	
1397/16650 (epoch 4.195), train_loss = 1.83971299, grad/param norm = 2.6152e-01, time/batch = 0.6401s	
1398/16650 (epoch 4.198), train_loss = 1.62892840, grad/param norm = 2.8422e-01, time/batch = 0.6373s	
1399/16650 (epoch 4.201), train_loss = 1.86656905, grad/param norm = 2.5254e-01, time/batch = 0.6408s	
1400/16650 (epoch 4.204), train_loss = 1.84540872, grad/param norm = 2.8887e-01, time/batch = 0.6372s	
1401/16650 (epoch 4.207), train_loss = 1.90367969, grad/param norm = 2.9939e-01, time/batch = 0.6411s	
1402/16650 (epoch 4.210), train_loss = 1.76464013, grad/param norm = 2.5090e-01, time/batch = 0.6363s	
1403/16650 (epoch 4.213), train_loss = 1.86525991, grad/param norm = 2.8534e-01, time/batch = 0.6363s	
1404/16650 (epoch 4.216), train_loss = 1.82310307, grad/param norm = 3.0150e-01, time/batch = 0.6395s	
1405/16650 (epoch 4.219), train_loss = 1.80887786, grad/param norm = 2.6524e-01, time/batch = 0.6359s	
1406/16650 (epoch 4.222), train_loss = 1.84765779, grad/param norm = 2.6472e-01, time/batch = 0.6353s	
1407/16650 (epoch 4.225), train_loss = 1.79855269, grad/param norm = 2.7807e-01, time/batch = 0.6350s	
1408/16650 (epoch 4.228), train_loss = 1.76801312, grad/param norm = 2.7709e-01, time/batch = 0.6337s	
1409/16650 (epoch 4.231), train_loss = 1.84015982, grad/param norm = 2.5959e-01, time/batch = 0.6398s	
1410/16650 (epoch 4.234), train_loss = 1.91233423, grad/param norm = 2.6161e-01, time/batch = 0.6515s	
1411/16650 (epoch 4.237), train_loss = 1.73600782, grad/param norm = 2.6360e-01, time/batch = 0.6512s	
1412/16650 (epoch 4.240), train_loss = 1.86867873, grad/param norm = 2.4827e-01, time/batch = 0.6429s	
1413/16650 (epoch 4.243), train_loss = 1.88129903, grad/param norm = 2.6654e-01, time/batch = 0.6432s	
1414/16650 (epoch 4.246), train_loss = 2.07038038, grad/param norm = 3.0199e-01, time/batch = 0.6357s	
1415/16650 (epoch 4.249), train_loss = 1.68898606, grad/param norm = 2.7926e-01, time/batch = 0.6344s	
1416/16650 (epoch 4.252), train_loss = 1.84308558, grad/param norm = 2.6828e-01, time/batch = 0.6335s	
1417/16650 (epoch 4.255), train_loss = 1.94183572, grad/param norm = 3.4686e-01, time/batch = 0.6328s	
1418/16650 (epoch 4.258), train_loss = 1.89245487, grad/param norm = 3.0294e-01, time/batch = 0.6341s	
1419/16650 (epoch 4.261), train_loss = 1.88712949, grad/param norm = 2.8884e-01, time/batch = 0.6340s	
1420/16650 (epoch 4.264), train_loss = 1.82764585, grad/param norm = 2.7595e-01, time/batch = 0.6365s	
1421/16650 (epoch 4.267), train_loss = 1.70123060, grad/param norm = 2.5575e-01, time/batch = 0.6379s	
1422/16650 (epoch 4.270), train_loss = 1.71116239, grad/param norm = 2.3110e-01, time/batch = 0.6373s	
1423/16650 (epoch 4.273), train_loss = 1.92526117, grad/param norm = 2.4858e-01, time/batch = 0.6340s	
1424/16650 (epoch 4.276), train_loss = 1.81089430, grad/param norm = 2.7761e-01, time/batch = 0.6343s	
1425/16650 (epoch 4.279), train_loss = 1.83165434, grad/param norm = 2.7078e-01, time/batch = 0.6361s	
1426/16650 (epoch 4.282), train_loss = 1.65778223, grad/param norm = 2.4388e-01, time/batch = 0.6347s	
1427/16650 (epoch 4.285), train_loss = 1.65291844, grad/param norm = 2.3239e-01, time/batch = 0.6378s	
1428/16650 (epoch 4.288), train_loss = 1.78185502, grad/param norm = 2.3668e-01, time/batch = 0.6366s	
1429/16650 (epoch 4.291), train_loss = 1.54308967, grad/param norm = 2.3683e-01, time/batch = 0.6364s	
1430/16650 (epoch 4.294), train_loss = 1.61848926, grad/param norm = 2.3295e-01, time/batch = 0.6347s	
1431/16650 (epoch 4.297), train_loss = 1.63606096, grad/param norm = 2.3840e-01, time/batch = 0.6358s	
1432/16650 (epoch 4.300), train_loss = 1.59926805, grad/param norm = 2.6516e-01, time/batch = 0.6348s	
1433/16650 (epoch 4.303), train_loss = 1.54507700, grad/param norm = 2.7494e-01, time/batch = 0.6359s	
1434/16650 (epoch 4.306), train_loss = 1.94131700, grad/param norm = 3.1453e-01, time/batch = 0.6359s	
1435/16650 (epoch 4.309), train_loss = 1.95163564, grad/param norm = 2.8337e-01, time/batch = 0.6372s	
1436/16650 (epoch 4.312), train_loss = 1.73139477, grad/param norm = 2.8153e-01, time/batch = 0.6384s	
1437/16650 (epoch 4.315), train_loss = 1.55684834, grad/param norm = 2.3362e-01, time/batch = 0.6404s	
1438/16650 (epoch 4.318), train_loss = 1.66962904, grad/param norm = 2.7655e-01, time/batch = 0.6429s	
1439/16650 (epoch 4.321), train_loss = 2.03534044, grad/param norm = 3.5352e-01, time/batch = 0.6368s	
1440/16650 (epoch 4.324), train_loss = 1.88651132, grad/param norm = 2.8377e-01, time/batch = 0.6333s	
1441/16650 (epoch 4.327), train_loss = 1.95668492, grad/param norm = 2.9842e-01, time/batch = 0.6372s	
1442/16650 (epoch 4.330), train_loss = 1.89394709, grad/param norm = 2.7586e-01, time/batch = 0.6348s	
1443/16650 (epoch 4.333), train_loss = 1.92622776, grad/param norm = 2.7062e-01, time/batch = 0.6343s	
1444/16650 (epoch 4.336), train_loss = 1.61797471, grad/param norm = 2.3976e-01, time/batch = 0.6348s	
1445/16650 (epoch 4.339), train_loss = 1.79485962, grad/param norm = 2.8041e-01, time/batch = 0.6370s	
1446/16650 (epoch 4.342), train_loss = 1.80613972, grad/param norm = 2.7183e-01, time/batch = 0.6356s	
1447/16650 (epoch 4.345), train_loss = 1.67713881, grad/param norm = 2.7283e-01, time/batch = 0.6347s	
1448/16650 (epoch 4.348), train_loss = 1.76035985, grad/param norm = 2.6802e-01, time/batch = 0.6344s	
1449/16650 (epoch 4.351), train_loss = 1.92634798, grad/param norm = 2.7367e-01, time/batch = 0.6443s	
1450/16650 (epoch 4.354), train_loss = 1.94439765, grad/param norm = 2.6960e-01, time/batch = 0.6408s	
1451/16650 (epoch 4.357), train_loss = 1.86890192, grad/param norm = 2.7366e-01, time/batch = 0.6390s	
1452/16650 (epoch 4.360), train_loss = 1.86031599, grad/param norm = 2.5569e-01, time/batch = 0.6359s	
1453/16650 (epoch 4.363), train_loss = 1.98320628, grad/param norm = 3.0996e-01, time/batch = 0.6366s	
1454/16650 (epoch 4.366), train_loss = 1.96761390, grad/param norm = 2.6690e-01, time/batch = 0.6351s	
1455/16650 (epoch 4.369), train_loss = 1.83641396, grad/param norm = 2.6368e-01, time/batch = 0.6351s	
1456/16650 (epoch 4.372), train_loss = 1.84178300, grad/param norm = 2.6408e-01, time/batch = 0.6333s	
1457/16650 (epoch 4.375), train_loss = 1.73946936, grad/param norm = 2.5565e-01, time/batch = 0.6368s	
1458/16650 (epoch 4.378), train_loss = 1.60732015, grad/param norm = 3.0868e-01, time/batch = 0.6345s	
1459/16650 (epoch 4.381), train_loss = 1.87406899, grad/param norm = 3.0500e-01, time/batch = 0.6346s	
1460/16650 (epoch 4.384), train_loss = 1.84257082, grad/param norm = 2.5748e-01, time/batch = 0.6357s	
1461/16650 (epoch 4.387), train_loss = 1.65088313, grad/param norm = 2.8058e-01, time/batch = 0.6381s	
1462/16650 (epoch 4.390), train_loss = 1.85092225, grad/param norm = 2.7717e-01, time/batch = 0.6380s	
1463/16650 (epoch 4.393), train_loss = 1.76999170, grad/param norm = 3.0403e-01, time/batch = 0.6361s	
1464/16650 (epoch 4.396), train_loss = 1.98326858, grad/param norm = 2.7467e-01, time/batch = 0.6371s	
1465/16650 (epoch 4.399), train_loss = 1.89095670, grad/param norm = 2.6121e-01, time/batch = 0.6349s	
1466/16650 (epoch 4.402), train_loss = 1.67751026, grad/param norm = 2.6041e-01, time/batch = 0.6350s	
1467/16650 (epoch 4.405), train_loss = 1.62757402, grad/param norm = 2.3625e-01, time/batch = 0.6347s	
1468/16650 (epoch 4.408), train_loss = 1.95852109, grad/param norm = 3.0770e-01, time/batch = 0.6365s	
1469/16650 (epoch 4.411), train_loss = 1.71343735, grad/param norm = 2.8520e-01, time/batch = 0.6350s	
1470/16650 (epoch 4.414), train_loss = 1.58172586, grad/param norm = 2.3484e-01, time/batch = 0.6334s	
1471/16650 (epoch 4.417), train_loss = 1.60099644, grad/param norm = 2.2264e-01, time/batch = 0.6380s	
1472/16650 (epoch 4.420), train_loss = 1.64307767, grad/param norm = 2.7104e-01, time/batch = 0.6434s	
1473/16650 (epoch 4.423), train_loss = 1.34214125, grad/param norm = 2.5776e-01, time/batch = 0.6332s	
1474/16650 (epoch 4.426), train_loss = 1.77720029, grad/param norm = 2.6833e-01, time/batch = 0.6334s	
1475/16650 (epoch 4.429), train_loss = 1.86322171, grad/param norm = 2.7836e-01, time/batch = 0.6335s	
1476/16650 (epoch 4.432), train_loss = 1.76974107, grad/param norm = 2.6969e-01, time/batch = 0.6339s	
1477/16650 (epoch 4.435), train_loss = 2.00397523, grad/param norm = 2.7063e-01, time/batch = 0.6348s	
1478/16650 (epoch 4.438), train_loss = 1.99539217, grad/param norm = 3.0182e-01, time/batch = 0.6348s	
1479/16650 (epoch 4.441), train_loss = 1.91263358, grad/param norm = 2.7388e-01, time/batch = 0.6353s	
1480/16650 (epoch 4.444), train_loss = 1.74102597, grad/param norm = 2.4673e-01, time/batch = 0.6391s	
1481/16650 (epoch 4.447), train_loss = 1.81267268, grad/param norm = 2.8605e-01, time/batch = 0.6495s	
1482/16650 (epoch 4.450), train_loss = 1.70036197, grad/param norm = 2.8332e-01, time/batch = 0.6463s	
1483/16650 (epoch 4.453), train_loss = 1.82580379, grad/param norm = 2.6047e-01, time/batch = 0.6705s	
1484/16650 (epoch 4.456), train_loss = 1.63601245, grad/param norm = 2.8284e-01, time/batch = 0.6676s	
1485/16650 (epoch 4.459), train_loss = 1.75801171, grad/param norm = 2.6386e-01, time/batch = 0.6779s	
1486/16650 (epoch 4.462), train_loss = 2.00358611, grad/param norm = 2.7163e-01, time/batch = 0.6471s	
1487/16650 (epoch 4.465), train_loss = 1.73698559, grad/param norm = 2.5808e-01, time/batch = 0.6370s	
1488/16650 (epoch 4.468), train_loss = 1.41756946, grad/param norm = 2.5537e-01, time/batch = 0.6384s	
1489/16650 (epoch 4.471), train_loss = 1.45024094, grad/param norm = 2.8191e-01, time/batch = 0.6508s	
1490/16650 (epoch 4.474), train_loss = 1.56303649, grad/param norm = 2.6153e-01, time/batch = 0.6392s	
1491/16650 (epoch 4.477), train_loss = 1.77353134, grad/param norm = 2.4974e-01, time/batch = 0.6454s	
1492/16650 (epoch 4.480), train_loss = 1.86495566, grad/param norm = 2.5584e-01, time/batch = 0.6444s	
1493/16650 (epoch 4.483), train_loss = 1.94285860, grad/param norm = 2.5735e-01, time/batch = 0.6344s	
1494/16650 (epoch 4.486), train_loss = 1.57892133, grad/param norm = 3.1200e-01, time/batch = 0.6394s	
1495/16650 (epoch 4.489), train_loss = 1.78608504, grad/param norm = 3.3057e-01, time/batch = 0.6435s	
1496/16650 (epoch 4.492), train_loss = 1.79369478, grad/param norm = 2.7310e-01, time/batch = 0.6375s	
1497/16650 (epoch 4.495), train_loss = 1.64917366, grad/param norm = 2.7547e-01, time/batch = 0.6330s	
1498/16650 (epoch 4.498), train_loss = 1.89396676, grad/param norm = 2.7468e-01, time/batch = 0.6331s	
1499/16650 (epoch 4.502), train_loss = 2.04414635, grad/param norm = 2.6347e-01, time/batch = 0.6360s	
1500/16650 (epoch 4.505), train_loss = 1.78398248, grad/param norm = 2.4713e-01, time/batch = 0.6339s	
1501/16650 (epoch 4.508), train_loss = 1.81210832, grad/param norm = 2.4935e-01, time/batch = 0.6367s	
1502/16650 (epoch 4.511), train_loss = 1.99979359, grad/param norm = 3.1366e-01, time/batch = 0.6392s	
1503/16650 (epoch 4.514), train_loss = 1.67400018, grad/param norm = 2.3873e-01, time/batch = 0.6414s	
1504/16650 (epoch 4.517), train_loss = 1.79501976, grad/param norm = 2.7777e-01, time/batch = 0.6415s	
1505/16650 (epoch 4.520), train_loss = 1.88829982, grad/param norm = 2.8660e-01, time/batch = 0.6372s	
1506/16650 (epoch 4.523), train_loss = 1.82493114, grad/param norm = 2.7460e-01, time/batch = 0.6339s	
1507/16650 (epoch 4.526), train_loss = 1.78823722, grad/param norm = 2.6594e-01, time/batch = 0.6342s	
1508/16650 (epoch 4.529), train_loss = 1.98320352, grad/param norm = 2.4758e-01, time/batch = 0.6337s	
1509/16650 (epoch 4.532), train_loss = 1.70012812, grad/param norm = 2.7197e-01, time/batch = 0.6342s	
1510/16650 (epoch 4.535), train_loss = 1.62782682, grad/param norm = 2.3518e-01, time/batch = 0.6345s	
1511/16650 (epoch 4.538), train_loss = 1.78429949, grad/param norm = 2.6816e-01, time/batch = 0.6380s	
1512/16650 (epoch 4.541), train_loss = 1.95117576, grad/param norm = 2.7148e-01, time/batch = 0.6379s	
1513/16650 (epoch 4.544), train_loss = 2.02489295, grad/param norm = 3.0609e-01, time/batch = 0.6409s	
1514/16650 (epoch 4.547), train_loss = 1.59564749, grad/param norm = 2.5136e-01, time/batch = 0.6369s	
1515/16650 (epoch 4.550), train_loss = 1.70194131, grad/param norm = 2.4012e-01, time/batch = 0.6361s	
1516/16650 (epoch 4.553), train_loss = 1.86101521, grad/param norm = 2.8016e-01, time/batch = 0.6377s	
1517/16650 (epoch 4.556), train_loss = 1.64739509, grad/param norm = 2.4891e-01, time/batch = 0.6380s	
1518/16650 (epoch 4.559), train_loss = 1.54693076, grad/param norm = 2.3905e-01, time/batch = 0.6344s	
1519/16650 (epoch 4.562), train_loss = 1.79554763, grad/param norm = 2.5607e-01, time/batch = 0.6353s	
1520/16650 (epoch 4.565), train_loss = 1.49132063, grad/param norm = 2.4329e-01, time/batch = 0.6367s	
1521/16650 (epoch 4.568), train_loss = 1.53839773, grad/param norm = 2.3536e-01, time/batch = 0.6389s	
1522/16650 (epoch 4.571), train_loss = 1.63691149, grad/param norm = 3.1068e-01, time/batch = 0.6408s	
1523/16650 (epoch 4.574), train_loss = 1.74988622, grad/param norm = 2.8553e-01, time/batch = 0.6356s	
1524/16650 (epoch 4.577), train_loss = 1.71966930, grad/param norm = 2.6856e-01, time/batch = 0.6398s	
1525/16650 (epoch 4.580), train_loss = 1.67547103, grad/param norm = 2.8860e-01, time/batch = 0.6357s	
1526/16650 (epoch 4.583), train_loss = 1.60157379, grad/param norm = 2.8660e-01, time/batch = 0.6348s	
1527/16650 (epoch 4.586), train_loss = 1.86903793, grad/param norm = 3.0363e-01, time/batch = 0.6349s	
1528/16650 (epoch 4.589), train_loss = 1.54816680, grad/param norm = 2.2644e-01, time/batch = 0.6356s	
1529/16650 (epoch 4.592), train_loss = 1.75191408, grad/param norm = 2.7861e-01, time/batch = 0.6381s	
1530/16650 (epoch 4.595), train_loss = 1.62790427, grad/param norm = 3.2367e-01, time/batch = 0.6373s	
1531/16650 (epoch 4.598), train_loss = 1.62911199, grad/param norm = 2.9796e-01, time/batch = 0.6617s	
1532/16650 (epoch 4.601), train_loss = 1.69193552, grad/param norm = 2.9238e-01, time/batch = 0.6685s	
1533/16650 (epoch 4.604), train_loss = 1.84575966, grad/param norm = 2.7926e-01, time/batch = 0.6374s	
1534/16650 (epoch 4.607), train_loss = 1.73548234, grad/param norm = 2.5753e-01, time/batch = 0.6377s	
1535/16650 (epoch 4.610), train_loss = 1.67917722, grad/param norm = 2.6267e-01, time/batch = 0.6352s	
1536/16650 (epoch 4.613), train_loss = 1.90713632, grad/param norm = 2.8057e-01, time/batch = 0.6351s	
1537/16650 (epoch 4.616), train_loss = 1.98529407, grad/param norm = 3.1232e-01, time/batch = 0.6348s	
1538/16650 (epoch 4.619), train_loss = 1.70227145, grad/param norm = 3.0629e-01, time/batch = 0.6352s	
1539/16650 (epoch 4.622), train_loss = 1.52685358, grad/param norm = 2.7989e-01, time/batch = 0.6354s	
1540/16650 (epoch 4.625), train_loss = 1.71634600, grad/param norm = 2.6558e-01, time/batch = 0.6335s	
1541/16650 (epoch 4.628), train_loss = 1.67190313, grad/param norm = 2.6595e-01, time/batch = 0.6534s	
1542/16650 (epoch 4.631), train_loss = 1.72206933, grad/param norm = 2.6972e-01, time/batch = 0.6442s	
1543/16650 (epoch 4.634), train_loss = 1.87654780, grad/param norm = 2.7326e-01, time/batch = 0.6544s	
1544/16650 (epoch 4.637), train_loss = 1.94885657, grad/param norm = 2.6170e-01, time/batch = 0.6629s	
1545/16650 (epoch 4.640), train_loss = 1.72920619, grad/param norm = 2.5388e-01, time/batch = 0.6644s	
1546/16650 (epoch 4.643), train_loss = 1.85268089, grad/param norm = 3.1445e-01, time/batch = 0.6682s	
1547/16650 (epoch 4.646), train_loss = 1.98586981, grad/param norm = 3.4773e-01, time/batch = 0.6663s	
1548/16650 (epoch 4.649), train_loss = 1.73433947, grad/param norm = 2.5589e-01, time/batch = 0.6602s	
1549/16650 (epoch 4.652), train_loss = 1.95733443, grad/param norm = 3.0290e-01, time/batch = 0.6523s	
1550/16650 (epoch 4.655), train_loss = 1.84009069, grad/param norm = 2.7976e-01, time/batch = 0.6499s	
1551/16650 (epoch 4.658), train_loss = 1.64459761, grad/param norm = 2.8901e-01, time/batch = 0.6489s	
1552/16650 (epoch 4.661), train_loss = 1.85223711, grad/param norm = 2.4338e-01, time/batch = 0.6534s	
1553/16650 (epoch 4.664), train_loss = 1.78474392, grad/param norm = 2.5934e-01, time/batch = 0.6334s	
1554/16650 (epoch 4.667), train_loss = 1.91086004, grad/param norm = 2.4416e-01, time/batch = 0.6368s	
1555/16650 (epoch 4.670), train_loss = 1.61372037, grad/param norm = 2.5046e-01, time/batch = 0.6333s	
1556/16650 (epoch 4.673), train_loss = 1.54371932, grad/param norm = 2.3015e-01, time/batch = 0.6307s	
1557/16650 (epoch 4.676), train_loss = 1.74426962, grad/param norm = 2.4745e-01, time/batch = 0.6311s	
1558/16650 (epoch 4.679), train_loss = 1.64394759, grad/param norm = 2.4635e-01, time/batch = 0.6311s	
1559/16650 (epoch 4.682), train_loss = 1.84657521, grad/param norm = 2.4723e-01, time/batch = 0.6313s	
1560/16650 (epoch 4.685), train_loss = 1.66000877, grad/param norm = 2.6889e-01, time/batch = 0.6344s	
1561/16650 (epoch 4.688), train_loss = 1.77835214, grad/param norm = 2.9560e-01, time/batch = 0.6373s	
1562/16650 (epoch 4.691), train_loss = 1.79622608, grad/param norm = 2.7217e-01, time/batch = 0.6479s	
1563/16650 (epoch 4.694), train_loss = 1.61075185, grad/param norm = 2.7113e-01, time/batch = 0.6393s	
1564/16650 (epoch 4.697), train_loss = 1.51701009, grad/param norm = 2.3332e-01, time/batch = 0.6404s	
1565/16650 (epoch 4.700), train_loss = 1.84212261, grad/param norm = 2.5490e-01, time/batch = 0.6476s	
1566/16650 (epoch 4.703), train_loss = 1.69007371, grad/param norm = 2.7706e-01, time/batch = 0.6426s	
1567/16650 (epoch 4.706), train_loss = 1.82359763, grad/param norm = 3.1704e-01, time/batch = 0.6348s	
1568/16650 (epoch 4.709), train_loss = 1.68684798, grad/param norm = 2.9750e-01, time/batch = 0.6318s	
1569/16650 (epoch 4.712), train_loss = 1.63154961, grad/param norm = 2.4908e-01, time/batch = 0.6374s	
1570/16650 (epoch 4.715), train_loss = 1.88100415, grad/param norm = 2.6058e-01, time/batch = 0.6401s	
1571/16650 (epoch 4.718), train_loss = 1.94555425, grad/param norm = 2.7673e-01, time/batch = 0.6440s	
1572/16650 (epoch 4.721), train_loss = 1.85610801, grad/param norm = 2.7612e-01, time/batch = 0.6422s	
1573/16650 (epoch 4.724), train_loss = 1.94047820, grad/param norm = 2.8547e-01, time/batch = 0.6465s	
1574/16650 (epoch 4.727), train_loss = 1.79514315, grad/param norm = 2.7583e-01, time/batch = 0.6416s	
1575/16650 (epoch 4.730), train_loss = 1.68120024, grad/param norm = 2.8414e-01, time/batch = 0.6433s	
1576/16650 (epoch 4.733), train_loss = 1.88107753, grad/param norm = 2.5953e-01, time/batch = 0.6578s	
1577/16650 (epoch 4.736), train_loss = 1.63958342, grad/param norm = 2.4134e-01, time/batch = 0.6656s	
1578/16650 (epoch 4.739), train_loss = 1.77777419, grad/param norm = 2.5600e-01, time/batch = 0.6434s	
1579/16650 (epoch 4.742), train_loss = 1.79389575, grad/param norm = 2.7241e-01, time/batch = 0.6363s	
1580/16650 (epoch 4.745), train_loss = 1.46766021, grad/param norm = 2.3325e-01, time/batch = 0.6409s	
1581/16650 (epoch 4.748), train_loss = 1.66192928, grad/param norm = 2.6160e-01, time/batch = 0.6400s	
1582/16650 (epoch 4.751), train_loss = 1.83477401, grad/param norm = 2.8053e-01, time/batch = 0.6389s	
1583/16650 (epoch 4.754), train_loss = 1.94575685, grad/param norm = 2.9130e-01, time/batch = 0.6372s	
1584/16650 (epoch 4.757), train_loss = 1.83762308, grad/param norm = 2.7881e-01, time/batch = 0.6406s	
1585/16650 (epoch 4.760), train_loss = 1.75797279, grad/param norm = 2.8562e-01, time/batch = 0.6367s	
1586/16650 (epoch 4.763), train_loss = 1.64658546, grad/param norm = 2.7666e-01, time/batch = 0.6332s	
1587/16650 (epoch 4.766), train_loss = 1.77107763, grad/param norm = 2.6573e-01, time/batch = 0.6356s	
1588/16650 (epoch 4.769), train_loss = 1.69511529, grad/param norm = 2.4882e-01, time/batch = 0.6367s	
1589/16650 (epoch 4.772), train_loss = 1.66706327, grad/param norm = 2.2453e-01, time/batch = 0.6346s	
1590/16650 (epoch 4.775), train_loss = 1.72985070, grad/param norm = 2.4568e-01, time/batch = 0.6325s	
1591/16650 (epoch 4.778), train_loss = 1.59079927, grad/param norm = 2.5928e-01, time/batch = 0.6372s	
1592/16650 (epoch 4.781), train_loss = 1.80284691, grad/param norm = 2.5857e-01, time/batch = 0.6440s	
1593/16650 (epoch 4.784), train_loss = 1.83945049, grad/param norm = 2.7117e-01, time/batch = 0.6358s	
1594/16650 (epoch 4.787), train_loss = 1.85750172, grad/param norm = 2.5918e-01, time/batch = 0.6421s	
1595/16650 (epoch 4.790), train_loss = 1.66876642, grad/param norm = 2.9565e-01, time/batch = 0.6357s	
1596/16650 (epoch 4.793), train_loss = 1.65175086, grad/param norm = 3.0794e-01, time/batch = 0.6377s	
1597/16650 (epoch 4.796), train_loss = 2.11892857, grad/param norm = 3.3299e-01, time/batch = 0.6359s	
1598/16650 (epoch 4.799), train_loss = 1.93843535, grad/param norm = 2.6143e-01, time/batch = 0.6358s	
1599/16650 (epoch 4.802), train_loss = 1.72556859, grad/param norm = 2.6518e-01, time/batch = 0.6366s	
1600/16650 (epoch 4.805), train_loss = 1.67737710, grad/param norm = 2.4580e-01, time/batch = 0.6336s	
1601/16650 (epoch 4.808), train_loss = 1.74969247, grad/param norm = 2.3958e-01, time/batch = 0.6360s	
1602/16650 (epoch 4.811), train_loss = 1.83392515, grad/param norm = 2.4733e-01, time/batch = 0.6336s	
1603/16650 (epoch 4.814), train_loss = 1.65068720, grad/param norm = 2.5054e-01, time/batch = 0.6362s	
1604/16650 (epoch 4.817), train_loss = 1.72052965, grad/param norm = 2.5879e-01, time/batch = 0.6366s	
1605/16650 (epoch 4.820), train_loss = 1.80162711, grad/param norm = 2.5692e-01, time/batch = 0.6363s	
1606/16650 (epoch 4.823), train_loss = 1.58489413, grad/param norm = 2.2850e-01, time/batch = 0.6360s	
1607/16650 (epoch 4.826), train_loss = 1.68419201, grad/param norm = 2.3403e-01, time/batch = 0.6353s	
1608/16650 (epoch 4.829), train_loss = 1.97231057, grad/param norm = 2.6221e-01, time/batch = 0.6339s	
1609/16650 (epoch 4.832), train_loss = 1.91104798, grad/param norm = 2.6107e-01, time/batch = 0.6351s	
1610/16650 (epoch 4.835), train_loss = 1.88554568, grad/param norm = 2.8849e-01, time/batch = 0.6337s	
1611/16650 (epoch 4.838), train_loss = 1.62605970, grad/param norm = 3.0123e-01, time/batch = 0.6374s	
1612/16650 (epoch 4.841), train_loss = 1.57548140, grad/param norm = 2.3558e-01, time/batch = 0.6356s	
1613/16650 (epoch 4.844), train_loss = 1.71194942, grad/param norm = 2.5231e-01, time/batch = 0.6374s	
1614/16650 (epoch 4.847), train_loss = 1.92566050, grad/param norm = 2.7297e-01, time/batch = 0.6464s	
1615/16650 (epoch 4.850), train_loss = 1.65484545, grad/param norm = 2.7775e-01, time/batch = 0.6568s	
1616/16650 (epoch 4.853), train_loss = 1.77961971, grad/param norm = 2.3201e-01, time/batch = 0.6398s	
1617/16650 (epoch 4.856), train_loss = 1.63879227, grad/param norm = 2.5516e-01, time/batch = 0.6354s	
1618/16650 (epoch 4.859), train_loss = 1.74135155, grad/param norm = 2.5032e-01, time/batch = 0.6366s	
1619/16650 (epoch 4.862), train_loss = 1.71032803, grad/param norm = 2.5498e-01, time/batch = 0.6368s	
1620/16650 (epoch 4.865), train_loss = 1.44373215, grad/param norm = 2.4170e-01, time/batch = 0.6370s	
1621/16650 (epoch 4.868), train_loss = 1.74768161, grad/param norm = 2.4395e-01, time/batch = 0.6432s	
1622/16650 (epoch 4.871), train_loss = 1.76908225, grad/param norm = 2.5798e-01, time/batch = 0.6394s	
1623/16650 (epoch 4.874), train_loss = 1.79283392, grad/param norm = 2.8254e-01, time/batch = 0.6385s	
1624/16650 (epoch 4.877), train_loss = 1.56648558, grad/param norm = 2.5404e-01, time/batch = 0.6343s	
1625/16650 (epoch 4.880), train_loss = 1.68425907, grad/param norm = 3.1869e-01, time/batch = 0.6378s	
1626/16650 (epoch 4.883), train_loss = 1.80557679, grad/param norm = 2.8033e-01, time/batch = 0.6359s	
1627/16650 (epoch 4.886), train_loss = 1.80031768, grad/param norm = 2.5312e-01, time/batch = 0.6372s	
1628/16650 (epoch 4.889), train_loss = 1.65871572, grad/param norm = 2.6902e-01, time/batch = 0.6382s	
1629/16650 (epoch 4.892), train_loss = 1.60944090, grad/param norm = 2.2673e-01, time/batch = 0.6365s	
1630/16650 (epoch 4.895), train_loss = 1.84561990, grad/param norm = 2.8131e-01, time/batch = 0.6379s	
1631/16650 (epoch 4.898), train_loss = 1.78113356, grad/param norm = 2.8596e-01, time/batch = 0.6334s	
1632/16650 (epoch 4.901), train_loss = 1.69993682, grad/param norm = 2.2643e-01, time/batch = 0.6382s	
1633/16650 (epoch 4.904), train_loss = 1.64663664, grad/param norm = 2.5372e-01, time/batch = 0.6328s	
1634/16650 (epoch 4.907), train_loss = 1.72809358, grad/param norm = 2.4851e-01, time/batch = 0.6330s	
1635/16650 (epoch 4.910), train_loss = 1.77788200, grad/param norm = 2.7334e-01, time/batch = 0.6342s	
1636/16650 (epoch 4.913), train_loss = 1.65981138, grad/param norm = 2.6474e-01, time/batch = 0.6350s	
1637/16650 (epoch 4.916), train_loss = 1.76745670, grad/param norm = 2.5650e-01, time/batch = 0.6385s	
1638/16650 (epoch 4.919), train_loss = 1.86198688, grad/param norm = 2.7663e-01, time/batch = 0.6406s	
1639/16650 (epoch 4.922), train_loss = 1.85974938, grad/param norm = 2.5122e-01, time/batch = 0.6321s	
1640/16650 (epoch 4.925), train_loss = 1.72595895, grad/param norm = 2.8104e-01, time/batch = 0.6379s	
1641/16650 (epoch 4.928), train_loss = 1.67505280, grad/param norm = 2.2641e-01, time/batch = 0.6461s	
1642/16650 (epoch 4.931), train_loss = 1.73002015, grad/param norm = 2.5516e-01, time/batch = 0.6523s	
1643/16650 (epoch 4.934), train_loss = 1.62112418, grad/param norm = 2.5237e-01, time/batch = 0.6619s	
1644/16650 (epoch 4.937), train_loss = 1.71749938, grad/param norm = 2.5060e-01, time/batch = 0.6514s	
1645/16650 (epoch 4.940), train_loss = 1.64352691, grad/param norm = 2.3998e-01, time/batch = 0.6600s	
1646/16650 (epoch 4.943), train_loss = 1.62400729, grad/param norm = 2.3570e-01, time/batch = 0.6517s	
1647/16650 (epoch 4.946), train_loss = 1.62510574, grad/param norm = 2.4692e-01, time/batch = 0.6507s	
1648/16650 (epoch 4.949), train_loss = 1.73228141, grad/param norm = 2.5664e-01, time/batch = 0.6397s	
1649/16650 (epoch 4.952), train_loss = 1.39408387, grad/param norm = 2.6212e-01, time/batch = 0.6345s	
1650/16650 (epoch 4.955), train_loss = 1.66496065, grad/param norm = 2.7978e-01, time/batch = 0.6318s	
1651/16650 (epoch 4.958), train_loss = 1.82773659, grad/param norm = 3.0382e-01, time/batch = 0.6350s	
1652/16650 (epoch 4.961), train_loss = 1.65199011, grad/param norm = 2.5547e-01, time/batch = 0.6377s	
1653/16650 (epoch 4.964), train_loss = 1.62815581, grad/param norm = 2.8013e-01, time/batch = 0.6546s	
1654/16650 (epoch 4.967), train_loss = 1.87893395, grad/param norm = 2.8238e-01, time/batch = 0.6491s	
1655/16650 (epoch 4.970), train_loss = 1.48396039, grad/param norm = 2.3086e-01, time/batch = 0.6387s	
1656/16650 (epoch 4.973), train_loss = 1.73127279, grad/param norm = 2.9497e-01, time/batch = 0.6359s	
1657/16650 (epoch 4.976), train_loss = 1.61115379, grad/param norm = 2.5470e-01, time/batch = 0.6696s	
1658/16650 (epoch 4.979), train_loss = 1.81853374, grad/param norm = 2.6010e-01, time/batch = 0.6672s	
1659/16650 (epoch 4.982), train_loss = 1.73814718, grad/param norm = 2.8230e-01, time/batch = 0.6424s	
1660/16650 (epoch 4.985), train_loss = 1.62327677, grad/param norm = 2.7566e-01, time/batch = 0.6408s	
1661/16650 (epoch 4.988), train_loss = 2.00019588, grad/param norm = 2.7641e-01, time/batch = 0.6410s	
1662/16650 (epoch 4.991), train_loss = 1.64263285, grad/param norm = 2.5946e-01, time/batch = 0.6394s	
1663/16650 (epoch 4.994), train_loss = 1.69577487, grad/param norm = 2.4306e-01, time/batch = 0.6381s	
1664/16650 (epoch 4.997), train_loss = 1.79824879, grad/param norm = 2.6841e-01, time/batch = 0.6362s	
1665/16650 (epoch 5.000), train_loss = 1.84049921, grad/param norm = 3.1123e-01, time/batch = 0.6370s	
1666/16650 (epoch 5.003), train_loss = 1.82106159, grad/param norm = 2.8559e-01, time/batch = 0.6420s	
1667/16650 (epoch 5.006), train_loss = 1.84906363, grad/param norm = 2.7853e-01, time/batch = 0.6491s	
1668/16650 (epoch 5.009), train_loss = 1.94754975, grad/param norm = 2.8348e-01, time/batch = 0.6455s	
1669/16650 (epoch 5.012), train_loss = 2.00104071, grad/param norm = 2.8376e-01, time/batch = 0.6623s	
1670/16650 (epoch 5.015), train_loss = 1.88702578, grad/param norm = 2.7728e-01, time/batch = 0.6689s	
1671/16650 (epoch 5.018), train_loss = 1.48695583, grad/param norm = 2.5197e-01, time/batch = 0.6594s	
1672/16650 (epoch 5.021), train_loss = 1.88704710, grad/param norm = 2.7343e-01, time/batch = 0.6396s	
1673/16650 (epoch 5.024), train_loss = 1.70213903, grad/param norm = 2.4573e-01, time/batch = 0.6386s	
1674/16650 (epoch 5.027), train_loss = 1.84797962, grad/param norm = 2.6556e-01, time/batch = 0.6431s	
1675/16650 (epoch 5.030), train_loss = 1.62762112, grad/param norm = 2.5227e-01, time/batch = 0.6368s	
1676/16650 (epoch 5.033), train_loss = 1.71216640, grad/param norm = 2.3295e-01, time/batch = 0.6439s	
1677/16650 (epoch 5.036), train_loss = 1.61996793, grad/param norm = 2.8897e-01, time/batch = 0.6604s	
1678/16650 (epoch 5.039), train_loss = 1.81701540, grad/param norm = 3.0323e-01, time/batch = 0.6476s	
1679/16650 (epoch 5.042), train_loss = 1.85727653, grad/param norm = 2.7279e-01, time/batch = 0.6387s	
1680/16650 (epoch 5.045), train_loss = 1.64057145, grad/param norm = 2.4092e-01, time/batch = 0.6366s	
1681/16650 (epoch 5.048), train_loss = 1.73198648, grad/param norm = 2.4270e-01, time/batch = 0.6394s	
1682/16650 (epoch 5.051), train_loss = 1.73795178, grad/param norm = 2.5783e-01, time/batch = 0.6388s	
1683/16650 (epoch 5.054), train_loss = 1.72997583, grad/param norm = 2.4730e-01, time/batch = 0.6326s	
1684/16650 (epoch 5.057), train_loss = 1.65698089, grad/param norm = 2.4193e-01, time/batch = 0.6333s	
1685/16650 (epoch 5.060), train_loss = 1.59708910, grad/param norm = 2.6075e-01, time/batch = 0.6370s	
1686/16650 (epoch 5.063), train_loss = 1.68143143, grad/param norm = 2.3566e-01, time/batch = 0.6335s	
1687/16650 (epoch 5.066), train_loss = 1.89362962, grad/param norm = 3.0373e-01, time/batch = 0.6341s	
1688/16650 (epoch 5.069), train_loss = 1.88439239, grad/param norm = 2.5427e-01, time/batch = 0.6363s	
1689/16650 (epoch 5.072), train_loss = 1.69062643, grad/param norm = 2.5947e-01, time/batch = 0.6340s	
1690/16650 (epoch 5.075), train_loss = 1.69918655, grad/param norm = 2.4728e-01, time/batch = 0.6379s	
1691/16650 (epoch 5.078), train_loss = 1.72197452, grad/param norm = 2.3734e-01, time/batch = 0.6362s	
1692/16650 (epoch 5.081), train_loss = 1.73082494, grad/param norm = 2.5076e-01, time/batch = 0.6347s	
1693/16650 (epoch 5.084), train_loss = 1.79441451, grad/param norm = 2.4900e-01, time/batch = 0.6335s	
1694/16650 (epoch 5.087), train_loss = 1.74724314, grad/param norm = 2.5429e-01, time/batch = 0.6364s	
1695/16650 (epoch 5.090), train_loss = 1.60285453, grad/param norm = 2.4828e-01, time/batch = 0.6367s	
1696/16650 (epoch 5.093), train_loss = 2.03476458, grad/param norm = 2.6794e-01, time/batch = 0.6353s	
1697/16650 (epoch 5.096), train_loss = 1.67374109, grad/param norm = 2.4828e-01, time/batch = 0.6348s	
1698/16650 (epoch 5.099), train_loss = 1.65086133, grad/param norm = 2.4472e-01, time/batch = 0.6333s	
1699/16650 (epoch 5.102), train_loss = 1.69179350, grad/param norm = 2.4868e-01, time/batch = 0.6339s	
1700/16650 (epoch 5.105), train_loss = 1.81228943, grad/param norm = 2.6381e-01, time/batch = 0.6534s	
1701/16650 (epoch 5.108), train_loss = 1.87806252, grad/param norm = 2.7134e-01, time/batch = 0.6748s	
1702/16650 (epoch 5.111), train_loss = 1.71429078, grad/param norm = 2.3594e-01, time/batch = 0.6344s	
1703/16650 (epoch 5.114), train_loss = 1.89906440, grad/param norm = 2.5631e-01, time/batch = 0.6355s	
1704/16650 (epoch 5.117), train_loss = 1.80317375, grad/param norm = 2.5650e-01, time/batch = 0.6368s	
1705/16650 (epoch 5.120), train_loss = 1.62070436, grad/param norm = 2.7393e-01, time/batch = 0.6410s	
1706/16650 (epoch 5.123), train_loss = 1.69587090, grad/param norm = 2.4930e-01, time/batch = 0.6339s	
1707/16650 (epoch 5.126), train_loss = 1.78706069, grad/param norm = 3.0581e-01, time/batch = 0.6340s	
1708/16650 (epoch 5.129), train_loss = 1.80368397, grad/param norm = 2.4456e-01, time/batch = 0.6338s	
1709/16650 (epoch 5.132), train_loss = 1.90265869, grad/param norm = 2.5672e-01, time/batch = 0.6352s	
1710/16650 (epoch 5.135), train_loss = 1.75153723, grad/param norm = 2.5911e-01, time/batch = 0.6355s	
1711/16650 (epoch 5.138), train_loss = 1.75085635, grad/param norm = 2.8941e-01, time/batch = 0.6376s	
1712/16650 (epoch 5.141), train_loss = 1.82605597, grad/param norm = 2.6181e-01, time/batch = 0.6378s	
1713/16650 (epoch 5.144), train_loss = 1.72725403, grad/param norm = 2.3854e-01, time/batch = 0.6385s	
1714/16650 (epoch 5.147), train_loss = 1.84351570, grad/param norm = 2.6871e-01, time/batch = 0.6451s	
1715/16650 (epoch 5.150), train_loss = 1.94915374, grad/param norm = 2.5590e-01, time/batch = 0.6497s	
1716/16650 (epoch 5.153), train_loss = 1.70093860, grad/param norm = 2.5357e-01, time/batch = 0.6457s	
1717/16650 (epoch 5.156), train_loss = 1.54451907, grad/param norm = 2.4035e-01, time/batch = 0.6422s	
1718/16650 (epoch 5.159), train_loss = 1.89389539, grad/param norm = 2.6537e-01, time/batch = 0.6347s	
1719/16650 (epoch 5.162), train_loss = 1.73413701, grad/param norm = 2.7861e-01, time/batch = 0.6348s	
1720/16650 (epoch 5.165), train_loss = 1.76887047, grad/param norm = 2.7730e-01, time/batch = 0.6343s	
1721/16650 (epoch 5.168), train_loss = 1.44805947, grad/param norm = 2.5471e-01, time/batch = 0.6389s	
1722/16650 (epoch 5.171), train_loss = 1.80159258, grad/param norm = 2.2828e-01, time/batch = 0.6381s	
1723/16650 (epoch 5.174), train_loss = 1.57440192, grad/param norm = 2.4287e-01, time/batch = 0.6350s	
1724/16650 (epoch 5.177), train_loss = 1.72329831, grad/param norm = 2.4339e-01, time/batch = 0.6343s	
1725/16650 (epoch 5.180), train_loss = 1.86587642, grad/param norm = 2.3452e-01, time/batch = 0.6350s	
1726/16650 (epoch 5.183), train_loss = 1.96744931, grad/param norm = 2.4632e-01, time/batch = 0.6341s	
1727/16650 (epoch 5.186), train_loss = 1.84703531, grad/param norm = 2.5912e-01, time/batch = 0.6326s	
1728/16650 (epoch 5.189), train_loss = 1.61705867, grad/param norm = 2.2124e-01, time/batch = 0.6335s	
1729/16650 (epoch 5.192), train_loss = 1.64919125, grad/param norm = 2.5828e-01, time/batch = 0.6424s	
1730/16650 (epoch 5.195), train_loss = 1.72525883, grad/param norm = 2.5583e-01, time/batch = 0.6437s	
1731/16650 (epoch 5.198), train_loss = 1.47559667, grad/param norm = 2.5053e-01, time/batch = 0.6406s	
1732/16650 (epoch 5.201), train_loss = 1.73192183, grad/param norm = 2.3573e-01, time/batch = 0.6350s	
1733/16650 (epoch 5.204), train_loss = 1.72134007, grad/param norm = 2.9171e-01, time/batch = 0.6338s	
1734/16650 (epoch 5.207), train_loss = 1.79762578, grad/param norm = 2.9080e-01, time/batch = 0.6337s	
1735/16650 (epoch 5.210), train_loss = 1.63694581, grad/param norm = 2.3321e-01, time/batch = 0.6333s	
1736/16650 (epoch 5.213), train_loss = 1.76524655, grad/param norm = 2.6515e-01, time/batch = 0.6345s	
1737/16650 (epoch 5.216), train_loss = 1.71292810, grad/param norm = 2.7693e-01, time/batch = 0.6370s	
1738/16650 (epoch 5.219), train_loss = 1.70753101, grad/param norm = 2.6697e-01, time/batch = 0.6363s	
1739/16650 (epoch 5.222), train_loss = 1.72855136, grad/param norm = 2.5799e-01, time/batch = 0.6370s	
1740/16650 (epoch 5.225), train_loss = 1.72029608, grad/param norm = 2.6647e-01, time/batch = 0.6345s	
1741/16650 (epoch 5.228), train_loss = 1.65983590, grad/param norm = 2.6714e-01, time/batch = 0.6365s	
1742/16650 (epoch 5.231), train_loss = 1.73608662, grad/param norm = 2.6246e-01, time/batch = 0.6384s	
1743/16650 (epoch 5.234), train_loss = 1.81553691, grad/param norm = 2.5095e-01, time/batch = 0.6420s	
1744/16650 (epoch 5.237), train_loss = 1.64593737, grad/param norm = 2.5253e-01, time/batch = 0.6390s	
1745/16650 (epoch 5.240), train_loss = 1.76676413, grad/param norm = 2.3533e-01, time/batch = 0.6348s	
1746/16650 (epoch 5.243), train_loss = 1.76686875, grad/param norm = 2.6049e-01, time/batch = 0.6363s	
1747/16650 (epoch 5.246), train_loss = 1.93388721, grad/param norm = 3.0506e-01, time/batch = 0.6388s	
1748/16650 (epoch 5.249), train_loss = 1.58015510, grad/param norm = 2.5838e-01, time/batch = 0.6381s	
1749/16650 (epoch 5.252), train_loss = 1.71982310, grad/param norm = 2.6366e-01, time/batch = 0.6726s	
1750/16650 (epoch 5.255), train_loss = 1.86257562, grad/param norm = 3.2581e-01, time/batch = 0.6482s	
1751/16650 (epoch 5.258), train_loss = 1.77952627, grad/param norm = 2.8071e-01, time/batch = 0.6366s	
1752/16650 (epoch 5.261), train_loss = 1.74995144, grad/param norm = 2.7653e-01, time/batch = 0.6348s	
1753/16650 (epoch 5.264), train_loss = 1.70371020, grad/param norm = 2.5829e-01, time/batch = 0.6562s	
1754/16650 (epoch 5.267), train_loss = 1.59329017, grad/param norm = 2.4733e-01, time/batch = 0.6715s	
1755/16650 (epoch 5.270), train_loss = 1.63166334, grad/param norm = 2.2399e-01, time/batch = 0.6459s	
1756/16650 (epoch 5.273), train_loss = 1.82914891, grad/param norm = 2.4015e-01, time/batch = 0.6415s	
1757/16650 (epoch 5.276), train_loss = 1.70830423, grad/param norm = 2.5369e-01, time/batch = 0.6345s	
1758/16650 (epoch 5.279), train_loss = 1.71188134, grad/param norm = 2.4034e-01, time/batch = 0.6359s	
1759/16650 (epoch 5.282), train_loss = 1.52547766, grad/param norm = 2.2601e-01, time/batch = 0.6337s	
1760/16650 (epoch 5.285), train_loss = 1.54864123, grad/param norm = 2.3851e-01, time/batch = 0.6411s	
1761/16650 (epoch 5.288), train_loss = 1.66127074, grad/param norm = 2.3634e-01, time/batch = 0.6438s	
1762/16650 (epoch 5.291), train_loss = 1.41202636, grad/param norm = 2.2759e-01, time/batch = 0.6470s	
1763/16650 (epoch 5.294), train_loss = 1.49093940, grad/param norm = 2.2529e-01, time/batch = 0.6588s	
1764/16650 (epoch 5.297), train_loss = 1.54565169, grad/param norm = 2.2870e-01, time/batch = 0.6728s	
1765/16650 (epoch 5.300), train_loss = 1.46262453, grad/param norm = 2.5415e-01, time/batch = 0.6685s	
1766/16650 (epoch 5.303), train_loss = 1.44524594, grad/param norm = 2.5903e-01, time/batch = 0.6656s	
1767/16650 (epoch 5.306), train_loss = 1.80063327, grad/param norm = 3.0050e-01, time/batch = 0.6588s	
1768/16650 (epoch 5.309), train_loss = 1.84546030, grad/param norm = 2.7959e-01, time/batch = 0.6370s	
1769/16650 (epoch 5.312), train_loss = 1.59412379, grad/param norm = 2.5015e-01, time/batch = 0.6328s	
1770/16650 (epoch 5.315), train_loss = 1.42594737, grad/param norm = 2.2197e-01, time/batch = 0.6338s	
1771/16650 (epoch 5.318), train_loss = 1.54752115, grad/param norm = 2.5591e-01, time/batch = 0.6434s	
1772/16650 (epoch 5.321), train_loss = 1.91655151, grad/param norm = 3.1723e-01, time/batch = 0.6422s	
1773/16650 (epoch 5.324), train_loss = 1.73344920, grad/param norm = 2.6490e-01, time/batch = 0.6352s	
1774/16650 (epoch 5.327), train_loss = 1.84889109, grad/param norm = 2.8948e-01, time/batch = 0.6349s	
1775/16650 (epoch 5.330), train_loss = 1.78403652, grad/param norm = 2.7441e-01, time/batch = 0.6348s	
1776/16650 (epoch 5.333), train_loss = 1.82550628, grad/param norm = 2.6598e-01, time/batch = 0.6325s	
1777/16650 (epoch 5.336), train_loss = 1.52607944, grad/param norm = 2.3017e-01, time/batch = 0.6348s	
1778/16650 (epoch 5.339), train_loss = 1.66862609, grad/param norm = 2.6420e-01, time/batch = 0.6347s	
1779/16650 (epoch 5.342), train_loss = 1.70757189, grad/param norm = 2.8573e-01, time/batch = 0.6376s	
1780/16650 (epoch 5.345), train_loss = 1.56390038, grad/param norm = 2.5634e-01, time/batch = 0.6386s	
1781/16650 (epoch 5.348), train_loss = 1.65722728, grad/param norm = 2.5989e-01, time/batch = 0.6393s	
1782/16650 (epoch 5.351), train_loss = 1.81472117, grad/param norm = 2.6835e-01, time/batch = 0.6431s	
1783/16650 (epoch 5.354), train_loss = 1.84048423, grad/param norm = 2.6942e-01, time/batch = 0.6732s	
1784/16650 (epoch 5.357), train_loss = 1.75694267, grad/param norm = 2.6500e-01, time/batch = 0.6444s	
1785/16650 (epoch 5.360), train_loss = 1.74061955, grad/param norm = 2.5016e-01, time/batch = 0.6326s	
1786/16650 (epoch 5.363), train_loss = 1.86926513, grad/param norm = 2.8072e-01, time/batch = 0.6331s	
1787/16650 (epoch 5.366), train_loss = 1.87118451, grad/param norm = 2.6790e-01, time/batch = 0.6348s	
1788/16650 (epoch 5.369), train_loss = 1.72574717, grad/param norm = 2.6551e-01, time/batch = 0.6365s	
1789/16650 (epoch 5.372), train_loss = 1.73821877, grad/param norm = 2.6085e-01, time/batch = 0.6374s	
1790/16650 (epoch 5.375), train_loss = 1.64523603, grad/param norm = 2.3839e-01, time/batch = 0.6346s	
1791/16650 (epoch 5.378), train_loss = 1.49978543, grad/param norm = 2.7637e-01, time/batch = 0.6350s	
1792/16650 (epoch 5.381), train_loss = 1.74699523, grad/param norm = 2.8328e-01, time/batch = 0.6337s	
1793/16650 (epoch 5.384), train_loss = 1.74934674, grad/param norm = 2.5493e-01, time/batch = 0.6353s	
1794/16650 (epoch 5.387), train_loss = 1.50396406, grad/param norm = 2.7204e-01, time/batch = 0.6344s	
1795/16650 (epoch 5.390), train_loss = 1.76223137, grad/param norm = 2.6067e-01, time/batch = 0.6316s	
1796/16650 (epoch 5.393), train_loss = 1.68303706, grad/param norm = 2.8325e-01, time/batch = 0.6338s	
1797/16650 (epoch 5.396), train_loss = 1.86506511, grad/param norm = 2.5950e-01, time/batch = 0.6348s	
1798/16650 (epoch 5.399), train_loss = 1.78132717, grad/param norm = 2.5323e-01, time/batch = 0.6334s	
1799/16650 (epoch 5.402), train_loss = 1.55068827, grad/param norm = 2.3868e-01, time/batch = 0.6348s	
1800/16650 (epoch 5.405), train_loss = 1.52264498, grad/param norm = 2.2810e-01, time/batch = 0.6349s	
1801/16650 (epoch 5.408), train_loss = 1.84737720, grad/param norm = 2.7655e-01, time/batch = 0.6353s	
1802/16650 (epoch 5.411), train_loss = 1.58299405, grad/param norm = 2.6325e-01, time/batch = 0.6423s	
1803/16650 (epoch 5.414), train_loss = 1.48154969, grad/param norm = 2.3230e-01, time/batch = 0.6334s	
1804/16650 (epoch 5.417), train_loss = 1.48993533, grad/param norm = 2.0604e-01, time/batch = 0.6422s	
1805/16650 (epoch 5.420), train_loss = 1.52513781, grad/param norm = 2.5657e-01, time/batch = 0.6430s	
1806/16650 (epoch 5.423), train_loss = 1.23414267, grad/param norm = 2.3278e-01, time/batch = 0.6430s	
1807/16650 (epoch 5.426), train_loss = 1.66098739, grad/param norm = 2.7047e-01, time/batch = 0.6561s	
1808/16650 (epoch 5.429), train_loss = 1.77212623, grad/param norm = 2.6413e-01, time/batch = 0.6403s	
1809/16650 (epoch 5.432), train_loss = 1.69435992, grad/param norm = 2.7517e-01, time/batch = 0.6423s	
1810/16650 (epoch 5.435), train_loss = 1.92997800, grad/param norm = 2.6806e-01, time/batch = 0.6385s	
1811/16650 (epoch 5.438), train_loss = 1.88423785, grad/param norm = 2.7292e-01, time/batch = 0.6344s	
1812/16650 (epoch 5.441), train_loss = 1.81152926, grad/param norm = 2.4916e-01, time/batch = 0.6328s	
1813/16650 (epoch 5.444), train_loss = 1.63908054, grad/param norm = 2.4982e-01, time/batch = 0.6358s	
1814/16650 (epoch 5.447), train_loss = 1.68764276, grad/param norm = 2.7799e-01, time/batch = 0.6388s	
1815/16650 (epoch 5.450), train_loss = 1.57802969, grad/param norm = 2.7206e-01, time/batch = 0.6332s	
1816/16650 (epoch 5.453), train_loss = 1.69357641, grad/param norm = 2.4695e-01, time/batch = 0.6322s	
1817/16650 (epoch 5.456), train_loss = 1.52179094, grad/param norm = 2.6307e-01, time/batch = 0.6685s	
1818/16650 (epoch 5.459), train_loss = 1.63782679, grad/param norm = 2.4318e-01, time/batch = 0.6594s	
1819/16650 (epoch 5.462), train_loss = 1.91154437, grad/param norm = 2.6943e-01, time/batch = 0.6326s	
1820/16650 (epoch 5.465), train_loss = 1.63632698, grad/param norm = 2.6057e-01, time/batch = 0.6379s	
1821/16650 (epoch 5.468), train_loss = 1.31292254, grad/param norm = 2.3940e-01, time/batch = 0.6392s	
1822/16650 (epoch 5.471), train_loss = 1.30969754, grad/param norm = 2.5308e-01, time/batch = 0.6352s	
1823/16650 (epoch 5.474), train_loss = 1.45837074, grad/param norm = 2.2901e-01, time/batch = 0.6335s	
1824/16650 (epoch 5.477), train_loss = 1.68013523, grad/param norm = 2.5480e-01, time/batch = 0.6382s	
1825/16650 (epoch 5.480), train_loss = 1.75287491, grad/param norm = 2.5379e-01, time/batch = 0.6384s	
1826/16650 (epoch 5.483), train_loss = 1.85074243, grad/param norm = 2.5241e-01, time/batch = 0.6383s	
1827/16650 (epoch 5.486), train_loss = 1.47836313, grad/param norm = 2.9360e-01, time/batch = 0.6347s	
1828/16650 (epoch 5.489), train_loss = 1.66615996, grad/param norm = 2.9538e-01, time/batch = 0.6327s	
1829/16650 (epoch 5.492), train_loss = 1.67202772, grad/param norm = 2.4427e-01, time/batch = 0.6342s	
1830/16650 (epoch 5.495), train_loss = 1.54677770, grad/param norm = 2.6915e-01, time/batch = 0.6334s	
1831/16650 (epoch 5.498), train_loss = 1.73609686, grad/param norm = 2.6666e-01, time/batch = 0.6423s	
1832/16650 (epoch 5.502), train_loss = 1.93962554, grad/param norm = 2.6752e-01, time/batch = 0.6334s	
1833/16650 (epoch 5.505), train_loss = 1.68654863, grad/param norm = 2.3931e-01, time/batch = 0.6323s	
1834/16650 (epoch 5.508), train_loss = 1.71281483, grad/param norm = 2.4727e-01, time/batch = 0.6324s	
1835/16650 (epoch 5.511), train_loss = 1.90119548, grad/param norm = 3.1119e-01, time/batch = 0.6322s	
1836/16650 (epoch 5.514), train_loss = 1.56095288, grad/param norm = 2.3506e-01, time/batch = 0.6321s	
1837/16650 (epoch 5.517), train_loss = 1.68547117, grad/param norm = 2.7033e-01, time/batch = 0.6324s	
1838/16650 (epoch 5.520), train_loss = 1.75442395, grad/param norm = 2.7164e-01, time/batch = 0.6381s	
1839/16650 (epoch 5.523), train_loss = 1.67553105, grad/param norm = 2.4835e-01, time/batch = 0.6354s	
1840/16650 (epoch 5.526), train_loss = 1.67570884, grad/param norm = 2.4192e-01, time/batch = 0.6346s	
1841/16650 (epoch 5.529), train_loss = 1.89052852, grad/param norm = 2.4195e-01, time/batch = 0.6351s	
1842/16650 (epoch 5.532), train_loss = 1.55876520, grad/param norm = 2.5857e-01, time/batch = 0.6327s	
1843/16650 (epoch 5.535), train_loss = 1.53457872, grad/param norm = 2.4494e-01, time/batch = 0.6334s	
1844/16650 (epoch 5.538), train_loss = 1.64920909, grad/param norm = 2.5354e-01, time/batch = 0.6330s	
1845/16650 (epoch 5.541), train_loss = 1.85386634, grad/param norm = 2.6624e-01, time/batch = 0.6337s	
1846/16650 (epoch 5.544), train_loss = 1.91675516, grad/param norm = 2.8977e-01, time/batch = 0.6349s	
1847/16650 (epoch 5.547), train_loss = 1.48371392, grad/param norm = 2.3545e-01, time/batch = 0.6357s	
1848/16650 (epoch 5.550), train_loss = 1.58157363, grad/param norm = 2.4428e-01, time/batch = 0.6312s	
1849/16650 (epoch 5.553), train_loss = 1.73608593, grad/param norm = 2.7735e-01, time/batch = 0.6330s	
1850/16650 (epoch 5.556), train_loss = 1.54600237, grad/param norm = 2.4372e-01, time/batch = 0.6334s	
1851/16650 (epoch 5.559), train_loss = 1.43204565, grad/param norm = 2.2971e-01, time/batch = 0.6356s	
1852/16650 (epoch 5.562), train_loss = 1.68169042, grad/param norm = 2.4016e-01, time/batch = 0.6333s	
1853/16650 (epoch 5.565), train_loss = 1.37681591, grad/param norm = 2.3657e-01, time/batch = 0.6333s	
1854/16650 (epoch 5.568), train_loss = 1.41529414, grad/param norm = 2.2182e-01, time/batch = 0.6446s	
1855/16650 (epoch 5.571), train_loss = 1.50941848, grad/param norm = 2.8842e-01, time/batch = 0.6432s	
1856/16650 (epoch 5.574), train_loss = 1.63248665, grad/param norm = 2.6098e-01, time/batch = 0.6494s	
1857/16650 (epoch 5.577), train_loss = 1.60286365, grad/param norm = 2.4536e-01, time/batch = 0.6588s	
1858/16650 (epoch 5.580), train_loss = 1.53410204, grad/param norm = 2.6238e-01, time/batch = 0.6720s	
1859/16650 (epoch 5.583), train_loss = 1.49771270, grad/param norm = 2.7579e-01, time/batch = 0.6761s	
1860/16650 (epoch 5.586), train_loss = 1.74110137, grad/param norm = 2.8542e-01, time/batch = 0.6584s	
1861/16650 (epoch 5.589), train_loss = 1.42941869, grad/param norm = 2.1201e-01, time/batch = 0.6768s	
1862/16650 (epoch 5.592), train_loss = 1.65495942, grad/param norm = 2.7860e-01, time/batch = 0.6453s	
1863/16650 (epoch 5.595), train_loss = 1.52343872, grad/param norm = 2.9127e-01, time/batch = 0.6391s	
1864/16650 (epoch 5.598), train_loss = 1.52656466, grad/param norm = 2.7393e-01, time/batch = 0.6350s	
1865/16650 (epoch 5.601), train_loss = 1.57783548, grad/param norm = 2.9563e-01, time/batch = 0.6637s	
1866/16650 (epoch 5.604), train_loss = 1.73169874, grad/param norm = 2.7124e-01, time/batch = 0.6643s	
1867/16650 (epoch 5.607), train_loss = 1.62620105, grad/param norm = 2.4456e-01, time/batch = 0.6324s	
1868/16650 (epoch 5.610), train_loss = 1.54126416, grad/param norm = 2.2639e-01, time/batch = 0.6375s	
1869/16650 (epoch 5.613), train_loss = 1.79837180, grad/param norm = 2.7674e-01, time/batch = 0.6390s	
1870/16650 (epoch 5.616), train_loss = 1.86624561, grad/param norm = 3.1128e-01, time/batch = 0.6372s	
1871/16650 (epoch 5.619), train_loss = 1.56519393, grad/param norm = 2.8210e-01, time/batch = 0.6400s	
1872/16650 (epoch 5.622), train_loss = 1.41070473, grad/param norm = 2.5518e-01, time/batch = 0.6371s	
1873/16650 (epoch 5.625), train_loss = 1.58869302, grad/param norm = 2.4732e-01, time/batch = 0.6392s	
1874/16650 (epoch 5.628), train_loss = 1.57057964, grad/param norm = 2.5414e-01, time/batch = 0.6414s	
1875/16650 (epoch 5.631), train_loss = 1.61568328, grad/param norm = 2.7154e-01, time/batch = 0.6325s	
1876/16650 (epoch 5.634), train_loss = 1.79931972, grad/param norm = 2.6222e-01, time/batch = 0.6328s	
1877/16650 (epoch 5.637), train_loss = 1.85461774, grad/param norm = 2.5536e-01, time/batch = 0.6321s	
1878/16650 (epoch 5.640), train_loss = 1.61837896, grad/param norm = 2.4707e-01, time/batch = 0.6323s	
1879/16650 (epoch 5.643), train_loss = 1.74255275, grad/param norm = 2.9079e-01, time/batch = 0.6362s	
1880/16650 (epoch 5.646), train_loss = 1.84224713, grad/param norm = 3.3756e-01, time/batch = 0.6359s	
1881/16650 (epoch 5.649), train_loss = 1.63856982, grad/param norm = 2.5592e-01, time/batch = 0.6343s	
1882/16650 (epoch 5.652), train_loss = 1.84374488, grad/param norm = 2.9398e-01, time/batch = 0.6338s	
1883/16650 (epoch 5.655), train_loss = 1.70318485, grad/param norm = 2.8394e-01, time/batch = 0.6438s	
1884/16650 (epoch 5.658), train_loss = 1.54304249, grad/param norm = 2.9240e-01, time/batch = 0.6436s	
1885/16650 (epoch 5.661), train_loss = 1.73987758, grad/param norm = 2.3260e-01, time/batch = 0.6589s	
1886/16650 (epoch 5.664), train_loss = 1.67912086, grad/param norm = 2.5577e-01, time/batch = 0.6588s	
1887/16650 (epoch 5.667), train_loss = 1.80781236, grad/param norm = 2.4023e-01, time/batch = 0.6630s	
1888/16650 (epoch 5.670), train_loss = 1.50752241, grad/param norm = 2.4093e-01, time/batch = 0.6602s	
1889/16650 (epoch 5.673), train_loss = 1.46233069, grad/param norm = 2.2678e-01, time/batch = 0.6627s	
1890/16650 (epoch 5.676), train_loss = 1.65396448, grad/param norm = 2.4668e-01, time/batch = 0.6570s	
1891/16650 (epoch 5.679), train_loss = 1.53315522, grad/param norm = 2.3425e-01, time/batch = 0.6541s	
1892/16650 (epoch 5.682), train_loss = 1.74593960, grad/param norm = 2.5221e-01, time/batch = 0.6508s	
1893/16650 (epoch 5.685), train_loss = 1.53184201, grad/param norm = 2.5578e-01, time/batch = 0.6471s	
1894/16650 (epoch 5.688), train_loss = 1.65095177, grad/param norm = 2.8445e-01, time/batch = 0.6593s	
1895/16650 (epoch 5.691), train_loss = 1.69571328, grad/param norm = 2.6751e-01, time/batch = 0.6736s	
1896/16650 (epoch 5.694), train_loss = 1.49382860, grad/param norm = 2.5006e-01, time/batch = 0.6378s	
1897/16650 (epoch 5.697), train_loss = 1.41630185, grad/param norm = 2.2161e-01, time/batch = 0.6339s	
1898/16650 (epoch 5.700), train_loss = 1.74579348, grad/param norm = 2.4551e-01, time/batch = 0.6326s	
1899/16650 (epoch 5.703), train_loss = 1.59204761, grad/param norm = 2.8208e-01, time/batch = 0.6327s	
1900/16650 (epoch 5.706), train_loss = 1.71720043, grad/param norm = 2.7193e-01, time/batch = 0.6331s	
1901/16650 (epoch 5.709), train_loss = 1.55494427, grad/param norm = 2.6755e-01, time/batch = 0.6345s	
1902/16650 (epoch 5.712), train_loss = 1.54955861, grad/param norm = 2.5634e-01, time/batch = 0.6349s	
1903/16650 (epoch 5.715), train_loss = 1.76950389, grad/param norm = 2.5114e-01, time/batch = 0.6385s	
1904/16650 (epoch 5.718), train_loss = 1.84701457, grad/param norm = 2.6347e-01, time/batch = 0.6380s	
1905/16650 (epoch 5.721), train_loss = 1.76684736, grad/param norm = 2.5787e-01, time/batch = 0.6333s	
1906/16650 (epoch 5.724), train_loss = 1.83764433, grad/param norm = 2.6680e-01, time/batch = 0.6319s	
1907/16650 (epoch 5.727), train_loss = 1.69537374, grad/param norm = 2.3973e-01, time/batch = 0.6325s	
1908/16650 (epoch 5.730), train_loss = 1.58339809, grad/param norm = 2.6099e-01, time/batch = 0.6383s	
1909/16650 (epoch 5.733), train_loss = 1.77700265, grad/param norm = 2.5781e-01, time/batch = 0.6373s	
1910/16650 (epoch 5.736), train_loss = 1.52942848, grad/param norm = 2.3750e-01, time/batch = 0.6344s	
1911/16650 (epoch 5.739), train_loss = 1.67635010, grad/param norm = 2.4973e-01, time/batch = 0.6371s	
1912/16650 (epoch 5.742), train_loss = 1.68465258, grad/param norm = 2.6145e-01, time/batch = 0.6451s	
1913/16650 (epoch 5.745), train_loss = 1.37462144, grad/param norm = 2.1549e-01, time/batch = 0.6498s	
1914/16650 (epoch 5.748), train_loss = 1.54312202, grad/param norm = 2.5307e-01, time/batch = 0.6415s	
1915/16650 (epoch 5.751), train_loss = 1.73794847, grad/param norm = 2.8849e-01, time/batch = 0.6374s	
1916/16650 (epoch 5.754), train_loss = 1.84535845, grad/param norm = 2.6880e-01, time/batch = 0.6352s	
1917/16650 (epoch 5.757), train_loss = 1.73691681, grad/param norm = 2.6091e-01, time/batch = 0.6376s	
1918/16650 (epoch 5.760), train_loss = 1.62793770, grad/param norm = 2.7057e-01, time/batch = 0.6347s	
1919/16650 (epoch 5.763), train_loss = 1.54599899, grad/param norm = 2.5629e-01, time/batch = 0.6348s	
1920/16650 (epoch 5.766), train_loss = 1.66296485, grad/param norm = 2.5593e-01, time/batch = 0.6345s	
1921/16650 (epoch 5.769), train_loss = 1.59765745, grad/param norm = 2.5082e-01, time/batch = 0.6381s	
1922/16650 (epoch 5.772), train_loss = 1.55085080, grad/param norm = 2.1871e-01, time/batch = 0.6339s	
1923/16650 (epoch 5.775), train_loss = 1.62553630, grad/param norm = 2.2970e-01, time/batch = 0.6386s	
1924/16650 (epoch 5.778), train_loss = 1.48840115, grad/param norm = 2.4479e-01, time/batch = 0.6324s	
1925/16650 (epoch 5.781), train_loss = 1.70069752, grad/param norm = 2.5050e-01, time/batch = 0.6329s	
1926/16650 (epoch 5.784), train_loss = 1.73671215, grad/param norm = 2.6027e-01, time/batch = 0.6325s	
1927/16650 (epoch 5.787), train_loss = 1.75863590, grad/param norm = 2.5310e-01, time/batch = 0.6402s	
1928/16650 (epoch 5.790), train_loss = 1.57210640, grad/param norm = 2.6282e-01, time/batch = 0.6406s	
1929/16650 (epoch 5.793), train_loss = 1.54732427, grad/param norm = 2.9420e-01, time/batch = 0.6567s	
1930/16650 (epoch 5.796), train_loss = 2.03417883, grad/param norm = 3.0806e-01, time/batch = 0.6378s	
1931/16650 (epoch 5.799), train_loss = 1.84784512, grad/param norm = 2.4247e-01, time/batch = 0.6337s	
1932/16650 (epoch 5.802), train_loss = 1.63567547, grad/param norm = 2.6175e-01, time/batch = 0.6334s	
1933/16650 (epoch 5.805), train_loss = 1.59874503, grad/param norm = 2.4047e-01, time/batch = 0.6330s	
1934/16650 (epoch 5.808), train_loss = 1.64167265, grad/param norm = 2.3523e-01, time/batch = 0.6351s	
1935/16650 (epoch 5.811), train_loss = 1.74748765, grad/param norm = 2.4217e-01, time/batch = 0.6335s	
1936/16650 (epoch 5.814), train_loss = 1.53474434, grad/param norm = 2.2910e-01, time/batch = 0.6326s	
1937/16650 (epoch 5.817), train_loss = 1.61507222, grad/param norm = 2.4461e-01, time/batch = 0.6349s	
1938/16650 (epoch 5.820), train_loss = 1.69438820, grad/param norm = 2.5200e-01, time/batch = 0.6357s	
1939/16650 (epoch 5.823), train_loss = 1.48794060, grad/param norm = 2.3183e-01, time/batch = 0.6426s	
1940/16650 (epoch 5.826), train_loss = 1.59302390, grad/param norm = 2.2956e-01, time/batch = 0.6535s	
1941/16650 (epoch 5.829), train_loss = 1.83620658, grad/param norm = 2.5440e-01, time/batch = 0.6485s	
1942/16650 (epoch 5.832), train_loss = 1.80278032, grad/param norm = 2.5343e-01, time/batch = 0.6438s	
1943/16650 (epoch 5.835), train_loss = 1.78809621, grad/param norm = 2.9011e-01, time/batch = 0.6736s	
1944/16650 (epoch 5.838), train_loss = 1.52440810, grad/param norm = 2.8013e-01, time/batch = 0.6485s	
1945/16650 (epoch 5.841), train_loss = 1.47153968, grad/param norm = 2.2245e-01, time/batch = 0.6328s	
1946/16650 (epoch 5.844), train_loss = 1.59934550, grad/param norm = 2.5083e-01, time/batch = 0.6348s	
1947/16650 (epoch 5.847), train_loss = 1.80128866, grad/param norm = 2.5319e-01, time/batch = 0.6402s	
1948/16650 (epoch 5.850), train_loss = 1.54220680, grad/param norm = 2.7086e-01, time/batch = 0.6544s	
1949/16650 (epoch 5.853), train_loss = 1.68738743, grad/param norm = 2.3969e-01, time/batch = 0.6499s	
1950/16650 (epoch 5.856), train_loss = 1.53580994, grad/param norm = 2.4440e-01, time/batch = 0.6558s	
1951/16650 (epoch 5.859), train_loss = 1.65640111, grad/param norm = 2.4760e-01, time/batch = 0.6581s	
1952/16650 (epoch 5.862), train_loss = 1.61556093, grad/param norm = 2.4184e-01, time/batch = 0.6484s	
1953/16650 (epoch 5.865), train_loss = 1.35238616, grad/param norm = 2.2811e-01, time/batch = 0.6362s	
1954/16650 (epoch 5.868), train_loss = 1.67310633, grad/param norm = 2.3778e-01, time/batch = 0.6390s	
1955/16650 (epoch 5.871), train_loss = 1.69651154, grad/param norm = 2.5894e-01, time/batch = 0.6376s	
1956/16650 (epoch 5.874), train_loss = 1.70114320, grad/param norm = 2.6829e-01, time/batch = 0.6359s	
1957/16650 (epoch 5.877), train_loss = 1.48792536, grad/param norm = 2.3725e-01, time/batch = 0.6331s	
1958/16650 (epoch 5.880), train_loss = 1.58496408, grad/param norm = 2.9570e-01, time/batch = 0.6367s	
1959/16650 (epoch 5.883), train_loss = 1.70324502, grad/param norm = 2.5464e-01, time/batch = 0.6356s	
1960/16650 (epoch 5.886), train_loss = 1.70083793, grad/param norm = 2.4140e-01, time/batch = 0.6319s	
1961/16650 (epoch 5.889), train_loss = 1.54468152, grad/param norm = 2.5538e-01, time/batch = 0.6502s	
1962/16650 (epoch 5.892), train_loss = 1.52692819, grad/param norm = 2.1381e-01, time/batch = 0.6350s	
1963/16650 (epoch 5.895), train_loss = 1.74508860, grad/param norm = 2.6715e-01, time/batch = 0.6367s	
1964/16650 (epoch 5.898), train_loss = 1.69199125, grad/param norm = 2.7682e-01, time/batch = 0.6382s	
1965/16650 (epoch 5.901), train_loss = 1.62190146, grad/param norm = 2.2023e-01, time/batch = 0.6347s	
1966/16650 (epoch 5.904), train_loss = 1.55452898, grad/param norm = 2.4069e-01, time/batch = 0.6336s	
1967/16650 (epoch 5.907), train_loss = 1.63226567, grad/param norm = 2.4765e-01, time/batch = 0.6369s	
1968/16650 (epoch 5.910), train_loss = 1.67777780, grad/param norm = 2.6983e-01, time/batch = 0.6407s	
1969/16650 (epoch 5.913), train_loss = 1.57010660, grad/param norm = 2.5517e-01, time/batch = 0.6381s	
1970/16650 (epoch 5.916), train_loss = 1.66812782, grad/param norm = 2.5027e-01, time/batch = 0.6370s	
1971/16650 (epoch 5.919), train_loss = 1.76437152, grad/param norm = 2.7224e-01, time/batch = 0.6418s	
1972/16650 (epoch 5.922), train_loss = 1.75909208, grad/param norm = 2.5892e-01, time/batch = 0.6384s	
1973/16650 (epoch 5.925), train_loss = 1.61681811, grad/param norm = 2.6714e-01, time/batch = 0.6430s	
1974/16650 (epoch 5.928), train_loss = 1.58556813, grad/param norm = 2.2557e-01, time/batch = 0.6369s	
1975/16650 (epoch 5.931), train_loss = 1.63467170, grad/param norm = 2.4220e-01, time/batch = 0.6352s	
1976/16650 (epoch 5.934), train_loss = 1.50197253, grad/param norm = 2.4046e-01, time/batch = 0.6342s	
1977/16650 (epoch 5.937), train_loss = 1.61694204, grad/param norm = 2.3958e-01, time/batch = 0.6711s	
1978/16650 (epoch 5.940), train_loss = 1.54835980, grad/param norm = 2.2473e-01, time/batch = 0.6557s	
1979/16650 (epoch 5.943), train_loss = 1.52229655, grad/param norm = 2.2105e-01, time/batch = 0.6362s	
1980/16650 (epoch 5.946), train_loss = 1.53937982, grad/param norm = 2.3834e-01, time/batch = 0.6391s	
1981/16650 (epoch 5.949), train_loss = 1.61853610, grad/param norm = 2.3542e-01, time/batch = 0.6394s	
1982/16650 (epoch 5.952), train_loss = 1.30959653, grad/param norm = 2.6445e-01, time/batch = 0.6340s	
1983/16650 (epoch 5.955), train_loss = 1.56111504, grad/param norm = 2.6054e-01, time/batch = 0.6336s	
1984/16650 (epoch 5.958), train_loss = 1.73593645, grad/param norm = 2.8093e-01, time/batch = 0.6333s	
1985/16650 (epoch 5.961), train_loss = 1.54670567, grad/param norm = 2.4313e-01, time/batch = 0.6325s	
1986/16650 (epoch 5.964), train_loss = 1.52632120, grad/param norm = 2.6024e-01, time/batch = 0.6340s	
1987/16650 (epoch 5.967), train_loss = 1.79591665, grad/param norm = 2.7281e-01, time/batch = 0.6352s	
1988/16650 (epoch 5.970), train_loss = 1.38781931, grad/param norm = 2.2054e-01, time/batch = 0.6372s	
1989/16650 (epoch 5.973), train_loss = 1.63019354, grad/param norm = 2.8989e-01, time/batch = 0.6349s	
1990/16650 (epoch 5.976), train_loss = 1.52249471, grad/param norm = 2.4067e-01, time/batch = 0.6340s	
1991/16650 (epoch 5.979), train_loss = 1.72960425, grad/param norm = 2.5302e-01, time/batch = 0.6380s	
1992/16650 (epoch 5.982), train_loss = 1.66113884, grad/param norm = 2.7193e-01, time/batch = 0.6395s	
1993/16650 (epoch 5.985), train_loss = 1.53338269, grad/param norm = 2.5368e-01, time/batch = 0.6353s	
1994/16650 (epoch 5.988), train_loss = 1.90758574, grad/param norm = 2.7898e-01, time/batch = 0.6388s	
1995/16650 (epoch 5.991), train_loss = 1.54699261, grad/param norm = 2.5857e-01, time/batch = 0.6372s	
1996/16650 (epoch 5.994), train_loss = 1.59080065, grad/param norm = 2.3404e-01, time/batch = 0.6374s	
1997/16650 (epoch 5.997), train_loss = 1.70635161, grad/param norm = 2.5962e-01, time/batch = 0.6392s	
1998/16650 (epoch 6.000), train_loss = 1.75235121, grad/param norm = 2.8621e-01, time/batch = 0.6469s	
1999/16650 (epoch 6.003), train_loss = 1.72183633, grad/param norm = 2.6684e-01, time/batch = 0.6419s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch6.01_1.8416.t7	
2000/16650 (epoch 6.006), train_loss = 1.75160830, grad/param norm = 2.6729e-01, time/batch = 0.6394s	
2001/16650 (epoch 6.009), train_loss = 2.00544949, grad/param norm = 2.8349e-01, time/batch = 0.6485s	
2002/16650 (epoch 6.012), train_loss = 1.90489363, grad/param norm = 2.8620e-01, time/batch = 0.6366s	
2003/16650 (epoch 6.015), train_loss = 1.76461723, grad/param norm = 2.5283e-01, time/batch = 0.6427s	
2004/16650 (epoch 6.018), train_loss = 1.37731603, grad/param norm = 2.4620e-01, time/batch = 0.6390s	
2005/16650 (epoch 6.021), train_loss = 1.78691650, grad/param norm = 2.5395e-01, time/batch = 0.6421s	
2006/16650 (epoch 6.024), train_loss = 1.59143418, grad/param norm = 2.4497e-01, time/batch = 0.6520s	
2007/16650 (epoch 6.027), train_loss = 1.76952366, grad/param norm = 2.7069e-01, time/batch = 0.6542s	
2008/16650 (epoch 6.030), train_loss = 1.51454522, grad/param norm = 2.4126e-01, time/batch = 0.6459s	
2009/16650 (epoch 6.033), train_loss = 1.63000291, grad/param norm = 2.3345e-01, time/batch = 0.6386s	
2010/16650 (epoch 6.036), train_loss = 1.50059548, grad/param norm = 2.7994e-01, time/batch = 0.6336s	
2011/16650 (epoch 6.039), train_loss = 1.72217288, grad/param norm = 2.9126e-01, time/batch = 0.6347s	
2012/16650 (epoch 6.042), train_loss = 1.74947236, grad/param norm = 2.5120e-01, time/batch = 0.6344s	
2013/16650 (epoch 6.045), train_loss = 1.54307167, grad/param norm = 2.2934e-01, time/batch = 0.6344s	
2014/16650 (epoch 6.048), train_loss = 1.65759697, grad/param norm = 2.3955e-01, time/batch = 0.6350s	
2015/16650 (epoch 6.051), train_loss = 1.65178060, grad/param norm = 2.5175e-01, time/batch = 0.6362s	
2016/16650 (epoch 6.054), train_loss = 1.63243743, grad/param norm = 2.3684e-01, time/batch = 0.6370s	
2017/16650 (epoch 6.057), train_loss = 1.57874147, grad/param norm = 2.4619e-01, time/batch = 0.6401s	
2018/16650 (epoch 6.060), train_loss = 1.49951484, grad/param norm = 2.4209e-01, time/batch = 0.6362s	
2019/16650 (epoch 6.063), train_loss = 1.60211116, grad/param norm = 2.3348e-01, time/batch = 0.6371s	
2020/16650 (epoch 6.066), train_loss = 1.81104147, grad/param norm = 2.8890e-01, time/batch = 0.6364s	
2021/16650 (epoch 6.069), train_loss = 1.77456784, grad/param norm = 2.5723e-01, time/batch = 0.6388s	
2022/16650 (epoch 6.072), train_loss = 1.59095003, grad/param norm = 2.5160e-01, time/batch = 0.6342s	
2023/16650 (epoch 6.075), train_loss = 1.61932420, grad/param norm = 2.4963e-01, time/batch = 0.6339s	
2024/16650 (epoch 6.078), train_loss = 1.64650106, grad/param norm = 2.4595e-01, time/batch = 0.6342s	
2025/16650 (epoch 6.081), train_loss = 1.61769870, grad/param norm = 2.6412e-01, time/batch = 0.6340s	
2026/16650 (epoch 6.084), train_loss = 1.70832994, grad/param norm = 2.3950e-01, time/batch = 0.6385s	
2027/16650 (epoch 6.087), train_loss = 1.64712704, grad/param norm = 2.3376e-01, time/batch = 0.6378s	
2028/16650 (epoch 6.090), train_loss = 1.49736898, grad/param norm = 2.3169e-01, time/batch = 0.6439s	
2029/16650 (epoch 6.093), train_loss = 1.94057097, grad/param norm = 2.6296e-01, time/batch = 0.6341s	
2030/16650 (epoch 6.096), train_loss = 1.57903876, grad/param norm = 2.3711e-01, time/batch = 0.6339s	
2031/16650 (epoch 6.099), train_loss = 1.56486624, grad/param norm = 2.3839e-01, time/batch = 0.6353s	
2032/16650 (epoch 6.102), train_loss = 1.60860004, grad/param norm = 2.4375e-01, time/batch = 0.6360s	
2033/16650 (epoch 6.105), train_loss = 1.72590580, grad/param norm = 2.5156e-01, time/batch = 0.6385s	
2034/16650 (epoch 6.108), train_loss = 1.75471634, grad/param norm = 2.5255e-01, time/batch = 0.6400s	
2035/16650 (epoch 6.111), train_loss = 1.63510413, grad/param norm = 2.3144e-01, time/batch = 0.6426s	
2036/16650 (epoch 6.114), train_loss = 1.79444788, grad/param norm = 2.3821e-01, time/batch = 0.6405s	
2037/16650 (epoch 6.117), train_loss = 1.71634042, grad/param norm = 2.5851e-01, time/batch = 0.6526s	
2038/16650 (epoch 6.120), train_loss = 1.52203323, grad/param norm = 2.5050e-01, time/batch = 0.6605s	
2039/16650 (epoch 6.123), train_loss = 1.60807731, grad/param norm = 2.5066e-01, time/batch = 0.6761s	
2040/16650 (epoch 6.126), train_loss = 1.69558035, grad/param norm = 2.9694e-01, time/batch = 0.6590s	
2041/16650 (epoch 6.129), train_loss = 1.70265864, grad/param norm = 2.3964e-01, time/batch = 0.6359s	
2042/16650 (epoch 6.132), train_loss = 1.79501848, grad/param norm = 2.5325e-01, time/batch = 0.6397s	
2043/16650 (epoch 6.135), train_loss = 1.67533428, grad/param norm = 2.6469e-01, time/batch = 0.6391s	
2044/16650 (epoch 6.138), train_loss = 1.68258970, grad/param norm = 2.8611e-01, time/batch = 0.6440s	
2045/16650 (epoch 6.141), train_loss = 1.73502966, grad/param norm = 2.6120e-01, time/batch = 0.6374s	
2046/16650 (epoch 6.144), train_loss = 1.62300217, grad/param norm = 2.3380e-01, time/batch = 0.6392s	
2047/16650 (epoch 6.147), train_loss = 1.76495198, grad/param norm = 2.7035e-01, time/batch = 0.6354s	
2048/16650 (epoch 6.150), train_loss = 1.87037729, grad/param norm = 2.5509e-01, time/batch = 0.6344s	
2049/16650 (epoch 6.153), train_loss = 1.61413047, grad/param norm = 2.4499e-01, time/batch = 0.6378s	
2050/16650 (epoch 6.156), train_loss = 1.44731558, grad/param norm = 2.3016e-01, time/batch = 0.6504s	
2051/16650 (epoch 6.159), train_loss = 1.80789454, grad/param norm = 2.5537e-01, time/batch = 0.6445s	
2052/16650 (epoch 6.162), train_loss = 1.66959952, grad/param norm = 2.6336e-01, time/batch = 0.6335s	
2053/16650 (epoch 6.165), train_loss = 1.68966130, grad/param norm = 2.6742e-01, time/batch = 0.6362s	
2054/16650 (epoch 6.168), train_loss = 1.35054236, grad/param norm = 2.3398e-01, time/batch = 0.6361s	
2055/16650 (epoch 6.171), train_loss = 1.70372584, grad/param norm = 2.2707e-01, time/batch = 0.6337s	
2056/16650 (epoch 6.174), train_loss = 1.48588074, grad/param norm = 2.3814e-01, time/batch = 0.6453s	
2057/16650 (epoch 6.177), train_loss = 1.62942575, grad/param norm = 2.3258e-01, time/batch = 0.6456s	
2058/16650 (epoch 6.180), train_loss = 1.78343463, grad/param norm = 2.2959e-01, time/batch = 0.6380s	
2059/16650 (epoch 6.183), train_loss = 1.89131424, grad/param norm = 2.4873e-01, time/batch = 0.6397s	
2060/16650 (epoch 6.186), train_loss = 1.74939332, grad/param norm = 2.4782e-01, time/batch = 0.6333s	
2061/16650 (epoch 6.189), train_loss = 1.52699919, grad/param norm = 2.1718e-01, time/batch = 0.6383s	
2062/16650 (epoch 6.192), train_loss = 1.55667836, grad/param norm = 2.5697e-01, time/batch = 0.6354s	
2063/16650 (epoch 6.195), train_loss = 1.63621046, grad/param norm = 2.5883e-01, time/batch = 0.6346s	
2064/16650 (epoch 6.198), train_loss = 1.37849193, grad/param norm = 2.4937e-01, time/batch = 0.6346s	
2065/16650 (epoch 6.201), train_loss = 1.63006728, grad/param norm = 2.3570e-01, time/batch = 0.6366s	
2066/16650 (epoch 6.204), train_loss = 1.62452369, grad/param norm = 2.7266e-01, time/batch = 0.6361s	
2067/16650 (epoch 6.207), train_loss = 1.70510162, grad/param norm = 2.7295e-01, time/batch = 0.6359s	
2068/16650 (epoch 6.210), train_loss = 1.54394223, grad/param norm = 2.2835e-01, time/batch = 0.6350s	
2069/16650 (epoch 6.213), train_loss = 1.68295925, grad/param norm = 2.5387e-01, time/batch = 0.6470s	
2070/16650 (epoch 6.216), train_loss = 1.62340775, grad/param norm = 2.6934e-01, time/batch = 0.6335s	
2071/16650 (epoch 6.219), train_loss = 1.62187035, grad/param norm = 2.6726e-01, time/batch = 0.6355s	
2072/16650 (epoch 6.222), train_loss = 1.63425043, grad/param norm = 2.5344e-01, time/batch = 0.6344s	
2073/16650 (epoch 6.225), train_loss = 1.64682248, grad/param norm = 2.6460e-01, time/batch = 0.6348s	
2074/16650 (epoch 6.228), train_loss = 1.56467984, grad/param norm = 2.5965e-01, time/batch = 0.6407s	
2075/16650 (epoch 6.231), train_loss = 1.63498539, grad/param norm = 2.4799e-01, time/batch = 0.6392s	
2076/16650 (epoch 6.234), train_loss = 1.73632207, grad/param norm = 2.3864e-01, time/batch = 0.6371s	
2077/16650 (epoch 6.237), train_loss = 1.58247513, grad/param norm = 2.4477e-01, time/batch = 0.6339s	
2078/16650 (epoch 6.240), train_loss = 1.68349771, grad/param norm = 2.3448e-01, time/batch = 0.6331s	
2079/16650 (epoch 6.243), train_loss = 1.67757864, grad/param norm = 2.5475e-01, time/batch = 0.6326s	
2080/16650 (epoch 6.246), train_loss = 1.80721740, grad/param norm = 2.8277e-01, time/batch = 0.6326s	
2081/16650 (epoch 6.249), train_loss = 1.49105625, grad/param norm = 2.3974e-01, time/batch = 0.6350s	
2082/16650 (epoch 6.252), train_loss = 1.62483052, grad/param norm = 2.5959e-01, time/batch = 0.6435s	
2083/16650 (epoch 6.255), train_loss = 1.78375590, grad/param norm = 3.1218e-01, time/batch = 0.6737s	
2084/16650 (epoch 6.258), train_loss = 1.69944426, grad/param norm = 2.7176e-01, time/batch = 0.6468s	
2085/16650 (epoch 6.261), train_loss = 1.64134408, grad/param norm = 2.6366e-01, time/batch = 0.6358s	
2086/16650 (epoch 6.264), train_loss = 1.60988706, grad/param norm = 2.4813e-01, time/batch = 0.6377s	
2087/16650 (epoch 6.267), train_loss = 1.51470214, grad/param norm = 2.5146e-01, time/batch = 0.6396s	
2088/16650 (epoch 6.270), train_loss = 1.56815938, grad/param norm = 2.2278e-01, time/batch = 0.6375s	
2089/16650 (epoch 6.273), train_loss = 1.74664829, grad/param norm = 2.3074e-01, time/batch = 0.6372s	
2090/16650 (epoch 6.276), train_loss = 1.62216521, grad/param norm = 2.4661e-01, time/batch = 0.6378s	
2091/16650 (epoch 6.279), train_loss = 1.61985584, grad/param norm = 2.3114e-01, time/batch = 0.6386s	
2092/16650 (epoch 6.282), train_loss = 1.42754380, grad/param norm = 2.1399e-01, time/batch = 0.6371s	
2093/16650 (epoch 6.285), train_loss = 1.47286147, grad/param norm = 2.4373e-01, time/batch = 0.6369s	
2094/16650 (epoch 6.288), train_loss = 1.56566429, grad/param norm = 2.2547e-01, time/batch = 0.6449s	
2095/16650 (epoch 6.291), train_loss = 1.31925112, grad/param norm = 2.1428e-01, time/batch = 0.6483s	
2096/16650 (epoch 6.294), train_loss = 1.39506164, grad/param norm = 2.1169e-01, time/batch = 0.6609s	
2097/16650 (epoch 6.297), train_loss = 1.47153431, grad/param norm = 2.1977e-01, time/batch = 0.6612s	
2098/16650 (epoch 6.300), train_loss = 1.36155076, grad/param norm = 2.4313e-01, time/batch = 0.6605s	
2099/16650 (epoch 6.303), train_loss = 1.36342112, grad/param norm = 2.4562e-01, time/batch = 0.6579s	
2100/16650 (epoch 6.306), train_loss = 1.68806064, grad/param norm = 2.7868e-01, time/batch = 0.6533s	
2101/16650 (epoch 6.309), train_loss = 1.74905975, grad/param norm = 2.6499e-01, time/batch = 0.6469s	
2102/16650 (epoch 6.312), train_loss = 1.50154303, grad/param norm = 2.4484e-01, time/batch = 0.6415s	
2103/16650 (epoch 6.315), train_loss = 1.31602028, grad/param norm = 2.1345e-01, time/batch = 0.6324s	
2104/16650 (epoch 6.318), train_loss = 1.45130259, grad/param norm = 2.4051e-01, time/batch = 0.6319s	
2105/16650 (epoch 6.321), train_loss = 1.82016663, grad/param norm = 2.8575e-01, time/batch = 0.6342s	
2106/16650 (epoch 6.324), train_loss = 1.61205502, grad/param norm = 2.4781e-01, time/batch = 0.6339s	
2107/16650 (epoch 6.327), train_loss = 1.75603752, grad/param norm = 2.8035e-01, time/batch = 0.6336s	
2108/16650 (epoch 6.330), train_loss = 1.68815125, grad/param norm = 2.6551e-01, time/batch = 0.6368s	
2109/16650 (epoch 6.333), train_loss = 1.73890266, grad/param norm = 2.6455e-01, time/batch = 0.6376s	
2110/16650 (epoch 6.336), train_loss = 1.44968743, grad/param norm = 2.2873e-01, time/batch = 0.6328s	
2111/16650 (epoch 6.339), train_loss = 1.57231087, grad/param norm = 2.5797e-01, time/batch = 0.6346s	
2112/16650 (epoch 6.342), train_loss = 1.61547418, grad/param norm = 2.9535e-01, time/batch = 0.6333s	
2113/16650 (epoch 6.345), train_loss = 1.46185386, grad/param norm = 2.4430e-01, time/batch = 0.6329s	
2114/16650 (epoch 6.348), train_loss = 1.58319385, grad/param norm = 2.5128e-01, time/batch = 0.6352s	
2115/16650 (epoch 6.351), train_loss = 1.72553816, grad/param norm = 2.7452e-01, time/batch = 0.6344s	
2116/16650 (epoch 6.354), train_loss = 1.75922362, grad/param norm = 2.6229e-01, time/batch = 0.6387s	
2117/16650 (epoch 6.357), train_loss = 1.66692957, grad/param norm = 2.5594e-01, time/batch = 0.6760s	
2118/16650 (epoch 6.360), train_loss = 1.65001154, grad/param norm = 2.5152e-01, time/batch = 0.6487s	
2119/16650 (epoch 6.363), train_loss = 1.77238207, grad/param norm = 2.7076e-01, time/batch = 0.6340s	
2120/16650 (epoch 6.366), train_loss = 1.80195946, grad/param norm = 2.6958e-01, time/batch = 0.6322s	
2121/16650 (epoch 6.369), train_loss = 1.62994348, grad/param norm = 2.5321e-01, time/batch = 0.6548s	
2122/16650 (epoch 6.372), train_loss = 1.64601742, grad/param norm = 2.5439e-01, time/batch = 0.6717s	
2123/16650 (epoch 6.375), train_loss = 1.56611372, grad/param norm = 2.4035e-01, time/batch = 0.6325s	
2124/16650 (epoch 6.378), train_loss = 1.42037964, grad/param norm = 2.6623e-01, time/batch = 0.6328s	
2125/16650 (epoch 6.381), train_loss = 1.66101283, grad/param norm = 2.7465e-01, time/batch = 0.6354s	
2126/16650 (epoch 6.384), train_loss = 1.67853505, grad/param norm = 2.5120e-01, time/batch = 0.6376s	
2127/16650 (epoch 6.387), train_loss = 1.38768029, grad/param norm = 2.5943e-01, time/batch = 0.6361s	
2128/16650 (epoch 6.390), train_loss = 1.68274190, grad/param norm = 2.4848e-01, time/batch = 0.6426s	
2129/16650 (epoch 6.393), train_loss = 1.60805476, grad/param norm = 2.8159e-01, time/batch = 0.6399s	
2130/16650 (epoch 6.396), train_loss = 1.77515901, grad/param norm = 2.5969e-01, time/batch = 0.6474s	
2131/16650 (epoch 6.399), train_loss = 1.68359170, grad/param norm = 2.4543e-01, time/batch = 0.6559s	
2132/16650 (epoch 6.402), train_loss = 1.45946917, grad/param norm = 2.3073e-01, time/batch = 0.6695s	
2133/16650 (epoch 6.405), train_loss = 1.43965208, grad/param norm = 2.2181e-01, time/batch = 0.6379s	
2134/16650 (epoch 6.408), train_loss = 1.74511314, grad/param norm = 2.5406e-01, time/batch = 0.6470s	
2135/16650 (epoch 6.411), train_loss = 1.48044770, grad/param norm = 2.4814e-01, time/batch = 0.6401s	
2136/16650 (epoch 6.414), train_loss = 1.40237218, grad/param norm = 2.2686e-01, time/batch = 0.6363s	
2137/16650 (epoch 6.417), train_loss = 1.40436839, grad/param norm = 1.9934e-01, time/batch = 0.6358s	
2138/16650 (epoch 6.420), train_loss = 1.43879800, grad/param norm = 2.4754e-01, time/batch = 0.6342s	
2139/16650 (epoch 6.423), train_loss = 1.15299091, grad/param norm = 2.1095e-01, time/batch = 0.6331s	
2140/16650 (epoch 6.426), train_loss = 1.55502058, grad/param norm = 2.5674e-01, time/batch = 0.6371s	
2141/16650 (epoch 6.429), train_loss = 1.69203153, grad/param norm = 2.5047e-01, time/batch = 0.6433s	
2142/16650 (epoch 6.432), train_loss = 1.63249485, grad/param norm = 2.7307e-01, time/batch = 0.6353s	
2143/16650 (epoch 6.435), train_loss = 1.85175231, grad/param norm = 2.5079e-01, time/batch = 0.6355s	
2144/16650 (epoch 6.438), train_loss = 1.79625400, grad/param norm = 2.5434e-01, time/batch = 0.6317s	
2145/16650 (epoch 6.441), train_loss = 1.72778893, grad/param norm = 2.5128e-01, time/batch = 0.6336s	
2146/16650 (epoch 6.444), train_loss = 1.55145772, grad/param norm = 2.4253e-01, time/batch = 0.6343s	
2147/16650 (epoch 6.447), train_loss = 1.59241973, grad/param norm = 2.7541e-01, time/batch = 0.6323s	
2148/16650 (epoch 6.450), train_loss = 1.48418335, grad/param norm = 2.5880e-01, time/batch = 0.6324s	
2149/16650 (epoch 6.453), train_loss = 1.59551063, grad/param norm = 2.7030e-01, time/batch = 0.6339s	
2150/16650 (epoch 6.456), train_loss = 1.44185005, grad/param norm = 2.6178e-01, time/batch = 0.6338s	
2151/16650 (epoch 6.459), train_loss = 1.54718946, grad/param norm = 2.3898e-01, time/batch = 0.6752s	
2152/16650 (epoch 6.462), train_loss = 1.82966989, grad/param norm = 2.6947e-01, time/batch = 0.6548s	
2153/16650 (epoch 6.465), train_loss = 1.55383711, grad/param norm = 2.5197e-01, time/batch = 0.6355s	
2154/16650 (epoch 6.468), train_loss = 1.23026043, grad/param norm = 2.2582e-01, time/batch = 0.6344s	
2155/16650 (epoch 6.471), train_loss = 1.20662377, grad/param norm = 2.3329e-01, time/batch = 0.6335s	
2156/16650 (epoch 6.474), train_loss = 1.37649662, grad/param norm = 2.1580e-01, time/batch = 0.6334s	
2157/16650 (epoch 6.477), train_loss = 1.60153090, grad/param norm = 2.5255e-01, time/batch = 0.6348s	
2158/16650 (epoch 6.480), train_loss = 1.65432678, grad/param norm = 2.5437e-01, time/batch = 0.6344s	
2159/16650 (epoch 6.483), train_loss = 1.77363003, grad/param norm = 2.5535e-01, time/batch = 0.6415s	
2160/16650 (epoch 6.486), train_loss = 1.39999005, grad/param norm = 2.7726e-01, time/batch = 0.6403s	
2161/16650 (epoch 6.489), train_loss = 1.55589331, grad/param norm = 2.5810e-01, time/batch = 0.6376s	
2162/16650 (epoch 6.492), train_loss = 1.58373644, grad/param norm = 2.4128e-01, time/batch = 0.6332s	
2163/16650 (epoch 6.495), train_loss = 1.47173983, grad/param norm = 2.7217e-01, time/batch = 0.6332s	
2164/16650 (epoch 6.498), train_loss = 1.60999708, grad/param norm = 2.5439e-01, time/batch = 0.6376s	
2165/16650 (epoch 6.502), train_loss = 1.85149827, grad/param norm = 2.6620e-01, time/batch = 0.6321s	
2166/16650 (epoch 6.505), train_loss = 1.60310491, grad/param norm = 2.2323e-01, time/batch = 0.6338s	
2167/16650 (epoch 6.508), train_loss = 1.63263589, grad/param norm = 2.4045e-01, time/batch = 0.6350s	
2168/16650 (epoch 6.511), train_loss = 1.80572854, grad/param norm = 2.9907e-01, time/batch = 0.6349s	
2169/16650 (epoch 6.514), train_loss = 1.46768927, grad/param norm = 2.3236e-01, time/batch = 0.6361s	
2170/16650 (epoch 6.517), train_loss = 1.59587058, grad/param norm = 2.6151e-01, time/batch = 0.6321s	
2171/16650 (epoch 6.520), train_loss = 1.64463509, grad/param norm = 2.5745e-01, time/batch = 0.6350s	
2172/16650 (epoch 6.523), train_loss = 1.56773350, grad/param norm = 2.3803e-01, time/batch = 0.6330s	
2173/16650 (epoch 6.526), train_loss = 1.59498229, grad/param norm = 2.3426e-01, time/batch = 0.6334s	
2174/16650 (epoch 6.529), train_loss = 1.80552012, grad/param norm = 2.5336e-01, time/batch = 0.6329s	
2175/16650 (epoch 6.532), train_loss = 1.44963616, grad/param norm = 2.6040e-01, time/batch = 0.6337s	
2176/16650 (epoch 6.535), train_loss = 1.45019864, grad/param norm = 2.3943e-01, time/batch = 0.6354s	
2177/16650 (epoch 6.538), train_loss = 1.54975608, grad/param norm = 2.3224e-01, time/batch = 0.6349s	
2178/16650 (epoch 6.541), train_loss = 1.77321105, grad/param norm = 2.5895e-01, time/batch = 0.6317s	
2179/16650 (epoch 6.544), train_loss = 1.83106731, grad/param norm = 2.8360e-01, time/batch = 0.6333s	
2180/16650 (epoch 6.547), train_loss = 1.39793364, grad/param norm = 2.1862e-01, time/batch = 0.6332s	
2181/16650 (epoch 6.550), train_loss = 1.47834143, grad/param norm = 2.2591e-01, time/batch = 0.6402s	
2182/16650 (epoch 6.553), train_loss = 1.62103717, grad/param norm = 2.6120e-01, time/batch = 0.6367s	
2183/16650 (epoch 6.556), train_loss = 1.46660771, grad/param norm = 2.4038e-01, time/batch = 0.6365s	
2184/16650 (epoch 6.559), train_loss = 1.33393703, grad/param norm = 2.1432e-01, time/batch = 0.6354s	
2185/16650 (epoch 6.562), train_loss = 1.58259450, grad/param norm = 2.2377e-01, time/batch = 0.6404s	
2186/16650 (epoch 6.565), train_loss = 1.28714660, grad/param norm = 2.3714e-01, time/batch = 0.6383s	
2187/16650 (epoch 6.568), train_loss = 1.32774834, grad/param norm = 2.1517e-01, time/batch = 0.6406s	
2188/16650 (epoch 6.571), train_loss = 1.41721328, grad/param norm = 2.5865e-01, time/batch = 0.6405s	
2189/16650 (epoch 6.574), train_loss = 1.53395325, grad/param norm = 2.3679e-01, time/batch = 0.6364s	
2190/16650 (epoch 6.577), train_loss = 1.51429699, grad/param norm = 2.3845e-01, time/batch = 0.6751s	
2191/16650 (epoch 6.580), train_loss = 1.42741001, grad/param norm = 2.5591e-01, time/batch = 0.6559s	
2192/16650 (epoch 6.583), train_loss = 1.42594392, grad/param norm = 2.5633e-01, time/batch = 0.6346s	
2193/16650 (epoch 6.586), train_loss = 1.62454247, grad/param norm = 2.6730e-01, time/batch = 0.6341s	
2194/16650 (epoch 6.589), train_loss = 1.33446766, grad/param norm = 2.0454e-01, time/batch = 0.6373s	
2195/16650 (epoch 6.592), train_loss = 1.57537673, grad/param norm = 2.7489e-01, time/batch = 0.6307s	
2196/16650 (epoch 6.595), train_loss = 1.44562601, grad/param norm = 2.6755e-01, time/batch = 0.6307s	
2197/16650 (epoch 6.598), train_loss = 1.45033070, grad/param norm = 2.6745e-01, time/batch = 0.6324s	
2198/16650 (epoch 6.601), train_loss = 1.48468552, grad/param norm = 2.9034e-01, time/batch = 0.6355s	
2199/16650 (epoch 6.604), train_loss = 1.64339361, grad/param norm = 2.6158e-01, time/batch = 0.6332s	
2200/16650 (epoch 6.607), train_loss = 1.53842487, grad/param norm = 2.3500e-01, time/batch = 0.6330s	
2201/16650 (epoch 6.610), train_loss = 1.44035248, grad/param norm = 2.1099e-01, time/batch = 0.6373s	
2202/16650 (epoch 6.613), train_loss = 1.70625004, grad/param norm = 2.6460e-01, time/batch = 0.6382s	
2203/16650 (epoch 6.616), train_loss = 1.76908336, grad/param norm = 2.9338e-01, time/batch = 0.6344s	
2204/16650 (epoch 6.619), train_loss = 1.45687961, grad/param norm = 2.6295e-01, time/batch = 0.6338s	
2205/16650 (epoch 6.622), train_loss = 1.32054429, grad/param norm = 2.3097e-01, time/batch = 0.6307s	
2206/16650 (epoch 6.625), train_loss = 1.48927629, grad/param norm = 2.2848e-01, time/batch = 0.6333s	
2207/16650 (epoch 6.628), train_loss = 1.48972359, grad/param norm = 2.5147e-01, time/batch = 0.6329s	
2208/16650 (epoch 6.631), train_loss = 1.52626614, grad/param norm = 2.6542e-01, time/batch = 0.6356s	
2209/16650 (epoch 6.634), train_loss = 1.73180192, grad/param norm = 2.5103e-01, time/batch = 0.6327s	
2210/16650 (epoch 6.637), train_loss = 1.78369542, grad/param norm = 2.6053e-01, time/batch = 0.6344s	
2211/16650 (epoch 6.640), train_loss = 1.53030103, grad/param norm = 2.4535e-01, time/batch = 0.6420s	
2212/16650 (epoch 6.643), train_loss = 1.64633175, grad/param norm = 2.6949e-01, time/batch = 0.6325s	
2213/16650 (epoch 6.646), train_loss = 1.72399052, grad/param norm = 2.7571e-01, time/batch = 0.6327s	
2214/16650 (epoch 6.649), train_loss = 1.55607834, grad/param norm = 2.5779e-01, time/batch = 0.6329s	
2215/16650 (epoch 6.652), train_loss = 1.75253425, grad/param norm = 2.8878e-01, time/batch = 0.6310s	
2216/16650 (epoch 6.655), train_loss = 1.58317810, grad/param norm = 2.3711e-01, time/batch = 0.6334s	
2217/16650 (epoch 6.658), train_loss = 1.45041706, grad/param norm = 2.6465e-01, time/batch = 0.6355s	
2218/16650 (epoch 6.661), train_loss = 1.64544393, grad/param norm = 2.2719e-01, time/batch = 0.6350s	
2219/16650 (epoch 6.664), train_loss = 1.59233186, grad/param norm = 2.5041e-01, time/batch = 0.6366s	
2220/16650 (epoch 6.667), train_loss = 1.72452767, grad/param norm = 2.3996e-01, time/batch = 0.6362s	
2221/16650 (epoch 6.670), train_loss = 1.42226471, grad/param norm = 2.3305e-01, time/batch = 0.6344s	
2222/16650 (epoch 6.673), train_loss = 1.39697715, grad/param norm = 2.2272e-01, time/batch = 0.6420s	
2223/16650 (epoch 6.676), train_loss = 1.56650914, grad/param norm = 2.4149e-01, time/batch = 0.6417s	
2224/16650 (epoch 6.679), train_loss = 1.44415048, grad/param norm = 2.2935e-01, time/batch = 0.6622s	
2225/16650 (epoch 6.682), train_loss = 1.66206253, grad/param norm = 2.6660e-01, time/batch = 0.6662s	
2226/16650 (epoch 6.685), train_loss = 1.43054608, grad/param norm = 2.4351e-01, time/batch = 0.6693s	
2227/16650 (epoch 6.688), train_loss = 1.55399492, grad/param norm = 2.6474e-01, time/batch = 0.6370s	
2228/16650 (epoch 6.691), train_loss = 1.61037993, grad/param norm = 2.6166e-01, time/batch = 0.6489s	
2229/16650 (epoch 6.694), train_loss = 1.41438601, grad/param norm = 2.4109e-01, time/batch = 0.6770s	
2230/16650 (epoch 6.697), train_loss = 1.34881498, grad/param norm = 2.1300e-01, time/batch = 0.6531s	
2231/16650 (epoch 6.700), train_loss = 1.67016708, grad/param norm = 2.3868e-01, time/batch = 0.6365s	
2232/16650 (epoch 6.703), train_loss = 1.50196943, grad/param norm = 2.6881e-01, time/batch = 0.6347s	
2233/16650 (epoch 6.706), train_loss = 1.64063769, grad/param norm = 2.5859e-01, time/batch = 0.6348s	
2234/16650 (epoch 6.709), train_loss = 1.45923709, grad/param norm = 2.4800e-01, time/batch = 0.6344s	
2235/16650 (epoch 6.712), train_loss = 1.47146172, grad/param norm = 2.5187e-01, time/batch = 0.6397s	
2236/16650 (epoch 6.715), train_loss = 1.68254811, grad/param norm = 2.4890e-01, time/batch = 0.6391s	
2237/16650 (epoch 6.718), train_loss = 1.75228669, grad/param norm = 2.4874e-01, time/batch = 0.6341s	
2238/16650 (epoch 6.721), train_loss = 1.69217627, grad/param norm = 2.5298e-01, time/batch = 0.6360s	
2239/16650 (epoch 6.724), train_loss = 1.73255562, grad/param norm = 2.5350e-01, time/batch = 0.6375s	
2240/16650 (epoch 6.727), train_loss = 1.61299324, grad/param norm = 2.2249e-01, time/batch = 0.6334s	
2241/16650 (epoch 6.730), train_loss = 1.50888652, grad/param norm = 2.5507e-01, time/batch = 0.6370s	
2242/16650 (epoch 6.733), train_loss = 1.70661100, grad/param norm = 2.6446e-01, time/batch = 0.6337s	
2243/16650 (epoch 6.736), train_loss = 1.43085228, grad/param norm = 2.2914e-01, time/batch = 0.6405s	
2244/16650 (epoch 6.739), train_loss = 1.59511868, grad/param norm = 2.4475e-01, time/batch = 0.6437s	
2245/16650 (epoch 6.742), train_loss = 1.59655424, grad/param norm = 2.5827e-01, time/batch = 0.6495s	
2246/16650 (epoch 6.745), train_loss = 1.30912904, grad/param norm = 2.1401e-01, time/batch = 0.6412s	
2247/16650 (epoch 6.748), train_loss = 1.44663616, grad/param norm = 2.5187e-01, time/batch = 0.6396s	
2248/16650 (epoch 6.751), train_loss = 1.65156736, grad/param norm = 2.7121e-01, time/batch = 0.6363s	
2249/16650 (epoch 6.754), train_loss = 1.76267946, grad/param norm = 2.5587e-01, time/batch = 0.6348s	
2250/16650 (epoch 6.757), train_loss = 1.64945219, grad/param norm = 2.4534e-01, time/batch = 0.6346s	
2251/16650 (epoch 6.760), train_loss = 1.52418237, grad/param norm = 2.5357e-01, time/batch = 0.6400s	
2252/16650 (epoch 6.763), train_loss = 1.45763727, grad/param norm = 2.4383e-01, time/batch = 0.6384s	
2253/16650 (epoch 6.766), train_loss = 1.57343075, grad/param norm = 2.4480e-01, time/batch = 0.6360s	
2254/16650 (epoch 6.769), train_loss = 1.51626987, grad/param norm = 2.5441e-01, time/batch = 0.6350s	
2255/16650 (epoch 6.772), train_loss = 1.45980187, grad/param norm = 2.1545e-01, time/batch = 0.6378s	
2256/16650 (epoch 6.775), train_loss = 1.54683390, grad/param norm = 2.2391e-01, time/batch = 0.6430s	
2257/16650 (epoch 6.778), train_loss = 1.41834596, grad/param norm = 2.3423e-01, time/batch = 0.6400s	
2258/16650 (epoch 6.781), train_loss = 1.61845307, grad/param norm = 2.5655e-01, time/batch = 0.6486s	
2259/16650 (epoch 6.784), train_loss = 1.65230464, grad/param norm = 2.6531e-01, time/batch = 0.6417s	
2260/16650 (epoch 6.787), train_loss = 1.67456298, grad/param norm = 2.4612e-01, time/batch = 0.6358s	
2261/16650 (epoch 6.790), train_loss = 1.49591487, grad/param norm = 2.4040e-01, time/batch = 0.6410s	
2262/16650 (epoch 6.793), train_loss = 1.46535234, grad/param norm = 2.8661e-01, time/batch = 0.6325s	
2263/16650 (epoch 6.796), train_loss = 1.96130704, grad/param norm = 2.8680e-01, time/batch = 0.6320s	
2264/16650 (epoch 6.799), train_loss = 1.78011111, grad/param norm = 2.4228e-01, time/batch = 0.6417s	
2265/16650 (epoch 6.802), train_loss = 1.56763296, grad/param norm = 2.6167e-01, time/batch = 0.6337s	
2266/16650 (epoch 6.805), train_loss = 1.53735368, grad/param norm = 2.3434e-01, time/batch = 0.6344s	
2267/16650 (epoch 6.808), train_loss = 1.55226584, grad/param norm = 2.2720e-01, time/batch = 0.6333s	
2268/16650 (epoch 6.811), train_loss = 1.67425354, grad/param norm = 2.3925e-01, time/batch = 0.6365s	
2269/16650 (epoch 6.814), train_loss = 1.44285312, grad/param norm = 2.1731e-01, time/batch = 0.6473s	
2270/16650 (epoch 6.817), train_loss = 1.52786060, grad/param norm = 2.4520e-01, time/batch = 0.6535s	
2271/16650 (epoch 6.820), train_loss = 1.60636948, grad/param norm = 2.4932e-01, time/batch = 0.6475s	
2272/16650 (epoch 6.823), train_loss = 1.40605252, grad/param norm = 2.3030e-01, time/batch = 0.6692s	
2273/16650 (epoch 6.826), train_loss = 1.51736533, grad/param norm = 2.1781e-01, time/batch = 0.6751s	
2274/16650 (epoch 6.829), train_loss = 1.72706044, grad/param norm = 2.5073e-01, time/batch = 0.6574s	
2275/16650 (epoch 6.832), train_loss = 1.71231927, grad/param norm = 2.4722e-01, time/batch = 0.6640s	
2276/16650 (epoch 6.835), train_loss = 1.70343991, grad/param norm = 2.9038e-01, time/batch = 0.6610s	
2277/16650 (epoch 6.838), train_loss = 1.44324740, grad/param norm = 2.7164e-01, time/batch = 0.6531s	
2278/16650 (epoch 6.841), train_loss = 1.39088382, grad/param norm = 2.1281e-01, time/batch = 0.6494s	
2279/16650 (epoch 6.844), train_loss = 1.50412301, grad/param norm = 2.4356e-01, time/batch = 0.6396s	
2280/16650 (epoch 6.847), train_loss = 1.70112531, grad/param norm = 2.3267e-01, time/batch = 0.6412s	
2281/16650 (epoch 6.850), train_loss = 1.43917468, grad/param norm = 2.6062e-01, time/batch = 0.6393s	
2282/16650 (epoch 6.853), train_loss = 1.61308363, grad/param norm = 2.3950e-01, time/batch = 0.6385s	
2283/16650 (epoch 6.856), train_loss = 1.45059197, grad/param norm = 2.4174e-01, time/batch = 0.6423s	
2284/16650 (epoch 6.859), train_loss = 1.58517554, grad/param norm = 2.3886e-01, time/batch = 0.6417s	
2285/16650 (epoch 6.862), train_loss = 1.53644047, grad/param norm = 2.3584e-01, time/batch = 0.6462s	
2286/16650 (epoch 6.865), train_loss = 1.28388848, grad/param norm = 2.2234e-01, time/batch = 0.6338s	
2287/16650 (epoch 6.868), train_loss = 1.60891830, grad/param norm = 2.3581e-01, time/batch = 0.6332s	
2288/16650 (epoch 6.871), train_loss = 1.63534480, grad/param norm = 2.6326e-01, time/batch = 0.6319s	
2289/16650 (epoch 6.874), train_loss = 1.62316522, grad/param norm = 2.5796e-01, time/batch = 0.6315s	
2290/16650 (epoch 6.877), train_loss = 1.42426320, grad/param norm = 2.2343e-01, time/batch = 0.6314s	
2291/16650 (epoch 6.880), train_loss = 1.50206967, grad/param norm = 2.7398e-01, time/batch = 0.6411s	
2292/16650 (epoch 6.883), train_loss = 1.62080623, grad/param norm = 2.4423e-01, time/batch = 0.6419s	
2293/16650 (epoch 6.886), train_loss = 1.61148470, grad/param norm = 2.3658e-01, time/batch = 0.6416s	
2294/16650 (epoch 6.889), train_loss = 1.45535976, grad/param norm = 2.4286e-01, time/batch = 0.6387s	
2295/16650 (epoch 6.892), train_loss = 1.46130742, grad/param norm = 2.0821e-01, time/batch = 0.6349s	
2296/16650 (epoch 6.895), train_loss = 1.65845951, grad/param norm = 2.5352e-01, time/batch = 0.6320s	
2297/16650 (epoch 6.898), train_loss = 1.60852822, grad/param norm = 2.6154e-01, time/batch = 0.6327s	
2298/16650 (epoch 6.901), train_loss = 1.55686155, grad/param norm = 2.1793e-01, time/batch = 0.6320s	
2299/16650 (epoch 6.904), train_loss = 1.47836301, grad/param norm = 2.3875e-01, time/batch = 0.6310s	
2300/16650 (epoch 6.907), train_loss = 1.54952425, grad/param norm = 2.3839e-01, time/batch = 0.6387s	
2301/16650 (epoch 6.910), train_loss = 1.59019424, grad/param norm = 2.6168e-01, time/batch = 0.6474s	
2302/16650 (epoch 6.913), train_loss = 1.49818358, grad/param norm = 2.5076e-01, time/batch = 0.6744s	
2303/16650 (epoch 6.916), train_loss = 1.59164900, grad/param norm = 2.4936e-01, time/batch = 0.6494s	
2304/16650 (epoch 6.919), train_loss = 1.68468618, grad/param norm = 2.6420e-01, time/batch = 0.6424s	
2305/16650 (epoch 6.922), train_loss = 1.68388670, grad/param norm = 2.4849e-01, time/batch = 0.6508s	
2306/16650 (epoch 6.925), train_loss = 1.52835600, grad/param norm = 2.5587e-01, time/batch = 0.6640s	
2307/16650 (epoch 6.928), train_loss = 1.51588207, grad/param norm = 2.2281e-01, time/batch = 0.6730s	
2308/16650 (epoch 6.931), train_loss = 1.56440510, grad/param norm = 2.3832e-01, time/batch = 0.6484s	
2309/16650 (epoch 6.934), train_loss = 1.40447521, grad/param norm = 2.3057e-01, time/batch = 0.6446s	
2310/16650 (epoch 6.937), train_loss = 1.53897519, grad/param norm = 2.4379e-01, time/batch = 0.6418s	
2311/16650 (epoch 6.940), train_loss = 1.47043521, grad/param norm = 2.1368e-01, time/batch = 0.6405s	
2312/16650 (epoch 6.943), train_loss = 1.44866249, grad/param norm = 2.1528e-01, time/batch = 0.6403s	
2313/16650 (epoch 6.946), train_loss = 1.47040919, grad/param norm = 2.3841e-01, time/batch = 0.6480s	
2314/16650 (epoch 6.949), train_loss = 1.52804055, grad/param norm = 2.2705e-01, time/batch = 0.6362s	
2315/16650 (epoch 6.952), train_loss = 1.24645792, grad/param norm = 2.6339e-01, time/batch = 0.6465s	
2316/16650 (epoch 6.955), train_loss = 1.48416935, grad/param norm = 2.4941e-01, time/batch = 0.6509s	
2317/16650 (epoch 6.958), train_loss = 1.66175222, grad/param norm = 2.7679e-01, time/batch = 0.6554s	
2318/16650 (epoch 6.961), train_loss = 1.46121177, grad/param norm = 2.3393e-01, time/batch = 0.6820s	
2319/16650 (epoch 6.964), train_loss = 1.44404158, grad/param norm = 2.5137e-01, time/batch = 0.6621s	
2320/16650 (epoch 6.967), train_loss = 1.72226790, grad/param norm = 2.6280e-01, time/batch = 0.6517s	
2321/16650 (epoch 6.970), train_loss = 1.31152262, grad/param norm = 2.1792e-01, time/batch = 0.6469s	
2322/16650 (epoch 6.973), train_loss = 1.55292868, grad/param norm = 2.9454e-01, time/batch = 0.6340s	
2323/16650 (epoch 6.976), train_loss = 1.44287988, grad/param norm = 2.3303e-01, time/batch = 0.6337s	
2324/16650 (epoch 6.979), train_loss = 1.64186739, grad/param norm = 2.4998e-01, time/batch = 0.6372s	
2325/16650 (epoch 6.982), train_loss = 1.60375755, grad/param norm = 2.6333e-01, time/batch = 0.6401s	
2326/16650 (epoch 6.985), train_loss = 1.46942258, grad/param norm = 2.4237e-01, time/batch = 0.6594s	
2327/16650 (epoch 6.988), train_loss = 1.82065639, grad/param norm = 2.7118e-01, time/batch = 0.6578s	
2328/16650 (epoch 6.991), train_loss = 1.46333462, grad/param norm = 2.5464e-01, time/batch = 0.6374s	
2329/16650 (epoch 6.994), train_loss = 1.50557698, grad/param norm = 2.2580e-01, time/batch = 0.6378s	
2330/16650 (epoch 6.997), train_loss = 1.62697030, grad/param norm = 2.6137e-01, time/batch = 0.6360s	
2331/16650 (epoch 7.000), train_loss = 1.65982065, grad/param norm = 2.7869e-01, time/batch = 0.6356s	
2332/16650 (epoch 7.003), train_loss = 1.64233376, grad/param norm = 2.6140e-01, time/batch = 0.6313s	
2333/16650 (epoch 7.006), train_loss = 1.67827768, grad/param norm = 2.5461e-01, time/batch = 0.6351s	
2334/16650 (epoch 7.009), train_loss = 1.77180768, grad/param norm = 2.5968e-01, time/batch = 0.6353s	
2335/16650 (epoch 7.012), train_loss = 1.81024971, grad/param norm = 2.8952e-01, time/batch = 0.6333s	
2336/16650 (epoch 7.015), train_loss = 1.67108042, grad/param norm = 2.6356e-01, time/batch = 0.6360s	
2337/16650 (epoch 7.018), train_loss = 1.28793072, grad/param norm = 2.3341e-01, time/batch = 0.6318s	
2338/16650 (epoch 7.021), train_loss = 1.70469188, grad/param norm = 2.4952e-01, time/batch = 0.6303s	
2339/16650 (epoch 7.024), train_loss = 1.50119708, grad/param norm = 2.4287e-01, time/batch = 0.6304s	
2340/16650 (epoch 7.027), train_loss = 1.69980039, grad/param norm = 2.6715e-01, time/batch = 0.6326s	
2341/16650 (epoch 7.030), train_loss = 1.42158957, grad/param norm = 2.3699e-01, time/batch = 0.6368s	
2342/16650 (epoch 7.033), train_loss = 1.56091554, grad/param norm = 2.3083e-01, time/batch = 0.6346s	
2343/16650 (epoch 7.036), train_loss = 1.41262681, grad/param norm = 2.8153e-01, time/batch = 0.6344s	
2344/16650 (epoch 7.039), train_loss = 1.64121623, grad/param norm = 2.7379e-01, time/batch = 0.6361s	
2345/16650 (epoch 7.042), train_loss = 1.67163136, grad/param norm = 2.4230e-01, time/batch = 0.6340s	
2346/16650 (epoch 7.045), train_loss = 1.46865171, grad/param norm = 2.2383e-01, time/batch = 0.6325s	
2347/16650 (epoch 7.048), train_loss = 1.59703767, grad/param norm = 2.3727e-01, time/batch = 0.6318s	
2348/16650 (epoch 7.051), train_loss = 1.58546827, grad/param norm = 2.4893e-01, time/batch = 0.6304s	
2349/16650 (epoch 7.054), train_loss = 1.56354180, grad/param norm = 2.2925e-01, time/batch = 0.6312s	
2350/16650 (epoch 7.057), train_loss = 1.50670233, grad/param norm = 2.3906e-01, time/batch = 0.6322s	
2351/16650 (epoch 7.060), train_loss = 1.42366428, grad/param norm = 2.2160e-01, time/batch = 0.6360s	
2352/16650 (epoch 7.063), train_loss = 1.52927621, grad/param norm = 2.3803e-01, time/batch = 0.6413s	
2353/16650 (epoch 7.066), train_loss = 1.73118408, grad/param norm = 2.7559e-01, time/batch = 0.6321s	
2354/16650 (epoch 7.069), train_loss = 1.68166648, grad/param norm = 2.6148e-01, time/batch = 0.6303s	
2355/16650 (epoch 7.072), train_loss = 1.51131646, grad/param norm = 2.5170e-01, time/batch = 0.6302s	
2356/16650 (epoch 7.075), train_loss = 1.54873342, grad/param norm = 2.5225e-01, time/batch = 0.6315s	
2357/16650 (epoch 7.078), train_loss = 1.58250040, grad/param norm = 2.2544e-01, time/batch = 0.6323s	
2358/16650 (epoch 7.081), train_loss = 1.52681035, grad/param norm = 2.6147e-01, time/batch = 0.6304s	
2359/16650 (epoch 7.084), train_loss = 1.63192217, grad/param norm = 2.3422e-01, time/batch = 0.6374s	
2360/16650 (epoch 7.087), train_loss = 1.56930717, grad/param norm = 2.2885e-01, time/batch = 0.6337s	
2361/16650 (epoch 7.090), train_loss = 1.41793856, grad/param norm = 2.2401e-01, time/batch = 0.6370s	
2362/16650 (epoch 7.093), train_loss = 1.86079260, grad/param norm = 2.6025e-01, time/batch = 0.6355s	
2363/16650 (epoch 7.096), train_loss = 1.51441869, grad/param norm = 2.3796e-01, time/batch = 0.6334s	
2364/16650 (epoch 7.099), train_loss = 1.49201612, grad/param norm = 2.3169e-01, time/batch = 0.6712s	
2365/16650 (epoch 7.102), train_loss = 1.54222966, grad/param norm = 2.3622e-01, time/batch = 0.6512s	
2366/16650 (epoch 7.105), train_loss = 1.65063444, grad/param norm = 2.4738e-01, time/batch = 0.6318s	
2367/16650 (epoch 7.108), train_loss = 1.65990854, grad/param norm = 2.5748e-01, time/batch = 0.6356s	
2368/16650 (epoch 7.111), train_loss = 1.57343557, grad/param norm = 2.4061e-01, time/batch = 0.6429s	
2369/16650 (epoch 7.114), train_loss = 1.71157720, grad/param norm = 2.2709e-01, time/batch = 0.6684s	
2370/16650 (epoch 7.117), train_loss = 1.64786887, grad/param norm = 2.6105e-01, time/batch = 0.6363s	
2371/16650 (epoch 7.120), train_loss = 1.44382222, grad/param norm = 2.3847e-01, time/batch = 0.6341s	
2372/16650 (epoch 7.123), train_loss = 1.53422029, grad/param norm = 2.5133e-01, time/batch = 0.6302s	
2373/16650 (epoch 7.126), train_loss = 1.60623545, grad/param norm = 2.7942e-01, time/batch = 0.6325s	
2374/16650 (epoch 7.129), train_loss = 1.61541637, grad/param norm = 2.3835e-01, time/batch = 0.6340s	
2375/16650 (epoch 7.132), train_loss = 1.69956074, grad/param norm = 2.4681e-01, time/batch = 0.6335s	
2376/16650 (epoch 7.135), train_loss = 1.61367257, grad/param norm = 2.6456e-01, time/batch = 0.6305s	
2377/16650 (epoch 7.138), train_loss = 1.61940620, grad/param norm = 2.7521e-01, time/batch = 0.6382s	
2378/16650 (epoch 7.141), train_loss = 1.66107586, grad/param norm = 2.8126e-01, time/batch = 0.6324s	
2379/16650 (epoch 7.144), train_loss = 1.54425834, grad/param norm = 2.3789e-01, time/batch = 0.6309s	
2380/16650 (epoch 7.147), train_loss = 1.70705690, grad/param norm = 2.7779e-01, time/batch = 0.6308s	
2381/16650 (epoch 7.150), train_loss = 1.80858795, grad/param norm = 2.5039e-01, time/batch = 0.6345s	
2382/16650 (epoch 7.153), train_loss = 1.54375618, grad/param norm = 2.3369e-01, time/batch = 0.6336s	
2383/16650 (epoch 7.156), train_loss = 1.37939631, grad/param norm = 2.2529e-01, time/batch = 0.6381s	
2384/16650 (epoch 7.159), train_loss = 1.72803570, grad/param norm = 2.5420e-01, time/batch = 0.6310s	
2385/16650 (epoch 7.162), train_loss = 1.61480947, grad/param norm = 2.5070e-01, time/batch = 0.6317s	
2386/16650 (epoch 7.165), train_loss = 1.62427787, grad/param norm = 2.5183e-01, time/batch = 0.6328s	
2387/16650 (epoch 7.168), train_loss = 1.27459925, grad/param norm = 2.2325e-01, time/batch = 0.6301s	
2388/16650 (epoch 7.171), train_loss = 1.62788561, grad/param norm = 2.2597e-01, time/batch = 0.6312s	
2389/16650 (epoch 7.174), train_loss = 1.39854848, grad/param norm = 2.3364e-01, time/batch = 0.6307s	
2390/16650 (epoch 7.177), train_loss = 1.55546781, grad/param norm = 2.3214e-01, time/batch = 0.6351s	
2391/16650 (epoch 7.180), train_loss = 1.71480922, grad/param norm = 2.3480e-01, time/batch = 0.6377s	
2392/16650 (epoch 7.183), train_loss = 1.82412635, grad/param norm = 2.6021e-01, time/batch = 0.6367s	
2393/16650 (epoch 7.186), train_loss = 1.66623520, grad/param norm = 2.4582e-01, time/batch = 0.6348s	
2394/16650 (epoch 7.189), train_loss = 1.44526522, grad/param norm = 2.1912e-01, time/batch = 0.6352s	
2395/16650 (epoch 7.192), train_loss = 1.48166064, grad/param norm = 2.5952e-01, time/batch = 0.6440s	
2396/16650 (epoch 7.195), train_loss = 1.56880598, grad/param norm = 2.5340e-01, time/batch = 0.6415s	
2397/16650 (epoch 7.198), train_loss = 1.30416927, grad/param norm = 2.3856e-01, time/batch = 0.6327s	
2398/16650 (epoch 7.201), train_loss = 1.54538502, grad/param norm = 2.3217e-01, time/batch = 0.6321s	
2399/16650 (epoch 7.204), train_loss = 1.55141360, grad/param norm = 2.5819e-01, time/batch = 0.6368s	
2400/16650 (epoch 7.207), train_loss = 1.62474806, grad/param norm = 2.6829e-01, time/batch = 0.6324s	
2401/16650 (epoch 7.210), train_loss = 1.47444972, grad/param norm = 2.2937e-01, time/batch = 0.6348s	
2402/16650 (epoch 7.213), train_loss = 1.60934022, grad/param norm = 2.4231e-01, time/batch = 0.6343s	
2403/16650 (epoch 7.216), train_loss = 1.54807224, grad/param norm = 2.5924e-01, time/batch = 0.6356s	
2404/16650 (epoch 7.219), train_loss = 1.54467428, grad/param norm = 2.5415e-01, time/batch = 0.6336s	
2405/16650 (epoch 7.222), train_loss = 1.55725736, grad/param norm = 2.5168e-01, time/batch = 0.6321s	
2406/16650 (epoch 7.225), train_loss = 1.58777172, grad/param norm = 2.6704e-01, time/batch = 0.6303s	
2407/16650 (epoch 7.228), train_loss = 1.48547436, grad/param norm = 2.4501e-01, time/batch = 0.6323s	
2408/16650 (epoch 7.231), train_loss = 1.55137769, grad/param norm = 2.3894e-01, time/batch = 0.6385s	
2409/16650 (epoch 7.234), train_loss = 1.66527940, grad/param norm = 2.3689e-01, time/batch = 0.6433s	
2410/16650 (epoch 7.237), train_loss = 1.52870264, grad/param norm = 2.4442e-01, time/batch = 0.6473s	
2411/16650 (epoch 7.240), train_loss = 1.60967245, grad/param norm = 2.4235e-01, time/batch = 0.6597s	
2412/16650 (epoch 7.243), train_loss = 1.60125011, grad/param norm = 2.4920e-01, time/batch = 0.6725s	
2413/16650 (epoch 7.246), train_loss = 1.71190221, grad/param norm = 2.6962e-01, time/batch = 0.6675s	
2414/16650 (epoch 7.249), train_loss = 1.41301700, grad/param norm = 2.3300e-01, time/batch = 0.6759s	
2415/16650 (epoch 7.252), train_loss = 1.54284648, grad/param norm = 2.5329e-01, time/batch = 0.6661s	
2416/16650 (epoch 7.255), train_loss = 1.71008287, grad/param norm = 2.9055e-01, time/batch = 0.6603s	
2417/16650 (epoch 7.258), train_loss = 1.64171376, grad/param norm = 2.6273e-01, time/batch = 0.6583s	
2418/16650 (epoch 7.261), train_loss = 1.55945613, grad/param norm = 2.4185e-01, time/batch = 0.6576s	
2419/16650 (epoch 7.264), train_loss = 1.53030485, grad/param norm = 2.4531e-01, time/batch = 0.6501s	
2420/16650 (epoch 7.267), train_loss = 1.44961249, grad/param norm = 2.5352e-01, time/batch = 0.6487s	
2421/16650 (epoch 7.270), train_loss = 1.50698152, grad/param norm = 2.2000e-01, time/batch = 0.6478s	
2422/16650 (epoch 7.273), train_loss = 1.67053946, grad/param norm = 2.2200e-01, time/batch = 0.6388s	
2423/16650 (epoch 7.276), train_loss = 1.54596751, grad/param norm = 2.2754e-01, time/batch = 0.6299s	
2424/16650 (epoch 7.279), train_loss = 1.54946814, grad/param norm = 2.2956e-01, time/batch = 0.6300s	
2425/16650 (epoch 7.282), train_loss = 1.35692424, grad/param norm = 2.1234e-01, time/batch = 0.6320s	
2426/16650 (epoch 7.285), train_loss = 1.40883164, grad/param norm = 2.4312e-01, time/batch = 0.6348s	
2427/16650 (epoch 7.288), train_loss = 1.48968968, grad/param norm = 2.2032e-01, time/batch = 0.6317s	
2428/16650 (epoch 7.291), train_loss = 1.24786314, grad/param norm = 2.0521e-01, time/batch = 0.6326s	
2429/16650 (epoch 7.294), train_loss = 1.32254554, grad/param norm = 1.9871e-01, time/batch = 0.6293s	
2430/16650 (epoch 7.297), train_loss = 1.40698064, grad/param norm = 2.1758e-01, time/batch = 0.6307s	
2431/16650 (epoch 7.300), train_loss = 1.28453085, grad/param norm = 2.3793e-01, time/batch = 0.6311s	
2432/16650 (epoch 7.303), train_loss = 1.29535246, grad/param norm = 2.2550e-01, time/batch = 0.6290s	
2433/16650 (epoch 7.306), train_loss = 1.59113201, grad/param norm = 2.4967e-01, time/batch = 0.6286s	
2434/16650 (epoch 7.309), train_loss = 1.66876708, grad/param norm = 2.4918e-01, time/batch = 0.6311s	
2435/16650 (epoch 7.312), train_loss = 1.42595146, grad/param norm = 2.3908e-01, time/batch = 0.6346s	
2436/16650 (epoch 7.315), train_loss = 1.22368354, grad/param norm = 2.0175e-01, time/batch = 0.6326s	
2437/16650 (epoch 7.318), train_loss = 1.35640824, grad/param norm = 2.2405e-01, time/batch = 0.6327s	
2438/16650 (epoch 7.321), train_loss = 1.73589912, grad/param norm = 2.7726e-01, time/batch = 0.6316s	
2439/16650 (epoch 7.324), train_loss = 1.51564233, grad/param norm = 2.4660e-01, time/batch = 0.6288s	
2440/16650 (epoch 7.327), train_loss = 1.68619609, grad/param norm = 2.6997e-01, time/batch = 0.6286s	
2441/16650 (epoch 7.330), train_loss = 1.59880623, grad/param norm = 2.5950e-01, time/batch = 0.6377s	
2442/16650 (epoch 7.333), train_loss = 1.66278932, grad/param norm = 2.6894e-01, time/batch = 0.6293s	
2443/16650 (epoch 7.336), train_loss = 1.38841520, grad/param norm = 2.3220e-01, time/batch = 0.6308s	
2444/16650 (epoch 7.339), train_loss = 1.49974300, grad/param norm = 2.5036e-01, time/batch = 0.6317s	
2445/16650 (epoch 7.342), train_loss = 1.53373335, grad/param norm = 2.7903e-01, time/batch = 0.6287s	
2446/16650 (epoch 7.345), train_loss = 1.37304255, grad/param norm = 2.3329e-01, time/batch = 0.6313s	
2447/16650 (epoch 7.348), train_loss = 1.51901977, grad/param norm = 2.3791e-01, time/batch = 0.6316s	
2448/16650 (epoch 7.351), train_loss = 1.63828647, grad/param norm = 2.6074e-01, time/batch = 0.6264s	
2449/16650 (epoch 7.354), train_loss = 1.69227850, grad/param norm = 2.4842e-01, time/batch = 0.6280s	
2450/16650 (epoch 7.357), train_loss = 1.59732727, grad/param norm = 2.5349e-01, time/batch = 0.6360s	
2451/16650 (epoch 7.360), train_loss = 1.57882193, grad/param norm = 2.5432e-01, time/batch = 0.6327s	
2452/16650 (epoch 7.363), train_loss = 1.69364603, grad/param norm = 2.6187e-01, time/batch = 0.6357s	
2453/16650 (epoch 7.366), train_loss = 1.74040295, grad/param norm = 2.6594e-01, time/batch = 0.6320s	
2454/16650 (epoch 7.369), train_loss = 1.55141817, grad/param norm = 2.3784e-01, time/batch = 0.6317s	
2455/16650 (epoch 7.372), train_loss = 1.56474718, grad/param norm = 2.4058e-01, time/batch = 0.6357s	
2456/16650 (epoch 7.375), train_loss = 1.49558385, grad/param norm = 2.4295e-01, time/batch = 0.6662s	
2457/16650 (epoch 7.378), train_loss = 1.35551871, grad/param norm = 2.5342e-01, time/batch = 0.6568s	
2458/16650 (epoch 7.381), train_loss = 1.58835060, grad/param norm = 2.6952e-01, time/batch = 0.6362s	
2459/16650 (epoch 7.384), train_loss = 1.62551401, grad/param norm = 2.4706e-01, time/batch = 0.6366s	
2460/16650 (epoch 7.387), train_loss = 1.29277648, grad/param norm = 2.3953e-01, time/batch = 0.6361s	
2461/16650 (epoch 7.390), train_loss = 1.61570364, grad/param norm = 2.4419e-01, time/batch = 0.6388s	
2462/16650 (epoch 7.393), train_loss = 1.54229007, grad/param norm = 2.7330e-01, time/batch = 0.6317s	
2463/16650 (epoch 7.396), train_loss = 1.69970708, grad/param norm = 2.4815e-01, time/batch = 0.6316s	
2464/16650 (epoch 7.399), train_loss = 1.59955830, grad/param norm = 2.4145e-01, time/batch = 0.6313s	
2465/16650 (epoch 7.402), train_loss = 1.39065049, grad/param norm = 2.2706e-01, time/batch = 0.6303s	
2466/16650 (epoch 7.405), train_loss = 1.37248873, grad/param norm = 2.1850e-01, time/batch = 0.6340s	
2467/16650 (epoch 7.408), train_loss = 1.66849648, grad/param norm = 2.4317e-01, time/batch = 0.6355s	
2468/16650 (epoch 7.411), train_loss = 1.40547684, grad/param norm = 2.3723e-01, time/batch = 0.6332s	
2469/16650 (epoch 7.414), train_loss = 1.34008725, grad/param norm = 2.2231e-01, time/batch = 0.6362s	
2470/16650 (epoch 7.417), train_loss = 1.33157780, grad/param norm = 1.9830e-01, time/batch = 0.6375s	
2471/16650 (epoch 7.420), train_loss = 1.36388434, grad/param norm = 2.4296e-01, time/batch = 0.6377s	
2472/16650 (epoch 7.423), train_loss = 1.08673063, grad/param norm = 1.9227e-01, time/batch = 0.6342s	
2473/16650 (epoch 7.426), train_loss = 1.46068709, grad/param norm = 2.4398e-01, time/batch = 0.6299s	
2474/16650 (epoch 7.429), train_loss = 1.62093618, grad/param norm = 2.4599e-01, time/batch = 0.6299s	
2475/16650 (epoch 7.432), train_loss = 1.57919601, grad/param norm = 2.7068e-01, time/batch = 0.6286s	
2476/16650 (epoch 7.435), train_loss = 1.78076468, grad/param norm = 2.4363e-01, time/batch = 0.6288s	
2477/16650 (epoch 7.438), train_loss = 1.72811522, grad/param norm = 2.4921e-01, time/batch = 0.6327s	
2478/16650 (epoch 7.441), train_loss = 1.64939183, grad/param norm = 2.5637e-01, time/batch = 0.6324s	
2479/16650 (epoch 7.444), train_loss = 1.47911932, grad/param norm = 2.3235e-01, time/batch = 0.6289s	
2480/16650 (epoch 7.447), train_loss = 1.51200865, grad/param norm = 2.6539e-01, time/batch = 0.6327s	
2481/16650 (epoch 7.450), train_loss = 1.41953380, grad/param norm = 2.5659e-01, time/batch = 0.6342s	
2482/16650 (epoch 7.453), train_loss = 1.50425596, grad/param norm = 2.5245e-01, time/batch = 0.6320s	
2483/16650 (epoch 7.456), train_loss = 1.36753132, grad/param norm = 2.4544e-01, time/batch = 0.6340s	
2484/16650 (epoch 7.459), train_loss = 1.46882365, grad/param norm = 2.3815e-01, time/batch = 0.6336s	
2485/16650 (epoch 7.462), train_loss = 1.75945205, grad/param norm = 2.6530e-01, time/batch = 0.6333s	
2486/16650 (epoch 7.465), train_loss = 1.46896529, grad/param norm = 2.4556e-01, time/batch = 0.6317s	
2487/16650 (epoch 7.468), train_loss = 1.16453691, grad/param norm = 2.1869e-01, time/batch = 0.6295s	
2488/16650 (epoch 7.471), train_loss = 1.12935078, grad/param norm = 2.1854e-01, time/batch = 0.6338s	
2489/16650 (epoch 7.474), train_loss = 1.31461324, grad/param norm = 2.0461e-01, time/batch = 0.6310s	
2490/16650 (epoch 7.477), train_loss = 1.52706674, grad/param norm = 2.4465e-01, time/batch = 0.6309s	
2491/16650 (epoch 7.480), train_loss = 1.57407566, grad/param norm = 2.5385e-01, time/batch = 0.6392s	
2492/16650 (epoch 7.483), train_loss = 1.70631694, grad/param norm = 2.6044e-01, time/batch = 0.6319s	
2493/16650 (epoch 7.486), train_loss = 1.33676008, grad/param norm = 2.5736e-01, time/batch = 0.6360s	
2494/16650 (epoch 7.489), train_loss = 1.47049310, grad/param norm = 2.4431e-01, time/batch = 0.6379s	
2495/16650 (epoch 7.492), train_loss = 1.51754780, grad/param norm = 2.4036e-01, time/batch = 0.6322s	
2496/16650 (epoch 7.495), train_loss = 1.40411386, grad/param norm = 2.7065e-01, time/batch = 0.6302s	
2497/16650 (epoch 7.498), train_loss = 1.51469979, grad/param norm = 2.4675e-01, time/batch = 0.6378s	
2498/16650 (epoch 7.502), train_loss = 1.77162609, grad/param norm = 2.8018e-01, time/batch = 0.6463s	
2499/16650 (epoch 7.505), train_loss = 1.53862385, grad/param norm = 2.2204e-01, time/batch = 0.6334s	
2500/16650 (epoch 7.508), train_loss = 1.56206341, grad/param norm = 2.2904e-01, time/batch = 0.6325s	
2501/16650 (epoch 7.511), train_loss = 1.71377670, grad/param norm = 2.9097e-01, time/batch = 0.6338s	
2502/16650 (epoch 7.514), train_loss = 1.39310172, grad/param norm = 2.4519e-01, time/batch = 0.6392s	
2503/16650 (epoch 7.517), train_loss = 1.51422591, grad/param norm = 2.5518e-01, time/batch = 0.6444s	
2504/16650 (epoch 7.520), train_loss = 1.56402105, grad/param norm = 2.4672e-01, time/batch = 0.6508s	
2505/16650 (epoch 7.523), train_loss = 1.47883660, grad/param norm = 2.3093e-01, time/batch = 0.6740s	
2506/16650 (epoch 7.526), train_loss = 1.53212317, grad/param norm = 2.3288e-01, time/batch = 0.6491s	
2507/16650 (epoch 7.529), train_loss = 1.72199650, grad/param norm = 2.5795e-01, time/batch = 0.6318s	
2508/16650 (epoch 7.532), train_loss = 1.36543116, grad/param norm = 2.6198e-01, time/batch = 0.6312s	
2509/16650 (epoch 7.535), train_loss = 1.37347785, grad/param norm = 2.2875e-01, time/batch = 0.6320s	
2510/16650 (epoch 7.538), train_loss = 1.46965807, grad/param norm = 2.3462e-01, time/batch = 0.6322s	
2511/16650 (epoch 7.541), train_loss = 1.70122948, grad/param norm = 2.6690e-01, time/batch = 0.6358s	
2512/16650 (epoch 7.544), train_loss = 1.75604825, grad/param norm = 2.7812e-01, time/batch = 0.6320s	
2513/16650 (epoch 7.547), train_loss = 1.32830748, grad/param norm = 2.1732e-01, time/batch = 0.6332s	
2514/16650 (epoch 7.550), train_loss = 1.39967317, grad/param norm = 2.1806e-01, time/batch = 0.6380s	
2515/16650 (epoch 7.553), train_loss = 1.52919078, grad/param norm = 2.4741e-01, time/batch = 0.6419s	
2516/16650 (epoch 7.556), train_loss = 1.39605936, grad/param norm = 2.2811e-01, time/batch = 0.6450s	
2517/16650 (epoch 7.559), train_loss = 1.25628547, grad/param norm = 2.0662e-01, time/batch = 0.6357s	
2518/16650 (epoch 7.562), train_loss = 1.49610408, grad/param norm = 2.1694e-01, time/batch = 0.6537s	
2519/16650 (epoch 7.565), train_loss = 1.21676850, grad/param norm = 2.2982e-01, time/batch = 0.6554s	
2520/16650 (epoch 7.568), train_loss = 1.25841995, grad/param norm = 2.1571e-01, time/batch = 0.6595s	
2521/16650 (epoch 7.571), train_loss = 1.34073948, grad/param norm = 2.3799e-01, time/batch = 0.6457s	
2522/16650 (epoch 7.574), train_loss = 1.45538997, grad/param norm = 2.2831e-01, time/batch = 0.6439s	
2523/16650 (epoch 7.577), train_loss = 1.43050038, grad/param norm = 2.3290e-01, time/batch = 0.6361s	
2524/16650 (epoch 7.580), train_loss = 1.33452881, grad/param norm = 2.3485e-01, time/batch = 0.6360s	
2525/16650 (epoch 7.583), train_loss = 1.36152063, grad/param norm = 2.4023e-01, time/batch = 0.6314s	
2526/16650 (epoch 7.586), train_loss = 1.53158249, grad/param norm = 2.6718e-01, time/batch = 0.6364s	
2527/16650 (epoch 7.589), train_loss = 1.25415329, grad/param norm = 2.0274e-01, time/batch = 0.6459s	
2528/16650 (epoch 7.592), train_loss = 1.51193042, grad/param norm = 2.8352e-01, time/batch = 0.6417s	
2529/16650 (epoch 7.595), train_loss = 1.38481008, grad/param norm = 2.5909e-01, time/batch = 0.6372s	
2530/16650 (epoch 7.598), train_loss = 1.38731548, grad/param norm = 2.7263e-01, time/batch = 0.6376s	
2531/16650 (epoch 7.601), train_loss = 1.41316509, grad/param norm = 2.9109e-01, time/batch = 0.6317s	
2532/16650 (epoch 7.604), train_loss = 1.58094249, grad/param norm = 2.6621e-01, time/batch = 0.6295s	
2533/16650 (epoch 7.607), train_loss = 1.47038991, grad/param norm = 2.3421e-01, time/batch = 0.6299s	
2534/16650 (epoch 7.610), train_loss = 1.37043753, grad/param norm = 2.2145e-01, time/batch = 0.6625s	
2535/16650 (epoch 7.613), train_loss = 1.63034796, grad/param norm = 2.5863e-01, time/batch = 0.6561s	
2536/16650 (epoch 7.616), train_loss = 1.68731637, grad/param norm = 2.7787e-01, time/batch = 0.6317s	
2537/16650 (epoch 7.619), train_loss = 1.36858643, grad/param norm = 2.5005e-01, time/batch = 0.6312s	
2538/16650 (epoch 7.622), train_loss = 1.24552471, grad/param norm = 2.2411e-01, time/batch = 0.6399s	
2539/16650 (epoch 7.625), train_loss = 1.41198434, grad/param norm = 2.2283e-01, time/batch = 0.6695s	
2540/16650 (epoch 7.628), train_loss = 1.42095993, grad/param norm = 2.4585e-01, time/batch = 0.6418s	
2541/16650 (epoch 7.631), train_loss = 1.46616686, grad/param norm = 2.5579e-01, time/batch = 0.6320s	
2542/16650 (epoch 7.634), train_loss = 1.67660681, grad/param norm = 2.4844e-01, time/batch = 0.6322s	
2543/16650 (epoch 7.637), train_loss = 1.72797391, grad/param norm = 2.6880e-01, time/batch = 0.6577s	
2544/16650 (epoch 7.640), train_loss = 1.45072353, grad/param norm = 2.4288e-01, time/batch = 0.6657s	
2545/16650 (epoch 7.643), train_loss = 1.56172987, grad/param norm = 2.5526e-01, time/batch = 0.6328s	
2546/16650 (epoch 7.646), train_loss = 1.62581641, grad/param norm = 2.5312e-01, time/batch = 0.6300s	
2547/16650 (epoch 7.649), train_loss = 1.49190331, grad/param norm = 2.4582e-01, time/batch = 0.6300s	
2548/16650 (epoch 7.652), train_loss = 1.66931518, grad/param norm = 2.7482e-01, time/batch = 0.6288s	
2549/16650 (epoch 7.655), train_loss = 1.49971821, grad/param norm = 2.2256e-01, time/batch = 0.6276s	
2550/16650 (epoch 7.658), train_loss = 1.37878978, grad/param norm = 2.4148e-01, time/batch = 0.6301s	
2551/16650 (epoch 7.661), train_loss = 1.56967556, grad/param norm = 2.3033e-01, time/batch = 0.6483s	
2552/16650 (epoch 7.664), train_loss = 1.51508817, grad/param norm = 2.4553e-01, time/batch = 0.6397s	
2553/16650 (epoch 7.667), train_loss = 1.65448100, grad/param norm = 2.4542e-01, time/batch = 0.6346s	
2554/16650 (epoch 7.670), train_loss = 1.34490736, grad/param norm = 2.3021e-01, time/batch = 0.6302s	
2555/16650 (epoch 7.673), train_loss = 1.34496731, grad/param norm = 2.1978e-01, time/batch = 0.6297s	
2556/16650 (epoch 7.676), train_loss = 1.49717585, grad/param norm = 2.4133e-01, time/batch = 0.6283s	
2557/16650 (epoch 7.679), train_loss = 1.37546057, grad/param norm = 2.2986e-01, time/batch = 0.6282s	
2558/16650 (epoch 7.682), train_loss = 1.58254340, grad/param norm = 2.6523e-01, time/batch = 0.6313s	
2559/16650 (epoch 7.685), train_loss = 1.34406518, grad/param norm = 2.3675e-01, time/batch = 0.6294s	
2560/16650 (epoch 7.688), train_loss = 1.47974036, grad/param norm = 2.5078e-01, time/batch = 0.6315s	
2561/16650 (epoch 7.691), train_loss = 1.54318653, grad/param norm = 2.5726e-01, time/batch = 0.6335s	
2562/16650 (epoch 7.694), train_loss = 1.34797517, grad/param norm = 2.3245e-01, time/batch = 0.6314s	
2563/16650 (epoch 7.697), train_loss = 1.29065083, grad/param norm = 2.1200e-01, time/batch = 0.6300s	
2564/16650 (epoch 7.700), train_loss = 1.60079005, grad/param norm = 2.3954e-01, time/batch = 0.6289s	
2565/16650 (epoch 7.703), train_loss = 1.41325512, grad/param norm = 2.6058e-01, time/batch = 0.6326s	
2566/16650 (epoch 7.706), train_loss = 1.57844762, grad/param norm = 2.5712e-01, time/batch = 0.6326s	
2567/16650 (epoch 7.709), train_loss = 1.38226205, grad/param norm = 2.3467e-01, time/batch = 0.6329s	
2568/16650 (epoch 7.712), train_loss = 1.39472663, grad/param norm = 2.4088e-01, time/batch = 0.6308s	
2569/16650 (epoch 7.715), train_loss = 1.61619684, grad/param norm = 2.4879e-01, time/batch = 0.6323s	
2570/16650 (epoch 7.718), train_loss = 1.67439425, grad/param norm = 2.4347e-01, time/batch = 0.6309s	
2571/16650 (epoch 7.721), train_loss = 1.63070063, grad/param norm = 2.6535e-01, time/batch = 0.6300s	
2572/16650 (epoch 7.724), train_loss = 1.64469073, grad/param norm = 2.5223e-01, time/batch = 0.6308s	
2573/16650 (epoch 7.727), train_loss = 1.55264335, grad/param norm = 2.2062e-01, time/batch = 0.6294s	
2574/16650 (epoch 7.730), train_loss = 1.45069793, grad/param norm = 2.4501e-01, time/batch = 0.6283s	
2575/16650 (epoch 7.733), train_loss = 1.63774523, grad/param norm = 2.5958e-01, time/batch = 0.6288s	
2576/16650 (epoch 7.736), train_loss = 1.34074767, grad/param norm = 2.1761e-01, time/batch = 0.6294s	
2577/16650 (epoch 7.739), train_loss = 1.51754486, grad/param norm = 2.3294e-01, time/batch = 0.6281s	
2578/16650 (epoch 7.742), train_loss = 1.52263213, grad/param norm = 2.5497e-01, time/batch = 0.6314s	
2579/16650 (epoch 7.745), train_loss = 1.25630990, grad/param norm = 2.1239e-01, time/batch = 0.6316s	
2580/16650 (epoch 7.748), train_loss = 1.36367837, grad/param norm = 2.4960e-01, time/batch = 0.6290s	
2581/16650 (epoch 7.751), train_loss = 1.56578666, grad/param norm = 2.5809e-01, time/batch = 0.6310s	
2582/16650 (epoch 7.754), train_loss = 1.69711380, grad/param norm = 2.5067e-01, time/batch = 0.6301s	
2583/16650 (epoch 7.757), train_loss = 1.57558992, grad/param norm = 2.3196e-01, time/batch = 0.6291s	
2584/16650 (epoch 7.760), train_loss = 1.44937818, grad/param norm = 2.4650e-01, time/batch = 0.6278s	
2585/16650 (epoch 7.763), train_loss = 1.37795338, grad/param norm = 2.3734e-01, time/batch = 0.6279s	
2586/16650 (epoch 7.766), train_loss = 1.49415269, grad/param norm = 2.3190e-01, time/batch = 0.6281s	
2587/16650 (epoch 7.769), train_loss = 1.45056101, grad/param norm = 2.4403e-01, time/batch = 0.6289s	
2588/16650 (epoch 7.772), train_loss = 1.38136868, grad/param norm = 2.0898e-01, time/batch = 0.6278s	
2589/16650 (epoch 7.775), train_loss = 1.47660990, grad/param norm = 2.2101e-01, time/batch = 0.6271s	
2590/16650 (epoch 7.778), train_loss = 1.36046034, grad/param norm = 2.2498e-01, time/batch = 0.6270s	
2591/16650 (epoch 7.781), train_loss = 1.55202644, grad/param norm = 2.5445e-01, time/batch = 0.6293s	
2592/16650 (epoch 7.784), train_loss = 1.57521618, grad/param norm = 2.6256e-01, time/batch = 0.6592s	
2593/16650 (epoch 7.787), train_loss = 1.60414218, grad/param norm = 2.4285e-01, time/batch = 0.6581s	
2594/16650 (epoch 7.790), train_loss = 1.43731147, grad/param norm = 2.3185e-01, time/batch = 0.6289s	
2595/16650 (epoch 7.793), train_loss = 1.38899886, grad/param norm = 2.7883e-01, time/batch = 0.6357s	
2596/16650 (epoch 7.796), train_loss = 1.89193543, grad/param norm = 2.7262e-01, time/batch = 0.6436s	
2597/16650 (epoch 7.799), train_loss = 1.71754715, grad/param norm = 2.3929e-01, time/batch = 0.6688s	
2598/16650 (epoch 7.802), train_loss = 1.51750612, grad/param norm = 2.6738e-01, time/batch = 0.6509s	
2599/16650 (epoch 7.805), train_loss = 1.48625161, grad/param norm = 2.3321e-01, time/batch = 0.6598s	
2600/16650 (epoch 7.808), train_loss = 1.47621772, grad/param norm = 2.2123e-01, time/batch = 0.6617s	
2601/16650 (epoch 7.811), train_loss = 1.61466797, grad/param norm = 2.3677e-01, time/batch = 0.6433s	
2602/16650 (epoch 7.814), train_loss = 1.36827047, grad/param norm = 2.1944e-01, time/batch = 0.6330s	
2603/16650 (epoch 7.817), train_loss = 1.45672863, grad/param norm = 2.4531e-01, time/batch = 0.6307s	
2604/16650 (epoch 7.820), train_loss = 1.53501199, grad/param norm = 2.4852e-01, time/batch = 0.6325s	
2605/16650 (epoch 7.823), train_loss = 1.34083933, grad/param norm = 2.2066e-01, time/batch = 0.6289s	
2606/16650 (epoch 7.826), train_loss = 1.45901023, grad/param norm = 2.0682e-01, time/batch = 0.6290s	
2607/16650 (epoch 7.829), train_loss = 1.64947237, grad/param norm = 2.5969e-01, time/batch = 0.6318s	
2608/16650 (epoch 7.832), train_loss = 1.64087853, grad/param norm = 2.4497e-01, time/batch = 0.6273s	
2609/16650 (epoch 7.835), train_loss = 1.62754401, grad/param norm = 2.8318e-01, time/batch = 0.6294s	
2610/16650 (epoch 7.838), train_loss = 1.38234632, grad/param norm = 2.6371e-01, time/batch = 0.6316s	
2611/16650 (epoch 7.841), train_loss = 1.32972009, grad/param norm = 2.0755e-01, time/batch = 0.6383s	
2612/16650 (epoch 7.844), train_loss = 1.42786128, grad/param norm = 2.3760e-01, time/batch = 0.6359s	
2613/16650 (epoch 7.847), train_loss = 1.62201739, grad/param norm = 2.2662e-01, time/batch = 0.6299s	
2614/16650 (epoch 7.850), train_loss = 1.35300022, grad/param norm = 2.4740e-01, time/batch = 0.6316s	
2615/16650 (epoch 7.853), train_loss = 1.55480625, grad/param norm = 2.4051e-01, time/batch = 0.6361s	
2616/16650 (epoch 7.856), train_loss = 1.38191455, grad/param norm = 2.3940e-01, time/batch = 0.6289s	
2617/16650 (epoch 7.859), train_loss = 1.52958724, grad/param norm = 2.3394e-01, time/batch = 0.6299s	
2618/16650 (epoch 7.862), train_loss = 1.46711997, grad/param norm = 2.2791e-01, time/batch = 0.6308s	
2619/16650 (epoch 7.865), train_loss = 1.22803037, grad/param norm = 2.2043e-01, time/batch = 0.6358s	
2620/16650 (epoch 7.868), train_loss = 1.55130950, grad/param norm = 2.3764e-01, time/batch = 0.6325s	
2621/16650 (epoch 7.871), train_loss = 1.57208181, grad/param norm = 2.6184e-01, time/batch = 0.6388s	
2622/16650 (epoch 7.874), train_loss = 1.55436951, grad/param norm = 2.4254e-01, time/batch = 0.6304s	
2623/16650 (epoch 7.877), train_loss = 1.36840637, grad/param norm = 2.1383e-01, time/batch = 0.6334s	
2624/16650 (epoch 7.880), train_loss = 1.43070758, grad/param norm = 2.6403e-01, time/batch = 0.6303s	
2625/16650 (epoch 7.883), train_loss = 1.55374962, grad/param norm = 2.4585e-01, time/batch = 0.6354s	
2626/16650 (epoch 7.886), train_loss = 1.53356955, grad/param norm = 2.3552e-01, time/batch = 0.6387s	
2627/16650 (epoch 7.889), train_loss = 1.38652978, grad/param norm = 2.4073e-01, time/batch = 0.6465s	
2628/16650 (epoch 7.892), train_loss = 1.40685372, grad/param norm = 2.1283e-01, time/batch = 0.6578s	
2629/16650 (epoch 7.895), train_loss = 1.58553118, grad/param norm = 2.4610e-01, time/batch = 0.6599s	
2630/16650 (epoch 7.898), train_loss = 1.54733995, grad/param norm = 2.6542e-01, time/batch = 0.6555s	
2631/16650 (epoch 7.901), train_loss = 1.49756036, grad/param norm = 2.1984e-01, time/batch = 0.6557s	
2632/16650 (epoch 7.904), train_loss = 1.41504024, grad/param norm = 2.3458e-01, time/batch = 0.6573s	
2633/16650 (epoch 7.907), train_loss = 1.48285069, grad/param norm = 2.3199e-01, time/batch = 0.6489s	
2634/16650 (epoch 7.910), train_loss = 1.50988312, grad/param norm = 2.5794e-01, time/batch = 0.6493s	
2635/16650 (epoch 7.913), train_loss = 1.43432064, grad/param norm = 2.4567e-01, time/batch = 0.6472s	
2636/16650 (epoch 7.916), train_loss = 1.52773419, grad/param norm = 2.5123e-01, time/batch = 0.6727s	
2637/16650 (epoch 7.919), train_loss = 1.61908419, grad/param norm = 2.6994e-01, time/batch = 0.6433s	
2638/16650 (epoch 7.922), train_loss = 1.62623118, grad/param norm = 2.5951e-01, time/batch = 0.6365s	
2639/16650 (epoch 7.925), train_loss = 1.44999266, grad/param norm = 2.5772e-01, time/batch = 0.6286s	
2640/16650 (epoch 7.928), train_loss = 1.45317873, grad/param norm = 2.2575e-01, time/batch = 0.6302s	
2641/16650 (epoch 7.931), train_loss = 1.50724653, grad/param norm = 2.3592e-01, time/batch = 0.6358s	
2642/16650 (epoch 7.934), train_loss = 1.32770794, grad/param norm = 2.3414e-01, time/batch = 0.6292s	
2643/16650 (epoch 7.937), train_loss = 1.48588559, grad/param norm = 2.5769e-01, time/batch = 0.6304s	
2644/16650 (epoch 7.940), train_loss = 1.40443567, grad/param norm = 2.0506e-01, time/batch = 0.6317s	
2645/16650 (epoch 7.943), train_loss = 1.39833211, grad/param norm = 2.1677e-01, time/batch = 0.6367s	
2646/16650 (epoch 7.946), train_loss = 1.40716089, grad/param norm = 2.3832e-01, time/batch = 0.6331s	
2647/16650 (epoch 7.949), train_loss = 1.44107018, grad/param norm = 2.1847e-01, time/batch = 0.6300s	
2648/16650 (epoch 7.952), train_loss = 1.18358853, grad/param norm = 2.3616e-01, time/batch = 0.6286s	
2649/16650 (epoch 7.955), train_loss = 1.41111541, grad/param norm = 2.4011e-01, time/batch = 0.6310s	
2650/16650 (epoch 7.958), train_loss = 1.59106653, grad/param norm = 2.6944e-01, time/batch = 0.6277s	
2651/16650 (epoch 7.961), train_loss = 1.39441187, grad/param norm = 2.3130e-01, time/batch = 0.6360s	
2652/16650 (epoch 7.964), train_loss = 1.38253682, grad/param norm = 2.4487e-01, time/batch = 0.6434s	
2653/16650 (epoch 7.967), train_loss = 1.65103782, grad/param norm = 2.5029e-01, time/batch = 0.6366s	
2654/16650 (epoch 7.970), train_loss = 1.25741224, grad/param norm = 2.1600e-01, time/batch = 0.6422s	
2655/16650 (epoch 7.973), train_loss = 1.47853193, grad/param norm = 2.9780e-01, time/batch = 0.6288s	
2656/16650 (epoch 7.976), train_loss = 1.37042574, grad/param norm = 2.2531e-01, time/batch = 0.6279s	
2657/16650 (epoch 7.979), train_loss = 1.56017333, grad/param norm = 2.4049e-01, time/batch = 0.6299s	
2658/16650 (epoch 7.982), train_loss = 1.54269133, grad/param norm = 2.5133e-01, time/batch = 0.6312s	
2659/16650 (epoch 7.985), train_loss = 1.41278623, grad/param norm = 2.3128e-01, time/batch = 0.6310s	
2660/16650 (epoch 7.988), train_loss = 1.73298272, grad/param norm = 2.6155e-01, time/batch = 0.6323s	
2661/16650 (epoch 7.991), train_loss = 1.39570984, grad/param norm = 2.4868e-01, time/batch = 0.6336s	
2662/16650 (epoch 7.994), train_loss = 1.42950654, grad/param norm = 2.2430e-01, time/batch = 0.6339s	
2663/16650 (epoch 7.997), train_loss = 1.54850263, grad/param norm = 2.4895e-01, time/batch = 0.6285s	
2664/16650 (epoch 8.000), train_loss = 1.59302052, grad/param norm = 3.0998e-01, time/batch = 0.6277s	
2665/16650 (epoch 8.003), train_loss = 1.58454433, grad/param norm = 2.7816e-01, time/batch = 0.6282s	
2666/16650 (epoch 8.006), train_loss = 1.61142258, grad/param norm = 2.5623e-01, time/batch = 0.6274s	
2667/16650 (epoch 8.009), train_loss = 1.68980311, grad/param norm = 2.4882e-01, time/batch = 0.6279s	
2668/16650 (epoch 8.012), train_loss = 1.74293280, grad/param norm = 2.9434e-01, time/batch = 0.6279s	
2669/16650 (epoch 8.015), train_loss = 1.57448049, grad/param norm = 2.6218e-01, time/batch = 0.6292s	
2670/16650 (epoch 8.018), train_loss = 1.22223767, grad/param norm = 2.3698e-01, time/batch = 0.6574s	
2671/16650 (epoch 8.021), train_loss = 1.63259736, grad/param norm = 2.4627e-01, time/batch = 0.6662s	
2672/16650 (epoch 8.024), train_loss = 1.42167208, grad/param norm = 2.3727e-01, time/batch = 0.6316s	
2673/16650 (epoch 8.027), train_loss = 1.63627377, grad/param norm = 2.5958e-01, time/batch = 0.6315s	
2674/16650 (epoch 8.030), train_loss = 1.34376642, grad/param norm = 2.2806e-01, time/batch = 0.6322s	
2675/16650 (epoch 8.033), train_loss = 1.49249435, grad/param norm = 2.3131e-01, time/batch = 0.6685s	
2676/16650 (epoch 8.036), train_loss = 1.33763323, grad/param norm = 2.6231e-01, time/batch = 0.6454s	
2677/16650 (epoch 8.039), train_loss = 1.57164001, grad/param norm = 2.6134e-01, time/batch = 0.6285s	
2678/16650 (epoch 8.042), train_loss = 1.60342920, grad/param norm = 2.3685e-01, time/batch = 0.6315s	
2679/16650 (epoch 8.045), train_loss = 1.41092920, grad/param norm = 2.2284e-01, time/batch = 0.6312s	
2680/16650 (epoch 8.048), train_loss = 1.54272085, grad/param norm = 2.4656e-01, time/batch = 0.6265s	
2681/16650 (epoch 8.051), train_loss = 1.53213573, grad/param norm = 2.5774e-01, time/batch = 0.6300s	
2682/16650 (epoch 8.054), train_loss = 1.51034959, grad/param norm = 2.2861e-01, time/batch = 0.6300s	
2683/16650 (epoch 8.057), train_loss = 1.45157724, grad/param norm = 2.2717e-01, time/batch = 0.6317s	
2684/16650 (epoch 8.060), train_loss = 1.35910230, grad/param norm = 2.1961e-01, time/batch = 0.6287s	
2685/16650 (epoch 8.063), train_loss = 1.46293638, grad/param norm = 2.4345e-01, time/batch = 0.6313s	
2686/16650 (epoch 8.066), train_loss = 1.65765845, grad/param norm = 2.7009e-01, time/batch = 0.6305s	
2687/16650 (epoch 8.069), train_loss = 1.59989281, grad/param norm = 2.5495e-01, time/batch = 0.6317s	
2688/16650 (epoch 8.072), train_loss = 1.43707756, grad/param norm = 2.4470e-01, time/batch = 0.6265s	
2689/16650 (epoch 8.075), train_loss = 1.48638446, grad/param norm = 2.4345e-01, time/batch = 0.6311s	
2690/16650 (epoch 8.078), train_loss = 1.53606553, grad/param norm = 2.2515e-01, time/batch = 0.6428s	
2691/16650 (epoch 8.081), train_loss = 1.44864025, grad/param norm = 2.4554e-01, time/batch = 0.6469s	
2692/16650 (epoch 8.084), train_loss = 1.55768477, grad/param norm = 2.2173e-01, time/batch = 0.6517s	
2693/16650 (epoch 8.087), train_loss = 1.50187232, grad/param norm = 2.2447e-01, time/batch = 0.6586s	
2694/16650 (epoch 8.090), train_loss = 1.35981903, grad/param norm = 2.2389e-01, time/batch = 0.6591s	
2695/16650 (epoch 8.093), train_loss = 1.78512935, grad/param norm = 2.5825e-01, time/batch = 0.6424s	
2696/16650 (epoch 8.096), train_loss = 1.45713349, grad/param norm = 2.3321e-01, time/batch = 0.6466s	
2697/16650 (epoch 8.099), train_loss = 1.43114791, grad/param norm = 2.2107e-01, time/batch = 0.6545s	
2698/16650 (epoch 8.102), train_loss = 1.48881026, grad/param norm = 2.3547e-01, time/batch = 0.6490s	
2699/16650 (epoch 8.105), train_loss = 1.58065086, grad/param norm = 2.4532e-01, time/batch = 0.6369s	
2700/16650 (epoch 8.108), train_loss = 1.58443107, grad/param norm = 2.4237e-01, time/batch = 0.6322s	
2701/16650 (epoch 8.111), train_loss = 1.52265170, grad/param norm = 2.4290e-01, time/batch = 0.6371s	
2702/16650 (epoch 8.114), train_loss = 1.64989691, grad/param norm = 2.2898e-01, time/batch = 0.6387s	
2703/16650 (epoch 8.117), train_loss = 1.59057743, grad/param norm = 2.4512e-01, time/batch = 0.6382s	
2704/16650 (epoch 8.120), train_loss = 1.37810009, grad/param norm = 2.3168e-01, time/batch = 0.6535s	
2705/16650 (epoch 8.123), train_loss = 1.47108161, grad/param norm = 2.4709e-01, time/batch = 0.6692s	
2706/16650 (epoch 8.126), train_loss = 1.53156565, grad/param norm = 2.7003e-01, time/batch = 0.6446s	
2707/16650 (epoch 8.129), train_loss = 1.54027577, grad/param norm = 2.3919e-01, time/batch = 0.6300s	
2708/16650 (epoch 8.132), train_loss = 1.61659196, grad/param norm = 2.4424e-01, time/batch = 0.6308s	
2709/16650 (epoch 8.135), train_loss = 1.55551701, grad/param norm = 2.5494e-01, time/batch = 0.6350s	
2710/16650 (epoch 8.138), train_loss = 1.56375654, grad/param norm = 2.6072e-01, time/batch = 0.6423s	
2711/16650 (epoch 8.141), train_loss = 1.59272448, grad/param norm = 2.8583e-01, time/batch = 0.6413s	
2712/16650 (epoch 8.144), train_loss = 1.48317018, grad/param norm = 2.3951e-01, time/batch = 0.6405s	
2713/16650 (epoch 8.147), train_loss = 1.65435023, grad/param norm = 2.7487e-01, time/batch = 0.6358s	
2714/16650 (epoch 8.150), train_loss = 1.75114896, grad/param norm = 2.5195e-01, time/batch = 0.6361s	
2715/16650 (epoch 8.153), train_loss = 1.48180001, grad/param norm = 2.2981e-01, time/batch = 0.6422s	
2716/16650 (epoch 8.156), train_loss = 1.32754839, grad/param norm = 2.2583e-01, time/batch = 0.6575s	
2717/16650 (epoch 8.159), train_loss = 1.65931630, grad/param norm = 2.5147e-01, time/batch = 0.6443s	
2718/16650 (epoch 8.162), train_loss = 1.56725344, grad/param norm = 2.4200e-01, time/batch = 0.6522s	
2719/16650 (epoch 8.165), train_loss = 1.56788009, grad/param norm = 2.4387e-01, time/batch = 0.6416s	
2720/16650 (epoch 8.168), train_loss = 1.21054084, grad/param norm = 2.1357e-01, time/batch = 0.6398s	
2721/16650 (epoch 8.171), train_loss = 1.56224652, grad/param norm = 2.2046e-01, time/batch = 0.6419s	
2722/16650 (epoch 8.174), train_loss = 1.33016851, grad/param norm = 2.3833e-01, time/batch = 0.6476s	
2723/16650 (epoch 8.177), train_loss = 1.49085696, grad/param norm = 2.3163e-01, time/batch = 0.6669s	
2724/16650 (epoch 8.180), train_loss = 1.65040147, grad/param norm = 2.3860e-01, time/batch = 0.6719s	
2725/16650 (epoch 8.183), train_loss = 1.76830120, grad/param norm = 2.5588e-01, time/batch = 0.6744s	
2726/16650 (epoch 8.186), train_loss = 1.60463245, grad/param norm = 2.3824e-01, time/batch = 0.6432s	
2727/16650 (epoch 8.189), train_loss = 1.37253285, grad/param norm = 2.2294e-01, time/batch = 0.6473s	
2728/16650 (epoch 8.192), train_loss = 1.41681334, grad/param norm = 2.6645e-01, time/batch = 0.6356s	
2729/16650 (epoch 8.195), train_loss = 1.51647692, grad/param norm = 2.4314e-01, time/batch = 0.6270s	
2730/16650 (epoch 8.198), train_loss = 1.24855892, grad/param norm = 2.3215e-01, time/batch = 0.6293s	
2731/16650 (epoch 8.201), train_loss = 1.47086868, grad/param norm = 2.3965e-01, time/batch = 0.6336s	
2732/16650 (epoch 8.204), train_loss = 1.49676128, grad/param norm = 2.6090e-01, time/batch = 0.6387s	
2733/16650 (epoch 8.207), train_loss = 1.56012687, grad/param norm = 2.5511e-01, time/batch = 0.6300s	
2734/16650 (epoch 8.210), train_loss = 1.41924478, grad/param norm = 2.2196e-01, time/batch = 0.6290s	
2735/16650 (epoch 8.213), train_loss = 1.54418549, grad/param norm = 2.3427e-01, time/batch = 0.6305s	
2736/16650 (epoch 8.216), train_loss = 1.47363721, grad/param norm = 2.4990e-01, time/batch = 0.6310s	
2737/16650 (epoch 8.219), train_loss = 1.48020786, grad/param norm = 2.4442e-01, time/batch = 0.6291s	
2738/16650 (epoch 8.222), train_loss = 1.49014098, grad/param norm = 2.4294e-01, time/batch = 0.6307s	
2739/16650 (epoch 8.225), train_loss = 1.51707763, grad/param norm = 2.5514e-01, time/batch = 0.6305s	
2740/16650 (epoch 8.228), train_loss = 1.41348985, grad/param norm = 2.3490e-01, time/batch = 0.6294s	
2741/16650 (epoch 8.231), train_loss = 1.48679791, grad/param norm = 2.4112e-01, time/batch = 0.6340s	
2742/16650 (epoch 8.234), train_loss = 1.60890783, grad/param norm = 2.3873e-01, time/batch = 0.6310s	
2743/16650 (epoch 8.237), train_loss = 1.47978200, grad/param norm = 2.4722e-01, time/batch = 0.6313s	
2744/16650 (epoch 8.240), train_loss = 1.54332460, grad/param norm = 2.3574e-01, time/batch = 0.6332s	
2745/16650 (epoch 8.243), train_loss = 1.53222660, grad/param norm = 2.3789e-01, time/batch = 0.6310s	
2746/16650 (epoch 8.246), train_loss = 1.62572704, grad/param norm = 2.4519e-01, time/batch = 0.6307s	
2747/16650 (epoch 8.249), train_loss = 1.35123970, grad/param norm = 2.3044e-01, time/batch = 0.6484s	
2748/16650 (epoch 8.252), train_loss = 1.48267484, grad/param norm = 2.4430e-01, time/batch = 0.6447s	
2749/16650 (epoch 8.255), train_loss = 1.64044956, grad/param norm = 2.7225e-01, time/batch = 0.6395s	
2750/16650 (epoch 8.258), train_loss = 1.59102726, grad/param norm = 2.5292e-01, time/batch = 0.6383s	
2751/16650 (epoch 8.261), train_loss = 1.49674993, grad/param norm = 2.2978e-01, time/batch = 0.6399s	
2752/16650 (epoch 8.264), train_loss = 1.46473520, grad/param norm = 2.5447e-01, time/batch = 0.6395s	
2753/16650 (epoch 8.267), train_loss = 1.39149480, grad/param norm = 2.5365e-01, time/batch = 0.6400s	
2754/16650 (epoch 8.270), train_loss = 1.44948008, grad/param norm = 2.1774e-01, time/batch = 0.6364s	
2755/16650 (epoch 8.273), train_loss = 1.60414246, grad/param norm = 2.1771e-01, time/batch = 0.6344s	
2756/16650 (epoch 8.276), train_loss = 1.48380297, grad/param norm = 2.2380e-01, time/batch = 0.6321s	
2757/16650 (epoch 8.279), train_loss = 1.49098140, grad/param norm = 2.3031e-01, time/batch = 0.6297s	
2758/16650 (epoch 8.282), train_loss = 1.29703262, grad/param norm = 2.0472e-01, time/batch = 0.6297s	
2759/16650 (epoch 8.285), train_loss = 1.34633661, grad/param norm = 2.3484e-01, time/batch = 0.6293s	
2760/16650 (epoch 8.288), train_loss = 1.43215647, grad/param norm = 2.2178e-01, time/batch = 0.6293s	
2761/16650 (epoch 8.291), train_loss = 1.19227509, grad/param norm = 1.9288e-01, time/batch = 0.6356s	
2762/16650 (epoch 8.294), train_loss = 1.26177019, grad/param norm = 1.8680e-01, time/batch = 0.6342s	
2763/16650 (epoch 8.297), train_loss = 1.36356782, grad/param norm = 2.1767e-01, time/batch = 0.6451s	
2764/16650 (epoch 8.300), train_loss = 1.22218794, grad/param norm = 2.2379e-01, time/batch = 0.6686s	
2765/16650 (epoch 8.303), train_loss = 1.24211564, grad/param norm = 2.0788e-01, time/batch = 0.6346s	
2766/16650 (epoch 8.306), train_loss = 1.51010011, grad/param norm = 2.3179e-01, time/batch = 0.6287s	
2767/16650 (epoch 8.309), train_loss = 1.60446292, grad/param norm = 2.4787e-01, time/batch = 0.6299s	
2768/16650 (epoch 8.312), train_loss = 1.35792024, grad/param norm = 2.3022e-01, time/batch = 0.6562s	
2769/16650 (epoch 8.315), train_loss = 1.15170333, grad/param norm = 2.0837e-01, time/batch = 0.6620s	
2770/16650 (epoch 8.318), train_loss = 1.27489744, grad/param norm = 2.1410e-01, time/batch = 0.6306s	
2771/16650 (epoch 8.321), train_loss = 1.66154788, grad/param norm = 2.7577e-01, time/batch = 0.6323s	
2772/16650 (epoch 8.324), train_loss = 1.43529024, grad/param norm = 2.3826e-01, time/batch = 0.6355s	
2773/16650 (epoch 8.327), train_loss = 1.62602401, grad/param norm = 2.6633e-01, time/batch = 0.6686s	
2774/16650 (epoch 8.330), train_loss = 1.53534853, grad/param norm = 2.7451e-01, time/batch = 0.6356s	
2775/16650 (epoch 8.333), train_loss = 1.58717045, grad/param norm = 2.7163e-01, time/batch = 0.6287s	
2776/16650 (epoch 8.336), train_loss = 1.33384911, grad/param norm = 2.2625e-01, time/batch = 0.6313s	
2777/16650 (epoch 8.339), train_loss = 1.44328791, grad/param norm = 2.5186e-01, time/batch = 0.6466s	
2778/16650 (epoch 8.342), train_loss = 1.45799500, grad/param norm = 2.6752e-01, time/batch = 0.6683s	
2779/16650 (epoch 8.345), train_loss = 1.30059519, grad/param norm = 2.1718e-01, time/batch = 0.6359s	
2780/16650 (epoch 8.348), train_loss = 1.46672548, grad/param norm = 2.2632e-01, time/batch = 0.6301s	
2781/16650 (epoch 8.351), train_loss = 1.56589716, grad/param norm = 2.5211e-01, time/batch = 0.6330s	
2782/16650 (epoch 8.354), train_loss = 1.63326788, grad/param norm = 2.3792e-01, time/batch = 0.6303s	
2783/16650 (epoch 8.357), train_loss = 1.53835639, grad/param norm = 2.5218e-01, time/batch = 0.6380s	
2784/16650 (epoch 8.360), train_loss = 1.51709562, grad/param norm = 2.4715e-01, time/batch = 0.6467s	
2785/16650 (epoch 8.363), train_loss = 1.62925753, grad/param norm = 2.5968e-01, time/batch = 0.6479s	
2786/16650 (epoch 8.366), train_loss = 1.68730609, grad/param norm = 2.6349e-01, time/batch = 1.5929s	
2787/16650 (epoch 8.369), train_loss = 1.48976968, grad/param norm = 2.3488e-01, time/batch = 0.6786s	
2788/16650 (epoch 8.372), train_loss = 1.49053797, grad/param norm = 2.3166e-01, time/batch = 0.6459s	
2789/16650 (epoch 8.375), train_loss = 1.42826617, grad/param norm = 2.3652e-01, time/batch = 0.6396s	
2790/16650 (epoch 8.378), train_loss = 1.30053432, grad/param norm = 2.3414e-01, time/batch = 0.6306s	
2791/16650 (epoch 8.381), train_loss = 1.52176936, grad/param norm = 2.5996e-01, time/batch = 0.6355s	
2792/16650 (epoch 8.384), train_loss = 1.57850768, grad/param norm = 2.4166e-01, time/batch = 0.6325s	
2793/16650 (epoch 8.387), train_loss = 1.21944008, grad/param norm = 2.2382e-01, time/batch = 0.6893s	
2794/16650 (epoch 8.390), train_loss = 1.55559333, grad/param norm = 2.4363e-01, time/batch = 0.6308s	
2795/16650 (epoch 8.393), train_loss = 1.48432736, grad/param norm = 2.6917e-01, time/batch = 0.6289s	
2796/16650 (epoch 8.396), train_loss = 1.64443446, grad/param norm = 2.5442e-01, time/batch = 0.6415s	
2797/16650 (epoch 8.399), train_loss = 1.54489392, grad/param norm = 2.5244e-01, time/batch = 0.6357s	
2798/16650 (epoch 8.402), train_loss = 1.33560745, grad/param norm = 2.2583e-01, time/batch = 0.6473s	
2799/16650 (epoch 8.405), train_loss = 1.31119111, grad/param norm = 2.2082e-01, time/batch = 0.6809s	
2800/16650 (epoch 8.408), train_loss = 1.61062626, grad/param norm = 2.3935e-01, time/batch = 0.6538s	
2801/16650 (epoch 8.411), train_loss = 1.34121817, grad/param norm = 2.4285e-01, time/batch = 0.6398s	
2802/16650 (epoch 8.414), train_loss = 1.28944291, grad/param norm = 2.1708e-01, time/batch = 0.6476s	
2803/16650 (epoch 8.417), train_loss = 1.26751517, grad/param norm = 1.9138e-01, time/batch = 0.6420s	
2804/16650 (epoch 8.420), train_loss = 1.29879918, grad/param norm = 2.3551e-01, time/batch = 0.6293s	
2805/16650 (epoch 8.423), train_loss = 1.03699581, grad/param norm = 1.8524e-01, time/batch = 0.6520s	
2806/16650 (epoch 8.426), train_loss = 1.37856809, grad/param norm = 2.4088e-01, time/batch = 0.6663s	
2807/16650 (epoch 8.429), train_loss = 1.56073989, grad/param norm = 2.4859e-01, time/batch = 0.6279s	
2808/16650 (epoch 8.432), train_loss = 1.52701672, grad/param norm = 2.6304e-01, time/batch = 0.6286s	
2809/16650 (epoch 8.435), train_loss = 1.71569605, grad/param norm = 2.4192e-01, time/batch = 0.6297s	
2810/16650 (epoch 8.438), train_loss = 1.67200656, grad/param norm = 2.4443e-01, time/batch = 0.6645s	
2811/16650 (epoch 8.441), train_loss = 1.57233387, grad/param norm = 2.5054e-01, time/batch = 0.6531s	
2812/16650 (epoch 8.444), train_loss = 1.42381793, grad/param norm = 2.3409e-01, time/batch = 0.6270s	
2813/16650 (epoch 8.447), train_loss = 1.44305276, grad/param norm = 2.5109e-01, time/batch = 0.6282s	
2814/16650 (epoch 8.450), train_loss = 1.35786916, grad/param norm = 2.4681e-01, time/batch = 0.6282s	
2815/16650 (epoch 8.453), train_loss = 1.42406632, grad/param norm = 2.3183e-01, time/batch = 0.6293s	
2816/16650 (epoch 8.456), train_loss = 1.30381995, grad/param norm = 2.2817e-01, time/batch = 0.6287s	
2817/16650 (epoch 8.459), train_loss = 1.40093658, grad/param norm = 2.3503e-01, time/batch = 0.6297s	
2818/16650 (epoch 8.462), train_loss = 1.69395855, grad/param norm = 2.6090e-01, time/batch = 0.6300s	
2819/16650 (epoch 8.465), train_loss = 1.40064424, grad/param norm = 2.4199e-01, time/batch = 0.6281s	
2820/16650 (epoch 8.468), train_loss = 1.11514639, grad/param norm = 2.1346e-01, time/batch = 0.6289s	
2821/16650 (epoch 8.471), train_loss = 1.06586889, grad/param norm = 2.1099e-01, time/batch = 0.6347s	
2822/16650 (epoch 8.474), train_loss = 1.26335068, grad/param norm = 1.9886e-01, time/batch = 0.6325s	
2823/16650 (epoch 8.477), train_loss = 1.46442605, grad/param norm = 2.4353e-01, time/batch = 0.6350s	
2824/16650 (epoch 8.480), train_loss = 1.50628556, grad/param norm = 2.4549e-01, time/batch = 0.6308s	
2825/16650 (epoch 8.483), train_loss = 1.64811117, grad/param norm = 2.6732e-01, time/batch = 0.6319s	
2826/16650 (epoch 8.486), train_loss = 1.29250488, grad/param norm = 2.4298e-01, time/batch = 0.6326s	
2827/16650 (epoch 8.489), train_loss = 1.40027554, grad/param norm = 2.4180e-01, time/batch = 0.6317s	
2828/16650 (epoch 8.492), train_loss = 1.46426768, grad/param norm = 2.3800e-01, time/batch = 0.6281s	
2829/16650 (epoch 8.495), train_loss = 1.34440050, grad/param norm = 2.6173e-01, time/batch = 0.6284s	
2830/16650 (epoch 8.498), train_loss = 1.43453127, grad/param norm = 2.4264e-01, time/batch = 0.6309s	
2831/16650 (epoch 8.502), train_loss = 1.69769727, grad/param norm = 2.7862e-01, time/batch = 0.6406s	
2832/16650 (epoch 8.505), train_loss = 1.48776619, grad/param norm = 2.1723e-01, time/batch = 0.6349s	
2833/16650 (epoch 8.508), train_loss = 1.50315892, grad/param norm = 2.2411e-01, time/batch = 0.6501s	
2834/16650 (epoch 8.511), train_loss = 1.63177346, grad/param norm = 2.7746e-01, time/batch = 0.6366s	
2835/16650 (epoch 8.514), train_loss = 1.32346660, grad/param norm = 2.4041e-01, time/batch = 0.6349s	
2836/16650 (epoch 8.517), train_loss = 1.44741289, grad/param norm = 2.6218e-01, time/batch = 0.6377s	
2837/16650 (epoch 8.520), train_loss = 1.48285227, grad/param norm = 2.4200e-01, time/batch = 0.6267s	
2838/16650 (epoch 8.523), train_loss = 1.39545946, grad/param norm = 2.2046e-01, time/batch = 0.6283s	
2839/16650 (epoch 8.526), train_loss = 1.48216415, grad/param norm = 2.3486e-01, time/batch = 0.6332s	
2840/16650 (epoch 8.529), train_loss = 1.64938923, grad/param norm = 2.5082e-01, time/batch = 0.6304s	
2841/16650 (epoch 8.532), train_loss = 1.28871136, grad/param norm = 2.4975e-01, time/batch = 0.6356s	
2842/16650 (epoch 8.535), train_loss = 1.30384078, grad/param norm = 2.2079e-01, time/batch = 0.6308s	
2843/16650 (epoch 8.538), train_loss = 1.39386459, grad/param norm = 2.3638e-01, time/batch = 0.6330s	
2844/16650 (epoch 8.541), train_loss = 1.63139828, grad/param norm = 2.6255e-01, time/batch = 0.6319s	
2845/16650 (epoch 8.544), train_loss = 1.68383588, grad/param norm = 2.6834e-01, time/batch = 0.6300s	
2846/16650 (epoch 8.547), train_loss = 1.27370395, grad/param norm = 2.1875e-01, time/batch = 0.6311s	
2847/16650 (epoch 8.550), train_loss = 1.34328706, grad/param norm = 2.1937e-01, time/batch = 0.6328s	
2848/16650 (epoch 8.553), train_loss = 1.45245730, grad/param norm = 2.4338e-01, time/batch = 0.6291s	
2849/16650 (epoch 8.556), train_loss = 1.33199354, grad/param norm = 2.2033e-01, time/batch = 0.6281s	
2850/16650 (epoch 8.559), train_loss = 1.19359295, grad/param norm = 2.0041e-01, time/batch = 0.6283s	
2851/16650 (epoch 8.562), train_loss = 1.42451619, grad/param norm = 2.1890e-01, time/batch = 0.6320s	
2852/16650 (epoch 8.565), train_loss = 1.16039619, grad/param norm = 2.2649e-01, time/batch = 0.6313s	
2853/16650 (epoch 8.568), train_loss = 1.19094177, grad/param norm = 2.0896e-01, time/batch = 0.6300s	
2854/16650 (epoch 8.571), train_loss = 1.27239549, grad/param norm = 2.2336e-01, time/batch = 0.6666s	
2855/16650 (epoch 8.574), train_loss = 1.39428925, grad/param norm = 2.2527e-01, time/batch = 0.6550s	
2856/16650 (epoch 8.577), train_loss = 1.34951334, grad/param norm = 2.2496e-01, time/batch = 0.6281s	
2857/16650 (epoch 8.580), train_loss = 1.27037803, grad/param norm = 2.2881e-01, time/batch = 0.6303s	
2858/16650 (epoch 8.583), train_loss = 1.31777149, grad/param norm = 2.3817e-01, time/batch = 0.6384s	
2859/16650 (epoch 8.586), train_loss = 1.44866343, grad/param norm = 2.6563e-01, time/batch = 0.6682s	
2860/16650 (epoch 8.589), train_loss = 1.19136770, grad/param norm = 2.0386e-01, time/batch = 0.6435s	
2861/16650 (epoch 8.592), train_loss = 1.45888400, grad/param norm = 2.8609e-01, time/batch = 0.6330s	
2862/16650 (epoch 8.595), train_loss = 1.31902290, grad/param norm = 2.4291e-01, time/batch = 0.6318s	
2863/16650 (epoch 8.598), train_loss = 1.32752848, grad/param norm = 2.4919e-01, time/batch = 0.6545s	
2864/16650 (epoch 8.601), train_loss = 1.34455805, grad/param norm = 2.7156e-01, time/batch = 0.6640s	
2865/16650 (epoch 8.604), train_loss = 1.51632115, grad/param norm = 2.5892e-01, time/batch = 0.6288s	
2866/16650 (epoch 8.607), train_loss = 1.41971865, grad/param norm = 2.3613e-01, time/batch = 0.6299s	
2867/16650 (epoch 8.610), train_loss = 1.30427163, grad/param norm = 2.1788e-01, time/batch = 0.6302s	
2868/16650 (epoch 8.613), train_loss = 1.56592164, grad/param norm = 2.4859e-01, time/batch = 0.6320s	
2869/16650 (epoch 8.616), train_loss = 1.61781081, grad/param norm = 2.7066e-01, time/batch = 0.6300s	
2870/16650 (epoch 8.619), train_loss = 1.28253160, grad/param norm = 2.3068e-01, time/batch = 0.6379s	
2871/16650 (epoch 8.622), train_loss = 1.18047899, grad/param norm = 2.3078e-01, time/batch = 0.6330s	
2872/16650 (epoch 8.625), train_loss = 1.35516471, grad/param norm = 2.2776e-01, time/batch = 0.6304s	
2873/16650 (epoch 8.628), train_loss = 1.37003447, grad/param norm = 2.5032e-01, time/batch = 0.6362s	
2874/16650 (epoch 8.631), train_loss = 1.41423468, grad/param norm = 2.5245e-01, time/batch = 0.6356s	
2875/16650 (epoch 8.634), train_loss = 1.63555345, grad/param norm = 2.5621e-01, time/batch = 0.6393s	
2876/16650 (epoch 8.637), train_loss = 1.66475035, grad/param norm = 2.6221e-01, time/batch = 0.6476s	
2877/16650 (epoch 8.640), train_loss = 1.37889204, grad/param norm = 2.3571e-01, time/batch = 0.6493s	
2878/16650 (epoch 8.643), train_loss = 1.49793458, grad/param norm = 2.5134e-01, time/batch = 0.6597s	
2879/16650 (epoch 8.646), train_loss = 1.54169288, grad/param norm = 2.5138e-01, time/batch = 0.6668s	
2880/16650 (epoch 8.649), train_loss = 1.43621547, grad/param norm = 2.2644e-01, time/batch = 0.6488s	
2881/16650 (epoch 8.652), train_loss = 1.59605571, grad/param norm = 2.6151e-01, time/batch = 0.6481s	
2882/16650 (epoch 8.655), train_loss = 1.43513341, grad/param norm = 2.2055e-01, time/batch = 0.6376s	
2883/16650 (epoch 8.658), train_loss = 1.31922588, grad/param norm = 2.2991e-01, time/batch = 0.6322s	
2884/16650 (epoch 8.661), train_loss = 1.50594231, grad/param norm = 2.2995e-01, time/batch = 0.6424s	
2885/16650 (epoch 8.664), train_loss = 1.45181904, grad/param norm = 2.4383e-01, time/batch = 0.6373s	
2886/16650 (epoch 8.667), train_loss = 1.58883160, grad/param norm = 2.4680e-01, time/batch = 0.6398s	
2887/16650 (epoch 8.670), train_loss = 1.27594112, grad/param norm = 2.2284e-01, time/batch = 0.6314s	
2888/16650 (epoch 8.673), train_loss = 1.29632703, grad/param norm = 2.1514e-01, time/batch = 0.6308s	
2889/16650 (epoch 8.676), train_loss = 1.42986738, grad/param norm = 2.4159e-01, time/batch = 0.6349s	
2890/16650 (epoch 8.679), train_loss = 1.31874825, grad/param norm = 2.2537e-01, time/batch = 0.6375s	
2891/16650 (epoch 8.682), train_loss = 1.51115408, grad/param norm = 2.5615e-01, time/batch = 0.6380s	
2892/16650 (epoch 8.685), train_loss = 1.26977486, grad/param norm = 2.3229e-01, time/batch = 0.6393s	
2893/16650 (epoch 8.688), train_loss = 1.41808214, grad/param norm = 2.4715e-01, time/batch = 0.6326s	
2894/16650 (epoch 8.691), train_loss = 1.48572196, grad/param norm = 2.5394e-01, time/batch = 0.6358s	
2895/16650 (epoch 8.694), train_loss = 1.28574523, grad/param norm = 2.2296e-01, time/batch = 0.6450s	
2896/16650 (epoch 8.697), train_loss = 1.24452453, grad/param norm = 2.1329e-01, time/batch = 0.6371s	
2897/16650 (epoch 8.700), train_loss = 1.54031976, grad/param norm = 2.3958e-01, time/batch = 0.6542s	
2898/16650 (epoch 8.703), train_loss = 1.33396954, grad/param norm = 2.5377e-01, time/batch = 0.6706s	
2899/16650 (epoch 8.706), train_loss = 1.52411853, grad/param norm = 2.6042e-01, time/batch = 0.6399s	
2900/16650 (epoch 8.709), train_loss = 1.31850858, grad/param norm = 2.2579e-01, time/batch = 0.6435s	
2901/16650 (epoch 8.712), train_loss = 1.32643025, grad/param norm = 2.3470e-01, time/batch = 0.6468s	
2902/16650 (epoch 8.715), train_loss = 1.56188295, grad/param norm = 2.4398e-01, time/batch = 0.6400s	
2903/16650 (epoch 8.718), train_loss = 1.60899278, grad/param norm = 2.4811e-01, time/batch = 0.6373s	
2904/16650 (epoch 8.721), train_loss = 1.57245654, grad/param norm = 2.6570e-01, time/batch = 0.6356s	
2905/16650 (epoch 8.724), train_loss = 1.57223998, grad/param norm = 2.6161e-01, time/batch = 0.6373s	
2906/16650 (epoch 8.727), train_loss = 1.49357763, grad/param norm = 2.1767e-01, time/batch = 0.6419s	
2907/16650 (epoch 8.730), train_loss = 1.39319313, grad/param norm = 2.3173e-01, time/batch = 0.6390s	
2908/16650 (epoch 8.733), train_loss = 1.57585940, grad/param norm = 2.6191e-01, time/batch = 0.6509s	
2909/16650 (epoch 8.736), train_loss = 1.26871359, grad/param norm = 2.1914e-01, time/batch = 0.6462s	
2910/16650 (epoch 8.739), train_loss = 1.44427566, grad/param norm = 2.2223e-01, time/batch = 0.6381s	
2911/16650 (epoch 8.742), train_loss = 1.45889847, grad/param norm = 2.5534e-01, time/batch = 0.6359s	
2912/16650 (epoch 8.745), train_loss = 1.20710438, grad/param norm = 2.0772e-01, time/batch = 0.6316s	
2913/16650 (epoch 8.748), train_loss = 1.29378382, grad/param norm = 2.4787e-01, time/batch = 0.6274s	
2914/16650 (epoch 8.751), train_loss = 1.50075596, grad/param norm = 2.9502e-01, time/batch = 0.6284s	
2915/16650 (epoch 8.754), train_loss = 1.64337451, grad/param norm = 2.8136e-01, time/batch = 0.6280s	
2916/16650 (epoch 8.757), train_loss = 1.52095047, grad/param norm = 2.3213e-01, time/batch = 0.6288s	
2917/16650 (epoch 8.760), train_loss = 1.38659968, grad/param norm = 2.3446e-01, time/batch = 0.6312s	
2918/16650 (epoch 8.763), train_loss = 1.31615815, grad/param norm = 2.2567e-01, time/batch = 0.6333s	
2919/16650 (epoch 8.766), train_loss = 1.43457294, grad/param norm = 2.2170e-01, time/batch = 0.6281s	
2920/16650 (epoch 8.769), train_loss = 1.39525210, grad/param norm = 2.3833e-01, time/batch = 0.6281s	
2921/16650 (epoch 8.772), train_loss = 1.31834428, grad/param norm = 2.0764e-01, time/batch = 0.6314s	
2922/16650 (epoch 8.775), train_loss = 1.41838645, grad/param norm = 2.2201e-01, time/batch = 0.6289s	
2923/16650 (epoch 8.778), train_loss = 1.31218061, grad/param norm = 2.1815e-01, time/batch = 0.6303s	
2924/16650 (epoch 8.781), train_loss = 1.49555590, grad/param norm = 2.4487e-01, time/batch = 0.6314s	
2925/16650 (epoch 8.784), train_loss = 1.50924576, grad/param norm = 2.4591e-01, time/batch = 0.6349s	
2926/16650 (epoch 8.787), train_loss = 1.53809410, grad/param norm = 2.4479e-01, time/batch = 0.6332s	
2927/16650 (epoch 8.790), train_loss = 1.39362186, grad/param norm = 2.2626e-01, time/batch = 0.6292s	
2928/16650 (epoch 8.793), train_loss = 1.32134768, grad/param norm = 2.6925e-01, time/batch = 0.6294s	
2929/16650 (epoch 8.796), train_loss = 1.82664779, grad/param norm = 2.6792e-01, time/batch = 0.6291s	
2930/16650 (epoch 8.799), train_loss = 1.66000709, grad/param norm = 2.3879e-01, time/batch = 0.6294s	
2931/16650 (epoch 8.802), train_loss = 1.46432689, grad/param norm = 2.6549e-01, time/batch = 0.6313s	
2932/16650 (epoch 8.805), train_loss = 1.43780432, grad/param norm = 2.2580e-01, time/batch = 0.6377s	
2933/16650 (epoch 8.808), train_loss = 1.41838259, grad/param norm = 2.2511e-01, time/batch = 0.6379s	
2934/16650 (epoch 8.811), train_loss = 1.56465204, grad/param norm = 2.3899e-01, time/batch = 0.6408s	
2935/16650 (epoch 8.814), train_loss = 1.30172513, grad/param norm = 2.2438e-01, time/batch = 0.6574s	
2936/16650 (epoch 8.817), train_loss = 1.40085306, grad/param norm = 2.4142e-01, time/batch = 0.6639s	
2937/16650 (epoch 8.820), train_loss = 1.47595356, grad/param norm = 2.5001e-01, time/batch = 0.6502s	
2938/16650 (epoch 8.823), train_loss = 1.28896263, grad/param norm = 2.1643e-01, time/batch = 0.6605s	
2939/16650 (epoch 8.826), train_loss = 1.41059060, grad/param norm = 2.0493e-01, time/batch = 0.6492s	
2940/16650 (epoch 8.829), train_loss = 1.59449109, grad/param norm = 2.7047e-01, time/batch = 0.6533s	
2941/16650 (epoch 8.832), train_loss = 1.57760882, grad/param norm = 2.4312e-01, time/batch = 0.6662s	
2942/16650 (epoch 8.835), train_loss = 1.56475546, grad/param norm = 2.7480e-01, time/batch = 0.6598s	
2943/16650 (epoch 8.838), train_loss = 1.32872644, grad/param norm = 2.5111e-01, time/batch = 0.6367s	
2944/16650 (epoch 8.841), train_loss = 1.28743902, grad/param norm = 2.1173e-01, time/batch = 0.6286s	
2945/16650 (epoch 8.844), train_loss = 1.36427287, grad/param norm = 2.3710e-01, time/batch = 0.6401s	
2946/16650 (epoch 8.847), train_loss = 1.55235737, grad/param norm = 2.3250e-01, time/batch = 0.6345s	
2947/16650 (epoch 8.850), train_loss = 1.28879226, grad/param norm = 2.3823e-01, time/batch = 0.6315s	
2948/16650 (epoch 8.853), train_loss = 1.49459851, grad/param norm = 2.3713e-01, time/batch = 0.6301s	
2949/16650 (epoch 8.856), train_loss = 1.31877003, grad/param norm = 2.3643e-01, time/batch = 0.6291s	
2950/16650 (epoch 8.859), train_loss = 1.49034544, grad/param norm = 2.4027e-01, time/batch = 0.6269s	
2951/16650 (epoch 8.862), train_loss = 1.40851818, grad/param norm = 2.1830e-01, time/batch = 0.6334s	
2952/16650 (epoch 8.865), train_loss = 1.18165685, grad/param norm = 2.1710e-01, time/batch = 0.6299s	
2953/16650 (epoch 8.868), train_loss = 1.50066658, grad/param norm = 2.4320e-01, time/batch = 0.6288s	
2954/16650 (epoch 8.871), train_loss = 1.52434620, grad/param norm = 2.5645e-01, time/batch = 0.6297s	
2955/16650 (epoch 8.874), train_loss = 1.49766677, grad/param norm = 2.3433e-01, time/batch = 0.6278s	
2956/16650 (epoch 8.877), train_loss = 1.31830507, grad/param norm = 2.1352e-01, time/batch = 0.6279s	
2957/16650 (epoch 8.880), train_loss = 1.37703472, grad/param norm = 2.6891e-01, time/batch = 0.6280s	
2958/16650 (epoch 8.883), train_loss = 1.49177234, grad/param norm = 2.3987e-01, time/batch = 0.6266s	
2959/16650 (epoch 8.886), train_loss = 1.46746959, grad/param norm = 2.4011e-01, time/batch = 0.6285s	
2960/16650 (epoch 8.889), train_loss = 1.32440930, grad/param norm = 2.3299e-01, time/batch = 0.6301s	
2961/16650 (epoch 8.892), train_loss = 1.35606811, grad/param norm = 2.1743e-01, time/batch = 0.6321s	
2962/16650 (epoch 8.895), train_loss = 1.52287776, grad/param norm = 2.3650e-01, time/batch = 0.6420s	
2963/16650 (epoch 8.898), train_loss = 1.49003023, grad/param norm = 2.5551e-01, time/batch = 0.6498s	
2964/16650 (epoch 8.901), train_loss = 1.43822415, grad/param norm = 2.1616e-01, time/batch = 0.6414s	
2965/16650 (epoch 8.904), train_loss = 1.36163092, grad/param norm = 2.3092e-01, time/batch = 0.6399s	
2966/16650 (epoch 8.907), train_loss = 1.43793105, grad/param norm = 2.3704e-01, time/batch = 0.6333s	
2967/16650 (epoch 8.910), train_loss = 1.45049471, grad/param norm = 2.5617e-01, time/batch = 0.6278s	
2968/16650 (epoch 8.913), train_loss = 1.37371320, grad/param norm = 2.3817e-01, time/batch = 0.6314s	
2969/16650 (epoch 8.916), train_loss = 1.47189671, grad/param norm = 2.4669e-01, time/batch = 0.6415s	
2970/16650 (epoch 8.919), train_loss = 1.56995326, grad/param norm = 2.7334e-01, time/batch = 0.6495s	
2971/16650 (epoch 8.922), train_loss = 1.57507079, grad/param norm = 2.6703e-01, time/batch = 0.6691s	
2972/16650 (epoch 8.925), train_loss = 1.38720586, grad/param norm = 2.5412e-01, time/batch = 0.6701s	
2973/16650 (epoch 8.928), train_loss = 1.39323648, grad/param norm = 2.2275e-01, time/batch = 0.6467s	
2974/16650 (epoch 8.931), train_loss = 1.46177047, grad/param norm = 2.3549e-01, time/batch = 0.6383s	
2975/16650 (epoch 8.934), train_loss = 1.26604492, grad/param norm = 2.1963e-01, time/batch = 0.6318s	
2976/16650 (epoch 8.937), train_loss = 1.43404098, grad/param norm = 2.5758e-01, time/batch = 0.6327s	
2977/16650 (epoch 8.940), train_loss = 1.34359300, grad/param norm = 2.0367e-01, time/batch = 0.6322s	
2978/16650 (epoch 8.943), train_loss = 1.36873362, grad/param norm = 2.2697e-01, time/batch = 0.6333s	
2979/16650 (epoch 8.946), train_loss = 1.35823038, grad/param norm = 2.4151e-01, time/batch = 0.6333s	
2980/16650 (epoch 8.949), train_loss = 1.37398145, grad/param norm = 2.2261e-01, time/batch = 0.6583s	
2981/16650 (epoch 8.952), train_loss = 1.13737333, grad/param norm = 2.2207e-01, time/batch = 0.6655s	
2982/16650 (epoch 8.955), train_loss = 1.35160037, grad/param norm = 2.3127e-01, time/batch = 0.6420s	
2983/16650 (epoch 8.958), train_loss = 1.52107319, grad/param norm = 2.6598e-01, time/batch = 0.6537s	
2984/16650 (epoch 8.961), train_loss = 1.34124836, grad/param norm = 2.2917e-01, time/batch = 0.6438s	
2985/16650 (epoch 8.964), train_loss = 1.33298736, grad/param norm = 2.4254e-01, time/batch = 0.6475s	
2986/16650 (epoch 8.967), train_loss = 1.58710374, grad/param norm = 2.4886e-01, time/batch = 0.6413s	
2987/16650 (epoch 8.970), train_loss = 1.21043003, grad/param norm = 2.0634e-01, time/batch = 0.6522s	
2988/16650 (epoch 8.973), train_loss = 1.40658192, grad/param norm = 2.9241e-01, time/batch = 0.6441s	
2989/16650 (epoch 8.976), train_loss = 1.31169829, grad/param norm = 2.2790e-01, time/batch = 0.6422s	
2990/16650 (epoch 8.979), train_loss = 1.49117004, grad/param norm = 2.3163e-01, time/batch = 0.6369s	
2991/16650 (epoch 8.982), train_loss = 1.48007282, grad/param norm = 2.4326e-01, time/batch = 0.6301s	
2992/16650 (epoch 8.985), train_loss = 1.36218754, grad/param norm = 2.2848e-01, time/batch = 0.6291s	
2993/16650 (epoch 8.988), train_loss = 1.66193075, grad/param norm = 2.5961e-01, time/batch = 0.6294s	
2994/16650 (epoch 8.991), train_loss = 1.34033320, grad/param norm = 2.6049e-01, time/batch = 0.6308s	
2995/16650 (epoch 8.994), train_loss = 1.37333230, grad/param norm = 2.2060e-01, time/batch = 0.6273s	
2996/16650 (epoch 8.997), train_loss = 1.48581429, grad/param norm = 2.4568e-01, time/batch = 0.6270s	
2997/16650 (epoch 9.000), train_loss = 1.52668057, grad/param norm = 2.7392e-01, time/batch = 0.6273s	
2998/16650 (epoch 9.003), train_loss = 1.52496006, grad/param norm = 2.6290e-01, time/batch = 0.6275s	
2999/16650 (epoch 9.006), train_loss = 1.55198539, grad/param norm = 2.6590e-01, time/batch = 0.6309s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch9.01_1.7537.t7	
3000/16650 (epoch 9.009), train_loss = 1.62272066, grad/param norm = 2.4569e-01, time/batch = 0.6340s	
3001/16650 (epoch 9.012), train_loss = 1.88570985, grad/param norm = 3.1128e-01, time/batch = 0.6368s	
3002/16650 (epoch 9.015), train_loss = 1.48794434, grad/param norm = 2.6715e-01, time/batch = 0.6295s	
3003/16650 (epoch 9.018), train_loss = 1.16127985, grad/param norm = 2.2664e-01, time/batch = 0.6343s	
3004/16650 (epoch 9.021), train_loss = 1.57394055, grad/param norm = 2.4358e-01, time/batch = 0.6403s	
3005/16650 (epoch 9.024), train_loss = 1.35732600, grad/param norm = 2.3786e-01, time/batch = 0.6415s	
3006/16650 (epoch 9.027), train_loss = 1.57931424, grad/param norm = 2.5522e-01, time/batch = 0.6444s	
3007/16650 (epoch 9.030), train_loss = 1.27143536, grad/param norm = 2.1912e-01, time/batch = 0.6348s	
3008/16650 (epoch 9.033), train_loss = 1.42917104, grad/param norm = 2.3071e-01, time/batch = 0.6318s	
3009/16650 (epoch 9.036), train_loss = 1.27094895, grad/param norm = 2.5399e-01, time/batch = 0.6316s	
3010/16650 (epoch 9.039), train_loss = 1.52134664, grad/param norm = 2.6147e-01, time/batch = 0.6309s	
3011/16650 (epoch 9.042), train_loss = 1.54802962, grad/param norm = 2.4201e-01, time/batch = 0.6312s	
3012/16650 (epoch 9.045), train_loss = 1.36896687, grad/param norm = 2.2716e-01, time/batch = 0.6390s	
3013/16650 (epoch 9.048), train_loss = 1.48415582, grad/param norm = 2.3737e-01, time/batch = 0.6334s	
3014/16650 (epoch 9.051), train_loss = 1.47481068, grad/param norm = 2.5793e-01, time/batch = 0.6344s	
3015/16650 (epoch 9.054), train_loss = 1.45921523, grad/param norm = 2.3168e-01, time/batch = 0.6322s	
3016/16650 (epoch 9.057), train_loss = 1.40101036, grad/param norm = 2.2436e-01, time/batch = 0.6306s	
3017/16650 (epoch 9.060), train_loss = 1.30269195, grad/param norm = 2.1664e-01, time/batch = 0.6483s	
3018/16650 (epoch 9.063), train_loss = 1.40641856, grad/param norm = 2.4047e-01, time/batch = 0.6461s	
3019/16650 (epoch 9.066), train_loss = 1.59271935, grad/param norm = 2.5735e-01, time/batch = 0.6662s	
3020/16650 (epoch 9.069), train_loss = 1.53565379, grad/param norm = 2.4282e-01, time/batch = 0.6556s	
3021/16650 (epoch 9.072), train_loss = 1.38792137, grad/param norm = 2.4922e-01, time/batch = 0.6334s	
3022/16650 (epoch 9.075), train_loss = 1.43166556, grad/param norm = 2.3463e-01, time/batch = 0.6372s	
3023/16650 (epoch 9.078), train_loss = 1.49661633, grad/param norm = 2.3172e-01, time/batch = 0.6302s	
3024/16650 (epoch 9.081), train_loss = 1.39123253, grad/param norm = 2.4074e-01, time/batch = 0.6287s	
3025/16650 (epoch 9.084), train_loss = 1.49527080, grad/param norm = 2.1643e-01, time/batch = 0.6281s	
3026/16650 (epoch 9.087), train_loss = 1.43820232, grad/param norm = 2.2893e-01, time/batch = 0.6280s	
3027/16650 (epoch 9.090), train_loss = 1.31433929, grad/param norm = 2.2248e-01, time/batch = 0.6283s	
3028/16650 (epoch 9.093), train_loss = 1.72210839, grad/param norm = 2.5799e-01, time/batch = 0.6284s	
3029/16650 (epoch 9.096), train_loss = 1.40614742, grad/param norm = 2.2371e-01, time/batch = 0.6281s	
3030/16650 (epoch 9.099), train_loss = 1.38137886, grad/param norm = 2.1725e-01, time/batch = 0.6296s	
3031/16650 (epoch 9.102), train_loss = 1.44350797, grad/param norm = 2.3958e-01, time/batch = 0.6343s	
3032/16650 (epoch 9.105), train_loss = 1.51505227, grad/param norm = 2.3745e-01, time/batch = 0.6321s	
3033/16650 (epoch 9.108), train_loss = 1.51805301, grad/param norm = 2.3578e-01, time/batch = 0.6284s	
3034/16650 (epoch 9.111), train_loss = 1.47128521, grad/param norm = 2.3869e-01, time/batch = 0.6282s	
3035/16650 (epoch 9.114), train_loss = 1.60001957, grad/param norm = 2.4213e-01, time/batch = 0.6291s	
3036/16650 (epoch 9.117), train_loss = 1.54257406, grad/param norm = 2.3789e-01, time/batch = 0.6293s	
3037/16650 (epoch 9.120), train_loss = 1.32173948, grad/param norm = 2.2628e-01, time/batch = 0.6272s	
3038/16650 (epoch 9.123), train_loss = 1.41676364, grad/param norm = 2.4619e-01, time/batch = 0.6277s	
3039/16650 (epoch 9.126), train_loss = 1.46054206, grad/param norm = 2.6292e-01, time/batch = 0.6345s	
3040/16650 (epoch 9.129), train_loss = 1.47525849, grad/param norm = 2.3609e-01, time/batch = 0.6308s	
3041/16650 (epoch 9.132), train_loss = 1.54641536, grad/param norm = 2.4681e-01, time/batch = 0.6308s	
3042/16650 (epoch 9.135), train_loss = 1.49329283, grad/param norm = 2.4185e-01, time/batch = 0.6292s	
3043/16650 (epoch 9.138), train_loss = 1.50591953, grad/param norm = 2.3933e-01, time/batch = 0.6306s	
3044/16650 (epoch 9.141), train_loss = 1.52991462, grad/param norm = 2.7900e-01, time/batch = 0.6294s	
3045/16650 (epoch 9.144), train_loss = 1.43382853, grad/param norm = 2.5186e-01, time/batch = 0.6310s	
3046/16650 (epoch 9.147), train_loss = 1.59672585, grad/param norm = 2.5938e-01, time/batch = 0.6357s	
3047/16650 (epoch 9.150), train_loss = 1.70013434, grad/param norm = 2.5084e-01, time/batch = 0.6331s	
3048/16650 (epoch 9.153), train_loss = 1.42453005, grad/param norm = 2.1987e-01, time/batch = 0.6311s	
3049/16650 (epoch 9.156), train_loss = 1.27539355, grad/param norm = 2.2577e-01, time/batch = 0.6268s	
3050/16650 (epoch 9.159), train_loss = 1.59383160, grad/param norm = 2.4743e-01, time/batch = 0.6279s	
3051/16650 (epoch 9.162), train_loss = 1.52021321, grad/param norm = 2.3232e-01, time/batch = 0.6302s	
3052/16650 (epoch 9.165), train_loss = 1.51651244, grad/param norm = 2.3910e-01, time/batch = 0.6286s	
3053/16650 (epoch 9.168), train_loss = 1.15970442, grad/param norm = 2.1186e-01, time/batch = 0.6286s	
3054/16650 (epoch 9.171), train_loss = 1.50834662, grad/param norm = 2.1837e-01, time/batch = 0.6336s	
3055/16650 (epoch 9.174), train_loss = 1.26966101, grad/param norm = 2.3830e-01, time/batch = 0.6287s	
3056/16650 (epoch 9.177), train_loss = 1.43675595, grad/param norm = 2.3380e-01, time/batch = 0.6348s	
3057/16650 (epoch 9.180), train_loss = 1.59440922, grad/param norm = 2.3911e-01, time/batch = 0.6380s	
3058/16650 (epoch 9.183), train_loss = 1.72135408, grad/param norm = 2.6134e-01, time/batch = 0.6336s	
3059/16650 (epoch 9.186), train_loss = 1.56188498, grad/param norm = 2.5003e-01, time/batch = 0.6385s	
3060/16650 (epoch 9.189), train_loss = 1.31493146, grad/param norm = 2.2532e-01, time/batch = 0.6460s	
3061/16650 (epoch 9.192), train_loss = 1.36663249, grad/param norm = 2.7441e-01, time/batch = 0.6640s	
3062/16650 (epoch 9.195), train_loss = 1.47147178, grad/param norm = 2.4522e-01, time/batch = 0.6507s	
3063/16650 (epoch 9.198), train_loss = 1.20208237, grad/param norm = 2.2523e-01, time/batch = 0.6328s	
3064/16650 (epoch 9.201), train_loss = 1.40261453, grad/param norm = 2.2889e-01, time/batch = 0.6366s	
3065/16650 (epoch 9.204), train_loss = 1.44299734, grad/param norm = 2.4297e-01, time/batch = 0.6322s	
3066/16650 (epoch 9.207), train_loss = 1.50434919, grad/param norm = 2.5264e-01, time/batch = 0.6302s	
3067/16650 (epoch 9.210), train_loss = 1.37181866, grad/param norm = 2.2410e-01, time/batch = 0.6364s	
3068/16650 (epoch 9.213), train_loss = 1.48310348, grad/param norm = 2.2539e-01, time/batch = 0.6650s	
3069/16650 (epoch 9.216), train_loss = 1.40664550, grad/param norm = 2.4253e-01, time/batch = 0.6427s	
3070/16650 (epoch 9.219), train_loss = 1.42989346, grad/param norm = 2.4076e-01, time/batch = 0.6392s	
3071/16650 (epoch 9.222), train_loss = 1.42537659, grad/param norm = 2.3578e-01, time/batch = 0.6372s	
3072/16650 (epoch 9.225), train_loss = 1.44722832, grad/param norm = 2.4273e-01, time/batch = 0.6587s	
3073/16650 (epoch 9.228), train_loss = 1.35548072, grad/param norm = 2.3468e-01, time/batch = 0.6650s	
3074/16650 (epoch 9.231), train_loss = 1.42337223, grad/param norm = 2.3602e-01, time/batch = 0.6300s	
3075/16650 (epoch 9.234), train_loss = 1.55851568, grad/param norm = 2.4046e-01, time/batch = 0.6340s	
3076/16650 (epoch 9.237), train_loss = 1.44047489, grad/param norm = 2.4795e-01, time/batch = 0.6306s	
3077/16650 (epoch 9.240), train_loss = 1.47992716, grad/param norm = 2.3785e-01, time/batch = 0.6272s	
3078/16650 (epoch 9.243), train_loss = 1.47078529, grad/param norm = 2.2907e-01, time/batch = 0.6298s	
3079/16650 (epoch 9.246), train_loss = 1.56492696, grad/param norm = 2.5235e-01, time/batch = 0.6315s	
3080/16650 (epoch 9.249), train_loss = 1.30712616, grad/param norm = 2.3781e-01, time/batch = 0.6323s	
3081/16650 (epoch 9.252), train_loss = 1.43032817, grad/param norm = 2.3931e-01, time/batch = 0.6360s	
3082/16650 (epoch 9.255), train_loss = 1.57581526, grad/param norm = 2.5625e-01, time/batch = 0.6318s	
3083/16650 (epoch 9.258), train_loss = 1.54840068, grad/param norm = 2.4726e-01, time/batch = 0.6370s	
3084/16650 (epoch 9.261), train_loss = 1.44863691, grad/param norm = 2.3273e-01, time/batch = 0.6348s	
3085/16650 (epoch 9.264), train_loss = 1.40432962, grad/param norm = 2.5127e-01, time/batch = 0.6330s	
3086/16650 (epoch 9.267), train_loss = 1.33462903, grad/param norm = 2.3169e-01, time/batch = 0.6294s	
3087/16650 (epoch 9.270), train_loss = 1.40496688, grad/param norm = 2.1717e-01, time/batch = 0.6283s	
3088/16650 (epoch 9.273), train_loss = 1.54777859, grad/param norm = 2.1774e-01, time/batch = 0.6317s	
3089/16650 (epoch 9.276), train_loss = 1.42691219, grad/param norm = 2.1926e-01, time/batch = 0.6322s	
3090/16650 (epoch 9.279), train_loss = 1.43437972, grad/param norm = 2.2976e-01, time/batch = 0.6351s	
3091/16650 (epoch 9.282), train_loss = 1.24610381, grad/param norm = 1.9880e-01, time/batch = 0.6328s	
3092/16650 (epoch 9.285), train_loss = 1.28562721, grad/param norm = 2.2581e-01, time/batch = 0.6305s	
3093/16650 (epoch 9.288), train_loss = 1.37963383, grad/param norm = 2.2930e-01, time/batch = 0.6291s	
3094/16650 (epoch 9.291), train_loss = 1.14267455, grad/param norm = 1.9303e-01, time/batch = 0.6298s	
3095/16650 (epoch 9.294), train_loss = 1.21386152, grad/param norm = 1.7966e-01, time/batch = 0.6324s	
3096/16650 (epoch 9.297), train_loss = 1.32242976, grad/param norm = 2.1817e-01, time/batch = 0.6311s	
3097/16650 (epoch 9.300), train_loss = 1.16636123, grad/param norm = 2.1296e-01, time/batch = 0.6363s	
3098/16650 (epoch 9.303), train_loss = 1.19893397, grad/param norm = 1.9295e-01, time/batch = 0.6432s	
3099/16650 (epoch 9.306), train_loss = 1.45521540, grad/param norm = 2.2479e-01, time/batch = 0.6666s	
3100/16650 (epoch 9.309), train_loss = 1.54089658, grad/param norm = 2.4424e-01, time/batch = 0.6536s	
3101/16650 (epoch 9.312), train_loss = 1.29838394, grad/param norm = 2.2632e-01, time/batch = 0.6477s	
3102/16650 (epoch 9.315), train_loss = 1.09182299, grad/param norm = 2.0804e-01, time/batch = 0.6331s	
3103/16650 (epoch 9.318), train_loss = 1.20175088, grad/param norm = 2.0411e-01, time/batch = 0.6309s	
3104/16650 (epoch 9.321), train_loss = 1.60071214, grad/param norm = 2.7859e-01, time/batch = 0.6310s	
3105/16650 (epoch 9.324), train_loss = 1.36934522, grad/param norm = 2.2744e-01, time/batch = 0.6295s	
3106/16650 (epoch 9.327), train_loss = 1.57399200, grad/param norm = 2.7062e-01, time/batch = 0.6344s	
3107/16650 (epoch 9.330), train_loss = 1.48029561, grad/param norm = 2.6178e-01, time/batch = 0.6344s	
3108/16650 (epoch 9.333), train_loss = 1.51720036, grad/param norm = 2.6002e-01, time/batch = 0.6287s	
3109/16650 (epoch 9.336), train_loss = 1.27867259, grad/param norm = 2.2101e-01, time/batch = 0.6297s	
3110/16650 (epoch 9.339), train_loss = 1.39086298, grad/param norm = 2.4834e-01, time/batch = 0.6294s	
3111/16650 (epoch 9.342), train_loss = 1.39166068, grad/param norm = 2.5461e-01, time/batch = 0.6377s	
3112/16650 (epoch 9.345), train_loss = 1.25056949, grad/param norm = 2.2199e-01, time/batch = 0.6310s	
3113/16650 (epoch 9.348), train_loss = 1.41691770, grad/param norm = 2.2503e-01, time/batch = 0.6331s	
3114/16650 (epoch 9.351), train_loss = 1.51275295, grad/param norm = 2.5201e-01, time/batch = 0.6321s	
3115/16650 (epoch 9.354), train_loss = 1.57725969, grad/param norm = 2.3717e-01, time/batch = 0.6313s	
3116/16650 (epoch 9.357), train_loss = 1.48076967, grad/param norm = 2.5588e-01, time/batch = 0.6286s	
3117/16650 (epoch 9.360), train_loss = 1.47146454, grad/param norm = 2.4205e-01, time/batch = 0.6284s	
3118/16650 (epoch 9.363), train_loss = 1.57383533, grad/param norm = 2.5542e-01, time/batch = 0.6286s	
3119/16650 (epoch 9.366), train_loss = 1.64217520, grad/param norm = 2.5627e-01, time/batch = 0.6291s	
3120/16650 (epoch 9.369), train_loss = 1.43081658, grad/param norm = 2.2955e-01, time/batch = 0.6297s	
3121/16650 (epoch 9.372), train_loss = 1.43470613, grad/param norm = 2.2497e-01, time/batch = 0.6722s	
3122/16650 (epoch 9.375), train_loss = 1.36822970, grad/param norm = 2.2147e-01, time/batch = 0.6536s	
3123/16650 (epoch 9.378), train_loss = 1.25395215, grad/param norm = 2.1853e-01, time/batch = 0.6353s	
3124/16650 (epoch 9.381), train_loss = 1.46945638, grad/param norm = 2.5148e-01, time/batch = 0.6332s	
3125/16650 (epoch 9.384), train_loss = 1.54012224, grad/param norm = 2.4241e-01, time/batch = 0.6435s	
3126/16650 (epoch 9.387), train_loss = 1.16243157, grad/param norm = 2.1120e-01, time/batch = 0.6684s	
3127/16650 (epoch 9.390), train_loss = 1.49508258, grad/param norm = 2.4067e-01, time/batch = 0.6335s	
3128/16650 (epoch 9.393), train_loss = 1.43484156, grad/param norm = 2.6160e-01, time/batch = 0.6278s	
3129/16650 (epoch 9.396), train_loss = 1.59950938, grad/param norm = 2.5685e-01, time/batch = 0.6300s	
3130/16650 (epoch 9.399), train_loss = 1.49014947, grad/param norm = 2.4228e-01, time/batch = 0.6296s	
3131/16650 (epoch 9.402), train_loss = 1.29397452, grad/param norm = 2.3732e-01, time/batch = 0.6347s	
3132/16650 (epoch 9.405), train_loss = 1.25379914, grad/param norm = 2.2647e-01, time/batch = 0.6322s	
3133/16650 (epoch 9.408), train_loss = 1.56675663, grad/param norm = 2.3914e-01, time/batch = 0.6297s	
3134/16650 (epoch 9.411), train_loss = 1.28777484, grad/param norm = 2.3881e-01, time/batch = 0.6289s	
3135/16650 (epoch 9.414), train_loss = 1.24412437, grad/param norm = 2.1501e-01, time/batch = 0.6273s	
3136/16650 (epoch 9.417), train_loss = 1.21805155, grad/param norm = 1.8981e-01, time/batch = 0.6277s	
3137/16650 (epoch 9.420), train_loss = 1.24505716, grad/param norm = 2.3194e-01, time/batch = 0.6346s	
3138/16650 (epoch 9.423), train_loss = 0.99114045, grad/param norm = 1.8623e-01, time/batch = 0.6287s	
3139/16650 (epoch 9.426), train_loss = 1.30908071, grad/param norm = 2.4289e-01, time/batch = 0.6301s	
3140/16650 (epoch 9.429), train_loss = 1.50375604, grad/param norm = 2.5353e-01, time/batch = 0.6282s	
3141/16650 (epoch 9.432), train_loss = 1.48296084, grad/param norm = 2.5802e-01, time/batch = 0.6304s	
3142/16650 (epoch 9.435), train_loss = 1.65540648, grad/param norm = 2.3696e-01, time/batch = 0.6278s	
3143/16650 (epoch 9.438), train_loss = 1.61749493, grad/param norm = 2.5040e-01, time/batch = 0.6273s	
3144/16650 (epoch 9.441), train_loss = 1.49655667, grad/param norm = 2.5538e-01, time/batch = 0.6288s	
3145/16650 (epoch 9.444), train_loss = 1.36878408, grad/param norm = 2.3678e-01, time/batch = 0.6293s	
3146/16650 (epoch 9.447), train_loss = 1.38620644, grad/param norm = 2.3748e-01, time/batch = 0.6293s	
3147/16650 (epoch 9.450), train_loss = 1.29281822, grad/param norm = 2.3112e-01, time/batch = 0.6341s	
3148/16650 (epoch 9.453), train_loss = 1.35353185, grad/param norm = 2.3322e-01, time/batch = 0.6318s	
3149/16650 (epoch 9.456), train_loss = 1.25189450, grad/param norm = 2.2419e-01, time/batch = 0.6293s	
3150/16650 (epoch 9.459), train_loss = 1.33832568, grad/param norm = 2.3384e-01, time/batch = 0.6291s	
3151/16650 (epoch 9.462), train_loss = 1.63965397, grad/param norm = 2.5762e-01, time/batch = 0.6391s	
3152/16650 (epoch 9.465), train_loss = 1.34681264, grad/param norm = 2.3958e-01, time/batch = 0.6394s	
3153/16650 (epoch 9.468), train_loss = 1.07585364, grad/param norm = 2.1204e-01, time/batch = 0.6462s	
3154/16650 (epoch 9.471), train_loss = 1.01323113, grad/param norm = 2.0982e-01, time/batch = 0.6643s	
3155/16650 (epoch 9.474), train_loss = 1.21842282, grad/param norm = 1.9909e-01, time/batch = 0.6674s	
3156/16650 (epoch 9.477), train_loss = 1.40853983, grad/param norm = 2.4273e-01, time/batch = 0.6598s	
3157/16650 (epoch 9.480), train_loss = 1.44407201, grad/param norm = 2.5088e-01, time/batch = 0.6568s	
3158/16650 (epoch 9.483), train_loss = 1.59539771, grad/param norm = 2.5935e-01, time/batch = 0.6748s	
3159/16650 (epoch 9.486), train_loss = 1.24790973, grad/param norm = 2.2903e-01, time/batch = 0.6429s	
3160/16650 (epoch 9.489), train_loss = 1.33906210, grad/param norm = 2.3877e-01, time/batch = 0.6401s	
3161/16650 (epoch 9.492), train_loss = 1.41411404, grad/param norm = 2.3641e-01, time/batch = 0.6361s	
3162/16650 (epoch 9.495), train_loss = 1.29016023, grad/param norm = 2.5897e-01, time/batch = 0.6377s	
3163/16650 (epoch 9.498), train_loss = 1.38374563, grad/param norm = 2.5162e-01, time/batch = 0.6363s	
3164/16650 (epoch 9.502), train_loss = 1.64390082, grad/param norm = 2.7591e-01, time/batch = 0.6342s	
3165/16650 (epoch 9.505), train_loss = 1.44295776, grad/param norm = 2.1926e-01, time/batch = 0.6313s	
3166/16650 (epoch 9.508), train_loss = 1.45613807, grad/param norm = 2.2428e-01, time/batch = 0.6290s	
3167/16650 (epoch 9.511), train_loss = 1.57298578, grad/param norm = 2.7860e-01, time/batch = 0.6301s	
3168/16650 (epoch 9.514), train_loss = 1.26635882, grad/param norm = 2.3319e-01, time/batch = 0.6365s	
3169/16650 (epoch 9.517), train_loss = 1.38567035, grad/param norm = 2.5606e-01, time/batch = 0.6319s	
3170/16650 (epoch 9.520), train_loss = 1.40825277, grad/param norm = 2.3294e-01, time/batch = 0.6284s	
3171/16650 (epoch 9.523), train_loss = 1.32636605, grad/param norm = 2.1672e-01, time/batch = 0.6338s	
3172/16650 (epoch 9.526), train_loss = 1.43622775, grad/param norm = 2.3133e-01, time/batch = 0.6326s	
3173/16650 (epoch 9.529), train_loss = 1.58933977, grad/param norm = 2.4777e-01, time/batch = 0.6364s	
3174/16650 (epoch 9.532), train_loss = 1.21865580, grad/param norm = 2.3258e-01, time/batch = 0.6676s	
3175/16650 (epoch 9.535), train_loss = 1.24588984, grad/param norm = 2.2609e-01, time/batch = 0.6527s	
3176/16650 (epoch 9.538), train_loss = 1.32929755, grad/param norm = 2.3956e-01, time/batch = 0.6288s	
3177/16650 (epoch 9.541), train_loss = 1.56140946, grad/param norm = 2.5808e-01, time/batch = 0.6318s	
3178/16650 (epoch 9.544), train_loss = 1.62318745, grad/param norm = 2.6874e-01, time/batch = 0.6303s	
3179/16650 (epoch 9.547), train_loss = 1.23062288, grad/param norm = 2.1578e-01, time/batch = 0.6302s	
3180/16650 (epoch 9.550), train_loss = 1.29803905, grad/param norm = 2.2200e-01, time/batch = 0.6308s	
3181/16650 (epoch 9.553), train_loss = 1.39241810, grad/param norm = 2.4519e-01, time/batch = 0.6347s	
3182/16650 (epoch 9.556), train_loss = 1.27898663, grad/param norm = 2.1367e-01, time/batch = 0.6305s	
3183/16650 (epoch 9.559), train_loss = 1.14254057, grad/param norm = 2.0320e-01, time/batch = 0.6292s	
3184/16650 (epoch 9.562), train_loss = 1.36426409, grad/param norm = 2.1961e-01, time/batch = 0.6300s	
3185/16650 (epoch 9.565), train_loss = 1.11790996, grad/param norm = 2.2600e-01, time/batch = 0.6294s	
3186/16650 (epoch 9.568), train_loss = 1.12940064, grad/param norm = 1.9532e-01, time/batch = 0.6283s	
3187/16650 (epoch 9.571), train_loss = 1.21668741, grad/param norm = 2.2949e-01, time/batch = 0.6286s	
3188/16650 (epoch 9.574), train_loss = 1.34844330, grad/param norm = 2.2626e-01, time/batch = 0.6281s	
3189/16650 (epoch 9.577), train_loss = 1.28368374, grad/param norm = 2.2028e-01, time/batch = 0.6330s	
3190/16650 (epoch 9.580), train_loss = 1.21013919, grad/param norm = 2.2997e-01, time/batch = 0.6345s	
3191/16650 (epoch 9.583), train_loss = 1.27845025, grad/param norm = 2.3981e-01, time/batch = 0.6322s	
3192/16650 (epoch 9.586), train_loss = 1.37419551, grad/param norm = 2.6734e-01, time/batch = 0.6291s	
3193/16650 (epoch 9.589), train_loss = 1.14145792, grad/param norm = 1.9703e-01, time/batch = 0.6276s	
3194/16650 (epoch 9.592), train_loss = 1.39994646, grad/param norm = 2.6778e-01, time/batch = 0.6294s	
3195/16650 (epoch 9.595), train_loss = 1.25517234, grad/param norm = 2.2807e-01, time/batch = 0.6285s	
3196/16650 (epoch 9.598), train_loss = 1.27261722, grad/param norm = 2.4063e-01, time/batch = 0.6287s	
3197/16650 (epoch 9.601), train_loss = 1.29081547, grad/param norm = 2.7798e-01, time/batch = 0.6292s	
3198/16650 (epoch 9.604), train_loss = 1.46301432, grad/param norm = 2.6424e-01, time/batch = 0.6342s	
3199/16650 (epoch 9.607), train_loss = 1.37497382, grad/param norm = 2.3478e-01, time/batch = 0.6282s	
3200/16650 (epoch 9.610), train_loss = 1.24691256, grad/param norm = 2.0577e-01, time/batch = 0.6300s	
3201/16650 (epoch 9.613), train_loss = 1.50961862, grad/param norm = 2.3553e-01, time/batch = 0.6308s	
3202/16650 (epoch 9.616), train_loss = 1.55325176, grad/param norm = 2.6076e-01, time/batch = 0.6291s	
3203/16650 (epoch 9.619), train_loss = 1.21685946, grad/param norm = 2.1596e-01, time/batch = 0.6278s	
3204/16650 (epoch 9.622), train_loss = 1.12870174, grad/param norm = 2.2193e-01, time/batch = 0.6294s	
3205/16650 (epoch 9.625), train_loss = 1.29678682, grad/param norm = 2.2817e-01, time/batch = 0.6292s	
3206/16650 (epoch 9.628), train_loss = 1.32078948, grad/param norm = 2.5143e-01, time/batch = 0.6300s	
3207/16650 (epoch 9.631), train_loss = 1.36769598, grad/param norm = 2.5966e-01, time/batch = 0.6351s	
3208/16650 (epoch 9.634), train_loss = 1.60523625, grad/param norm = 2.5854e-01, time/batch = 0.6311s	
3209/16650 (epoch 9.637), train_loss = 1.61000425, grad/param norm = 2.5354e-01, time/batch = 0.6314s	
3210/16650 (epoch 9.640), train_loss = 1.31589503, grad/param norm = 2.3131e-01, time/batch = 0.6285s	
3211/16650 (epoch 9.643), train_loss = 1.44768357, grad/param norm = 2.5406e-01, time/batch = 0.6315s	
3212/16650 (epoch 9.646), train_loss = 1.47602135, grad/param norm = 2.5995e-01, time/batch = 0.6302s	
3213/16650 (epoch 9.649), train_loss = 1.38886825, grad/param norm = 2.2279e-01, time/batch = 0.6506s	
3214/16650 (epoch 9.652), train_loss = 1.53043678, grad/param norm = 2.5333e-01, time/batch = 0.6668s	
3215/16650 (epoch 9.655), train_loss = 1.38011491, grad/param norm = 2.1703e-01, time/batch = 0.6371s	
3216/16650 (epoch 9.658), train_loss = 1.26494553, grad/param norm = 2.1784e-01, time/batch = 0.6390s	
3217/16650 (epoch 9.661), train_loss = 1.45481164, grad/param norm = 2.3021e-01, time/batch = 0.6410s	
3218/16650 (epoch 9.664), train_loss = 1.39102292, grad/param norm = 2.3927e-01, time/batch = 0.6369s	
3219/16650 (epoch 9.667), train_loss = 1.53284606, grad/param norm = 2.4331e-01, time/batch = 0.6381s	
3220/16650 (epoch 9.670), train_loss = 1.21413630, grad/param norm = 2.1105e-01, time/batch = 0.6362s	
3221/16650 (epoch 9.673), train_loss = 1.24526688, grad/param norm = 2.0699e-01, time/batch = 0.6397s	
3222/16650 (epoch 9.676), train_loss = 1.36840749, grad/param norm = 2.4316e-01, time/batch = 0.6326s	
3223/16650 (epoch 9.679), train_loss = 1.25806243, grad/param norm = 2.2042e-01, time/batch = 0.6293s	
3224/16650 (epoch 9.682), train_loss = 1.45819535, grad/param norm = 2.5322e-01, time/batch = 0.6300s	
3225/16650 (epoch 9.685), train_loss = 1.20364791, grad/param norm = 2.2812e-01, time/batch = 0.6301s	
3226/16650 (epoch 9.688), train_loss = 1.36715810, grad/param norm = 2.4885e-01, time/batch = 0.6278s	
3227/16650 (epoch 9.691), train_loss = 1.42758280, grad/param norm = 2.5037e-01, time/batch = 0.6276s	
3228/16650 (epoch 9.694), train_loss = 1.22455101, grad/param norm = 2.1475e-01, time/batch = 0.6283s	
3229/16650 (epoch 9.697), train_loss = 1.20424217, grad/param norm = 2.1263e-01, time/batch = 0.6278s	
3230/16650 (epoch 9.700), train_loss = 1.48649460, grad/param norm = 2.4259e-01, time/batch = 0.6270s	
3231/16650 (epoch 9.703), train_loss = 1.26971255, grad/param norm = 2.3451e-01, time/batch = 0.6335s	
3232/16650 (epoch 9.706), train_loss = 1.47301244, grad/param norm = 2.4702e-01, time/batch = 0.6330s	
3233/16650 (epoch 9.709), train_loss = 1.26072311, grad/param norm = 2.1924e-01, time/batch = 0.6312s	
3234/16650 (epoch 9.712), train_loss = 1.27025075, grad/param norm = 2.3386e-01, time/batch = 0.6280s	
3235/16650 (epoch 9.715), train_loss = 1.50621876, grad/param norm = 2.3142e-01, time/batch = 0.6270s	
3236/16650 (epoch 9.718), train_loss = 1.54688490, grad/param norm = 2.4490e-01, time/batch = 0.6278s	
3237/16650 (epoch 9.721), train_loss = 1.50693388, grad/param norm = 2.5923e-01, time/batch = 0.6275s	
3238/16650 (epoch 9.724), train_loss = 1.51771147, grad/param norm = 2.6124e-01, time/batch = 0.6285s	
3239/16650 (epoch 9.727), train_loss = 1.44345693, grad/param norm = 2.2036e-01, time/batch = 0.6296s	
3240/16650 (epoch 9.730), train_loss = 1.33988882, grad/param norm = 2.2806e-01, time/batch = 0.6307s	
3241/16650 (epoch 9.733), train_loss = 1.51855609, grad/param norm = 2.5537e-01, time/batch = 0.6379s	
3242/16650 (epoch 9.736), train_loss = 1.20633521, grad/param norm = 2.1676e-01, time/batch = 0.6462s	
3243/16650 (epoch 9.739), train_loss = 1.38270922, grad/param norm = 2.1951e-01, time/batch = 0.6347s	
3244/16650 (epoch 9.742), train_loss = 1.39961732, grad/param norm = 2.5545e-01, time/batch = 0.6327s	
3245/16650 (epoch 9.745), train_loss = 1.15993219, grad/param norm = 2.0425e-01, time/batch = 0.6373s	
3246/16650 (epoch 9.748), train_loss = 1.24314105, grad/param norm = 2.4505e-01, time/batch = 0.6377s	
3247/16650 (epoch 9.751), train_loss = 1.44133607, grad/param norm = 2.9985e-01, time/batch = 0.6349s	
3248/16650 (epoch 9.754), train_loss = 1.57699918, grad/param norm = 2.6788e-01, time/batch = 0.6493s	
3249/16650 (epoch 9.757), train_loss = 1.47496500, grad/param norm = 2.4305e-01, time/batch = 0.6699s	
3250/16650 (epoch 9.760), train_loss = 1.33346527, grad/param norm = 2.3367e-01, time/batch = 0.6592s	
3251/16650 (epoch 9.763), train_loss = 1.26461127, grad/param norm = 2.2608e-01, time/batch = 0.6473s	
3252/16650 (epoch 9.766), train_loss = 1.38655662, grad/param norm = 2.1790e-01, time/batch = 0.6551s	
3253/16650 (epoch 9.769), train_loss = 1.34901098, grad/param norm = 2.3745e-01, time/batch = 0.6691s	
3254/16650 (epoch 9.772), train_loss = 1.26993815, grad/param norm = 2.1139e-01, time/batch = 0.6293s	
3255/16650 (epoch 9.775), train_loss = 1.36522971, grad/param norm = 2.2515e-01, time/batch = 0.6292s	
3256/16650 (epoch 9.778), train_loss = 1.27448581, grad/param norm = 2.1497e-01, time/batch = 0.6338s	
3257/16650 (epoch 9.781), train_loss = 1.45429879, grad/param norm = 2.4148e-01, time/batch = 0.6632s	
3258/16650 (epoch 9.784), train_loss = 1.45649886, grad/param norm = 2.4975e-01, time/batch = 0.6551s	
3259/16650 (epoch 9.787), train_loss = 1.48191281, grad/param norm = 2.4122e-01, time/batch = 0.6280s	
3260/16650 (epoch 9.790), train_loss = 1.35699034, grad/param norm = 2.2625e-01, time/batch = 0.6319s	
3261/16650 (epoch 9.793), train_loss = 1.25485866, grad/param norm = 2.6595e-01, time/batch = 0.6296s	
3262/16650 (epoch 9.796), train_loss = 1.76622568, grad/param norm = 2.6752e-01, time/batch = 0.6287s	
3263/16650 (epoch 9.799), train_loss = 1.60168678, grad/param norm = 2.3961e-01, time/batch = 0.6310s	
3264/16650 (epoch 9.802), train_loss = 1.41806470, grad/param norm = 2.5389e-01, time/batch = 0.6292s	
3265/16650 (epoch 9.805), train_loss = 1.38289594, grad/param norm = 2.1658e-01, time/batch = 0.6316s	
3266/16650 (epoch 9.808), train_loss = 1.37175030, grad/param norm = 2.2528e-01, time/batch = 0.6315s	
3267/16650 (epoch 9.811), train_loss = 1.51725267, grad/param norm = 2.3751e-01, time/batch = 0.6284s	
3268/16650 (epoch 9.814), train_loss = 1.24425566, grad/param norm = 2.2104e-01, time/batch = 0.6278s	
3269/16650 (epoch 9.817), train_loss = 1.35709147, grad/param norm = 2.4947e-01, time/batch = 0.6290s	
3270/16650 (epoch 9.820), train_loss = 1.42817644, grad/param norm = 2.5218e-01, time/batch = 0.6314s	
3271/16650 (epoch 9.823), train_loss = 1.24607161, grad/param norm = 2.1656e-01, time/batch = 0.6300s	
3272/16650 (epoch 9.826), train_loss = 1.36896730, grad/param norm = 2.1024e-01, time/batch = 0.6405s	
3273/16650 (epoch 9.829), train_loss = 1.53659269, grad/param norm = 2.6151e-01, time/batch = 0.6383s	
3274/16650 (epoch 9.832), train_loss = 1.52556289, grad/param norm = 2.4567e-01, time/batch = 0.6390s	
3275/16650 (epoch 9.835), train_loss = 1.50722624, grad/param norm = 2.6629e-01, time/batch = 0.6330s	
3276/16650 (epoch 9.838), train_loss = 1.27350649, grad/param norm = 2.3731e-01, time/batch = 0.6287s	
3277/16650 (epoch 9.841), train_loss = 1.24884257, grad/param norm = 2.0804e-01, time/batch = 0.6283s	
3278/16650 (epoch 9.844), train_loss = 1.30930625, grad/param norm = 2.3165e-01, time/batch = 0.6314s	
3279/16650 (epoch 9.847), train_loss = 1.48539582, grad/param norm = 2.3394e-01, time/batch = 0.6300s	
3280/16650 (epoch 9.850), train_loss = 1.23539962, grad/param norm = 2.4398e-01, time/batch = 0.6295s	
3281/16650 (epoch 9.853), train_loss = 1.43450181, grad/param norm = 2.3561e-01, time/batch = 0.6362s	
3282/16650 (epoch 9.856), train_loss = 1.25808662, grad/param norm = 2.3134e-01, time/batch = 0.6332s	
3283/16650 (epoch 9.859), train_loss = 1.45292836, grad/param norm = 2.4364e-01, time/batch = 0.6295s	
3284/16650 (epoch 9.862), train_loss = 1.35068928, grad/param norm = 2.1049e-01, time/batch = 0.6299s	
3285/16650 (epoch 9.865), train_loss = 1.13901896, grad/param norm = 2.0925e-01, time/batch = 0.6283s	
3286/16650 (epoch 9.868), train_loss = 1.45419658, grad/param norm = 2.4300e-01, time/batch = 0.6282s	
3287/16650 (epoch 9.871), train_loss = 1.47386966, grad/param norm = 2.4531e-01, time/batch = 0.6282s	
3288/16650 (epoch 9.874), train_loss = 1.44803389, grad/param norm = 2.3510e-01, time/batch = 0.6351s	
3289/16650 (epoch 9.877), train_loss = 1.27544180, grad/param norm = 2.1474e-01, time/batch = 0.6315s	
3290/16650 (epoch 9.880), train_loss = 1.32668759, grad/param norm = 2.7541e-01, time/batch = 0.6309s	
3291/16650 (epoch 9.883), train_loss = 1.43283354, grad/param norm = 2.3519e-01, time/batch = 0.6350s	
3292/16650 (epoch 9.886), train_loss = 1.41090548, grad/param norm = 2.4814e-01, time/batch = 0.6290s	
3293/16650 (epoch 9.889), train_loss = 1.27123345, grad/param norm = 2.3627e-01, time/batch = 0.6294s	
3294/16650 (epoch 9.892), train_loss = 1.31289809, grad/param norm = 2.2089e-01, time/batch = 0.6284s	
3295/16650 (epoch 9.895), train_loss = 1.47208406, grad/param norm = 2.3435e-01, time/batch = 0.6297s	
3296/16650 (epoch 9.898), train_loss = 1.44133248, grad/param norm = 2.4598e-01, time/batch = 0.6286s	
3297/16650 (epoch 9.901), train_loss = 1.38286325, grad/param norm = 2.1047e-01, time/batch = 0.6296s	
3298/16650 (epoch 9.904), train_loss = 1.31177437, grad/param norm = 2.3621e-01, time/batch = 0.6300s	
3299/16650 (epoch 9.907), train_loss = 1.39970626, grad/param norm = 2.3153e-01, time/batch = 0.6329s	
3300/16650 (epoch 9.910), train_loss = 1.40425255, grad/param norm = 2.4630e-01, time/batch = 0.6293s	
3301/16650 (epoch 9.913), train_loss = 1.32896458, grad/param norm = 2.3737e-01, time/batch = 0.6317s	
3302/16650 (epoch 9.916), train_loss = 1.42911890, grad/param norm = 2.4370e-01, time/batch = 0.6287s	
3303/16650 (epoch 9.919), train_loss = 1.53583513, grad/param norm = 2.4799e-01, time/batch = 0.6296s	
3304/16650 (epoch 9.922), train_loss = 1.52633336, grad/param norm = 2.4956e-01, time/batch = 0.6284s	
3305/16650 (epoch 9.925), train_loss = 1.33386234, grad/param norm = 2.6342e-01, time/batch = 0.6307s	
3306/16650 (epoch 9.928), train_loss = 1.33131118, grad/param norm = 2.1118e-01, time/batch = 0.6683s	
3307/16650 (epoch 9.931), train_loss = 1.41862619, grad/param norm = 2.3607e-01, time/batch = 0.6487s	
3308/16650 (epoch 9.934), train_loss = 1.21978454, grad/param norm = 2.1293e-01, time/batch = 0.6303s	
3309/16650 (epoch 9.937), train_loss = 1.37881920, grad/param norm = 2.5175e-01, time/batch = 0.6284s	
3310/16650 (epoch 9.940), train_loss = 1.29581756, grad/param norm = 2.0241e-01, time/batch = 0.6295s	
3311/16650 (epoch 9.943), train_loss = 1.33848494, grad/param norm = 2.2302e-01, time/batch = 0.6354s	
3312/16650 (epoch 9.946), train_loss = 1.31176142, grad/param norm = 2.4517e-01, time/batch = 0.6305s	
3313/16650 (epoch 9.949), train_loss = 1.31783385, grad/param norm = 2.3813e-01, time/batch = 0.6306s	
3314/16650 (epoch 9.952), train_loss = 1.09799286, grad/param norm = 2.2159e-01, time/batch = 0.6285s	
3315/16650 (epoch 9.955), train_loss = 1.30483288, grad/param norm = 2.2740e-01, time/batch = 0.6294s	
3316/16650 (epoch 9.958), train_loss = 1.46246437, grad/param norm = 2.5943e-01, time/batch = 0.6365s	
3317/16650 (epoch 9.961), train_loss = 1.29408226, grad/param norm = 2.2302e-01, time/batch = 0.6411s	
3318/16650 (epoch 9.964), train_loss = 1.27571396, grad/param norm = 2.3800e-01, time/batch = 0.6360s	
3319/16650 (epoch 9.967), train_loss = 1.53190424, grad/param norm = 2.5113e-01, time/batch = 0.6310s	
3320/16650 (epoch 9.970), train_loss = 1.17612820, grad/param norm = 2.1026e-01, time/batch = 0.6340s	
3321/16650 (epoch 9.973), train_loss = 1.33985513, grad/param norm = 2.9056e-01, time/batch = 0.6476s	
3322/16650 (epoch 9.976), train_loss = 1.26652030, grad/param norm = 2.3151e-01, time/batch = 0.6356s	
3323/16650 (epoch 9.979), train_loss = 1.43012337, grad/param norm = 2.2598e-01, time/batch = 0.6400s	
3324/16650 (epoch 9.982), train_loss = 1.42988769, grad/param norm = 2.3697e-01, time/batch = 0.6337s	
3325/16650 (epoch 9.985), train_loss = 1.31529539, grad/param norm = 2.3103e-01, time/batch = 0.6320s	
3326/16650 (epoch 9.988), train_loss = 1.60244347, grad/param norm = 2.6071e-01, time/batch = 0.6275s	
3327/16650 (epoch 9.991), train_loss = 1.27964939, grad/param norm = 2.5594e-01, time/batch = 0.6290s	
3328/16650 (epoch 9.994), train_loss = 1.32366142, grad/param norm = 2.2299e-01, time/batch = 0.6279s	
3329/16650 (epoch 9.997), train_loss = 1.43264668, grad/param norm = 2.4254e-01, time/batch = 0.6290s	
decayed learning rate by a factor 0.97 to 0.00194	
3330/16650 (epoch 10.000), train_loss = 1.47733805, grad/param norm = 2.6939e-01, time/batch = 0.6300s	
3331/16650 (epoch 10.003), train_loss = 1.47264845, grad/param norm = 2.6658e-01, time/batch = 0.6334s	
3332/16650 (epoch 10.006), train_loss = 1.48848669, grad/param norm = 2.3808e-01, time/batch = 0.6366s	
3333/16650 (epoch 10.009), train_loss = 1.56726636, grad/param norm = 2.4509e-01, time/batch = 0.6283s	
3334/16650 (epoch 10.012), train_loss = 1.64205121, grad/param norm = 3.2183e-01, time/batch = 0.6310s	
3335/16650 (epoch 10.015), train_loss = 1.40785122, grad/param norm = 2.6039e-01, time/batch = 0.6310s	
3336/16650 (epoch 10.018), train_loss = 1.11693487, grad/param norm = 2.3008e-01, time/batch = 0.6272s	
3337/16650 (epoch 10.021), train_loss = 1.52302505, grad/param norm = 2.4370e-01, time/batch = 0.6267s	
3338/16650 (epoch 10.024), train_loss = 1.30440128, grad/param norm = 2.3697e-01, time/batch = 0.6284s	
3339/16650 (epoch 10.027), train_loss = 1.52520170, grad/param norm = 2.5214e-01, time/batch = 0.6355s	
3340/16650 (epoch 10.030), train_loss = 1.21893550, grad/param norm = 2.1534e-01, time/batch = 0.6465s	
3341/16650 (epoch 10.033), train_loss = 1.36744972, grad/param norm = 2.2320e-01, time/batch = 0.6533s	
3342/16650 (epoch 10.036), train_loss = 1.20341285, grad/param norm = 2.4989e-01, time/batch = 0.6574s	
3343/16650 (epoch 10.039), train_loss = 1.46454606, grad/param norm = 2.4888e-01, time/batch = 0.6567s	
3344/16650 (epoch 10.042), train_loss = 1.49240454, grad/param norm = 2.4087e-01, time/batch = 0.6316s	
3345/16650 (epoch 10.045), train_loss = 1.33602700, grad/param norm = 2.2668e-01, time/batch = 0.6309s	
3346/16650 (epoch 10.048), train_loss = 1.44333701, grad/param norm = 2.4070e-01, time/batch = 0.6290s	
3347/16650 (epoch 10.051), train_loss = 1.41634890, grad/param norm = 2.5611e-01, time/batch = 0.6308s	
3348/16650 (epoch 10.054), train_loss = 1.41597553, grad/param norm = 2.3564e-01, time/batch = 0.6325s	
3349/16650 (epoch 10.057), train_loss = 1.35313615, grad/param norm = 2.2721e-01, time/batch = 0.6304s	
3350/16650 (epoch 10.060), train_loss = 1.25205750, grad/param norm = 2.2061e-01, time/batch = 0.6317s	
3351/16650 (epoch 10.063), train_loss = 1.34668529, grad/param norm = 2.3480e-01, time/batch = 0.6318s	
3352/16650 (epoch 10.066), train_loss = 1.54767569, grad/param norm = 2.5430e-01, time/batch = 0.6349s	
3353/16650 (epoch 10.069), train_loss = 1.48400441, grad/param norm = 2.3764e-01, time/batch = 0.6291s	
3354/16650 (epoch 10.072), train_loss = 1.33971110, grad/param norm = 2.4415e-01, time/batch = 0.6474s	
3355/16650 (epoch 10.075), train_loss = 1.38538395, grad/param norm = 2.2278e-01, time/batch = 0.6696s	
3356/16650 (epoch 10.078), train_loss = 1.46074684, grad/param norm = 2.3446e-01, time/batch = 0.6319s	
3357/16650 (epoch 10.081), train_loss = 1.34112721, grad/param norm = 2.4154e-01, time/batch = 0.6385s	
3358/16650 (epoch 10.084), train_loss = 1.44248345, grad/param norm = 2.2285e-01, time/batch = 0.6426s	
3359/16650 (epoch 10.087), train_loss = 1.37281349, grad/param norm = 2.3166e-01, time/batch = 0.6468s	
3360/16650 (epoch 10.090), train_loss = 1.27594548, grad/param norm = 2.1856e-01, time/batch = 0.6566s	
3361/16650 (epoch 10.093), train_loss = 1.66277601, grad/param norm = 2.5110e-01, time/batch = 0.6621s	
3362/16650 (epoch 10.096), train_loss = 1.35888566, grad/param norm = 2.2228e-01, time/batch = 0.6589s	
3363/16650 (epoch 10.099), train_loss = 1.33157379, grad/param norm = 2.0934e-01, time/batch = 0.6587s	
3364/16650 (epoch 10.102), train_loss = 1.39731707, grad/param norm = 2.4319e-01, time/batch = 0.6568s	
3365/16650 (epoch 10.105), train_loss = 1.45987859, grad/param norm = 2.3889e-01, time/batch = 0.6509s	
3366/16650 (epoch 10.108), train_loss = 1.46090402, grad/param norm = 2.3581e-01, time/batch = 0.6453s	
3367/16650 (epoch 10.111), train_loss = 1.42535411, grad/param norm = 2.3430e-01, time/batch = 0.6415s	
3368/16650 (epoch 10.114), train_loss = 1.54336515, grad/param norm = 2.4013e-01, time/batch = 0.6369s	
3369/16650 (epoch 10.117), train_loss = 1.50653710, grad/param norm = 2.3927e-01, time/batch = 0.6271s	
3370/16650 (epoch 10.120), train_loss = 1.26642372, grad/param norm = 2.2186e-01, time/batch = 0.6334s	
3371/16650 (epoch 10.123), train_loss = 1.36783677, grad/param norm = 2.4534e-01, time/batch = 0.6354s	
3372/16650 (epoch 10.126), train_loss = 1.39309758, grad/param norm = 2.5525e-01, time/batch = 0.6340s	
3373/16650 (epoch 10.129), train_loss = 1.41590289, grad/param norm = 2.3062e-01, time/batch = 0.6416s	
3374/16650 (epoch 10.132), train_loss = 1.48055840, grad/param norm = 2.4513e-01, time/batch = 0.6363s	
3375/16650 (epoch 10.135), train_loss = 1.43678655, grad/param norm = 2.3524e-01, time/batch = 0.6333s	
3376/16650 (epoch 10.138), train_loss = 1.45522810, grad/param norm = 2.2948e-01, time/batch = 0.6302s	
3377/16650 (epoch 10.141), train_loss = 1.47702962, grad/param norm = 2.6440e-01, time/batch = 0.6282s	
3378/16650 (epoch 10.144), train_loss = 1.38694176, grad/param norm = 2.5129e-01, time/batch = 0.6268s	
3379/16650 (epoch 10.147), train_loss = 1.54301033, grad/param norm = 2.4244e-01, time/batch = 0.6269s	
3380/16650 (epoch 10.150), train_loss = 1.64698773, grad/param norm = 2.4735e-01, time/batch = 0.6272s	
3381/16650 (epoch 10.153), train_loss = 1.38543194, grad/param norm = 2.2502e-01, time/batch = 0.6298s	
3382/16650 (epoch 10.156), train_loss = 1.22573552, grad/param norm = 2.2440e-01, time/batch = 0.6381s	
3383/16650 (epoch 10.159), train_loss = 1.53664750, grad/param norm = 2.4952e-01, time/batch = 0.6309s	
3384/16650 (epoch 10.162), train_loss = 1.48568573, grad/param norm = 2.3234e-01, time/batch = 0.6307s	
3385/16650 (epoch 10.165), train_loss = 1.47273306, grad/param norm = 2.4181e-01, time/batch = 0.6269s	
3386/16650 (epoch 10.168), train_loss = 1.11557594, grad/param norm = 2.0777e-01, time/batch = 0.6303s	
3387/16650 (epoch 10.171), train_loss = 1.46435938, grad/param norm = 2.1569e-01, time/batch = 0.6278s	
3388/16650 (epoch 10.174), train_loss = 1.21215604, grad/param norm = 2.3376e-01, time/batch = 0.6277s	
3389/16650 (epoch 10.177), train_loss = 1.38859542, grad/param norm = 2.4560e-01, time/batch = 0.6282s	
3390/16650 (epoch 10.180), train_loss = 1.54057089, grad/param norm = 2.4700e-01, time/batch = 0.6284s	
3391/16650 (epoch 10.183), train_loss = 1.67827039, grad/param norm = 2.9002e-01, time/batch = 0.6335s	
3392/16650 (epoch 10.186), train_loss = 1.52260335, grad/param norm = 2.8572e-01, time/batch = 0.6307s	
3393/16650 (epoch 10.189), train_loss = 1.26025363, grad/param norm = 2.1232e-01, time/batch = 0.6279s	
3394/16650 (epoch 10.192), train_loss = 1.32172706, grad/param norm = 2.5900e-01, time/batch = 0.6280s	
3395/16650 (epoch 10.195), train_loss = 1.41806800, grad/param norm = 2.4597e-01, time/batch = 0.6285s	
3396/16650 (epoch 10.198), train_loss = 1.15422301, grad/param norm = 2.1793e-01, time/batch = 0.6437s	
3397/16650 (epoch 10.201), train_loss = 1.34447536, grad/param norm = 2.3220e-01, time/batch = 0.6358s	
3398/16650 (epoch 10.204), train_loss = 1.39272030, grad/param norm = 2.3681e-01, time/batch = 0.6601s	
3399/16650 (epoch 10.207), train_loss = 1.45152727, grad/param norm = 2.5782e-01, time/batch = 0.6627s	
3400/16650 (epoch 10.210), train_loss = 1.33020850, grad/param norm = 2.3511e-01, time/batch = 0.6380s	
3401/16650 (epoch 10.213), train_loss = 1.43087371, grad/param norm = 2.2904e-01, time/batch = 0.6386s	
3402/16650 (epoch 10.216), train_loss = 1.34230288, grad/param norm = 2.3837e-01, time/batch = 0.6360s	
3403/16650 (epoch 10.219), train_loss = 1.38025217, grad/param norm = 2.3778e-01, time/batch = 0.6383s	
3404/16650 (epoch 10.222), train_loss = 1.36432122, grad/param norm = 2.2578e-01, time/batch = 0.6511s	
3405/16650 (epoch 10.225), train_loss = 1.38635189, grad/param norm = 2.3410e-01, time/batch = 0.6358s	
3406/16650 (epoch 10.228), train_loss = 1.29978734, grad/param norm = 2.2950e-01, time/batch = 0.6302s	
3407/16650 (epoch 10.231), train_loss = 1.36614433, grad/param norm = 2.2811e-01, time/batch = 0.6370s	
3408/16650 (epoch 10.234), train_loss = 1.51259522, grad/param norm = 2.4383e-01, time/batch = 0.6410s	
3409/16650 (epoch 10.237), train_loss = 1.39782224, grad/param norm = 2.4792e-01, time/batch = 0.6414s	
3410/16650 (epoch 10.240), train_loss = 1.41945074, grad/param norm = 2.3623e-01, time/batch = 0.6376s	
3411/16650 (epoch 10.243), train_loss = 1.41235833, grad/param norm = 2.1951e-01, time/batch = 0.6376s	
3412/16650 (epoch 10.246), train_loss = 1.50707718, grad/param norm = 2.5184e-01, time/batch = 0.6399s	
3413/16650 (epoch 10.249), train_loss = 1.26052107, grad/param norm = 2.4826e-01, time/batch = 0.6450s	
3414/16650 (epoch 10.252), train_loss = 1.37549119, grad/param norm = 2.3352e-01, time/batch = 0.6419s	
3415/16650 (epoch 10.255), train_loss = 1.51568178, grad/param norm = 2.4944e-01, time/batch = 0.6401s	
3416/16650 (epoch 10.258), train_loss = 1.50474162, grad/param norm = 2.4408e-01, time/batch = 0.6311s	
3417/16650 (epoch 10.261), train_loss = 1.40074379, grad/param norm = 2.3974e-01, time/batch = 0.6308s	
3418/16650 (epoch 10.264), train_loss = 1.35131197, grad/param norm = 2.5888e-01, time/batch = 0.6278s	
3419/16650 (epoch 10.267), train_loss = 1.29235902, grad/param norm = 2.2302e-01, time/batch = 0.6322s	
3420/16650 (epoch 10.270), train_loss = 1.36122049, grad/param norm = 2.1939e-01, time/batch = 0.6294s	
3421/16650 (epoch 10.273), train_loss = 1.49603479, grad/param norm = 2.2027e-01, time/batch = 0.6321s	
3422/16650 (epoch 10.276), train_loss = 1.37585477, grad/param norm = 2.1416e-01, time/batch = 0.6296s	
3423/16650 (epoch 10.279), train_loss = 1.37702278, grad/param norm = 2.2867e-01, time/batch = 0.6288s	
3424/16650 (epoch 10.282), train_loss = 1.20652641, grad/param norm = 2.0136e-01, time/batch = 0.6321s	
3425/16650 (epoch 10.285), train_loss = 1.23480864, grad/param norm = 2.2234e-01, time/batch = 0.6318s	
3426/16650 (epoch 10.288), train_loss = 1.32450853, grad/param norm = 2.3455e-01, time/batch = 0.6327s	
3427/16650 (epoch 10.291), train_loss = 1.10007856, grad/param norm = 2.0480e-01, time/batch = 0.6335s	
3428/16650 (epoch 10.294), train_loss = 1.17877323, grad/param norm = 1.7810e-01, time/batch = 0.6294s	
3429/16650 (epoch 10.297), train_loss = 1.27673145, grad/param norm = 2.2044e-01, time/batch = 0.6299s	
3430/16650 (epoch 10.300), train_loss = 1.11845105, grad/param norm = 2.0809e-01, time/batch = 0.6299s	
3431/16650 (epoch 10.303), train_loss = 1.15814700, grad/param norm = 1.8816e-01, time/batch = 0.6323s	
3432/16650 (epoch 10.306), train_loss = 1.40717467, grad/param norm = 2.1735e-01, time/batch = 0.6341s	
3433/16650 (epoch 10.309), train_loss = 1.48532995, grad/param norm = 2.4071e-01, time/batch = 0.6385s	
3434/16650 (epoch 10.312), train_loss = 1.24189693, grad/param norm = 2.2343e-01, time/batch = 0.6388s	
3435/16650 (epoch 10.315), train_loss = 1.03546531, grad/param norm = 1.8876e-01, time/batch = 0.6493s	
3436/16650 (epoch 10.318), train_loss = 1.13669693, grad/param norm = 2.0116e-01, time/batch = 0.6584s	
3437/16650 (epoch 10.321), train_loss = 1.54110305, grad/param norm = 2.6325e-01, time/batch = 0.6594s	
3438/16650 (epoch 10.324), train_loss = 1.31435017, grad/param norm = 2.3425e-01, time/batch = 0.6307s	
3439/16650 (epoch 10.327), train_loss = 1.51758107, grad/param norm = 2.6318e-01, time/batch = 0.6279s	
3440/16650 (epoch 10.330), train_loss = 1.42487015, grad/param norm = 2.4467e-01, time/batch = 0.6270s	
3441/16650 (epoch 10.333), train_loss = 1.45806820, grad/param norm = 2.5342e-01, time/batch = 0.6309s	
3442/16650 (epoch 10.336), train_loss = 1.22432779, grad/param norm = 2.2127e-01, time/batch = 0.6690s	
3443/16650 (epoch 10.339), train_loss = 1.34182620, grad/param norm = 2.4126e-01, time/batch = 0.6327s	
3444/16650 (epoch 10.342), train_loss = 1.33507687, grad/param norm = 2.5182e-01, time/batch = 0.6301s	
3445/16650 (epoch 10.345), train_loss = 1.20028668, grad/param norm = 2.1754e-01, time/batch = 0.6276s	
3446/16650 (epoch 10.348), train_loss = 1.36961494, grad/param norm = 2.1910e-01, time/batch = 0.6421s	
3447/16650 (epoch 10.351), train_loss = 1.46267457, grad/param norm = 2.6703e-01, time/batch = 0.6682s	
3448/16650 (epoch 10.354), train_loss = 1.52143247, grad/param norm = 2.4357e-01, time/batch = 0.6330s	
3449/16650 (epoch 10.357), train_loss = 1.42279239, grad/param norm = 2.5555e-01, time/batch = 0.6281s	
3450/16650 (epoch 10.360), train_loss = 1.42289497, grad/param norm = 2.3279e-01, time/batch = 0.6390s	
3451/16650 (epoch 10.363), train_loss = 1.51944477, grad/param norm = 2.5266e-01, time/batch = 0.6530s	
3452/16650 (epoch 10.366), train_loss = 1.59279555, grad/param norm = 2.5732e-01, time/batch = 0.6366s	
3453/16650 (epoch 10.369), train_loss = 1.37520530, grad/param norm = 2.2558e-01, time/batch = 0.6280s	
3454/16650 (epoch 10.372), train_loss = 1.37823361, grad/param norm = 2.2263e-01, time/batch = 0.6280s	
3455/16650 (epoch 10.375), train_loss = 1.32960784, grad/param norm = 2.2056e-01, time/batch = 0.6270s	
3456/16650 (epoch 10.378), train_loss = 1.20660544, grad/param norm = 2.0964e-01, time/batch = 0.6269s	
3457/16650 (epoch 10.381), train_loss = 1.41964625, grad/param norm = 2.4547e-01, time/batch = 0.6292s	
3458/16650 (epoch 10.384), train_loss = 1.49662666, grad/param norm = 2.3989e-01, time/batch = 0.6330s	
3459/16650 (epoch 10.387), train_loss = 1.11075632, grad/param norm = 2.0168e-01, time/batch = 0.6319s	
3460/16650 (epoch 10.390), train_loss = 1.44184048, grad/param norm = 2.4345e-01, time/batch = 0.6315s	
3461/16650 (epoch 10.393), train_loss = 1.38952894, grad/param norm = 2.6165e-01, time/batch = 0.6319s	
3462/16650 (epoch 10.396), train_loss = 1.55145940, grad/param norm = 2.5435e-01, time/batch = 0.6282s	
3463/16650 (epoch 10.399), train_loss = 1.44029052, grad/param norm = 2.4183e-01, time/batch = 0.6280s	
3464/16650 (epoch 10.402), train_loss = 1.24190041, grad/param norm = 2.2623e-01, time/batch = 0.6287s	
3465/16650 (epoch 10.405), train_loss = 1.20584706, grad/param norm = 2.3426e-01, time/batch = 0.6272s	
3466/16650 (epoch 10.408), train_loss = 1.51877955, grad/param norm = 2.3635e-01, time/batch = 0.6291s	
3467/16650 (epoch 10.411), train_loss = 1.23461414, grad/param norm = 2.3644e-01, time/batch = 0.6288s	
3468/16650 (epoch 10.414), train_loss = 1.20505112, grad/param norm = 2.1825e-01, time/batch = 0.6329s	
3469/16650 (epoch 10.417), train_loss = 1.17183913, grad/param norm = 1.9464e-01, time/batch = 0.6268s	
3470/16650 (epoch 10.420), train_loss = 1.19435096, grad/param norm = 2.2928e-01, time/batch = 0.6270s	
3471/16650 (epoch 10.423), train_loss = 0.95917499, grad/param norm = 1.9508e-01, time/batch = 0.6293s	
3472/16650 (epoch 10.426), train_loss = 1.24372238, grad/param norm = 2.4128e-01, time/batch = 0.6279s	
3473/16650 (epoch 10.429), train_loss = 1.46423442, grad/param norm = 2.5141e-01, time/batch = 0.6294s	
3474/16650 (epoch 10.432), train_loss = 1.43898641, grad/param norm = 2.5627e-01, time/batch = 0.6287s	
3475/16650 (epoch 10.435), train_loss = 1.59613373, grad/param norm = 2.3289e-01, time/batch = 0.6344s	
3476/16650 (epoch 10.438), train_loss = 1.56191649, grad/param norm = 2.5792e-01, time/batch = 0.6341s	
3477/16650 (epoch 10.441), train_loss = 1.43243535, grad/param norm = 2.5948e-01, time/batch = 0.6325s	
3478/16650 (epoch 10.444), train_loss = 1.31744116, grad/param norm = 2.4041e-01, time/batch = 0.6285s	
3479/16650 (epoch 10.447), train_loss = 1.32810738, grad/param norm = 2.2464e-01, time/batch = 0.6283s	
3480/16650 (epoch 10.450), train_loss = 1.23027659, grad/param norm = 2.1694e-01, time/batch = 0.6358s	
3481/16650 (epoch 10.453), train_loss = 1.28878969, grad/param norm = 2.3438e-01, time/batch = 0.6388s	
3482/16650 (epoch 10.456), train_loss = 1.20003707, grad/param norm = 2.1788e-01, time/batch = 0.6341s	
3483/16650 (epoch 10.459), train_loss = 1.27890651, grad/param norm = 2.3578e-01, time/batch = 0.6350s	
3484/16650 (epoch 10.462), train_loss = 1.58284714, grad/param norm = 2.5241e-01, time/batch = 0.6374s	
3485/16650 (epoch 10.465), train_loss = 1.30423238, grad/param norm = 2.3249e-01, time/batch = 0.6411s	
3486/16650 (epoch 10.468), train_loss = 1.03377532, grad/param norm = 2.0806e-01, time/batch = 0.6687s	
3487/16650 (epoch 10.471), train_loss = 0.96672214, grad/param norm = 2.1410e-01, time/batch = 0.6442s	
3488/16650 (epoch 10.474), train_loss = 1.17260704, grad/param norm = 1.9924e-01, time/batch = 0.6255s	
3489/16650 (epoch 10.477), train_loss = 1.35849143, grad/param norm = 2.4472e-01, time/batch = 0.6282s	
3490/16650 (epoch 10.480), train_loss = 1.38885722, grad/param norm = 2.5123e-01, time/batch = 0.6397s	
3491/16650 (epoch 10.483), train_loss = 1.54501873, grad/param norm = 2.5070e-01, time/batch = 0.6651s	
3492/16650 (epoch 10.486), train_loss = 1.20569675, grad/param norm = 2.2048e-01, time/batch = 0.6337s	
3493/16650 (epoch 10.489), train_loss = 1.27669394, grad/param norm = 2.2181e-01, time/batch = 0.6314s	
3494/16650 (epoch 10.492), train_loss = 1.35783767, grad/param norm = 2.3284e-01, time/batch = 0.6339s	
3495/16650 (epoch 10.495), train_loss = 1.23679388, grad/param norm = 2.5532e-01, time/batch = 0.6358s	
3496/16650 (epoch 10.498), train_loss = 1.34561793, grad/param norm = 2.6431e-01, time/batch = 0.6354s	
3497/16650 (epoch 10.502), train_loss = 1.58971978, grad/param norm = 2.6348e-01, time/batch = 0.6292s	
3498/16650 (epoch 10.505), train_loss = 1.39895062, grad/param norm = 2.1104e-01, time/batch = 0.6286s	
3499/16650 (epoch 10.508), train_loss = 1.40353337, grad/param norm = 2.2471e-01, time/batch = 0.6300s	
3500/16650 (epoch 10.511), train_loss = 1.50972240, grad/param norm = 2.6686e-01, time/batch = 0.6282s	
3501/16650 (epoch 10.514), train_loss = 1.21033557, grad/param norm = 2.2875e-01, time/batch = 0.6331s	
3502/16650 (epoch 10.517), train_loss = 1.33014019, grad/param norm = 2.4586e-01, time/batch = 0.6342s	
3503/16650 (epoch 10.520), train_loss = 1.33906499, grad/param norm = 2.2967e-01, time/batch = 0.6287s	
3504/16650 (epoch 10.523), train_loss = 1.26498848, grad/param norm = 2.1386e-01, time/batch = 0.6289s	
3505/16650 (epoch 10.526), train_loss = 1.39140189, grad/param norm = 2.3059e-01, time/batch = 0.6281s	
3506/16650 (epoch 10.529), train_loss = 1.53980078, grad/param norm = 2.4674e-01, time/batch = 0.6288s	
3507/16650 (epoch 10.532), train_loss = 1.14854740, grad/param norm = 2.1964e-01, time/batch = 0.6300s	
3508/16650 (epoch 10.535), train_loss = 1.19429290, grad/param norm = 2.3217e-01, time/batch = 0.6303s	
3509/16650 (epoch 10.538), train_loss = 1.26707288, grad/param norm = 2.3716e-01, time/batch = 0.6315s	
3510/16650 (epoch 10.541), train_loss = 1.49429144, grad/param norm = 2.5186e-01, time/batch = 0.6343s	
3511/16650 (epoch 10.544), train_loss = 1.55253537, grad/param norm = 2.5619e-01, time/batch = 0.6325s	
3512/16650 (epoch 10.547), train_loss = 1.19519473, grad/param norm = 2.1619e-01, time/batch = 0.6294s	
3513/16650 (epoch 10.550), train_loss = 1.26006271, grad/param norm = 2.2675e-01, time/batch = 0.6317s	
3514/16650 (epoch 10.553), train_loss = 1.33859221, grad/param norm = 2.4947e-01, time/batch = 0.6294s	
3515/16650 (epoch 10.556), train_loss = 1.22923699, grad/param norm = 2.0768e-01, time/batch = 0.6296s	
3516/16650 (epoch 10.559), train_loss = 1.09453355, grad/param norm = 1.9869e-01, time/batch = 0.6305s	
3517/16650 (epoch 10.562), train_loss = 1.30628924, grad/param norm = 2.1674e-01, time/batch = 0.6314s	
3518/16650 (epoch 10.565), train_loss = 1.07741679, grad/param norm = 2.1836e-01, time/batch = 0.6327s	
3519/16650 (epoch 10.568), train_loss = 1.08903811, grad/param norm = 1.9918e-01, time/batch = 0.6401s	
3520/16650 (epoch 10.571), train_loss = 1.16350905, grad/param norm = 2.2643e-01, time/batch = 0.6281s	
3521/16650 (epoch 10.574), train_loss = 1.29185577, grad/param norm = 2.2529e-01, time/batch = 0.6349s	
3522/16650 (epoch 10.577), train_loss = 1.22420988, grad/param norm = 2.1107e-01, time/batch = 0.6320s	
3523/16650 (epoch 10.580), train_loss = 1.15612648, grad/param norm = 2.3075e-01, time/batch = 0.6310s	
3524/16650 (epoch 10.583), train_loss = 1.23923359, grad/param norm = 2.2838e-01, time/batch = 0.6290s	
3525/16650 (epoch 10.586), train_loss = 1.29822733, grad/param norm = 2.5458e-01, time/batch = 0.6366s	
3526/16650 (epoch 10.589), train_loss = 1.10453810, grad/param norm = 1.9796e-01, time/batch = 0.6362s	
3527/16650 (epoch 10.592), train_loss = 1.34310664, grad/param norm = 2.5784e-01, time/batch = 0.6371s	
3528/16650 (epoch 10.595), train_loss = 1.19469373, grad/param norm = 2.2538e-01, time/batch = 0.6359s	
3529/16650 (epoch 10.598), train_loss = 1.22886028, grad/param norm = 2.4417e-01, time/batch = 0.6450s	
3530/16650 (epoch 10.601), train_loss = 1.23352706, grad/param norm = 2.6801e-01, time/batch = 0.6617s	
3531/16650 (epoch 10.604), train_loss = 1.39710757, grad/param norm = 2.5018e-01, time/batch = 0.6527s	
3532/16650 (epoch 10.607), train_loss = 1.33912678, grad/param norm = 2.3531e-01, time/batch = 0.6280s	
3533/16650 (epoch 10.610), train_loss = 1.19621440, grad/param norm = 2.0617e-01, time/batch = 0.6274s	
3534/16650 (epoch 10.613), train_loss = 1.45600832, grad/param norm = 2.3746e-01, time/batch = 0.6276s	
3535/16650 (epoch 10.616), train_loss = 1.49563615, grad/param norm = 2.6214e-01, time/batch = 0.6331s	
3536/16650 (epoch 10.619), train_loss = 1.16110990, grad/param norm = 2.0922e-01, time/batch = 0.6295s	
3537/16650 (epoch 10.622), train_loss = 1.07829759, grad/param norm = 2.2099e-01, time/batch = 0.6277s	
3538/16650 (epoch 10.625), train_loss = 1.24237569, grad/param norm = 2.2531e-01, time/batch = 0.6297s	
3539/16650 (epoch 10.628), train_loss = 1.27612932, grad/param norm = 2.4897e-01, time/batch = 0.6296s	
3540/16650 (epoch 10.631), train_loss = 1.31644326, grad/param norm = 2.5920e-01, time/batch = 0.6291s	
3541/16650 (epoch 10.634), train_loss = 1.56501564, grad/param norm = 2.6048e-01, time/batch = 0.6319s	
3542/16650 (epoch 10.637), train_loss = 1.55402834, grad/param norm = 2.5380e-01, time/batch = 0.6386s	
3543/16650 (epoch 10.640), train_loss = 1.25160170, grad/param norm = 2.2808e-01, time/batch = 0.6419s	
3544/16650 (epoch 10.643), train_loss = 1.39273545, grad/param norm = 2.4902e-01, time/batch = 0.6686s	
3545/16650 (epoch 10.646), train_loss = 1.41671221, grad/param norm = 2.6128e-01, time/batch = 0.6496s	
3546/16650 (epoch 10.649), train_loss = 1.34332137, grad/param norm = 2.2770e-01, time/batch = 0.6302s	
3547/16650 (epoch 10.652), train_loss = 1.46636957, grad/param norm = 2.4245e-01, time/batch = 0.6292s	
3548/16650 (epoch 10.655), train_loss = 1.34329871, grad/param norm = 2.2365e-01, time/batch = 0.6444s	
3549/16650 (epoch 10.658), train_loss = 1.21124160, grad/param norm = 2.1280e-01, time/batch = 0.6691s	
3550/16650 (epoch 10.661), train_loss = 1.40986588, grad/param norm = 2.3019e-01, time/batch = 0.6346s	
3551/16650 (epoch 10.664), train_loss = 1.32558918, grad/param norm = 2.3561e-01, time/batch = 0.6370s	
3552/16650 (epoch 10.667), train_loss = 1.48352430, grad/param norm = 2.4408e-01, time/batch = 0.6351s	
3553/16650 (epoch 10.670), train_loss = 1.15987509, grad/param norm = 2.0091e-01, time/batch = 0.6307s	
3554/16650 (epoch 10.673), train_loss = 1.20756869, grad/param norm = 2.0691e-01, time/batch = 0.6315s	
3555/16650 (epoch 10.676), train_loss = 1.30794892, grad/param norm = 2.3231e-01, time/batch = 0.6320s	
3556/16650 (epoch 10.679), train_loss = 1.20167391, grad/param norm = 2.2567e-01, time/batch = 0.6286s	
3557/16650 (epoch 10.682), train_loss = 1.39672820, grad/param norm = 2.3733e-01, time/batch = 0.6286s	
3558/16650 (epoch 10.685), train_loss = 1.14652520, grad/param norm = 2.2875e-01, time/batch = 0.6279s	
3559/16650 (epoch 10.688), train_loss = 1.32064437, grad/param norm = 2.4484e-01, time/batch = 0.6290s	
3560/16650 (epoch 10.691), train_loss = 1.36219521, grad/param norm = 2.4420e-01, time/batch = 0.6316s	
3561/16650 (epoch 10.694), train_loss = 1.16340505, grad/param norm = 2.0509e-01, time/batch = 0.6357s	
3562/16650 (epoch 10.697), train_loss = 1.16199867, grad/param norm = 2.0968e-01, time/batch = 0.6307s	
3563/16650 (epoch 10.700), train_loss = 1.42503200, grad/param norm = 2.3878e-01, time/batch = 0.6280s	
3564/16650 (epoch 10.703), train_loss = 1.21133920, grad/param norm = 2.3205e-01, time/batch = 0.6281s	
3565/16650 (epoch 10.706), train_loss = 1.42254906, grad/param norm = 2.6127e-01, time/batch = 0.6275s	
3566/16650 (epoch 10.709), train_loss = 1.21489284, grad/param norm = 2.2153e-01, time/batch = 0.6271s	
3567/16650 (epoch 10.712), train_loss = 1.21734515, grad/param norm = 2.3476e-01, time/batch = 0.6311s	
3568/16650 (epoch 10.715), train_loss = 1.45424305, grad/param norm = 2.3485e-01, time/batch = 0.6395s	
3569/16650 (epoch 10.718), train_loss = 1.48396835, grad/param norm = 2.4245e-01, time/batch = 0.6404s	
3570/16650 (epoch 10.721), train_loss = 1.44542850, grad/param norm = 2.5024e-01, time/batch = 0.6558s	
3571/16650 (epoch 10.724), train_loss = 1.46259797, grad/param norm = 2.5578e-01, time/batch = 0.6617s	
3572/16650 (epoch 10.727), train_loss = 1.38952615, grad/param norm = 2.1968e-01, time/batch = 0.6527s	
3573/16650 (epoch 10.730), train_loss = 1.28455681, grad/param norm = 2.2423e-01, time/batch = 0.6507s	
3574/16650 (epoch 10.733), train_loss = 1.45932616, grad/param norm = 2.4583e-01, time/batch = 0.6492s	
3575/16650 (epoch 10.736), train_loss = 1.15607102, grad/param norm = 2.1678e-01, time/batch = 0.6433s	
3576/16650 (epoch 10.739), train_loss = 1.32551759, grad/param norm = 2.2003e-01, time/batch = 0.6464s	
3577/16650 (epoch 10.742), train_loss = 1.34785791, grad/param norm = 2.5560e-01, time/batch = 0.6375s	
3578/16650 (epoch 10.745), train_loss = 1.11533493, grad/param norm = 2.0533e-01, time/batch = 0.6348s	
3579/16650 (epoch 10.748), train_loss = 1.19711410, grad/param norm = 2.4423e-01, time/batch = 0.6358s	
3580/16650 (epoch 10.751), train_loss = 1.38023029, grad/param norm = 2.6360e-01, time/batch = 0.6314s	
3581/16650 (epoch 10.754), train_loss = 1.50998707, grad/param norm = 2.5054e-01, time/batch = 0.6349s	
3582/16650 (epoch 10.757), train_loss = 1.42596229, grad/param norm = 2.4246e-01, time/batch = 0.6341s	
3583/16650 (epoch 10.760), train_loss = 1.29402970, grad/param norm = 2.4509e-01, time/batch = 0.6293s	
3584/16650 (epoch 10.763), train_loss = 1.21841242, grad/param norm = 2.2898e-01, time/batch = 0.6413s	
3585/16650 (epoch 10.766), train_loss = 1.33851060, grad/param norm = 2.1972e-01, time/batch = 0.6390s	
3586/16650 (epoch 10.769), train_loss = 1.30229638, grad/param norm = 2.3073e-01, time/batch = 0.6418s	
3587/16650 (epoch 10.772), train_loss = 1.22255620, grad/param norm = 2.1230e-01, time/batch = 0.6520s	
3588/16650 (epoch 10.775), train_loss = 1.31690282, grad/param norm = 2.2578e-01, time/batch = 0.6689s	
3589/16650 (epoch 10.778), train_loss = 1.24437069, grad/param norm = 2.1688e-01, time/batch = 0.6371s	
3590/16650 (epoch 10.781), train_loss = 1.40427382, grad/param norm = 2.3496e-01, time/batch = 0.6286s	
3591/16650 (epoch 10.784), train_loss = 1.40146209, grad/param norm = 2.4417e-01, time/batch = 0.6294s	
3592/16650 (epoch 10.787), train_loss = 1.42962671, grad/param norm = 2.3847e-01, time/batch = 0.6287s	
3593/16650 (epoch 10.790), train_loss = 1.31549059, grad/param norm = 2.2599e-01, time/batch = 0.6304s	
3594/16650 (epoch 10.793), train_loss = 1.19782813, grad/param norm = 2.5013e-01, time/batch = 0.6306s	
3595/16650 (epoch 10.796), train_loss = 1.70182385, grad/param norm = 2.6784e-01, time/batch = 0.6315s	
3596/16650 (epoch 10.799), train_loss = 1.54476805, grad/param norm = 2.3997e-01, time/batch = 0.6294s	
3597/16650 (epoch 10.802), train_loss = 1.36397086, grad/param norm = 2.5084e-01, time/batch = 0.6276s	
3598/16650 (epoch 10.805), train_loss = 1.33553179, grad/param norm = 2.1798e-01, time/batch = 0.6274s	
3599/16650 (epoch 10.808), train_loss = 1.32373615, grad/param norm = 2.2165e-01, time/batch = 0.6288s	
3600/16650 (epoch 10.811), train_loss = 1.47389381, grad/param norm = 2.3777e-01, time/batch = 0.6293s	
3601/16650 (epoch 10.814), train_loss = 1.19516170, grad/param norm = 2.2055e-01, time/batch = 0.6337s	
3602/16650 (epoch 10.817), train_loss = 1.31383819, grad/param norm = 2.7172e-01, time/batch = 0.6307s	
3603/16650 (epoch 10.820), train_loss = 1.38971461, grad/param norm = 2.6553e-01, time/batch = 0.6339s	
3604/16650 (epoch 10.823), train_loss = 1.20966117, grad/param norm = 2.1766e-01, time/batch = 0.6322s	
3605/16650 (epoch 10.826), train_loss = 1.33237208, grad/param norm = 2.1508e-01, time/batch = 0.6302s	
3606/16650 (epoch 10.829), train_loss = 1.48274162, grad/param norm = 2.5715e-01, time/batch = 0.6292s	
3607/16650 (epoch 10.832), train_loss = 1.48517072, grad/param norm = 2.5805e-01, time/batch = 0.6301s	
3608/16650 (epoch 10.835), train_loss = 1.46180498, grad/param norm = 2.7246e-01, time/batch = 0.6295s	
3609/16650 (epoch 10.838), train_loss = 1.22205142, grad/param norm = 2.2977e-01, time/batch = 0.6292s	
3610/16650 (epoch 10.841), train_loss = 1.20939900, grad/param norm = 2.0586e-01, time/batch = 0.6287s	
3611/16650 (epoch 10.844), train_loss = 1.25465552, grad/param norm = 2.2377e-01, time/batch = 0.6330s	
3612/16650 (epoch 10.847), train_loss = 1.42641715, grad/param norm = 2.3811e-01, time/batch = 0.6311s	
3613/16650 (epoch 10.850), train_loss = 1.18271919, grad/param norm = 2.4631e-01, time/batch = 0.6294s	
3614/16650 (epoch 10.853), train_loss = 1.37276539, grad/param norm = 2.4315e-01, time/batch = 0.6320s	
3615/16650 (epoch 10.856), train_loss = 1.20568731, grad/param norm = 2.2887e-01, time/batch = 0.6312s	
3616/16650 (epoch 10.859), train_loss = 1.40889502, grad/param norm = 2.4619e-01, time/batch = 0.6284s	
3617/16650 (epoch 10.862), train_loss = 1.30904051, grad/param norm = 2.1510e-01, time/batch = 0.6295s	
3618/16650 (epoch 10.865), train_loss = 1.09346148, grad/param norm = 2.0423e-01, time/batch = 0.6305s	
3619/16650 (epoch 10.868), train_loss = 1.40579471, grad/param norm = 2.4436e-01, time/batch = 0.6389s	
3620/16650 (epoch 10.871), train_loss = 1.42170805, grad/param norm = 2.4320e-01, time/batch = 0.6409s	
3621/16650 (epoch 10.874), train_loss = 1.40289014, grad/param norm = 2.3875e-01, time/batch = 0.6450s	
3622/16650 (epoch 10.877), train_loss = 1.24160534, grad/param norm = 2.1931e-01, time/batch = 0.6390s	
3623/16650 (epoch 10.880), train_loss = 1.28195847, grad/param norm = 2.7228e-01, time/batch = 0.6548s	
3624/16650 (epoch 10.883), train_loss = 1.37424955, grad/param norm = 2.2928e-01, time/batch = 0.6634s	
3625/16650 (epoch 10.886), train_loss = 1.35830409, grad/param norm = 2.5529e-01, time/batch = 0.6488s	
3626/16650 (epoch 10.889), train_loss = 1.21109928, grad/param norm = 2.2926e-01, time/batch = 0.6414s	
3627/16650 (epoch 10.892), train_loss = 1.27245023, grad/param norm = 2.2071e-01, time/batch = 0.6433s	
3628/16650 (epoch 10.895), train_loss = 1.41890111, grad/param norm = 2.3379e-01, time/batch = 0.6561s	
3629/16650 (epoch 10.898), train_loss = 1.39542091, grad/param norm = 2.4071e-01, time/batch = 0.6450s	
3630/16650 (epoch 10.901), train_loss = 1.33496720, grad/param norm = 2.0936e-01, time/batch = 0.6323s	
3631/16650 (epoch 10.904), train_loss = 1.26093033, grad/param norm = 2.3940e-01, time/batch = 0.6374s	
3632/16650 (epoch 10.907), train_loss = 1.36769277, grad/param norm = 2.3829e-01, time/batch = 0.6354s	
3633/16650 (epoch 10.910), train_loss = 1.36011375, grad/param norm = 2.3325e-01, time/batch = 0.6368s	
3634/16650 (epoch 10.913), train_loss = 1.27115371, grad/param norm = 2.2419e-01, time/batch = 0.6341s	
3635/16650 (epoch 10.916), train_loss = 1.38209841, grad/param norm = 2.4004e-01, time/batch = 0.6333s	
3636/16650 (epoch 10.919), train_loss = 1.51085361, grad/param norm = 2.8714e-01, time/batch = 0.6658s	
3637/16650 (epoch 10.922), train_loss = 1.48625230, grad/param norm = 2.6397e-01, time/batch = 0.6550s	
3638/16650 (epoch 10.925), train_loss = 1.27583451, grad/param norm = 2.4268e-01, time/batch = 0.6291s	
3639/16650 (epoch 10.928), train_loss = 1.27702365, grad/param norm = 2.1308e-01, time/batch = 0.6323s	
3640/16650 (epoch 10.931), train_loss = 1.37613738, grad/param norm = 2.3683e-01, time/batch = 0.6398s	
3641/16650 (epoch 10.934), train_loss = 1.17770006, grad/param norm = 2.1280e-01, time/batch = 0.6710s	
3642/16650 (epoch 10.937), train_loss = 1.33111522, grad/param norm = 2.6361e-01, time/batch = 0.6404s	
3643/16650 (epoch 10.940), train_loss = 1.25472752, grad/param norm = 2.0350e-01, time/batch = 0.6297s	
3644/16650 (epoch 10.943), train_loss = 1.30248412, grad/param norm = 2.3018e-01, time/batch = 0.6301s	
3645/16650 (epoch 10.946), train_loss = 1.26372287, grad/param norm = 2.4599e-01, time/batch = 0.6321s	
3646/16650 (epoch 10.949), train_loss = 1.25197894, grad/param norm = 2.4120e-01, time/batch = 0.6300s	
3647/16650 (epoch 10.952), train_loss = 1.05148957, grad/param norm = 2.1644e-01, time/batch = 0.6336s	
3648/16650 (epoch 10.955), train_loss = 1.25199557, grad/param norm = 2.2060e-01, time/batch = 0.6374s	
3649/16650 (epoch 10.958), train_loss = 1.41115795, grad/param norm = 2.6119e-01, time/batch = 0.6280s	
3650/16650 (epoch 10.961), train_loss = 1.25021394, grad/param norm = 2.1739e-01, time/batch = 0.6287s	
3651/16650 (epoch 10.964), train_loss = 1.22064252, grad/param norm = 2.3239e-01, time/batch = 0.6323s	
3652/16650 (epoch 10.967), train_loss = 1.47966139, grad/param norm = 2.4850e-01, time/batch = 0.6290s	
3653/16650 (epoch 10.970), train_loss = 1.14276515, grad/param norm = 2.0965e-01, time/batch = 0.6304s	
3654/16650 (epoch 10.973), train_loss = 1.27421528, grad/param norm = 2.7122e-01, time/batch = 0.6301s	
3655/16650 (epoch 10.976), train_loss = 1.22000688, grad/param norm = 2.3114e-01, time/batch = 0.6312s	
3656/16650 (epoch 10.979), train_loss = 1.37471574, grad/param norm = 2.2692e-01, time/batch = 0.6418s	
3657/16650 (epoch 10.982), train_loss = 1.39009475, grad/param norm = 2.3679e-01, time/batch = 0.6541s	
3658/16650 (epoch 10.985), train_loss = 1.26821975, grad/param norm = 2.2602e-01, time/batch = 0.6474s	
3659/16650 (epoch 10.988), train_loss = 1.55185820, grad/param norm = 2.7641e-01, time/batch = 0.6409s	
3660/16650 (epoch 10.991), train_loss = 1.22874324, grad/param norm = 2.6084e-01, time/batch = 0.6345s	
3661/16650 (epoch 10.994), train_loss = 1.28174257, grad/param norm = 2.3417e-01, time/batch = 0.6342s	
3662/16650 (epoch 10.997), train_loss = 1.38337806, grad/param norm = 2.4784e-01, time/batch = 0.6398s	
decayed learning rate by a factor 0.97 to 0.0018818	
3663/16650 (epoch 11.000), train_loss = 1.41608024, grad/param norm = 2.5805e-01, time/batch = 0.6325s	
3664/16650 (epoch 11.003), train_loss = 1.40895555, grad/param norm = 2.5602e-01, time/batch = 0.6300s	
3665/16650 (epoch 11.006), train_loss = 1.43677056, grad/param norm = 2.2981e-01, time/batch = 0.6290s	
3666/16650 (epoch 11.009), train_loss = 1.52264909, grad/param norm = 2.5097e-01, time/batch = 0.6321s	
3667/16650 (epoch 11.012), train_loss = 1.58592210, grad/param norm = 3.0284e-01, time/batch = 0.6282s	
3668/16650 (epoch 11.015), train_loss = 1.33252183, grad/param norm = 2.5561e-01, time/batch = 0.6297s	
3669/16650 (epoch 11.018), train_loss = 1.09054603, grad/param norm = 2.4968e-01, time/batch = 0.6327s	
3670/16650 (epoch 11.021), train_loss = 1.47187728, grad/param norm = 2.4524e-01, time/batch = 0.6309s	
3671/16650 (epoch 11.024), train_loss = 1.25673361, grad/param norm = 2.3279e-01, time/batch = 0.6326s	
3672/16650 (epoch 11.027), train_loss = 1.46791645, grad/param norm = 2.4697e-01, time/batch = 0.6297s	
3673/16650 (epoch 11.030), train_loss = 1.17324056, grad/param norm = 2.1650e-01, time/batch = 0.6316s	
3674/16650 (epoch 11.033), train_loss = 1.32100745, grad/param norm = 2.2717e-01, time/batch = 0.6291s	
3675/16650 (epoch 11.036), train_loss = 1.14337568, grad/param norm = 2.4636e-01, time/batch = 0.6596s	
3676/16650 (epoch 11.039), train_loss = 1.41586090, grad/param norm = 2.4264e-01, time/batch = 0.6581s	
3677/16650 (epoch 11.042), train_loss = 1.44129680, grad/param norm = 2.4329e-01, time/batch = 0.6351s	
3678/16650 (epoch 11.045), train_loss = 1.30154356, grad/param norm = 2.2645e-01, time/batch = 0.6298s	
3679/16650 (epoch 11.048), train_loss = 1.40533669, grad/param norm = 2.4081e-01, time/batch = 0.6399s	
3680/16650 (epoch 11.051), train_loss = 1.35885380, grad/param norm = 2.5355e-01, time/batch = 0.6682s	
3681/16650 (epoch 11.054), train_loss = 1.36907700, grad/param norm = 2.4165e-01, time/batch = 0.6458s	
3682/16650 (epoch 11.057), train_loss = 1.31062736, grad/param norm = 2.3535e-01, time/batch = 0.6301s	
3683/16650 (epoch 11.060), train_loss = 1.20578564, grad/param norm = 2.2458e-01, time/batch = 0.6315s	
3684/16650 (epoch 11.063), train_loss = 1.29328218, grad/param norm = 2.3646e-01, time/batch = 0.6310s	
3685/16650 (epoch 11.066), train_loss = 1.50954223, grad/param norm = 2.3770e-01, time/batch = 0.6295s	
3686/16650 (epoch 11.069), train_loss = 1.44208831, grad/param norm = 2.5447e-01, time/batch = 0.6305s	
3687/16650 (epoch 11.072), train_loss = 1.29133497, grad/param norm = 2.5346e-01, time/batch = 0.6338s	
3688/16650 (epoch 11.075), train_loss = 1.34580648, grad/param norm = 2.2726e-01, time/batch = 0.6310s	
3689/16650 (epoch 11.078), train_loss = 1.42317304, grad/param norm = 2.3424e-01, time/batch = 0.6298s	
3690/16650 (epoch 11.081), train_loss = 1.29536284, grad/param norm = 2.4261e-01, time/batch = 0.6292s	
3691/16650 (epoch 11.084), train_loss = 1.39898849, grad/param norm = 2.3151e-01, time/batch = 0.6352s	
3692/16650 (epoch 11.087), train_loss = 1.31358505, grad/param norm = 2.3479e-01, time/batch = 0.6405s	
3693/16650 (epoch 11.090), train_loss = 1.23723872, grad/param norm = 2.1593e-01, time/batch = 0.6421s	
3694/16650 (epoch 11.093), train_loss = 1.60694111, grad/param norm = 2.4720e-01, time/batch = 0.6417s	
3695/16650 (epoch 11.096), train_loss = 1.30970464, grad/param norm = 2.2157e-01, time/batch = 0.6458s	
3696/16650 (epoch 11.099), train_loss = 1.29033980, grad/param norm = 2.1422e-01, time/batch = 0.6415s	
3697/16650 (epoch 11.102), train_loss = 1.35387335, grad/param norm = 2.4595e-01, time/batch = 0.6377s	
3698/16650 (epoch 11.105), train_loss = 1.41101162, grad/param norm = 2.4146e-01, time/batch = 0.6294s	
3699/16650 (epoch 11.108), train_loss = 1.41368392, grad/param norm = 2.4652e-01, time/batch = 0.6293s	
3700/16650 (epoch 11.111), train_loss = 1.38198781, grad/param norm = 2.2997e-01, time/batch = 0.6314s	
3701/16650 (epoch 11.114), train_loss = 1.49311758, grad/param norm = 2.4100e-01, time/batch = 0.6354s	
3702/16650 (epoch 11.117), train_loss = 1.48003117, grad/param norm = 2.4089e-01, time/batch = 0.6323s	
3703/16650 (epoch 11.120), train_loss = 1.21704136, grad/param norm = 2.1590e-01, time/batch = 0.6327s	
3704/16650 (epoch 11.123), train_loss = 1.31934434, grad/param norm = 2.4215e-01, time/batch = 0.6339s	
3705/16650 (epoch 11.126), train_loss = 1.33819964, grad/param norm = 2.4991e-01, time/batch = 0.6318s	
3706/16650 (epoch 11.129), train_loss = 1.36770491, grad/param norm = 2.2238e-01, time/batch = 0.6281s	
3707/16650 (epoch 11.132), train_loss = 1.41857674, grad/param norm = 2.3772e-01, time/batch = 0.6275s	
3708/16650 (epoch 11.135), train_loss = 1.38823968, grad/param norm = 2.3179e-01, time/batch = 0.6283s	
3709/16650 (epoch 11.138), train_loss = 1.40693140, grad/param norm = 2.1923e-01, time/batch = 0.6281s	
3710/16650 (epoch 11.141), train_loss = 1.43124314, grad/param norm = 2.5491e-01, time/batch = 0.6304s	
3711/16650 (epoch 11.144), train_loss = 1.33786088, grad/param norm = 2.4351e-01, time/batch = 0.6319s	
3712/16650 (epoch 11.147), train_loss = 1.50222689, grad/param norm = 2.3835e-01, time/batch = 0.6326s	
3713/16650 (epoch 11.150), train_loss = 1.59958665, grad/param norm = 2.3889e-01, time/batch = 0.6345s	
3714/16650 (epoch 11.153), train_loss = 1.35100112, grad/param norm = 2.2703e-01, time/batch = 0.6310s	
3715/16650 (epoch 11.156), train_loss = 1.17075776, grad/param norm = 2.1660e-01, time/batch = 0.6354s	
3716/16650 (epoch 11.159), train_loss = 1.48519670, grad/param norm = 2.5256e-01, time/batch = 0.6397s	
3717/16650 (epoch 11.162), train_loss = 1.45514437, grad/param norm = 2.2920e-01, time/batch = 0.6534s	
3718/16650 (epoch 11.165), train_loss = 1.43619720, grad/param norm = 2.4151e-01, time/batch = 0.6559s	
3719/16650 (epoch 11.168), train_loss = 1.07802117, grad/param norm = 2.0570e-01, time/batch = 0.6783s	
3720/16650 (epoch 11.171), train_loss = 1.43312967, grad/param norm = 2.2010e-01, time/batch = 0.6692s	
3721/16650 (epoch 11.174), train_loss = 1.16506434, grad/param norm = 2.3118e-01, time/batch = 0.6741s	
3722/16650 (epoch 11.177), train_loss = 1.34196096, grad/param norm = 2.2993e-01, time/batch = 0.6416s	
3723/16650 (epoch 11.180), train_loss = 1.48848040, grad/param norm = 2.5338e-01, time/batch = 0.6516s	
3724/16650 (epoch 11.183), train_loss = 1.62680419, grad/param norm = 2.7238e-01, time/batch = 0.6693s	
3725/16650 (epoch 11.186), train_loss = 1.45325523, grad/param norm = 2.4826e-01, time/batch = 0.6322s	
3726/16650 (epoch 11.189), train_loss = 1.20857195, grad/param norm = 2.0131e-01, time/batch = 0.6392s	
3727/16650 (epoch 11.192), train_loss = 1.27179632, grad/param norm = 2.4956e-01, time/batch = 0.6353s	
3728/16650 (epoch 11.195), train_loss = 1.35730390, grad/param norm = 2.4113e-01, time/batch = 0.6340s	
3729/16650 (epoch 11.198), train_loss = 1.11671737, grad/param norm = 2.1529e-01, time/batch = 0.6371s	
3730/16650 (epoch 11.201), train_loss = 1.28697333, grad/param norm = 2.2900e-01, time/batch = 0.6331s	
3731/16650 (epoch 11.204), train_loss = 1.36165713, grad/param norm = 2.7886e-01, time/batch = 0.6344s	
3732/16650 (epoch 11.207), train_loss = 1.41894846, grad/param norm = 2.6949e-01, time/batch = 0.6324s	
3733/16650 (epoch 11.210), train_loss = 1.28372341, grad/param norm = 2.2812e-01, time/batch = 0.6335s	
3734/16650 (epoch 11.213), train_loss = 1.39557119, grad/param norm = 2.3384e-01, time/batch = 0.6300s	
3735/16650 (epoch 11.216), train_loss = 1.29017732, grad/param norm = 2.3415e-01, time/batch = 0.6310s	
3736/16650 (epoch 11.219), train_loss = 1.33014188, grad/param norm = 2.2817e-01, time/batch = 0.6317s	
3737/16650 (epoch 11.222), train_loss = 1.32001162, grad/param norm = 2.2095e-01, time/batch = 0.6313s	
3738/16650 (epoch 11.225), train_loss = 1.33538099, grad/param norm = 2.2392e-01, time/batch = 0.6361s	
3739/16650 (epoch 11.228), train_loss = 1.25292760, grad/param norm = 2.2675e-01, time/batch = 0.6361s	
3740/16650 (epoch 11.231), train_loss = 1.31298985, grad/param norm = 2.2649e-01, time/batch = 0.6329s	
3741/16650 (epoch 11.234), train_loss = 1.47455275, grad/param norm = 2.4397e-01, time/batch = 0.6447s	
3742/16650 (epoch 11.237), train_loss = 1.35139605, grad/param norm = 2.5377e-01, time/batch = 0.6443s	
3743/16650 (epoch 11.240), train_loss = 1.37593925, grad/param norm = 2.5116e-01, time/batch = 0.6313s	
3744/16650 (epoch 11.243), train_loss = 1.36608470, grad/param norm = 2.2509e-01, time/batch = 0.6310s	
3745/16650 (epoch 11.246), train_loss = 1.46820475, grad/param norm = 2.5739e-01, time/batch = 0.6308s	
3746/16650 (epoch 11.249), train_loss = 1.22009561, grad/param norm = 2.5029e-01, time/batch = 0.6317s	
3747/16650 (epoch 11.252), train_loss = 1.32413918, grad/param norm = 2.2788e-01, time/batch = 0.6276s	
3748/16650 (epoch 11.255), train_loss = 1.46254529, grad/param norm = 2.4657e-01, time/batch = 0.6286s	
3749/16650 (epoch 11.258), train_loss = 1.46506784, grad/param norm = 2.4184e-01, time/batch = 0.6297s	
3750/16650 (epoch 11.261), train_loss = 1.35393940, grad/param norm = 2.3975e-01, time/batch = 0.6297s	
3751/16650 (epoch 11.264), train_loss = 1.30047259, grad/param norm = 2.5924e-01, time/batch = 0.6314s	
3752/16650 (epoch 11.267), train_loss = 1.25517765, grad/param norm = 2.2094e-01, time/batch = 0.6298s	
3753/16650 (epoch 11.270), train_loss = 1.32710404, grad/param norm = 2.2699e-01, time/batch = 0.6308s	
3754/16650 (epoch 11.273), train_loss = 1.44730505, grad/param norm = 2.2087e-01, time/batch = 0.6326s	
3755/16650 (epoch 11.276), train_loss = 1.33219949, grad/param norm = 2.1022e-01, time/batch = 0.6272s	
3756/16650 (epoch 11.279), train_loss = 1.32777636, grad/param norm = 2.2633e-01, time/batch = 0.6287s	
3757/16650 (epoch 11.282), train_loss = 1.16803042, grad/param norm = 2.0183e-01, time/batch = 0.6330s	
3758/16650 (epoch 11.285), train_loss = 1.19150532, grad/param norm = 2.1940e-01, time/batch = 0.6309s	
3759/16650 (epoch 11.288), train_loss = 1.27305583, grad/param norm = 2.3444e-01, time/batch = 0.6340s	
3760/16650 (epoch 11.291), train_loss = 1.06076978, grad/param norm = 2.1021e-01, time/batch = 0.6297s	
3761/16650 (epoch 11.294), train_loss = 1.13943684, grad/param norm = 1.8344e-01, time/batch = 0.6329s	
3762/16650 (epoch 11.297), train_loss = 1.23737290, grad/param norm = 2.2007e-01, time/batch = 0.6387s	
3763/16650 (epoch 11.300), train_loss = 1.07451512, grad/param norm = 2.0754e-01, time/batch = 0.6323s	
3764/16650 (epoch 11.303), train_loss = 1.12116551, grad/param norm = 1.8547e-01, time/batch = 0.6486s	
3765/16650 (epoch 11.306), train_loss = 1.36664788, grad/param norm = 2.1483e-01, time/batch = 0.6351s	
3766/16650 (epoch 11.309), train_loss = 1.43266131, grad/param norm = 2.3834e-01, time/batch = 0.6305s	
3767/16650 (epoch 11.312), train_loss = 1.19845411, grad/param norm = 2.3046e-01, time/batch = 0.6299s	
3768/16650 (epoch 11.315), train_loss = 0.98771052, grad/param norm = 1.7764e-01, time/batch = 0.6301s	
3769/16650 (epoch 11.318), train_loss = 1.08725087, grad/param norm = 2.0810e-01, time/batch = 0.6380s	
3770/16650 (epoch 11.321), train_loss = 1.49866001, grad/param norm = 2.5857e-01, time/batch = 0.6313s	
3771/16650 (epoch 11.324), train_loss = 1.26383768, grad/param norm = 2.4370e-01, time/batch = 0.6338s	
3772/16650 (epoch 11.327), train_loss = 1.45993877, grad/param norm = 2.5334e-01, time/batch = 0.6641s	
3773/16650 (epoch 11.330), train_loss = 1.37275759, grad/param norm = 2.5273e-01, time/batch = 0.6550s	
3774/16650 (epoch 11.333), train_loss = 1.40816715, grad/param norm = 2.6004e-01, time/batch = 0.6308s	
3775/16650 (epoch 11.336), train_loss = 1.17913395, grad/param norm = 2.1837e-01, time/batch = 0.6395s	
3776/16650 (epoch 11.339), train_loss = 1.29564375, grad/param norm = 2.3626e-01, time/batch = 0.6392s	
3777/16650 (epoch 11.342), train_loss = 1.27738328, grad/param norm = 2.4484e-01, time/batch = 0.6686s	
3778/16650 (epoch 11.345), train_loss = 1.15127294, grad/param norm = 2.0884e-01, time/batch = 0.6426s	
3779/16650 (epoch 11.348), train_loss = 1.32777389, grad/param norm = 2.2214e-01, time/batch = 0.6315s	
3780/16650 (epoch 11.351), train_loss = 1.41082884, grad/param norm = 2.6359e-01, time/batch = 0.6306s	
3781/16650 (epoch 11.354), train_loss = 1.47750158, grad/param norm = 2.6567e-01, time/batch = 0.6322s	
3782/16650 (epoch 11.357), train_loss = 1.38083139, grad/param norm = 2.6898e-01, time/batch = 0.6288s	
3783/16650 (epoch 11.360), train_loss = 1.37528891, grad/param norm = 2.3112e-01, time/batch = 0.6284s	
3784/16650 (epoch 11.363), train_loss = 1.46884226, grad/param norm = 2.5546e-01, time/batch = 0.6368s	
3785/16650 (epoch 11.366), train_loss = 1.54313524, grad/param norm = 2.5920e-01, time/batch = 0.6376s	
3786/16650 (epoch 11.369), train_loss = 1.32070274, grad/param norm = 2.2509e-01, time/batch = 0.6352s	
3787/16650 (epoch 11.372), train_loss = 1.32570185, grad/param norm = 2.2034e-01, time/batch = 0.6344s	
3788/16650 (epoch 11.375), train_loss = 1.29534794, grad/param norm = 2.2271e-01, time/batch = 0.6326s	
3789/16650 (epoch 11.378), train_loss = 1.17285799, grad/param norm = 2.1449e-01, time/batch = 0.6291s	
3790/16650 (epoch 11.381), train_loss = 1.37362889, grad/param norm = 2.4233e-01, time/batch = 0.6362s	
3791/16650 (epoch 11.384), train_loss = 1.45270895, grad/param norm = 2.3677e-01, time/batch = 0.6350s	
3792/16650 (epoch 11.387), train_loss = 1.06604801, grad/param norm = 2.0447e-01, time/batch = 0.6309s	
3793/16650 (epoch 11.390), train_loss = 1.39304461, grad/param norm = 2.4411e-01, time/batch = 0.6306s	
3794/16650 (epoch 11.393), train_loss = 1.34702542, grad/param norm = 2.5852e-01, time/batch = 0.6330s	
3795/16650 (epoch 11.396), train_loss = 1.50078916, grad/param norm = 2.6397e-01, time/batch = 0.6324s	
3796/16650 (epoch 11.399), train_loss = 1.39639462, grad/param norm = 2.5343e-01, time/batch = 0.6315s	
3797/16650 (epoch 11.402), train_loss = 1.20372961, grad/param norm = 2.2021e-01, time/batch = 0.6303s	
3798/16650 (epoch 11.405), train_loss = 1.17271111, grad/param norm = 2.5173e-01, time/batch = 0.6287s	
3799/16650 (epoch 11.408), train_loss = 1.46935291, grad/param norm = 2.3513e-01, time/batch = 0.6285s	
3800/16650 (epoch 11.411), train_loss = 1.19518008, grad/param norm = 2.4450e-01, time/batch = 0.6293s	
3801/16650 (epoch 11.414), train_loss = 1.16953224, grad/param norm = 2.2246e-01, time/batch = 0.6314s	
3802/16650 (epoch 11.417), train_loss = 1.13020831, grad/param norm = 1.9129e-01, time/batch = 0.6307s	
3803/16650 (epoch 11.420), train_loss = 1.14624203, grad/param norm = 2.3694e-01, time/batch = 0.6303s	
3804/16650 (epoch 11.423), train_loss = 0.93400589, grad/param norm = 1.9459e-01, time/batch = 0.6320s	
3805/16650 (epoch 11.426), train_loss = 1.19358178, grad/param norm = 2.4640e-01, time/batch = 0.6321s	
3806/16650 (epoch 11.429), train_loss = 1.41712030, grad/param norm = 2.4406e-01, time/batch = 0.6286s	
3807/16650 (epoch 11.432), train_loss = 1.38650582, grad/param norm = 2.4924e-01, time/batch = 0.6283s	
3808/16650 (epoch 11.435), train_loss = 1.54979759, grad/param norm = 2.3687e-01, time/batch = 0.6280s	
3809/16650 (epoch 11.438), train_loss = 1.51440764, grad/param norm = 2.5814e-01, time/batch = 0.6360s	
3810/16650 (epoch 11.441), train_loss = 1.37528502, grad/param norm = 2.5866e-01, time/batch = 0.6383s	
3811/16650 (epoch 11.444), train_loss = 1.26543649, grad/param norm = 2.3773e-01, time/batch = 0.6614s	
3812/16650 (epoch 11.447), train_loss = 1.27878296, grad/param norm = 2.1444e-01, time/batch = 0.6609s	
3813/16650 (epoch 11.450), train_loss = 1.18861918, grad/param norm = 2.2103e-01, time/batch = 0.6464s	
3814/16650 (epoch 11.453), train_loss = 1.23450200, grad/param norm = 2.2551e-01, time/batch = 0.6317s	
3815/16650 (epoch 11.456), train_loss = 1.14775549, grad/param norm = 2.1007e-01, time/batch = 0.6432s	
3816/16650 (epoch 11.459), train_loss = 1.22977098, grad/param norm = 2.3255e-01, time/batch = 0.6690s	
3817/16650 (epoch 11.462), train_loss = 1.51977225, grad/param norm = 2.4598e-01, time/batch = 0.6478s	
3818/16650 (epoch 11.465), train_loss = 1.26138187, grad/param norm = 2.3227e-01, time/batch = 0.6364s	
3819/16650 (epoch 11.468), train_loss = 0.99862889, grad/param norm = 2.0675e-01, time/batch = 0.6386s	
3820/16650 (epoch 11.471), train_loss = 0.91717318, grad/param norm = 2.0308e-01, time/batch = 0.6526s	
3821/16650 (epoch 11.474), train_loss = 1.13633213, grad/param norm = 1.9803e-01, time/batch = 0.6712s	
3822/16650 (epoch 11.477), train_loss = 1.31692710, grad/param norm = 2.4005e-01, time/batch = 0.6335s	
3823/16650 (epoch 11.480), train_loss = 1.34117718, grad/param norm = 2.5011e-01, time/batch = 0.6299s	
3824/16650 (epoch 11.483), train_loss = 1.49082660, grad/param norm = 2.4062e-01, time/batch = 0.6286s	
3825/16650 (epoch 11.486), train_loss = 1.17565527, grad/param norm = 2.2286e-01, time/batch = 0.6304s	
3826/16650 (epoch 11.489), train_loss = 1.22004674, grad/param norm = 2.0787e-01, time/batch = 0.6307s	
3827/16650 (epoch 11.492), train_loss = 1.30767557, grad/param norm = 2.3012e-01, time/batch = 0.6317s	
3828/16650 (epoch 11.495), train_loss = 1.19370030, grad/param norm = 2.7120e-01, time/batch = 0.6341s	
3829/16650 (epoch 11.498), train_loss = 1.30169756, grad/param norm = 2.7298e-01, time/batch = 0.6322s	
3830/16650 (epoch 11.502), train_loss = 1.53926278, grad/param norm = 2.5547e-01, time/batch = 0.6334s	
3831/16650 (epoch 11.505), train_loss = 1.36748285, grad/param norm = 2.1323e-01, time/batch = 0.6311s	
3832/16650 (epoch 11.508), train_loss = 1.35635106, grad/param norm = 2.2501e-01, time/batch = 0.6304s	
3833/16650 (epoch 11.511), train_loss = 1.45479940, grad/param norm = 2.5449e-01, time/batch = 0.6285s	
3834/16650 (epoch 11.514), train_loss = 1.15969714, grad/param norm = 2.2378e-01, time/batch = 0.6331s	
3835/16650 (epoch 11.517), train_loss = 1.27989426, grad/param norm = 2.4007e-01, time/batch = 0.6335s	
3836/16650 (epoch 11.520), train_loss = 1.28342032, grad/param norm = 2.2657e-01, time/batch = 0.6341s	
3837/16650 (epoch 11.523), train_loss = 1.21660353, grad/param norm = 2.1469e-01, time/batch = 0.6343s	
3838/16650 (epoch 11.526), train_loss = 1.34742709, grad/param norm = 2.2751e-01, time/batch = 0.6315s	
3839/16650 (epoch 11.529), train_loss = 1.49433964, grad/param norm = 2.5667e-01, time/batch = 0.6303s	
3840/16650 (epoch 11.532), train_loss = 1.08513837, grad/param norm = 2.1063e-01, time/batch = 0.6283s	
3841/16650 (epoch 11.535), train_loss = 1.14834368, grad/param norm = 2.2865e-01, time/batch = 0.6341s	
3842/16650 (epoch 11.538), train_loss = 1.20718279, grad/param norm = 2.3852e-01, time/batch = 0.6313s	
3843/16650 (epoch 11.541), train_loss = 1.43982179, grad/param norm = 2.7035e-01, time/batch = 0.6290s	
3844/16650 (epoch 11.544), train_loss = 1.49244777, grad/param norm = 2.5772e-01, time/batch = 0.6282s	
3845/16650 (epoch 11.547), train_loss = 1.16052938, grad/param norm = 2.1780e-01, time/batch = 0.6303s	
3846/16650 (epoch 11.550), train_loss = 1.22522258, grad/param norm = 2.3288e-01, time/batch = 0.6297s	
3847/16650 (epoch 11.553), train_loss = 1.28915236, grad/param norm = 2.4682e-01, time/batch = 0.6304s	
3848/16650 (epoch 11.556), train_loss = 1.18476221, grad/param norm = 2.0056e-01, time/batch = 0.6280s	
3849/16650 (epoch 11.559), train_loss = 1.05231699, grad/param norm = 1.9425e-01, time/batch = 0.6277s	
3850/16650 (epoch 11.562), train_loss = 1.25133736, grad/param norm = 2.1587e-01, time/batch = 0.6277s	
3851/16650 (epoch 11.565), train_loss = 1.02988446, grad/param norm = 2.1229e-01, time/batch = 0.6316s	
3852/16650 (epoch 11.568), train_loss = 1.05247325, grad/param norm = 1.9891e-01, time/batch = 0.6294s	
3853/16650 (epoch 11.571), train_loss = 1.11027703, grad/param norm = 2.1661e-01, time/batch = 0.6284s	
3854/16650 (epoch 11.574), train_loss = 1.24677975, grad/param norm = 2.3024e-01, time/batch = 0.6295s	
3855/16650 (epoch 11.577), train_loss = 1.17694338, grad/param norm = 2.0569e-01, time/batch = 0.6308s	
3856/16650 (epoch 11.580), train_loss = 1.11053955, grad/param norm = 2.2919e-01, time/batch = 0.6284s	
3857/16650 (epoch 11.583), train_loss = 1.20784368, grad/param norm = 2.2176e-01, time/batch = 0.6305s	
3858/16650 (epoch 11.586), train_loss = 1.23923592, grad/param norm = 2.4806e-01, time/batch = 0.6284s	
3859/16650 (epoch 11.589), train_loss = 1.06964105, grad/param norm = 1.9563e-01, time/batch = 0.6320s	
3860/16650 (epoch 11.592), train_loss = 1.28733979, grad/param norm = 2.5001e-01, time/batch = 0.6724s	
3861/16650 (epoch 11.595), train_loss = 1.14537509, grad/param norm = 2.2215e-01, time/batch = 0.6449s	
3862/16650 (epoch 11.598), train_loss = 1.19181035, grad/param norm = 2.4454e-01, time/batch = 0.6366s	
3863/16650 (epoch 11.601), train_loss = 1.18609154, grad/param norm = 2.5827e-01, time/batch = 0.6330s	
3864/16650 (epoch 11.604), train_loss = 1.34254290, grad/param norm = 2.4146e-01, time/batch = 0.6324s	
3865/16650 (epoch 11.607), train_loss = 1.29666501, grad/param norm = 2.4507e-01, time/batch = 0.6399s	
3866/16650 (epoch 11.610), train_loss = 1.15914685, grad/param norm = 2.1429e-01, time/batch = 0.6415s	
3867/16650 (epoch 11.613), train_loss = 1.40552518, grad/param norm = 2.4141e-01, time/batch = 0.6582s	
3868/16650 (epoch 11.616), train_loss = 1.43402910, grad/param norm = 2.6166e-01, time/batch = 0.6612s	
3869/16650 (epoch 11.619), train_loss = 1.11163752, grad/param norm = 2.1154e-01, time/batch = 0.6579s	
3870/16650 (epoch 11.622), train_loss = 1.04031180, grad/param norm = 2.1893e-01, time/batch = 0.6464s	
3871/16650 (epoch 11.625), train_loss = 1.19572984, grad/param norm = 2.2765e-01, time/batch = 0.6624s	
3872/16650 (epoch 11.628), train_loss = 1.23467984, grad/param norm = 2.5077e-01, time/batch = 0.6561s	
3873/16650 (epoch 11.631), train_loss = 1.26890012, grad/param norm = 2.6249e-01, time/batch = 0.6515s	
3874/16650 (epoch 11.634), train_loss = 1.52922703, grad/param norm = 2.5808e-01, time/batch = 0.6357s	
3875/16650 (epoch 11.637), train_loss = 1.51122022, grad/param norm = 2.5610e-01, time/batch = 0.6284s	
3876/16650 (epoch 11.640), train_loss = 1.19867368, grad/param norm = 2.2226e-01, time/batch = 0.6275s	
3877/16650 (epoch 11.643), train_loss = 1.35103430, grad/param norm = 2.3728e-01, time/batch = 0.6282s	
3878/16650 (epoch 11.646), train_loss = 1.36402015, grad/param norm = 2.6733e-01, time/batch = 0.6287s	
3879/16650 (epoch 11.649), train_loss = 1.30038997, grad/param norm = 2.3179e-01, time/batch = 0.6354s	
3880/16650 (epoch 11.652), train_loss = 1.41385950, grad/param norm = 2.3690e-01, time/batch = 0.6321s	
3881/16650 (epoch 11.655), train_loss = 1.30519143, grad/param norm = 2.3076e-01, time/batch = 0.6341s	
3882/16650 (epoch 11.658), train_loss = 1.16802266, grad/param norm = 2.1215e-01, time/batch = 0.6549s	
3883/16650 (epoch 11.661), train_loss = 1.36438884, grad/param norm = 2.3178e-01, time/batch = 0.6477s	
3884/16650 (epoch 11.664), train_loss = 1.27386169, grad/param norm = 2.3301e-01, time/batch = 0.6368s	
3885/16650 (epoch 11.667), train_loss = 1.43377043, grad/param norm = 2.4574e-01, time/batch = 0.6296s	
3886/16650 (epoch 11.670), train_loss = 1.12144256, grad/param norm = 2.1212e-01, time/batch = 0.6292s	
3887/16650 (epoch 11.673), train_loss = 1.16733112, grad/param norm = 2.0425e-01, time/batch = 0.6307s	
3888/16650 (epoch 11.676), train_loss = 1.26163283, grad/param norm = 2.3240e-01, time/batch = 0.6305s	
3889/16650 (epoch 11.679), train_loss = 1.15069494, grad/param norm = 2.2601e-01, time/batch = 0.6288s	
3890/16650 (epoch 11.682), train_loss = 1.33838067, grad/param norm = 2.3353e-01, time/batch = 0.6288s	
3891/16650 (epoch 11.685), train_loss = 1.10349074, grad/param norm = 2.2807e-01, time/batch = 0.6305s	
3892/16650 (epoch 11.688), train_loss = 1.27115979, grad/param norm = 2.3508e-01, time/batch = 0.6303s	
3893/16650 (epoch 11.691), train_loss = 1.30752494, grad/param norm = 2.3642e-01, time/batch = 0.6311s	
3894/16650 (epoch 11.694), train_loss = 1.11632941, grad/param norm = 2.0291e-01, time/batch = 0.6388s	
3895/16650 (epoch 11.697), train_loss = 1.12006039, grad/param norm = 2.0811e-01, time/batch = 0.6327s	
3896/16650 (epoch 11.700), train_loss = 1.36890053, grad/param norm = 2.3268e-01, time/batch = 0.6328s	
3897/16650 (epoch 11.703), train_loss = 1.15352724, grad/param norm = 2.2336e-01, time/batch = 0.6281s	
3898/16650 (epoch 11.706), train_loss = 1.37157295, grad/param norm = 2.5199e-01, time/batch = 0.6355s	
3899/16650 (epoch 11.709), train_loss = 1.17470494, grad/param norm = 2.1561e-01, time/batch = 0.6681s	
3900/16650 (epoch 11.712), train_loss = 1.17526766, grad/param norm = 2.4155e-01, time/batch = 0.6409s	
3901/16650 (epoch 11.715), train_loss = 1.40194538, grad/param norm = 2.2941e-01, time/batch = 0.6327s	
3902/16650 (epoch 11.718), train_loss = 1.44099845, grad/param norm = 2.5622e-01, time/batch = 0.6335s	
3903/16650 (epoch 11.721), train_loss = 1.39177139, grad/param norm = 2.4673e-01, time/batch = 0.6561s	
3904/16650 (epoch 11.724), train_loss = 1.41341535, grad/param norm = 2.5021e-01, time/batch = 0.6683s	
3905/16650 (epoch 11.727), train_loss = 1.33939298, grad/param norm = 2.1620e-01, time/batch = 0.6501s	
3906/16650 (epoch 11.730), train_loss = 1.23476816, grad/param norm = 2.1875e-01, time/batch = 0.6524s	
3907/16650 (epoch 11.733), train_loss = 1.41050639, grad/param norm = 2.4636e-01, time/batch = 0.6476s	
3908/16650 (epoch 11.736), train_loss = 1.11146054, grad/param norm = 2.1559e-01, time/batch = 0.6309s	
3909/16650 (epoch 11.739), train_loss = 1.27968750, grad/param norm = 2.3350e-01, time/batch = 0.6309s	
3910/16650 (epoch 11.742), train_loss = 1.30469820, grad/param norm = 2.6218e-01, time/batch = 0.6298s	
3911/16650 (epoch 11.745), train_loss = 1.07439953, grad/param norm = 2.0611e-01, time/batch = 0.6411s	
3912/16650 (epoch 11.748), train_loss = 1.15367315, grad/param norm = 2.4315e-01, time/batch = 0.6666s	
3913/16650 (epoch 11.751), train_loss = 1.32751790, grad/param norm = 2.5389e-01, time/batch = 0.6525s	
3914/16650 (epoch 11.754), train_loss = 1.45961587, grad/param norm = 2.4558e-01, time/batch = 0.6379s	
3915/16650 (epoch 11.757), train_loss = 1.37051957, grad/param norm = 2.3303e-01, time/batch = 0.6306s	
3916/16650 (epoch 11.760), train_loss = 1.24849072, grad/param norm = 2.5029e-01, time/batch = 0.6392s	
3917/16650 (epoch 11.763), train_loss = 1.17672216, grad/param norm = 2.3608e-01, time/batch = 0.6358s	
3918/16650 (epoch 11.766), train_loss = 1.29610808, grad/param norm = 2.1961e-01, time/batch = 0.6328s	
3919/16650 (epoch 11.769), train_loss = 1.26903183, grad/param norm = 2.2772e-01, time/batch = 0.6310s	
3920/16650 (epoch 11.772), train_loss = 1.18145665, grad/param norm = 2.0369e-01, time/batch = 0.6311s	
3921/16650 (epoch 11.775), train_loss = 1.26553479, grad/param norm = 2.2410e-01, time/batch = 0.6341s	
3922/16650 (epoch 11.778), train_loss = 1.22222553, grad/param norm = 2.2250e-01, time/batch = 0.6292s	
3923/16650 (epoch 11.781), train_loss = 1.35997469, grad/param norm = 2.3594e-01, time/batch = 0.6285s	
3924/16650 (epoch 11.784), train_loss = 1.35319721, grad/param norm = 2.4301e-01, time/batch = 0.6278s	
3925/16650 (epoch 11.787), train_loss = 1.37182485, grad/param norm = 2.3296e-01, time/batch = 0.6281s	
3926/16650 (epoch 11.790), train_loss = 1.27156510, grad/param norm = 2.2125e-01, time/batch = 0.6330s	
3927/16650 (epoch 11.793), train_loss = 1.15669061, grad/param norm = 2.6159e-01, time/batch = 0.6399s	
3928/16650 (epoch 11.796), train_loss = 1.64583741, grad/param norm = 2.6639e-01, time/batch = 0.6307s	
3929/16650 (epoch 11.799), train_loss = 1.49483670, grad/param norm = 2.3964e-01, time/batch = 0.6341s	
3930/16650 (epoch 11.802), train_loss = 1.32503907, grad/param norm = 2.5669e-01, time/batch = 0.6263s	
3931/16650 (epoch 11.805), train_loss = 1.28768364, grad/param norm = 2.1630e-01, time/batch = 0.6445s	
3932/16650 (epoch 11.808), train_loss = 1.28739215, grad/param norm = 2.2363e-01, time/batch = 0.6549s	
3933/16650 (epoch 11.811), train_loss = 1.43905348, grad/param norm = 2.4369e-01, time/batch = 0.6432s	
3934/16650 (epoch 11.814), train_loss = 1.15445627, grad/param norm = 2.2461e-01, time/batch = 0.6492s	
3935/16650 (epoch 11.817), train_loss = 1.26503799, grad/param norm = 2.5382e-01, time/batch = 0.6467s	
3936/16650 (epoch 11.820), train_loss = 1.33992666, grad/param norm = 2.5971e-01, time/batch = 0.6373s	
3937/16650 (epoch 11.823), train_loss = 1.17461862, grad/param norm = 2.2128e-01, time/batch = 0.6480s	
3938/16650 (epoch 11.826), train_loss = 1.28704232, grad/param norm = 2.1880e-01, time/batch = 0.6685s	
3939/16650 (epoch 11.829), train_loss = 1.42730603, grad/param norm = 2.4765e-01, time/batch = 0.6337s	
3940/16650 (epoch 11.832), train_loss = 1.43498069, grad/param norm = 2.4805e-01, time/batch = 0.6261s	
3941/16650 (epoch 11.835), train_loss = 1.41446378, grad/param norm = 2.7241e-01, time/batch = 0.6289s	
3942/16650 (epoch 11.838), train_loss = 1.17447027, grad/param norm = 2.3010e-01, time/batch = 0.6560s	
3943/16650 (epoch 11.841), train_loss = 1.17527185, grad/param norm = 2.0914e-01, time/batch = 0.6409s	
3944/16650 (epoch 11.844), train_loss = 1.20911688, grad/param norm = 2.2329e-01, time/batch = 0.6317s	
3945/16650 (epoch 11.847), train_loss = 1.37774864, grad/param norm = 2.3559e-01, time/batch = 0.6346s	
3946/16650 (epoch 11.850), train_loss = 1.14082908, grad/param norm = 2.3329e-01, time/batch = 0.6283s	
3947/16650 (epoch 11.853), train_loss = 1.31974449, grad/param norm = 2.4423e-01, time/batch = 0.6683s	
3948/16650 (epoch 11.856), train_loss = 1.16334353, grad/param norm = 2.2867e-01, time/batch = 0.6478s	
3949/16650 (epoch 11.859), train_loss = 1.36306045, grad/param norm = 2.4403e-01, time/batch = 0.6276s	
3950/16650 (epoch 11.862), train_loss = 1.26990778, grad/param norm = 2.2989e-01, time/batch = 0.6283s	
3951/16650 (epoch 11.865), train_loss = 1.04986247, grad/param norm = 1.9765e-01, time/batch = 0.6319s	
3952/16650 (epoch 11.868), train_loss = 1.36103614, grad/param norm = 2.5045e-01, time/batch = 0.6299s	
3953/16650 (epoch 11.871), train_loss = 1.37462968, grad/param norm = 2.4754e-01, time/batch = 0.6299s	
3954/16650 (epoch 11.874), train_loss = 1.35230553, grad/param norm = 2.3578e-01, time/batch = 0.6341s	
3955/16650 (epoch 11.877), train_loss = 1.20316087, grad/param norm = 2.2024e-01, time/batch = 0.6280s	
3956/16650 (epoch 11.880), train_loss = 1.23203090, grad/param norm = 2.6569e-01, time/batch = 0.6275s	
3957/16650 (epoch 11.883), train_loss = 1.33188990, grad/param norm = 2.3761e-01, time/batch = 0.6325s	
3958/16650 (epoch 11.886), train_loss = 1.31592521, grad/param norm = 2.5598e-01, time/batch = 0.6353s	
3959/16650 (epoch 11.889), train_loss = 1.16222459, grad/param norm = 2.2997e-01, time/batch = 0.6390s	
3960/16650 (epoch 11.892), train_loss = 1.23743905, grad/param norm = 2.2272e-01, time/batch = 0.6455s	
3961/16650 (epoch 11.895), train_loss = 1.37706893, grad/param norm = 2.3299e-01, time/batch = 0.6367s	
3962/16650 (epoch 11.898), train_loss = 1.35380496, grad/param norm = 2.3950e-01, time/batch = 0.6401s	
3963/16650 (epoch 11.901), train_loss = 1.29479801, grad/param norm = 2.0817e-01, time/batch = 0.6372s	
3964/16650 (epoch 11.904), train_loss = 1.21694651, grad/param norm = 2.4488e-01, time/batch = 0.6519s	
3965/16650 (epoch 11.907), train_loss = 1.33235171, grad/param norm = 2.3825e-01, time/batch = 0.6437s	
3966/16650 (epoch 11.910), train_loss = 1.32214154, grad/param norm = 2.3082e-01, time/batch = 0.6317s	
3967/16650 (epoch 11.913), train_loss = 1.22475333, grad/param norm = 2.2847e-01, time/batch = 0.6441s	
3968/16650 (epoch 11.916), train_loss = 1.33691908, grad/param norm = 2.4128e-01, time/batch = 0.6454s	
3969/16650 (epoch 11.919), train_loss = 1.47354658, grad/param norm = 2.5652e-01, time/batch = 0.6428s	
3970/16650 (epoch 11.922), train_loss = 1.43133077, grad/param norm = 2.4891e-01, time/batch = 0.6416s	
3971/16650 (epoch 11.925), train_loss = 1.23600502, grad/param norm = 2.9385e-01, time/batch = 0.6449s	
3972/16650 (epoch 11.928), train_loss = 1.23713057, grad/param norm = 2.2010e-01, time/batch = 0.6710s	
3973/16650 (epoch 11.931), train_loss = 1.33651486, grad/param norm = 2.4295e-01, time/batch = 0.6522s	
3974/16650 (epoch 11.934), train_loss = 1.14597270, grad/param norm = 2.2131e-01, time/batch = 0.6381s	
3975/16650 (epoch 11.937), train_loss = 1.29935578, grad/param norm = 3.2080e-01, time/batch = 0.6328s	
3976/16650 (epoch 11.940), train_loss = 1.21309051, grad/param norm = 2.0220e-01, time/batch = 0.6478s	
3977/16650 (epoch 11.943), train_loss = 1.26907132, grad/param norm = 2.3059e-01, time/batch = 0.6685s	
3978/16650 (epoch 11.946), train_loss = 1.22099551, grad/param norm = 2.4596e-01, time/batch = 0.6317s	
3979/16650 (epoch 11.949), train_loss = 1.20685119, grad/param norm = 2.5480e-01, time/batch = 0.6345s	
3980/16650 (epoch 11.952), train_loss = 1.02529799, grad/param norm = 2.2069e-01, time/batch = 0.6273s	
3981/16650 (epoch 11.955), train_loss = 1.21388810, grad/param norm = 2.1995e-01, time/batch = 0.6298s	
3982/16650 (epoch 11.958), train_loss = 1.36411750, grad/param norm = 2.5907e-01, time/batch = 0.6298s	
3983/16650 (epoch 11.961), train_loss = 1.20844711, grad/param norm = 2.1280e-01, time/batch = 0.6291s	
3984/16650 (epoch 11.964), train_loss = 1.18049794, grad/param norm = 2.3061e-01, time/batch = 0.6269s	
3985/16650 (epoch 11.967), train_loss = 1.43215645, grad/param norm = 2.4727e-01, time/batch = 0.6264s	
3986/16650 (epoch 11.970), train_loss = 1.11798411, grad/param norm = 2.1837e-01, time/batch = 0.6276s	
3987/16650 (epoch 11.973), train_loss = 1.22441329, grad/param norm = 2.6100e-01, time/batch = 0.6289s	
3988/16650 (epoch 11.976), train_loss = 1.17933648, grad/param norm = 2.3449e-01, time/batch = 0.6305s	
3989/16650 (epoch 11.979), train_loss = 1.32968870, grad/param norm = 2.2776e-01, time/batch = 0.6287s	
3990/16650 (epoch 11.982), train_loss = 1.34829040, grad/param norm = 2.3850e-01, time/batch = 0.6286s	
3991/16650 (epoch 11.985), train_loss = 1.22182175, grad/param norm = 2.2584e-01, time/batch = 0.6312s	
3992/16650 (epoch 11.988), train_loss = 1.49643752, grad/param norm = 2.6269e-01, time/batch = 0.6298s	
3993/16650 (epoch 11.991), train_loss = 1.18024170, grad/param norm = 2.7487e-01, time/batch = 0.6303s	
3994/16650 (epoch 11.994), train_loss = 1.22976017, grad/param norm = 2.2324e-01, time/batch = 0.6296s	
3995/16650 (epoch 11.997), train_loss = 1.32578553, grad/param norm = 2.4216e-01, time/batch = 0.6297s	
decayed learning rate by a factor 0.97 to 0.001825346	
3996/16650 (epoch 12.000), train_loss = 1.35727964, grad/param norm = 2.5945e-01, time/batch = 0.6349s	
3997/16650 (epoch 12.003), train_loss = 1.35853650, grad/param norm = 2.6698e-01, time/batch = 0.6391s	
3998/16650 (epoch 12.006), train_loss = 1.39587364, grad/param norm = 2.4166e-01, time/batch = 0.6426s	
3999/16650 (epoch 12.009), train_loss = 1.47081308, grad/param norm = 2.5067e-01, time/batch = 0.6662s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch12.01_1.7492.t7	
4000/16650 (epoch 12.012), train_loss = 1.53366509, grad/param norm = 2.6853e-01, time/batch = 0.6495s	
4001/16650 (epoch 12.015), train_loss = 1.44120383, grad/param norm = 2.8596e-01, time/batch = 0.6664s	
4002/16650 (epoch 12.018), train_loss = 1.04920974, grad/param norm = 2.3790e-01, time/batch = 0.6334s	
4003/16650 (epoch 12.021), train_loss = 1.41397458, grad/param norm = 2.4373e-01, time/batch = 0.6372s	
4004/16650 (epoch 12.024), train_loss = 1.22830669, grad/param norm = 2.3178e-01, time/batch = 0.6359s	
4005/16650 (epoch 12.027), train_loss = 1.41274896, grad/param norm = 2.4873e-01, time/batch = 0.6364s	
4006/16650 (epoch 12.030), train_loss = 1.13712688, grad/param norm = 2.1714e-01, time/batch = 0.6389s	
4007/16650 (epoch 12.033), train_loss = 1.27313099, grad/param norm = 2.2405e-01, time/batch = 0.6350s	
4008/16650 (epoch 12.036), train_loss = 1.08986339, grad/param norm = 2.3824e-01, time/batch = 0.6304s	
4009/16650 (epoch 12.039), train_loss = 1.37133522, grad/param norm = 2.3878e-01, time/batch = 0.6337s	
4010/16650 (epoch 12.042), train_loss = 1.38823837, grad/param norm = 2.3707e-01, time/batch = 0.6297s	
4011/16650 (epoch 12.045), train_loss = 1.27106201, grad/param norm = 2.3349e-01, time/batch = 0.6304s	
4012/16650 (epoch 12.048), train_loss = 1.36596991, grad/param norm = 2.4538e-01, time/batch = 0.6372s	
4013/16650 (epoch 12.051), train_loss = 1.31190405, grad/param norm = 2.5659e-01, time/batch = 0.6378s	
4014/16650 (epoch 12.054), train_loss = 1.32436932, grad/param norm = 2.4733e-01, time/batch = 0.6414s	
4015/16650 (epoch 12.057), train_loss = 1.27160032, grad/param norm = 2.3545e-01, time/batch = 0.6373s	
4016/16650 (epoch 12.060), train_loss = 1.15630104, grad/param norm = 2.2274e-01, time/batch = 0.6341s	
4017/16650 (epoch 12.063), train_loss = 1.25050840, grad/param norm = 2.2734e-01, time/batch = 0.6306s	
4018/16650 (epoch 12.066), train_loss = 1.46561268, grad/param norm = 2.3952e-01, time/batch = 0.6354s	
4019/16650 (epoch 12.069), train_loss = 1.39624298, grad/param norm = 2.5613e-01, time/batch = 0.6287s	
4020/16650 (epoch 12.072), train_loss = 1.23984554, grad/param norm = 2.4431e-01, time/batch = 0.6603s	
4021/16650 (epoch 12.075), train_loss = 1.31334340, grad/param norm = 2.3521e-01, time/batch = 0.6601s	
4022/16650 (epoch 12.078), train_loss = 1.38220793, grad/param norm = 2.2730e-01, time/batch = 0.6298s	
4023/16650 (epoch 12.081), train_loss = 1.25930914, grad/param norm = 2.4281e-01, time/batch = 0.6316s	
4024/16650 (epoch 12.084), train_loss = 1.35009334, grad/param norm = 2.3034e-01, time/batch = 0.6407s	
4025/16650 (epoch 12.087), train_loss = 1.26626091, grad/param norm = 2.4409e-01, time/batch = 0.6701s	
4026/16650 (epoch 12.090), train_loss = 1.20558372, grad/param norm = 2.1884e-01, time/batch = 0.6423s	
4027/16650 (epoch 12.093), train_loss = 1.54503687, grad/param norm = 2.4631e-01, time/batch = 0.6294s	
4028/16650 (epoch 12.096), train_loss = 1.26734865, grad/param norm = 2.2601e-01, time/batch = 0.6321s	
4029/16650 (epoch 12.099), train_loss = 1.25941343, grad/param norm = 2.2137e-01, time/batch = 0.6520s	
4030/16650 (epoch 12.102), train_loss = 1.31931483, grad/param norm = 2.5038e-01, time/batch = 0.6689s	
4031/16650 (epoch 12.105), train_loss = 1.36874577, grad/param norm = 2.4165e-01, time/batch = 0.6398s	
4032/16650 (epoch 12.108), train_loss = 1.37337339, grad/param norm = 2.5616e-01, time/batch = 0.6336s	
4033/16650 (epoch 12.111), train_loss = 1.34749533, grad/param norm = 2.3154e-01, time/batch = 0.6279s	
4034/16650 (epoch 12.114), train_loss = 1.44728114, grad/param norm = 2.4547e-01, time/batch = 0.6289s	
4035/16650 (epoch 12.117), train_loss = 1.44039163, grad/param norm = 2.4378e-01, time/batch = 0.6292s	
4036/16650 (epoch 12.120), train_loss = 1.17830274, grad/param norm = 2.2128e-01, time/batch = 0.6286s	
4037/16650 (epoch 12.123), train_loss = 1.28037735, grad/param norm = 2.3535e-01, time/batch = 0.6286s	
4038/16650 (epoch 12.126), train_loss = 1.29300832, grad/param norm = 2.5375e-01, time/batch = 0.6300s	
4039/16650 (epoch 12.129), train_loss = 1.33500330, grad/param norm = 2.2588e-01, time/batch = 0.6294s	
4040/16650 (epoch 12.132), train_loss = 1.36515242, grad/param norm = 2.3925e-01, time/batch = 0.6320s	
4041/16650 (epoch 12.135), train_loss = 1.35009114, grad/param norm = 2.3389e-01, time/batch = 0.6336s	
4042/16650 (epoch 12.138), train_loss = 1.36972821, grad/param norm = 2.2037e-01, time/batch = 0.6295s	
4043/16650 (epoch 12.141), train_loss = 1.39006383, grad/param norm = 2.6385e-01, time/batch = 0.6319s	
4044/16650 (epoch 12.144), train_loss = 1.28957616, grad/param norm = 2.3801e-01, time/batch = 0.6313s	
4045/16650 (epoch 12.147), train_loss = 1.46543262, grad/param norm = 2.3937e-01, time/batch = 0.6520s	
4046/16650 (epoch 12.150), train_loss = 1.55344920, grad/param norm = 2.5463e-01, time/batch = 0.6416s	
4047/16650 (epoch 12.153), train_loss = 1.31905860, grad/param norm = 2.4151e-01, time/batch = 0.6402s	
4048/16650 (epoch 12.156), train_loss = 1.13446296, grad/param norm = 2.1579e-01, time/batch = 0.6347s	
4049/16650 (epoch 12.159), train_loss = 1.42469939, grad/param norm = 2.4851e-01, time/batch = 0.6326s	
4050/16650 (epoch 12.162), train_loss = 1.42748109, grad/param norm = 2.2917e-01, time/batch = 0.6282s	
4051/16650 (epoch 12.165), train_loss = 1.39828032, grad/param norm = 2.4089e-01, time/batch = 0.6331s	
4052/16650 (epoch 12.168), train_loss = 1.04600490, grad/param norm = 2.0820e-01, time/batch = 0.6346s	
4053/16650 (epoch 12.171), train_loss = 1.40199751, grad/param norm = 2.2302e-01, time/batch = 0.6371s	
4054/16650 (epoch 12.174), train_loss = 1.12373231, grad/param norm = 2.3229e-01, time/batch = 0.6410s	
4055/16650 (epoch 12.177), train_loss = 1.29498260, grad/param norm = 2.3623e-01, time/batch = 0.6295s	
4056/16650 (epoch 12.180), train_loss = 1.44296724, grad/param norm = 2.4901e-01, time/batch = 0.6315s	
4057/16650 (epoch 12.183), train_loss = 1.57231234, grad/param norm = 2.6443e-01, time/batch = 0.6358s	
4058/16650 (epoch 12.186), train_loss = 1.40108920, grad/param norm = 2.3661e-01, time/batch = 0.6309s	
4059/16650 (epoch 12.189), train_loss = 1.17247714, grad/param norm = 1.9840e-01, time/batch = 0.6316s	
4060/16650 (epoch 12.192), train_loss = 1.23311790, grad/param norm = 2.5128e-01, time/batch = 0.6308s	
4061/16650 (epoch 12.195), train_loss = 1.30711583, grad/param norm = 2.4005e-01, time/batch = 0.6319s	
4062/16650 (epoch 12.198), train_loss = 1.07078220, grad/param norm = 2.0691e-01, time/batch = 0.6315s	
4063/16650 (epoch 12.201), train_loss = 1.23656158, grad/param norm = 2.3530e-01, time/batch = 0.6308s	
4064/16650 (epoch 12.204), train_loss = 1.31661801, grad/param norm = 2.6806e-01, time/batch = 0.6319s	
4065/16650 (epoch 12.207), train_loss = 1.36829898, grad/param norm = 2.6378e-01, time/batch = 0.6340s	
4066/16650 (epoch 12.210), train_loss = 1.24158482, grad/param norm = 2.3101e-01, time/batch = 0.6338s	
4067/16650 (epoch 12.213), train_loss = 1.35703944, grad/param norm = 2.3277e-01, time/batch = 0.6402s	
4068/16650 (epoch 12.216), train_loss = 1.24769402, grad/param norm = 2.2803e-01, time/batch = 0.6348s	
4069/16650 (epoch 12.219), train_loss = 1.28964342, grad/param norm = 2.3419e-01, time/batch = 0.6314s	
4070/16650 (epoch 12.222), train_loss = 1.28874714, grad/param norm = 2.2568e-01, time/batch = 0.6305s	
4071/16650 (epoch 12.225), train_loss = 1.28818720, grad/param norm = 2.1734e-01, time/batch = 0.6318s	
4072/16650 (epoch 12.228), train_loss = 1.21005255, grad/param norm = 2.2429e-01, time/batch = 0.6310s	
4073/16650 (epoch 12.231), train_loss = 1.27012104, grad/param norm = 2.3040e-01, time/batch = 0.6307s	
4074/16650 (epoch 12.234), train_loss = 1.44294219, grad/param norm = 2.5303e-01, time/batch = 0.6332s	
4075/16650 (epoch 12.237), train_loss = 1.30106503, grad/param norm = 2.3203e-01, time/batch = 0.6348s	
4076/16650 (epoch 12.240), train_loss = 1.33313287, grad/param norm = 2.5776e-01, time/batch = 0.6346s	
4077/16650 (epoch 12.243), train_loss = 1.32332087, grad/param norm = 2.3458e-01, time/batch = 0.6288s	
4078/16650 (epoch 12.246), train_loss = 1.43206099, grad/param norm = 2.5645e-01, time/batch = 0.6290s	
4079/16650 (epoch 12.249), train_loss = 1.17513202, grad/param norm = 2.5379e-01, time/batch = 0.6282s	
4080/16650 (epoch 12.252), train_loss = 1.27883333, grad/param norm = 2.3106e-01, time/batch = 0.6291s	
4081/16650 (epoch 12.255), train_loss = 1.41767405, grad/param norm = 2.5085e-01, time/batch = 0.6341s	
4082/16650 (epoch 12.258), train_loss = 1.41962503, grad/param norm = 2.4221e-01, time/batch = 0.6318s	
4083/16650 (epoch 12.261), train_loss = 1.30237465, grad/param norm = 2.3608e-01, time/batch = 0.6316s	
4084/16650 (epoch 12.264), train_loss = 1.25568518, grad/param norm = 2.5980e-01, time/batch = 0.6321s	
4085/16650 (epoch 12.267), train_loss = 1.23077953, grad/param norm = 2.3014e-01, time/batch = 0.6324s	
4086/16650 (epoch 12.270), train_loss = 1.28233140, grad/param norm = 2.2202e-01, time/batch = 0.6448s	
4087/16650 (epoch 12.273), train_loss = 1.40381008, grad/param norm = 2.1662e-01, time/batch = 0.6609s	
4088/16650 (epoch 12.276), train_loss = 1.29712828, grad/param norm = 2.1399e-01, time/batch = 0.6703s	
4089/16650 (epoch 12.279), train_loss = 1.27787479, grad/param norm = 2.2076e-01, time/batch = 0.6377s	
4090/16650 (epoch 12.282), train_loss = 1.14525031, grad/param norm = 2.1176e-01, time/batch = 0.6338s	
4091/16650 (epoch 12.285), train_loss = 1.15352127, grad/param norm = 2.1613e-01, time/batch = 0.6392s	
4092/16650 (epoch 12.288), train_loss = 1.22477386, grad/param norm = 2.3251e-01, time/batch = 0.6707s	
4093/16650 (epoch 12.291), train_loss = 1.02611926, grad/param norm = 2.0735e-01, time/batch = 0.6555s	
4094/16650 (epoch 12.294), train_loss = 1.10347185, grad/param norm = 1.8589e-01, time/batch = 0.6346s	
4095/16650 (epoch 12.297), train_loss = 1.20686948, grad/param norm = 2.2462e-01, time/batch = 0.6295s	
4096/16650 (epoch 12.300), train_loss = 1.03654908, grad/param norm = 2.0796e-01, time/batch = 0.6303s	
4097/16650 (epoch 12.303), train_loss = 1.08295795, grad/param norm = 1.8461e-01, time/batch = 0.6302s	
4098/16650 (epoch 12.306), train_loss = 1.33161595, grad/param norm = 2.2058e-01, time/batch = 0.6301s	
4099/16650 (epoch 12.309), train_loss = 1.39884827, grad/param norm = 2.4238e-01, time/batch = 0.6370s	
4100/16650 (epoch 12.312), train_loss = 1.16581068, grad/param norm = 2.3762e-01, time/batch = 0.6281s	
4101/16650 (epoch 12.315), train_loss = 0.94912417, grad/param norm = 1.7756e-01, time/batch = 0.6322s	
4102/16650 (epoch 12.318), train_loss = 1.04228157, grad/param norm = 2.1512e-01, time/batch = 0.6367s	
4103/16650 (epoch 12.321), train_loss = 1.45527104, grad/param norm = 2.5777e-01, time/batch = 0.6317s	
4104/16650 (epoch 12.324), train_loss = 1.21720396, grad/param norm = 2.4704e-01, time/batch = 0.6300s	
4105/16650 (epoch 12.327), train_loss = 1.41874799, grad/param norm = 2.5982e-01, time/batch = 0.6274s	
4106/16650 (epoch 12.330), train_loss = 1.33037989, grad/param norm = 2.3298e-01, time/batch = 0.6283s	
4107/16650 (epoch 12.333), train_loss = 1.36183412, grad/param norm = 2.6230e-01, time/batch = 0.6351s	
4108/16650 (epoch 12.336), train_loss = 1.14707516, grad/param norm = 2.2177e-01, time/batch = 0.6325s	
4109/16650 (epoch 12.339), train_loss = 1.25245057, grad/param norm = 2.2507e-01, time/batch = 0.6344s	
4110/16650 (epoch 12.342), train_loss = 1.22657498, grad/param norm = 2.4257e-01, time/batch = 0.6313s	
4111/16650 (epoch 12.345), train_loss = 1.11158659, grad/param norm = 2.1509e-01, time/batch = 0.6401s	
4112/16650 (epoch 12.348), train_loss = 1.28873433, grad/param norm = 2.2388e-01, time/batch = 0.6351s	
4113/16650 (epoch 12.351), train_loss = 1.35964205, grad/param norm = 2.4105e-01, time/batch = 0.6292s	
4114/16650 (epoch 12.354), train_loss = 1.43267539, grad/param norm = 2.6752e-01, time/batch = 0.6297s	
4115/16650 (epoch 12.357), train_loss = 1.33562041, grad/param norm = 2.5848e-01, time/batch = 0.6289s	
4116/16650 (epoch 12.360), train_loss = 1.33532918, grad/param norm = 2.3581e-01, time/batch = 0.6310s	
4117/16650 (epoch 12.363), train_loss = 1.42659919, grad/param norm = 2.6188e-01, time/batch = 0.6310s	
4118/16650 (epoch 12.366), train_loss = 1.50047137, grad/param norm = 2.6560e-01, time/batch = 0.6291s	
4119/16650 (epoch 12.369), train_loss = 1.28157157, grad/param norm = 2.2769e-01, time/batch = 0.6279s	
4120/16650 (epoch 12.372), train_loss = 1.27986354, grad/param norm = 2.2496e-01, time/batch = 0.6280s	
4121/16650 (epoch 12.375), train_loss = 1.26863044, grad/param norm = 2.3090e-01, time/batch = 0.6304s	
4122/16650 (epoch 12.378), train_loss = 1.13545877, grad/param norm = 2.1220e-01, time/batch = 0.6354s	
4123/16650 (epoch 12.381), train_loss = 1.33010330, grad/param norm = 2.3970e-01, time/batch = 0.6345s	
4124/16650 (epoch 12.384), train_loss = 1.41509355, grad/param norm = 2.3586e-01, time/batch = 0.6411s	
4125/16650 (epoch 12.387), train_loss = 1.02880434, grad/param norm = 2.0789e-01, time/batch = 0.6331s	
4126/16650 (epoch 12.390), train_loss = 1.35316430, grad/param norm = 2.4533e-01, time/batch = 0.6332s	
4127/16650 (epoch 12.393), train_loss = 1.29216886, grad/param norm = 2.4994e-01, time/batch = 0.6331s	
4128/16650 (epoch 12.396), train_loss = 1.45082589, grad/param norm = 2.5774e-01, time/batch = 0.6296s	
4129/16650 (epoch 12.399), train_loss = 1.35032724, grad/param norm = 2.5324e-01, time/batch = 0.6310s	
4130/16650 (epoch 12.402), train_loss = 1.16599406, grad/param norm = 2.1955e-01, time/batch = 0.6367s	
4131/16650 (epoch 12.405), train_loss = 1.11842399, grad/param norm = 2.2513e-01, time/batch = 0.6407s	
4132/16650 (epoch 12.408), train_loss = 1.41927312, grad/param norm = 2.4026e-01, time/batch = 0.6382s	
4133/16650 (epoch 12.411), train_loss = 1.15625746, grad/param norm = 2.4587e-01, time/batch = 0.6360s	
4134/16650 (epoch 12.414), train_loss = 1.13873334, grad/param norm = 2.3984e-01, time/batch = 0.6309s	
4135/16650 (epoch 12.417), train_loss = 1.09963219, grad/param norm = 1.9861e-01, time/batch = 0.6319s	
4136/16650 (epoch 12.420), train_loss = 1.10554402, grad/param norm = 2.4623e-01, time/batch = 0.6360s	
4137/16650 (epoch 12.423), train_loss = 0.90071505, grad/param norm = 1.8822e-01, time/batch = 0.6333s	
4138/16650 (epoch 12.426), train_loss = 1.14678153, grad/param norm = 2.5477e-01, time/batch = 0.6319s	
4139/16650 (epoch 12.429), train_loss = 1.37760498, grad/param norm = 2.4390e-01, time/batch = 0.6294s	
4140/16650 (epoch 12.432), train_loss = 1.34147447, grad/param norm = 2.4424e-01, time/batch = 0.6285s	
4141/16650 (epoch 12.435), train_loss = 1.50732387, grad/param norm = 2.4034e-01, time/batch = 0.6338s	
4142/16650 (epoch 12.438), train_loss = 1.46683893, grad/param norm = 2.5884e-01, time/batch = 0.6333s	
4143/16650 (epoch 12.441), train_loss = 1.32093303, grad/param norm = 2.5834e-01, time/batch = 0.6316s	
4144/16650 (epoch 12.444), train_loss = 1.21157540, grad/param norm = 2.3235e-01, time/batch = 0.6276s	
4145/16650 (epoch 12.447), train_loss = 1.23702288, grad/param norm = 2.1102e-01, time/batch = 0.6297s	
4146/16650 (epoch 12.450), train_loss = 1.15597916, grad/param norm = 2.3270e-01, time/batch = 0.6278s	
4147/16650 (epoch 12.453), train_loss = 1.18619464, grad/param norm = 2.1450e-01, time/batch = 0.6270s	
4148/16650 (epoch 12.456), train_loss = 1.10032802, grad/param norm = 2.0736e-01, time/batch = 0.6303s	
4149/16650 (epoch 12.459), train_loss = 1.18269218, grad/param norm = 2.3566e-01, time/batch = 0.6308s	
4150/16650 (epoch 12.462), train_loss = 1.46975832, grad/param norm = 2.6064e-01, time/batch = 0.6573s	
4151/16650 (epoch 12.465), train_loss = 1.21864791, grad/param norm = 2.3831e-01, time/batch = 0.6620s	
4152/16650 (epoch 12.468), train_loss = 0.96438870, grad/param norm = 2.1033e-01, time/batch = 0.6296s	
4153/16650 (epoch 12.471), train_loss = 0.87394961, grad/param norm = 2.0169e-01, time/batch = 0.6297s	
4154/16650 (epoch 12.474), train_loss = 1.10346736, grad/param norm = 2.0088e-01, time/batch = 0.6395s	
4155/16650 (epoch 12.477), train_loss = 1.28102991, grad/param norm = 2.3738e-01, time/batch = 0.6693s	
4156/16650 (epoch 12.480), train_loss = 1.30961820, grad/param norm = 2.5343e-01, time/batch = 0.6446s	
4157/16650 (epoch 12.483), train_loss = 1.44380034, grad/param norm = 2.2901e-01, time/batch = 0.6282s	
4158/16650 (epoch 12.486), train_loss = 1.14160083, grad/param norm = 2.2336e-01, time/batch = 0.6266s	
4159/16650 (epoch 12.489), train_loss = 1.18272649, grad/param norm = 2.1925e-01, time/batch = 0.6296s	
4160/16650 (epoch 12.492), train_loss = 1.26547645, grad/param norm = 2.3267e-01, time/batch = 0.6324s	
4161/16650 (epoch 12.495), train_loss = 1.15036260, grad/param norm = 2.6204e-01, time/batch = 0.6343s	
4162/16650 (epoch 12.498), train_loss = 1.24769832, grad/param norm = 2.4700e-01, time/batch = 0.6456s	
4163/16650 (epoch 12.502), train_loss = 1.48995699, grad/param norm = 2.5997e-01, time/batch = 0.6387s	
4164/16650 (epoch 12.505), train_loss = 1.33443593, grad/param norm = 2.1566e-01, time/batch = 0.6413s	
4165/16650 (epoch 12.508), train_loss = 1.31260800, grad/param norm = 2.2589e-01, time/batch = 0.6428s	
4166/16650 (epoch 12.511), train_loss = 1.40212949, grad/param norm = 2.4998e-01, time/batch = 0.6412s	
4167/16650 (epoch 12.514), train_loss = 1.11782292, grad/param norm = 2.2518e-01, time/batch = 0.6418s	
4168/16650 (epoch 12.517), train_loss = 1.23971776, grad/param norm = 2.3974e-01, time/batch = 0.6321s	
4169/16650 (epoch 12.520), train_loss = 1.23623203, grad/param norm = 2.2700e-01, time/batch = 0.6280s	
4170/16650 (epoch 12.523), train_loss = 1.17735807, grad/param norm = 2.1600e-01, time/batch = 0.6276s	
4171/16650 (epoch 12.526), train_loss = 1.30858568, grad/param norm = 2.2470e-01, time/batch = 0.6317s	
4172/16650 (epoch 12.529), train_loss = 1.45110254, grad/param norm = 2.5827e-01, time/batch = 0.6293s	
4173/16650 (epoch 12.532), train_loss = 1.03020243, grad/param norm = 2.0684e-01, time/batch = 0.6295s	
4174/16650 (epoch 12.535), train_loss = 1.10411401, grad/param norm = 2.2967e-01, time/batch = 0.6306s	
4175/16650 (epoch 12.538), train_loss = 1.14970668, grad/param norm = 2.3885e-01, time/batch = 0.6308s	
4176/16650 (epoch 12.541), train_loss = 1.38795697, grad/param norm = 2.4649e-01, time/batch = 0.6322s	
4177/16650 (epoch 12.544), train_loss = 1.44073209, grad/param norm = 2.6750e-01, time/batch = 0.6369s	
4178/16650 (epoch 12.547), train_loss = 1.13803378, grad/param norm = 2.2884e-01, time/batch = 0.6366s	
4179/16650 (epoch 12.550), train_loss = 1.18203372, grad/param norm = 2.3493e-01, time/batch = 0.6370s	
4180/16650 (epoch 12.553), train_loss = 1.24027899, grad/param norm = 2.4619e-01, time/batch = 0.6402s	
4181/16650 (epoch 12.556), train_loss = 1.15341110, grad/param norm = 2.0244e-01, time/batch = 0.6644s	
4182/16650 (epoch 12.559), train_loss = 1.01424784, grad/param norm = 1.8875e-01, time/batch = 0.6595s	
4183/16650 (epoch 12.562), train_loss = 1.21146210, grad/param norm = 2.2520e-01, time/batch = 0.6663s	
4184/16650 (epoch 12.565), train_loss = 0.98735176, grad/param norm = 2.0989e-01, time/batch = 0.6371s	
4185/16650 (epoch 12.568), train_loss = 1.01571745, grad/param norm = 1.9874e-01, time/batch = 0.6425s	
4186/16650 (epoch 12.571), train_loss = 1.06662248, grad/param norm = 2.1892e-01, time/batch = 0.6394s	
4187/16650 (epoch 12.574), train_loss = 1.19510562, grad/param norm = 2.2410e-01, time/batch = 0.6363s	
4188/16650 (epoch 12.577), train_loss = 1.14280537, grad/param norm = 2.0572e-01, time/batch = 0.6376s	
4189/16650 (epoch 12.580), train_loss = 1.06467334, grad/param norm = 2.2516e-01, time/batch = 0.6390s	
4190/16650 (epoch 12.583), train_loss = 1.17654557, grad/param norm = 2.2289e-01, time/batch = 0.6440s	
4191/16650 (epoch 12.586), train_loss = 1.18907944, grad/param norm = 2.5305e-01, time/batch = 0.6438s	
4192/16650 (epoch 12.589), train_loss = 1.04262242, grad/param norm = 2.0035e-01, time/batch = 0.6504s	
4193/16650 (epoch 12.592), train_loss = 1.23683261, grad/param norm = 2.3986e-01, time/batch = 0.6431s	
4194/16650 (epoch 12.595), train_loss = 1.10258243, grad/param norm = 2.2218e-01, time/batch = 0.6691s	
4195/16650 (epoch 12.598), train_loss = 1.15359821, grad/param norm = 2.4478e-01, time/batch = 0.6496s	
4196/16650 (epoch 12.601), train_loss = 1.14605880, grad/param norm = 2.6550e-01, time/batch = 0.6471s	
4197/16650 (epoch 12.604), train_loss = 1.30624356, grad/param norm = 2.4221e-01, time/batch = 0.6426s	
4198/16650 (epoch 12.607), train_loss = 1.25842047, grad/param norm = 2.3904e-01, time/batch = 0.6364s	
4199/16650 (epoch 12.610), train_loss = 1.10742292, grad/param norm = 2.0280e-01, time/batch = 0.6528s	
4200/16650 (epoch 12.613), train_loss = 1.35005391, grad/param norm = 2.3737e-01, time/batch = 0.6443s	
4201/16650 (epoch 12.616), train_loss = 1.38163289, grad/param norm = 2.5702e-01, time/batch = 0.6462s	
4202/16650 (epoch 12.619), train_loss = 1.06373862, grad/param norm = 2.1195e-01, time/batch = 0.6499s	
4203/16650 (epoch 12.622), train_loss = 1.00134744, grad/param norm = 2.1070e-01, time/batch = 0.6413s	
4204/16650 (epoch 12.625), train_loss = 1.15416104, grad/param norm = 2.2450e-01, time/batch = 0.6415s	
4205/16650 (epoch 12.628), train_loss = 1.19437066, grad/param norm = 2.5414e-01, time/batch = 0.6411s	
4206/16650 (epoch 12.631), train_loss = 1.23257708, grad/param norm = 2.7401e-01, time/batch = 0.6351s	
4207/16650 (epoch 12.634), train_loss = 1.49345778, grad/param norm = 2.6931e-01, time/batch = 0.6369s	
4208/16650 (epoch 12.637), train_loss = 1.46235440, grad/param norm = 2.4918e-01, time/batch = 0.6308s	
4209/16650 (epoch 12.640), train_loss = 1.15490561, grad/param norm = 2.2555e-01, time/batch = 0.6342s	
4210/16650 (epoch 12.643), train_loss = 1.31390316, grad/param norm = 2.3374e-01, time/batch = 0.6312s	
4211/16650 (epoch 12.646), train_loss = 1.30561787, grad/param norm = 2.5918e-01, time/batch = 0.6399s	
4212/16650 (epoch 12.649), train_loss = 1.25796858, grad/param norm = 2.3100e-01, time/batch = 0.6288s	
4213/16650 (epoch 12.652), train_loss = 1.37262658, grad/param norm = 2.4263e-01, time/batch = 0.6326s	
4214/16650 (epoch 12.655), train_loss = 1.25303256, grad/param norm = 2.2317e-01, time/batch = 0.6332s	
4215/16650 (epoch 12.658), train_loss = 1.13148235, grad/param norm = 2.1647e-01, time/batch = 0.6304s	
4216/16650 (epoch 12.661), train_loss = 1.32038496, grad/param norm = 2.3312e-01, time/batch = 0.6313s	
4217/16650 (epoch 12.664), train_loss = 1.23489268, grad/param norm = 2.3060e-01, time/batch = 0.6299s	
4218/16650 (epoch 12.667), train_loss = 1.37782823, grad/param norm = 2.3502e-01, time/batch = 0.6313s	
4219/16650 (epoch 12.670), train_loss = 1.08373654, grad/param norm = 2.1888e-01, time/batch = 0.6297s	
4220/16650 (epoch 12.673), train_loss = 1.13336851, grad/param norm = 2.0198e-01, time/batch = 0.6296s	
4221/16650 (epoch 12.676), train_loss = 1.22799024, grad/param norm = 2.4158e-01, time/batch = 0.6323s	
4222/16650 (epoch 12.679), train_loss = 1.10525311, grad/param norm = 2.2947e-01, time/batch = 0.6334s	
4223/16650 (epoch 12.682), train_loss = 1.28844502, grad/param norm = 2.2369e-01, time/batch = 0.6317s	
4224/16650 (epoch 12.685), train_loss = 1.06629618, grad/param norm = 2.3353e-01, time/batch = 0.6303s	
4225/16650 (epoch 12.688), train_loss = 1.23339966, grad/param norm = 2.3211e-01, time/batch = 0.6308s	
4226/16650 (epoch 12.691), train_loss = 1.26050197, grad/param norm = 2.3405e-01, time/batch = 0.6356s	
4227/16650 (epoch 12.694), train_loss = 1.07571697, grad/param norm = 2.0555e-01, time/batch = 0.6436s	
4228/16650 (epoch 12.697), train_loss = 1.08414331, grad/param norm = 2.0855e-01, time/batch = 0.6296s	
4229/16650 (epoch 12.700), train_loss = 1.32071525, grad/param norm = 2.3396e-01, time/batch = 0.6321s	
4230/16650 (epoch 12.703), train_loss = 1.10740398, grad/param norm = 2.1787e-01, time/batch = 0.6328s	
4231/16650 (epoch 12.706), train_loss = 1.32466565, grad/param norm = 2.4137e-01, time/batch = 0.6322s	
4232/16650 (epoch 12.709), train_loss = 1.13483333, grad/param norm = 2.1559e-01, time/batch = 0.6333s	
4233/16650 (epoch 12.712), train_loss = 1.13093337, grad/param norm = 2.5197e-01, time/batch = 0.6373s	
4234/16650 (epoch 12.715), train_loss = 1.36625032, grad/param norm = 2.2958e-01, time/batch = 0.6333s	
4235/16650 (epoch 12.718), train_loss = 1.39334017, grad/param norm = 2.4762e-01, time/batch = 0.6378s	
4236/16650 (epoch 12.721), train_loss = 1.34891857, grad/param norm = 2.4193e-01, time/batch = 0.6426s	
4237/16650 (epoch 12.724), train_loss = 1.37002460, grad/param norm = 2.5450e-01, time/batch = 0.6521s	
4238/16650 (epoch 12.727), train_loss = 1.30044060, grad/param norm = 2.1812e-01, time/batch = 0.6687s	
4239/16650 (epoch 12.730), train_loss = 1.19577833, grad/param norm = 2.2073e-01, time/batch = 0.6327s	
4240/16650 (epoch 12.733), train_loss = 1.35344253, grad/param norm = 2.3612e-01, time/batch = 0.6319s	
4241/16650 (epoch 12.736), train_loss = 1.06610797, grad/param norm = 2.1613e-01, time/batch = 0.6340s	
4242/16650 (epoch 12.739), train_loss = 1.24033509, grad/param norm = 2.3862e-01, time/batch = 0.6635s	
4243/16650 (epoch 12.742), train_loss = 1.26519706, grad/param norm = 2.6169e-01, time/batch = 0.6552s	
4244/16650 (epoch 12.745), train_loss = 1.03330846, grad/param norm = 2.0666e-01, time/batch = 0.6312s	
4245/16650 (epoch 12.748), train_loss = 1.10914616, grad/param norm = 2.4158e-01, time/batch = 0.6296s	
4246/16650 (epoch 12.751), train_loss = 1.28644220, grad/param norm = 2.5809e-01, time/batch = 0.6324s	
4247/16650 (epoch 12.754), train_loss = 1.42237656, grad/param norm = 2.7514e-01, time/batch = 0.6336s	
4248/16650 (epoch 12.757), train_loss = 1.33249186, grad/param norm = 2.4170e-01, time/batch = 0.6291s	
4249/16650 (epoch 12.760), train_loss = 1.21070121, grad/param norm = 2.5174e-01, time/batch = 0.6275s	
4250/16650 (epoch 12.763), train_loss = 1.13868318, grad/param norm = 2.3698e-01, time/batch = 0.6313s	
4251/16650 (epoch 12.766), train_loss = 1.24697861, grad/param norm = 2.1557e-01, time/batch = 0.6358s	
4252/16650 (epoch 12.769), train_loss = 1.23372756, grad/param norm = 2.3065e-01, time/batch = 0.6387s	
4253/16650 (epoch 12.772), train_loss = 1.14684652, grad/param norm = 2.0428e-01, time/batch = 0.6308s	
4254/16650 (epoch 12.775), train_loss = 1.21830418, grad/param norm = 2.2626e-01, time/batch = 0.6341s	
4255/16650 (epoch 12.778), train_loss = 1.20213584, grad/param norm = 2.2449e-01, time/batch = 0.6314s	
4256/16650 (epoch 12.781), train_loss = 1.32071489, grad/param norm = 2.3518e-01, time/batch = 0.6298s	
4257/16650 (epoch 12.784), train_loss = 1.31928584, grad/param norm = 2.5101e-01, time/batch = 0.6302s	
4258/16650 (epoch 12.787), train_loss = 1.33118022, grad/param norm = 2.3270e-01, time/batch = 0.6320s	
4259/16650 (epoch 12.790), train_loss = 1.23655624, grad/param norm = 2.1689e-01, time/batch = 0.6315s	
4260/16650 (epoch 12.793), train_loss = 1.11966101, grad/param norm = 2.3580e-01, time/batch = 0.6372s	
4261/16650 (epoch 12.796), train_loss = 1.59438977, grad/param norm = 2.6403e-01, time/batch = 0.6324s	
4262/16650 (epoch 12.799), train_loss = 1.45739729, grad/param norm = 2.3505e-01, time/batch = 0.6345s	
4263/16650 (epoch 12.802), train_loss = 1.28129222, grad/param norm = 2.5163e-01, time/batch = 0.6344s	
4264/16650 (epoch 12.805), train_loss = 1.23940825, grad/param norm = 2.1894e-01, time/batch = 0.6286s	
4265/16650 (epoch 12.808), train_loss = 1.24804973, grad/param norm = 2.2532e-01, time/batch = 0.6287s	
4266/16650 (epoch 12.811), train_loss = 1.40170273, grad/param norm = 2.3498e-01, time/batch = 0.6290s	
4267/16650 (epoch 12.814), train_loss = 1.11964402, grad/param norm = 2.2085e-01, time/batch = 0.6295s	
4268/16650 (epoch 12.817), train_loss = 1.21968345, grad/param norm = 2.5050e-01, time/batch = 0.6340s	
4269/16650 (epoch 12.820), train_loss = 1.29381262, grad/param norm = 2.4475e-01, time/batch = 0.6305s	
4270/16650 (epoch 12.823), train_loss = 1.13996772, grad/param norm = 2.2157e-01, time/batch = 0.6316s	
4271/16650 (epoch 12.826), train_loss = 1.24119021, grad/param norm = 2.1890e-01, time/batch = 0.6332s	
4272/16650 (epoch 12.829), train_loss = 1.37619372, grad/param norm = 2.4182e-01, time/batch = 0.6349s	
4273/16650 (epoch 12.832), train_loss = 1.39524062, grad/param norm = 2.4791e-01, time/batch = 0.6404s	
4274/16650 (epoch 12.835), train_loss = 1.35911847, grad/param norm = 2.6763e-01, time/batch = 0.6426s	
4275/16650 (epoch 12.838), train_loss = 1.13559675, grad/param norm = 2.3054e-01, time/batch = 0.6566s	
4276/16650 (epoch 12.841), train_loss = 1.14451046, grad/param norm = 2.1096e-01, time/batch = 0.6623s	
4277/16650 (epoch 12.844), train_loss = 1.16289636, grad/param norm = 2.1557e-01, time/batch = 0.6511s	
4278/16650 (epoch 12.847), train_loss = 1.33594180, grad/param norm = 2.3983e-01, time/batch = 0.6310s	
4279/16650 (epoch 12.850), train_loss = 1.11508612, grad/param norm = 2.5139e-01, time/batch = 0.6305s	
4280/16650 (epoch 12.853), train_loss = 1.28585298, grad/param norm = 2.4239e-01, time/batch = 0.6337s	
4281/16650 (epoch 12.856), train_loss = 1.12981834, grad/param norm = 2.3407e-01, time/batch = 0.6340s	
4282/16650 (epoch 12.859), train_loss = 1.32574602, grad/param norm = 2.4215e-01, time/batch = 0.6343s	
4283/16650 (epoch 12.862), train_loss = 1.23101342, grad/param norm = 2.2592e-01, time/batch = 0.6317s	
4284/16650 (epoch 12.865), train_loss = 1.01285587, grad/param norm = 1.9502e-01, time/batch = 0.6338s	
4285/16650 (epoch 12.868), train_loss = 1.31466163, grad/param norm = 2.4851e-01, time/batch = 0.6346s	
4286/16650 (epoch 12.871), train_loss = 1.32852445, grad/param norm = 2.4780e-01, time/batch = 0.6442s	
4287/16650 (epoch 12.874), train_loss = 1.31037711, grad/param norm = 2.4073e-01, time/batch = 0.6363s	
4288/16650 (epoch 12.877), train_loss = 1.17095277, grad/param norm = 2.2329e-01, time/batch = 0.6302s	
4289/16650 (epoch 12.880), train_loss = 1.18885370, grad/param norm = 2.5654e-01, time/batch = 0.6304s	
4290/16650 (epoch 12.883), train_loss = 1.29664560, grad/param norm = 2.5163e-01, time/batch = 0.6454s	
4291/16650 (epoch 12.886), train_loss = 1.27504776, grad/param norm = 2.6532e-01, time/batch = 0.6705s	
4292/16650 (epoch 12.889), train_loss = 1.11892343, grad/param norm = 2.3184e-01, time/batch = 0.6379s	
4293/16650 (epoch 12.892), train_loss = 1.20173136, grad/param norm = 2.2299e-01, time/batch = 0.6364s	
4294/16650 (epoch 12.895), train_loss = 1.34393707, grad/param norm = 2.4157e-01, time/batch = 0.6389s	
4295/16650 (epoch 12.898), train_loss = 1.30756604, grad/param norm = 2.3179e-01, time/batch = 0.6440s	
4296/16650 (epoch 12.901), train_loss = 1.24865248, grad/param norm = 2.0775e-01, time/batch = 0.6349s	
4297/16650 (epoch 12.904), train_loss = 1.17556133, grad/param norm = 2.4626e-01, time/batch = 0.6347s	
4298/16650 (epoch 12.907), train_loss = 1.29467848, grad/param norm = 2.4791e-01, time/batch = 0.6306s	
4299/16650 (epoch 12.910), train_loss = 1.29027851, grad/param norm = 2.2953e-01, time/batch = 0.6351s	
4300/16650 (epoch 12.913), train_loss = 1.18195140, grad/param norm = 2.3425e-01, time/batch = 0.6291s	
4301/16650 (epoch 12.916), train_loss = 1.29099282, grad/param norm = 2.3838e-01, time/batch = 0.6378s	
4302/16650 (epoch 12.919), train_loss = 1.43616862, grad/param norm = 2.4826e-01, time/batch = 0.6337s	
4303/16650 (epoch 12.922), train_loss = 1.37395717, grad/param norm = 2.3765e-01, time/batch = 0.6306s	
4304/16650 (epoch 12.925), train_loss = 1.19349049, grad/param norm = 2.5740e-01, time/batch = 0.6346s	
4305/16650 (epoch 12.928), train_loss = 1.20963228, grad/param norm = 2.2804e-01, time/batch = 0.6347s	
4306/16650 (epoch 12.931), train_loss = 1.29448316, grad/param norm = 2.3604e-01, time/batch = 0.6315s	
4307/16650 (epoch 12.934), train_loss = 1.10766422, grad/param norm = 2.2061e-01, time/batch = 0.6304s	
4308/16650 (epoch 12.937), train_loss = 1.24097241, grad/param norm = 2.8039e-01, time/batch = 0.6305s	
4309/16650 (epoch 12.940), train_loss = 1.18249732, grad/param norm = 1.9533e-01, time/batch = 0.6348s	
4310/16650 (epoch 12.943), train_loss = 1.23536869, grad/param norm = 2.3132e-01, time/batch = 0.6345s	
4311/16650 (epoch 12.946), train_loss = 1.17434732, grad/param norm = 2.4377e-01, time/batch = 0.6364s	
4312/16650 (epoch 12.949), train_loss = 1.15158398, grad/param norm = 2.5720e-01, time/batch = 0.6327s	
4313/16650 (epoch 12.952), train_loss = 0.99877072, grad/param norm = 2.2384e-01, time/batch = 0.6365s	
4314/16650 (epoch 12.955), train_loss = 1.17694191, grad/param norm = 2.2659e-01, time/batch = 0.6299s	
4315/16650 (epoch 12.958), train_loss = 1.31826582, grad/param norm = 2.5843e-01, time/batch = 0.6300s	
4316/16650 (epoch 12.961), train_loss = 1.17853351, grad/param norm = 2.1777e-01, time/batch = 0.6309s	
4317/16650 (epoch 12.964), train_loss = 1.14386427, grad/param norm = 2.3438e-01, time/batch = 0.6350s	
4318/16650 (epoch 12.967), train_loss = 1.39326389, grad/param norm = 2.5501e-01, time/batch = 0.6340s	
4319/16650 (epoch 12.970), train_loss = 1.08801050, grad/param norm = 2.2649e-01, time/batch = 0.6315s	
4320/16650 (epoch 12.973), train_loss = 1.18819153, grad/param norm = 2.6391e-01, time/batch = 0.6323s	
4321/16650 (epoch 12.976), train_loss = 1.13902077, grad/param norm = 2.3469e-01, time/batch = 0.6337s	
4322/16650 (epoch 12.979), train_loss = 1.28429289, grad/param norm = 2.4704e-01, time/batch = 0.6311s	
4323/16650 (epoch 12.982), train_loss = 1.31263922, grad/param norm = 2.4442e-01, time/batch = 0.6302s	
4324/16650 (epoch 12.985), train_loss = 1.17981475, grad/param norm = 2.2553e-01, time/batch = 0.6309s	
4325/16650 (epoch 12.988), train_loss = 1.46018875, grad/param norm = 2.7368e-01, time/batch = 0.6334s	
4326/16650 (epoch 12.991), train_loss = 1.14147360, grad/param norm = 2.4882e-01, time/batch = 0.6365s	
4327/16650 (epoch 12.994), train_loss = 1.19153629, grad/param norm = 2.2762e-01, time/batch = 0.6398s	
4328/16650 (epoch 12.997), train_loss = 1.27921960, grad/param norm = 2.4564e-01, time/batch = 0.6440s	
decayed learning rate by a factor 0.97 to 0.00177058562	
4329/16650 (epoch 13.000), train_loss = 1.30725696, grad/param norm = 2.5104e-01, time/batch = 0.6299s	
4330/16650 (epoch 13.003), train_loss = 1.31276719, grad/param norm = 2.6045e-01, time/batch = 0.6293s	
4331/16650 (epoch 13.006), train_loss = 1.34811884, grad/param norm = 2.4337e-01, time/batch = 0.6310s	
4332/16650 (epoch 13.009), train_loss = 1.42720877, grad/param norm = 2.5088e-01, time/batch = 0.6365s	
4333/16650 (epoch 13.012), train_loss = 1.47935147, grad/param norm = 2.6248e-01, time/batch = 0.6397s	
4334/16650 (epoch 13.015), train_loss = 1.24032240, grad/param norm = 3.0257e-01, time/batch = 0.6419s	
4335/16650 (epoch 13.018), train_loss = 1.00739484, grad/param norm = 2.2687e-01, time/batch = 0.6371s	
4336/16650 (epoch 13.021), train_loss = 1.37709134, grad/param norm = 2.6527e-01, time/batch = 0.6343s	
4337/16650 (epoch 13.024), train_loss = 1.20135410, grad/param norm = 2.3111e-01, time/batch = 0.6311s	
4338/16650 (epoch 13.027), train_loss = 1.36551126, grad/param norm = 2.5038e-01, time/batch = 0.6303s	
4339/16650 (epoch 13.030), train_loss = 1.10289966, grad/param norm = 2.2094e-01, time/batch = 0.6296s	
4340/16650 (epoch 13.033), train_loss = 1.23347081, grad/param norm = 2.2851e-01, time/batch = 0.6297s	
4341/16650 (epoch 13.036), train_loss = 1.05020445, grad/param norm = 2.4112e-01, time/batch = 0.6331s	
4342/16650 (epoch 13.039), train_loss = 1.34238737, grad/param norm = 2.4907e-01, time/batch = 0.6322s	
4343/16650 (epoch 13.042), train_loss = 1.34453687, grad/param norm = 2.4108e-01, time/batch = 0.6323s	
4344/16650 (epoch 13.045), train_loss = 1.23819472, grad/param norm = 2.4190e-01, time/batch = 0.6297s	
4345/16650 (epoch 13.048), train_loss = 1.33040466, grad/param norm = 2.5905e-01, time/batch = 0.6292s	
4346/16650 (epoch 13.051), train_loss = 1.26226275, grad/param norm = 2.5668e-01, time/batch = 0.6328s	
4347/16650 (epoch 13.054), train_loss = 1.28321251, grad/param norm = 2.4781e-01, time/batch = 0.6361s	
4348/16650 (epoch 13.057), train_loss = 1.23683220, grad/param norm = 2.4662e-01, time/batch = 0.6464s	
4349/16650 (epoch 13.060), train_loss = 1.11455100, grad/param norm = 2.2087e-01, time/batch = 0.6686s	
4350/16650 (epoch 13.063), train_loss = 1.21199625, grad/param norm = 2.3914e-01, time/batch = 0.6389s	
4351/16650 (epoch 13.066), train_loss = 1.43179726, grad/param norm = 2.4496e-01, time/batch = 0.6326s	
4352/16650 (epoch 13.069), train_loss = 1.35169299, grad/param norm = 2.5613e-01, time/batch = 0.6307s	
4353/16650 (epoch 13.072), train_loss = 1.19564132, grad/param norm = 2.4396e-01, time/batch = 0.6303s	
4354/16650 (epoch 13.075), train_loss = 1.29249636, grad/param norm = 2.4409e-01, time/batch = 0.6299s	
4355/16650 (epoch 13.078), train_loss = 1.36059911, grad/param norm = 2.2980e-01, time/batch = 0.6307s	
4356/16650 (epoch 13.081), train_loss = 1.22813556, grad/param norm = 2.3690e-01, time/batch = 0.6325s	
4357/16650 (epoch 13.084), train_loss = 1.29687094, grad/param norm = 2.3077e-01, time/batch = 0.6306s	
4358/16650 (epoch 13.087), train_loss = 1.22791364, grad/param norm = 2.4710e-01, time/batch = 0.6323s	
4359/16650 (epoch 13.090), train_loss = 1.17550991, grad/param norm = 2.2391e-01, time/batch = 0.6411s	
4360/16650 (epoch 13.093), train_loss = 1.49098882, grad/param norm = 2.4766e-01, time/batch = 0.6377s	
4361/16650 (epoch 13.096), train_loss = 1.22464105, grad/param norm = 2.3336e-01, time/batch = 0.6377s	
4362/16650 (epoch 13.099), train_loss = 1.21781375, grad/param norm = 2.1453e-01, time/batch = 0.6333s	
4363/16650 (epoch 13.102), train_loss = 1.28322943, grad/param norm = 2.5206e-01, time/batch = 0.6312s	
4364/16650 (epoch 13.105), train_loss = 1.33088167, grad/param norm = 2.3997e-01, time/batch = 0.6355s	
4365/16650 (epoch 13.108), train_loss = 1.33246741, grad/param norm = 2.5251e-01, time/batch = 0.6416s	
4366/16650 (epoch 13.111), train_loss = 1.31641416, grad/param norm = 2.3231e-01, time/batch = 0.6464s	
4367/16650 (epoch 13.114), train_loss = 1.40127594, grad/param norm = 2.5156e-01, time/batch = 0.6509s	
4368/16650 (epoch 13.117), train_loss = 1.39685697, grad/param norm = 2.4774e-01, time/batch = 0.6530s	
4369/16650 (epoch 13.120), train_loss = 1.14201024, grad/param norm = 2.1638e-01, time/batch = 0.6654s	
4370/16650 (epoch 13.123), train_loss = 1.24145484, grad/param norm = 2.3718e-01, time/batch = 0.6521s	
4371/16650 (epoch 13.126), train_loss = 1.26056116, grad/param norm = 2.5546e-01, time/batch = 0.6605s	
4372/16650 (epoch 13.129), train_loss = 1.30314846, grad/param norm = 2.3262e-01, time/batch = 0.6496s	
4373/16650 (epoch 13.132), train_loss = 1.31517953, grad/param norm = 2.4985e-01, time/batch = 0.6433s	
4374/16650 (epoch 13.135), train_loss = 1.31663741, grad/param norm = 2.3890e-01, time/batch = 0.6422s	
4375/16650 (epoch 13.138), train_loss = 1.34100823, grad/param norm = 2.2714e-01, time/batch = 0.6296s	
4376/16650 (epoch 13.141), train_loss = 1.35618442, grad/param norm = 2.9082e-01, time/batch = 0.6320s	
4377/16650 (epoch 13.144), train_loss = 1.24625249, grad/param norm = 2.3979e-01, time/batch = 0.6312s	
4378/16650 (epoch 13.147), train_loss = 1.42886742, grad/param norm = 2.3821e-01, time/batch = 0.6422s	
4379/16650 (epoch 13.150), train_loss = 1.51224704, grad/param norm = 2.3865e-01, time/batch = 0.6528s	
4380/16650 (epoch 13.153), train_loss = 1.26923881, grad/param norm = 2.4704e-01, time/batch = 0.6631s	
4381/16650 (epoch 13.156), train_loss = 1.08495165, grad/param norm = 2.0507e-01, time/batch = 0.6599s	
4382/16650 (epoch 13.159), train_loss = 1.36915757, grad/param norm = 2.5404e-01, time/batch = 0.6629s	
4383/16650 (epoch 13.162), train_loss = 1.40272956, grad/param norm = 2.3028e-01, time/batch = 0.6705s	
4384/16650 (epoch 13.165), train_loss = 1.35938838, grad/param norm = 2.4024e-01, time/batch = 0.6609s	
4385/16650 (epoch 13.168), train_loss = 1.01762762, grad/param norm = 2.0695e-01, time/batch = 0.6483s	
4386/16650 (epoch 13.171), train_loss = 1.36591731, grad/param norm = 2.2938e-01, time/batch = 0.6583s	
4387/16650 (epoch 13.174), train_loss = 1.09166126, grad/param norm = 2.4731e-01, time/batch = 0.6714s	
4388/16650 (epoch 13.177), train_loss = 1.25390966, grad/param norm = 2.4438e-01, time/batch = 0.6620s	
4389/16650 (epoch 13.180), train_loss = 1.40468063, grad/param norm = 2.4833e-01, time/batch = 0.6680s	
4390/16650 (epoch 13.183), train_loss = 1.53472764, grad/param norm = 2.7719e-01, time/batch = 0.6611s	
4391/16650 (epoch 13.186), train_loss = 1.35923094, grad/param norm = 2.3654e-01, time/batch = 0.6536s	
4392/16650 (epoch 13.189), train_loss = 1.13934661, grad/param norm = 2.0215e-01, time/batch = 0.6407s	
4393/16650 (epoch 13.192), train_loss = 1.18966818, grad/param norm = 2.4628e-01, time/batch = 0.6383s	
4394/16650 (epoch 13.195), train_loss = 1.25035755, grad/param norm = 2.4633e-01, time/batch = 0.6310s	
4395/16650 (epoch 13.198), train_loss = 1.04355385, grad/param norm = 2.1923e-01, time/batch = 0.6288s	
4396/16650 (epoch 13.201), train_loss = 1.19220226, grad/param norm = 2.4878e-01, time/batch = 0.6332s	
4397/16650 (epoch 13.204), train_loss = 1.26388212, grad/param norm = 2.5127e-01, time/batch = 0.6283s	
4398/16650 (epoch 13.207), train_loss = 1.32411932, grad/param norm = 2.6395e-01, time/batch = 0.6287s	
4399/16650 (epoch 13.210), train_loss = 1.19337243, grad/param norm = 2.3257e-01, time/batch = 0.6302s	
4400/16650 (epoch 13.213), train_loss = 1.32164489, grad/param norm = 2.4876e-01, time/batch = 0.6289s	
4401/16650 (epoch 13.216), train_loss = 1.20925501, grad/param norm = 2.2307e-01, time/batch = 0.6305s	
4402/16650 (epoch 13.219), train_loss = 1.24685761, grad/param norm = 2.4298e-01, time/batch = 0.6387s	
4403/16650 (epoch 13.222), train_loss = 1.25590357, grad/param norm = 2.2512e-01, time/batch = 0.6684s	
4404/16650 (epoch 13.225), train_loss = 1.25151033, grad/param norm = 2.1781e-01, time/batch = 0.6419s	
4405/16650 (epoch 13.228), train_loss = 1.16920446, grad/param norm = 2.3483e-01, time/batch = 0.6296s	
4406/16650 (epoch 13.231), train_loss = 1.22725634, grad/param norm = 2.3694e-01, time/batch = 0.6304s	
4407/16650 (epoch 13.234), train_loss = 1.42140774, grad/param norm = 2.5169e-01, time/batch = 0.6314s	
4408/16650 (epoch 13.237), train_loss = 1.27165760, grad/param norm = 2.3891e-01, time/batch = 0.6331s	
4409/16650 (epoch 13.240), train_loss = 1.28946040, grad/param norm = 2.6828e-01, time/batch = 0.6322s	
4410/16650 (epoch 13.243), train_loss = 1.28056162, grad/param norm = 2.3234e-01, time/batch = 0.6347s	
4411/16650 (epoch 13.246), train_loss = 1.39607293, grad/param norm = 2.5404e-01, time/batch = 0.6376s	
4412/16650 (epoch 13.249), train_loss = 1.13246108, grad/param norm = 2.5070e-01, time/batch = 0.6357s	
4413/16650 (epoch 13.252), train_loss = 1.23139558, grad/param norm = 2.2428e-01, time/batch = 0.6319s	
4414/16650 (epoch 13.255), train_loss = 1.37453706, grad/param norm = 2.4633e-01, time/batch = 0.6324s	
4415/16650 (epoch 13.258), train_loss = 1.37482388, grad/param norm = 2.4455e-01, time/batch = 0.6329s	
4416/16650 (epoch 13.261), train_loss = 1.25880037, grad/param norm = 2.3468e-01, time/batch = 0.6342s	
4417/16650 (epoch 13.264), train_loss = 1.21823073, grad/param norm = 2.6424e-01, time/batch = 0.6347s	
4418/16650 (epoch 13.267), train_loss = 1.19918633, grad/param norm = 2.3264e-01, time/batch = 0.6370s	
4419/16650 (epoch 13.270), train_loss = 1.24399073, grad/param norm = 2.2260e-01, time/batch = 0.6370s	
4420/16650 (epoch 13.273), train_loss = 1.36395030, grad/param norm = 2.1827e-01, time/batch = 0.6342s	
4421/16650 (epoch 13.276), train_loss = 1.25917016, grad/param norm = 2.1469e-01, time/batch = 0.6412s	
4422/16650 (epoch 13.279), train_loss = 1.23217984, grad/param norm = 2.1908e-01, time/batch = 0.6376s	
4423/16650 (epoch 13.282), train_loss = 1.11808004, grad/param norm = 2.1918e-01, time/batch = 0.6381s	
4424/16650 (epoch 13.285), train_loss = 1.12624788, grad/param norm = 2.1354e-01, time/batch = 0.6353s	
4425/16650 (epoch 13.288), train_loss = 1.18504094, grad/param norm = 2.2984e-01, time/batch = 0.6315s	
4426/16650 (epoch 13.291), train_loss = 0.99238241, grad/param norm = 2.0750e-01, time/batch = 0.6326s	
4427/16650 (epoch 13.294), train_loss = 1.07696768, grad/param norm = 1.9230e-01, time/batch = 0.6330s	
4428/16650 (epoch 13.297), train_loss = 1.17995674, grad/param norm = 2.3203e-01, time/batch = 0.6294s	
4429/16650 (epoch 13.300), train_loss = 1.00438804, grad/param norm = 2.0413e-01, time/batch = 0.6337s	
4430/16650 (epoch 13.303), train_loss = 1.05320770, grad/param norm = 1.9038e-01, time/batch = 0.6301s	
4431/16650 (epoch 13.306), train_loss = 1.29061297, grad/param norm = 2.2128e-01, time/batch = 0.6336s	
4432/16650 (epoch 13.309), train_loss = 1.35807975, grad/param norm = 2.4396e-01, time/batch = 0.6483s	
4433/16650 (epoch 13.312), train_loss = 1.12556855, grad/param norm = 2.3489e-01, time/batch = 0.6678s	
4434/16650 (epoch 13.315), train_loss = 0.91826166, grad/param norm = 1.8324e-01, time/batch = 0.6326s	
4435/16650 (epoch 13.318), train_loss = 1.00348346, grad/param norm = 2.1739e-01, time/batch = 0.6345s	
4436/16650 (epoch 13.321), train_loss = 1.41550801, grad/param norm = 2.5364e-01, time/batch = 0.6293s	
4437/16650 (epoch 13.324), train_loss = 1.16997281, grad/param norm = 2.3621e-01, time/batch = 0.6607s	
4438/16650 (epoch 13.327), train_loss = 1.38375646, grad/param norm = 2.8494e-01, time/batch = 0.6348s	
4439/16650 (epoch 13.330), train_loss = 1.28950850, grad/param norm = 2.3687e-01, time/batch = 0.6313s	
4440/16650 (epoch 13.333), train_loss = 1.32429047, grad/param norm = 2.5513e-01, time/batch = 0.6305s	
4441/16650 (epoch 13.336), train_loss = 1.12642489, grad/param norm = 2.4254e-01, time/batch = 0.6325s	
4442/16650 (epoch 13.339), train_loss = 1.21847527, grad/param norm = 2.2328e-01, time/batch = 0.6332s	
4443/16650 (epoch 13.342), train_loss = 1.18691616, grad/param norm = 2.4597e-01, time/batch = 0.6317s	
4444/16650 (epoch 13.345), train_loss = 1.06749901, grad/param norm = 2.0742e-01, time/batch = 0.6321s	
4445/16650 (epoch 13.348), train_loss = 1.25258835, grad/param norm = 2.3580e-01, time/batch = 0.6361s	
4446/16650 (epoch 13.351), train_loss = 1.31577310, grad/param norm = 2.4408e-01, time/batch = 0.6535s	
4447/16650 (epoch 13.354), train_loss = 1.38911411, grad/param norm = 2.6058e-01, time/batch = 0.6681s	
4448/16650 (epoch 13.357), train_loss = 1.29428749, grad/param norm = 2.5558e-01, time/batch = 0.6321s	
4449/16650 (epoch 13.360), train_loss = 1.29709020, grad/param norm = 2.3483e-01, time/batch = 0.6302s	
4450/16650 (epoch 13.363), train_loss = 1.38386602, grad/param norm = 2.6200e-01, time/batch = 0.6306s	
4451/16650 (epoch 13.366), train_loss = 1.44671997, grad/param norm = 2.5754e-01, time/batch = 0.6352s	
4452/16650 (epoch 13.369), train_loss = 1.25283190, grad/param norm = 2.3054e-01, time/batch = 0.6319s	
4453/16650 (epoch 13.372), train_loss = 1.24331227, grad/param norm = 2.2189e-01, time/batch = 0.6319s	
4454/16650 (epoch 13.375), train_loss = 1.23975439, grad/param norm = 2.3753e-01, time/batch = 0.6326s	
4455/16650 (epoch 13.378), train_loss = 1.10754040, grad/param norm = 2.1978e-01, time/batch = 0.6358s	
4456/16650 (epoch 13.381), train_loss = 1.29278563, grad/param norm = 2.4114e-01, time/batch = 0.6346s	
4457/16650 (epoch 13.384), train_loss = 1.38062007, grad/param norm = 2.3960e-01, time/batch = 0.6342s	
4458/16650 (epoch 13.387), train_loss = 0.98950021, grad/param norm = 2.0309e-01, time/batch = 0.6300s	
4459/16650 (epoch 13.390), train_loss = 1.32076950, grad/param norm = 2.4081e-01, time/batch = 0.6302s	
4460/16650 (epoch 13.393), train_loss = 1.24956540, grad/param norm = 2.5879e-01, time/batch = 0.6405s	
4461/16650 (epoch 13.396), train_loss = 1.39895084, grad/param norm = 2.5001e-01, time/batch = 0.6556s	
4462/16650 (epoch 13.399), train_loss = 1.29811481, grad/param norm = 2.5552e-01, time/batch = 0.6499s	
4463/16650 (epoch 13.402), train_loss = 1.12867857, grad/param norm = 2.1518e-01, time/batch = 0.6578s	
4464/16650 (epoch 13.405), train_loss = 1.07478228, grad/param norm = 2.2202e-01, time/batch = 0.6619s	
4465/16650 (epoch 13.408), train_loss = 1.37515389, grad/param norm = 2.4027e-01, time/batch = 0.6464s	
4466/16650 (epoch 13.411), train_loss = 1.11477314, grad/param norm = 2.4407e-01, time/batch = 0.6362s	
4467/16650 (epoch 13.414), train_loss = 1.10599154, grad/param norm = 2.3952e-01, time/batch = 0.6308s	
4468/16650 (epoch 13.417), train_loss = 1.06898595, grad/param norm = 2.0351e-01, time/batch = 0.6298s	
4469/16650 (epoch 13.420), train_loss = 1.07151599, grad/param norm = 2.5595e-01, time/batch = 0.6325s	
4470/16650 (epoch 13.423), train_loss = 0.87165923, grad/param norm = 1.8408e-01, time/batch = 0.6305s	
4471/16650 (epoch 13.426), train_loss = 1.09761086, grad/param norm = 2.4981e-01, time/batch = 0.6322s	
4472/16650 (epoch 13.429), train_loss = 1.33785683, grad/param norm = 2.5131e-01, time/batch = 0.6322s	
4473/16650 (epoch 13.432), train_loss = 1.30682677, grad/param norm = 2.5104e-01, time/batch = 0.6338s	
4474/16650 (epoch 13.435), train_loss = 1.46211113, grad/param norm = 2.3601e-01, time/batch = 0.6295s	
4475/16650 (epoch 13.438), train_loss = 1.43723592, grad/param norm = 2.7783e-01, time/batch = 0.6350s	
4476/16650 (epoch 13.441), train_loss = 1.27620306, grad/param norm = 2.6532e-01, time/batch = 0.6297s	
4477/16650 (epoch 13.444), train_loss = 1.17815296, grad/param norm = 2.3604e-01, time/batch = 0.6356s	
4478/16650 (epoch 13.447), train_loss = 1.20127874, grad/param norm = 2.1803e-01, time/batch = 0.6383s	
4479/16650 (epoch 13.450), train_loss = 1.11757827, grad/param norm = 2.2280e-01, time/batch = 0.6480s	
4480/16650 (epoch 13.453), train_loss = 1.15056261, grad/param norm = 2.0855e-01, time/batch = 0.6475s	
4481/16650 (epoch 13.456), train_loss = 1.06436436, grad/param norm = 2.0823e-01, time/batch = 0.6721s	
4482/16650 (epoch 13.459), train_loss = 1.14164337, grad/param norm = 2.3414e-01, time/batch = 0.6467s	
4483/16650 (epoch 13.462), train_loss = 1.41623597, grad/param norm = 2.6737e-01, time/batch = 0.6394s	
4484/16650 (epoch 13.465), train_loss = 1.17707216, grad/param norm = 2.3949e-01, time/batch = 0.6349s	
4485/16650 (epoch 13.468), train_loss = 0.93372696, grad/param norm = 2.0725e-01, time/batch = 0.6510s	
4486/16650 (epoch 13.471), train_loss = 0.83611225, grad/param norm = 1.9375e-01, time/batch = 0.6671s	
4487/16650 (epoch 13.474), train_loss = 1.07338981, grad/param norm = 2.0117e-01, time/batch = 0.6319s	
4488/16650 (epoch 13.477), train_loss = 1.24350276, grad/param norm = 2.3242e-01, time/batch = 0.6315s	
4489/16650 (epoch 13.480), train_loss = 1.27167783, grad/param norm = 2.5206e-01, time/batch = 0.6328s	
4490/16650 (epoch 13.483), train_loss = 1.40752300, grad/param norm = 2.3260e-01, time/batch = 0.6300s	
4491/16650 (epoch 13.486), train_loss = 1.10979998, grad/param norm = 2.1991e-01, time/batch = 0.6320s	
4492/16650 (epoch 13.489), train_loss = 1.14537376, grad/param norm = 2.2410e-01, time/batch = 0.6314s	
4493/16650 (epoch 13.492), train_loss = 1.22950140, grad/param norm = 2.3516e-01, time/batch = 0.6315s	
4494/16650 (epoch 13.495), train_loss = 1.11509969, grad/param norm = 2.5358e-01, time/batch = 0.6307s	
4495/16650 (epoch 13.498), train_loss = 1.20796571, grad/param norm = 2.3781e-01, time/batch = 0.6328s	
4496/16650 (epoch 13.502), train_loss = 1.43639953, grad/param norm = 2.4984e-01, time/batch = 0.6330s	
4497/16650 (epoch 13.505), train_loss = 1.29369191, grad/param norm = 2.1713e-01, time/batch = 0.6360s	
4498/16650 (epoch 13.508), train_loss = 1.26979697, grad/param norm = 2.2595e-01, time/batch = 0.6346s	
4499/16650 (epoch 13.511), train_loss = 1.35224367, grad/param norm = 2.4283e-01, time/batch = 0.6313s	
4500/16650 (epoch 13.514), train_loss = 1.07825632, grad/param norm = 2.3430e-01, time/batch = 0.6294s	
4501/16650 (epoch 13.517), train_loss = 1.19980743, grad/param norm = 2.4491e-01, time/batch = 0.6329s	
4502/16650 (epoch 13.520), train_loss = 1.19730027, grad/param norm = 2.3588e-01, time/batch = 0.6304s	
4503/16650 (epoch 13.523), train_loss = 1.14435823, grad/param norm = 2.1902e-01, time/batch = 0.6328s	
4504/16650 (epoch 13.526), train_loss = 1.27290805, grad/param norm = 2.2428e-01, time/batch = 0.6318s	
4505/16650 (epoch 13.529), train_loss = 1.41550863, grad/param norm = 2.6473e-01, time/batch = 0.6288s	
4506/16650 (epoch 13.532), train_loss = 0.98257176, grad/param norm = 2.0768e-01, time/batch = 0.6275s	
4507/16650 (epoch 13.535), train_loss = 1.06650068, grad/param norm = 2.3363e-01, time/batch = 0.6304s	
4508/16650 (epoch 13.538), train_loss = 1.09661741, grad/param norm = 2.3144e-01, time/batch = 0.6296s	
4509/16650 (epoch 13.541), train_loss = 1.34591866, grad/param norm = 2.5069e-01, time/batch = 0.6341s	
4510/16650 (epoch 13.544), train_loss = 1.39841134, grad/param norm = 2.6156e-01, time/batch = 0.6346s	
4511/16650 (epoch 13.547), train_loss = 1.09948575, grad/param norm = 2.2621e-01, time/batch = 0.6334s	
4512/16650 (epoch 13.550), train_loss = 1.14076415, grad/param norm = 2.2934e-01, time/batch = 0.6318s	
4513/16650 (epoch 13.553), train_loss = 1.19460423, grad/param norm = 2.4728e-01, time/batch = 0.6309s	
4514/16650 (epoch 13.556), train_loss = 1.12057732, grad/param norm = 2.0123e-01, time/batch = 0.6282s	
4515/16650 (epoch 13.559), train_loss = 0.98406604, grad/param norm = 1.9141e-01, time/batch = 0.6305s	
4516/16650 (epoch 13.562), train_loss = 1.16658992, grad/param norm = 2.2647e-01, time/batch = 0.6296s	
4517/16650 (epoch 13.565), train_loss = 0.95298287, grad/param norm = 2.1009e-01, time/batch = 0.6313s	
4518/16650 (epoch 13.568), train_loss = 0.98137264, grad/param norm = 1.9832e-01, time/batch = 0.6310s	
4519/16650 (epoch 13.571), train_loss = 1.02272992, grad/param norm = 2.2634e-01, time/batch = 0.6296s	
4520/16650 (epoch 13.574), train_loss = 1.15328698, grad/param norm = 2.2507e-01, time/batch = 0.6300s	
4521/16650 (epoch 13.577), train_loss = 1.11182662, grad/param norm = 2.0766e-01, time/batch = 0.6356s	
4522/16650 (epoch 13.580), train_loss = 1.02311454, grad/param norm = 2.1855e-01, time/batch = 0.6323s	
4523/16650 (epoch 13.583), train_loss = 1.14609109, grad/param norm = 2.2080e-01, time/batch = 0.6308s	
4524/16650 (epoch 13.586), train_loss = 1.14400684, grad/param norm = 2.5962e-01, time/batch = 0.6400s	
4525/16650 (epoch 13.589), train_loss = 1.01117397, grad/param norm = 2.0291e-01, time/batch = 0.6684s	
4526/16650 (epoch 13.592), train_loss = 1.19196124, grad/param norm = 2.3025e-01, time/batch = 0.6423s	
4527/16650 (epoch 13.595), train_loss = 1.07287910, grad/param norm = 2.2088e-01, time/batch = 0.6351s	
4528/16650 (epoch 13.598), train_loss = 1.12021350, grad/param norm = 2.4653e-01, time/batch = 0.6310s	
4529/16650 (epoch 13.601), train_loss = 1.10170122, grad/param norm = 2.6073e-01, time/batch = 0.6363s	
4530/16650 (epoch 13.604), train_loss = 1.26451079, grad/param norm = 2.4096e-01, time/batch = 0.6437s	
4531/16650 (epoch 13.607), train_loss = 1.22879937, grad/param norm = 2.3706e-01, time/batch = 0.6416s	
4532/16650 (epoch 13.610), train_loss = 1.06336416, grad/param norm = 1.9945e-01, time/batch = 0.6412s	
4533/16650 (epoch 13.613), train_loss = 1.30883999, grad/param norm = 2.4000e-01, time/batch = 0.6301s	
4534/16650 (epoch 13.616), train_loss = 1.33645178, grad/param norm = 2.6172e-01, time/batch = 0.6262s	
4535/16650 (epoch 13.619), train_loss = 1.01935273, grad/param norm = 2.1680e-01, time/batch = 0.6275s	
4536/16650 (epoch 13.622), train_loss = 0.97481257, grad/param norm = 2.0802e-01, time/batch = 0.6311s	
4537/16650 (epoch 13.625), train_loss = 1.11476585, grad/param norm = 2.2874e-01, time/batch = 0.6284s	
4538/16650 (epoch 13.628), train_loss = 1.15108005, grad/param norm = 2.5008e-01, time/batch = 0.6282s	
4539/16650 (epoch 13.631), train_loss = 1.19177801, grad/param norm = 2.7616e-01, time/batch = 0.6317s	
4540/16650 (epoch 13.634), train_loss = 1.45139035, grad/param norm = 2.6152e-01, time/batch = 0.6287s	
4541/16650 (epoch 13.637), train_loss = 1.41822744, grad/param norm = 2.4665e-01, time/batch = 0.6402s	
4542/16650 (epoch 13.640), train_loss = 1.11661331, grad/param norm = 2.3056e-01, time/batch = 0.6329s	
4543/16650 (epoch 13.643), train_loss = 1.27832623, grad/param norm = 2.3064e-01, time/batch = 0.6321s	
4544/16650 (epoch 13.646), train_loss = 1.24824160, grad/param norm = 2.4367e-01, time/batch = 0.6293s	
4545/16650 (epoch 13.649), train_loss = 1.22489704, grad/param norm = 2.3861e-01, time/batch = 0.6295s	
4546/16650 (epoch 13.652), train_loss = 1.34185533, grad/param norm = 2.5294e-01, time/batch = 0.6288s	
4547/16650 (epoch 13.655), train_loss = 1.22013731, grad/param norm = 2.2913e-01, time/batch = 0.6301s	
4548/16650 (epoch 13.658), train_loss = 1.08779015, grad/param norm = 2.2125e-01, time/batch = 0.6294s	
4549/16650 (epoch 13.661), train_loss = 1.27900673, grad/param norm = 2.3408e-01, time/batch = 0.6308s	
4550/16650 (epoch 13.664), train_loss = 1.19656782, grad/param norm = 2.3289e-01, time/batch = 0.6287s	
4551/16650 (epoch 13.667), train_loss = 1.33142969, grad/param norm = 2.3386e-01, time/batch = 0.6307s	
4552/16650 (epoch 13.670), train_loss = 1.05291954, grad/param norm = 2.3482e-01, time/batch = 0.6286s	
4553/16650 (epoch 13.673), train_loss = 1.10383373, grad/param norm = 2.0490e-01, time/batch = 0.6343s	
4554/16650 (epoch 13.676), train_loss = 1.19311771, grad/param norm = 2.4613e-01, time/batch = 0.6420s	
4555/16650 (epoch 13.679), train_loss = 1.07455791, grad/param norm = 2.3268e-01, time/batch = 0.6514s	
4556/16650 (epoch 13.682), train_loss = 1.24311625, grad/param norm = 2.2365e-01, time/batch = 0.6569s	
4557/16650 (epoch 13.685), train_loss = 1.02916386, grad/param norm = 2.3491e-01, time/batch = 0.6716s	
4558/16650 (epoch 13.688), train_loss = 1.19725170, grad/param norm = 2.3468e-01, time/batch = 0.6552s	
4559/16650 (epoch 13.691), train_loss = 1.21611077, grad/param norm = 2.3150e-01, time/batch = 0.6719s	
4560/16650 (epoch 13.694), train_loss = 1.04020265, grad/param norm = 2.0992e-01, time/batch = 0.6678s	
4561/16650 (epoch 13.697), train_loss = 1.05069784, grad/param norm = 2.1807e-01, time/batch = 0.6447s	
4562/16650 (epoch 13.700), train_loss = 1.28104832, grad/param norm = 2.3473e-01, time/batch = 0.6448s	
4563/16650 (epoch 13.703), train_loss = 1.07123420, grad/param norm = 2.2977e-01, time/batch = 0.6445s	
4564/16650 (epoch 13.706), train_loss = 1.28141609, grad/param norm = 2.5193e-01, time/batch = 0.6689s	
4565/16650 (epoch 13.709), train_loss = 1.10061174, grad/param norm = 2.2197e-01, time/batch = 0.6394s	
4566/16650 (epoch 13.712), train_loss = 1.08533164, grad/param norm = 2.4835e-01, time/batch = 0.6291s	
4567/16650 (epoch 13.715), train_loss = 1.32520242, grad/param norm = 2.3067e-01, time/batch = 0.6306s	
4568/16650 (epoch 13.718), train_loss = 1.35680505, grad/param norm = 2.5607e-01, time/batch = 0.6313s	
4569/16650 (epoch 13.721), train_loss = 1.31114262, grad/param norm = 2.4630e-01, time/batch = 0.6338s	
4570/16650 (epoch 13.724), train_loss = 1.33443359, grad/param norm = 2.7230e-01, time/batch = 0.6374s	
4571/16650 (epoch 13.727), train_loss = 1.26679811, grad/param norm = 2.2419e-01, time/batch = 0.6365s	
4572/16650 (epoch 13.730), train_loss = 1.15955297, grad/param norm = 2.2156e-01, time/batch = 0.6356s	
4573/16650 (epoch 13.733), train_loss = 1.30686744, grad/param norm = 2.3676e-01, time/batch = 0.6347s	
4574/16650 (epoch 13.736), train_loss = 1.02013559, grad/param norm = 2.1124e-01, time/batch = 0.6303s	
4575/16650 (epoch 13.739), train_loss = 1.19570246, grad/param norm = 2.3733e-01, time/batch = 0.6295s	
4576/16650 (epoch 13.742), train_loss = 1.23597474, grad/param norm = 2.7690e-01, time/batch = 0.6304s	
4577/16650 (epoch 13.745), train_loss = 0.99907362, grad/param norm = 2.0993e-01, time/batch = 0.6333s	
4578/16650 (epoch 13.748), train_loss = 1.07131782, grad/param norm = 2.4751e-01, time/batch = 0.6378s	
4579/16650 (epoch 13.751), train_loss = 1.24839820, grad/param norm = 2.9120e-01, time/batch = 0.6408s	
4580/16650 (epoch 13.754), train_loss = 1.38581771, grad/param norm = 2.8256e-01, time/batch = 0.6387s	
4581/16650 (epoch 13.757), train_loss = 1.28677878, grad/param norm = 2.2998e-01, time/batch = 0.6355s	
4582/16650 (epoch 13.760), train_loss = 1.16932377, grad/param norm = 2.4689e-01, time/batch = 0.6300s	
4583/16650 (epoch 13.763), train_loss = 1.10020553, grad/param norm = 2.3642e-01, time/batch = 0.6355s	
4584/16650 (epoch 13.766), train_loss = 1.19748996, grad/param norm = 2.1398e-01, time/batch = 0.6339s	
4585/16650 (epoch 13.769), train_loss = 1.20074259, grad/param norm = 2.2902e-01, time/batch = 0.6435s	
4586/16650 (epoch 13.772), train_loss = 1.12255220, grad/param norm = 2.0132e-01, time/batch = 0.6327s	
4587/16650 (epoch 13.775), train_loss = 1.17913085, grad/param norm = 2.2363e-01, time/batch = 0.6321s	
4588/16650 (epoch 13.778), train_loss = 1.17739232, grad/param norm = 2.2371e-01, time/batch = 0.6324s	
4589/16650 (epoch 13.781), train_loss = 1.29024068, grad/param norm = 2.3909e-01, time/batch = 0.6295s	
4590/16650 (epoch 13.784), train_loss = 1.28063082, grad/param norm = 2.5437e-01, time/batch = 0.6407s	
4591/16650 (epoch 13.787), train_loss = 1.29110470, grad/param norm = 2.3110e-01, time/batch = 0.6334s	
4592/16650 (epoch 13.790), train_loss = 1.20744551, grad/param norm = 2.1178e-01, time/batch = 0.6313s	
4593/16650 (epoch 13.793), train_loss = 1.07923264, grad/param norm = 2.2905e-01, time/batch = 0.6300s	
4594/16650 (epoch 13.796), train_loss = 1.54947622, grad/param norm = 2.6422e-01, time/batch = 0.6292s	
4595/16650 (epoch 13.799), train_loss = 1.42184894, grad/param norm = 2.3626e-01, time/batch = 0.6290s	
4596/16650 (epoch 13.802), train_loss = 1.23897813, grad/param norm = 2.5410e-01, time/batch = 0.6305s	
4597/16650 (epoch 13.805), train_loss = 1.20001754, grad/param norm = 2.1752e-01, time/batch = 0.6324s	
4598/16650 (epoch 13.808), train_loss = 1.21669518, grad/param norm = 2.3098e-01, time/batch = 0.6277s	
4599/16650 (epoch 13.811), train_loss = 1.36308431, grad/param norm = 2.3371e-01, time/batch = 0.6277s	
4600/16650 (epoch 13.814), train_loss = 1.08156970, grad/param norm = 2.1822e-01, time/batch = 0.6342s	
4601/16650 (epoch 13.817), train_loss = 1.17402730, grad/param norm = 2.4926e-01, time/batch = 0.6347s	
4602/16650 (epoch 13.820), train_loss = 1.25233134, grad/param norm = 2.4268e-01, time/batch = 0.6301s	
4603/16650 (epoch 13.823), train_loss = 1.10790034, grad/param norm = 2.1713e-01, time/batch = 0.6299s	
4604/16650 (epoch 13.826), train_loss = 1.20458452, grad/param norm = 2.1863e-01, time/batch = 0.6308s	
4605/16650 (epoch 13.829), train_loss = 1.33073631, grad/param norm = 2.3507e-01, time/batch = 0.6299s	
4606/16650 (epoch 13.832), train_loss = 1.35015592, grad/param norm = 2.5510e-01, time/batch = 0.6321s	
4607/16650 (epoch 13.835), train_loss = 1.31551551, grad/param norm = 2.7206e-01, time/batch = 0.6300s	
4608/16650 (epoch 13.838), train_loss = 1.09272206, grad/param norm = 2.3554e-01, time/batch = 0.6441s	
4609/16650 (epoch 13.841), train_loss = 1.11714364, grad/param norm = 2.1048e-01, time/batch = 0.6323s	
4610/16650 (epoch 13.844), train_loss = 1.13453555, grad/param norm = 2.2254e-01, time/batch = 0.6287s	
4611/16650 (epoch 13.847), train_loss = 1.29958856, grad/param norm = 2.4671e-01, time/batch = 0.6327s	
4612/16650 (epoch 13.850), train_loss = 1.07975404, grad/param norm = 2.4724e-01, time/batch = 0.6322s	
4613/16650 (epoch 13.853), train_loss = 1.25802098, grad/param norm = 2.4866e-01, time/batch = 0.6322s	
4614/16650 (epoch 13.856), train_loss = 1.09650243, grad/param norm = 2.3816e-01, time/batch = 0.6325s	
4615/16650 (epoch 13.859), train_loss = 1.29177022, grad/param norm = 2.4825e-01, time/batch = 0.6323s	
4616/16650 (epoch 13.862), train_loss = 1.19710824, grad/param norm = 2.3123e-01, time/batch = 0.6295s	
4617/16650 (epoch 13.865), train_loss = 0.98359104, grad/param norm = 1.9759e-01, time/batch = 0.6653s	
4618/16650 (epoch 13.868), train_loss = 1.27273242, grad/param norm = 2.4517e-01, time/batch = 0.6516s	
4619/16650 (epoch 13.871), train_loss = 1.28201307, grad/param norm = 2.4474e-01, time/batch = 0.6304s	
4620/16650 (epoch 13.874), train_loss = 1.26515898, grad/param norm = 2.3956e-01, time/batch = 0.6304s	
4621/16650 (epoch 13.877), train_loss = 1.13846412, grad/param norm = 2.1505e-01, time/batch = 0.6440s	
4622/16650 (epoch 13.880), train_loss = 1.14902655, grad/param norm = 2.4932e-01, time/batch = 0.6690s	
4623/16650 (epoch 13.883), train_loss = 1.25610353, grad/param norm = 2.5570e-01, time/batch = 0.6415s	
4624/16650 (epoch 13.886), train_loss = 1.23346733, grad/param norm = 2.5333e-01, time/batch = 0.6325s	
4625/16650 (epoch 13.889), train_loss = 1.07278917, grad/param norm = 2.3178e-01, time/batch = 0.6397s	
4626/16650 (epoch 13.892), train_loss = 1.16490895, grad/param norm = 2.2139e-01, time/batch = 0.6588s	
4627/16650 (epoch 13.895), train_loss = 1.31443520, grad/param norm = 2.5540e-01, time/batch = 0.6656s	
4628/16650 (epoch 13.898), train_loss = 1.26683804, grad/param norm = 2.3011e-01, time/batch = 0.6364s	
4629/16650 (epoch 13.901), train_loss = 1.21613446, grad/param norm = 2.1683e-01, time/batch = 0.6408s	
4630/16650 (epoch 13.904), train_loss = 1.13812861, grad/param norm = 2.4441e-01, time/batch = 0.6462s	
4631/16650 (epoch 13.907), train_loss = 1.26561844, grad/param norm = 2.5813e-01, time/batch = 0.6565s	
4632/16650 (epoch 13.910), train_loss = 1.26190544, grad/param norm = 2.3568e-01, time/batch = 0.6460s	
4633/16650 (epoch 13.913), train_loss = 1.14165528, grad/param norm = 2.4575e-01, time/batch = 0.6411s	
4634/16650 (epoch 13.916), train_loss = 1.24690246, grad/param norm = 2.4136e-01, time/batch = 0.6393s	
4635/16650 (epoch 13.919), train_loss = 1.39178457, grad/param norm = 2.4430e-01, time/batch = 0.6341s	
4636/16650 (epoch 13.922), train_loss = 1.32537346, grad/param norm = 2.3570e-01, time/batch = 0.6369s	
4637/16650 (epoch 13.925), train_loss = 1.15310203, grad/param norm = 2.5259e-01, time/batch = 0.6510s	
4638/16650 (epoch 13.928), train_loss = 1.17425864, grad/param norm = 2.3079e-01, time/batch = 0.6634s	
4639/16650 (epoch 13.931), train_loss = 1.25684434, grad/param norm = 2.3101e-01, time/batch = 0.6583s	
4640/16650 (epoch 13.934), train_loss = 1.07109174, grad/param norm = 2.2615e-01, time/batch = 0.6504s	
4641/16650 (epoch 13.937), train_loss = 1.18302442, grad/param norm = 2.6179e-01, time/batch = 0.6512s	
4642/16650 (epoch 13.940), train_loss = 1.14983941, grad/param norm = 2.0012e-01, time/batch = 0.6398s	
4643/16650 (epoch 13.943), train_loss = 1.20334495, grad/param norm = 2.3453e-01, time/batch = 0.6279s	
4644/16650 (epoch 13.946), train_loss = 1.13262946, grad/param norm = 2.3509e-01, time/batch = 0.6267s	
4645/16650 (epoch 13.949), train_loss = 1.10122787, grad/param norm = 2.5864e-01, time/batch = 0.6284s	
4646/16650 (epoch 13.952), train_loss = 0.97579978, grad/param norm = 2.3548e-01, time/batch = 0.6348s	
4647/16650 (epoch 13.955), train_loss = 1.13833964, grad/param norm = 2.2643e-01, time/batch = 0.6340s	
4648/16650 (epoch 13.958), train_loss = 1.27049172, grad/param norm = 2.5377e-01, time/batch = 0.6413s	
4649/16650 (epoch 13.961), train_loss = 1.15055650, grad/param norm = 2.2543e-01, time/batch = 0.6548s	
4650/16650 (epoch 13.964), train_loss = 1.10822648, grad/param norm = 2.3102e-01, time/batch = 0.6595s	
4651/16650 (epoch 13.967), train_loss = 1.35733389, grad/param norm = 2.5104e-01, time/batch = 0.6760s	
4652/16650 (epoch 13.970), train_loss = 1.05479149, grad/param norm = 2.2490e-01, time/batch = 0.6591s	
4653/16650 (epoch 13.973), train_loss = 1.15297826, grad/param norm = 2.6154e-01, time/batch = 0.6529s	
4654/16650 (epoch 13.976), train_loss = 1.10324635, grad/param norm = 2.3495e-01, time/batch = 0.6368s	
4655/16650 (epoch 13.979), train_loss = 1.23998842, grad/param norm = 2.3532e-01, time/batch = 0.6316s	
4656/16650 (epoch 13.982), train_loss = 1.28652833, grad/param norm = 2.5683e-01, time/batch = 0.6292s	
4657/16650 (epoch 13.985), train_loss = 1.14720902, grad/param norm = 2.2737e-01, time/batch = 0.6324s	
4658/16650 (epoch 13.988), train_loss = 1.40521424, grad/param norm = 2.5498e-01, time/batch = 0.6297s	
4659/16650 (epoch 13.991), train_loss = 1.10779396, grad/param norm = 2.5238e-01, time/batch = 0.6281s	
4660/16650 (epoch 13.994), train_loss = 1.15253698, grad/param norm = 2.3379e-01, time/batch = 0.6267s	
4661/16650 (epoch 13.997), train_loss = 1.21789027, grad/param norm = 2.4521e-01, time/batch = 0.6299s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
4662/16650 (epoch 14.000), train_loss = 1.27153878, grad/param norm = 2.5728e-01, time/batch = 0.6307s	
4663/16650 (epoch 14.003), train_loss = 1.26397708, grad/param norm = 2.5278e-01, time/batch = 0.6397s	
4664/16650 (epoch 14.006), train_loss = 1.31163522, grad/param norm = 2.6009e-01, time/batch = 0.6379s	
4665/16650 (epoch 14.009), train_loss = 1.38756237, grad/param norm = 2.5108e-01, time/batch = 0.6395s	
4666/16650 (epoch 14.012), train_loss = 1.43125859, grad/param norm = 2.6032e-01, time/batch = 0.6426s	
4667/16650 (epoch 14.015), train_loss = 1.20816273, grad/param norm = 3.1409e-01, time/batch = 0.6372s	
4668/16650 (epoch 14.018), train_loss = 0.97153817, grad/param norm = 2.2144e-01, time/batch = 0.6295s	
4669/16650 (epoch 14.021), train_loss = 1.34233431, grad/param norm = 2.8135e-01, time/batch = 0.6289s	
4670/16650 (epoch 14.024), train_loss = 1.17130980, grad/param norm = 2.2849e-01, time/batch = 0.6295s	
4671/16650 (epoch 14.027), train_loss = 1.30911250, grad/param norm = 2.3770e-01, time/batch = 0.6360s	
4672/16650 (epoch 14.030), train_loss = 1.07009319, grad/param norm = 2.2236e-01, time/batch = 0.6368s	
4673/16650 (epoch 14.033), train_loss = 1.19101360, grad/param norm = 2.2372e-01, time/batch = 0.6340s	
4674/16650 (epoch 14.036), train_loss = 1.00417243, grad/param norm = 2.4320e-01, time/batch = 0.6283s	
4675/16650 (epoch 14.039), train_loss = 1.31411520, grad/param norm = 2.5258e-01, time/batch = 0.6287s	
4676/16650 (epoch 14.042), train_loss = 1.29805237, grad/param norm = 2.3881e-01, time/batch = 0.6313s	
4677/16650 (epoch 14.045), train_loss = 1.20845189, grad/param norm = 2.3953e-01, time/batch = 0.6303s	
4678/16650 (epoch 14.048), train_loss = 1.29332317, grad/param norm = 2.5673e-01, time/batch = 0.6297s	
4679/16650 (epoch 14.051), train_loss = 1.22182974, grad/param norm = 2.5226e-01, time/batch = 0.6327s	
4680/16650 (epoch 14.054), train_loss = 1.23322474, grad/param norm = 2.4725e-01, time/batch = 0.6346s	
4681/16650 (epoch 14.057), train_loss = 1.20036774, grad/param norm = 2.4715e-01, time/batch = 0.6415s	
4682/16650 (epoch 14.060), train_loss = 1.07355331, grad/param norm = 2.1941e-01, time/batch = 0.6435s	
4683/16650 (epoch 14.063), train_loss = 1.16307864, grad/param norm = 2.2561e-01, time/batch = 0.6387s	
4684/16650 (epoch 14.066), train_loss = 1.39130143, grad/param norm = 2.4866e-01, time/batch = 0.6301s	
4685/16650 (epoch 14.069), train_loss = 1.31501581, grad/param norm = 2.5562e-01, time/batch = 0.6295s	
4686/16650 (epoch 14.072), train_loss = 1.16634535, grad/param norm = 2.7303e-01, time/batch = 0.6291s	
4687/16650 (epoch 14.075), train_loss = 1.25966262, grad/param norm = 2.4781e-01, time/batch = 0.6319s	
4688/16650 (epoch 14.078), train_loss = 1.32706735, grad/param norm = 2.3286e-01, time/batch = 0.6299s	
4689/16650 (epoch 14.081), train_loss = 1.19486984, grad/param norm = 2.2644e-01, time/batch = 0.6318s	
4690/16650 (epoch 14.084), train_loss = 1.26067739, grad/param norm = 2.3497e-01, time/batch = 0.6299s	
4691/16650 (epoch 14.087), train_loss = 1.19377358, grad/param norm = 2.4342e-01, time/batch = 0.6332s	
4692/16650 (epoch 14.090), train_loss = 1.14003255, grad/param norm = 2.1722e-01, time/batch = 0.6304s	
4693/16650 (epoch 14.093), train_loss = 1.45434989, grad/param norm = 2.5762e-01, time/batch = 0.6288s	
4694/16650 (epoch 14.096), train_loss = 1.18796185, grad/param norm = 2.3683e-01, time/batch = 0.6337s	
4695/16650 (epoch 14.099), train_loss = 1.18823933, grad/param norm = 2.3088e-01, time/batch = 0.6686s	
4696/16650 (epoch 14.102), train_loss = 1.25344507, grad/param norm = 2.5076e-01, time/batch = 0.6465s	
4697/16650 (epoch 14.105), train_loss = 1.29587682, grad/param norm = 2.4239e-01, time/batch = 0.6349s	
4698/16650 (epoch 14.108), train_loss = 1.28888980, grad/param norm = 2.5215e-01, time/batch = 0.6338s	
4699/16650 (epoch 14.111), train_loss = 1.29231292, grad/param norm = 2.3905e-01, time/batch = 0.6507s	
4700/16650 (epoch 14.114), train_loss = 1.35822723, grad/param norm = 2.5266e-01, time/batch = 0.6682s	
4701/16650 (epoch 14.117), train_loss = 1.35781628, grad/param norm = 2.4676e-01, time/batch = 0.6319s	
4702/16650 (epoch 14.120), train_loss = 1.10247828, grad/param norm = 2.1659e-01, time/batch = 0.6305s	
4703/16650 (epoch 14.123), train_loss = 1.20822472, grad/param norm = 2.4104e-01, time/batch = 0.6351s	
4704/16650 (epoch 14.126), train_loss = 1.21907862, grad/param norm = 2.4546e-01, time/batch = 0.6301s	
4705/16650 (epoch 14.129), train_loss = 1.26806775, grad/param norm = 2.3605e-01, time/batch = 0.6323s	
4706/16650 (epoch 14.132), train_loss = 1.27193220, grad/param norm = 2.4661e-01, time/batch = 0.6288s	
4707/16650 (epoch 14.135), train_loss = 1.28501416, grad/param norm = 2.4277e-01, time/batch = 0.6311s	
4708/16650 (epoch 14.138), train_loss = 1.30419356, grad/param norm = 2.4470e-01, time/batch = 0.6301s	
4709/16650 (epoch 14.141), train_loss = 1.31076980, grad/param norm = 2.6993e-01, time/batch = 0.6297s	
4710/16650 (epoch 14.144), train_loss = 1.21593947, grad/param norm = 2.4028e-01, time/batch = 0.6302s	
4711/16650 (epoch 14.147), train_loss = 1.38873002, grad/param norm = 2.3908e-01, time/batch = 0.6390s	
4712/16650 (epoch 14.150), train_loss = 1.47787612, grad/param norm = 2.4488e-01, time/batch = 0.6314s	
4713/16650 (epoch 14.153), train_loss = 1.25097935, grad/param norm = 2.9486e-01, time/batch = 0.6309s	
4714/16650 (epoch 14.156), train_loss = 1.06321005, grad/param norm = 2.0735e-01, time/batch = 0.6329s	
4715/16650 (epoch 14.159), train_loss = 1.32372240, grad/param norm = 2.5573e-01, time/batch = 0.6337s	
4716/16650 (epoch 14.162), train_loss = 1.37181712, grad/param norm = 2.3978e-01, time/batch = 0.6379s	
4717/16650 (epoch 14.165), train_loss = 1.33036354, grad/param norm = 2.4345e-01, time/batch = 0.6323s	
4718/16650 (epoch 14.168), train_loss = 0.99083944, grad/param norm = 2.0603e-01, time/batch = 0.6340s	
4719/16650 (epoch 14.171), train_loss = 1.32912492, grad/param norm = 2.2266e-01, time/batch = 0.6308s	
4720/16650 (epoch 14.174), train_loss = 1.05802104, grad/param norm = 2.4493e-01, time/batch = 0.6293s	
4721/16650 (epoch 14.177), train_loss = 1.21676624, grad/param norm = 2.3584e-01, time/batch = 0.6340s	
4722/16650 (epoch 14.180), train_loss = 1.36603394, grad/param norm = 2.6472e-01, time/batch = 0.6317s	
4723/16650 (epoch 14.183), train_loss = 1.49449695, grad/param norm = 2.8749e-01, time/batch = 0.6318s	
4724/16650 (epoch 14.186), train_loss = 1.32548783, grad/param norm = 2.5619e-01, time/batch = 0.6298s	
4725/16650 (epoch 14.189), train_loss = 1.11063178, grad/param norm = 2.0832e-01, time/batch = 0.6316s	
4726/16650 (epoch 14.192), train_loss = 1.15603451, grad/param norm = 2.4183e-01, time/batch = 0.6302s	
4727/16650 (epoch 14.195), train_loss = 1.20480108, grad/param norm = 2.6530e-01, time/batch = 0.6320s	
4728/16650 (epoch 14.198), train_loss = 1.01229181, grad/param norm = 2.1485e-01, time/batch = 0.6301s	
4729/16650 (epoch 14.201), train_loss = 1.15403642, grad/param norm = 2.3221e-01, time/batch = 0.6295s	
4730/16650 (epoch 14.204), train_loss = 1.21574251, grad/param norm = 2.2702e-01, time/batch = 0.6290s	
4731/16650 (epoch 14.207), train_loss = 1.29077437, grad/param norm = 2.7649e-01, time/batch = 0.6352s	
4732/16650 (epoch 14.210), train_loss = 1.16030847, grad/param norm = 2.2810e-01, time/batch = 0.6344s	
4733/16650 (epoch 14.213), train_loss = 1.28270403, grad/param norm = 2.3724e-01, time/batch = 0.6297s	
4734/16650 (epoch 14.216), train_loss = 1.17335980, grad/param norm = 2.1357e-01, time/batch = 0.6298s	
4735/16650 (epoch 14.219), train_loss = 1.21909786, grad/param norm = 2.4853e-01, time/batch = 0.6297s	
4736/16650 (epoch 14.222), train_loss = 1.23319092, grad/param norm = 2.2678e-01, time/batch = 0.6307s	
4737/16650 (epoch 14.225), train_loss = 1.22035567, grad/param norm = 2.2308e-01, time/batch = 0.6296s	
4738/16650 (epoch 14.228), train_loss = 1.13497441, grad/param norm = 2.4023e-01, time/batch = 0.6309s	
4739/16650 (epoch 14.231), train_loss = 1.19023631, grad/param norm = 2.3188e-01, time/batch = 0.6316s	
4740/16650 (epoch 14.234), train_loss = 1.38730515, grad/param norm = 2.4695e-01, time/batch = 0.6311s	
4741/16650 (epoch 14.237), train_loss = 1.24207540, grad/param norm = 2.4843e-01, time/batch = 0.6404s	
4742/16650 (epoch 14.240), train_loss = 1.25577237, grad/param norm = 2.5026e-01, time/batch = 0.6436s	
4743/16650 (epoch 14.243), train_loss = 1.23962266, grad/param norm = 2.2121e-01, time/batch = 0.6604s	
4744/16650 (epoch 14.246), train_loss = 1.35024794, grad/param norm = 2.5119e-01, time/batch = 0.6719s	
4745/16650 (epoch 14.249), train_loss = 1.09370741, grad/param norm = 2.5629e-01, time/batch = 0.6548s	
4746/16650 (epoch 14.252), train_loss = 1.19473833, grad/param norm = 2.2311e-01, time/batch = 0.6615s	
4747/16650 (epoch 14.255), train_loss = 1.33695763, grad/param norm = 2.4597e-01, time/batch = 0.6443s	
4748/16650 (epoch 14.258), train_loss = 1.34096948, grad/param norm = 2.4083e-01, time/batch = 0.6347s	
4749/16650 (epoch 14.261), train_loss = 1.21658961, grad/param norm = 2.2782e-01, time/batch = 0.6301s	
4750/16650 (epoch 14.264), train_loss = 1.17669430, grad/param norm = 2.4858e-01, time/batch = 0.6279s	
4751/16650 (epoch 14.267), train_loss = 1.17163069, grad/param norm = 2.3598e-01, time/batch = 0.6356s	
4752/16650 (epoch 14.270), train_loss = 1.21841244, grad/param norm = 2.2593e-01, time/batch = 0.6300s	
4753/16650 (epoch 14.273), train_loss = 1.32926966, grad/param norm = 2.1863e-01, time/batch = 0.6290s	
4754/16650 (epoch 14.276), train_loss = 1.23101593, grad/param norm = 2.1793e-01, time/batch = 0.6285s	
4755/16650 (epoch 14.279), train_loss = 1.19214908, grad/param norm = 2.2249e-01, time/batch = 0.6288s	
4756/16650 (epoch 14.282), train_loss = 1.09610254, grad/param norm = 2.2338e-01, time/batch = 0.6323s	
4757/16650 (epoch 14.285), train_loss = 1.09691949, grad/param norm = 2.1510e-01, time/batch = 0.6351s	
4758/16650 (epoch 14.288), train_loss = 1.15773245, grad/param norm = 2.3656e-01, time/batch = 0.6459s	
4759/16650 (epoch 14.291), train_loss = 0.95929173, grad/param norm = 2.0111e-01, time/batch = 0.6433s	
4760/16650 (epoch 14.294), train_loss = 1.04934871, grad/param norm = 1.8915e-01, time/batch = 0.6614s	
4761/16650 (epoch 14.297), train_loss = 1.14867019, grad/param norm = 2.2665e-01, time/batch = 0.6606s	
4762/16650 (epoch 14.300), train_loss = 0.97356634, grad/param norm = 2.0409e-01, time/batch = 0.6648s	
4763/16650 (epoch 14.303), train_loss = 1.02191215, grad/param norm = 1.9226e-01, time/batch = 0.6644s	
4764/16650 (epoch 14.306), train_loss = 1.26207033, grad/param norm = 2.2813e-01, time/batch = 0.6627s	
4765/16650 (epoch 14.309), train_loss = 1.31762310, grad/param norm = 2.4695e-01, time/batch = 0.6616s	
4766/16650 (epoch 14.312), train_loss = 1.09383454, grad/param norm = 2.3146e-01, time/batch = 0.6525s	
4767/16650 (epoch 14.315), train_loss = 0.88852415, grad/param norm = 1.8644e-01, time/batch = 0.6538s	
4768/16650 (epoch 14.318), train_loss = 0.96902550, grad/param norm = 2.1244e-01, time/batch = 0.6667s	
4769/16650 (epoch 14.321), train_loss = 1.38378368, grad/param norm = 2.6553e-01, time/batch = 0.6582s	
4770/16650 (epoch 14.324), train_loss = 1.13408364, grad/param norm = 2.7153e-01, time/batch = 0.6303s	
4771/16650 (epoch 14.327), train_loss = 1.35440948, grad/param norm = 3.0450e-01, time/batch = 0.6309s	
4772/16650 (epoch 14.330), train_loss = 1.27162557, grad/param norm = 2.6297e-01, time/batch = 0.6304s	
4773/16650 (epoch 14.333), train_loss = 1.29460298, grad/param norm = 2.8405e-01, time/batch = 0.6361s	
4774/16650 (epoch 14.336), train_loss = 1.09785567, grad/param norm = 2.4029e-01, time/batch = 0.6491s	
4775/16650 (epoch 14.339), train_loss = 1.18707741, grad/param norm = 2.3660e-01, time/batch = 0.6344s	
4776/16650 (epoch 14.342), train_loss = 1.15813309, grad/param norm = 2.4971e-01, time/batch = 0.6304s	
4777/16650 (epoch 14.345), train_loss = 1.04615148, grad/param norm = 2.1543e-01, time/batch = 0.6315s	
4778/16650 (epoch 14.348), train_loss = 1.21884850, grad/param norm = 2.4249e-01, time/batch = 0.6308s	
4779/16650 (epoch 14.351), train_loss = 1.26886167, grad/param norm = 2.3827e-01, time/batch = 0.6424s	
4780/16650 (epoch 14.354), train_loss = 1.35435058, grad/param norm = 2.6944e-01, time/batch = 0.6339s	
4781/16650 (epoch 14.357), train_loss = 1.25189954, grad/param norm = 2.4211e-01, time/batch = 0.6358s	
4782/16650 (epoch 14.360), train_loss = 1.25372827, grad/param norm = 2.3244e-01, time/batch = 0.6370s	
4783/16650 (epoch 14.363), train_loss = 1.35565484, grad/param norm = 2.6017e-01, time/batch = 0.6306s	
4784/16650 (epoch 14.366), train_loss = 1.40758301, grad/param norm = 2.5593e-01, time/batch = 0.6344s	
4785/16650 (epoch 14.369), train_loss = 1.21870034, grad/param norm = 2.3533e-01, time/batch = 0.6363s	
4786/16650 (epoch 14.372), train_loss = 1.21290457, grad/param norm = 2.2692e-01, time/batch = 0.6330s	
4787/16650 (epoch 14.375), train_loss = 1.19942853, grad/param norm = 2.2644e-01, time/batch = 0.6302s	
4788/16650 (epoch 14.378), train_loss = 1.07694973, grad/param norm = 2.1843e-01, time/batch = 0.6298s	
4789/16650 (epoch 14.381), train_loss = 1.25101454, grad/param norm = 2.4104e-01, time/batch = 0.6323s	
4790/16650 (epoch 14.384), train_loss = 1.34782247, grad/param norm = 2.3912e-01, time/batch = 0.6341s	
4791/16650 (epoch 14.387), train_loss = 0.95972168, grad/param norm = 2.0490e-01, time/batch = 0.6382s	
4792/16650 (epoch 14.390), train_loss = 1.29031897, grad/param norm = 2.4121e-01, time/batch = 0.6304s	
4793/16650 (epoch 14.393), train_loss = 1.20379289, grad/param norm = 2.5222e-01, time/batch = 0.6303s	
4794/16650 (epoch 14.396), train_loss = 1.35290646, grad/param norm = 2.5013e-01, time/batch = 0.6291s	
4795/16650 (epoch 14.399), train_loss = 1.25950454, grad/param norm = 2.5269e-01, time/batch = 0.6292s	
4796/16650 (epoch 14.402), train_loss = 1.10765706, grad/param norm = 2.2557e-01, time/batch = 0.6290s	
4797/16650 (epoch 14.405), train_loss = 1.03869217, grad/param norm = 2.3434e-01, time/batch = 0.6291s	
4798/16650 (epoch 14.408), train_loss = 1.33301356, grad/param norm = 2.4273e-01, time/batch = 0.6297s	
4799/16650 (epoch 14.411), train_loss = 1.07936062, grad/param norm = 2.4023e-01, time/batch = 0.6316s	
4800/16650 (epoch 14.414), train_loss = 1.06988956, grad/param norm = 2.3506e-01, time/batch = 0.6280s	
4801/16650 (epoch 14.417), train_loss = 1.03337162, grad/param norm = 2.0341e-01, time/batch = 0.6319s	
4802/16650 (epoch 14.420), train_loss = 1.03109704, grad/param norm = 2.3810e-01, time/batch = 0.6348s	
4803/16650 (epoch 14.423), train_loss = 0.84235252, grad/param norm = 1.8106e-01, time/batch = 0.6312s	
4804/16650 (epoch 14.426), train_loss = 1.06711015, grad/param norm = 2.5238e-01, time/batch = 0.6292s	
4805/16650 (epoch 14.429), train_loss = 1.30205563, grad/param norm = 2.5659e-01, time/batch = 0.6316s	
4806/16650 (epoch 14.432), train_loss = 1.27928377, grad/param norm = 2.5784e-01, time/batch = 0.6326s	
4807/16650 (epoch 14.435), train_loss = 1.41808432, grad/param norm = 2.4581e-01, time/batch = 0.6342s	
4808/16650 (epoch 14.438), train_loss = 1.39949528, grad/param norm = 2.7630e-01, time/batch = 0.6325s	
4809/16650 (epoch 14.441), train_loss = 1.23609257, grad/param norm = 2.6398e-01, time/batch = 0.6286s	
4810/16650 (epoch 14.444), train_loss = 1.13507904, grad/param norm = 2.3745e-01, time/batch = 0.6283s	
4811/16650 (epoch 14.447), train_loss = 1.16927121, grad/param norm = 2.1935e-01, time/batch = 0.6314s	
4812/16650 (epoch 14.450), train_loss = 1.09904662, grad/param norm = 2.4249e-01, time/batch = 0.6294s	
4813/16650 (epoch 14.453), train_loss = 1.13224329, grad/param norm = 2.2352e-01, time/batch = 0.6290s	
4814/16650 (epoch 14.456), train_loss = 1.03352310, grad/param norm = 2.2221e-01, time/batch = 0.6306s	
4815/16650 (epoch 14.459), train_loss = 1.10270133, grad/param norm = 2.3361e-01, time/batch = 0.6333s	
4816/16650 (epoch 14.462), train_loss = 1.36298429, grad/param norm = 2.7629e-01, time/batch = 0.6320s	
4817/16650 (epoch 14.465), train_loss = 1.13790039, grad/param norm = 2.4801e-01, time/batch = 0.6313s	
4818/16650 (epoch 14.468), train_loss = 0.90162908, grad/param norm = 2.0993e-01, time/batch = 0.6291s	
4819/16650 (epoch 14.471), train_loss = 0.80060496, grad/param norm = 1.8712e-01, time/batch = 0.6297s	
4820/16650 (epoch 14.474), train_loss = 1.03361310, grad/param norm = 2.0332e-01, time/batch = 0.6366s	
4821/16650 (epoch 14.477), train_loss = 1.21357921, grad/param norm = 2.4098e-01, time/batch = 0.6414s	
4822/16650 (epoch 14.480), train_loss = 1.23413728, grad/param norm = 2.5665e-01, time/batch = 0.6355s	
4823/16650 (epoch 14.483), train_loss = 1.37850771, grad/param norm = 2.4211e-01, time/batch = 0.6330s	
4824/16650 (epoch 14.486), train_loss = 1.07673448, grad/param norm = 2.1929e-01, time/batch = 0.6299s	
4825/16650 (epoch 14.489), train_loss = 1.11513814, grad/param norm = 2.3243e-01, time/batch = 0.6314s	
4826/16650 (epoch 14.492), train_loss = 1.18332410, grad/param norm = 2.3673e-01, time/batch = 0.6279s	
4827/16650 (epoch 14.495), train_loss = 1.08218589, grad/param norm = 2.5205e-01, time/batch = 0.6284s	
4828/16650 (epoch 14.498), train_loss = 1.16797324, grad/param norm = 2.2659e-01, time/batch = 0.6293s	
4829/16650 (epoch 14.502), train_loss = 1.38974503, grad/param norm = 2.5420e-01, time/batch = 0.6282s	
4830/16650 (epoch 14.505), train_loss = 1.25742964, grad/param norm = 2.3056e-01, time/batch = 0.6310s	
4831/16650 (epoch 14.508), train_loss = 1.22942411, grad/param norm = 2.2793e-01, time/batch = 0.6708s	
4832/16650 (epoch 14.511), train_loss = 1.30549102, grad/param norm = 2.4649e-01, time/batch = 0.6492s	
4833/16650 (epoch 14.514), train_loss = 1.02789541, grad/param norm = 2.2253e-01, time/batch = 0.6310s	
4834/16650 (epoch 14.517), train_loss = 1.15923275, grad/param norm = 2.4282e-01, time/batch = 0.6383s	
4835/16650 (epoch 14.520), train_loss = 1.15014921, grad/param norm = 2.3517e-01, time/batch = 0.6378s	
4836/16650 (epoch 14.523), train_loss = 1.11509237, grad/param norm = 2.1957e-01, time/batch = 0.6350s	
4837/16650 (epoch 14.526), train_loss = 1.24500239, grad/param norm = 2.2320e-01, time/batch = 0.6441s	
4838/16650 (epoch 14.529), train_loss = 1.37085661, grad/param norm = 2.7079e-01, time/batch = 0.6677s	
4839/16650 (epoch 14.532), train_loss = 0.94375948, grad/param norm = 2.0708e-01, time/batch = 0.6450s	
4840/16650 (epoch 14.535), train_loss = 1.03097418, grad/param norm = 2.2691e-01, time/batch = 0.6445s	
4841/16650 (epoch 14.538), train_loss = 1.05467172, grad/param norm = 2.3012e-01, time/batch = 0.6447s	
4842/16650 (epoch 14.541), train_loss = 1.31085424, grad/param norm = 2.4818e-01, time/batch = 0.6303s	
4843/16650 (epoch 14.544), train_loss = 1.35501852, grad/param norm = 2.6875e-01, time/batch = 0.6265s	
4844/16650 (epoch 14.547), train_loss = 1.06353441, grad/param norm = 2.2544e-01, time/batch = 0.6282s	
4845/16650 (epoch 14.550), train_loss = 1.09993180, grad/param norm = 2.3185e-01, time/batch = 0.6289s	
4846/16650 (epoch 14.553), train_loss = 1.14921028, grad/param norm = 2.5057e-01, time/batch = 0.6288s	
4847/16650 (epoch 14.556), train_loss = 1.08923025, grad/param norm = 2.0444e-01, time/batch = 0.6279s	
4848/16650 (epoch 14.559), train_loss = 0.95374908, grad/param norm = 1.9194e-01, time/batch = 0.6294s	
4849/16650 (epoch 14.562), train_loss = 1.13038397, grad/param norm = 2.2926e-01, time/batch = 0.6291s	
4850/16650 (epoch 14.565), train_loss = 0.92134023, grad/param norm = 2.1087e-01, time/batch = 0.6297s	
4851/16650 (epoch 14.568), train_loss = 0.95178708, grad/param norm = 2.0519e-01, time/batch = 0.6315s	
4852/16650 (epoch 14.571), train_loss = 0.98494729, grad/param norm = 2.4426e-01, time/batch = 0.6372s	
4853/16650 (epoch 14.574), train_loss = 1.12387177, grad/param norm = 2.3688e-01, time/batch = 0.6335s	
4854/16650 (epoch 14.577), train_loss = 1.08709069, grad/param norm = 2.1598e-01, time/batch = 0.6361s	
4855/16650 (epoch 14.580), train_loss = 0.99447301, grad/param norm = 2.1804e-01, time/batch = 0.6384s	
4856/16650 (epoch 14.583), train_loss = 1.12235985, grad/param norm = 2.3712e-01, time/batch = 0.6397s	
4857/16650 (epoch 14.586), train_loss = 1.10634542, grad/param norm = 2.7467e-01, time/batch = 0.6305s	
4858/16650 (epoch 14.589), train_loss = 0.99193944, grad/param norm = 2.1325e-01, time/batch = 0.6338s	
4859/16650 (epoch 14.592), train_loss = 1.15763025, grad/param norm = 2.3286e-01, time/batch = 0.6351s	
4860/16650 (epoch 14.595), train_loss = 1.04948712, grad/param norm = 2.2194e-01, time/batch = 0.6298s	
4861/16650 (epoch 14.598), train_loss = 1.08491209, grad/param norm = 2.3552e-01, time/batch = 0.6401s	
4862/16650 (epoch 14.601), train_loss = 1.05721897, grad/param norm = 2.7548e-01, time/batch = 0.6449s	
4863/16650 (epoch 14.604), train_loss = 1.23731128, grad/param norm = 2.6231e-01, time/batch = 0.6538s	
4864/16650 (epoch 14.607), train_loss = 1.20405154, grad/param norm = 2.4701e-01, time/batch = 0.6379s	
4865/16650 (epoch 14.610), train_loss = 1.02290818, grad/param norm = 2.0200e-01, time/batch = 0.6382s	
4866/16650 (epoch 14.613), train_loss = 1.26546288, grad/param norm = 2.3825e-01, time/batch = 0.6385s	
4867/16650 (epoch 14.616), train_loss = 1.29141594, grad/param norm = 2.7025e-01, time/batch = 0.6369s	
4868/16650 (epoch 14.619), train_loss = 0.98351683, grad/param norm = 2.1662e-01, time/batch = 0.6309s	
4869/16650 (epoch 14.622), train_loss = 0.93993686, grad/param norm = 2.1024e-01, time/batch = 0.6301s	
4870/16650 (epoch 14.625), train_loss = 1.07517332, grad/param norm = 2.2420e-01, time/batch = 0.6336s	
4871/16650 (epoch 14.628), train_loss = 1.11101870, grad/param norm = 2.4912e-01, time/batch = 0.6320s	
4872/16650 (epoch 14.631), train_loss = 1.15677680, grad/param norm = 2.6156e-01, time/batch = 0.6305s	
4873/16650 (epoch 14.634), train_loss = 1.41166623, grad/param norm = 2.8667e-01, time/batch = 0.6318s	
4874/16650 (epoch 14.637), train_loss = 1.37335967, grad/param norm = 2.4037e-01, time/batch = 0.6318s	
4875/16650 (epoch 14.640), train_loss = 1.08085105, grad/param norm = 2.3549e-01, time/batch = 0.6362s	
4876/16650 (epoch 14.643), train_loss = 1.24437475, grad/param norm = 2.3727e-01, time/batch = 0.6392s	
4877/16650 (epoch 14.646), train_loss = 1.20473262, grad/param norm = 2.3376e-01, time/batch = 0.6425s	
4878/16650 (epoch 14.649), train_loss = 1.18440065, grad/param norm = 2.5195e-01, time/batch = 0.6347s	
4879/16650 (epoch 14.652), train_loss = 1.29646120, grad/param norm = 2.6577e-01, time/batch = 0.6358s	
4880/16650 (epoch 14.655), train_loss = 1.20232872, grad/param norm = 2.7429e-01, time/batch = 0.6313s	
4881/16650 (epoch 14.658), train_loss = 1.06210166, grad/param norm = 2.4741e-01, time/batch = 0.6336s	
4882/16650 (epoch 14.661), train_loss = 1.25073326, grad/param norm = 2.4248e-01, time/batch = 0.6339s	
4883/16650 (epoch 14.664), train_loss = 1.15592317, grad/param norm = 2.3867e-01, time/batch = 0.6376s	
4884/16650 (epoch 14.667), train_loss = 1.28917833, grad/param norm = 2.3273e-01, time/batch = 0.6300s	
4885/16650 (epoch 14.670), train_loss = 1.00750248, grad/param norm = 2.2898e-01, time/batch = 0.6304s	
4886/16650 (epoch 14.673), train_loss = 1.06587125, grad/param norm = 2.0057e-01, time/batch = 0.6291s	
4887/16650 (epoch 14.676), train_loss = 1.15382085, grad/param norm = 2.4949e-01, time/batch = 0.6296s	
4888/16650 (epoch 14.679), train_loss = 1.04430888, grad/param norm = 2.4904e-01, time/batch = 0.6350s	
4889/16650 (epoch 14.682), train_loss = 1.19862231, grad/param norm = 2.3497e-01, time/batch = 0.6683s	
4890/16650 (epoch 14.685), train_loss = 0.99169838, grad/param norm = 2.3561e-01, time/batch = 0.6428s	
4891/16650 (epoch 14.688), train_loss = 1.17975680, grad/param norm = 2.3622e-01, time/batch = 0.6323s	
4892/16650 (epoch 14.691), train_loss = 1.18508610, grad/param norm = 2.3263e-01, time/batch = 0.6363s	
4893/16650 (epoch 14.694), train_loss = 1.00677107, grad/param norm = 2.1336e-01, time/batch = 0.6556s	
4894/16650 (epoch 14.697), train_loss = 1.02710096, grad/param norm = 2.2341e-01, time/batch = 0.6682s	
4895/16650 (epoch 14.700), train_loss = 1.24308080, grad/param norm = 2.3982e-01, time/batch = 0.6388s	
4896/16650 (epoch 14.703), train_loss = 1.03986072, grad/param norm = 2.2112e-01, time/batch = 0.6532s	
4897/16650 (epoch 14.706), train_loss = 1.23820735, grad/param norm = 2.6140e-01, time/batch = 0.6504s	
4898/16650 (epoch 14.709), train_loss = 1.05920803, grad/param norm = 2.1049e-01, time/batch = 0.6450s	
4899/16650 (epoch 14.712), train_loss = 1.06282116, grad/param norm = 2.6046e-01, time/batch = 0.6523s	
4900/16650 (epoch 14.715), train_loss = 1.29140058, grad/param norm = 2.3594e-01, time/batch = 0.6601s	
4901/16650 (epoch 14.718), train_loss = 1.30548100, grad/param norm = 2.4263e-01, time/batch = 0.6479s	
4902/16650 (epoch 14.721), train_loss = 1.28045080, grad/param norm = 2.5743e-01, time/batch = 0.6421s	
4903/16650 (epoch 14.724), train_loss = 1.28986814, grad/param norm = 2.6850e-01, time/batch = 0.6358s	
4904/16650 (epoch 14.727), train_loss = 1.23685257, grad/param norm = 2.2925e-01, time/batch = 0.6298s	
4905/16650 (epoch 14.730), train_loss = 1.12676327, grad/param norm = 2.2976e-01, time/batch = 0.6301s	
4906/16650 (epoch 14.733), train_loss = 1.27241793, grad/param norm = 2.5195e-01, time/batch = 0.6323s	
4907/16650 (epoch 14.736), train_loss = 0.98381471, grad/param norm = 2.1381e-01, time/batch = 0.6297s	
4908/16650 (epoch 14.739), train_loss = 1.16439166, grad/param norm = 2.4426e-01, time/batch = 0.6305s	
4909/16650 (epoch 14.742), train_loss = 1.19760733, grad/param norm = 2.6155e-01, time/batch = 0.6296s	
4910/16650 (epoch 14.745), train_loss = 0.96597839, grad/param norm = 2.0959e-01, time/batch = 0.6279s	
4911/16650 (epoch 14.748), train_loss = 1.03964441, grad/param norm = 2.4799e-01, time/batch = 0.6304s	
4912/16650 (epoch 14.751), train_loss = 1.21998540, grad/param norm = 2.9668e-01, time/batch = 0.6320s	
4913/16650 (epoch 14.754), train_loss = 1.33674778, grad/param norm = 2.6902e-01, time/batch = 0.6309s	
4914/16650 (epoch 14.757), train_loss = 1.26693384, grad/param norm = 2.3028e-01, time/batch = 0.6319s	
4915/16650 (epoch 14.760), train_loss = 1.12647158, grad/param norm = 2.3980e-01, time/batch = 0.6303s	
4916/16650 (epoch 14.763), train_loss = 1.06641662, grad/param norm = 2.4081e-01, time/batch = 0.6317s	
4917/16650 (epoch 14.766), train_loss = 1.15915106, grad/param norm = 2.1688e-01, time/batch = 0.6308s	
4918/16650 (epoch 14.769), train_loss = 1.17789199, grad/param norm = 2.3579e-01, time/batch = 0.6301s	
4919/16650 (epoch 14.772), train_loss = 1.09749875, grad/param norm = 2.1218e-01, time/batch = 0.6286s	
4920/16650 (epoch 14.775), train_loss = 1.14720828, grad/param norm = 2.2685e-01, time/batch = 0.6283s	
4921/16650 (epoch 14.778), train_loss = 1.15704091, grad/param norm = 2.2958e-01, time/batch = 0.6311s	
4922/16650 (epoch 14.781), train_loss = 1.26684670, grad/param norm = 2.3907e-01, time/batch = 0.6291s	
4923/16650 (epoch 14.784), train_loss = 1.24519266, grad/param norm = 2.5907e-01, time/batch = 0.6313s	
4924/16650 (epoch 14.787), train_loss = 1.26020138, grad/param norm = 2.4010e-01, time/batch = 0.6307s	
4925/16650 (epoch 14.790), train_loss = 1.19511960, grad/param norm = 2.2418e-01, time/batch = 0.6354s	
4926/16650 (epoch 14.793), train_loss = 1.04500350, grad/param norm = 2.3371e-01, time/batch = 0.6302s	
4927/16650 (epoch 14.796), train_loss = 1.50941384, grad/param norm = 2.6469e-01, time/batch = 0.6278s	
4928/16650 (epoch 14.799), train_loss = 1.38556494, grad/param norm = 2.4020e-01, time/batch = 0.6329s	
4929/16650 (epoch 14.802), train_loss = 1.20212606, grad/param norm = 2.4739e-01, time/batch = 0.6379s	
4930/16650 (epoch 14.805), train_loss = 1.15622209, grad/param norm = 2.2188e-01, time/batch = 0.6517s	
4931/16650 (epoch 14.808), train_loss = 1.19311120, grad/param norm = 2.3569e-01, time/batch = 0.6587s	
4932/16650 (epoch 14.811), train_loss = 1.32127075, grad/param norm = 2.3087e-01, time/batch = 0.6506s	
4933/16650 (epoch 14.814), train_loss = 1.05428576, grad/param norm = 2.2101e-01, time/batch = 0.6378s	
4934/16650 (epoch 14.817), train_loss = 1.13673973, grad/param norm = 2.5306e-01, time/batch = 0.6333s	
4935/16650 (epoch 14.820), train_loss = 1.21892452, grad/param norm = 2.4090e-01, time/batch = 0.6293s	
4936/16650 (epoch 14.823), train_loss = 1.08001285, grad/param norm = 2.1000e-01, time/batch = 0.6295s	
4937/16650 (epoch 14.826), train_loss = 1.16962306, grad/param norm = 2.1949e-01, time/batch = 0.6347s	
4938/16650 (epoch 14.829), train_loss = 1.29326207, grad/param norm = 2.3797e-01, time/batch = 0.6451s	
4939/16650 (epoch 14.832), train_loss = 1.30744329, grad/param norm = 2.5352e-01, time/batch = 0.6508s	
4940/16650 (epoch 14.835), train_loss = 1.26400400, grad/param norm = 2.5737e-01, time/batch = 0.6434s	
4941/16650 (epoch 14.838), train_loss = 1.06564126, grad/param norm = 2.3836e-01, time/batch = 0.6355s	
4942/16650 (epoch 14.841), train_loss = 1.09294345, grad/param norm = 2.1368e-01, time/batch = 0.6321s	
4943/16650 (epoch 14.844), train_loss = 1.10044320, grad/param norm = 2.2295e-01, time/batch = 0.6327s	
4944/16650 (epoch 14.847), train_loss = 1.26748004, grad/param norm = 2.5000e-01, time/batch = 0.6288s	
4945/16650 (epoch 14.850), train_loss = 1.04978824, grad/param norm = 2.4947e-01, time/batch = 0.6281s	
4946/16650 (epoch 14.853), train_loss = 1.22899980, grad/param norm = 2.4370e-01, time/batch = 0.6353s	
4947/16650 (epoch 14.856), train_loss = 1.06895245, grad/param norm = 2.3480e-01, time/batch = 0.6350s	
4948/16650 (epoch 14.859), train_loss = 1.25364366, grad/param norm = 2.5117e-01, time/batch = 0.6371s	
4949/16650 (epoch 14.862), train_loss = 1.17273792, grad/param norm = 2.3918e-01, time/batch = 0.6351s	
4950/16650 (epoch 14.865), train_loss = 0.96583514, grad/param norm = 2.0345e-01, time/batch = 0.6428s	
4951/16650 (epoch 14.868), train_loss = 1.24137874, grad/param norm = 2.4861e-01, time/batch = 0.6579s	
4952/16650 (epoch 14.871), train_loss = 1.23890826, grad/param norm = 2.3868e-01, time/batch = 0.6399s	
4953/16650 (epoch 14.874), train_loss = 1.22032152, grad/param norm = 2.3797e-01, time/batch = 0.6303s	
4954/16650 (epoch 14.877), train_loss = 1.11897621, grad/param norm = 2.1992e-01, time/batch = 0.6319s	
4955/16650 (epoch 14.880), train_loss = 1.10947014, grad/param norm = 2.3993e-01, time/batch = 0.6395s	
4956/16650 (epoch 14.883), train_loss = 1.21812848, grad/param norm = 2.6171e-01, time/batch = 0.6693s	
4957/16650 (epoch 14.886), train_loss = 1.19239767, grad/param norm = 2.4197e-01, time/batch = 0.6579s	
4958/16650 (epoch 14.889), train_loss = 1.02738337, grad/param norm = 2.2994e-01, time/batch = 0.6334s	
4959/16650 (epoch 14.892), train_loss = 1.13558684, grad/param norm = 2.2762e-01, time/batch = 0.6373s	
4960/16650 (epoch 14.895), train_loss = 1.27828328, grad/param norm = 2.6828e-01, time/batch = 0.6437s	
4961/16650 (epoch 14.898), train_loss = 1.23284114, grad/param norm = 2.2849e-01, time/batch = 0.6444s	
4962/16650 (epoch 14.901), train_loss = 1.18507913, grad/param norm = 2.1840e-01, time/batch = 0.6565s	
4963/16650 (epoch 14.904), train_loss = 1.10462528, grad/param norm = 2.4836e-01, time/batch = 0.6592s	
4964/16650 (epoch 14.907), train_loss = 1.23338751, grad/param norm = 2.5683e-01, time/batch = 0.6593s	
4965/16650 (epoch 14.910), train_loss = 1.22348304, grad/param norm = 2.4240e-01, time/batch = 0.6589s	
4966/16650 (epoch 14.913), train_loss = 1.11092378, grad/param norm = 2.4815e-01, time/batch = 0.6587s	
4967/16650 (epoch 14.916), train_loss = 1.20203565, grad/param norm = 2.3745e-01, time/batch = 0.6537s	
4968/16650 (epoch 14.919), train_loss = 1.35088310, grad/param norm = 2.4053e-01, time/batch = 0.6472s	
4969/16650 (epoch 14.922), train_loss = 1.28606169, grad/param norm = 2.3626e-01, time/batch = 0.6395s	
4970/16650 (epoch 14.925), train_loss = 1.11174712, grad/param norm = 2.4794e-01, time/batch = 0.6412s	
4971/16650 (epoch 14.928), train_loss = 1.13959235, grad/param norm = 2.3411e-01, time/batch = 0.6321s	
4972/16650 (epoch 14.931), train_loss = 1.22582042, grad/param norm = 2.2903e-01, time/batch = 0.6295s	
4973/16650 (epoch 14.934), train_loss = 1.03957742, grad/param norm = 2.3605e-01, time/batch = 0.6299s	
4974/16650 (epoch 14.937), train_loss = 1.14021453, grad/param norm = 2.7307e-01, time/batch = 0.6301s	
4975/16650 (epoch 14.940), train_loss = 1.12242317, grad/param norm = 2.0939e-01, time/batch = 0.6317s	
4976/16650 (epoch 14.943), train_loss = 1.17769219, grad/param norm = 2.3992e-01, time/batch = 0.6305s	
4977/16650 (epoch 14.946), train_loss = 1.10066728, grad/param norm = 2.3434e-01, time/batch = 0.6305s	
4978/16650 (epoch 14.949), train_loss = 1.05478818, grad/param norm = 2.2872e-01, time/batch = 0.6333s	
4979/16650 (epoch 14.952), train_loss = 0.95031214, grad/param norm = 2.2340e-01, time/batch = 0.6377s	
4980/16650 (epoch 14.955), train_loss = 1.09972299, grad/param norm = 2.2694e-01, time/batch = 0.6290s	
4981/16650 (epoch 14.958), train_loss = 1.22808521, grad/param norm = 2.3757e-01, time/batch = 0.6319s	
4982/16650 (epoch 14.961), train_loss = 1.12818604, grad/param norm = 2.2650e-01, time/batch = 0.6302s	
4983/16650 (epoch 14.964), train_loss = 1.07353715, grad/param norm = 2.4286e-01, time/batch = 0.6326s	
4984/16650 (epoch 14.967), train_loss = 1.31284822, grad/param norm = 2.4930e-01, time/batch = 0.6368s	
4985/16650 (epoch 14.970), train_loss = 1.02761156, grad/param norm = 2.1821e-01, time/batch = 0.6303s	
4986/16650 (epoch 14.973), train_loss = 1.11643683, grad/param norm = 2.6470e-01, time/batch = 0.6297s	
4987/16650 (epoch 14.976), train_loss = 1.06232480, grad/param norm = 2.3211e-01, time/batch = 0.6286s	
4988/16650 (epoch 14.979), train_loss = 1.20984171, grad/param norm = 2.4914e-01, time/batch = 0.6280s	
4989/16650 (epoch 14.982), train_loss = 1.25835288, grad/param norm = 2.5719e-01, time/batch = 0.6345s	
4990/16650 (epoch 14.985), train_loss = 1.11317681, grad/param norm = 2.2213e-01, time/batch = 0.6662s	
4991/16650 (epoch 14.988), train_loss = 1.35974733, grad/param norm = 2.5731e-01, time/batch = 0.6536s	
4992/16650 (epoch 14.991), train_loss = 1.07626139, grad/param norm = 2.4873e-01, time/batch = 0.6331s	
4993/16650 (epoch 14.994), train_loss = 1.12313602, grad/param norm = 2.5185e-01, time/batch = 0.6283s	
4994/16650 (epoch 14.997), train_loss = 1.17350325, grad/param norm = 2.4111e-01, time/batch = 0.6400s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
4995/16650 (epoch 15.000), train_loss = 1.22988582, grad/param norm = 2.4601e-01, time/batch = 0.6683s	
4996/16650 (epoch 15.003), train_loss = 1.22629057, grad/param norm = 2.5572e-01, time/batch = 0.6367s	
4997/16650 (epoch 15.006), train_loss = 1.26455083, grad/param norm = 2.5007e-01, time/batch = 0.6312s	
4998/16650 (epoch 15.009), train_loss = 1.35019253, grad/param norm = 2.5443e-01, time/batch = 0.6284s	
4999/16650 (epoch 15.012), train_loss = 1.37808463, grad/param norm = 2.6089e-01, time/batch = 0.6299s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch15.02_1.7952.t7	
5000/16650 (epoch 15.015), train_loss = 1.16945403, grad/param norm = 2.6182e-01, time/batch = 0.6314s	
5001/16650 (epoch 15.018), train_loss = 1.28373324, grad/param norm = 2.5830e-01, time/batch = 0.6380s	
5002/16650 (epoch 15.021), train_loss = 1.29356097, grad/param norm = 2.8583e-01, time/batch = 0.6441s	
5003/16650 (epoch 15.024), train_loss = 1.15321623, grad/param norm = 2.4340e-01, time/batch = 0.6421s	
5004/16650 (epoch 15.027), train_loss = 1.27241483, grad/param norm = 2.4109e-01, time/batch = 0.6604s	
5005/16650 (epoch 15.030), train_loss = 1.04263580, grad/param norm = 2.3007e-01, time/batch = 0.6378s	
5006/16650 (epoch 15.033), train_loss = 1.16539071, grad/param norm = 2.3291e-01, time/batch = 0.6357s	
5007/16650 (epoch 15.036), train_loss = 0.96915363, grad/param norm = 2.4475e-01, time/batch = 0.6333s	
5008/16650 (epoch 15.039), train_loss = 1.28239153, grad/param norm = 2.5763e-01, time/batch = 0.6305s	
5009/16650 (epoch 15.042), train_loss = 1.25862445, grad/param norm = 2.4284e-01, time/batch = 0.6289s	
5010/16650 (epoch 15.045), train_loss = 1.17922078, grad/param norm = 2.4942e-01, time/batch = 0.6285s	
5011/16650 (epoch 15.048), train_loss = 1.25127124, grad/param norm = 2.5650e-01, time/batch = 0.6359s	
5012/16650 (epoch 15.051), train_loss = 1.19333036, grad/param norm = 2.5585e-01, time/batch = 0.6391s	
5013/16650 (epoch 15.054), train_loss = 1.20557960, grad/param norm = 2.5109e-01, time/batch = 0.6351s	
5014/16650 (epoch 15.057), train_loss = 1.17386368, grad/param norm = 2.5405e-01, time/batch = 0.6330s	
5015/16650 (epoch 15.060), train_loss = 1.04100184, grad/param norm = 2.2653e-01, time/batch = 0.6290s	
5016/16650 (epoch 15.063), train_loss = 1.13316388, grad/param norm = 2.3796e-01, time/batch = 0.6319s	
5017/16650 (epoch 15.066), train_loss = 1.34705009, grad/param norm = 2.4511e-01, time/batch = 0.6342s	
5018/16650 (epoch 15.069), train_loss = 1.27548924, grad/param norm = 2.5534e-01, time/batch = 0.6395s	
5019/16650 (epoch 15.072), train_loss = 1.12428502, grad/param norm = 2.4968e-01, time/batch = 0.6507s	
5020/16650 (epoch 15.075), train_loss = 1.23459827, grad/param norm = 2.4717e-01, time/batch = 0.6527s	
5021/16650 (epoch 15.078), train_loss = 1.29224878, grad/param norm = 2.4256e-01, time/batch = 0.6560s	
5022/16650 (epoch 15.081), train_loss = 1.16229219, grad/param norm = 2.2890e-01, time/batch = 0.6342s	
5023/16650 (epoch 15.084), train_loss = 1.22045263, grad/param norm = 2.2897e-01, time/batch = 0.6410s	
5024/16650 (epoch 15.087), train_loss = 1.15837758, grad/param norm = 2.3548e-01, time/batch = 0.6621s	
5025/16650 (epoch 15.090), train_loss = 1.12026229, grad/param norm = 2.1920e-01, time/batch = 0.6545s	
5026/16650 (epoch 15.093), train_loss = 1.40102101, grad/param norm = 2.4918e-01, time/batch = 0.6279s	
5027/16650 (epoch 15.096), train_loss = 1.14698860, grad/param norm = 2.3141e-01, time/batch = 0.6308s	
5028/16650 (epoch 15.099), train_loss = 1.15207813, grad/param norm = 2.1838e-01, time/batch = 0.6379s	
5029/16650 (epoch 15.102), train_loss = 1.21995509, grad/param norm = 2.4962e-01, time/batch = 0.6689s	
5030/16650 (epoch 15.105), train_loss = 1.26433586, grad/param norm = 2.3898e-01, time/batch = 0.6490s	
5031/16650 (epoch 15.108), train_loss = 1.24209180, grad/param norm = 2.4329e-01, time/batch = 0.6377s	
5032/16650 (epoch 15.111), train_loss = 1.25750889, grad/param norm = 2.3156e-01, time/batch = 0.6320s	
5033/16650 (epoch 15.114), train_loss = 1.31228205, grad/param norm = 2.4994e-01, time/batch = 0.6340s	
5034/16650 (epoch 15.117), train_loss = 1.32255529, grad/param norm = 2.4907e-01, time/batch = 0.6316s	
5035/16650 (epoch 15.120), train_loss = 1.06810762, grad/param norm = 2.0968e-01, time/batch = 0.6387s	
5036/16650 (epoch 15.123), train_loss = 1.16381566, grad/param norm = 2.3578e-01, time/batch = 0.6337s	
5037/16650 (epoch 15.126), train_loss = 1.18451724, grad/param norm = 2.4461e-01, time/batch = 0.6327s	
5038/16650 (epoch 15.129), train_loss = 1.23805012, grad/param norm = 2.4620e-01, time/batch = 0.6468s	
5039/16650 (epoch 15.132), train_loss = 1.22499247, grad/param norm = 2.4439e-01, time/batch = 0.6376s	
5040/16650 (epoch 15.135), train_loss = 1.25704802, grad/param norm = 2.4728e-01, time/batch = 0.6287s	
5041/16650 (epoch 15.138), train_loss = 1.25634124, grad/param norm = 2.2826e-01, time/batch = 0.6315s	
5042/16650 (epoch 15.141), train_loss = 1.27417172, grad/param norm = 2.6686e-01, time/batch = 0.6320s	
5043/16650 (epoch 15.144), train_loss = 1.19018101, grad/param norm = 2.5672e-01, time/batch = 0.6296s	
5044/16650 (epoch 15.147), train_loss = 1.35045729, grad/param norm = 2.4613e-01, time/batch = 0.6309s	
5045/16650 (epoch 15.150), train_loss = 1.43516343, grad/param norm = 2.5020e-01, time/batch = 0.6310s	
5046/16650 (epoch 15.153), train_loss = 1.20553213, grad/param norm = 2.6163e-01, time/batch = 0.6307s	
5047/16650 (epoch 15.156), train_loss = 1.04444811, grad/param norm = 2.1763e-01, time/batch = 0.6316s	
5048/16650 (epoch 15.159), train_loss = 1.28057930, grad/param norm = 2.5249e-01, time/batch = 0.6298s	
5049/16650 (epoch 15.162), train_loss = 1.34248981, grad/param norm = 2.4566e-01, time/batch = 0.6312s	
5050/16650 (epoch 15.165), train_loss = 1.29940299, grad/param norm = 2.3966e-01, time/batch = 0.6301s	
5051/16650 (epoch 15.168), train_loss = 0.96939324, grad/param norm = 2.0551e-01, time/batch = 0.6319s	
5052/16650 (epoch 15.171), train_loss = 1.29371677, grad/param norm = 2.2381e-01, time/batch = 0.6353s	
5053/16650 (epoch 15.174), train_loss = 1.02397847, grad/param norm = 2.4281e-01, time/batch = 0.6354s	
5054/16650 (epoch 15.177), train_loss = 1.18413808, grad/param norm = 2.3630e-01, time/batch = 0.6322s	
5055/16650 (epoch 15.180), train_loss = 1.31440565, grad/param norm = 2.5288e-01, time/batch = 0.6325s	
5056/16650 (epoch 15.183), train_loss = 1.46299225, grad/param norm = 2.6125e-01, time/batch = 0.6294s	
5057/16650 (epoch 15.186), train_loss = 1.28132464, grad/param norm = 2.5492e-01, time/batch = 0.6304s	
5058/16650 (epoch 15.189), train_loss = 1.07378879, grad/param norm = 2.0899e-01, time/batch = 0.6315s	
5059/16650 (epoch 15.192), train_loss = 1.12286626, grad/param norm = 2.3664e-01, time/batch = 0.6308s	
5060/16650 (epoch 15.195), train_loss = 1.17231873, grad/param norm = 2.7121e-01, time/batch = 0.6310s	
5061/16650 (epoch 15.198), train_loss = 0.99754414, grad/param norm = 2.3161e-01, time/batch = 0.6348s	
5062/16650 (epoch 15.201), train_loss = 1.11824556, grad/param norm = 2.3246e-01, time/batch = 0.6362s	
5063/16650 (epoch 15.204), train_loss = 1.18167388, grad/param norm = 2.2885e-01, time/batch = 0.6330s	
5064/16650 (epoch 15.207), train_loss = 1.26023588, grad/param norm = 2.8910e-01, time/batch = 0.6308s	
5065/16650 (epoch 15.210), train_loss = 1.13223997, grad/param norm = 2.2830e-01, time/batch = 0.6300s	
5066/16650 (epoch 15.213), train_loss = 1.25278915, grad/param norm = 2.3491e-01, time/batch = 0.6328s	
5067/16650 (epoch 15.216), train_loss = 1.14134383, grad/param norm = 2.2198e-01, time/batch = 0.6328s	
5068/16650 (epoch 15.219), train_loss = 1.18211380, grad/param norm = 2.4591e-01, time/batch = 0.6337s	
5069/16650 (epoch 15.222), train_loss = 1.20225973, grad/param norm = 2.2762e-01, time/batch = 0.6333s	
5070/16650 (epoch 15.225), train_loss = 1.19033331, grad/param norm = 2.2305e-01, time/batch = 0.6331s	
5071/16650 (epoch 15.228), train_loss = 1.09407257, grad/param norm = 2.4425e-01, time/batch = 0.6314s	
5072/16650 (epoch 15.231), train_loss = 1.15397207, grad/param norm = 2.3027e-01, time/batch = 0.6322s	
5073/16650 (epoch 15.234), train_loss = 1.35426981, grad/param norm = 2.5428e-01, time/batch = 0.6308s	
5074/16650 (epoch 15.237), train_loss = 1.22954657, grad/param norm = 2.5570e-01, time/batch = 0.6324s	
5075/16650 (epoch 15.240), train_loss = 1.22127573, grad/param norm = 2.5665e-01, time/batch = 0.6316s	
5076/16650 (epoch 15.243), train_loss = 1.21199160, grad/param norm = 2.2179e-01, time/batch = 0.6331s	
5077/16650 (epoch 15.246), train_loss = 1.32379662, grad/param norm = 2.5612e-01, time/batch = 0.6336s	
5078/16650 (epoch 15.249), train_loss = 1.04989215, grad/param norm = 2.3921e-01, time/batch = 0.6319s	
5079/16650 (epoch 15.252), train_loss = 1.15858860, grad/param norm = 2.2370e-01, time/batch = 0.6313s	
5080/16650 (epoch 15.255), train_loss = 1.30331838, grad/param norm = 2.5054e-01, time/batch = 0.6352s	
5081/16650 (epoch 15.258), train_loss = 1.31033410, grad/param norm = 2.3975e-01, time/batch = 0.6486s	
5082/16650 (epoch 15.261), train_loss = 1.18921233, grad/param norm = 2.3260e-01, time/batch = 0.6325s	
5083/16650 (epoch 15.264), train_loss = 1.15231006, grad/param norm = 2.4982e-01, time/batch = 0.6297s	
5084/16650 (epoch 15.267), train_loss = 1.13763107, grad/param norm = 2.3332e-01, time/batch = 0.6289s	
5085/16650 (epoch 15.270), train_loss = 1.18753400, grad/param norm = 2.3482e-01, time/batch = 0.6332s	
5086/16650 (epoch 15.273), train_loss = 1.29562756, grad/param norm = 2.2373e-01, time/batch = 0.6333s	
5087/16650 (epoch 15.276), train_loss = 1.20478499, grad/param norm = 2.3215e-01, time/batch = 0.6684s	
5088/16650 (epoch 15.279), train_loss = 1.15377671, grad/param norm = 2.1770e-01, time/batch = 0.6455s	
5089/16650 (epoch 15.282), train_loss = 1.07198704, grad/param norm = 2.2024e-01, time/batch = 0.6326s	
5090/16650 (epoch 15.285), train_loss = 1.06725987, grad/param norm = 2.1171e-01, time/batch = 0.6294s	
5091/16650 (epoch 15.288), train_loss = 1.12673261, grad/param norm = 2.4697e-01, time/batch = 0.6512s	
5092/16650 (epoch 15.291), train_loss = 0.92764186, grad/param norm = 2.0419e-01, time/batch = 0.6706s	
5093/16650 (epoch 15.294), train_loss = 1.03134563, grad/param norm = 1.8994e-01, time/batch = 0.6291s	
5094/16650 (epoch 15.297), train_loss = 1.12404246, grad/param norm = 2.3241e-01, time/batch = 0.6265s	
5095/16650 (epoch 15.300), train_loss = 0.94382738, grad/param norm = 2.0467e-01, time/batch = 0.6415s	
5096/16650 (epoch 15.303), train_loss = 0.99408383, grad/param norm = 1.9567e-01, time/batch = 0.6376s	
5097/16650 (epoch 15.306), train_loss = 1.23235876, grad/param norm = 2.3031e-01, time/batch = 0.6321s	
5098/16650 (epoch 15.309), train_loss = 1.27744078, grad/param norm = 2.4535e-01, time/batch = 0.6294s	
5099/16650 (epoch 15.312), train_loss = 1.06189680, grad/param norm = 2.2720e-01, time/batch = 0.6282s	
5100/16650 (epoch 15.315), train_loss = 0.85608798, grad/param norm = 1.8288e-01, time/batch = 0.6278s	
5101/16650 (epoch 15.318), train_loss = 0.93764454, grad/param norm = 2.1406e-01, time/batch = 0.6308s	
5102/16650 (epoch 15.321), train_loss = 1.35551152, grad/param norm = 2.6221e-01, time/batch = 0.6284s	
5103/16650 (epoch 15.324), train_loss = 1.09730768, grad/param norm = 2.3239e-01, time/batch = 0.6278s	
5104/16650 (epoch 15.327), train_loss = 1.31230096, grad/param norm = 3.0074e-01, time/batch = 0.6304s	
5105/16650 (epoch 15.330), train_loss = 1.22780344, grad/param norm = 2.3659e-01, time/batch = 0.6312s	
5106/16650 (epoch 15.333), train_loss = 1.24633560, grad/param norm = 2.4014e-01, time/batch = 0.6301s	
5107/16650 (epoch 15.336), train_loss = 1.06985446, grad/param norm = 2.6152e-01, time/batch = 0.6329s	
5108/16650 (epoch 15.339), train_loss = 1.15007471, grad/param norm = 2.3121e-01, time/batch = 0.6387s	
5109/16650 (epoch 15.342), train_loss = 1.11167323, grad/param norm = 2.4069e-01, time/batch = 0.6366s	
5110/16650 (epoch 15.345), train_loss = 1.01847912, grad/param norm = 2.2072e-01, time/batch = 0.6361s	
5111/16650 (epoch 15.348), train_loss = 1.18236362, grad/param norm = 2.4054e-01, time/batch = 0.6493s	
5112/16650 (epoch 15.351), train_loss = 1.23384082, grad/param norm = 2.2991e-01, time/batch = 0.6486s	
5113/16650 (epoch 15.354), train_loss = 1.30909208, grad/param norm = 2.8189e-01, time/batch = 0.6647s	
5114/16650 (epoch 15.357), train_loss = 1.21978513, grad/param norm = 2.6863e-01, time/batch = 0.6500s	
5115/16650 (epoch 15.360), train_loss = 1.21300911, grad/param norm = 2.3278e-01, time/batch = 0.6670s	
5116/16650 (epoch 15.363), train_loss = 1.31424495, grad/param norm = 2.6080e-01, time/batch = 0.6428s	
5117/16650 (epoch 15.366), train_loss = 1.37664646, grad/param norm = 2.6585e-01, time/batch = 0.6471s	
5118/16650 (epoch 15.369), train_loss = 1.18943322, grad/param norm = 2.4177e-01, time/batch = 0.6330s	
5119/16650 (epoch 15.372), train_loss = 1.18217505, grad/param norm = 2.3146e-01, time/batch = 0.6270s	
5120/16650 (epoch 15.375), train_loss = 1.18196343, grad/param norm = 2.3442e-01, time/batch = 0.6275s	
5121/16650 (epoch 15.378), train_loss = 1.05510151, grad/param norm = 2.2506e-01, time/batch = 0.6305s	
5122/16650 (epoch 15.381), train_loss = 1.20735755, grad/param norm = 2.2864e-01, time/batch = 0.6315s	
5123/16650 (epoch 15.384), train_loss = 1.32242885, grad/param norm = 2.4431e-01, time/batch = 0.6306s	
5124/16650 (epoch 15.387), train_loss = 0.92860425, grad/param norm = 2.1816e-01, time/batch = 0.6336s	
5125/16650 (epoch 15.390), train_loss = 1.25470601, grad/param norm = 2.4392e-01, time/batch = 0.6535s	
5126/16650 (epoch 15.393), train_loss = 1.16352484, grad/param norm = 2.4918e-01, time/batch = 0.6717s	
5127/16650 (epoch 15.396), train_loss = 1.30926235, grad/param norm = 2.5939e-01, time/batch = 0.6634s	
5128/16650 (epoch 15.399), train_loss = 1.23001700, grad/param norm = 2.6183e-01, time/batch = 0.6611s	
5129/16650 (epoch 15.402), train_loss = 1.06733034, grad/param norm = 2.1032e-01, time/batch = 0.6606s	
5130/16650 (epoch 15.405), train_loss = 1.00571231, grad/param norm = 2.3253e-01, time/batch = 0.6681s	
5131/16650 (epoch 15.408), train_loss = 1.28310557, grad/param norm = 2.4055e-01, time/batch = 0.6638s	
5132/16650 (epoch 15.411), train_loss = 1.04082370, grad/param norm = 2.4924e-01, time/batch = 0.6581s	
5133/16650 (epoch 15.414), train_loss = 1.03704909, grad/param norm = 2.3080e-01, time/batch = 0.6453s	
5134/16650 (epoch 15.417), train_loss = 0.99101463, grad/param norm = 2.0551e-01, time/batch = 0.6402s	
5135/16650 (epoch 15.420), train_loss = 0.99726624, grad/param norm = 2.3293e-01, time/batch = 0.6346s	
5136/16650 (epoch 15.423), train_loss = 0.82566227, grad/param norm = 1.7726e-01, time/batch = 0.6331s	
5137/16650 (epoch 15.426), train_loss = 1.04323927, grad/param norm = 2.6217e-01, time/batch = 0.6372s	
5138/16650 (epoch 15.429), train_loss = 1.26261010, grad/param norm = 2.4678e-01, time/batch = 0.6280s	
5139/16650 (epoch 15.432), train_loss = 1.24408486, grad/param norm = 2.6036e-01, time/batch = 0.6323s	
5140/16650 (epoch 15.435), train_loss = 1.37454852, grad/param norm = 2.3760e-01, time/batch = 0.6327s	
5141/16650 (epoch 15.438), train_loss = 1.36556629, grad/param norm = 2.6938e-01, time/batch = 0.6284s	
5142/16650 (epoch 15.441), train_loss = 1.19978073, grad/param norm = 2.6731e-01, time/batch = 0.6297s	
5143/16650 (epoch 15.444), train_loss = 1.10111516, grad/param norm = 2.3783e-01, time/batch = 0.6297s	
5144/16650 (epoch 15.447), train_loss = 1.13976259, grad/param norm = 2.2854e-01, time/batch = 0.6288s	
5145/16650 (epoch 15.450), train_loss = 1.06789617, grad/param norm = 2.2649e-01, time/batch = 0.6201s	
5146/16650 (epoch 15.453), train_loss = 1.10515318, grad/param norm = 2.2072e-01, time/batch = 0.6165s	
5147/16650 (epoch 15.456), train_loss = 1.01621565, grad/param norm = 2.3802e-01, time/batch = 0.6242s	
5148/16650 (epoch 15.459), train_loss = 1.06773771, grad/param norm = 2.3419e-01, time/batch = 0.6275s	
5149/16650 (epoch 15.462), train_loss = 1.32345827, grad/param norm = 2.9516e-01, time/batch = 0.6234s	
5150/16650 (epoch 15.465), train_loss = 1.09241893, grad/param norm = 2.4111e-01, time/batch = 0.6184s	
5151/16650 (epoch 15.468), train_loss = 0.88102029, grad/param norm = 2.0963e-01, time/batch = 0.6199s	
5152/16650 (epoch 15.471), train_loss = 0.76548304, grad/param norm = 1.8928e-01, time/batch = 0.6176s	
5153/16650 (epoch 15.474), train_loss = 0.99948970, grad/param norm = 2.0903e-01, time/batch = 0.6171s	
5154/16650 (epoch 15.477), train_loss = 1.17939527, grad/param norm = 2.4746e-01, time/batch = 0.6167s	
5155/16650 (epoch 15.480), train_loss = 1.20373316, grad/param norm = 2.6392e-01, time/batch = 0.6184s	
5156/16650 (epoch 15.483), train_loss = 1.34069664, grad/param norm = 2.4535e-01, time/batch = 0.6210s	
5157/16650 (epoch 15.486), train_loss = 1.04962814, grad/param norm = 2.1616e-01, time/batch = 0.6211s	
5158/16650 (epoch 15.489), train_loss = 1.09169167, grad/param norm = 2.3679e-01, time/batch = 0.6162s	
5159/16650 (epoch 15.492), train_loss = 1.15293751, grad/param norm = 2.3642e-01, time/batch = 0.6190s	
5160/16650 (epoch 15.495), train_loss = 1.05873192, grad/param norm = 2.5849e-01, time/batch = 0.6493s	
5161/16650 (epoch 15.498), train_loss = 1.14251300, grad/param norm = 2.4135e-01, time/batch = 0.6526s	
5162/16650 (epoch 15.502), train_loss = 1.34458331, grad/param norm = 2.5477e-01, time/batch = 0.6173s	
5163/16650 (epoch 15.505), train_loss = 1.21936902, grad/param norm = 2.2617e-01, time/batch = 0.6164s	
5164/16650 (epoch 15.508), train_loss = 1.19547956, grad/param norm = 2.3198e-01, time/batch = 0.6169s	
5165/16650 (epoch 15.511), train_loss = 1.26134698, grad/param norm = 2.4630e-01, time/batch = 0.6186s	
5166/16650 (epoch 15.514), train_loss = 1.00151169, grad/param norm = 2.2566e-01, time/batch = 0.6171s	
5167/16650 (epoch 15.517), train_loss = 1.12679023, grad/param norm = 2.3895e-01, time/batch = 0.6168s	
5168/16650 (epoch 15.520), train_loss = 1.10788489, grad/param norm = 2.4182e-01, time/batch = 0.6183s	
5169/16650 (epoch 15.523), train_loss = 1.08649756, grad/param norm = 2.1931e-01, time/batch = 0.6200s	
5170/16650 (epoch 15.526), train_loss = 1.22369222, grad/param norm = 2.3662e-01, time/batch = 0.6181s	
5171/16650 (epoch 15.529), train_loss = 1.32430990, grad/param norm = 2.6006e-01, time/batch = 0.6208s	
5172/16650 (epoch 15.532), train_loss = 0.91491632, grad/param norm = 2.1203e-01, time/batch = 0.6176s	
5173/16650 (epoch 15.535), train_loss = 0.99656852, grad/param norm = 2.2576e-01, time/batch = 0.6162s	
5174/16650 (epoch 15.538), train_loss = 1.02303272, grad/param norm = 2.4196e-01, time/batch = 0.6180s	
5175/16650 (epoch 15.541), train_loss = 1.28661643, grad/param norm = 2.4608e-01, time/batch = 0.6167s	
5176/16650 (epoch 15.544), train_loss = 1.31208460, grad/param norm = 2.5135e-01, time/batch = 0.6171s	
5177/16650 (epoch 15.547), train_loss = 1.03080419, grad/param norm = 2.2249e-01, time/batch = 0.6167s	
5178/16650 (epoch 15.550), train_loss = 1.06559945, grad/param norm = 2.4226e-01, time/batch = 0.6186s	
5179/16650 (epoch 15.553), train_loss = 1.10468275, grad/param norm = 2.4956e-01, time/batch = 0.6319s	
5180/16650 (epoch 15.556), train_loss = 1.06481311, grad/param norm = 2.2114e-01, time/batch = 0.6356s	
5181/16650 (epoch 15.559), train_loss = 0.92794821, grad/param norm = 2.0035e-01, time/batch = 0.6229s	
5182/16650 (epoch 15.562), train_loss = 1.10007659, grad/param norm = 2.3791e-01, time/batch = 0.6252s	
5183/16650 (epoch 15.565), train_loss = 0.89556813, grad/param norm = 2.1397e-01, time/batch = 0.6165s	
5184/16650 (epoch 15.568), train_loss = 0.92436961, grad/param norm = 2.1249e-01, time/batch = 0.6148s	
5185/16650 (epoch 15.571), train_loss = 0.95261374, grad/param norm = 2.4378e-01, time/batch = 0.6165s	
5186/16650 (epoch 15.574), train_loss = 1.09170645, grad/param norm = 2.4065e-01, time/batch = 0.6188s	
5187/16650 (epoch 15.577), train_loss = 1.05273140, grad/param norm = 2.1524e-01, time/batch = 0.6179s	
5188/16650 (epoch 15.580), train_loss = 0.96241682, grad/param norm = 2.1671e-01, time/batch = 0.6162s	
5189/16650 (epoch 15.583), train_loss = 1.09814857, grad/param norm = 2.4445e-01, time/batch = 0.6150s	
5190/16650 (epoch 15.586), train_loss = 1.05655053, grad/param norm = 2.7148e-01, time/batch = 0.6163s	
5191/16650 (epoch 15.589), train_loss = 0.96644294, grad/param norm = 2.1544e-01, time/batch = 0.6209s	
5192/16650 (epoch 15.592), train_loss = 1.12209910, grad/param norm = 2.4600e-01, time/batch = 0.6179s	
5193/16650 (epoch 15.595), train_loss = 1.02578873, grad/param norm = 2.2540e-01, time/batch = 0.6162s	
5194/16650 (epoch 15.598), train_loss = 1.05215545, grad/param norm = 2.3630e-01, time/batch = 0.6151s	
5195/16650 (epoch 15.601), train_loss = 1.02219251, grad/param norm = 2.7123e-01, time/batch = 0.6159s	
5196/16650 (epoch 15.604), train_loss = 1.19666403, grad/param norm = 2.4783e-01, time/batch = 0.6161s	
5197/16650 (epoch 15.607), train_loss = 1.16726724, grad/param norm = 2.3471e-01, time/batch = 0.6158s	
5198/16650 (epoch 15.610), train_loss = 0.99342155, grad/param norm = 2.0949e-01, time/batch = 0.6177s	
5199/16650 (epoch 15.613), train_loss = 1.23777395, grad/param norm = 2.4726e-01, time/batch = 0.6216s	
5200/16650 (epoch 15.616), train_loss = 1.26154033, grad/param norm = 2.7623e-01, time/batch = 0.6198s	
5201/16650 (epoch 15.619), train_loss = 0.95351034, grad/param norm = 2.2837e-01, time/batch = 0.6236s	
5202/16650 (epoch 15.622), train_loss = 0.91111584, grad/param norm = 2.1854e-01, time/batch = 0.6161s	
5203/16650 (epoch 15.625), train_loss = 1.04624399, grad/param norm = 2.2039e-01, time/batch = 0.6154s	
5204/16650 (epoch 15.628), train_loss = 1.06932288, grad/param norm = 2.6390e-01, time/batch = 0.6165s	
5205/16650 (epoch 15.631), train_loss = 1.12941965, grad/param norm = 2.8406e-01, time/batch = 0.6432s	
5206/16650 (epoch 15.634), train_loss = 1.37292437, grad/param norm = 2.7372e-01, time/batch = 0.6535s	
5207/16650 (epoch 15.637), train_loss = 1.33715201, grad/param norm = 2.4679e-01, time/batch = 0.6245s	
5208/16650 (epoch 15.640), train_loss = 1.04648507, grad/param norm = 2.4459e-01, time/batch = 0.6388s	
5209/16650 (epoch 15.643), train_loss = 1.19770993, grad/param norm = 2.3042e-01, time/batch = 0.6573s	
5210/16650 (epoch 15.646), train_loss = 1.16916761, grad/param norm = 2.3268e-01, time/batch = 0.6467s	
5211/16650 (epoch 15.649), train_loss = 1.14722409, grad/param norm = 2.4118e-01, time/batch = 0.6229s	
5212/16650 (epoch 15.652), train_loss = 1.25782103, grad/param norm = 2.7223e-01, time/batch = 0.6155s	
5213/16650 (epoch 15.655), train_loss = 1.17531568, grad/param norm = 2.5061e-01, time/batch = 0.6195s	
5214/16650 (epoch 15.658), train_loss = 1.01378472, grad/param norm = 2.2653e-01, time/batch = 0.6174s	
5215/16650 (epoch 15.661), train_loss = 1.21182101, grad/param norm = 2.4002e-01, time/batch = 0.6142s	
5216/16650 (epoch 15.664), train_loss = 1.12144784, grad/param norm = 2.3426e-01, time/batch = 0.6157s	
5217/16650 (epoch 15.667), train_loss = 1.25962350, grad/param norm = 2.4324e-01, time/batch = 0.6181s	
5218/16650 (epoch 15.670), train_loss = 0.98144158, grad/param norm = 2.2844e-01, time/batch = 0.6158s	
5219/16650 (epoch 15.673), train_loss = 1.04281738, grad/param norm = 2.0658e-01, time/batch = 0.6151s	
5220/16650 (epoch 15.676), train_loss = 1.11757569, grad/param norm = 2.5257e-01, time/batch = 0.6151s	
5221/16650 (epoch 15.679), train_loss = 0.99742458, grad/param norm = 2.1976e-01, time/batch = 0.6173s	
5222/16650 (epoch 15.682), train_loss = 1.14904276, grad/param norm = 2.3491e-01, time/batch = 0.6188s	
5223/16650 (epoch 15.685), train_loss = 0.95780242, grad/param norm = 2.4754e-01, time/batch = 0.6161s	
5224/16650 (epoch 15.688), train_loss = 1.15489574, grad/param norm = 2.4764e-01, time/batch = 0.6234s	
5225/16650 (epoch 15.691), train_loss = 1.16316754, grad/param norm = 2.4110e-01, time/batch = 0.6247s	
5226/16650 (epoch 15.694), train_loss = 0.97461211, grad/param norm = 2.1177e-01, time/batch = 0.6227s	
5227/16650 (epoch 15.697), train_loss = 0.99218200, grad/param norm = 2.2384e-01, time/batch = 0.6199s	
5228/16650 (epoch 15.700), train_loss = 1.21557485, grad/param norm = 2.4387e-01, time/batch = 0.6156s	
5229/16650 (epoch 15.703), train_loss = 1.01639267, grad/param norm = 2.6005e-01, time/batch = 0.6174s	
5230/16650 (epoch 15.706), train_loss = 1.19401929, grad/param norm = 2.4657e-01, time/batch = 0.6164s	
5231/16650 (epoch 15.709), train_loss = 1.02746334, grad/param norm = 2.1646e-01, time/batch = 0.6189s	
5232/16650 (epoch 15.712), train_loss = 1.03324080, grad/param norm = 2.5423e-01, time/batch = 0.6218s	
5233/16650 (epoch 15.715), train_loss = 1.25070548, grad/param norm = 2.3923e-01, time/batch = 0.6323s	
5234/16650 (epoch 15.718), train_loss = 1.26622368, grad/param norm = 2.5733e-01, time/batch = 0.6412s	
5235/16650 (epoch 15.721), train_loss = 1.24869024, grad/param norm = 2.6268e-01, time/batch = 0.6426s	
5236/16650 (epoch 15.724), train_loss = 1.26068417, grad/param norm = 2.7233e-01, time/batch = 0.6255s	
5237/16650 (epoch 15.727), train_loss = 1.20335513, grad/param norm = 2.3699e-01, time/batch = 0.6196s	
5238/16650 (epoch 15.730), train_loss = 1.09993016, grad/param norm = 2.2562e-01, time/batch = 0.6205s	
5239/16650 (epoch 15.733), train_loss = 1.23186196, grad/param norm = 2.6624e-01, time/batch = 0.6189s	
5240/16650 (epoch 15.736), train_loss = 0.95366885, grad/param norm = 2.1248e-01, time/batch = 0.6232s	
5241/16650 (epoch 15.739), train_loss = 1.11779861, grad/param norm = 2.2919e-01, time/batch = 0.6218s	
5242/16650 (epoch 15.742), train_loss = 1.16115101, grad/param norm = 2.5825e-01, time/batch = 0.6232s	
5243/16650 (epoch 15.745), train_loss = 0.94135925, grad/param norm = 2.1795e-01, time/batch = 0.6227s	
5244/16650 (epoch 15.748), train_loss = 1.01460490, grad/param norm = 2.5887e-01, time/batch = 0.6253s	
5245/16650 (epoch 15.751), train_loss = 1.18982199, grad/param norm = 2.9721e-01, time/batch = 0.6308s	
5246/16650 (epoch 15.754), train_loss = 1.30173261, grad/param norm = 2.7397e-01, time/batch = 0.6228s	
5247/16650 (epoch 15.757), train_loss = 1.24834859, grad/param norm = 2.5153e-01, time/batch = 0.6207s	
5248/16650 (epoch 15.760), train_loss = 1.10406887, grad/param norm = 2.4390e-01, time/batch = 0.6366s	
5249/16650 (epoch 15.763), train_loss = 1.04092755, grad/param norm = 2.5476e-01, time/batch = 0.6196s	
5250/16650 (epoch 15.766), train_loss = 1.11443751, grad/param norm = 2.2013e-01, time/batch = 0.6173s	
5251/16650 (epoch 15.769), train_loss = 1.14043498, grad/param norm = 2.4338e-01, time/batch = 0.6220s	
5252/16650 (epoch 15.772), train_loss = 1.07088457, grad/param norm = 2.1789e-01, time/batch = 0.6268s	
5253/16650 (epoch 15.775), train_loss = 1.11882189, grad/param norm = 2.2948e-01, time/batch = 0.6248s	
5254/16650 (epoch 15.778), train_loss = 1.13649133, grad/param norm = 2.3954e-01, time/batch = 0.6363s	
5255/16650 (epoch 15.781), train_loss = 1.23708660, grad/param norm = 2.3726e-01, time/batch = 0.6571s	
5256/16650 (epoch 15.784), train_loss = 1.21611236, grad/param norm = 2.6390e-01, time/batch = 0.6284s	
5257/16650 (epoch 15.787), train_loss = 1.22105691, grad/param norm = 2.3351e-01, time/batch = 0.6242s	
5258/16650 (epoch 15.790), train_loss = 1.15997784, grad/param norm = 2.1949e-01, time/batch = 0.6213s	
5259/16650 (epoch 15.793), train_loss = 1.00915067, grad/param norm = 2.2390e-01, time/batch = 0.6281s	
5260/16650 (epoch 15.796), train_loss = 1.47333615, grad/param norm = 2.6832e-01, time/batch = 0.6190s	
5261/16650 (epoch 15.799), train_loss = 1.35466588, grad/param norm = 2.4372e-01, time/batch = 0.6259s	
5262/16650 (epoch 15.802), train_loss = 1.16539688, grad/param norm = 2.5047e-01, time/batch = 0.6175s	
5263/16650 (epoch 15.805), train_loss = 1.12672191, grad/param norm = 2.3107e-01, time/batch = 0.6152s	
5264/16650 (epoch 15.808), train_loss = 1.17418232, grad/param norm = 2.4480e-01, time/batch = 0.6165s	
5265/16650 (epoch 15.811), train_loss = 1.28270700, grad/param norm = 2.3726e-01, time/batch = 0.6171s	
5266/16650 (epoch 15.814), train_loss = 1.02642924, grad/param norm = 2.2648e-01, time/batch = 0.6150s	
5267/16650 (epoch 15.817), train_loss = 1.09700830, grad/param norm = 2.4960e-01, time/batch = 0.6159s	
5268/16650 (epoch 15.820), train_loss = 1.19678701, grad/param norm = 2.4350e-01, time/batch = 0.6182s	
5269/16650 (epoch 15.823), train_loss = 1.06014606, grad/param norm = 2.1343e-01, time/batch = 0.6187s	
5270/16650 (epoch 15.826), train_loss = 1.13914808, grad/param norm = 2.2120e-01, time/batch = 0.6194s	
5271/16650 (epoch 15.829), train_loss = 1.26129892, grad/param norm = 2.4151e-01, time/batch = 0.6182s	
5272/16650 (epoch 15.832), train_loss = 1.26420252, grad/param norm = 2.6289e-01, time/batch = 0.6151s	
5273/16650 (epoch 15.835), train_loss = 1.23585790, grad/param norm = 2.7552e-01, time/batch = 0.6162s	
5274/16650 (epoch 15.838), train_loss = 1.03305683, grad/param norm = 2.2488e-01, time/batch = 0.6144s	
5275/16650 (epoch 15.841), train_loss = 1.07418371, grad/param norm = 2.2034e-01, time/batch = 0.6151s	
5276/16650 (epoch 15.844), train_loss = 1.07077882, grad/param norm = 2.2763e-01, time/batch = 0.6152s	
5277/16650 (epoch 15.847), train_loss = 1.23067375, grad/param norm = 2.4020e-01, time/batch = 0.6153s	
5278/16650 (epoch 15.850), train_loss = 1.02210848, grad/param norm = 2.4087e-01, time/batch = 0.6164s	
5279/16650 (epoch 15.853), train_loss = 1.19968980, grad/param norm = 2.4843e-01, time/batch = 0.6175s	
5280/16650 (epoch 15.856), train_loss = 1.05330487, grad/param norm = 2.4895e-01, time/batch = 0.6210s	
5281/16650 (epoch 15.859), train_loss = 1.21687070, grad/param norm = 2.4840e-01, time/batch = 0.6217s	
5282/16650 (epoch 15.862), train_loss = 1.13350237, grad/param norm = 2.3282e-01, time/batch = 0.6186s	
5283/16650 (epoch 15.865), train_loss = 0.94351858, grad/param norm = 2.0812e-01, time/batch = 0.6197s	
5284/16650 (epoch 15.868), train_loss = 1.21378755, grad/param norm = 2.5376e-01, time/batch = 0.6161s	
5285/16650 (epoch 15.871), train_loss = 1.19702320, grad/param norm = 2.3242e-01, time/batch = 0.6467s	
5286/16650 (epoch 15.874), train_loss = 1.18520632, grad/param norm = 2.3780e-01, time/batch = 0.6184s	
5287/16650 (epoch 15.877), train_loss = 1.09998855, grad/param norm = 2.2732e-01, time/batch = 0.6204s	
5288/16650 (epoch 15.880), train_loss = 1.07550556, grad/param norm = 2.3252e-01, time/batch = 0.6158s	
5289/16650 (epoch 15.883), train_loss = 1.17185464, grad/param norm = 2.6074e-01, time/batch = 0.6170s	
5290/16650 (epoch 15.886), train_loss = 1.15715141, grad/param norm = 2.3252e-01, time/batch = 0.6552s	
5291/16650 (epoch 15.889), train_loss = 0.99912508, grad/param norm = 2.4099e-01, time/batch = 0.6353s	
5292/16650 (epoch 15.892), train_loss = 1.11228241, grad/param norm = 2.2097e-01, time/batch = 0.6154s	
5293/16650 (epoch 15.895), train_loss = 1.23717395, grad/param norm = 2.7413e-01, time/batch = 0.6167s	
5294/16650 (epoch 15.898), train_loss = 1.20460537, grad/param norm = 2.3439e-01, time/batch = 0.6283s	
5295/16650 (epoch 15.901), train_loss = 1.14418215, grad/param norm = 2.2380e-01, time/batch = 0.6551s	
5296/16650 (epoch 15.904), train_loss = 1.06310894, grad/param norm = 2.5017e-01, time/batch = 0.6262s	
5297/16650 (epoch 15.907), train_loss = 1.21388281, grad/param norm = 2.7112e-01, time/batch = 0.6155s	
5298/16650 (epoch 15.910), train_loss = 1.19981026, grad/param norm = 2.4958e-01, time/batch = 0.6154s	
5299/16650 (epoch 15.913), train_loss = 1.06856357, grad/param norm = 2.4346e-01, time/batch = 0.6159s	
5300/16650 (epoch 15.916), train_loss = 1.16371887, grad/param norm = 2.3418e-01, time/batch = 0.6165s	
5301/16650 (epoch 15.919), train_loss = 1.32074135, grad/param norm = 2.4692e-01, time/batch = 0.6294s	
5302/16650 (epoch 15.922), train_loss = 1.25875592, grad/param norm = 2.4849e-01, time/batch = 0.6170s	
5303/16650 (epoch 15.925), train_loss = 1.07745436, grad/param norm = 2.6724e-01, time/batch = 0.6340s	
5304/16650 (epoch 15.928), train_loss = 1.10613062, grad/param norm = 2.2430e-01, time/batch = 0.6454s	
5305/16650 (epoch 15.931), train_loss = 1.20002931, grad/param norm = 2.4618e-01, time/batch = 0.6376s	
5306/16650 (epoch 15.934), train_loss = 1.00635686, grad/param norm = 2.3049e-01, time/batch = 0.6177s	
5307/16650 (epoch 15.937), train_loss = 1.09920420, grad/param norm = 2.6053e-01, time/batch = 0.6170s	
5308/16650 (epoch 15.940), train_loss = 1.09293910, grad/param norm = 2.1885e-01, time/batch = 0.6143s	
5309/16650 (epoch 15.943), train_loss = 1.15352869, grad/param norm = 2.4324e-01, time/batch = 0.6225s	
5310/16650 (epoch 15.946), train_loss = 1.06330940, grad/param norm = 2.2784e-01, time/batch = 0.6166s	
5311/16650 (epoch 15.949), train_loss = 1.02262057, grad/param norm = 2.4538e-01, time/batch = 0.6189s	
5312/16650 (epoch 15.952), train_loss = 0.93053740, grad/param norm = 2.2622e-01, time/batch = 0.6248s	
5313/16650 (epoch 15.955), train_loss = 1.06908356, grad/param norm = 2.2862e-01, time/batch = 0.6296s	
5314/16650 (epoch 15.958), train_loss = 1.20563853, grad/param norm = 2.6053e-01, time/batch = 0.6138s	
5315/16650 (epoch 15.961), train_loss = 1.10132563, grad/param norm = 2.3364e-01, time/batch = 0.6150s	
5316/16650 (epoch 15.964), train_loss = 1.04334867, grad/param norm = 2.3705e-01, time/batch = 0.6219s	
5317/16650 (epoch 15.967), train_loss = 1.27113785, grad/param norm = 2.4238e-01, time/batch = 0.6140s	
5318/16650 (epoch 15.970), train_loss = 1.01056633, grad/param norm = 2.2463e-01, time/batch = 0.6192s	
5319/16650 (epoch 15.973), train_loss = 1.08033951, grad/param norm = 2.5687e-01, time/batch = 0.6489s	
5320/16650 (epoch 15.976), train_loss = 1.04002289, grad/param norm = 2.4050e-01, time/batch = 0.6506s	
5321/16650 (epoch 15.979), train_loss = 1.17847843, grad/param norm = 2.7016e-01, time/batch = 0.6353s	
5322/16650 (epoch 15.982), train_loss = 1.22149418, grad/param norm = 2.6429e-01, time/batch = 0.6317s	
5323/16650 (epoch 15.985), train_loss = 1.09113640, grad/param norm = 2.2518e-01, time/batch = 0.6266s	
5324/16650 (epoch 15.988), train_loss = 1.33289460, grad/param norm = 2.8768e-01, time/batch = 0.6306s	
5325/16650 (epoch 15.991), train_loss = 1.05141718, grad/param norm = 2.4784e-01, time/batch = 0.6168s	
5326/16650 (epoch 15.994), train_loss = 1.08431809, grad/param norm = 2.5131e-01, time/batch = 0.6224s	
5327/16650 (epoch 15.997), train_loss = 1.14710766, grad/param norm = 2.6843e-01, time/batch = 0.6176s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
5328/16650 (epoch 16.000), train_loss = 1.19303123, grad/param norm = 2.6369e-01, time/batch = 0.6274s	
5329/16650 (epoch 16.003), train_loss = 1.22043489, grad/param norm = 3.1817e-01, time/batch = 0.6300s	
5330/16650 (epoch 16.006), train_loss = 1.24428991, grad/param norm = 3.2793e-01, time/batch = 0.6553s	
5331/16650 (epoch 16.009), train_loss = 1.31676544, grad/param norm = 2.5119e-01, time/batch = 0.6276s	
5332/16650 (epoch 16.012), train_loss = 1.33312794, grad/param norm = 2.6826e-01, time/batch = 0.6185s	
5333/16650 (epoch 16.015), train_loss = 1.13821215, grad/param norm = 2.6136e-01, time/batch = 0.6180s	
5334/16650 (epoch 16.018), train_loss = 0.96175734, grad/param norm = 2.3224e-01, time/batch = 0.6392s	
5335/16650 (epoch 16.021), train_loss = 1.27253451, grad/param norm = 2.8216e-01, time/batch = 0.6535s	
5336/16650 (epoch 16.024), train_loss = 1.12763047, grad/param norm = 2.4620e-01, time/batch = 0.6212s	
5337/16650 (epoch 16.027), train_loss = 1.23878779, grad/param norm = 2.5065e-01, time/batch = 0.6237s	
5338/16650 (epoch 16.030), train_loss = 1.00443920, grad/param norm = 2.3048e-01, time/batch = 0.6172s	
5339/16650 (epoch 16.033), train_loss = 1.12926440, grad/param norm = 2.2562e-01, time/batch = 0.6167s	
5340/16650 (epoch 16.036), train_loss = 0.93444861, grad/param norm = 2.5269e-01, time/batch = 0.6145s	
5341/16650 (epoch 16.039), train_loss = 1.24824401, grad/param norm = 2.4452e-01, time/batch = 0.6180s	
5342/16650 (epoch 16.042), train_loss = 1.23345698, grad/param norm = 2.5849e-01, time/batch = 0.6188s	
5343/16650 (epoch 16.045), train_loss = 1.13843411, grad/param norm = 2.5192e-01, time/batch = 0.6244s	
5344/16650 (epoch 16.048), train_loss = 1.21257411, grad/param norm = 2.5432e-01, time/batch = 0.6223s	
5345/16650 (epoch 16.051), train_loss = 1.14622738, grad/param norm = 2.4959e-01, time/batch = 0.6206s	
5346/16650 (epoch 16.054), train_loss = 1.16471734, grad/param norm = 2.5753e-01, time/batch = 0.6174s	
5347/16650 (epoch 16.057), train_loss = 1.13623831, grad/param norm = 2.4501e-01, time/batch = 0.6188s	
5348/16650 (epoch 16.060), train_loss = 1.00458645, grad/param norm = 2.2282e-01, time/batch = 0.6194s	
5349/16650 (epoch 16.063), train_loss = 1.10368841, grad/param norm = 2.4072e-01, time/batch = 0.6173s	
5350/16650 (epoch 16.066), train_loss = 1.31751124, grad/param norm = 2.5368e-01, time/batch = 0.6172s	
5351/16650 (epoch 16.069), train_loss = 1.24322283, grad/param norm = 2.5776e-01, time/batch = 0.6177s	
5352/16650 (epoch 16.072), train_loss = 1.09836466, grad/param norm = 2.6059e-01, time/batch = 0.6187s	
5353/16650 (epoch 16.075), train_loss = 1.20341286, grad/param norm = 2.4958e-01, time/batch = 0.6179s	
5354/16650 (epoch 16.078), train_loss = 1.26651882, grad/param norm = 2.5115e-01, time/batch = 0.6164s	
5355/16650 (epoch 16.081), train_loss = 1.13011120, grad/param norm = 2.2433e-01, time/batch = 0.6160s	
5356/16650 (epoch 16.084), train_loss = 1.19159331, grad/param norm = 2.2811e-01, time/batch = 0.6159s	
5357/16650 (epoch 16.087), train_loss = 1.12657611, grad/param norm = 2.5924e-01, time/batch = 0.6160s	
5358/16650 (epoch 16.090), train_loss = 1.09352043, grad/param norm = 2.2896e-01, time/batch = 0.6164s	
5359/16650 (epoch 16.093), train_loss = 1.36756466, grad/param norm = 2.6277e-01, time/batch = 0.6159s	
5360/16650 (epoch 16.096), train_loss = 1.11110387, grad/param norm = 2.4696e-01, time/batch = 0.6150s	
5361/16650 (epoch 16.099), train_loss = 1.14089669, grad/param norm = 2.4066e-01, time/batch = 0.6218s	
5362/16650 (epoch 16.102), train_loss = 1.19726349, grad/param norm = 2.6012e-01, time/batch = 0.6156s	
5363/16650 (epoch 16.105), train_loss = 1.23357803, grad/param norm = 2.4451e-01, time/batch = 0.6169s	
5364/16650 (epoch 16.108), train_loss = 1.19900992, grad/param norm = 2.4071e-01, time/batch = 0.6211s	
5365/16650 (epoch 16.111), train_loss = 1.22465197, grad/param norm = 2.3519e-01, time/batch = 0.6168s	
5366/16650 (epoch 16.114), train_loss = 1.27554067, grad/param norm = 2.6057e-01, time/batch = 0.6155s	
5367/16650 (epoch 16.117), train_loss = 1.29427161, grad/param norm = 2.5923e-01, time/batch = 0.6167s	
5368/16650 (epoch 16.120), train_loss = 1.03565168, grad/param norm = 2.0956e-01, time/batch = 0.6161s	
5369/16650 (epoch 16.123), train_loss = 1.12979312, grad/param norm = 2.4407e-01, time/batch = 0.6178s	
5370/16650 (epoch 16.126), train_loss = 1.16026553, grad/param norm = 2.4276e-01, time/batch = 0.6218s	
5371/16650 (epoch 16.129), train_loss = 1.20287601, grad/param norm = 2.5439e-01, time/batch = 0.6309s	
5372/16650 (epoch 16.132), train_loss = 1.18776491, grad/param norm = 2.4981e-01, time/batch = 0.6245s	
5373/16650 (epoch 16.135), train_loss = 1.23226556, grad/param norm = 2.5484e-01, time/batch = 0.6200s	
5374/16650 (epoch 16.138), train_loss = 1.22153028, grad/param norm = 2.3308e-01, time/batch = 0.6186s	
5375/16650 (epoch 16.141), train_loss = 1.23941496, grad/param norm = 2.6114e-01, time/batch = 0.6154s	
5376/16650 (epoch 16.144), train_loss = 1.15343328, grad/param norm = 2.5059e-01, time/batch = 0.6165s	
5377/16650 (epoch 16.147), train_loss = 1.31284149, grad/param norm = 2.3898e-01, time/batch = 0.6157s	
5378/16650 (epoch 16.150), train_loss = 1.39303872, grad/param norm = 2.6251e-01, time/batch = 0.6153s	
5379/16650 (epoch 16.153), train_loss = 1.17454663, grad/param norm = 2.6963e-01, time/batch = 0.6174s	
5380/16650 (epoch 16.156), train_loss = 1.02489845, grad/param norm = 2.1060e-01, time/batch = 0.6166s	
5381/16650 (epoch 16.159), train_loss = 1.23791066, grad/param norm = 2.5215e-01, time/batch = 0.6200s	
5382/16650 (epoch 16.162), train_loss = 1.31381423, grad/param norm = 2.6179e-01, time/batch = 0.6186s	
5383/16650 (epoch 16.165), train_loss = 1.27215507, grad/param norm = 2.4728e-01, time/batch = 0.6186s	
5384/16650 (epoch 16.168), train_loss = 0.95174802, grad/param norm = 2.0755e-01, time/batch = 0.6155s	
5385/16650 (epoch 16.171), train_loss = 1.26570534, grad/param norm = 2.2964e-01, time/batch = 0.6150s	
5386/16650 (epoch 16.174), train_loss = 0.99912348, grad/param norm = 2.4313e-01, time/batch = 0.6153s	
5387/16650 (epoch 16.177), train_loss = 1.15167570, grad/param norm = 2.4235e-01, time/batch = 0.6158s	
5388/16650 (epoch 16.180), train_loss = 1.27095768, grad/param norm = 2.5340e-01, time/batch = 0.6211s	
5389/16650 (epoch 16.183), train_loss = 1.42721035, grad/param norm = 2.6781e-01, time/batch = 0.6535s	
5390/16650 (epoch 16.186), train_loss = 1.24628960, grad/param norm = 2.4203e-01, time/batch = 0.6400s	
5391/16650 (epoch 16.189), train_loss = 1.05830349, grad/param norm = 2.2147e-01, time/batch = 0.6191s	
5392/16650 (epoch 16.192), train_loss = 1.08972446, grad/param norm = 2.4763e-01, time/batch = 0.6185s	
5393/16650 (epoch 16.195), train_loss = 1.12870764, grad/param norm = 2.5117e-01, time/batch = 0.6183s	
5394/16650 (epoch 16.198), train_loss = 0.96811351, grad/param norm = 2.0598e-01, time/batch = 0.6195s	
5395/16650 (epoch 16.201), train_loss = 1.08907001, grad/param norm = 2.3219e-01, time/batch = 0.6238s	
5396/16650 (epoch 16.204), train_loss = 1.14064657, grad/param norm = 2.3416e-01, time/batch = 0.6206s	
5397/16650 (epoch 16.207), train_loss = 1.20582801, grad/param norm = 2.6267e-01, time/batch = 0.6295s	
5398/16650 (epoch 16.210), train_loss = 1.10325505, grad/param norm = 2.3693e-01, time/batch = 0.6212s	
5399/16650 (epoch 16.213), train_loss = 1.23467531, grad/param norm = 2.7445e-01, time/batch = 0.6334s	
5400/16650 (epoch 16.216), train_loss = 1.12596742, grad/param norm = 2.3998e-01, time/batch = 0.6419s	
5401/16650 (epoch 16.219), train_loss = 1.13934828, grad/param norm = 2.3381e-01, time/batch = 0.6522s	
5402/16650 (epoch 16.222), train_loss = 1.18572920, grad/param norm = 2.3817e-01, time/batch = 0.6186s	
5403/16650 (epoch 16.225), train_loss = 1.15850707, grad/param norm = 2.2773e-01, time/batch = 0.6165s	
5404/16650 (epoch 16.228), train_loss = 1.05080928, grad/param norm = 2.3247e-01, time/batch = 0.6162s	
5405/16650 (epoch 16.231), train_loss = 1.12572313, grad/param norm = 2.2839e-01, time/batch = 0.6158s	
5406/16650 (epoch 16.234), train_loss = 1.33041612, grad/param norm = 2.7904e-01, time/batch = 0.6194s	
5407/16650 (epoch 16.237), train_loss = 1.20106058, grad/param norm = 2.9035e-01, time/batch = 0.6174s	
5408/16650 (epoch 16.240), train_loss = 1.20593160, grad/param norm = 2.6208e-01, time/batch = 0.6211s	
5409/16650 (epoch 16.243), train_loss = 1.17691916, grad/param norm = 2.3293e-01, time/batch = 0.6208s	
5410/16650 (epoch 16.246), train_loss = 1.29019178, grad/param norm = 2.6132e-01, time/batch = 0.6224s	
5411/16650 (epoch 16.249), train_loss = 1.02280141, grad/param norm = 2.6061e-01, time/batch = 0.6320s	
5412/16650 (epoch 16.252), train_loss = 1.12515469, grad/param norm = 2.3029e-01, time/batch = 0.6295s	
5413/16650 (epoch 16.255), train_loss = 1.26405194, grad/param norm = 2.4952e-01, time/batch = 0.6386s	
5414/16650 (epoch 16.258), train_loss = 1.28499794, grad/param norm = 2.4728e-01, time/batch = 0.6457s	
5415/16650 (epoch 16.261), train_loss = 1.15975452, grad/param norm = 2.2921e-01, time/batch = 0.6483s	
5416/16650 (epoch 16.264), train_loss = 1.12595325, grad/param norm = 2.5572e-01, time/batch = 0.6473s	
5417/16650 (epoch 16.267), train_loss = 1.11254584, grad/param norm = 2.4486e-01, time/batch = 0.6435s	
5418/16650 (epoch 16.270), train_loss = 1.15666957, grad/param norm = 2.3382e-01, time/batch = 0.6416s	
5419/16650 (epoch 16.273), train_loss = 1.27498164, grad/param norm = 2.2778e-01, time/batch = 0.6580s	
5420/16650 (epoch 16.276), train_loss = 1.18034879, grad/param norm = 2.3520e-01, time/batch = 0.6451s	
5421/16650 (epoch 16.279), train_loss = 1.13206697, grad/param norm = 2.2564e-01, time/batch = 0.6435s	
5422/16650 (epoch 16.282), train_loss = 1.05145502, grad/param norm = 2.2855e-01, time/batch = 0.6318s	
5423/16650 (epoch 16.285), train_loss = 1.03532241, grad/param norm = 2.0888e-01, time/batch = 0.6285s	
5424/16650 (epoch 16.288), train_loss = 1.09851080, grad/param norm = 2.4445e-01, time/batch = 0.6232s	
5425/16650 (epoch 16.291), train_loss = 0.89316800, grad/param norm = 2.0164e-01, time/batch = 0.6281s	
5426/16650 (epoch 16.294), train_loss = 1.01080047, grad/param norm = 1.9585e-01, time/batch = 0.6178s	
5427/16650 (epoch 16.297), train_loss = 1.09437652, grad/param norm = 2.3005e-01, time/batch = 0.6175s	
5428/16650 (epoch 16.300), train_loss = 0.91538088, grad/param norm = 2.0623e-01, time/batch = 0.6163s	
5429/16650 (epoch 16.303), train_loss = 0.96475718, grad/param norm = 2.0280e-01, time/batch = 0.6184s	
5430/16650 (epoch 16.306), train_loss = 1.20721602, grad/param norm = 2.3751e-01, time/batch = 0.6168s	
5431/16650 (epoch 16.309), train_loss = 1.24542843, grad/param norm = 2.4950e-01, time/batch = 0.6216s	
5432/16650 (epoch 16.312), train_loss = 1.03252145, grad/param norm = 2.3803e-01, time/batch = 0.6257s	
5433/16650 (epoch 16.315), train_loss = 0.83185796, grad/param norm = 1.8224e-01, time/batch = 0.6186s	
5434/16650 (epoch 16.318), train_loss = 0.91538726, grad/param norm = 2.1725e-01, time/batch = 0.6167s	
5435/16650 (epoch 16.321), train_loss = 1.32133831, grad/param norm = 2.6426e-01, time/batch = 0.6159s	
5436/16650 (epoch 16.324), train_loss = 1.06727453, grad/param norm = 2.5850e-01, time/batch = 0.6181s	
5437/16650 (epoch 16.327), train_loss = 1.25880596, grad/param norm = 2.7524e-01, time/batch = 0.6158s	
5438/16650 (epoch 16.330), train_loss = 1.19066752, grad/param norm = 2.5036e-01, time/batch = 0.6166s	
5439/16650 (epoch 16.333), train_loss = 1.22740065, grad/param norm = 2.5903e-01, time/batch = 0.6212s	
5440/16650 (epoch 16.336), train_loss = 1.04321218, grad/param norm = 2.5880e-01, time/batch = 0.6192s	
5441/16650 (epoch 16.339), train_loss = 1.11964457, grad/param norm = 2.4545e-01, time/batch = 0.6205s	
5442/16650 (epoch 16.342), train_loss = 1.08098842, grad/param norm = 2.4899e-01, time/batch = 0.6226s	
5443/16650 (epoch 16.345), train_loss = 0.98388985, grad/param norm = 2.0550e-01, time/batch = 0.6200s	
5444/16650 (epoch 16.348), train_loss = 1.15159299, grad/param norm = 2.4222e-01, time/batch = 0.6253s	
5445/16650 (epoch 16.351), train_loss = 1.21153931, grad/param norm = 2.4695e-01, time/batch = 0.6277s	
5446/16650 (epoch 16.354), train_loss = 1.25272452, grad/param norm = 2.5726e-01, time/batch = 0.6207s	
5447/16650 (epoch 16.357), train_loss = 1.17463207, grad/param norm = 2.4368e-01, time/batch = 0.6201s	
5448/16650 (epoch 16.360), train_loss = 1.18359018, grad/param norm = 2.3677e-01, time/batch = 0.6209s	
5449/16650 (epoch 16.363), train_loss = 1.27770617, grad/param norm = 2.5523e-01, time/batch = 0.6192s	
5450/16650 (epoch 16.366), train_loss = 1.34865526, grad/param norm = 2.6847e-01, time/batch = 0.6210s	
5451/16650 (epoch 16.369), train_loss = 1.16405898, grad/param norm = 2.5299e-01, time/batch = 0.6206s	
5452/16650 (epoch 16.372), train_loss = 1.14436109, grad/param norm = 2.2529e-01, time/batch = 0.6192s	
5453/16650 (epoch 16.375), train_loss = 1.14639382, grad/param norm = 2.2491e-01, time/batch = 0.6187s	
5454/16650 (epoch 16.378), train_loss = 1.03541140, grad/param norm = 2.3145e-01, time/batch = 0.6484s	
5455/16650 (epoch 16.381), train_loss = 1.17368202, grad/param norm = 2.3092e-01, time/batch = 0.6453s	
5456/16650 (epoch 16.384), train_loss = 1.28913794, grad/param norm = 2.4887e-01, time/batch = 0.6196s	
5457/16650 (epoch 16.387), train_loss = 0.91304177, grad/param norm = 2.3890e-01, time/batch = 0.6184s	
5458/16650 (epoch 16.390), train_loss = 1.22372020, grad/param norm = 2.4989e-01, time/batch = 0.6185s	
5459/16650 (epoch 16.393), train_loss = 1.12537731, grad/param norm = 2.5334e-01, time/batch = 0.6551s	
5460/16650 (epoch 16.396), train_loss = 1.28119834, grad/param norm = 2.6980e-01, time/batch = 0.6357s	
5461/16650 (epoch 16.399), train_loss = 1.19861138, grad/param norm = 2.6645e-01, time/batch = 0.6180s	
5462/16650 (epoch 16.402), train_loss = 1.05694085, grad/param norm = 2.5069e-01, time/batch = 0.6175s	
5463/16650 (epoch 16.405), train_loss = 0.98147674, grad/param norm = 2.5442e-01, time/batch = 0.6221s	
5464/16650 (epoch 16.408), train_loss = 1.25019709, grad/param norm = 2.5979e-01, time/batch = 0.6272s	
5465/16650 (epoch 16.411), train_loss = 1.02019598, grad/param norm = 2.8841e-01, time/batch = 0.6189s	
5466/16650 (epoch 16.414), train_loss = 1.01719306, grad/param norm = 2.5185e-01, time/batch = 0.6173s	
5467/16650 (epoch 16.417), train_loss = 0.97399350, grad/param norm = 2.2256e-01, time/batch = 0.6174s	
5468/16650 (epoch 16.420), train_loss = 0.97781873, grad/param norm = 2.3600e-01, time/batch = 0.6164s	
5469/16650 (epoch 16.423), train_loss = 0.81530210, grad/param norm = 1.8482e-01, time/batch = 0.6146s	
5470/16650 (epoch 16.426), train_loss = 1.01284852, grad/param norm = 2.5314e-01, time/batch = 0.6160s	
5471/16650 (epoch 16.429), train_loss = 1.23869070, grad/param norm = 2.4465e-01, time/batch = 0.6181s	
5472/16650 (epoch 16.432), train_loss = 1.21468794, grad/param norm = 2.6292e-01, time/batch = 0.6191s	
5473/16650 (epoch 16.435), train_loss = 1.33131899, grad/param norm = 2.4955e-01, time/batch = 0.6183s	
5474/16650 (epoch 16.438), train_loss = 1.33891673, grad/param norm = 2.7814e-01, time/batch = 0.6163s	
5475/16650 (epoch 16.441), train_loss = 1.17011842, grad/param norm = 2.5549e-01, time/batch = 0.6177s	
5476/16650 (epoch 16.444), train_loss = 1.06951603, grad/param norm = 2.3401e-01, time/batch = 0.6228s	
5477/16650 (epoch 16.447), train_loss = 1.10980136, grad/param norm = 2.3650e-01, time/batch = 0.6158s	
5478/16650 (epoch 16.450), train_loss = 1.04828551, grad/param norm = 2.3540e-01, time/batch = 0.6168s	
5479/16650 (epoch 16.453), train_loss = 1.08193976, grad/param norm = 2.2802e-01, time/batch = 0.6175s	
5480/16650 (epoch 16.456), train_loss = 0.98190669, grad/param norm = 2.3916e-01, time/batch = 0.6168s	
5481/16650 (epoch 16.459), train_loss = 1.02758510, grad/param norm = 2.3083e-01, time/batch = 0.6229s	
5482/16650 (epoch 16.462), train_loss = 1.28684947, grad/param norm = 3.1718e-01, time/batch = 0.6202s	
5483/16650 (epoch 16.465), train_loss = 1.06025323, grad/param norm = 2.5928e-01, time/batch = 0.6172s	
5484/16650 (epoch 16.468), train_loss = 0.86140654, grad/param norm = 2.1753e-01, time/batch = 0.6180s	
5485/16650 (epoch 16.471), train_loss = 0.74054984, grad/param norm = 1.8783e-01, time/batch = 0.6175s	
5486/16650 (epoch 16.474), train_loss = 0.96606443, grad/param norm = 2.0749e-01, time/batch = 0.6159s	
5487/16650 (epoch 16.477), train_loss = 1.14851268, grad/param norm = 2.4927e-01, time/batch = 0.6169s	
5488/16650 (epoch 16.480), train_loss = 1.17836248, grad/param norm = 2.7573e-01, time/batch = 0.6171s	
5489/16650 (epoch 16.483), train_loss = 1.29843743, grad/param norm = 2.5271e-01, time/batch = 0.6162s	
5490/16650 (epoch 16.486), train_loss = 1.01613183, grad/param norm = 2.2195e-01, time/batch = 0.6438s	
5491/16650 (epoch 16.489), train_loss = 1.06627312, grad/param norm = 2.3408e-01, time/batch = 0.6292s	
5492/16650 (epoch 16.492), train_loss = 1.10779879, grad/param norm = 2.3098e-01, time/batch = 0.6226s	
5493/16650 (epoch 16.495), train_loss = 1.02267051, grad/param norm = 2.5399e-01, time/batch = 0.6253s	
5494/16650 (epoch 16.498), train_loss = 1.10561383, grad/param norm = 2.4855e-01, time/batch = 0.6502s	
5495/16650 (epoch 16.502), train_loss = 1.29978301, grad/param norm = 2.5531e-01, time/batch = 0.6496s	
5496/16650 (epoch 16.505), train_loss = 1.18802982, grad/param norm = 2.3714e-01, time/batch = 0.6527s	
5497/16650 (epoch 16.508), train_loss = 1.15998298, grad/param norm = 2.3347e-01, time/batch = 0.6272s	
5498/16650 (epoch 16.511), train_loss = 1.22019857, grad/param norm = 2.4397e-01, time/batch = 0.6237s	
5499/16650 (epoch 16.514), train_loss = 0.96242858, grad/param norm = 2.2416e-01, time/batch = 0.6572s	
5500/16650 (epoch 16.517), train_loss = 1.09890173, grad/param norm = 2.4263e-01, time/batch = 0.6354s	
5501/16650 (epoch 16.520), train_loss = 1.06499044, grad/param norm = 2.3759e-01, time/batch = 0.6328s	
5502/16650 (epoch 16.523), train_loss = 1.06095310, grad/param norm = 2.2292e-01, time/batch = 0.6241s	
5503/16650 (epoch 16.526), train_loss = 1.20373340, grad/param norm = 2.4289e-01, time/batch = 0.6159s	
5504/16650 (epoch 16.529), train_loss = 1.29103651, grad/param norm = 2.7107e-01, time/batch = 0.6204s	
5505/16650 (epoch 16.532), train_loss = 0.87331117, grad/param norm = 2.0685e-01, time/batch = 0.6197s	
5506/16650 (epoch 16.535), train_loss = 0.96734829, grad/param norm = 2.3045e-01, time/batch = 0.6277s	
5507/16650 (epoch 16.538), train_loss = 0.99297347, grad/param norm = 2.4463e-01, time/batch = 0.6270s	
5508/16650 (epoch 16.541), train_loss = 1.25464350, grad/param norm = 2.5223e-01, time/batch = 0.6423s	
5509/16650 (epoch 16.544), train_loss = 1.28633862, grad/param norm = 2.7269e-01, time/batch = 0.6306s	
5510/16650 (epoch 16.547), train_loss = 0.99358516, grad/param norm = 2.2314e-01, time/batch = 0.6193s	
5511/16650 (epoch 16.550), train_loss = 1.04500961, grad/param norm = 2.4768e-01, time/batch = 0.6267s	
5512/16650 (epoch 16.553), train_loss = 1.07955300, grad/param norm = 2.5731e-01, time/batch = 0.6238s	
5513/16650 (epoch 16.556), train_loss = 1.03268910, grad/param norm = 2.2183e-01, time/batch = 0.6298s	
5514/16650 (epoch 16.559), train_loss = 0.90361114, grad/param norm = 2.1348e-01, time/batch = 0.6220s	
5515/16650 (epoch 16.562), train_loss = 1.06190547, grad/param norm = 2.4071e-01, time/batch = 0.6382s	
5516/16650 (epoch 16.565), train_loss = 0.87928613, grad/param norm = 2.1674e-01, time/batch = 0.6224s	
5517/16650 (epoch 16.568), train_loss = 0.89518084, grad/param norm = 2.1642e-01, time/batch = 0.6172s	
5518/16650 (epoch 16.571), train_loss = 0.91705743, grad/param norm = 2.4265e-01, time/batch = 0.6170s	
5519/16650 (epoch 16.574), train_loss = 1.06555694, grad/param norm = 2.5046e-01, time/batch = 0.6243s	
5520/16650 (epoch 16.577), train_loss = 1.02405755, grad/param norm = 2.1951e-01, time/batch = 0.6160s	
5521/16650 (epoch 16.580), train_loss = 0.93589294, grad/param norm = 2.2512e-01, time/batch = 0.6181s	
5522/16650 (epoch 16.583), train_loss = 1.06407406, grad/param norm = 2.3918e-01, time/batch = 0.6155s	
5523/16650 (epoch 16.586), train_loss = 1.03149100, grad/param norm = 2.7822e-01, time/batch = 0.6163s	
5524/16650 (epoch 16.589), train_loss = 0.94181110, grad/param norm = 2.1623e-01, time/batch = 0.6239s	
5525/16650 (epoch 16.592), train_loss = 1.09322126, grad/param norm = 2.4301e-01, time/batch = 0.6201s	
5526/16650 (epoch 16.595), train_loss = 1.00266195, grad/param norm = 2.2677e-01, time/batch = 0.6179s	
5527/16650 (epoch 16.598), train_loss = 1.02710887, grad/param norm = 2.3230e-01, time/batch = 0.6180s	
5528/16650 (epoch 16.601), train_loss = 0.99101309, grad/param norm = 2.6591e-01, time/batch = 0.6173s	
5529/16650 (epoch 16.604), train_loss = 1.16585296, grad/param norm = 2.4246e-01, time/batch = 0.6514s	
5530/16650 (epoch 16.607), train_loss = 1.13796119, grad/param norm = 2.3248e-01, time/batch = 0.6412s	
5531/16650 (epoch 16.610), train_loss = 0.96778594, grad/param norm = 2.1657e-01, time/batch = 0.6178s	
5532/16650 (epoch 16.613), train_loss = 1.20944906, grad/param norm = 2.6504e-01, time/batch = 0.6175s	
5533/16650 (epoch 16.616), train_loss = 1.22499626, grad/param norm = 2.7195e-01, time/batch = 0.6228s	
5534/16650 (epoch 16.619), train_loss = 0.91185735, grad/param norm = 2.1710e-01, time/batch = 0.6554s	
5535/16650 (epoch 16.622), train_loss = 0.88740292, grad/param norm = 2.1853e-01, time/batch = 0.6312s	
5536/16650 (epoch 16.625), train_loss = 1.00919495, grad/param norm = 2.2122e-01, time/batch = 0.6165s	
5537/16650 (epoch 16.628), train_loss = 1.04400372, grad/param norm = 2.5961e-01, time/batch = 0.6165s	
5538/16650 (epoch 16.631), train_loss = 1.09805450, grad/param norm = 2.6562e-01, time/batch = 0.6182s	
5539/16650 (epoch 16.634), train_loss = 1.33032838, grad/param norm = 2.7980e-01, time/batch = 0.6166s	
5540/16650 (epoch 16.637), train_loss = 1.29853387, grad/param norm = 2.5291e-01, time/batch = 0.6175s	
5541/16650 (epoch 16.640), train_loss = 1.00769061, grad/param norm = 2.3105e-01, time/batch = 0.6178s	
5542/16650 (epoch 16.643), train_loss = 1.17283296, grad/param norm = 2.4607e-01, time/batch = 0.6198s	
5543/16650 (epoch 16.646), train_loss = 1.14187258, grad/param norm = 2.5071e-01, time/batch = 0.6177s	
5544/16650 (epoch 16.649), train_loss = 1.11401684, grad/param norm = 2.3633e-01, time/batch = 0.6174s	
5545/16650 (epoch 16.652), train_loss = 1.21622438, grad/param norm = 2.7222e-01, time/batch = 0.6176s	
5546/16650 (epoch 16.655), train_loss = 1.15220497, grad/param norm = 2.5795e-01, time/batch = 0.6162s	
5547/16650 (epoch 16.658), train_loss = 0.98029373, grad/param norm = 2.2223e-01, time/batch = 0.6166s	
5548/16650 (epoch 16.661), train_loss = 1.18065368, grad/param norm = 2.4838e-01, time/batch = 0.6196s	
5549/16650 (epoch 16.664), train_loss = 1.09248305, grad/param norm = 2.4183e-01, time/batch = 0.6156s	
5550/16650 (epoch 16.667), train_loss = 1.22305336, grad/param norm = 2.4644e-01, time/batch = 0.6166s	
5551/16650 (epoch 16.670), train_loss = 0.93728278, grad/param norm = 2.2868e-01, time/batch = 0.6177s	
5552/16650 (epoch 16.673), train_loss = 1.00804443, grad/param norm = 2.1092e-01, time/batch = 0.6178s	
5553/16650 (epoch 16.676), train_loss = 1.08700903, grad/param norm = 2.5058e-01, time/batch = 0.6195s	
5554/16650 (epoch 16.679), train_loss = 0.97086690, grad/param norm = 2.3548e-01, time/batch = 0.6145s	
5555/16650 (epoch 16.682), train_loss = 1.11566746, grad/param norm = 2.2985e-01, time/batch = 0.6158s	
5556/16650 (epoch 16.685), train_loss = 0.92352101, grad/param norm = 2.4406e-01, time/batch = 0.6155s	
5557/16650 (epoch 16.688), train_loss = 1.13919989, grad/param norm = 2.4699e-01, time/batch = 0.6162s	
5558/16650 (epoch 16.691), train_loss = 1.14600455, grad/param norm = 2.5053e-01, time/batch = 0.6153s	
5559/16650 (epoch 16.694), train_loss = 0.94477969, grad/param norm = 2.0626e-01, time/batch = 0.6175s	
5560/16650 (epoch 16.697), train_loss = 0.95631804, grad/param norm = 2.2173e-01, time/batch = 0.6170s	
5561/16650 (epoch 16.700), train_loss = 1.18916570, grad/param norm = 2.5305e-01, time/batch = 0.6206s	
5562/16650 (epoch 16.703), train_loss = 0.99946321, grad/param norm = 2.4799e-01, time/batch = 0.6168s	
5563/16650 (epoch 16.706), train_loss = 1.15484843, grad/param norm = 2.7609e-01, time/batch = 0.6158s	
5564/16650 (epoch 16.709), train_loss = 0.99555798, grad/param norm = 2.1740e-01, time/batch = 0.6170s	
5565/16650 (epoch 16.712), train_loss = 1.01007829, grad/param norm = 2.6723e-01, time/batch = 0.6154s	
5566/16650 (epoch 16.715), train_loss = 1.21190630, grad/param norm = 2.4250e-01, time/batch = 0.6155s	
5567/16650 (epoch 16.718), train_loss = 1.22783087, grad/param norm = 2.5305e-01, time/batch = 0.6159s	
5568/16650 (epoch 16.721), train_loss = 1.22439436, grad/param norm = 2.6814e-01, time/batch = 0.6155s	
5569/16650 (epoch 16.724), train_loss = 1.22340171, grad/param norm = 2.6378e-01, time/batch = 0.6163s	
5570/16650 (epoch 16.727), train_loss = 1.16738390, grad/param norm = 2.3200e-01, time/batch = 0.6174s	
5571/16650 (epoch 16.730), train_loss = 1.07279829, grad/param norm = 2.2685e-01, time/batch = 0.6215s	
5572/16650 (epoch 16.733), train_loss = 1.19179420, grad/param norm = 2.5440e-01, time/batch = 0.6217s	
5573/16650 (epoch 16.736), train_loss = 0.92168253, grad/param norm = 2.2044e-01, time/batch = 0.6210s	
5574/16650 (epoch 16.739), train_loss = 1.08185316, grad/param norm = 2.3050e-01, time/batch = 0.6211s	
5575/16650 (epoch 16.742), train_loss = 1.12279102, grad/param norm = 2.6554e-01, time/batch = 0.6269s	
5576/16650 (epoch 16.745), train_loss = 0.91834182, grad/param norm = 2.1772e-01, time/batch = 0.6249s	
5577/16650 (epoch 16.748), train_loss = 0.98240998, grad/param norm = 2.3966e-01, time/batch = 0.6236s	
5578/16650 (epoch 16.751), train_loss = 1.16714473, grad/param norm = 3.5197e-01, time/batch = 0.6275s	
5579/16650 (epoch 16.754), train_loss = 1.26718737, grad/param norm = 2.7015e-01, time/batch = 0.6553s	
5580/16650 (epoch 16.757), train_loss = 1.22680685, grad/param norm = 2.4644e-01, time/batch = 0.6304s	
5581/16650 (epoch 16.760), train_loss = 1.07203733, grad/param norm = 2.3726e-01, time/batch = 0.6185s	
5582/16650 (epoch 16.763), train_loss = 1.01383469, grad/param norm = 2.5113e-01, time/batch = 0.6183s	
5583/16650 (epoch 16.766), train_loss = 1.06875350, grad/param norm = 2.0705e-01, time/batch = 0.6261s	
5584/16650 (epoch 16.769), train_loss = 1.11558110, grad/param norm = 2.3915e-01, time/batch = 0.6366s	
5585/16650 (epoch 16.772), train_loss = 1.04510996, grad/param norm = 2.2389e-01, time/batch = 0.6199s	
5586/16650 (epoch 16.775), train_loss = 1.09330099, grad/param norm = 2.4666e-01, time/batch = 0.6172s	
5587/16650 (epoch 16.778), train_loss = 1.11390610, grad/param norm = 2.4049e-01, time/batch = 0.6179s	
5588/16650 (epoch 16.781), train_loss = 1.20076131, grad/param norm = 2.2515e-01, time/batch = 0.6221s	
5589/16650 (epoch 16.784), train_loss = 1.18049247, grad/param norm = 2.5119e-01, time/batch = 0.6256s	
5590/16650 (epoch 16.787), train_loss = 1.18925397, grad/param norm = 2.4247e-01, time/batch = 0.6253s	
5591/16650 (epoch 16.790), train_loss = 1.13617157, grad/param norm = 2.2604e-01, time/batch = 0.6419s	
5592/16650 (epoch 16.793), train_loss = 0.98570125, grad/param norm = 2.2862e-01, time/batch = 0.6643s	
5593/16650 (epoch 16.796), train_loss = 1.43286169, grad/param norm = 2.6911e-01, time/batch = 0.6549s	
5594/16650 (epoch 16.799), train_loss = 1.33144709, grad/param norm = 2.4445e-01, time/batch = 0.6369s	
5595/16650 (epoch 16.802), train_loss = 1.13050030, grad/param norm = 2.3632e-01, time/batch = 0.6337s	
5596/16650 (epoch 16.805), train_loss = 1.09744283, grad/param norm = 2.3269e-01, time/batch = 0.6337s	
5597/16650 (epoch 16.808), train_loss = 1.14515935, grad/param norm = 2.5128e-01, time/batch = 0.6339s	
5598/16650 (epoch 16.811), train_loss = 1.25089683, grad/param norm = 2.3779e-01, time/batch = 0.6256s	
5599/16650 (epoch 16.814), train_loss = 1.00730856, grad/param norm = 2.3358e-01, time/batch = 0.6361s	
5600/16650 (epoch 16.817), train_loss = 1.06269067, grad/param norm = 2.4635e-01, time/batch = 0.6159s	
5601/16650 (epoch 16.820), train_loss = 1.16750700, grad/param norm = 2.5200e-01, time/batch = 0.6181s	
5602/16650 (epoch 16.823), train_loss = 1.03492375, grad/param norm = 2.1685e-01, time/batch = 0.6270s	
5603/16650 (epoch 16.826), train_loss = 1.10524401, grad/param norm = 2.2731e-01, time/batch = 0.6199s	
5604/16650 (epoch 16.829), train_loss = 1.20981335, grad/param norm = 2.3528e-01, time/batch = 0.6352s	
5605/16650 (epoch 16.832), train_loss = 1.22076373, grad/param norm = 2.5620e-01, time/batch = 0.6272s	
5606/16650 (epoch 16.835), train_loss = 1.20006541, grad/param norm = 2.8197e-01, time/batch = 0.6165s	
5607/16650 (epoch 16.838), train_loss = 1.00619263, grad/param norm = 2.4962e-01, time/batch = 0.6234s	
5608/16650 (epoch 16.841), train_loss = 1.05236768, grad/param norm = 2.2535e-01, time/batch = 0.6288s	
5609/16650 (epoch 16.844), train_loss = 1.03982027, grad/param norm = 2.2671e-01, time/batch = 0.6562s	
5610/16650 (epoch 16.847), train_loss = 1.20278794, grad/param norm = 2.5047e-01, time/batch = 0.6359s	
5611/16650 (epoch 16.850), train_loss = 0.99909323, grad/param norm = 2.6937e-01, time/batch = 0.6191s	
5612/16650 (epoch 16.853), train_loss = 1.16568504, grad/param norm = 2.5702e-01, time/batch = 0.6168s	
5613/16650 (epoch 16.856), train_loss = 1.01973761, grad/param norm = 2.3294e-01, time/batch = 0.6349s	
5614/16650 (epoch 16.859), train_loss = 1.20456585, grad/param norm = 2.6498e-01, time/batch = 0.6562s	
5615/16650 (epoch 16.862), train_loss = 1.11289299, grad/param norm = 2.4212e-01, time/batch = 0.6227s	
5616/16650 (epoch 16.865), train_loss = 0.91995542, grad/param norm = 2.1071e-01, time/batch = 0.6223s	
5617/16650 (epoch 16.868), train_loss = 1.18547589, grad/param norm = 2.5334e-01, time/batch = 0.6175s	
5618/16650 (epoch 16.871), train_loss = 1.15431969, grad/param norm = 2.3237e-01, time/batch = 0.6192s	
5619/16650 (epoch 16.874), train_loss = 1.15103172, grad/param norm = 2.3825e-01, time/batch = 0.6163s	
5620/16650 (epoch 16.877), train_loss = 1.08484787, grad/param norm = 2.2941e-01, time/batch = 0.6148s	
5621/16650 (epoch 16.880), train_loss = 1.04167415, grad/param norm = 2.3542e-01, time/batch = 0.6258s	
5622/16650 (epoch 16.883), train_loss = 1.13294088, grad/param norm = 2.5186e-01, time/batch = 0.6247s	
5623/16650 (epoch 16.886), train_loss = 1.13014213, grad/param norm = 2.3483e-01, time/batch = 0.6171s	
5624/16650 (epoch 16.889), train_loss = 0.96702588, grad/param norm = 2.3878e-01, time/batch = 0.6156s	
5625/16650 (epoch 16.892), train_loss = 1.08378608, grad/param norm = 2.2265e-01, time/batch = 0.6154s	
5626/16650 (epoch 16.895), train_loss = 1.19107323, grad/param norm = 2.6458e-01, time/batch = 0.6149s	
5627/16650 (epoch 16.898), train_loss = 1.17325759, grad/param norm = 2.4305e-01, time/batch = 0.6139s	
5628/16650 (epoch 16.901), train_loss = 1.11224548, grad/param norm = 2.3323e-01, time/batch = 0.6155s	
5629/16650 (epoch 16.904), train_loss = 1.03786299, grad/param norm = 2.5096e-01, time/batch = 0.6155s	
5630/16650 (epoch 16.907), train_loss = 1.18948774, grad/param norm = 2.8303e-01, time/batch = 0.6186s	
5631/16650 (epoch 16.910), train_loss = 1.16301817, grad/param norm = 2.5548e-01, time/batch = 0.6180s	
5632/16650 (epoch 16.913), train_loss = 1.03470363, grad/param norm = 2.4615e-01, time/batch = 0.6178s	
5633/16650 (epoch 16.916), train_loss = 1.13508027, grad/param norm = 2.4547e-01, time/batch = 0.6157s	
5634/16650 (epoch 16.919), train_loss = 1.29937701, grad/param norm = 2.6486e-01, time/batch = 0.6158s	
5635/16650 (epoch 16.922), train_loss = 1.22868361, grad/param norm = 2.5023e-01, time/batch = 0.6162s	
5636/16650 (epoch 16.925), train_loss = 1.04428259, grad/param norm = 2.5252e-01, time/batch = 0.6165s	
5637/16650 (epoch 16.928), train_loss = 1.07598093, grad/param norm = 2.3232e-01, time/batch = 0.6289s	
5638/16650 (epoch 16.931), train_loss = 1.16165382, grad/param norm = 2.3847e-01, time/batch = 0.6299s	
5639/16650 (epoch 16.934), train_loss = 0.97300359, grad/param norm = 2.4680e-01, time/batch = 0.6318s	
5640/16650 (epoch 16.937), train_loss = 1.06492073, grad/param norm = 2.6711e-01, time/batch = 0.6186s	
5641/16650 (epoch 16.940), train_loss = 1.05754536, grad/param norm = 2.1848e-01, time/batch = 0.6210s	
5642/16650 (epoch 16.943), train_loss = 1.12724218, grad/param norm = 2.4880e-01, time/batch = 0.6180s	
5643/16650 (epoch 16.946), train_loss = 1.02663343, grad/param norm = 2.3173e-01, time/batch = 0.6172s	
5644/16650 (epoch 16.949), train_loss = 0.99163453, grad/param norm = 2.5273e-01, time/batch = 0.6263s	
5645/16650 (epoch 16.952), train_loss = 0.90680922, grad/param norm = 2.3643e-01, time/batch = 0.6307s	
5646/16650 (epoch 16.955), train_loss = 1.04604770, grad/param norm = 2.3986e-01, time/batch = 0.6278s	
5647/16650 (epoch 16.958), train_loss = 1.17035632, grad/param norm = 2.6179e-01, time/batch = 0.6226s	
5648/16650 (epoch 16.961), train_loss = 1.08674651, grad/param norm = 2.3391e-01, time/batch = 0.6210s	
5649/16650 (epoch 16.964), train_loss = 1.01423664, grad/param norm = 2.4795e-01, time/batch = 0.6161s	
5650/16650 (epoch 16.967), train_loss = 1.23601554, grad/param norm = 2.5776e-01, time/batch = 0.6168s	
5651/16650 (epoch 16.970), train_loss = 0.99069227, grad/param norm = 2.2452e-01, time/batch = 0.6190s	
5652/16650 (epoch 16.973), train_loss = 1.05761650, grad/param norm = 2.7786e-01, time/batch = 0.6183s	
5653/16650 (epoch 16.976), train_loss = 1.00538002, grad/param norm = 2.3319e-01, time/batch = 0.6178s	
5654/16650 (epoch 16.979), train_loss = 1.13653044, grad/param norm = 2.6628e-01, time/batch = 0.6183s	
5655/16650 (epoch 16.982), train_loss = 1.18299120, grad/param norm = 2.5270e-01, time/batch = 0.6197s	
5656/16650 (epoch 16.985), train_loss = 1.06443769, grad/param norm = 2.2452e-01, time/batch = 0.6218s	
5657/16650 (epoch 16.988), train_loss = 1.28175460, grad/param norm = 2.8168e-01, time/batch = 0.6191s	
5658/16650 (epoch 16.991), train_loss = 1.02514460, grad/param norm = 2.4987e-01, time/batch = 0.6374s	
5659/16650 (epoch 16.994), train_loss = 1.05185605, grad/param norm = 2.7028e-01, time/batch = 0.6552s	
5660/16650 (epoch 16.997), train_loss = 1.11766008, grad/param norm = 2.5160e-01, time/batch = 0.6147s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
5661/16650 (epoch 17.000), train_loss = 1.17189041, grad/param norm = 2.6935e-01, time/batch = 0.6195s	
5662/16650 (epoch 17.003), train_loss = 1.19143084, grad/param norm = 2.9958e-01, time/batch = 0.6197s	
5663/16650 (epoch 17.006), train_loss = 1.19403467, grad/param norm = 2.6910e-01, time/batch = 0.6495s	
5664/16650 (epoch 17.009), train_loss = 1.28605526, grad/param norm = 2.6445e-01, time/batch = 0.6450s	
5665/16650 (epoch 17.012), train_loss = 1.29013714, grad/param norm = 2.7843e-01, time/batch = 0.6158s	
5666/16650 (epoch 17.015), train_loss = 1.11409002, grad/param norm = 2.5354e-01, time/batch = 0.6168s	
5667/16650 (epoch 17.018), train_loss = 0.91432088, grad/param norm = 2.3412e-01, time/batch = 0.6146s	
5668/16650 (epoch 17.021), train_loss = 1.23585939, grad/param norm = 2.8108e-01, time/batch = 0.6154s	
5669/16650 (epoch 17.024), train_loss = 1.10923760, grad/param norm = 2.5635e-01, time/batch = 0.6144s	
5670/16650 (epoch 17.027), train_loss = 1.20457792, grad/param norm = 2.6304e-01, time/batch = 0.6152s	
5671/16650 (epoch 17.030), train_loss = 0.98259600, grad/param norm = 2.4379e-01, time/batch = 0.6176s	
5672/16650 (epoch 17.033), train_loss = 1.09818782, grad/param norm = 2.1705e-01, time/batch = 0.6166s	
5673/16650 (epoch 17.036), train_loss = 0.90075493, grad/param norm = 2.5065e-01, time/batch = 0.6169s	
5674/16650 (epoch 17.039), train_loss = 1.21374744, grad/param norm = 2.4921e-01, time/batch = 0.6157s	
5675/16650 (epoch 17.042), train_loss = 1.19427181, grad/param norm = 2.4060e-01, time/batch = 0.6171s	
5676/16650 (epoch 17.045), train_loss = 1.09610020, grad/param norm = 2.4242e-01, time/batch = 0.6140s	
5677/16650 (epoch 17.048), train_loss = 1.17974028, grad/param norm = 2.4476e-01, time/batch = 0.6161s	
5678/16650 (epoch 17.051), train_loss = 1.10893742, grad/param norm = 2.4812e-01, time/batch = 0.6150s	
5679/16650 (epoch 17.054), train_loss = 1.11909398, grad/param norm = 2.4879e-01, time/batch = 0.6172s	
5680/16650 (epoch 17.057), train_loss = 1.11681891, grad/param norm = 2.4967e-01, time/batch = 0.6218s	
5681/16650 (epoch 17.060), train_loss = 0.97634278, grad/param norm = 2.2287e-01, time/batch = 0.6245s	
5682/16650 (epoch 17.063), train_loss = 1.08608225, grad/param norm = 2.4369e-01, time/batch = 0.6190s	
5683/16650 (epoch 17.066), train_loss = 1.27588167, grad/param norm = 2.5327e-01, time/batch = 0.6191s	
5684/16650 (epoch 17.069), train_loss = 1.21370609, grad/param norm = 2.6427e-01, time/batch = 0.6267s	
5685/16650 (epoch 17.072), train_loss = 1.05149517, grad/param norm = 2.4169e-01, time/batch = 0.6391s	
5686/16650 (epoch 17.075), train_loss = 1.17614027, grad/param norm = 2.4942e-01, time/batch = 0.6409s	
5687/16650 (epoch 17.078), train_loss = 1.23522095, grad/param norm = 2.6203e-01, time/batch = 0.6555s	
5688/16650 (epoch 17.081), train_loss = 1.10972594, grad/param norm = 2.5508e-01, time/batch = 0.6543s	
5689/16650 (epoch 17.084), train_loss = 1.15767130, grad/param norm = 2.3309e-01, time/batch = 0.6575s	
5690/16650 (epoch 17.087), train_loss = 1.09429273, grad/param norm = 2.5132e-01, time/batch = 0.6349s	
5691/16650 (epoch 17.090), train_loss = 1.07157341, grad/param norm = 2.3227e-01, time/batch = 0.6273s	
5692/16650 (epoch 17.093), train_loss = 1.33227199, grad/param norm = 2.6582e-01, time/batch = 0.6218s	
5693/16650 (epoch 17.096), train_loss = 1.07548991, grad/param norm = 2.4229e-01, time/batch = 0.6230s	
5694/16650 (epoch 17.099), train_loss = 1.11214291, grad/param norm = 2.3165e-01, time/batch = 0.6201s	
5695/16650 (epoch 17.102), train_loss = 1.16449980, grad/param norm = 2.5230e-01, time/batch = 0.6260s	
5696/16650 (epoch 17.105), train_loss = 1.19647509, grad/param norm = 2.5558e-01, time/batch = 0.6297s	
5697/16650 (epoch 17.108), train_loss = 1.16302674, grad/param norm = 2.4122e-01, time/batch = 0.6336s	
5698/16650 (epoch 17.111), train_loss = 1.19549338, grad/param norm = 2.3051e-01, time/batch = 0.6269s	
5699/16650 (epoch 17.114), train_loss = 1.24782345, grad/param norm = 2.5987e-01, time/batch = 0.6260s	
5700/16650 (epoch 17.117), train_loss = 1.26201780, grad/param norm = 2.4841e-01, time/batch = 0.6333s	
5701/16650 (epoch 17.120), train_loss = 1.01369289, grad/param norm = 2.1210e-01, time/batch = 0.6485s	
5702/16650 (epoch 17.123), train_loss = 1.09641942, grad/param norm = 2.4547e-01, time/batch = 0.6478s	
5703/16650 (epoch 17.126), train_loss = 1.12665749, grad/param norm = 2.4314e-01, time/batch = 0.6500s	
5704/16650 (epoch 17.129), train_loss = 1.17229140, grad/param norm = 2.7925e-01, time/batch = 0.6548s	
5705/16650 (epoch 17.132), train_loss = 1.13731569, grad/param norm = 2.3950e-01, time/batch = 0.6508s	
5706/16650 (epoch 17.135), train_loss = 1.19729069, grad/param norm = 2.4656e-01, time/batch = 0.6527s	
5707/16650 (epoch 17.138), train_loss = 1.19068793, grad/param norm = 2.3259e-01, time/batch = 0.6376s	
5708/16650 (epoch 17.141), train_loss = 1.20881798, grad/param norm = 2.7380e-01, time/batch = 0.6317s	
5709/16650 (epoch 17.144), train_loss = 1.11304076, grad/param norm = 2.3791e-01, time/batch = 0.6567s	
5710/16650 (epoch 17.147), train_loss = 1.27422235, grad/param norm = 2.4028e-01, time/batch = 0.6367s	
5711/16650 (epoch 17.150), train_loss = 1.35659840, grad/param norm = 3.4572e-01, time/batch = 0.6171s	
5712/16650 (epoch 17.153), train_loss = 1.18456828, grad/param norm = 2.8894e-01, time/batch = 0.6177s	
5713/16650 (epoch 17.156), train_loss = 1.00368648, grad/param norm = 2.2913e-01, time/batch = 0.6283s	
5714/16650 (epoch 17.159), train_loss = 1.20324991, grad/param norm = 2.6040e-01, time/batch = 0.6556s	
5715/16650 (epoch 17.162), train_loss = 1.28481120, grad/param norm = 2.6212e-01, time/batch = 0.6291s	
5716/16650 (epoch 17.165), train_loss = 1.24821898, grad/param norm = 2.6759e-01, time/batch = 0.6173s	
5717/16650 (epoch 17.168), train_loss = 0.93700746, grad/param norm = 2.1105e-01, time/batch = 0.6152s	
5718/16650 (epoch 17.171), train_loss = 1.23273083, grad/param norm = 2.2587e-01, time/batch = 0.6170s	
5719/16650 (epoch 17.174), train_loss = 0.97023315, grad/param norm = 2.3416e-01, time/batch = 0.6150s	
5720/16650 (epoch 17.177), train_loss = 1.11588564, grad/param norm = 2.5523e-01, time/batch = 0.6143s	
5721/16650 (epoch 17.180), train_loss = 1.24766425, grad/param norm = 2.6310e-01, time/batch = 0.6201s	
5722/16650 (epoch 17.183), train_loss = 1.39924794, grad/param norm = 2.7897e-01, time/batch = 0.6162s	
5723/16650 (epoch 17.186), train_loss = 1.20961399, grad/param norm = 2.4665e-01, time/batch = 0.6179s	
5724/16650 (epoch 17.189), train_loss = 1.03267466, grad/param norm = 2.3747e-01, time/batch = 0.6173s	
5725/16650 (epoch 17.192), train_loss = 1.05181839, grad/param norm = 2.4062e-01, time/batch = 0.6149s	
5726/16650 (epoch 17.195), train_loss = 1.08422418, grad/param norm = 2.4302e-01, time/batch = 0.6180s	
5727/16650 (epoch 17.198), train_loss = 0.94481631, grad/param norm = 1.9906e-01, time/batch = 0.6165s	
5728/16650 (epoch 17.201), train_loss = 1.06879957, grad/param norm = 2.4695e-01, time/batch = 0.6164s	
5729/16650 (epoch 17.204), train_loss = 1.11463710, grad/param norm = 2.3881e-01, time/batch = 0.6183s	
5730/16650 (epoch 17.207), train_loss = 1.18572882, grad/param norm = 2.7029e-01, time/batch = 0.6191s	
5731/16650 (epoch 17.210), train_loss = 1.08081215, grad/param norm = 2.3488e-01, time/batch = 0.6185s	
5732/16650 (epoch 17.213), train_loss = 1.20234485, grad/param norm = 2.5076e-01, time/batch = 0.6227s	
5733/16650 (epoch 17.216), train_loss = 1.09220109, grad/param norm = 2.4191e-01, time/batch = 0.6172s	
5734/16650 (epoch 17.219), train_loss = 1.12669990, grad/param norm = 2.6608e-01, time/batch = 0.6181s	
5735/16650 (epoch 17.222), train_loss = 1.15603174, grad/param norm = 2.3655e-01, time/batch = 0.6172s	
5736/16650 (epoch 17.225), train_loss = 1.13524303, grad/param norm = 2.3243e-01, time/batch = 0.6172s	
5737/16650 (epoch 17.228), train_loss = 1.01659539, grad/param norm = 2.4043e-01, time/batch = 0.6197s	
5738/16650 (epoch 17.231), train_loss = 1.09438660, grad/param norm = 2.3415e-01, time/batch = 0.6169s	
5739/16650 (epoch 17.234), train_loss = 1.29068057, grad/param norm = 2.6364e-01, time/batch = 0.6155s	
5740/16650 (epoch 17.237), train_loss = 1.17450746, grad/param norm = 2.6175e-01, time/batch = 0.6179s	
5741/16650 (epoch 17.240), train_loss = 1.16499784, grad/param norm = 2.4809e-01, time/batch = 0.6206s	
5742/16650 (epoch 17.243), train_loss = 1.14875646, grad/param norm = 2.4342e-01, time/batch = 0.6168s	
5743/16650 (epoch 17.246), train_loss = 1.25120147, grad/param norm = 2.5278e-01, time/batch = 0.6157s	
5744/16650 (epoch 17.249), train_loss = 0.98660909, grad/param norm = 2.3126e-01, time/batch = 0.6186s	
5745/16650 (epoch 17.252), train_loss = 1.08844846, grad/param norm = 2.3546e-01, time/batch = 0.6144s	
5746/16650 (epoch 17.255), train_loss = 1.22869660, grad/param norm = 2.5051e-01, time/batch = 0.6164s	
5747/16650 (epoch 17.258), train_loss = 1.25274090, grad/param norm = 2.5381e-01, time/batch = 0.6149s	
5748/16650 (epoch 17.261), train_loss = 1.14236369, grad/param norm = 2.4546e-01, time/batch = 0.6180s	
5749/16650 (epoch 17.264), train_loss = 1.09940590, grad/param norm = 2.5589e-01, time/batch = 0.6526s	
5750/16650 (epoch 17.267), train_loss = 1.08152149, grad/param norm = 2.4270e-01, time/batch = 0.6407s	
5751/16650 (epoch 17.270), train_loss = 1.13037845, grad/param norm = 2.3768e-01, time/batch = 0.6180s	
5752/16650 (epoch 17.273), train_loss = 1.24844721, grad/param norm = 2.2978e-01, time/batch = 0.6166s	
5753/16650 (epoch 17.276), train_loss = 1.14992752, grad/param norm = 2.3399e-01, time/batch = 0.6204s	
5754/16650 (epoch 17.279), train_loss = 1.10093766, grad/param norm = 2.3115e-01, time/batch = 0.6555s	
5755/16650 (epoch 17.282), train_loss = 1.02153635, grad/param norm = 2.2384e-01, time/batch = 0.6326s	
5756/16650 (epoch 17.285), train_loss = 1.01253835, grad/param norm = 2.1153e-01, time/batch = 0.6156s	
5757/16650 (epoch 17.288), train_loss = 1.06076714, grad/param norm = 2.3645e-01, time/batch = 0.6217s	
5758/16650 (epoch 17.291), train_loss = 0.86779509, grad/param norm = 1.9764e-01, time/batch = 0.6178s	
5759/16650 (epoch 17.294), train_loss = 0.98147595, grad/param norm = 1.9256e-01, time/batch = 0.6139s	
5760/16650 (epoch 17.297), train_loss = 1.06837319, grad/param norm = 2.4909e-01, time/batch = 0.6147s	
5761/16650 (epoch 17.300), train_loss = 0.88189877, grad/param norm = 2.0566e-01, time/batch = 0.6169s	
5762/16650 (epoch 17.303), train_loss = 0.94003511, grad/param norm = 2.0857e-01, time/batch = 0.6171s	
5763/16650 (epoch 17.306), train_loss = 1.18926238, grad/param norm = 2.3819e-01, time/batch = 0.6144s	
5764/16650 (epoch 17.309), train_loss = 1.20655220, grad/param norm = 2.4735e-01, time/batch = 0.6156s	
5765/16650 (epoch 17.312), train_loss = 1.01138876, grad/param norm = 2.4370e-01, time/batch = 0.6178s	
5766/16650 (epoch 17.315), train_loss = 0.79966397, grad/param norm = 1.8409e-01, time/batch = 0.6189s	
5767/16650 (epoch 17.318), train_loss = 0.88850682, grad/param norm = 2.1601e-01, time/batch = 0.6170s	
5768/16650 (epoch 17.321), train_loss = 1.28635727, grad/param norm = 2.6180e-01, time/batch = 0.6146s	
5769/16650 (epoch 17.324), train_loss = 1.03656477, grad/param norm = 2.3354e-01, time/batch = 0.6147s	
5770/16650 (epoch 17.327), train_loss = 1.22676906, grad/param norm = 2.9376e-01, time/batch = 0.6283s	
5771/16650 (epoch 17.330), train_loss = 1.15789193, grad/param norm = 2.4940e-01, time/batch = 0.6342s	
5772/16650 (epoch 17.333), train_loss = 1.18699931, grad/param norm = 2.7070e-01, time/batch = 0.6155s	
5773/16650 (epoch 17.336), train_loss = 1.00890507, grad/param norm = 2.6131e-01, time/batch = 0.6166s	
5774/16650 (epoch 17.339), train_loss = 1.08929842, grad/param norm = 2.4355e-01, time/batch = 0.6216s	
5775/16650 (epoch 17.342), train_loss = 1.04675713, grad/param norm = 2.5213e-01, time/batch = 0.6226s	
5776/16650 (epoch 17.345), train_loss = 0.95351310, grad/param norm = 2.0577e-01, time/batch = 0.6172s	
5777/16650 (epoch 17.348), train_loss = 1.13066845, grad/param norm = 2.5531e-01, time/batch = 0.6157s	
5778/16650 (epoch 17.351), train_loss = 1.18055595, grad/param norm = 2.5088e-01, time/batch = 0.6157s	
5779/16650 (epoch 17.354), train_loss = 1.20823751, grad/param norm = 2.6939e-01, time/batch = 0.6251s	
5780/16650 (epoch 17.357), train_loss = 1.16072712, grad/param norm = 2.6077e-01, time/batch = 0.6326s	
5781/16650 (epoch 17.360), train_loss = 1.15819003, grad/param norm = 2.3931e-01, time/batch = 0.6392s	
5782/16650 (epoch 17.363), train_loss = 1.24702714, grad/param norm = 2.6241e-01, time/batch = 0.6371s	
5783/16650 (epoch 17.366), train_loss = 1.31776146, grad/param norm = 2.7131e-01, time/batch = 0.6431s	
5784/16650 (epoch 17.369), train_loss = 1.12432267, grad/param norm = 2.4617e-01, time/batch = 0.6467s	
5785/16650 (epoch 17.372), train_loss = 1.11744778, grad/param norm = 2.3398e-01, time/batch = 0.6296s	
5786/16650 (epoch 17.375), train_loss = 1.12953134, grad/param norm = 2.3086e-01, time/batch = 0.6508s	
5787/16650 (epoch 17.378), train_loss = 1.01229353, grad/param norm = 2.1778e-01, time/batch = 0.6335s	
5788/16650 (epoch 17.381), train_loss = 1.14168456, grad/param norm = 2.2422e-01, time/batch = 0.6272s	
5789/16650 (epoch 17.384), train_loss = 1.26945705, grad/param norm = 2.6249e-01, time/batch = 0.6567s	
5790/16650 (epoch 17.387), train_loss = 0.87713945, grad/param norm = 2.0401e-01, time/batch = 0.6466s	
5791/16650 (epoch 17.390), train_loss = 1.19051985, grad/param norm = 2.4672e-01, time/batch = 0.6234s	
5792/16650 (epoch 17.393), train_loss = 1.09391843, grad/param norm = 2.5815e-01, time/batch = 0.6264s	
5793/16650 (epoch 17.396), train_loss = 1.24560783, grad/param norm = 3.2593e-01, time/batch = 0.6210s	
5794/16650 (epoch 17.399), train_loss = 1.19003435, grad/param norm = 3.0045e-01, time/batch = 0.6194s	
5795/16650 (epoch 17.402), train_loss = 1.02984010, grad/param norm = 2.3733e-01, time/batch = 0.6202s	
5796/16650 (epoch 17.405), train_loss = 0.94627560, grad/param norm = 2.3687e-01, time/batch = 0.6155s	
5797/16650 (epoch 17.408), train_loss = 1.21899478, grad/param norm = 2.6904e-01, time/batch = 0.6191s	
5798/16650 (epoch 17.411), train_loss = 1.00604418, grad/param norm = 2.7817e-01, time/batch = 0.6202s	
5799/16650 (epoch 17.414), train_loss = 0.99781607, grad/param norm = 2.4312e-01, time/batch = 0.6180s	
5800/16650 (epoch 17.417), train_loss = 0.95987188, grad/param norm = 2.3242e-01, time/batch = 0.6299s	
5801/16650 (epoch 17.420), train_loss = 0.95033269, grad/param norm = 2.3660e-01, time/batch = 0.6218s	
5802/16650 (epoch 17.423), train_loss = 0.80120717, grad/param norm = 1.8191e-01, time/batch = 0.6168s	
5803/16650 (epoch 17.426), train_loss = 0.99073512, grad/param norm = 2.5961e-01, time/batch = 0.6215s	
5804/16650 (epoch 17.429), train_loss = 1.21067496, grad/param norm = 2.5060e-01, time/batch = 0.6211s	
5805/16650 (epoch 17.432), train_loss = 1.19567753, grad/param norm = 2.6639e-01, time/batch = 0.6153s	
5806/16650 (epoch 17.435), train_loss = 1.30653770, grad/param norm = 2.5807e-01, time/batch = 0.6159s	
5807/16650 (epoch 17.438), train_loss = 1.30514114, grad/param norm = 2.7865e-01, time/batch = 0.6172s	
5808/16650 (epoch 17.441), train_loss = 1.13969286, grad/param norm = 2.7630e-01, time/batch = 0.6234s	
5809/16650 (epoch 17.444), train_loss = 1.02712623, grad/param norm = 2.3194e-01, time/batch = 0.6280s	
5810/16650 (epoch 17.447), train_loss = 1.08311278, grad/param norm = 2.3646e-01, time/batch = 0.6163s	
5811/16650 (epoch 17.450), train_loss = 1.01750919, grad/param norm = 2.1932e-01, time/batch = 0.6172s	
5812/16650 (epoch 17.453), train_loss = 1.05482780, grad/param norm = 2.2401e-01, time/batch = 0.6165s	
5813/16650 (epoch 17.456), train_loss = 0.96177682, grad/param norm = 2.5581e-01, time/batch = 0.6206s	
5814/16650 (epoch 17.459), train_loss = 1.01583307, grad/param norm = 2.4302e-01, time/batch = 0.6184s	
5815/16650 (epoch 17.462), train_loss = 1.23952036, grad/param norm = 2.8419e-01, time/batch = 0.6378s	
5816/16650 (epoch 17.465), train_loss = 1.03184984, grad/param norm = 2.6058e-01, time/batch = 0.6209s	
5817/16650 (epoch 17.468), train_loss = 0.84814815, grad/param norm = 2.1754e-01, time/batch = 0.6173s	
5818/16650 (epoch 17.471), train_loss = 0.70868324, grad/param norm = 1.7848e-01, time/batch = 0.6135s	
5819/16650 (epoch 17.474), train_loss = 0.94390687, grad/param norm = 2.1804e-01, time/batch = 0.6152s	
5820/16650 (epoch 17.477), train_loss = 1.12048707, grad/param norm = 2.4559e-01, time/batch = 0.6190s	
5821/16650 (epoch 17.480), train_loss = 1.15168478, grad/param norm = 2.7486e-01, time/batch = 0.6202s	
5822/16650 (epoch 17.483), train_loss = 1.26531379, grad/param norm = 2.5194e-01, time/batch = 0.6223s	
5823/16650 (epoch 17.486), train_loss = 0.98750011, grad/param norm = 2.2028e-01, time/batch = 0.6222s	
5824/16650 (epoch 17.489), train_loss = 1.04590094, grad/param norm = 2.3488e-01, time/batch = 0.6180s	
5825/16650 (epoch 17.492), train_loss = 1.08382502, grad/param norm = 2.2929e-01, time/batch = 0.6227s	
5826/16650 (epoch 17.495), train_loss = 0.99841518, grad/param norm = 2.6966e-01, time/batch = 0.6217s	
5827/16650 (epoch 17.498), train_loss = 1.08124066, grad/param norm = 2.5699e-01, time/batch = 0.6168s	
5828/16650 (epoch 17.502), train_loss = 1.26355065, grad/param norm = 2.5915e-01, time/batch = 0.6174s	
5829/16650 (epoch 17.505), train_loss = 1.15137754, grad/param norm = 2.2964e-01, time/batch = 0.6202s	
5830/16650 (epoch 17.508), train_loss = 1.13588987, grad/param norm = 2.4031e-01, time/batch = 0.6178s	
5831/16650 (epoch 17.511), train_loss = 1.20277808, grad/param norm = 2.4755e-01, time/batch = 0.6214s	
5832/16650 (epoch 17.514), train_loss = 0.92997329, grad/param norm = 2.2553e-01, time/batch = 0.6197s	
5833/16650 (epoch 17.517), train_loss = 1.07367256, grad/param norm = 2.4721e-01, time/batch = 0.6302s	
5834/16650 (epoch 17.520), train_loss = 1.03555164, grad/param norm = 2.5857e-01, time/batch = 0.6558s	
5835/16650 (epoch 17.523), train_loss = 1.03597554, grad/param norm = 2.3467e-01, time/batch = 0.6272s	
5836/16650 (epoch 17.526), train_loss = 1.18583312, grad/param norm = 2.5984e-01, time/batch = 0.6207s	
5837/16650 (epoch 17.529), train_loss = 1.26224558, grad/param norm = 2.7493e-01, time/batch = 0.6188s	
5838/16650 (epoch 17.532), train_loss = 0.85549648, grad/param norm = 2.1233e-01, time/batch = 0.6376s	
5839/16650 (epoch 17.535), train_loss = 0.93740528, grad/param norm = 2.3503e-01, time/batch = 0.6542s	
5840/16650 (epoch 17.538), train_loss = 0.96849966, grad/param norm = 2.7085e-01, time/batch = 0.6167s	
5841/16650 (epoch 17.541), train_loss = 1.23296570, grad/param norm = 2.5653e-01, time/batch = 0.6181s	
5842/16650 (epoch 17.544), train_loss = 1.26314626, grad/param norm = 2.6894e-01, time/batch = 0.6197s	
5843/16650 (epoch 17.547), train_loss = 0.96519716, grad/param norm = 2.2571e-01, time/batch = 0.6493s	
5844/16650 (epoch 17.550), train_loss = 1.02464167, grad/param norm = 2.4376e-01, time/batch = 0.6440s	
5845/16650 (epoch 17.553), train_loss = 1.05829083, grad/param norm = 2.6172e-01, time/batch = 0.6168s	
5846/16650 (epoch 17.556), train_loss = 1.00742412, grad/param norm = 2.3445e-01, time/batch = 0.6162s	
5847/16650 (epoch 17.559), train_loss = 0.88761545, grad/param norm = 2.2310e-01, time/batch = 0.6176s	
5848/16650 (epoch 17.562), train_loss = 1.04034717, grad/param norm = 2.4529e-01, time/batch = 0.6183s	
5849/16650 (epoch 17.565), train_loss = 0.85537881, grad/param norm = 2.2648e-01, time/batch = 0.6174s	
5850/16650 (epoch 17.568), train_loss = 0.86959141, grad/param norm = 2.1944e-01, time/batch = 0.6180s	
5851/16650 (epoch 17.571), train_loss = 0.89741376, grad/param norm = 2.9627e-01, time/batch = 0.6265s	
5852/16650 (epoch 17.574), train_loss = 1.03821032, grad/param norm = 2.5795e-01, time/batch = 0.6280s	
5853/16650 (epoch 17.577), train_loss = 0.99109653, grad/param norm = 2.1158e-01, time/batch = 0.6190s	
5854/16650 (epoch 17.580), train_loss = 0.90063602, grad/param norm = 2.2370e-01, time/batch = 0.6174s	
5855/16650 (epoch 17.583), train_loss = 1.02887004, grad/param norm = 2.3280e-01, time/batch = 0.6178s	
5856/16650 (epoch 17.586), train_loss = 1.00512226, grad/param norm = 2.9935e-01, time/batch = 0.6159s	
5857/16650 (epoch 17.589), train_loss = 0.92375361, grad/param norm = 2.2226e-01, time/batch = 0.6163s	
5858/16650 (epoch 17.592), train_loss = 1.07224973, grad/param norm = 2.5861e-01, time/batch = 0.6165s	
5859/16650 (epoch 17.595), train_loss = 0.98282111, grad/param norm = 2.3223e-01, time/batch = 0.6189s	
5860/16650 (epoch 17.598), train_loss = 0.99826498, grad/param norm = 2.3056e-01, time/batch = 0.6178s	
5861/16650 (epoch 17.601), train_loss = 0.97545328, grad/param norm = 2.7039e-01, time/batch = 0.6283s	
5862/16650 (epoch 17.604), train_loss = 1.13950231, grad/param norm = 2.5452e-01, time/batch = 0.6175s	
5863/16650 (epoch 17.607), train_loss = 1.10781030, grad/param norm = 2.4191e-01, time/batch = 0.6203s	
5864/16650 (epoch 17.610), train_loss = 0.95576686, grad/param norm = 2.2458e-01, time/batch = 0.6257s	
5865/16650 (epoch 17.613), train_loss = 1.18543421, grad/param norm = 2.5805e-01, time/batch = 0.6229s	
5866/16650 (epoch 17.616), train_loss = 1.20151594, grad/param norm = 2.8008e-01, time/batch = 0.6186s	
5867/16650 (epoch 17.619), train_loss = 0.88469606, grad/param norm = 2.3150e-01, time/batch = 0.6175s	
5868/16650 (epoch 17.622), train_loss = 0.86529858, grad/param norm = 2.1777e-01, time/batch = 0.6185s	
5869/16650 (epoch 17.625), train_loss = 0.96881849, grad/param norm = 2.1320e-01, time/batch = 0.6178s	
5870/16650 (epoch 17.628), train_loss = 1.00746763, grad/param norm = 2.5991e-01, time/batch = 0.6147s	
5871/16650 (epoch 17.631), train_loss = 1.07197097, grad/param norm = 2.6886e-01, time/batch = 0.6190s	
5872/16650 (epoch 17.634), train_loss = 1.30650322, grad/param norm = 2.9992e-01, time/batch = 0.6158s	
5873/16650 (epoch 17.637), train_loss = 1.26325375, grad/param norm = 2.5528e-01, time/batch = 0.6156s	
5874/16650 (epoch 17.640), train_loss = 0.98787112, grad/param norm = 2.4213e-01, time/batch = 0.6156s	
5875/16650 (epoch 17.643), train_loss = 1.13510874, grad/param norm = 2.3551e-01, time/batch = 0.6188s	
5876/16650 (epoch 17.646), train_loss = 1.12114837, grad/param norm = 2.6065e-01, time/batch = 0.6288s	
5877/16650 (epoch 17.649), train_loss = 1.10011297, grad/param norm = 2.5435e-01, time/batch = 0.6313s	
5878/16650 (epoch 17.652), train_loss = 1.18131426, grad/param norm = 2.6135e-01, time/batch = 0.6512s	
5879/16650 (epoch 17.655), train_loss = 1.13862361, grad/param norm = 2.9579e-01, time/batch = 0.6571s	
5880/16650 (epoch 17.658), train_loss = 0.95068906, grad/param norm = 2.3125e-01, time/batch = 0.6379s	
5881/16650 (epoch 17.661), train_loss = 1.14835575, grad/param norm = 2.5533e-01, time/batch = 0.6214s	
5882/16650 (epoch 17.664), train_loss = 1.06589693, grad/param norm = 2.3680e-01, time/batch = 0.6170s	
5883/16650 (epoch 17.667), train_loss = 1.19564700, grad/param norm = 2.5623e-01, time/batch = 0.6170s	
5884/16650 (epoch 17.670), train_loss = 0.91574013, grad/param norm = 2.3474e-01, time/batch = 0.6164s	
5885/16650 (epoch 17.673), train_loss = 0.98412868, grad/param norm = 2.2047e-01, time/batch = 0.6192s	
5886/16650 (epoch 17.676), train_loss = 1.06914573, grad/param norm = 2.5846e-01, time/batch = 0.6183s	
5887/16650 (epoch 17.679), train_loss = 0.94772081, grad/param norm = 2.3892e-01, time/batch = 0.6162s	
5888/16650 (epoch 17.682), train_loss = 1.08749984, grad/param norm = 2.6018e-01, time/batch = 0.6164s	
5889/16650 (epoch 17.685), train_loss = 0.90117535, grad/param norm = 2.5165e-01, time/batch = 0.6166s	
5890/16650 (epoch 17.688), train_loss = 1.11600972, grad/param norm = 2.5217e-01, time/batch = 0.6300s	
5891/16650 (epoch 17.691), train_loss = 1.12537066, grad/param norm = 2.5798e-01, time/batch = 0.6206s	
5892/16650 (epoch 17.694), train_loss = 0.92394817, grad/param norm = 2.0724e-01, time/batch = 0.6200s	
5893/16650 (epoch 17.697), train_loss = 0.92773673, grad/param norm = 2.1490e-01, time/batch = 0.6211s	
5894/16650 (epoch 17.700), train_loss = 1.15394716, grad/param norm = 2.5238e-01, time/batch = 0.6263s	
5895/16650 (epoch 17.703), train_loss = 0.96748277, grad/param norm = 2.3869e-01, time/batch = 0.6229s	
5896/16650 (epoch 17.706), train_loss = 1.10701772, grad/param norm = 2.5376e-01, time/batch = 0.6237s	
5897/16650 (epoch 17.709), train_loss = 0.96066300, grad/param norm = 2.1600e-01, time/batch = 0.6334s	
5898/16650 (epoch 17.712), train_loss = 0.98724850, grad/param norm = 2.5887e-01, time/batch = 0.6304s	
5899/16650 (epoch 17.715), train_loss = 1.17230292, grad/param norm = 2.3742e-01, time/batch = 0.6163s	
5900/16650 (epoch 17.718), train_loss = 1.19757774, grad/param norm = 2.4595e-01, time/batch = 0.6166s	
5901/16650 (epoch 17.721), train_loss = 1.18854515, grad/param norm = 2.6432e-01, time/batch = 0.6224s	
5902/16650 (epoch 17.724), train_loss = 1.17829742, grad/param norm = 2.5582e-01, time/batch = 0.6190s	
5903/16650 (epoch 17.727), train_loss = 1.13940701, grad/param norm = 2.5297e-01, time/batch = 0.6221s	
5904/16650 (epoch 17.730), train_loss = 1.04830625, grad/param norm = 2.3975e-01, time/batch = 0.6181s	
5905/16650 (epoch 17.733), train_loss = 1.16768372, grad/param norm = 2.7209e-01, time/batch = 0.6167s	
5906/16650 (epoch 17.736), train_loss = 0.89853446, grad/param norm = 2.1724e-01, time/batch = 0.6158s	
5907/16650 (epoch 17.739), train_loss = 1.05792979, grad/param norm = 2.3948e-01, time/batch = 0.6155s	
5908/16650 (epoch 17.742), train_loss = 1.08600895, grad/param norm = 2.4641e-01, time/batch = 0.6219s	
5909/16650 (epoch 17.745), train_loss = 0.89509017, grad/param norm = 2.1631e-01, time/batch = 0.6243s	
5910/16650 (epoch 17.748), train_loss = 0.95248164, grad/param norm = 2.4962e-01, time/batch = 0.6215s	
5911/16650 (epoch 17.751), train_loss = 1.12944886, grad/param norm = 3.0512e-01, time/batch = 0.6228s	
5912/16650 (epoch 17.754), train_loss = 1.25652714, grad/param norm = 2.9688e-01, time/batch = 0.6263s	
5913/16650 (epoch 17.757), train_loss = 1.20347332, grad/param norm = 2.6538e-01, time/batch = 0.6149s	
5914/16650 (epoch 17.760), train_loss = 1.04907331, grad/param norm = 2.4584e-01, time/batch = 0.6163s	
5915/16650 (epoch 17.763), train_loss = 0.98342137, grad/param norm = 2.4016e-01, time/batch = 0.6239s	
5916/16650 (epoch 17.766), train_loss = 1.03904030, grad/param norm = 2.2342e-01, time/batch = 0.6236s	
5917/16650 (epoch 17.769), train_loss = 1.09331838, grad/param norm = 2.5686e-01, time/batch = 0.6423s	
5918/16650 (epoch 17.772), train_loss = 1.01739791, grad/param norm = 2.2023e-01, time/batch = 0.6475s	
5919/16650 (epoch 17.775), train_loss = 1.06047586, grad/param norm = 2.4365e-01, time/batch = 0.6453s	
5920/16650 (epoch 17.778), train_loss = 1.09712191, grad/param norm = 2.5234e-01, time/batch = 0.6406s	
5921/16650 (epoch 17.781), train_loss = 1.17500847, grad/param norm = 2.2564e-01, time/batch = 0.6414s	
5922/16650 (epoch 17.784), train_loss = 1.14188381, grad/param norm = 2.6996e-01, time/batch = 0.6397s	
5923/16650 (epoch 17.787), train_loss = 1.15846783, grad/param norm = 2.4774e-01, time/batch = 0.6241s	
5924/16650 (epoch 17.790), train_loss = 1.10639905, grad/param norm = 2.2854e-01, time/batch = 0.6265s	
5925/16650 (epoch 17.793), train_loss = 0.95841001, grad/param norm = 2.2928e-01, time/batch = 0.6137s	
5926/16650 (epoch 17.796), train_loss = 1.41546975, grad/param norm = 2.8349e-01, time/batch = 0.6155s	
5927/16650 (epoch 17.799), train_loss = 1.30192229, grad/param norm = 2.4435e-01, time/batch = 0.6243s	
5928/16650 (epoch 17.802), train_loss = 1.11200717, grad/param norm = 2.3841e-01, time/batch = 0.6554s	
5929/16650 (epoch 17.805), train_loss = 1.06881527, grad/param norm = 2.2713e-01, time/batch = 0.6289s	
5930/16650 (epoch 17.808), train_loss = 1.11866357, grad/param norm = 2.4840e-01, time/batch = 0.6138s	
5931/16650 (epoch 17.811), train_loss = 1.21433215, grad/param norm = 2.4222e-01, time/batch = 0.6165s	
5932/16650 (epoch 17.814), train_loss = 0.97328346, grad/param norm = 2.2925e-01, time/batch = 0.6371s	
5933/16650 (epoch 17.817), train_loss = 1.03263577, grad/param norm = 2.4858e-01, time/batch = 0.6565s	
5934/16650 (epoch 17.820), train_loss = 1.14054206, grad/param norm = 2.5101e-01, time/batch = 0.6240s	
5935/16650 (epoch 17.823), train_loss = 1.01594556, grad/param norm = 2.1561e-01, time/batch = 0.6188s	
5936/16650 (epoch 17.826), train_loss = 1.07675736, grad/param norm = 2.2735e-01, time/batch = 0.6171s	
5937/16650 (epoch 17.829), train_loss = 1.16667651, grad/param norm = 2.4593e-01, time/batch = 0.6209s	
5938/16650 (epoch 17.832), train_loss = 1.18321378, grad/param norm = 2.6468e-01, time/batch = 0.6179s	
5939/16650 (epoch 17.835), train_loss = 1.16661790, grad/param norm = 2.7200e-01, time/batch = 0.6156s	
5940/16650 (epoch 17.838), train_loss = 0.98024318, grad/param norm = 2.3898e-01, time/batch = 0.6155s	
5941/16650 (epoch 17.841), train_loss = 1.03332881, grad/param norm = 2.3712e-01, time/batch = 0.6169s	
5942/16650 (epoch 17.844), train_loss = 1.00068762, grad/param norm = 2.2045e-01, time/batch = 0.6159s	
5943/16650 (epoch 17.847), train_loss = 1.16463486, grad/param norm = 2.4120e-01, time/batch = 0.6164s	
5944/16650 (epoch 17.850), train_loss = 0.97240880, grad/param norm = 2.4710e-01, time/batch = 0.6158s	
5945/16650 (epoch 17.853), train_loss = 1.13600168, grad/param norm = 2.6249e-01, time/batch = 0.6160s	
5946/16650 (epoch 17.856), train_loss = 1.00783476, grad/param norm = 2.4655e-01, time/batch = 0.6175s	
5947/16650 (epoch 17.859), train_loss = 1.16600814, grad/param norm = 2.4528e-01, time/batch = 0.6159s	
5948/16650 (epoch 17.862), train_loss = 1.08259608, grad/param norm = 2.3723e-01, time/batch = 0.6156s	
5949/16650 (epoch 17.865), train_loss = 0.89673707, grad/param norm = 2.0509e-01, time/batch = 0.6248s	
5950/16650 (epoch 17.868), train_loss = 1.14336760, grad/param norm = 2.5494e-01, time/batch = 0.6240s	
5951/16650 (epoch 17.871), train_loss = 1.12369390, grad/param norm = 2.3898e-01, time/batch = 0.6338s	
5952/16650 (epoch 17.874), train_loss = 1.12226336, grad/param norm = 2.4079e-01, time/batch = 0.6315s	
5953/16650 (epoch 17.877), train_loss = 1.07335761, grad/param norm = 2.3894e-01, time/batch = 0.6274s	
5954/16650 (epoch 17.880), train_loss = 1.00855584, grad/param norm = 2.3470e-01, time/batch = 0.6237s	
5955/16650 (epoch 17.883), train_loss = 1.09448424, grad/param norm = 2.5268e-01, time/batch = 0.6193s	
5956/16650 (epoch 17.886), train_loss = 1.09132516, grad/param norm = 2.3996e-01, time/batch = 0.6155s	
5957/16650 (epoch 17.889), train_loss = 0.94110550, grad/param norm = 2.3217e-01, time/batch = 0.6198s	
5958/16650 (epoch 17.892), train_loss = 1.06051235, grad/param norm = 2.2686e-01, time/batch = 0.6172s	
5959/16650 (epoch 17.895), train_loss = 1.15551910, grad/param norm = 2.5978e-01, time/batch = 0.6153s	
5960/16650 (epoch 17.898), train_loss = 1.13430968, grad/param norm = 2.4229e-01, time/batch = 0.6192s	
5961/16650 (epoch 17.901), train_loss = 1.07084631, grad/param norm = 2.2431e-01, time/batch = 0.6185s	
5962/16650 (epoch 17.904), train_loss = 1.00828341, grad/param norm = 2.4513e-01, time/batch = 0.6173s	
5963/16650 (epoch 17.907), train_loss = 1.15847902, grad/param norm = 2.6154e-01, time/batch = 0.6161s	
5964/16650 (epoch 17.910), train_loss = 1.14133605, grad/param norm = 2.5805e-01, time/batch = 0.6173s	
5965/16650 (epoch 17.913), train_loss = 1.01080693, grad/param norm = 2.5226e-01, time/batch = 0.6184s	
5966/16650 (epoch 17.916), train_loss = 1.09249537, grad/param norm = 2.3973e-01, time/batch = 0.6213s	
5967/16650 (epoch 17.919), train_loss = 1.27617054, grad/param norm = 2.8515e-01, time/batch = 0.6234s	
5968/16650 (epoch 17.922), train_loss = 1.20293467, grad/param norm = 2.5258e-01, time/batch = 0.6168s	
5969/16650 (epoch 17.925), train_loss = 1.01660987, grad/param norm = 2.6136e-01, time/batch = 0.6162s	
5970/16650 (epoch 17.928), train_loss = 1.04946127, grad/param norm = 2.4013e-01, time/batch = 0.6177s	
5971/16650 (epoch 17.931), train_loss = 1.13344929, grad/param norm = 2.6520e-01, time/batch = 0.6262s	
5972/16650 (epoch 17.934), train_loss = 0.95203625, grad/param norm = 2.4036e-01, time/batch = 0.6281s	
5973/16650 (epoch 17.937), train_loss = 1.01661680, grad/param norm = 2.4056e-01, time/batch = 0.6352s	
5974/16650 (epoch 17.940), train_loss = 1.02808004, grad/param norm = 2.3208e-01, time/batch = 0.6502s	
5975/16650 (epoch 17.943), train_loss = 1.09301379, grad/param norm = 2.4090e-01, time/batch = 0.6538s	
5976/16650 (epoch 17.946), train_loss = 0.98720930, grad/param norm = 2.3352e-01, time/batch = 0.6438s	
5977/16650 (epoch 17.949), train_loss = 0.96806431, grad/param norm = 2.5300e-01, time/batch = 0.6580s	
5978/16650 (epoch 17.952), train_loss = 0.89139684, grad/param norm = 2.3676e-01, time/batch = 0.6602s	
5979/16650 (epoch 17.955), train_loss = 1.02444306, grad/param norm = 2.3375e-01, time/batch = 0.6177s	
5980/16650 (epoch 17.958), train_loss = 1.14430198, grad/param norm = 2.8537e-01, time/batch = 0.6169s	
5981/16650 (epoch 17.961), train_loss = 1.06679761, grad/param norm = 2.4171e-01, time/batch = 0.6210s	
5982/16650 (epoch 17.964), train_loss = 0.99222594, grad/param norm = 2.6231e-01, time/batch = 0.6187s	
5983/16650 (epoch 17.967), train_loss = 1.20623027, grad/param norm = 2.5526e-01, time/batch = 0.6168s	
5984/16650 (epoch 17.970), train_loss = 0.97831522, grad/param norm = 2.4612e-01, time/batch = 0.6144s	
5985/16650 (epoch 17.973), train_loss = 1.02527713, grad/param norm = 2.7133e-01, time/batch = 0.6244s	
5986/16650 (epoch 17.976), train_loss = 0.98397348, grad/param norm = 2.3441e-01, time/batch = 0.6172s	
5987/16650 (epoch 17.979), train_loss = 1.10831996, grad/param norm = 2.5969e-01, time/batch = 0.6172s	
5988/16650 (epoch 17.982), train_loss = 1.13606025, grad/param norm = 2.4616e-01, time/batch = 0.6150s	
5989/16650 (epoch 17.985), train_loss = 1.04170996, grad/param norm = 2.2721e-01, time/batch = 0.6175s	
5990/16650 (epoch 17.988), train_loss = 1.23033806, grad/param norm = 2.5265e-01, time/batch = 0.6193s	
5991/16650 (epoch 17.991), train_loss = 0.99303367, grad/param norm = 2.3571e-01, time/batch = 0.6225s	
5992/16650 (epoch 17.994), train_loss = 1.00823303, grad/param norm = 2.3475e-01, time/batch = 0.6250s	
5993/16650 (epoch 17.997), train_loss = 1.09164959, grad/param norm = 2.8481e-01, time/batch = 0.6186s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
5994/16650 (epoch 18.000), train_loss = 1.13578940, grad/param norm = 2.9500e-01, time/batch = 0.6166s	
5995/16650 (epoch 18.003), train_loss = 1.17714822, grad/param norm = 3.1241e-01, time/batch = 0.6239s	
5996/16650 (epoch 18.006), train_loss = 1.17683821, grad/param norm = 3.1549e-01, time/batch = 0.6188s	
5997/16650 (epoch 18.009), train_loss = 1.24861097, grad/param norm = 2.6422e-01, time/batch = 0.6180s	
5998/16650 (epoch 18.012), train_loss = 1.24638277, grad/param norm = 2.6661e-01, time/batch = 0.6279s	
5999/16650 (epoch 18.015), train_loss = 1.08920527, grad/param norm = 2.8385e-01, time/batch = 0.6181s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch18.02_1.8307.t7	
6000/16650 (epoch 18.018), train_loss = 0.89959188, grad/param norm = 2.4524e-01, time/batch = 0.6159s	
6001/16650 (epoch 18.021), train_loss = 1.49560933, grad/param norm = 3.2382e-01, time/batch = 0.6331s	
6002/16650 (epoch 18.024), train_loss = 1.07473086, grad/param norm = 2.5849e-01, time/batch = 0.6210s	
6003/16650 (epoch 18.027), train_loss = 1.17524308, grad/param norm = 2.5946e-01, time/batch = 0.6222s	
6004/16650 (epoch 18.030), train_loss = 0.94786195, grad/param norm = 2.3688e-01, time/batch = 0.6280s	
6005/16650 (epoch 18.033), train_loss = 1.07685464, grad/param norm = 2.3678e-01, time/batch = 0.6259s	
6006/16650 (epoch 18.036), train_loss = 0.87057403, grad/param norm = 2.5108e-01, time/batch = 0.6321s	
6007/16650 (epoch 18.039), train_loss = 1.18970217, grad/param norm = 2.4550e-01, time/batch = 0.6286s	
6008/16650 (epoch 18.042), train_loss = 1.17235371, grad/param norm = 2.6373e-01, time/batch = 0.6228s	
6009/16650 (epoch 18.045), train_loss = 1.06507192, grad/param norm = 2.5301e-01, time/batch = 0.6177s	
6010/16650 (epoch 18.048), train_loss = 1.14794420, grad/param norm = 2.4066e-01, time/batch = 0.6188s	
6011/16650 (epoch 18.051), train_loss = 1.07027452, grad/param norm = 2.5451e-01, time/batch = 0.6218s	
6012/16650 (epoch 18.054), train_loss = 1.09743683, grad/param norm = 2.5772e-01, time/batch = 0.6507s	
6013/16650 (epoch 18.057), train_loss = 1.08310697, grad/param norm = 2.4631e-01, time/batch = 0.6426s	
6014/16650 (epoch 18.060), train_loss = 0.94343749, grad/param norm = 2.3258e-01, time/batch = 0.6178s	
6015/16650 (epoch 18.063), train_loss = 1.05668719, grad/param norm = 2.5410e-01, time/batch = 0.6170s	
6016/16650 (epoch 18.066), train_loss = 1.24867046, grad/param norm = 2.8416e-01, time/batch = 0.6226s	
6017/16650 (epoch 18.069), train_loss = 1.16913672, grad/param norm = 2.5583e-01, time/batch = 0.6552s	
6018/16650 (epoch 18.072), train_loss = 1.03392331, grad/param norm = 2.7048e-01, time/batch = 0.6359s	
6019/16650 (epoch 18.075), train_loss = 1.15043806, grad/param norm = 2.5263e-01, time/batch = 0.6244s	
6020/16650 (epoch 18.078), train_loss = 1.20011603, grad/param norm = 2.5457e-01, time/batch = 0.6270s	
6021/16650 (epoch 18.081), train_loss = 1.08240092, grad/param norm = 2.3926e-01, time/batch = 0.6425s	
6022/16650 (epoch 18.084), train_loss = 1.13490783, grad/param norm = 2.3199e-01, time/batch = 0.6183s	
6023/16650 (epoch 18.087), train_loss = 1.07128227, grad/param norm = 2.3685e-01, time/batch = 0.6168s	
6024/16650 (epoch 18.090), train_loss = 1.05440167, grad/param norm = 2.3678e-01, time/batch = 0.6195s	
6025/16650 (epoch 18.093), train_loss = 1.31167121, grad/param norm = 2.8831e-01, time/batch = 0.6221s	
6026/16650 (epoch 18.096), train_loss = 1.03622203, grad/param norm = 2.4034e-01, time/batch = 0.6181s	
6027/16650 (epoch 18.099), train_loss = 1.08250764, grad/param norm = 2.3534e-01, time/batch = 0.6181s	
6028/16650 (epoch 18.102), train_loss = 1.13182916, grad/param norm = 2.5767e-01, time/batch = 0.6270s	
6029/16650 (epoch 18.105), train_loss = 1.16634855, grad/param norm = 2.5398e-01, time/batch = 0.6215s	
6030/16650 (epoch 18.108), train_loss = 1.13499003, grad/param norm = 2.4603e-01, time/batch = 0.6268s	
6031/16650 (epoch 18.111), train_loss = 1.15673120, grad/param norm = 2.2734e-01, time/batch = 0.6229s	
6032/16650 (epoch 18.114), train_loss = 1.21086442, grad/param norm = 2.5082e-01, time/batch = 0.6202s	
6033/16650 (epoch 18.117), train_loss = 1.24604385, grad/param norm = 2.9046e-01, time/batch = 0.6216s	
6034/16650 (epoch 18.120), train_loss = 1.00101100, grad/param norm = 2.2440e-01, time/batch = 0.6199s	
6035/16650 (epoch 18.123), train_loss = 1.06573315, grad/param norm = 2.3401e-01, time/batch = 0.6172s	
6036/16650 (epoch 18.126), train_loss = 1.10540318, grad/param norm = 2.3883e-01, time/batch = 0.6154s	
6037/16650 (epoch 18.129), train_loss = 1.13524401, grad/param norm = 2.5182e-01, time/batch = 0.6180s	
6038/16650 (epoch 18.132), train_loss = 1.11084840, grad/param norm = 2.5752e-01, time/batch = 0.6166s	
6039/16650 (epoch 18.135), train_loss = 1.17429187, grad/param norm = 2.4135e-01, time/batch = 0.6164s	
6040/16650 (epoch 18.138), train_loss = 1.15974620, grad/param norm = 2.4376e-01, time/batch = 0.6270s	
6041/16650 (epoch 18.141), train_loss = 1.16888186, grad/param norm = 2.6767e-01, time/batch = 0.6282s	
6042/16650 (epoch 18.144), train_loss = 1.09342493, grad/param norm = 2.4336e-01, time/batch = 0.6308s	
6043/16650 (epoch 18.147), train_loss = 1.23933141, grad/param norm = 2.3280e-01, time/batch = 0.6285s	
6044/16650 (epoch 18.150), train_loss = 1.32480838, grad/param norm = 2.6014e-01, time/batch = 0.6235s	
6045/16650 (epoch 18.153), train_loss = 1.14701556, grad/param norm = 2.8744e-01, time/batch = 0.6269s	
6046/16650 (epoch 18.156), train_loss = 1.00215801, grad/param norm = 2.4856e-01, time/batch = 0.6350s	
6047/16650 (epoch 18.159), train_loss = 1.17470957, grad/param norm = 2.6626e-01, time/batch = 0.6219s	
6048/16650 (epoch 18.162), train_loss = 1.24253063, grad/param norm = 2.6760e-01, time/batch = 0.6257s	
6049/16650 (epoch 18.165), train_loss = 1.22333494, grad/param norm = 2.5935e-01, time/batch = 0.6203s	
6050/16650 (epoch 18.168), train_loss = 0.91977192, grad/param norm = 2.1157e-01, time/batch = 0.6211s	
6051/16650 (epoch 18.171), train_loss = 1.20792955, grad/param norm = 2.3888e-01, time/batch = 0.6282s	
6052/16650 (epoch 18.174), train_loss = 0.93857753, grad/param norm = 2.3905e-01, time/batch = 0.6570s	
6053/16650 (epoch 18.177), train_loss = 1.08483899, grad/param norm = 2.4107e-01, time/batch = 0.6374s	
6054/16650 (epoch 18.180), train_loss = 1.21193186, grad/param norm = 2.5269e-01, time/batch = 0.6202s	
6055/16650 (epoch 18.183), train_loss = 1.36932979, grad/param norm = 2.7518e-01, time/batch = 0.6189s	
6056/16650 (epoch 18.186), train_loss = 1.18750932, grad/param norm = 2.5099e-01, time/batch = 0.6240s	
6057/16650 (epoch 18.189), train_loss = 1.00958537, grad/param norm = 2.2980e-01, time/batch = 0.6197s	
6058/16650 (epoch 18.192), train_loss = 1.03511435, grad/param norm = 2.7426e-01, time/batch = 0.6146s	
6059/16650 (epoch 18.195), train_loss = 1.06014657, grad/param norm = 2.4799e-01, time/batch = 0.6165s	
6060/16650 (epoch 18.198), train_loss = 0.92425120, grad/param norm = 2.2414e-01, time/batch = 0.6153s	
6061/16650 (epoch 18.201), train_loss = 1.04596035, grad/param norm = 2.6338e-01, time/batch = 0.6292s	
6062/16650 (epoch 18.204), train_loss = 1.08558997, grad/param norm = 2.4073e-01, time/batch = 0.6180s	
6063/16650 (epoch 18.207), train_loss = 1.13411382, grad/param norm = 2.6505e-01, time/batch = 0.6224s	
6064/16650 (epoch 18.210), train_loss = 1.06787842, grad/param norm = 2.4375e-01, time/batch = 0.6396s	
6065/16650 (epoch 18.213), train_loss = 1.18368686, grad/param norm = 2.5459e-01, time/batch = 0.6537s	
6066/16650 (epoch 18.216), train_loss = 1.07296639, grad/param norm = 2.5060e-01, time/batch = 0.6501s	
6067/16650 (epoch 18.219), train_loss = 1.08563308, grad/param norm = 2.4228e-01, time/batch = 0.6257s	
6068/16650 (epoch 18.222), train_loss = 1.11677739, grad/param norm = 2.2417e-01, time/batch = 0.6335s	
6069/16650 (epoch 18.225), train_loss = 1.11532615, grad/param norm = 2.5016e-01, time/batch = 0.6220s	
6070/16650 (epoch 18.228), train_loss = 0.98472062, grad/param norm = 2.5020e-01, time/batch = 0.6187s	
6071/16650 (epoch 18.231), train_loss = 1.07413164, grad/param norm = 2.4254e-01, time/batch = 0.6172s	
6072/16650 (epoch 18.234), train_loss = 1.27532648, grad/param norm = 2.5984e-01, time/batch = 0.6147s	
6073/16650 (epoch 18.237), train_loss = 1.15078354, grad/param norm = 2.6406e-01, time/batch = 0.6368s	
6074/16650 (epoch 18.240), train_loss = 1.14521070, grad/param norm = 2.5223e-01, time/batch = 0.6235s	
6075/16650 (epoch 18.243), train_loss = 1.11179385, grad/param norm = 2.5831e-01, time/batch = 0.6229s	
6076/16650 (epoch 18.246), train_loss = 1.23502630, grad/param norm = 2.7799e-01, time/batch = 0.6248s	
6077/16650 (epoch 18.249), train_loss = 0.97130552, grad/param norm = 2.3909e-01, time/batch = 0.6245s	
6078/16650 (epoch 18.252), train_loss = 1.05980638, grad/param norm = 2.3393e-01, time/batch = 0.6297s	
6079/16650 (epoch 18.255), train_loss = 1.20276291, grad/param norm = 2.6600e-01, time/batch = 0.6175s	
6080/16650 (epoch 18.258), train_loss = 1.22778106, grad/param norm = 2.5786e-01, time/batch = 0.6201s	
6081/16650 (epoch 18.261), train_loss = 1.10945097, grad/param norm = 2.3953e-01, time/batch = 0.6256s	
6082/16650 (epoch 18.264), train_loss = 1.06709294, grad/param norm = 2.4942e-01, time/batch = 0.6232s	
6083/16650 (epoch 18.267), train_loss = 1.05941596, grad/param norm = 2.4833e-01, time/batch = 0.6281s	
6084/16650 (epoch 18.270), train_loss = 1.10984294, grad/param norm = 2.4297e-01, time/batch = 0.6230s	
6085/16650 (epoch 18.273), train_loss = 1.22316966, grad/param norm = 2.3271e-01, time/batch = 0.6244s	
6086/16650 (epoch 18.276), train_loss = 1.11654601, grad/param norm = 2.2976e-01, time/batch = 0.6226s	
6087/16650 (epoch 18.279), train_loss = 1.07238267, grad/param norm = 2.3241e-01, time/batch = 0.6555s	
6088/16650 (epoch 18.282), train_loss = 1.00212723, grad/param norm = 2.2688e-01, time/batch = 0.6336s	
6089/16650 (epoch 18.285), train_loss = 0.98590101, grad/param norm = 2.1555e-01, time/batch = 0.6229s	
6090/16650 (epoch 18.288), train_loss = 1.04265044, grad/param norm = 2.3970e-01, time/batch = 0.6225s	
6091/16650 (epoch 18.291), train_loss = 0.84479038, grad/param norm = 2.0610e-01, time/batch = 0.6404s	
6092/16650 (epoch 18.294), train_loss = 0.96304935, grad/param norm = 1.9842e-01, time/batch = 0.6561s	
6093/16650 (epoch 18.297), train_loss = 1.04799953, grad/param norm = 2.4237e-01, time/batch = 0.6265s	
6094/16650 (epoch 18.300), train_loss = 0.85877523, grad/param norm = 2.1061e-01, time/batch = 0.6291s	
6095/16650 (epoch 18.303), train_loss = 0.92593773, grad/param norm = 2.1390e-01, time/batch = 0.6317s	
6096/16650 (epoch 18.306), train_loss = 1.15929759, grad/param norm = 2.3322e-01, time/batch = 0.6351s	
6097/16650 (epoch 18.309), train_loss = 1.18207857, grad/param norm = 2.4722e-01, time/batch = 0.6214s	
6098/16650 (epoch 18.312), train_loss = 0.98938578, grad/param norm = 2.5939e-01, time/batch = 0.6223s	
6099/16650 (epoch 18.315), train_loss = 0.78130459, grad/param norm = 1.9401e-01, time/batch = 0.6211s	
6100/16650 (epoch 18.318), train_loss = 0.87017178, grad/param norm = 2.1695e-01, time/batch = 0.6188s	
6101/16650 (epoch 18.321), train_loss = 1.25200358, grad/param norm = 2.6421e-01, time/batch = 0.6262s	
6102/16650 (epoch 18.324), train_loss = 1.00703960, grad/param norm = 2.4178e-01, time/batch = 0.6217s	
6103/16650 (epoch 18.327), train_loss = 1.18713979, grad/param norm = 2.6951e-01, time/batch = 0.6362s	
6104/16650 (epoch 18.330), train_loss = 1.12859667, grad/param norm = 2.4597e-01, time/batch = 0.6366s	
6105/16650 (epoch 18.333), train_loss = 1.15784488, grad/param norm = 2.7182e-01, time/batch = 0.6208s	
6106/16650 (epoch 18.336), train_loss = 0.97824955, grad/param norm = 2.6687e-01, time/batch = 0.6275s	
6107/16650 (epoch 18.339), train_loss = 1.05333294, grad/param norm = 2.4500e-01, time/batch = 0.6296s	
6108/16650 (epoch 18.342), train_loss = 1.00851335, grad/param norm = 2.4406e-01, time/batch = 0.6318s	
6109/16650 (epoch 18.345), train_loss = 0.93003794, grad/param norm = 2.1527e-01, time/batch = 0.6247s	
6110/16650 (epoch 18.348), train_loss = 1.10360312, grad/param norm = 2.7227e-01, time/batch = 0.6211s	
6111/16650 (epoch 18.351), train_loss = 1.15243449, grad/param norm = 2.6930e-01, time/batch = 0.6270s	
6112/16650 (epoch 18.354), train_loss = 1.17539992, grad/param norm = 2.7756e-01, time/batch = 0.6204s	
6113/16650 (epoch 18.357), train_loss = 1.12113319, grad/param norm = 2.5179e-01, time/batch = 0.6193s	
6114/16650 (epoch 18.360), train_loss = 1.13868276, grad/param norm = 2.4860e-01, time/batch = 0.6175s	
6115/16650 (epoch 18.363), train_loss = 1.21551272, grad/param norm = 2.5333e-01, time/batch = 0.6181s	
6116/16650 (epoch 18.366), train_loss = 1.27454340, grad/param norm = 2.9061e-01, time/batch = 0.6193s	
6117/16650 (epoch 18.369), train_loss = 1.10404911, grad/param norm = 2.5325e-01, time/batch = 0.6354s	
6118/16650 (epoch 18.372), train_loss = 1.09138747, grad/param norm = 2.2696e-01, time/batch = 0.6253s	
6119/16650 (epoch 18.375), train_loss = 1.10384405, grad/param norm = 2.2777e-01, time/batch = 0.6305s	
6120/16650 (epoch 18.378), train_loss = 0.98990074, grad/param norm = 2.1896e-01, time/batch = 0.6288s	
6121/16650 (epoch 18.381), train_loss = 1.10950578, grad/param norm = 2.1794e-01, time/batch = 0.6280s	
6122/16650 (epoch 18.384), train_loss = 1.24342726, grad/param norm = 2.6910e-01, time/batch = 0.6185s	
6123/16650 (epoch 18.387), train_loss = 0.85919704, grad/param norm = 2.0578e-01, time/batch = 0.6175s	
6124/16650 (epoch 18.390), train_loss = 1.16825453, grad/param norm = 2.3725e-01, time/batch = 0.6203s	
6125/16650 (epoch 18.393), train_loss = 1.05952316, grad/param norm = 2.4472e-01, time/batch = 0.6168s	
6126/16650 (epoch 18.396), train_loss = 1.21002471, grad/param norm = 2.7604e-01, time/batch = 0.6316s	
6127/16650 (epoch 18.399), train_loss = 1.14566913, grad/param norm = 2.7384e-01, time/batch = 0.6556s	
6128/16650 (epoch 18.402), train_loss = 1.00262534, grad/param norm = 2.6082e-01, time/batch = 0.6211s	
6129/16650 (epoch 18.405), train_loss = 0.92102534, grad/param norm = 2.4923e-01, time/batch = 0.6281s	
6130/16650 (epoch 18.408), train_loss = 1.18733385, grad/param norm = 3.0774e-01, time/batch = 0.6216s	
6131/16650 (epoch 18.411), train_loss = 0.98573286, grad/param norm = 3.1612e-01, time/batch = 0.6482s	
6132/16650 (epoch 18.414), train_loss = 0.97148837, grad/param norm = 2.3878e-01, time/batch = 0.6485s	
6133/16650 (epoch 18.417), train_loss = 0.92857403, grad/param norm = 2.3290e-01, time/batch = 0.6184s	
6134/16650 (epoch 18.420), train_loss = 0.92453708, grad/param norm = 2.3275e-01, time/batch = 0.6184s	
6135/16650 (epoch 18.423), train_loss = 0.79075266, grad/param norm = 1.8954e-01, time/batch = 0.6290s	
6136/16650 (epoch 18.426), train_loss = 0.97527052, grad/param norm = 2.7137e-01, time/batch = 0.6253s	
6137/16650 (epoch 18.429), train_loss = 1.17424791, grad/param norm = 2.4220e-01, time/batch = 0.6382s	
6138/16650 (epoch 18.432), train_loss = 1.16606844, grad/param norm = 2.8627e-01, time/batch = 0.6434s	
6139/16650 (epoch 18.435), train_loss = 1.27564350, grad/param norm = 2.6902e-01, time/batch = 0.6425s	
6140/16650 (epoch 18.438), train_loss = 1.26736487, grad/param norm = 2.9428e-01, time/batch = 0.6419s	
6141/16650 (epoch 18.441), train_loss = 1.10161991, grad/param norm = 2.6150e-01, time/batch = 0.6475s	
6142/16650 (epoch 18.444), train_loss = 1.00846110, grad/param norm = 2.3811e-01, time/batch = 0.6416s	
6143/16650 (epoch 18.447), train_loss = 1.05684928, grad/param norm = 2.5251e-01, time/batch = 0.6353s	
6144/16650 (epoch 18.450), train_loss = 1.00070551, grad/param norm = 2.3182e-01, time/batch = 0.6286s	
6145/16650 (epoch 18.453), train_loss = 1.03023152, grad/param norm = 2.5198e-01, time/batch = 0.6235s	
6146/16650 (epoch 18.456), train_loss = 0.94967628, grad/param norm = 2.5901e-01, time/batch = 0.6222s	
6147/16650 (epoch 18.459), train_loss = 0.99135991, grad/param norm = 2.5140e-01, time/batch = 0.6403s	
6148/16650 (epoch 18.462), train_loss = 1.20813130, grad/param norm = 2.8139e-01, time/batch = 0.6151s	
6149/16650 (epoch 18.465), train_loss = 0.99087862, grad/param norm = 2.4557e-01, time/batch = 0.6154s	
6150/16650 (epoch 18.468), train_loss = 0.83336577, grad/param norm = 2.2708e-01, time/batch = 0.6146s	
6151/16650 (epoch 18.471), train_loss = 0.69369355, grad/param norm = 1.8225e-01, time/batch = 0.6264s	
6152/16650 (epoch 18.474), train_loss = 0.92006199, grad/param norm = 2.2265e-01, time/batch = 0.6562s	
6153/16650 (epoch 18.477), train_loss = 1.09675857, grad/param norm = 2.4992e-01, time/batch = 0.6312s	
6154/16650 (epoch 18.480), train_loss = 1.13026535, grad/param norm = 2.7681e-01, time/batch = 0.6181s	
6155/16650 (epoch 18.483), train_loss = 1.23208758, grad/param norm = 2.5925e-01, time/batch = 0.6291s	
6156/16650 (epoch 18.486), train_loss = 0.96306940, grad/param norm = 2.1834e-01, time/batch = 0.6198s	
6157/16650 (epoch 18.489), train_loss = 1.02776498, grad/param norm = 2.4807e-01, time/batch = 0.6263s	
6158/16650 (epoch 18.492), train_loss = 1.04506406, grad/param norm = 2.1810e-01, time/batch = 0.6349s	
6159/16650 (epoch 18.495), train_loss = 0.96341925, grad/param norm = 2.7263e-01, time/batch = 0.6446s	
6160/16650 (epoch 18.498), train_loss = 1.04425655, grad/param norm = 2.5743e-01, time/batch = 0.6439s	
6161/16650 (epoch 18.502), train_loss = 1.23622110, grad/param norm = 2.6513e-01, time/batch = 0.6364s	
6162/16650 (epoch 18.505), train_loss = 1.12908559, grad/param norm = 2.4404e-01, time/batch = 0.6194s	
6163/16650 (epoch 18.508), train_loss = 1.10085277, grad/param norm = 2.4588e-01, time/batch = 0.6222s	
6164/16650 (epoch 18.511), train_loss = 1.18582108, grad/param norm = 2.5533e-01, time/batch = 0.6170s	
6165/16650 (epoch 18.514), train_loss = 0.91142360, grad/param norm = 2.2099e-01, time/batch = 0.6172s	
6166/16650 (epoch 18.517), train_loss = 1.05561456, grad/param norm = 2.5016e-01, time/batch = 0.6179s	
6167/16650 (epoch 18.520), train_loss = 0.99261104, grad/param norm = 2.3576e-01, time/batch = 0.6162s	
6168/16650 (epoch 18.523), train_loss = 1.01105116, grad/param norm = 2.2024e-01, time/batch = 0.6171s	
6169/16650 (epoch 18.526), train_loss = 1.15114135, grad/param norm = 2.4282e-01, time/batch = 0.6206s	
6170/16650 (epoch 18.529), train_loss = 1.21806647, grad/param norm = 2.7661e-01, time/batch = 0.6152s	
6171/16650 (epoch 18.532), train_loss = 0.83265783, grad/param norm = 2.2494e-01, time/batch = 0.6251s	
6172/16650 (epoch 18.535), train_loss = 0.91663208, grad/param norm = 2.4127e-01, time/batch = 0.6187s	
6173/16650 (epoch 18.538), train_loss = 0.92480661, grad/param norm = 2.4381e-01, time/batch = 0.6175s	
6174/16650 (epoch 18.541), train_loss = 1.21205783, grad/param norm = 2.6927e-01, time/batch = 0.6227s	
6175/16650 (epoch 18.544), train_loss = 1.23515692, grad/param norm = 3.3718e-01, time/batch = 0.6209s	
6176/16650 (epoch 18.547), train_loss = 0.94909650, grad/param norm = 2.4564e-01, time/batch = 0.6174s	
6177/16650 (epoch 18.550), train_loss = 1.01385953, grad/param norm = 2.4829e-01, time/batch = 0.6194s	
6178/16650 (epoch 18.553), train_loss = 1.03811503, grad/param norm = 2.6542e-01, time/batch = 0.6179s	
6179/16650 (epoch 18.556), train_loss = 0.98348028, grad/param norm = 2.3110e-01, time/batch = 0.6192s	
6180/16650 (epoch 18.559), train_loss = 0.86603681, grad/param norm = 2.2084e-01, time/batch = 0.6262s	
6181/16650 (epoch 18.562), train_loss = 1.01191248, grad/param norm = 2.4656e-01, time/batch = 0.6310s	
6182/16650 (epoch 18.565), train_loss = 0.84064852, grad/param norm = 2.4261e-01, time/batch = 0.6580s	
6183/16650 (epoch 18.568), train_loss = 0.85020575, grad/param norm = 2.3434e-01, time/batch = 0.6394s	
6184/16650 (epoch 18.571), train_loss = 0.88879573, grad/param norm = 4.7196e-01, time/batch = 0.6206s	
6185/16650 (epoch 18.574), train_loss = 1.02291742, grad/param norm = 2.5702e-01, time/batch = 0.6175s	
6186/16650 (epoch 18.577), train_loss = 0.99296270, grad/param norm = 2.3769e-01, time/batch = 0.6277s	
6187/16650 (epoch 18.580), train_loss = 0.86681554, grad/param norm = 2.1484e-01, time/batch = 0.6555s	
6188/16650 (epoch 18.583), train_loss = 1.01116612, grad/param norm = 2.3861e-01, time/batch = 0.6313s	
6189/16650 (epoch 18.586), train_loss = 0.99149043, grad/param norm = 3.0530e-01, time/batch = 0.6195s	
6190/16650 (epoch 18.589), train_loss = 0.89839146, grad/param norm = 2.1966e-01, time/batch = 0.6219s	
6191/16650 (epoch 18.592), train_loss = 1.05419183, grad/param norm = 2.6082e-01, time/batch = 0.6236s	
6192/16650 (epoch 18.595), train_loss = 0.95226005, grad/param norm = 2.3583e-01, time/batch = 0.6207s	
6193/16650 (epoch 18.598), train_loss = 0.98426066, grad/param norm = 2.5572e-01, time/batch = 0.6185s	
6194/16650 (epoch 18.601), train_loss = 0.95870004, grad/param norm = 2.5313e-01, time/batch = 0.6197s	
6195/16650 (epoch 18.604), train_loss = 1.12253838, grad/param norm = 2.7122e-01, time/batch = 0.6220s	
6196/16650 (epoch 18.607), train_loss = 1.08797168, grad/param norm = 2.3433e-01, time/batch = 0.6182s	
6197/16650 (epoch 18.610), train_loss = 0.94017668, grad/param norm = 2.3079e-01, time/batch = 0.6210s	
6198/16650 (epoch 18.613), train_loss = 1.16566523, grad/param norm = 2.5716e-01, time/batch = 0.6181s	
6199/16650 (epoch 18.616), train_loss = 1.17089523, grad/param norm = 2.9699e-01, time/batch = 0.6177s	
6200/16650 (epoch 18.619), train_loss = 0.86390054, grad/param norm = 2.3019e-01, time/batch = 0.6152s	
6201/16650 (epoch 18.622), train_loss = 0.84004016, grad/param norm = 2.1978e-01, time/batch = 0.6185s	
6202/16650 (epoch 18.625), train_loss = 0.94787529, grad/param norm = 2.2284e-01, time/batch = 0.6216s	
6203/16650 (epoch 18.628), train_loss = 0.98489343, grad/param norm = 2.6028e-01, time/batch = 0.6176s	
6204/16650 (epoch 18.631), train_loss = 1.05503950, grad/param norm = 2.6973e-01, time/batch = 0.6177s	
6205/16650 (epoch 18.634), train_loss = 1.26100016, grad/param norm = 3.0858e-01, time/batch = 0.6220s	
6206/16650 (epoch 18.637), train_loss = 1.23377338, grad/param norm = 2.5012e-01, time/batch = 0.6268s	
6207/16650 (epoch 18.640), train_loss = 0.95366087, grad/param norm = 2.3532e-01, time/batch = 0.6248s	
6208/16650 (epoch 18.643), train_loss = 1.10641564, grad/param norm = 2.4211e-01, time/batch = 0.6186s	
6209/16650 (epoch 18.646), train_loss = 1.08716085, grad/param norm = 2.3771e-01, time/batch = 0.6170s	
6210/16650 (epoch 18.649), train_loss = 1.06087066, grad/param norm = 2.4422e-01, time/batch = 0.6214s	
6211/16650 (epoch 18.652), train_loss = 1.14673002, grad/param norm = 2.5615e-01, time/batch = 0.6195s	
6212/16650 (epoch 18.655), train_loss = 1.10210211, grad/param norm = 2.7835e-01, time/batch = 0.6180s	
6213/16650 (epoch 18.658), train_loss = 0.94671613, grad/param norm = 2.7812e-01, time/batch = 0.6187s	
6214/16650 (epoch 18.661), train_loss = 1.13023886, grad/param norm = 2.6771e-01, time/batch = 0.6396s	
6215/16650 (epoch 18.664), train_loss = 1.03313983, grad/param norm = 2.3217e-01, time/batch = 0.6367s	
6216/16650 (epoch 18.667), train_loss = 1.16312412, grad/param norm = 2.4879e-01, time/batch = 0.6396s	
6217/16650 (epoch 18.670), train_loss = 0.89331381, grad/param norm = 2.4087e-01, time/batch = 0.6352s	
6218/16650 (epoch 18.673), train_loss = 0.96861997, grad/param norm = 2.4045e-01, time/batch = 0.6291s	
6219/16650 (epoch 18.676), train_loss = 1.04187841, grad/param norm = 2.5968e-01, time/batch = 0.6184s	
6220/16650 (epoch 18.679), train_loss = 0.91251637, grad/param norm = 2.2828e-01, time/batch = 0.6193s	
6221/16650 (epoch 18.682), train_loss = 1.05775118, grad/param norm = 2.3722e-01, time/batch = 0.6193s	
6222/16650 (epoch 18.685), train_loss = 0.88175080, grad/param norm = 2.4046e-01, time/batch = 0.6241s	
6223/16650 (epoch 18.688), train_loss = 1.08978403, grad/param norm = 2.4842e-01, time/batch = 0.6250s	
6224/16650 (epoch 18.691), train_loss = 1.10474582, grad/param norm = 2.6972e-01, time/batch = 0.6183s	
6225/16650 (epoch 18.694), train_loss = 0.90079131, grad/param norm = 2.2045e-01, time/batch = 0.6185s	
6226/16650 (epoch 18.697), train_loss = 0.90399235, grad/param norm = 2.1691e-01, time/batch = 0.6316s	
6227/16650 (epoch 18.700), train_loss = 1.14030497, grad/param norm = 2.6333e-01, time/batch = 0.6556s	
6228/16650 (epoch 18.703), train_loss = 0.93752963, grad/param norm = 2.2951e-01, time/batch = 0.6272s	
6229/16650 (epoch 18.706), train_loss = 1.07883339, grad/param norm = 2.6099e-01, time/batch = 0.6174s	
6230/16650 (epoch 18.709), train_loss = 0.94545829, grad/param norm = 2.1996e-01, time/batch = 0.6164s	
6231/16650 (epoch 18.712), train_loss = 0.96152649, grad/param norm = 2.6178e-01, time/batch = 0.6453s	
6232/16650 (epoch 18.715), train_loss = 1.14077302, grad/param norm = 2.5039e-01, time/batch = 0.6523s	
6233/16650 (epoch 18.718), train_loss = 1.16805182, grad/param norm = 2.4537e-01, time/batch = 0.6155s	
6234/16650 (epoch 18.721), train_loss = 1.15165808, grad/param norm = 2.5467e-01, time/batch = 0.6158s	
6235/16650 (epoch 18.724), train_loss = 1.14463736, grad/param norm = 2.5481e-01, time/batch = 0.6160s	
6236/16650 (epoch 18.727), train_loss = 1.11292690, grad/param norm = 2.4541e-01, time/batch = 0.6164s	
6237/16650 (epoch 18.730), train_loss = 1.01932180, grad/param norm = 2.4076e-01, time/batch = 0.6172s	
6238/16650 (epoch 18.733), train_loss = 1.14717101, grad/param norm = 2.6948e-01, time/batch = 0.6230s	
6239/16650 (epoch 18.736), train_loss = 0.89057539, grad/param norm = 2.3652e-01, time/batch = 0.6264s	
6240/16650 (epoch 18.739), train_loss = 1.03104648, grad/param norm = 2.4577e-01, time/batch = 0.6257s	
6241/16650 (epoch 18.742), train_loss = 1.04610587, grad/param norm = 2.3147e-01, time/batch = 0.6231s	
6242/16650 (epoch 18.745), train_loss = 0.86549250, grad/param norm = 2.2575e-01, time/batch = 0.6175s	
6243/16650 (epoch 18.748), train_loss = 0.92501117, grad/param norm = 2.5650e-01, time/batch = 0.6193s	
6244/16650 (epoch 18.751), train_loss = 1.09109037, grad/param norm = 3.5965e-01, time/batch = 0.6152s	
6245/16650 (epoch 18.754), train_loss = 1.25126024, grad/param norm = 3.3927e-01, time/batch = 0.6188s	
6246/16650 (epoch 18.757), train_loss = 1.19491505, grad/param norm = 2.6544e-01, time/batch = 0.6194s	
6247/16650 (epoch 18.760), train_loss = 1.03282279, grad/param norm = 2.4042e-01, time/batch = 0.6190s	
6248/16650 (epoch 18.763), train_loss = 0.95418324, grad/param norm = 2.3718e-01, time/batch = 0.6221s	
6249/16650 (epoch 18.766), train_loss = 1.01226015, grad/param norm = 2.1324e-01, time/batch = 0.6225s	
6250/16650 (epoch 18.769), train_loss = 1.06813495, grad/param norm = 2.4815e-01, time/batch = 0.6190s	
6251/16650 (epoch 18.772), train_loss = 0.99407836, grad/param norm = 2.1654e-01, time/batch = 0.6200s	
6252/16650 (epoch 18.775), train_loss = 1.01814562, grad/param norm = 2.3055e-01, time/batch = 0.6221s	
6253/16650 (epoch 18.778), train_loss = 1.07140453, grad/param norm = 2.4142e-01, time/batch = 0.6283s	
6254/16650 (epoch 18.781), train_loss = 1.14447248, grad/param norm = 2.2415e-01, time/batch = 0.6355s	
6255/16650 (epoch 18.784), train_loss = 1.11092808, grad/param norm = 2.5203e-01, time/batch = 0.6424s	
6256/16650 (epoch 18.787), train_loss = 1.13355873, grad/param norm = 2.5423e-01, time/batch = 0.6331s	
6257/16650 (epoch 18.790), train_loss = 1.06924934, grad/param norm = 2.1880e-01, time/batch = 0.6332s	
6258/16650 (epoch 18.793), train_loss = 0.93280048, grad/param norm = 2.3503e-01, time/batch = 0.6214s	
6259/16650 (epoch 18.796), train_loss = 1.38024295, grad/param norm = 2.9511e-01, time/batch = 0.6162s	
6260/16650 (epoch 18.799), train_loss = 1.27269036, grad/param norm = 2.5570e-01, time/batch = 0.6150s	
6261/16650 (epoch 18.802), train_loss = 1.08767177, grad/param norm = 2.2993e-01, time/batch = 0.6335s	
6262/16650 (epoch 18.805), train_loss = 1.04100003, grad/param norm = 2.2943e-01, time/batch = 0.6561s	
6263/16650 (epoch 18.808), train_loss = 1.09084784, grad/param norm = 2.5279e-01, time/batch = 0.6236s	
6264/16650 (epoch 18.811), train_loss = 1.18287748, grad/param norm = 2.3785e-01, time/batch = 0.6186s	
6265/16650 (epoch 18.814), train_loss = 0.94369348, grad/param norm = 2.2201e-01, time/batch = 0.6208s	
6266/16650 (epoch 18.817), train_loss = 1.00431537, grad/param norm = 2.3805e-01, time/batch = 0.6228s	
6267/16650 (epoch 18.820), train_loss = 1.12040763, grad/param norm = 2.6014e-01, time/batch = 0.6205s	
6268/16650 (epoch 18.823), train_loss = 0.98979411, grad/param norm = 2.2219e-01, time/batch = 0.6216s	
6269/16650 (epoch 18.826), train_loss = 1.05083920, grad/param norm = 2.3399e-01, time/batch = 0.6230s	
6270/16650 (epoch 18.829), train_loss = 1.13478134, grad/param norm = 2.4716e-01, time/batch = 0.6277s	
6271/16650 (epoch 18.832), train_loss = 1.15780526, grad/param norm = 2.6624e-01, time/batch = 0.6294s	
6272/16650 (epoch 18.835), train_loss = 1.15025132, grad/param norm = 2.8433e-01, time/batch = 0.6334s	
6273/16650 (epoch 18.838), train_loss = 0.95599655, grad/param norm = 2.4349e-01, time/batch = 0.6279s	
6274/16650 (epoch 18.841), train_loss = 1.00674636, grad/param norm = 2.3502e-01, time/batch = 0.6296s	
6275/16650 (epoch 18.844), train_loss = 0.97999785, grad/param norm = 2.2779e-01, time/batch = 0.6522s	
6276/16650 (epoch 18.847), train_loss = 1.14635250, grad/param norm = 2.5711e-01, time/batch = 0.6173s	
6277/16650 (epoch 18.850), train_loss = 0.94212284, grad/param norm = 2.4942e-01, time/batch = 0.6279s	
6278/16650 (epoch 18.853), train_loss = 1.09927771, grad/param norm = 2.5684e-01, time/batch = 0.6175s	
6279/16650 (epoch 18.856), train_loss = 0.98068805, grad/param norm = 2.3784e-01, time/batch = 0.6220s	
6280/16650 (epoch 18.859), train_loss = 1.14903816, grad/param norm = 2.5583e-01, time/batch = 0.6163s	
6281/16650 (epoch 18.862), train_loss = 1.05585438, grad/param norm = 2.3880e-01, time/batch = 0.6213s	
6282/16650 (epoch 18.865), train_loss = 0.87311287, grad/param norm = 2.1048e-01, time/batch = 0.6206s	
6283/16650 (epoch 18.868), train_loss = 1.12192366, grad/param norm = 2.5902e-01, time/batch = 0.6201s	
6284/16650 (epoch 18.871), train_loss = 1.09339739, grad/param norm = 2.4343e-01, time/batch = 0.6198s	
6285/16650 (epoch 18.874), train_loss = 1.09521319, grad/param norm = 2.3871e-01, time/batch = 0.6200s	
6286/16650 (epoch 18.877), train_loss = 1.04677378, grad/param norm = 2.3776e-01, time/batch = 0.6193s	
6287/16650 (epoch 18.880), train_loss = 0.98418881, grad/param norm = 2.3744e-01, time/batch = 0.6190s	
6288/16650 (epoch 18.883), train_loss = 1.05943303, grad/param norm = 2.4741e-01, time/batch = 0.6248s	
6289/16650 (epoch 18.886), train_loss = 1.06686022, grad/param norm = 2.3310e-01, time/batch = 0.6251s	
6290/16650 (epoch 18.889), train_loss = 0.91439870, grad/param norm = 2.3111e-01, time/batch = 0.6412s	
6291/16650 (epoch 18.892), train_loss = 1.04408648, grad/param norm = 2.2401e-01, time/batch = 0.6650s	
6292/16650 (epoch 18.895), train_loss = 1.10505944, grad/param norm = 2.3721e-01, time/batch = 0.6516s	
6293/16650 (epoch 18.898), train_loss = 1.11068358, grad/param norm = 2.5931e-01, time/batch = 0.6491s	
6294/16650 (epoch 18.901), train_loss = 1.04470792, grad/param norm = 2.2498e-01, time/batch = 0.6472s	
6295/16650 (epoch 18.904), train_loss = 0.98273010, grad/param norm = 2.6402e-01, time/batch = 0.6419s	
6296/16650 (epoch 18.907), train_loss = 1.13905147, grad/param norm = 2.8182e-01, time/batch = 0.6467s	
6297/16650 (epoch 18.910), train_loss = 1.10738750, grad/param norm = 2.5505e-01, time/batch = 0.6563s	
6298/16650 (epoch 18.913), train_loss = 0.97580266, grad/param norm = 2.4930e-01, time/batch = 0.6229s	
6299/16650 (epoch 18.916), train_loss = 1.06156908, grad/param norm = 2.4398e-01, time/batch = 0.6238s	
6300/16650 (epoch 18.919), train_loss = 1.23396342, grad/param norm = 2.7445e-01, time/batch = 0.6194s	
6301/16650 (epoch 18.922), train_loss = 1.16664899, grad/param norm = 2.5201e-01, time/batch = 0.6218s	
6302/16650 (epoch 18.925), train_loss = 0.98761342, grad/param norm = 2.5187e-01, time/batch = 0.6173s	
6303/16650 (epoch 18.928), train_loss = 1.02425561, grad/param norm = 2.4273e-01, time/batch = 0.6165s	
6304/16650 (epoch 18.931), train_loss = 1.10843256, grad/param norm = 2.5747e-01, time/batch = 0.6161s	
6305/16650 (epoch 18.934), train_loss = 0.92841809, grad/param norm = 2.5271e-01, time/batch = 0.6163s	
6306/16650 (epoch 18.937), train_loss = 0.98638916, grad/param norm = 2.5176e-01, time/batch = 0.6143s	
6307/16650 (epoch 18.940), train_loss = 1.00728834, grad/param norm = 2.2676e-01, time/batch = 0.6157s	
6308/16650 (epoch 18.943), train_loss = 1.08244382, grad/param norm = 2.5349e-01, time/batch = 0.6148s	
6309/16650 (epoch 18.946), train_loss = 0.96088342, grad/param norm = 2.4681e-01, time/batch = 0.6202s	
6310/16650 (epoch 18.949), train_loss = 0.95512247, grad/param norm = 2.7397e-01, time/batch = 0.6190s	
6311/16650 (epoch 18.952), train_loss = 0.86505293, grad/param norm = 2.3339e-01, time/batch = 0.6215s	
6312/16650 (epoch 18.955), train_loss = 1.01636862, grad/param norm = 2.3491e-01, time/batch = 0.6175s	
6313/16650 (epoch 18.958), train_loss = 1.13153483, grad/param norm = 2.9389e-01, time/batch = 0.6199s	
6314/16650 (epoch 18.961), train_loss = 1.04454890, grad/param norm = 2.3519e-01, time/batch = 0.6182s	
6315/16650 (epoch 18.964), train_loss = 0.96819779, grad/param norm = 2.6889e-01, time/batch = 0.6205s	
6316/16650 (epoch 18.967), train_loss = 1.16402318, grad/param norm = 2.6417e-01, time/batch = 0.6194s	
6317/16650 (epoch 18.970), train_loss = 0.95512187, grad/param norm = 2.2948e-01, time/batch = 0.6251s	
6318/16650 (epoch 18.973), train_loss = 0.99003953, grad/param norm = 2.6084e-01, time/batch = 0.6231s	
6319/16650 (epoch 18.976), train_loss = 0.95817525, grad/param norm = 2.3232e-01, time/batch = 0.6181s	
6320/16650 (epoch 18.979), train_loss = 1.07520925, grad/param norm = 2.7218e-01, time/batch = 0.6166s	
6321/16650 (epoch 18.982), train_loss = 1.11401270, grad/param norm = 2.6321e-01, time/batch = 0.6199s	
6322/16650 (epoch 18.985), train_loss = 1.01062400, grad/param norm = 2.3133e-01, time/batch = 0.6176s	
6323/16650 (epoch 18.988), train_loss = 1.20069844, grad/param norm = 2.7694e-01, time/batch = 0.6215s	
6324/16650 (epoch 18.991), train_loss = 0.97405797, grad/param norm = 2.4632e-01, time/batch = 0.6198s	
6325/16650 (epoch 18.994), train_loss = 0.97320754, grad/param norm = 2.2802e-01, time/batch = 0.6206s	
6326/16650 (epoch 18.997), train_loss = 1.05947115, grad/param norm = 2.5847e-01, time/batch = 0.6203s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
6327/16650 (epoch 19.000), train_loss = 1.10426437, grad/param norm = 2.8857e-01, time/batch = 0.6199s	
6328/16650 (epoch 19.003), train_loss = 1.13632264, grad/param norm = 3.0109e-01, time/batch = 0.6187s	
6329/16650 (epoch 19.006), train_loss = 1.13000559, grad/param norm = 2.9451e-01, time/batch = 0.6181s	
6330/16650 (epoch 19.009), train_loss = 1.22677951, grad/param norm = 2.8926e-01, time/batch = 0.6179s	
6331/16650 (epoch 19.012), train_loss = 1.20775097, grad/param norm = 2.7200e-01, time/batch = 0.6204s	
6332/16650 (epoch 19.015), train_loss = 1.06525036, grad/param norm = 2.8337e-01, time/batch = 0.6188s	
6333/16650 (epoch 19.018), train_loss = 0.86840968, grad/param norm = 2.3720e-01, time/batch = 0.6209s	
6334/16650 (epoch 19.021), train_loss = 1.19268826, grad/param norm = 2.8442e-01, time/batch = 0.6288s	
6335/16650 (epoch 19.024), train_loss = 1.05642523, grad/param norm = 2.7597e-01, time/batch = 0.6208s	
6336/16650 (epoch 19.027), train_loss = 1.13732746, grad/param norm = 2.7424e-01, time/batch = 0.6366s	
6337/16650 (epoch 19.030), train_loss = 0.93571270, grad/param norm = 2.4480e-01, time/batch = 0.6554s	
6338/16650 (epoch 19.033), train_loss = 1.04952305, grad/param norm = 2.2066e-01, time/batch = 0.6206s	
6339/16650 (epoch 19.036), train_loss = 0.83808723, grad/param norm = 2.5647e-01, time/batch = 0.6211s	
6340/16650 (epoch 19.039), train_loss = 1.16447386, grad/param norm = 2.5587e-01, time/batch = 0.6172s	
6341/16650 (epoch 19.042), train_loss = 1.13825642, grad/param norm = 2.5645e-01, time/batch = 0.6490s	
6342/16650 (epoch 19.045), train_loss = 1.03538830, grad/param norm = 2.5285e-01, time/batch = 0.6477s	
6343/16650 (epoch 19.048), train_loss = 1.13319263, grad/param norm = 2.5667e-01, time/batch = 0.6190s	
6344/16650 (epoch 19.051), train_loss = 1.03721416, grad/param norm = 2.5294e-01, time/batch = 0.6193s	
6345/16650 (epoch 19.054), train_loss = 1.07528688, grad/param norm = 2.6790e-01, time/batch = 0.6192s	
6346/16650 (epoch 19.057), train_loss = 1.05419639, grad/param norm = 2.5124e-01, time/batch = 0.6190s	
6347/16650 (epoch 19.060), train_loss = 0.92596747, grad/param norm = 2.3465e-01, time/batch = 0.6191s	
6348/16650 (epoch 19.063), train_loss = 1.04028803, grad/param norm = 2.4485e-01, time/batch = 0.6270s	
6349/16650 (epoch 19.066), train_loss = 1.22898090, grad/param norm = 2.7934e-01, time/batch = 0.6322s	
6350/16650 (epoch 19.069), train_loss = 1.15160718, grad/param norm = 2.8199e-01, time/batch = 0.6435s	
6351/16650 (epoch 19.072), train_loss = 1.01193033, grad/param norm = 2.5145e-01, time/batch = 0.6442s	
6352/16650 (epoch 19.075), train_loss = 1.11709215, grad/param norm = 2.4063e-01, time/batch = 0.6379s	
6353/16650 (epoch 19.078), train_loss = 1.17875351, grad/param norm = 2.4350e-01, time/batch = 0.6269s	
6354/16650 (epoch 19.081), train_loss = 1.06083066, grad/param norm = 2.5528e-01, time/batch = 0.6311s	
6355/16650 (epoch 19.084), train_loss = 1.10965619, grad/param norm = 2.3869e-01, time/batch = 0.6275s	
6356/16650 (epoch 19.087), train_loss = 1.04309225, grad/param norm = 2.4321e-01, time/batch = 0.6203s	
6357/16650 (epoch 19.090), train_loss = 1.03800702, grad/param norm = 2.4775e-01, time/batch = 0.6168s	
6358/16650 (epoch 19.093), train_loss = 1.28639607, grad/param norm = 2.9168e-01, time/batch = 0.6203s	
6359/16650 (epoch 19.096), train_loss = 1.00221168, grad/param norm = 2.5074e-01, time/batch = 0.6250s	
6360/16650 (epoch 19.099), train_loss = 1.06407969, grad/param norm = 2.4475e-01, time/batch = 0.6195s	
6361/16650 (epoch 19.102), train_loss = 1.11523322, grad/param norm = 2.6778e-01, time/batch = 0.6237s	
6362/16650 (epoch 19.105), train_loss = 1.13117664, grad/param norm = 2.6230e-01, time/batch = 0.6170s	
6363/16650 (epoch 19.108), train_loss = 1.11106702, grad/param norm = 2.5710e-01, time/batch = 0.6200s	
6364/16650 (epoch 19.111), train_loss = 1.14415837, grad/param norm = 2.3233e-01, time/batch = 0.6385s	
6365/16650 (epoch 19.114), train_loss = 1.18198365, grad/param norm = 2.5873e-01, time/batch = 0.6491s	
6366/16650 (epoch 19.117), train_loss = 1.21036225, grad/param norm = 2.5938e-01, time/batch = 0.6474s	
6367/16650 (epoch 19.120), train_loss = 0.97097010, grad/param norm = 2.1634e-01, time/batch = 0.6402s	
6368/16650 (epoch 19.123), train_loss = 1.04185878, grad/param norm = 2.5083e-01, time/batch = 0.6351s	
6369/16650 (epoch 19.126), train_loss = 1.07313211, grad/param norm = 2.3465e-01, time/batch = 0.6390s	
6370/16650 (epoch 19.129), train_loss = 1.10904444, grad/param norm = 2.7519e-01, time/batch = 0.6330s	
6371/16650 (epoch 19.132), train_loss = 1.06453859, grad/param norm = 2.4096e-01, time/batch = 0.6362s	
6372/16650 (epoch 19.135), train_loss = 1.15031820, grad/param norm = 2.4428e-01, time/batch = 0.6350s	
6373/16650 (epoch 19.138), train_loss = 1.12338325, grad/param norm = 2.2907e-01, time/batch = 0.6441s	
6374/16650 (epoch 19.141), train_loss = 1.13715753, grad/param norm = 2.9156e-01, time/batch = 0.6364s	
6375/16650 (epoch 19.144), train_loss = 1.04974558, grad/param norm = 2.3751e-01, time/batch = 0.6346s	
6376/16650 (epoch 19.147), train_loss = 1.21944880, grad/param norm = 2.5702e-01, time/batch = 0.6520s	
6377/16650 (epoch 19.150), train_loss = 1.29200959, grad/param norm = 2.7326e-01, time/batch = 0.6350s	
6378/16650 (epoch 19.153), train_loss = 1.11436922, grad/param norm = 3.0147e-01, time/batch = 0.6347s	
6379/16650 (epoch 19.156), train_loss = 0.97677937, grad/param norm = 2.3161e-01, time/batch = 0.6390s	
6380/16650 (epoch 19.159), train_loss = 1.15392228, grad/param norm = 2.8866e-01, time/batch = 0.6455s	
6381/16650 (epoch 19.162), train_loss = 1.21057248, grad/param norm = 2.7057e-01, time/batch = 0.6719s	
6382/16650 (epoch 19.165), train_loss = 1.19368140, grad/param norm = 2.6861e-01, time/batch = 0.6892s	
6383/16650 (epoch 19.168), train_loss = 0.89917294, grad/param norm = 2.1266e-01, time/batch = 0.9330s	
6384/16650 (epoch 19.171), train_loss = 1.17892266, grad/param norm = 2.3470e-01, time/batch = 0.9499s	
6385/16650 (epoch 19.174), train_loss = 0.91200136, grad/param norm = 2.2660e-01, time/batch = 0.9612s	
6386/16650 (epoch 19.177), train_loss = 1.06665738, grad/param norm = 2.6113e-01, time/batch = 0.9335s	
6387/16650 (epoch 19.180), train_loss = 1.19346967, grad/param norm = 2.5820e-01, time/batch = 0.9246s	
6388/16650 (epoch 19.183), train_loss = 1.33885342, grad/param norm = 2.8446e-01, time/batch = 1.6101s	
6389/16650 (epoch 19.186), train_loss = 1.16068408, grad/param norm = 2.6676e-01, time/batch = 1.7398s	
6390/16650 (epoch 19.189), train_loss = 0.99141904, grad/param norm = 2.2708e-01, time/batch = 1.7348s	
6391/16650 (epoch 19.192), train_loss = 1.00991648, grad/param norm = 2.6817e-01, time/batch = 18.2818s	
6392/16650 (epoch 19.195), train_loss = 1.02267447, grad/param norm = 2.4624e-01, time/batch = 15.3370s	
6393/16650 (epoch 19.198), train_loss = 0.88665007, grad/param norm = 1.9874e-01, time/batch = 18.1916s	
6394/16650 (epoch 19.201), train_loss = 1.01185117, grad/param norm = 2.3991e-01, time/batch = 17.6782s	
6395/16650 (epoch 19.204), train_loss = 1.05881964, grad/param norm = 2.4450e-01, time/batch = 17.5331s	
6396/16650 (epoch 19.207), train_loss = 1.11186297, grad/param norm = 2.6722e-01, time/batch = 7.9209s	
6397/16650 (epoch 19.210), train_loss = 1.04099936, grad/param norm = 2.4355e-01, time/batch = 0.6291s	
6398/16650 (epoch 19.213), train_loss = 1.15510031, grad/param norm = 2.6437e-01, time/batch = 0.6301s	
6399/16650 (epoch 19.216), train_loss = 1.04680101, grad/param norm = 2.5554e-01, time/batch = 0.6340s	
6400/16650 (epoch 19.219), train_loss = 1.05886507, grad/param norm = 2.4871e-01, time/batch = 0.6318s	
6401/16650 (epoch 19.222), train_loss = 1.08692615, grad/param norm = 2.1873e-01, time/batch = 0.6332s	
6402/16650 (epoch 19.225), train_loss = 1.08271658, grad/param norm = 2.4566e-01, time/batch = 0.6355s	
6403/16650 (epoch 19.228), train_loss = 0.95644965, grad/param norm = 2.3340e-01, time/batch = 0.6412s	
6404/16650 (epoch 19.231), train_loss = 1.04283813, grad/param norm = 2.3870e-01, time/batch = 0.8698s	
6405/16650 (epoch 19.234), train_loss = 1.23809452, grad/param norm = 2.4560e-01, time/batch = 0.9399s	
6406/16650 (epoch 19.237), train_loss = 1.11725072, grad/param norm = 2.4931e-01, time/batch = 0.9299s	
6407/16650 (epoch 19.240), train_loss = 1.12262760, grad/param norm = 2.5719e-01, time/batch = 0.9432s	
6408/16650 (epoch 19.243), train_loss = 1.07351031, grad/param norm = 2.5112e-01, time/batch = 0.9822s	
6409/16650 (epoch 19.246), train_loss = 1.20052976, grad/param norm = 2.6273e-01, time/batch = 1.3039s	
6410/16650 (epoch 19.249), train_loss = 0.94255962, grad/param norm = 2.3914e-01, time/batch = 1.7341s	
6411/16650 (epoch 19.252), train_loss = 1.03190910, grad/param norm = 2.4035e-01, time/batch = 1.7335s	
6412/16650 (epoch 19.255), train_loss = 1.16849037, grad/param norm = 2.6272e-01, time/batch = 12.4832s	
6413/16650 (epoch 19.258), train_loss = 1.20029439, grad/param norm = 2.5315e-01, time/batch = 15.5137s	
6414/16650 (epoch 19.261), train_loss = 1.09323331, grad/param norm = 2.4425e-01, time/batch = 15.7396s	
6415/16650 (epoch 19.264), train_loss = 1.02960552, grad/param norm = 2.4886e-01, time/batch = 18.1889s	
6416/16650 (epoch 19.267), train_loss = 1.02903882, grad/param norm = 2.4031e-01, time/batch = 18.1881s	
6417/16650 (epoch 19.270), train_loss = 1.08530638, grad/param norm = 2.3563e-01, time/batch = 17.9527s	
6418/16650 (epoch 19.273), train_loss = 1.19689141, grad/param norm = 2.3303e-01, time/batch = 15.7274s	
6419/16650 (epoch 19.276), train_loss = 1.08965491, grad/param norm = 2.2667e-01, time/batch = 17.2714s	
6420/16650 (epoch 19.279), train_loss = 1.05725772, grad/param norm = 2.4657e-01, time/batch = 18.4505s	
6421/16650 (epoch 19.282), train_loss = 0.97075825, grad/param norm = 2.2041e-01, time/batch = 17.1853s	
6422/16650 (epoch 19.285), train_loss = 0.96535470, grad/param norm = 2.2752e-01, time/batch = 18.0257s	
6423/16650 (epoch 19.288), train_loss = 1.00591754, grad/param norm = 2.3765e-01, time/batch = 17.4435s	
6424/16650 (epoch 19.291), train_loss = 0.82656083, grad/param norm = 2.0335e-01, time/batch = 17.0330s	
6425/16650 (epoch 19.294), train_loss = 0.93844133, grad/param norm = 1.9881e-01, time/batch = 18.5906s	
6426/16650 (epoch 19.297), train_loss = 1.02298590, grad/param norm = 2.4970e-01, time/batch = 16.3600s	
6427/16650 (epoch 19.300), train_loss = 0.83613236, grad/param norm = 2.2592e-01, time/batch = 18.9484s	
6428/16650 (epoch 19.303), train_loss = 0.90894982, grad/param norm = 2.1721e-01, time/batch = 15.9090s	
6429/16650 (epoch 19.306), train_loss = 1.14316318, grad/param norm = 2.3359e-01, time/batch = 15.8704s	
6430/16650 (epoch 19.309), train_loss = 1.15233659, grad/param norm = 2.5004e-01, time/batch = 16.8164s	
6431/16650 (epoch 19.312), train_loss = 0.96687833, grad/param norm = 2.6126e-01, time/batch = 18.0235s	
6432/16650 (epoch 19.315), train_loss = 0.75650071, grad/param norm = 1.8917e-01, time/batch = 16.7616s	
6433/16650 (epoch 19.318), train_loss = 0.85117691, grad/param norm = 2.1437e-01, time/batch = 14.4176s	
6434/16650 (epoch 19.321), train_loss = 1.21953788, grad/param norm = 2.7400e-01, time/batch = 18.4529s	
6435/16650 (epoch 19.324), train_loss = 0.98130671, grad/param norm = 2.4623e-01, time/batch = 15.6696s	
6436/16650 (epoch 19.327), train_loss = 1.14266984, grad/param norm = 2.7696e-01, time/batch = 17.1146s	
6437/16650 (epoch 19.330), train_loss = 1.10434567, grad/param norm = 2.5714e-01, time/batch = 18.2722s	
6438/16650 (epoch 19.333), train_loss = 1.12378677, grad/param norm = 2.6734e-01, time/batch = 17.6854s	
6439/16650 (epoch 19.336), train_loss = 0.94863144, grad/param norm = 2.5542e-01, time/batch = 17.6962s	
6440/16650 (epoch 19.339), train_loss = 1.01890759, grad/param norm = 2.4240e-01, time/batch = 17.8808s	
6441/16650 (epoch 19.342), train_loss = 0.97966800, grad/param norm = 2.4295e-01, time/batch = 17.5108s	
6442/16650 (epoch 19.345), train_loss = 0.90352156, grad/param norm = 2.0926e-01, time/batch = 14.7556s	
6443/16650 (epoch 19.348), train_loss = 1.07566963, grad/param norm = 2.6526e-01, time/batch = 13.7161s	
6444/16650 (epoch 19.351), train_loss = 1.11691052, grad/param norm = 2.6428e-01, time/batch = 13.4815s	
6445/16650 (epoch 19.354), train_loss = 1.13999027, grad/param norm = 2.5431e-01, time/batch = 16.2558s	
6446/16650 (epoch 19.357), train_loss = 1.09664592, grad/param norm = 2.5633e-01, time/batch = 14.7578s	
6447/16650 (epoch 19.360), train_loss = 1.11626408, grad/param norm = 2.5978e-01, time/batch = 16.6927s	
6448/16650 (epoch 19.363), train_loss = 1.18346904, grad/param norm = 2.5209e-01, time/batch = 18.1010s	
6449/16650 (epoch 19.366), train_loss = 1.23687048, grad/param norm = 2.6221e-01, time/batch = 18.1112s	
6450/16650 (epoch 19.369), train_loss = 1.07941042, grad/param norm = 2.7072e-01, time/batch = 16.2587s	
6451/16650 (epoch 19.372), train_loss = 1.06270578, grad/param norm = 2.3100e-01, time/batch = 18.5366s	
6452/16650 (epoch 19.375), train_loss = 1.08763863, grad/param norm = 2.2951e-01, time/batch = 15.7100s	
6453/16650 (epoch 19.378), train_loss = 0.96275368, grad/param norm = 2.1643e-01, time/batch = 15.6847s	
6454/16650 (epoch 19.381), train_loss = 1.08577649, grad/param norm = 2.3643e-01, time/batch = 15.6897s	
6455/16650 (epoch 19.384), train_loss = 1.22354032, grad/param norm = 2.8368e-01, time/batch = 17.9574s	
6456/16650 (epoch 19.387), train_loss = 0.83761947, grad/param norm = 2.1232e-01, time/batch = 18.6101s	
6457/16650 (epoch 19.390), train_loss = 1.14064356, grad/param norm = 2.3762e-01, time/batch = 17.0954s	
6458/16650 (epoch 19.393), train_loss = 1.03090043, grad/param norm = 2.6738e-01, time/batch = 18.1240s	
6459/16650 (epoch 19.396), train_loss = 1.18813882, grad/param norm = 2.7158e-01, time/batch = 17.7095s	
6460/16650 (epoch 19.399), train_loss = 1.11966463, grad/param norm = 2.6524e-01, time/batch = 15.4205s	
6461/16650 (epoch 19.402), train_loss = 0.97638200, grad/param norm = 2.4200e-01, time/batch = 17.7887s	
6462/16650 (epoch 19.405), train_loss = 0.88868393, grad/param norm = 2.4411e-01, time/batch = 14.5765s	
6463/16650 (epoch 19.408), train_loss = 1.15127852, grad/param norm = 2.8507e-01, time/batch = 18.2747s	
6464/16650 (epoch 19.411), train_loss = 0.96199125, grad/param norm = 2.7811e-01, time/batch = 15.2557s	
6465/16650 (epoch 19.414), train_loss = 0.95375469, grad/param norm = 2.4624e-01, time/batch = 16.5926s	
6466/16650 (epoch 19.417), train_loss = 0.91750490, grad/param norm = 2.3410e-01, time/batch = 16.2392s	
6467/16650 (epoch 19.420), train_loss = 0.91303522, grad/param norm = 2.4932e-01, time/batch = 16.9327s	
6468/16650 (epoch 19.423), train_loss = 0.77361301, grad/param norm = 1.9573e-01, time/batch = 16.9397s	
6469/16650 (epoch 19.426), train_loss = 0.93496749, grad/param norm = 2.5873e-01, time/batch = 17.9574s	
6470/16650 (epoch 19.429), train_loss = 1.15506244, grad/param norm = 2.5554e-01, time/batch = 18.4508s	
6471/16650 (epoch 19.432), train_loss = 1.13493848, grad/param norm = 2.8353e-01, time/batch = 17.0037s	
6472/16650 (epoch 19.435), train_loss = 1.25007429, grad/param norm = 2.6705e-01, time/batch = 17.6008s	
6473/16650 (epoch 19.438), train_loss = 1.25024082, grad/param norm = 3.1471e-01, time/batch = 18.3515s	
6474/16650 (epoch 19.441), train_loss = 1.08520022, grad/param norm = 3.0358e-01, time/batch = 17.0195s	
6475/16650 (epoch 19.444), train_loss = 0.97233357, grad/param norm = 2.4616e-01, time/batch = 15.7448s	
6476/16650 (epoch 19.447), train_loss = 1.02451656, grad/param norm = 2.5199e-01, time/batch = 16.3557s	
6477/16650 (epoch 19.450), train_loss = 0.98757893, grad/param norm = 2.3947e-01, time/batch = 18.0249s	
6478/16650 (epoch 19.453), train_loss = 1.00741224, grad/param norm = 2.6260e-01, time/batch = 16.8451s	
6479/16650 (epoch 19.456), train_loss = 0.91536543, grad/param norm = 2.4512e-01, time/batch = 18.6272s	
6480/16650 (epoch 19.459), train_loss = 0.97947410, grad/param norm = 2.4591e-01, time/batch = 16.7797s	
6481/16650 (epoch 19.462), train_loss = 1.16877106, grad/param norm = 2.7776e-01, time/batch = 22.1325s	
6482/16650 (epoch 19.465), train_loss = 0.96796844, grad/param norm = 2.7354e-01, time/batch = 24.1352s	
6483/16650 (epoch 19.468), train_loss = 0.81073407, grad/param norm = 2.2128e-01, time/batch = 17.5165s	
6484/16650 (epoch 19.471), train_loss = 0.67271447, grad/param norm = 1.8416e-01, time/batch = 16.0866s	
6485/16650 (epoch 19.474), train_loss = 0.89640567, grad/param norm = 2.3084e-01, time/batch = 18.8643s	
6486/16650 (epoch 19.477), train_loss = 1.07738028, grad/param norm = 2.4634e-01, time/batch = 17.0245s	
6487/16650 (epoch 19.480), train_loss = 1.09641894, grad/param norm = 2.7751e-01, time/batch = 16.8518s	
6488/16650 (epoch 19.483), train_loss = 1.19648777, grad/param norm = 2.6645e-01, time/batch = 15.6938s	
6489/16650 (epoch 19.486), train_loss = 0.93603589, grad/param norm = 2.1223e-01, time/batch = 18.1296s	
6490/16650 (epoch 19.489), train_loss = 0.99478507, grad/param norm = 2.4124e-01, time/batch = 18.4677s	
6491/16650 (epoch 19.492), train_loss = 1.02344244, grad/param norm = 2.1761e-01, time/batch = 16.0499s	
6492/16650 (epoch 19.495), train_loss = 0.93112365, grad/param norm = 2.5293e-01, time/batch = 17.8640s	
6493/16650 (epoch 19.498), train_loss = 1.02134494, grad/param norm = 2.7231e-01, time/batch = 18.0247s	
6494/16650 (epoch 19.502), train_loss = 1.19430601, grad/param norm = 2.6500e-01, time/batch = 15.9280s	
6495/16650 (epoch 19.505), train_loss = 1.10109402, grad/param norm = 2.3368e-01, time/batch = 16.8648s	
6496/16650 (epoch 19.508), train_loss = 1.08144271, grad/param norm = 2.6176e-01, time/batch = 15.2478s	
6497/16650 (epoch 19.511), train_loss = 1.16701807, grad/param norm = 2.5043e-01, time/batch = 18.2669s	
6498/16650 (epoch 19.514), train_loss = 0.89045282, grad/param norm = 2.3026e-01, time/batch = 16.7502s	
6499/16650 (epoch 19.517), train_loss = 1.03426077, grad/param norm = 2.5885e-01, time/batch = 17.7827s	
6500/16650 (epoch 19.520), train_loss = 0.95578994, grad/param norm = 2.3261e-01, time/batch = 16.8417s	
6501/16650 (epoch 19.523), train_loss = 0.98876291, grad/param norm = 2.3643e-01, time/batch = 17.6030s	
6502/16650 (epoch 19.526), train_loss = 1.13104978, grad/param norm = 2.5031e-01, time/batch = 17.5265s	
6503/16650 (epoch 19.529), train_loss = 1.19653931, grad/param norm = 2.9437e-01, time/batch = 15.6552s	
6504/16650 (epoch 19.532), train_loss = 0.80828708, grad/param norm = 2.2420e-01, time/batch = 18.4524s	
6505/16650 (epoch 19.535), train_loss = 0.89274997, grad/param norm = 2.5774e-01, time/batch = 15.9921s	
6506/16650 (epoch 19.538), train_loss = 0.91244013, grad/param norm = 2.7725e-01, time/batch = 16.8412s	
6507/16650 (epoch 19.541), train_loss = 1.17926750, grad/param norm = 2.6790e-01, time/batch = 17.5355s	
6508/16650 (epoch 19.544), train_loss = 1.22761808, grad/param norm = 3.1546e-01, time/batch = 15.2290s	
6509/16650 (epoch 19.547), train_loss = 0.91651641, grad/param norm = 2.5071e-01, time/batch = 17.6058s	
6510/16650 (epoch 19.550), train_loss = 0.98534298, grad/param norm = 2.5165e-01, time/batch = 16.8783s	
6511/16650 (epoch 19.553), train_loss = 1.01427367, grad/param norm = 2.6369e-01, time/batch = 18.3636s	
6512/16650 (epoch 19.556), train_loss = 0.95865044, grad/param norm = 2.6733e-01, time/batch = 16.8396s	
6513/16650 (epoch 19.559), train_loss = 0.84742910, grad/param norm = 2.2669e-01, time/batch = 16.7724s	
6514/16650 (epoch 19.562), train_loss = 0.98866266, grad/param norm = 2.6104e-01, time/batch = 18.2031s	
6515/16650 (epoch 19.565), train_loss = 0.82781681, grad/param norm = 2.5663e-01, time/batch = 16.6811s	
6516/16650 (epoch 19.568), train_loss = 0.82824308, grad/param norm = 2.2458e-01, time/batch = 17.6945s	
6517/16650 (epoch 19.571), train_loss = 0.86045200, grad/param norm = 2.8633e-01, time/batch = 14.7432s	
6518/16650 (epoch 19.574), train_loss = 0.99458806, grad/param norm = 2.7181e-01, time/batch = 16.1022s	
6519/16650 (epoch 19.577), train_loss = 0.97246155, grad/param norm = 2.4357e-01, time/batch = 16.1642s	
6520/16650 (epoch 19.580), train_loss = 0.84669202, grad/param norm = 2.3165e-01, time/batch = 17.8538s	
6521/16650 (epoch 19.583), train_loss = 0.99778012, grad/param norm = 2.5493e-01, time/batch = 18.0274s	
6522/16650 (epoch 19.586), train_loss = 0.94571921, grad/param norm = 2.7620e-01, time/batch = 16.9379s	
6523/16650 (epoch 19.589), train_loss = 0.87439668, grad/param norm = 2.1739e-01, time/batch = 17.5347s	
6524/16650 (epoch 19.592), train_loss = 1.01621463, grad/param norm = 2.5588e-01, time/batch = 16.1736s	
6525/16650 (epoch 19.595), train_loss = 0.95097848, grad/param norm = 2.5969e-01, time/batch = 18.6233s	
6526/16650 (epoch 19.598), train_loss = 0.96846450, grad/param norm = 2.5838e-01, time/batch = 16.9937s	
6527/16650 (epoch 19.601), train_loss = 0.93947115, grad/param norm = 2.7627e-01, time/batch = 17.6875s	
6528/16650 (epoch 19.604), train_loss = 1.10233400, grad/param norm = 2.5754e-01, time/batch = 17.6139s	
6529/16650 (epoch 19.607), train_loss = 1.06154268, grad/param norm = 2.3917e-01, time/batch = 14.7613s	
6530/16650 (epoch 19.610), train_loss = 0.92554567, grad/param norm = 2.4625e-01, time/batch = 17.5158s	
6531/16650 (epoch 19.613), train_loss = 1.14117056, grad/param norm = 2.5846e-01, time/batch = 18.4632s	
6532/16650 (epoch 19.616), train_loss = 1.15592769, grad/param norm = 3.2005e-01, time/batch = 17.8662s	
6533/16650 (epoch 19.619), train_loss = 0.84883876, grad/param norm = 2.3259e-01, time/batch = 17.0034s	
6534/16650 (epoch 19.622), train_loss = 0.82343296, grad/param norm = 2.2658e-01, time/batch = 15.1522s	
6535/16650 (epoch 19.625), train_loss = 0.93371815, grad/param norm = 2.3509e-01, time/batch = 15.5238s	
6536/16650 (epoch 19.628), train_loss = 0.95174307, grad/param norm = 2.5844e-01, time/batch = 15.7418s	
6537/16650 (epoch 19.631), train_loss = 1.03530289, grad/param norm = 2.8617e-01, time/batch = 17.0898s	
6538/16650 (epoch 19.634), train_loss = 1.24312992, grad/param norm = 3.1245e-01, time/batch = 17.6051s	
6539/16650 (epoch 19.637), train_loss = 1.20666393, grad/param norm = 2.6875e-01, time/batch = 18.4454s	
6540/16650 (epoch 19.640), train_loss = 0.94616858, grad/param norm = 2.6148e-01, time/batch = 17.0945s	
6541/16650 (epoch 19.643), train_loss = 1.08450862, grad/param norm = 2.3833e-01, time/batch = 16.7678s	
6542/16650 (epoch 19.646), train_loss = 1.07703577, grad/param norm = 2.6760e-01, time/batch = 18.2864s	
6543/16650 (epoch 19.649), train_loss = 1.03680470, grad/param norm = 2.5360e-01, time/batch = 17.0906s	
6544/16650 (epoch 19.652), train_loss = 1.11355024, grad/param norm = 2.6140e-01, time/batch = 17.5104s	
6545/16650 (epoch 19.655), train_loss = 1.06486239, grad/param norm = 2.6671e-01, time/batch = 16.9255s	
6546/16650 (epoch 19.658), train_loss = 0.90790373, grad/param norm = 2.3894e-01, time/batch = 17.9406s	
6547/16650 (epoch 19.661), train_loss = 1.08923115, grad/param norm = 2.8478e-01, time/batch = 16.2388s	
6548/16650 (epoch 19.664), train_loss = 1.01669500, grad/param norm = 2.4272e-01, time/batch = 17.4381s	
6549/16650 (epoch 19.667), train_loss = 1.13299736, grad/param norm = 2.4852e-01, time/batch = 18.1002s	
6550/16650 (epoch 19.670), train_loss = 0.87908664, grad/param norm = 2.4021e-01, time/batch = 15.8989s	
6551/16650 (epoch 19.673), train_loss = 0.94132849, grad/param norm = 2.4057e-01, time/batch = 18.0284s	
6552/16650 (epoch 19.676), train_loss = 1.02828533, grad/param norm = 2.8258e-01, time/batch = 16.7739s	
6553/16650 (epoch 19.679), train_loss = 0.90401165, grad/param norm = 2.4014e-01, time/batch = 17.6670s	
6554/16650 (epoch 19.682), train_loss = 1.02860740, grad/param norm = 2.3803e-01, time/batch = 18.4227s	
6555/16650 (epoch 19.685), train_loss = 0.86433090, grad/param norm = 2.3301e-01, time/batch = 18.6168s	
6556/16650 (epoch 19.688), train_loss = 1.07342181, grad/param norm = 2.5416e-01, time/batch = 18.2048s	
6557/16650 (epoch 19.691), train_loss = 1.08086107, grad/param norm = 2.5820e-01, time/batch = 15.3923s	
6558/16650 (epoch 19.694), train_loss = 0.88482861, grad/param norm = 2.0596e-01, time/batch = 17.5209s	
6559/16650 (epoch 19.697), train_loss = 0.87185634, grad/param norm = 2.1827e-01, time/batch = 17.2160s	
6560/16650 (epoch 19.700), train_loss = 1.11030746, grad/param norm = 2.5605e-01, time/batch = 17.0119s	
6561/16650 (epoch 19.703), train_loss = 0.91645517, grad/param norm = 2.3493e-01, time/batch = 17.8560s	
6562/16650 (epoch 19.706), train_loss = 1.04406611, grad/param norm = 2.4721e-01, time/batch = 17.9464s	
6563/16650 (epoch 19.709), train_loss = 0.91443452, grad/param norm = 2.2094e-01, time/batch = 18.1147s	
6564/16650 (epoch 19.712), train_loss = 0.93471899, grad/param norm = 2.5524e-01, time/batch = 17.7573s	
6565/16650 (epoch 19.715), train_loss = 1.10351716, grad/param norm = 2.4492e-01, time/batch = 18.2655s	
6566/16650 (epoch 19.718), train_loss = 1.15420747, grad/param norm = 2.5577e-01, time/batch = 17.8680s	
6567/16650 (epoch 19.721), train_loss = 1.12346669, grad/param norm = 2.5471e-01, time/batch = 16.0850s	
6568/16650 (epoch 19.724), train_loss = 1.12128137, grad/param norm = 2.6006e-01, time/batch = 16.8149s	
6569/16650 (epoch 19.727), train_loss = 1.09496320, grad/param norm = 2.6206e-01, time/batch = 17.2767s	
6570/16650 (epoch 19.730), train_loss = 0.98923351, grad/param norm = 2.4289e-01, time/batch = 17.2644s	
6571/16650 (epoch 19.733), train_loss = 1.12269905, grad/param norm = 2.7395e-01, time/batch = 16.5083s	
6572/16650 (epoch 19.736), train_loss = 0.86778584, grad/param norm = 2.2653e-01, time/batch = 18.0369s	
6573/16650 (epoch 19.739), train_loss = 1.00859469, grad/param norm = 2.3952e-01, time/batch = 18.1549s	
6574/16650 (epoch 19.742), train_loss = 1.01693403, grad/param norm = 2.3996e-01, time/batch = 16.7571s	
6575/16650 (epoch 19.745), train_loss = 0.85031749, grad/param norm = 2.3267e-01, time/batch = 15.3396s	
6576/16650 (epoch 19.748), train_loss = 0.87918898, grad/param norm = 2.3549e-01, time/batch = 13.7490s	
6577/16650 (epoch 19.751), train_loss = 1.06141183, grad/param norm = 2.9897e-01, time/batch = 13.6162s	
6578/16650 (epoch 19.754), train_loss = 1.21378268, grad/param norm = 2.9793e-01, time/batch = 14.1763s	
6579/16650 (epoch 19.757), train_loss = 1.16869851, grad/param norm = 2.8400e-01, time/batch = 17.7846s	
6580/16650 (epoch 19.760), train_loss = 1.00632053, grad/param norm = 2.5497e-01, time/batch = 18.5371s	
6581/16650 (epoch 19.763), train_loss = 0.93367315, grad/param norm = 2.4386e-01, time/batch = 17.7745s	
6582/16650 (epoch 19.766), train_loss = 0.98874288, grad/param norm = 2.1549e-01, time/batch = 16.2424s	
6583/16650 (epoch 19.769), train_loss = 1.05718719, grad/param norm = 2.6536e-01, time/batch = 18.2786s	
6584/16650 (epoch 19.772), train_loss = 0.98463619, grad/param norm = 2.3657e-01, time/batch = 18.4612s	
6585/16650 (epoch 19.775), train_loss = 0.99161283, grad/param norm = 2.3050e-01, time/batch = 17.1648s	
6586/16650 (epoch 19.778), train_loss = 1.04474447, grad/param norm = 2.4969e-01, time/batch = 18.3610s	
6587/16650 (epoch 19.781), train_loss = 1.13239053, grad/param norm = 2.3388e-01, time/batch = 17.6891s	
6588/16650 (epoch 19.784), train_loss = 1.08258925, grad/param norm = 2.5732e-01, time/batch = 15.3781s	
6589/16650 (epoch 19.787), train_loss = 1.09572064, grad/param norm = 2.4530e-01, time/batch = 18.3535s	
6590/16650 (epoch 19.790), train_loss = 1.05546499, grad/param norm = 2.3901e-01, time/batch = 18.3640s	
6591/16650 (epoch 19.793), train_loss = 0.91816653, grad/param norm = 2.3858e-01, time/batch = 17.1969s	
6592/16650 (epoch 19.796), train_loss = 1.35875319, grad/param norm = 2.8865e-01, time/batch = 17.0155s	
6593/16650 (epoch 19.799), train_loss = 1.23829096, grad/param norm = 2.5518e-01, time/batch = 16.8440s	
6594/16650 (epoch 19.802), train_loss = 1.07732150, grad/param norm = 2.4422e-01, time/batch = 18.3512s	
6595/16650 (epoch 19.805), train_loss = 1.02224937, grad/param norm = 2.4757e-01, time/batch = 17.5974s	
6596/16650 (epoch 19.808), train_loss = 1.07563607, grad/param norm = 2.5435e-01, time/batch = 17.4379s	
6597/16650 (epoch 19.811), train_loss = 1.15456521, grad/param norm = 2.5378e-01, time/batch = 17.6947s	
6598/16650 (epoch 19.814), train_loss = 0.91719375, grad/param norm = 2.1727e-01, time/batch = 17.8602s	
6599/16650 (epoch 19.817), train_loss = 0.98440114, grad/param norm = 2.5505e-01, time/batch = 16.7413s	
6600/16650 (epoch 19.820), train_loss = 1.09961453, grad/param norm = 2.7185e-01, time/batch = 17.6864s	
6601/16650 (epoch 19.823), train_loss = 0.98461571, grad/param norm = 2.3502e-01, time/batch = 17.4163s	
6602/16650 (epoch 19.826), train_loss = 1.01831312, grad/param norm = 2.2210e-01, time/batch = 14.9660s	
6603/16650 (epoch 19.829), train_loss = 1.09656184, grad/param norm = 2.4216e-01, time/batch = 18.9316s	
6604/16650 (epoch 19.832), train_loss = 1.13858443, grad/param norm = 2.8542e-01, time/batch = 19.0321s	
6605/16650 (epoch 19.835), train_loss = 1.11669963, grad/param norm = 2.8051e-01, time/batch = 15.5795s	
6606/16650 (epoch 19.838), train_loss = 0.94040140, grad/param norm = 2.5004e-01, time/batch = 17.4213s	
6607/16650 (epoch 19.841), train_loss = 0.98764313, grad/param norm = 2.5157e-01, time/batch = 17.4435s	
6608/16650 (epoch 19.844), train_loss = 0.94864728, grad/param norm = 2.1913e-01, time/batch = 16.2495s	
6609/16650 (epoch 19.847), train_loss = 1.12912240, grad/param norm = 2.7956e-01, time/batch = 17.9302s	
6610/16650 (epoch 19.850), train_loss = 0.92983797, grad/param norm = 2.5871e-01, time/batch = 17.8483s	
6611/16650 (epoch 19.853), train_loss = 1.06626674, grad/param norm = 2.6250e-01, time/batch = 17.9341s	
6612/16650 (epoch 19.856), train_loss = 0.95897452, grad/param norm = 2.4901e-01, time/batch = 17.0919s	
6613/16650 (epoch 19.859), train_loss = 1.11877204, grad/param norm = 2.5805e-01, time/batch = 18.0295s	
6614/16650 (epoch 19.862), train_loss = 1.03098291, grad/param norm = 2.3910e-01, time/batch = 17.8542s	
6615/16650 (epoch 19.865), train_loss = 0.85174481, grad/param norm = 2.1246e-01, time/batch = 18.2024s	
6616/16650 (epoch 19.868), train_loss = 1.08830295, grad/param norm = 2.4865e-01, time/batch = 15.2452s	
6617/16650 (epoch 19.871), train_loss = 1.06771015, grad/param norm = 2.4491e-01, time/batch = 16.7415s	
6618/16650 (epoch 19.874), train_loss = 1.07071679, grad/param norm = 2.4873e-01, time/batch = 18.8637s	
6619/16650 (epoch 19.877), train_loss = 1.03504485, grad/param norm = 2.5185e-01, time/batch = 16.7663s	
6620/16650 (epoch 19.880), train_loss = 0.95966072, grad/param norm = 2.4533e-01, time/batch = 17.5161s	
6621/16650 (epoch 19.883), train_loss = 1.02986383, grad/param norm = 2.5286e-01, time/batch = 18.5263s	
6622/16650 (epoch 19.886), train_loss = 1.03060404, grad/param norm = 2.2468e-01, time/batch = 18.3682s	
6623/16650 (epoch 19.889), train_loss = 0.88503141, grad/param norm = 2.2908e-01, time/batch = 16.8465s	
6624/16650 (epoch 19.892), train_loss = 1.02450157, grad/param norm = 2.2528e-01, time/batch = 18.2080s	
6625/16650 (epoch 19.895), train_loss = 1.08209857, grad/param norm = 2.4520e-01, time/batch = 17.7054s	
6626/16650 (epoch 19.898), train_loss = 1.06271589, grad/param norm = 2.4680e-01, time/batch = 16.3215s	
6627/16650 (epoch 19.901), train_loss = 1.01645701, grad/param norm = 2.3130e-01, time/batch = 18.5333s	
6628/16650 (epoch 19.904), train_loss = 0.94831019, grad/param norm = 2.3053e-01, time/batch = 18.0226s	
6629/16650 (epoch 19.907), train_loss = 1.10215210, grad/param norm = 2.5270e-01, time/batch = 17.4306s	
6630/16650 (epoch 19.910), train_loss = 1.08182963, grad/param norm = 2.5509e-01, time/batch = 18.0265s	
6631/16650 (epoch 19.913), train_loss = 0.95052609, grad/param norm = 2.5435e-01, time/batch = 18.4584s	
6632/16650 (epoch 19.916), train_loss = 1.03051466, grad/param norm = 2.4777e-01, time/batch = 17.1064s	
6633/16650 (epoch 19.919), train_loss = 1.20700345, grad/param norm = 2.8263e-01, time/batch = 17.4082s	
6634/16650 (epoch 19.922), train_loss = 1.13930579, grad/param norm = 2.5934e-01, time/batch = 18.6965s	
6635/16650 (epoch 19.925), train_loss = 0.96657399, grad/param norm = 2.6513e-01, time/batch = 17.8594s	
6636/16650 (epoch 19.928), train_loss = 1.00822858, grad/param norm = 2.6543e-01, time/batch = 16.5092s	
6637/16650 (epoch 19.931), train_loss = 1.07839899, grad/param norm = 2.6025e-01, time/batch = 15.2996s	
6638/16650 (epoch 19.934), train_loss = 0.92006382, grad/param norm = 2.8820e-01, time/batch = 19.0253s	
6639/16650 (epoch 19.937), train_loss = 0.96165410, grad/param norm = 2.5935e-01, time/batch = 17.7806s	
6640/16650 (epoch 19.940), train_loss = 0.97962401, grad/param norm = 2.3138e-01, time/batch = 15.7245s	
6641/16650 (epoch 19.943), train_loss = 1.06370171, grad/param norm = 2.6251e-01, time/batch = 18.1249s	
6642/16650 (epoch 19.946), train_loss = 0.93658401, grad/param norm = 2.2679e-01, time/batch = 19.3782s	
6643/16650 (epoch 19.949), train_loss = 0.92160270, grad/param norm = 2.3696e-01, time/batch = 15.4132s	
6644/16650 (epoch 19.952), train_loss = 0.85692905, grad/param norm = 2.5335e-01, time/batch = 17.2671s	
6645/16650 (epoch 19.955), train_loss = 0.98986391, grad/param norm = 2.3183e-01, time/batch = 17.0044s	
6646/16650 (epoch 19.958), train_loss = 1.08963221, grad/param norm = 2.7111e-01, time/batch = 18.2733s	
6647/16650 (epoch 19.961), train_loss = 1.01027399, grad/param norm = 2.2665e-01, time/batch = 17.5227s	
6648/16650 (epoch 19.964), train_loss = 0.94290413, grad/param norm = 2.6042e-01, time/batch = 17.6076s	
6649/16650 (epoch 19.967), train_loss = 1.14153193, grad/param norm = 2.6606e-01, time/batch = 18.7786s	
6650/16650 (epoch 19.970), train_loss = 0.93883935, grad/param norm = 2.4569e-01, time/batch = 15.7390s	
6651/16650 (epoch 19.973), train_loss = 0.96395159, grad/param norm = 2.5950e-01, time/batch = 18.1929s	
6652/16650 (epoch 19.976), train_loss = 0.94768952, grad/param norm = 2.4064e-01, time/batch = 17.6210s	
6653/16650 (epoch 19.979), train_loss = 1.04475758, grad/param norm = 2.7814e-01, time/batch = 16.8520s	
6654/16650 (epoch 19.982), train_loss = 1.08594010, grad/param norm = 2.6968e-01, time/batch = 17.5186s	
6655/16650 (epoch 19.985), train_loss = 0.98042705, grad/param norm = 2.3014e-01, time/batch = 18.2881s	
6656/16650 (epoch 19.988), train_loss = 1.16138336, grad/param norm = 2.7459e-01, time/batch = 18.2759s	
6657/16650 (epoch 19.991), train_loss = 0.95508565, grad/param norm = 2.5275e-01, time/batch = 15.8127s	
6658/16650 (epoch 19.994), train_loss = 0.94640211, grad/param norm = 2.3420e-01, time/batch = 18.4556s	
6659/16650 (epoch 19.997), train_loss = 1.03976399, grad/param norm = 2.8699e-01, time/batch = 17.7811s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
6660/16650 (epoch 20.000), train_loss = 1.08045260, grad/param norm = 2.7315e-01, time/batch = 14.8907s	
6661/16650 (epoch 20.003), train_loss = 1.12653062, grad/param norm = 3.0863e-01, time/batch = 17.2572s	
6662/16650 (epoch 20.006), train_loss = 1.10822429, grad/param norm = 3.4132e-01, time/batch = 16.9238s	
6663/16650 (epoch 20.009), train_loss = 1.18925522, grad/param norm = 2.6095e-01, time/batch = 18.6195s	
6664/16650 (epoch 20.012), train_loss = 1.17677505, grad/param norm = 2.7832e-01, time/batch = 18.5254s	
6665/16650 (epoch 20.015), train_loss = 1.03014544, grad/param norm = 2.8880e-01, time/batch = 18.4571s	
6666/16650 (epoch 20.018), train_loss = 0.85165851, grad/param norm = 2.4254e-01, time/batch = 17.6044s	
6667/16650 (epoch 20.021), train_loss = 1.16980293, grad/param norm = 3.0132e-01, time/batch = 15.9302s	
6668/16650 (epoch 20.024), train_loss = 1.02312161, grad/param norm = 2.5051e-01, time/batch = 18.8684s	
6669/16650 (epoch 20.027), train_loss = 1.11149470, grad/param norm = 2.8789e-01, time/batch = 16.9392s	
6670/16650 (epoch 20.030), train_loss = 0.90590231, grad/param norm = 2.3839e-01, time/batch = 17.7797s	
6671/16650 (epoch 20.033), train_loss = 1.04135922, grad/param norm = 2.4167e-01, time/batch = 17.6092s	
6672/16650 (epoch 20.036), train_loss = 0.81692785, grad/param norm = 2.6542e-01, time/batch = 18.3665s	
6673/16650 (epoch 20.039), train_loss = 1.12962079, grad/param norm = 2.4266e-01, time/batch = 17.0970s	
6674/16650 (epoch 20.042), train_loss = 1.10959513, grad/param norm = 2.5590e-01, time/batch = 16.0871s	
6675/16650 (epoch 20.045), train_loss = 1.00498974, grad/param norm = 2.5070e-01, time/batch = 17.5277s	
6676/16650 (epoch 20.048), train_loss = 1.10372728, grad/param norm = 2.6468e-01, time/batch = 16.7783s	
6677/16650 (epoch 20.051), train_loss = 1.00651692, grad/param norm = 2.6475e-01, time/batch = 14.6570s	
6678/16650 (epoch 20.054), train_loss = 1.04905987, grad/param norm = 2.6558e-01, time/batch = 15.2382s	
6679/16650 (epoch 20.057), train_loss = 1.03941454, grad/param norm = 2.5497e-01, time/batch = 17.6017s	
6680/16650 (epoch 20.060), train_loss = 0.88329814, grad/param norm = 2.2489e-01, time/batch = 17.0543s	
6681/16650 (epoch 20.063), train_loss = 1.00408501, grad/param norm = 2.4328e-01, time/batch = 16.0181s	
6682/16650 (epoch 20.066), train_loss = 1.19114330, grad/param norm = 2.6179e-01, time/batch = 15.5876s	
6683/16650 (epoch 20.069), train_loss = 1.11683872, grad/param norm = 2.7532e-01, time/batch = 13.9136s	
6684/16650 (epoch 20.072), train_loss = 0.99237939, grad/param norm = 2.4907e-01, time/batch = 13.8253s	
6685/16650 (epoch 20.075), train_loss = 1.10013151, grad/param norm = 2.4373e-01, time/batch = 14.3235s	
6686/16650 (epoch 20.078), train_loss = 1.15428122, grad/param norm = 2.6357e-01, time/batch = 14.9900s	
6687/16650 (epoch 20.081), train_loss = 1.03120385, grad/param norm = 2.3229e-01, time/batch = 13.8123s	
6688/16650 (epoch 20.084), train_loss = 1.09062104, grad/param norm = 2.4832e-01, time/batch = 14.3350s	
6689/16650 (epoch 20.087), train_loss = 1.01581224, grad/param norm = 2.4705e-01, time/batch = 20.3808s	
6690/16650 (epoch 20.090), train_loss = 1.01829929, grad/param norm = 2.5350e-01, time/batch = 25.1298s	
6691/16650 (epoch 20.093), train_loss = 1.26089193, grad/param norm = 3.0277e-01, time/batch = 17.5453s	
6692/16650 (epoch 20.096), train_loss = 0.98113872, grad/param norm = 2.5678e-01, time/batch = 15.5152s	
6693/16650 (epoch 20.099), train_loss = 1.03464015, grad/param norm = 2.3159e-01, time/batch = 15.5253s	
6694/16650 (epoch 20.102), train_loss = 1.07279770, grad/param norm = 2.6236e-01, time/batch = 18.0415s	
6695/16650 (epoch 20.105), train_loss = 1.09595511, grad/param norm = 2.6697e-01, time/batch = 16.9348s	
6696/16650 (epoch 20.108), train_loss = 1.08610683, grad/param norm = 2.5402e-01, time/batch = 14.9999s	
6697/16650 (epoch 20.111), train_loss = 1.11466040, grad/param norm = 2.3709e-01, time/batch = 15.8345s	
6698/16650 (epoch 20.114), train_loss = 1.15575194, grad/param norm = 2.6081e-01, time/batch = 17.3431s	
6699/16650 (epoch 20.117), train_loss = 1.21924654, grad/param norm = 3.4746e-01, time/batch = 15.6865s	
6700/16650 (epoch 20.120), train_loss = 0.95568958, grad/param norm = 2.3496e-01, time/batch = 16.4389s	
6701/16650 (epoch 20.123), train_loss = 1.01564404, grad/param norm = 2.4270e-01, time/batch = 17.2846s	
6702/16650 (epoch 20.126), train_loss = 1.05966516, grad/param norm = 2.4241e-01, time/batch = 16.8588s	
6703/16650 (epoch 20.129), train_loss = 1.07601382, grad/param norm = 2.5374e-01, time/batch = 15.7504s	
6704/16650 (epoch 20.132), train_loss = 1.04902093, grad/param norm = 2.5933e-01, time/batch = 17.2789s	
6705/16650 (epoch 20.135), train_loss = 1.12488159, grad/param norm = 2.5631e-01, time/batch = 16.2821s	
6706/16650 (epoch 20.138), train_loss = 1.10815141, grad/param norm = 2.4473e-01, time/batch = 16.4202s	
6707/16650 (epoch 20.141), train_loss = 1.11376669, grad/param norm = 2.8391e-01, time/batch = 16.5265s	
6708/16650 (epoch 20.144), train_loss = 1.03450519, grad/param norm = 2.5020e-01, time/batch = 15.8376s	
6709/16650 (epoch 20.147), train_loss = 1.19846111, grad/param norm = 2.6079e-01, time/batch = 17.1931s	
6710/16650 (epoch 20.150), train_loss = 1.25654011, grad/param norm = 2.7349e-01, time/batch = 15.6727s	
6711/16650 (epoch 20.153), train_loss = 1.09376458, grad/param norm = 2.7058e-01, time/batch = 16.3562s	
6712/16650 (epoch 20.156), train_loss = 0.95328650, grad/param norm = 2.4380e-01, time/batch = 17.5303s	
6713/16650 (epoch 20.159), train_loss = 1.12235160, grad/param norm = 2.8102e-01, time/batch = 16.6995s	
6714/16650 (epoch 20.162), train_loss = 1.17556112, grad/param norm = 2.6141e-01, time/batch = 14.9786s	
6715/16650 (epoch 20.165), train_loss = 1.17075565, grad/param norm = 2.7081e-01, time/batch = 16.3690s	
6716/16650 (epoch 20.168), train_loss = 0.88576874, grad/param norm = 2.2012e-01, time/batch = 17.8801s	
6717/16650 (epoch 20.171), train_loss = 1.16309057, grad/param norm = 2.4309e-01, time/batch = 14.4983s	
6718/16650 (epoch 20.174), train_loss = 0.87610142, grad/param norm = 2.2694e-01, time/batch = 16.6970s	
6719/16650 (epoch 20.177), train_loss = 1.03939498, grad/param norm = 2.5409e-01, time/batch = 17.6212s	
6720/16650 (epoch 20.180), train_loss = 1.17965929, grad/param norm = 2.6526e-01, time/batch = 16.4456s	
6721/16650 (epoch 20.183), train_loss = 1.31035170, grad/param norm = 2.8175e-01, time/batch = 14.9161s	
6722/16650 (epoch 20.186), train_loss = 1.12969775, grad/param norm = 2.6734e-01, time/batch = 16.5325s	
6723/16650 (epoch 20.189), train_loss = 0.95922289, grad/param norm = 2.2438e-01, time/batch = 17.8880s	
6724/16650 (epoch 20.192), train_loss = 0.99924928, grad/param norm = 2.6554e-01, time/batch = 17.0978s	
6725/16650 (epoch 20.195), train_loss = 1.00867926, grad/param norm = 2.9608e-01, time/batch = 15.6045s	
6726/16650 (epoch 20.198), train_loss = 0.87804192, grad/param norm = 2.1768e-01, time/batch = 16.6230s	
6727/16650 (epoch 20.201), train_loss = 0.99419763, grad/param norm = 2.5745e-01, time/batch = 17.5396s	
6728/16650 (epoch 20.204), train_loss = 1.04082412, grad/param norm = 2.4246e-01, time/batch = 16.4313s	
6729/16650 (epoch 20.207), train_loss = 1.08553263, grad/param norm = 2.8890e-01, time/batch = 16.6159s	
6730/16650 (epoch 20.210), train_loss = 1.01395959, grad/param norm = 2.4019e-01, time/batch = 17.0289s	
6731/16650 (epoch 20.213), train_loss = 1.13677329, grad/param norm = 2.7453e-01, time/batch = 17.3655s	
6732/16650 (epoch 20.216), train_loss = 1.01413368, grad/param norm = 2.5365e-01, time/batch = 17.1744s	
6733/16650 (epoch 20.219), train_loss = 1.05008817, grad/param norm = 2.6464e-01, time/batch = 16.6179s	
6734/16650 (epoch 20.222), train_loss = 1.06279918, grad/param norm = 2.3129e-01, time/batch = 15.1969s	
6735/16650 (epoch 20.225), train_loss = 1.06120325, grad/param norm = 2.5982e-01, time/batch = 15.7566s	
6736/16650 (epoch 20.228), train_loss = 0.93631271, grad/param norm = 2.3644e-01, time/batch = 16.6130s	
6737/16650 (epoch 20.231), train_loss = 1.02489067, grad/param norm = 2.5211e-01, time/batch = 14.6989s	
6738/16650 (epoch 20.234), train_loss = 1.22897463, grad/param norm = 2.5699e-01, time/batch = 17.1331s	
6739/16650 (epoch 20.237), train_loss = 1.09358902, grad/param norm = 2.4198e-01, time/batch = 15.6025s	
6740/16650 (epoch 20.240), train_loss = 1.09487191, grad/param norm = 2.5028e-01, time/batch = 17.4577s	
6741/16650 (epoch 20.243), train_loss = 1.03698014, grad/param norm = 2.4710e-01, time/batch = 16.2806s	
6742/16650 (epoch 20.246), train_loss = 1.18275817, grad/param norm = 2.9803e-01, time/batch = 17.3686s	
6743/16650 (epoch 20.249), train_loss = 0.92909592, grad/param norm = 2.4801e-01, time/batch = 17.0750s	
6744/16650 (epoch 20.252), train_loss = 1.02038967, grad/param norm = 2.4819e-01, time/batch = 15.3298s	
6745/16650 (epoch 20.255), train_loss = 1.13520415, grad/param norm = 2.7355e-01, time/batch = 16.6997s	
6746/16650 (epoch 20.258), train_loss = 1.17167333, grad/param norm = 2.5288e-01, time/batch = 15.9300s	
6747/16650 (epoch 20.261), train_loss = 1.05783173, grad/param norm = 2.3909e-01, time/batch = 14.7886s	
6748/16650 (epoch 20.264), train_loss = 0.99599740, grad/param norm = 2.5434e-01, time/batch = 15.7603s	
6749/16650 (epoch 20.267), train_loss = 1.01355040, grad/param norm = 2.3843e-01, time/batch = 15.2518s	
6750/16650 (epoch 20.270), train_loss = 1.06747074, grad/param norm = 2.5029e-01, time/batch = 16.1818s	
6751/16650 (epoch 20.273), train_loss = 1.16482222, grad/param norm = 2.2934e-01, time/batch = 16.6256s	
6752/16650 (epoch 20.276), train_loss = 1.06119800, grad/param norm = 2.3033e-01, time/batch = 15.8600s	
6753/16650 (epoch 20.279), train_loss = 1.03741687, grad/param norm = 2.4810e-01, time/batch = 17.3746s	
6754/16650 (epoch 20.282), train_loss = 0.94295161, grad/param norm = 2.2342e-01, time/batch = 17.0057s	
6755/16650 (epoch 20.285), train_loss = 0.95134021, grad/param norm = 2.3207e-01, time/batch = 17.0384s	
6756/16650 (epoch 20.288), train_loss = 0.98261136, grad/param norm = 2.4910e-01, time/batch = 16.4248s	
6757/16650 (epoch 20.291), train_loss = 0.80385441, grad/param norm = 2.0388e-01, time/batch = 15.4426s	
6758/16650 (epoch 20.294), train_loss = 0.91633845, grad/param norm = 2.0682e-01, time/batch = 16.5138s	
6759/16650 (epoch 20.297), train_loss = 0.99994205, grad/param norm = 2.3223e-01, time/batch = 17.5443s	
6760/16650 (epoch 20.300), train_loss = 0.81503502, grad/param norm = 2.2745e-01, time/batch = 17.4729s	
6761/16650 (epoch 20.303), train_loss = 0.88841647, grad/param norm = 2.2201e-01, time/batch = 16.0220s	
6762/16650 (epoch 20.306), train_loss = 1.12134374, grad/param norm = 2.4606e-01, time/batch = 17.4421s	
6763/16650 (epoch 20.309), train_loss = 1.12314094, grad/param norm = 2.4298e-01, time/batch = 15.7578s	
6764/16650 (epoch 20.312), train_loss = 0.93797410, grad/param norm = 2.6740e-01, time/batch = 16.0258s	
6765/16650 (epoch 20.315), train_loss = 0.73677002, grad/param norm = 1.9336e-01, time/batch = 16.9579s	
6766/16650 (epoch 20.318), train_loss = 0.83263816, grad/param norm = 2.1570e-01, time/batch = 16.0332s	
6767/16650 (epoch 20.321), train_loss = 1.18697941, grad/param norm = 2.6560e-01, time/batch = 17.6061s	
6768/16650 (epoch 20.324), train_loss = 0.96886561, grad/param norm = 2.5153e-01, time/batch = 14.4122s	
6769/16650 (epoch 20.327), train_loss = 1.10517815, grad/param norm = 2.6700e-01, time/batch = 16.8679s	
6770/16650 (epoch 20.330), train_loss = 1.08623299, grad/param norm = 2.8373e-01, time/batch = 16.6150s	
6771/16650 (epoch 20.333), train_loss = 1.10421732, grad/param norm = 3.0611e-01, time/batch = 17.8637s	
6772/16650 (epoch 20.336), train_loss = 0.92975522, grad/param norm = 2.6286e-01, time/batch = 17.2745s	
6773/16650 (epoch 20.339), train_loss = 0.99714225, grad/param norm = 2.4696e-01, time/batch = 15.8763s	
6774/16650 (epoch 20.342), train_loss = 0.96211740, grad/param norm = 2.5927e-01, time/batch = 16.3436s	
6775/16650 (epoch 20.345), train_loss = 0.88359282, grad/param norm = 2.1185e-01, time/batch = 16.7578s	
6776/16650 (epoch 20.348), train_loss = 1.05516131, grad/param norm = 2.8924e-01, time/batch = 16.5229s	
6777/16650 (epoch 20.351), train_loss = 1.10644010, grad/param norm = 3.0466e-01, time/batch = 16.7137s	
6778/16650 (epoch 20.354), train_loss = 1.12218025, grad/param norm = 2.6801e-01, time/batch = 17.7079s	
6779/16650 (epoch 20.357), train_loss = 1.07183452, grad/param norm = 2.6402e-01, time/batch = 15.6049s	
6780/16650 (epoch 20.360), train_loss = 1.08106463, grad/param norm = 2.5338e-01, time/batch = 16.8643s	
6781/16650 (epoch 20.363), train_loss = 1.15155161, grad/param norm = 2.6317e-01, time/batch = 16.7018s	
6782/16650 (epoch 20.366), train_loss = 1.20399591, grad/param norm = 2.8347e-01, time/batch = 16.4424s	
6783/16650 (epoch 20.369), train_loss = 1.04814318, grad/param norm = 2.4885e-01, time/batch = 17.5329s	
6784/16650 (epoch 20.372), train_loss = 1.03498094, grad/param norm = 2.2494e-01, time/batch = 17.8670s	
6785/16650 (epoch 20.375), train_loss = 1.06175826, grad/param norm = 2.3024e-01, time/batch = 16.0939s	
6786/16650 (epoch 20.378), train_loss = 0.94231939, grad/param norm = 2.2463e-01, time/batch = 15.0761s	
6787/16650 (epoch 20.381), train_loss = 1.06142660, grad/param norm = 2.3093e-01, time/batch = 14.1615s	
6788/16650 (epoch 20.384), train_loss = 1.20163430, grad/param norm = 2.8006e-01, time/batch = 17.1226s	
6789/16650 (epoch 20.387), train_loss = 0.81670837, grad/param norm = 2.0464e-01, time/batch = 17.3721s	
6790/16650 (epoch 20.390), train_loss = 1.12279451, grad/param norm = 2.4458e-01, time/batch = 16.3362s	
6791/16650 (epoch 20.393), train_loss = 1.00382793, grad/param norm = 2.6628e-01, time/batch = 17.6978s	
6792/16650 (epoch 20.396), train_loss = 1.15728373, grad/param norm = 2.8344e-01, time/batch = 16.5329s	
6793/16650 (epoch 20.399), train_loss = 1.07276780, grad/param norm = 2.4116e-01, time/batch = 16.0776s	
6794/16650 (epoch 20.402), train_loss = 0.95999672, grad/param norm = 2.5226e-01, time/batch = 15.4375s	
6795/16650 (epoch 20.405), train_loss = 0.86386463, grad/param norm = 2.5008e-01, time/batch = 16.1282s	
6796/16650 (epoch 20.408), train_loss = 1.11710913, grad/param norm = 3.0060e-01, time/batch = 18.2174s	
6797/16650 (epoch 20.411), train_loss = 0.94300187, grad/param norm = 3.4015e-01, time/batch = 15.2599s	
6798/16650 (epoch 20.414), train_loss = 0.93194974, grad/param norm = 2.6257e-01, time/batch = 17.5417s	
6799/16650 (epoch 20.417), train_loss = 0.89237192, grad/param norm = 2.3589e-01, time/batch = 16.5570s	
6800/16650 (epoch 20.420), train_loss = 0.90032195, grad/param norm = 2.3460e-01, time/batch = 17.1936s	
6801/16650 (epoch 20.423), train_loss = 0.76424864, grad/param norm = 2.0296e-01, time/batch = 14.4907s	
6802/16650 (epoch 20.426), train_loss = 0.92544605, grad/param norm = 2.6731e-01, time/batch = 17.5209s	
6803/16650 (epoch 20.429), train_loss = 1.12835419, grad/param norm = 2.5098e-01, time/batch = 14.7366s	
6804/16650 (epoch 20.432), train_loss = 1.11241497, grad/param norm = 2.7113e-01, time/batch = 16.2805s	
6805/16650 (epoch 20.435), train_loss = 1.21448311, grad/param norm = 2.5037e-01, time/batch = 17.2054s	
6806/16650 (epoch 20.438), train_loss = 1.21027283, grad/param norm = 2.9343e-01, time/batch = 15.0052s	
6807/16650 (epoch 20.441), train_loss = 1.05390585, grad/param norm = 2.7396e-01, time/batch = 16.4596s	
6808/16650 (epoch 20.444), train_loss = 0.94452226, grad/param norm = 2.5675e-01, time/batch = 16.2723s	
6809/16650 (epoch 20.447), train_loss = 1.01662487, grad/param norm = 2.6882e-01, time/batch = 16.5178s	
6810/16650 (epoch 20.450), train_loss = 0.95683362, grad/param norm = 2.4023e-01, time/batch = 17.7130s	
6811/16650 (epoch 20.453), train_loss = 0.98098326, grad/param norm = 2.5824e-01, time/batch = 16.6700s	
6812/16650 (epoch 20.456), train_loss = 0.88601234, grad/param norm = 2.3346e-01, time/batch = 14.0795s	
6813/16650 (epoch 20.459), train_loss = 0.95573840, grad/param norm = 2.4566e-01, time/batch = 17.0287s	
6814/16650 (epoch 20.462), train_loss = 1.16499310, grad/param norm = 3.1972e-01, time/batch = 15.8660s	
6815/16650 (epoch 20.465), train_loss = 0.94735361, grad/param norm = 2.6406e-01, time/batch = 16.4404s	
6816/16650 (epoch 20.468), train_loss = 0.80355752, grad/param norm = 2.5298e-01, time/batch = 17.5391s	
6817/16650 (epoch 20.471), train_loss = 0.66900043, grad/param norm = 1.9033e-01, time/batch = 17.7890s	
6818/16650 (epoch 20.474), train_loss = 0.87775375, grad/param norm = 2.2940e-01, time/batch = 17.2863s	
6819/16650 (epoch 20.477), train_loss = 1.06529517, grad/param norm = 2.6335e-01, time/batch = 16.4189s	
6820/16650 (epoch 20.480), train_loss = 1.08527798, grad/param norm = 2.7827e-01, time/batch = 15.9274s	
6821/16650 (epoch 20.483), train_loss = 1.16040695, grad/param norm = 2.5190e-01, time/batch = 16.2971s	
6822/16650 (epoch 20.486), train_loss = 0.92135393, grad/param norm = 2.1776e-01, time/batch = 16.7617s	
6823/16650 (epoch 20.489), train_loss = 0.97069974, grad/param norm = 2.3837e-01, time/batch = 16.9440s	
6824/16650 (epoch 20.492), train_loss = 0.99799052, grad/param norm = 2.2256e-01, time/batch = 17.4507s	
6825/16650 (epoch 20.495), train_loss = 0.91233013, grad/param norm = 2.5513e-01, time/batch = 17.4604s	
6826/16650 (epoch 20.498), train_loss = 1.00205063, grad/param norm = 2.6706e-01, time/batch = 15.2458s	
6827/16650 (epoch 20.502), train_loss = 1.16959030, grad/param norm = 2.6271e-01, time/batch = 17.6245s	
6828/16650 (epoch 20.505), train_loss = 1.06615878, grad/param norm = 2.3600e-01, time/batch = 17.2010s	
6829/16650 (epoch 20.508), train_loss = 1.05218311, grad/param norm = 2.6988e-01, time/batch = 16.1835s	
6830/16650 (epoch 20.511), train_loss = 1.14942545, grad/param norm = 2.6268e-01, time/batch = 15.2031s	
6831/16650 (epoch 20.514), train_loss = 0.86615865, grad/param norm = 2.2321e-01, time/batch = 17.6944s	
6832/16650 (epoch 20.517), train_loss = 1.01752728, grad/param norm = 2.7522e-01, time/batch = 16.2049s	
6833/16650 (epoch 20.520), train_loss = 0.93194938, grad/param norm = 2.3275e-01, time/batch = 15.5902s	
6834/16650 (epoch 20.523), train_loss = 0.96668716, grad/param norm = 2.3921e-01, time/batch = 16.9438s	
6835/16650 (epoch 20.526), train_loss = 1.11892891, grad/param norm = 2.6418e-01, time/batch = 16.7018s	
6836/16650 (epoch 20.529), train_loss = 1.17109268, grad/param norm = 2.9057e-01, time/batch = 15.3401s	
6837/16650 (epoch 20.532), train_loss = 0.79889347, grad/param norm = 2.4734e-01, time/batch = 14.4142s	
6838/16650 (epoch 20.535), train_loss = 0.88360676, grad/param norm = 2.6118e-01, time/batch = 17.6205s	
6839/16650 (epoch 20.538), train_loss = 0.87171971, grad/param norm = 2.5201e-01, time/batch = 17.4554s	
6840/16650 (epoch 20.541), train_loss = 1.14995729, grad/param norm = 2.7905e-01, time/batch = 15.4258s	
6841/16650 (epoch 20.544), train_loss = 1.18283030, grad/param norm = 3.1596e-01, time/batch = 17.4473s	
6842/16650 (epoch 20.547), train_loss = 0.89783850, grad/param norm = 2.5765e-01, time/batch = 17.6356s	
6843/16650 (epoch 20.550), train_loss = 0.98316016, grad/param norm = 2.7173e-01, time/batch = 16.7759s	
6844/16650 (epoch 20.553), train_loss = 0.99244277, grad/param norm = 2.6429e-01, time/batch = 15.6449s	
6845/16650 (epoch 20.556), train_loss = 0.93888623, grad/param norm = 2.4677e-01, time/batch = 16.7760s	
6846/16650 (epoch 20.559), train_loss = 0.82680491, grad/param norm = 2.3078e-01, time/batch = 17.7989s	
6847/16650 (epoch 20.562), train_loss = 0.95711863, grad/param norm = 2.4581e-01, time/batch = 16.6694s	
6848/16650 (epoch 20.565), train_loss = 0.80324039, grad/param norm = 2.4433e-01, time/batch = 16.1003s	
6849/16650 (epoch 20.568), train_loss = 0.80152909, grad/param norm = 2.0575e-01, time/batch = 16.7885s	
6850/16650 (epoch 20.571), train_loss = 0.84806409, grad/param norm = 3.0225e-01, time/batch = 17.7815s	
6851/16650 (epoch 20.574), train_loss = 0.99581994, grad/param norm = 3.1179e-01, time/batch = 15.4874s	
6852/16650 (epoch 20.577), train_loss = 0.94503522, grad/param norm = 2.3399e-01, time/batch = 17.0061s	
6853/16650 (epoch 20.580), train_loss = 0.83009928, grad/param norm = 2.2394e-01, time/batch = 17.1326s	
6854/16650 (epoch 20.583), train_loss = 0.97702149, grad/param norm = 2.6158e-01, time/batch = 17.2852s	
6855/16650 (epoch 20.586), train_loss = 0.90102644, grad/param norm = 2.7793e-01, time/batch = 16.7769s	
6856/16650 (epoch 20.589), train_loss = 0.85626747, grad/param norm = 2.1664e-01, time/batch = 17.1206s	
6857/16650 (epoch 20.592), train_loss = 0.99337778, grad/param norm = 2.5447e-01, time/batch = 14.3423s	
6858/16650 (epoch 20.595), train_loss = 0.92197361, grad/param norm = 2.4761e-01, time/batch = 15.1821s	
6859/16650 (epoch 20.598), train_loss = 0.94233686, grad/param norm = 2.4752e-01, time/batch = 15.6136s	
6860/16650 (epoch 20.601), train_loss = 0.92224938, grad/param norm = 2.8153e-01, time/batch = 16.9528s	
6861/16650 (epoch 20.604), train_loss = 1.08242718, grad/param norm = 2.7667e-01, time/batch = 16.3741s	
6862/16650 (epoch 20.607), train_loss = 1.02954910, grad/param norm = 2.3663e-01, time/batch = 16.0892s	
6863/16650 (epoch 20.610), train_loss = 0.89560744, grad/param norm = 2.2642e-01, time/batch = 14.4150s	
6864/16650 (epoch 20.613), train_loss = 1.13994597, grad/param norm = 4.0197e-01, time/batch = 15.8194s	
6865/16650 (epoch 20.616), train_loss = 1.14784924, grad/param norm = 3.2862e-01, time/batch = 17.2078s	
6866/16650 (epoch 20.619), train_loss = 0.81651850, grad/param norm = 2.1396e-01, time/batch = 13.8964s	
6867/16650 (epoch 20.622), train_loss = 0.81309444, grad/param norm = 2.4005e-01, time/batch = 17.2868s	
6868/16650 (epoch 20.625), train_loss = 0.90569892, grad/param norm = 2.2909e-01, time/batch = 16.5420s	
6869/16650 (epoch 20.628), train_loss = 0.93373046, grad/param norm = 2.5019e-01, time/batch = 16.5808s	
6870/16650 (epoch 20.631), train_loss = 1.01835897, grad/param norm = 3.0310e-01, time/batch = 16.4386s	
6871/16650 (epoch 20.634), train_loss = 1.21348274, grad/param norm = 3.1130e-01, time/batch = 14.2574s	
6872/16650 (epoch 20.637), train_loss = 1.19652354, grad/param norm = 2.7678e-01, time/batch = 17.5419s	
6873/16650 (epoch 20.640), train_loss = 0.91858192, grad/param norm = 2.5153e-01, time/batch = 16.8479s	
6874/16650 (epoch 20.643), train_loss = 1.04742138, grad/param norm = 2.4040e-01, time/batch = 16.7811s	
6875/16650 (epoch 20.646), train_loss = 1.05400724, grad/param norm = 2.5717e-01, time/batch = 17.5341s	
6876/16650 (epoch 20.649), train_loss = 1.00515995, grad/param norm = 2.6210e-01, time/batch = 15.9546s	
6877/16650 (epoch 20.652), train_loss = 1.09373570, grad/param norm = 2.5668e-01, time/batch = 15.3897s	
6878/16650 (epoch 20.655), train_loss = 1.04871129, grad/param norm = 2.6659e-01, time/batch = 17.7101s	
6879/16650 (epoch 20.658), train_loss = 0.89971781, grad/param norm = 2.6332e-01, time/batch = 18.1272s	
6880/16650 (epoch 20.661), train_loss = 1.06609765, grad/param norm = 2.8375e-01, time/batch = 16.6056s	
6881/16650 (epoch 20.664), train_loss = 1.00568459, grad/param norm = 2.5155e-01, time/batch = 16.6088s	
6882/16650 (epoch 20.667), train_loss = 1.11939254, grad/param norm = 2.6205e-01, time/batch = 17.1292s	
6883/16650 (epoch 20.670), train_loss = 0.85613062, grad/param norm = 2.4243e-01, time/batch = 16.5401s	
6884/16650 (epoch 20.673), train_loss = 0.91662219, grad/param norm = 2.2566e-01, time/batch = 15.5000s	
6885/16650 (epoch 20.676), train_loss = 1.00948539, grad/param norm = 2.6406e-01, time/batch = 17.5425s	
6886/16650 (epoch 20.679), train_loss = 0.88781535, grad/param norm = 2.5562e-01, time/batch = 17.7954s	
6887/16650 (epoch 20.682), train_loss = 1.00943245, grad/param norm = 2.4908e-01, time/batch = 14.1432s	
6888/16650 (epoch 20.685), train_loss = 0.84309188, grad/param norm = 2.4008e-01, time/batch = 16.4409s	
6889/16650 (epoch 20.688), train_loss = 1.05712927, grad/param norm = 2.5039e-01, time/batch = 16.7958s	
6890/16650 (epoch 20.691), train_loss = 1.05281683, grad/param norm = 2.6295e-01, time/batch = 17.6232s	
6891/16650 (epoch 20.694), train_loss = 0.86975576, grad/param norm = 2.2554e-01, time/batch = 15.8426s	
6892/16650 (epoch 20.697), train_loss = 0.85623427, grad/param norm = 2.2752e-01, time/batch = 17.1262s	
6893/16650 (epoch 20.700), train_loss = 1.08796812, grad/param norm = 2.6432e-01, time/batch = 17.3633s	
6894/16650 (epoch 20.703), train_loss = 0.88610976, grad/param norm = 2.8829e-01, time/batch = 16.7814s	
6895/16650 (epoch 20.706), train_loss = 1.01645135, grad/param norm = 2.5507e-01, time/batch = 15.6433s	
6896/16650 (epoch 20.709), train_loss = 0.90376517, grad/param norm = 2.3494e-01, time/batch = 17.5427s	
6897/16650 (epoch 20.712), train_loss = 0.91702166, grad/param norm = 2.5641e-01, time/batch = 17.3734s	
6898/16650 (epoch 20.715), train_loss = 1.08412733, grad/param norm = 2.5581e-01, time/batch = 15.3293s	
6899/16650 (epoch 20.718), train_loss = 1.12414476, grad/param norm = 2.6407e-01, time/batch = 17.7868s	
6900/16650 (epoch 20.721), train_loss = 1.09869372, grad/param norm = 2.6563e-01, time/batch = 17.0477s	
6901/16650 (epoch 20.724), train_loss = 1.09963350, grad/param norm = 2.7373e-01, time/batch = 17.0281s	
6902/16650 (epoch 20.727), train_loss = 1.06175441, grad/param norm = 2.5382e-01, time/batch = 16.0938s	
6903/16650 (epoch 20.730), train_loss = 0.95715466, grad/param norm = 2.3721e-01, time/batch = 17.3833s	
6904/16650 (epoch 20.733), train_loss = 1.10271713, grad/param norm = 2.6989e-01, time/batch = 17.2834s	
6905/16650 (epoch 20.736), train_loss = 0.83505370, grad/param norm = 2.3716e-01, time/batch = 16.1992s	
6906/16650 (epoch 20.739), train_loss = 0.98468078, grad/param norm = 2.4574e-01, time/batch = 0.9871s	
6907/16650 (epoch 20.742), train_loss = 0.97969658, grad/param norm = 2.2972e-01, time/batch = 0.6394s	
6908/16650 (epoch 20.745), train_loss = 0.82058718, grad/param norm = 2.2802e-01, time/batch = 0.6244s	
6909/16650 (epoch 20.748), train_loss = 0.86892263, grad/param norm = 2.7662e-01, time/batch = 0.6203s	
6910/16650 (epoch 20.751), train_loss = 1.04020633, grad/param norm = 4.0535e-01, time/batch = 0.6316s	
6911/16650 (epoch 20.754), train_loss = 1.21922899, grad/param norm = 3.2459e-01, time/batch = 0.6619s	
6912/16650 (epoch 20.757), train_loss = 1.14805603, grad/param norm = 2.7127e-01, time/batch = 0.6522s	
6913/16650 (epoch 20.760), train_loss = 0.99114106, grad/param norm = 2.4351e-01, time/batch = 0.9122s	
6914/16650 (epoch 20.763), train_loss = 0.90912215, grad/param norm = 2.3332e-01, time/batch = 0.9111s	
6915/16650 (epoch 20.766), train_loss = 0.97752804, grad/param norm = 2.2747e-01, time/batch = 0.9112s	
6916/16650 (epoch 20.769), train_loss = 1.03037719, grad/param norm = 2.5270e-01, time/batch = 0.9066s	
6917/16650 (epoch 20.772), train_loss = 0.94968020, grad/param norm = 2.2089e-01, time/batch = 0.9122s	
6918/16650 (epoch 20.775), train_loss = 0.97403491, grad/param norm = 2.4213e-01, time/batch = 1.3959s	
6919/16650 (epoch 20.778), train_loss = 1.01131508, grad/param norm = 2.4536e-01, time/batch = 1.6960s	
6920/16650 (epoch 20.781), train_loss = 1.10612694, grad/param norm = 2.2867e-01, time/batch = 1.6764s	
6921/16650 (epoch 20.784), train_loss = 1.06747137, grad/param norm = 2.6041e-01, time/batch = 12.4917s	
6922/16650 (epoch 20.787), train_loss = 1.08222843, grad/param norm = 2.4780e-01, time/batch = 17.3033s	
6923/16650 (epoch 20.790), train_loss = 1.03112801, grad/param norm = 2.3176e-01, time/batch = 14.4959s	
6924/16650 (epoch 20.793), train_loss = 0.89310310, grad/param norm = 2.4514e-01, time/batch = 17.6269s	
6925/16650 (epoch 20.796), train_loss = 1.32333440, grad/param norm = 2.9837e-01, time/batch = 17.0371s	
6926/16650 (epoch 20.799), train_loss = 1.21602693, grad/param norm = 2.6814e-01, time/batch = 17.7182s	
6927/16650 (epoch 20.802), train_loss = 1.05638433, grad/param norm = 2.5282e-01, time/batch = 15.4189s	
6928/16650 (epoch 20.805), train_loss = 1.00177479, grad/param norm = 2.4258e-01, time/batch = 14.8224s	
6929/16650 (epoch 20.808), train_loss = 1.05103708, grad/param norm = 2.5700e-01, time/batch = 16.9298s	
6930/16650 (epoch 20.811), train_loss = 1.13465944, grad/param norm = 2.5486e-01, time/batch = 15.5228s	
6931/16650 (epoch 20.814), train_loss = 0.90162804, grad/param norm = 2.2209e-01, time/batch = 16.7895s	
6932/16650 (epoch 20.817), train_loss = 0.95675173, grad/param norm = 2.5439e-01, time/batch = 17.2877s	
6933/16650 (epoch 20.820), train_loss = 1.07687145, grad/param norm = 2.7302e-01, time/batch = 16.0962s	
6934/16650 (epoch 20.823), train_loss = 0.96232793, grad/param norm = 2.3329e-01, time/batch = 15.0920s	
6935/16650 (epoch 20.826), train_loss = 0.98672314, grad/param norm = 2.3493e-01, time/batch = 17.2773s	
6936/16650 (epoch 20.829), train_loss = 1.06858634, grad/param norm = 2.6910e-01, time/batch = 17.2076s	
6937/16650 (epoch 20.832), train_loss = 1.11692902, grad/param norm = 2.7455e-01, time/batch = 17.6292s	
6938/16650 (epoch 20.835), train_loss = 1.09574851, grad/param norm = 2.7984e-01, time/batch = 14.7185s	
6939/16650 (epoch 20.838), train_loss = 0.91326701, grad/param norm = 2.4030e-01, time/batch = 16.1968s	
6940/16650 (epoch 20.841), train_loss = 0.96009408, grad/param norm = 2.4220e-01, time/batch = 17.5345s	
6941/16650 (epoch 20.844), train_loss = 0.92782422, grad/param norm = 2.1997e-01, time/batch = 15.1055s	
6942/16650 (epoch 20.847), train_loss = 1.10618495, grad/param norm = 2.7262e-01, time/batch = 14.4011s	
6943/16650 (epoch 20.850), train_loss = 0.89697318, grad/param norm = 2.6315e-01, time/batch = 18.1135s	
6944/16650 (epoch 20.853), train_loss = 1.02692731, grad/param norm = 2.5810e-01, time/batch = 15.7738s	
6945/16650 (epoch 20.856), train_loss = 0.93492636, grad/param norm = 2.5772e-01, time/batch = 16.4484s	
6946/16650 (epoch 20.859), train_loss = 1.09509569, grad/param norm = 2.5011e-01, time/batch = 15.5321s	
6947/16650 (epoch 20.862), train_loss = 0.99495015, grad/param norm = 2.3015e-01, time/batch = 17.2941s	
6948/16650 (epoch 20.865), train_loss = 0.84329771, grad/param norm = 2.3538e-01, time/batch = 17.5391s	
6949/16650 (epoch 20.868), train_loss = 1.08233924, grad/param norm = 2.6249e-01, time/batch = 16.8408s	
6950/16650 (epoch 20.871), train_loss = 1.04067250, grad/param norm = 2.5262e-01, time/batch = 16.9384s	
6951/16650 (epoch 20.874), train_loss = 1.04502024, grad/param norm = 2.4936e-01, time/batch = 16.9690s	
6952/16650 (epoch 20.877), train_loss = 1.01004800, grad/param norm = 2.4074e-01, time/batch = 16.4435s	
6953/16650 (epoch 20.880), train_loss = 0.92093336, grad/param norm = 2.4066e-01, time/batch = 16.7092s	
6954/16650 (epoch 20.883), train_loss = 1.00257802, grad/param norm = 2.4882e-01, time/batch = 16.6045s	
6955/16650 (epoch 20.886), train_loss = 1.01020649, grad/param norm = 2.4044e-01, time/batch = 17.5546s	
6956/16650 (epoch 20.889), train_loss = 0.86421012, grad/param norm = 2.3553e-01, time/batch = 16.4951s	
6957/16650 (epoch 20.892), train_loss = 0.99720505, grad/param norm = 2.2494e-01, time/batch = 15.0790s	
6958/16650 (epoch 20.895), train_loss = 1.05043705, grad/param norm = 2.4921e-01, time/batch = 16.2837s	
6959/16650 (epoch 20.898), train_loss = 1.03219114, grad/param norm = 2.4961e-01, time/batch = 16.9433s	
6960/16650 (epoch 20.901), train_loss = 1.00329645, grad/param norm = 2.4998e-01, time/batch = 15.2703s	
6961/16650 (epoch 20.904), train_loss = 0.92655434, grad/param norm = 2.3810e-01, time/batch = 15.5149s	
6962/16650 (epoch 20.907), train_loss = 1.07154434, grad/param norm = 2.5811e-01, time/batch = 17.8789s	
6963/16650 (epoch 20.910), train_loss = 1.06017095, grad/param norm = 2.6648e-01, time/batch = 16.6220s	
6964/16650 (epoch 20.913), train_loss = 0.92937603, grad/param norm = 2.5078e-01, time/batch = 15.1874s	
6965/16650 (epoch 20.916), train_loss = 1.01052274, grad/param norm = 2.7053e-01, time/batch = 17.2747s	
6966/16650 (epoch 20.919), train_loss = 1.16258544, grad/param norm = 2.5716e-01, time/batch = 15.1153s	
6967/16650 (epoch 20.922), train_loss = 1.11117195, grad/param norm = 2.5784e-01, time/batch = 15.4086s	
6968/16650 (epoch 20.925), train_loss = 0.93509661, grad/param norm = 2.5771e-01, time/batch = 17.7149s	
6969/16650 (epoch 20.928), train_loss = 0.99568897, grad/param norm = 2.5594e-01, time/batch = 17.3699s	
6970/16650 (epoch 20.931), train_loss = 1.06857045, grad/param norm = 2.5747e-01, time/batch = 16.0967s	
6971/16650 (epoch 20.934), train_loss = 0.88896374, grad/param norm = 2.5261e-01, time/batch = 16.6121s	
6972/16650 (epoch 20.937), train_loss = 0.95029895, grad/param norm = 3.0168e-01, time/batch = 17.5249s	
6973/16650 (epoch 20.940), train_loss = 0.95781063, grad/param norm = 2.3052e-01, time/batch = 18.0603s	
6974/16650 (epoch 20.943), train_loss = 1.04634774, grad/param norm = 2.7797e-01, time/batch = 15.8344s	
6975/16650 (epoch 20.946), train_loss = 0.91267821, grad/param norm = 2.3183e-01, time/batch = 16.9596s	
6976/16650 (epoch 20.949), train_loss = 0.89794759, grad/param norm = 2.8476e-01, time/batch = 17.7870s	
6977/16650 (epoch 20.952), train_loss = 0.82974523, grad/param norm = 2.3195e-01, time/batch = 16.8534s	
6978/16650 (epoch 20.955), train_loss = 0.97925184, grad/param norm = 2.4702e-01, time/batch = 14.5552s	
6979/16650 (epoch 20.958), train_loss = 1.05864341, grad/param norm = 2.7991e-01, time/batch = 14.5018s	
6980/16650 (epoch 20.961), train_loss = 0.99213340, grad/param norm = 2.3680e-01, time/batch = 17.4508s	
6981/16650 (epoch 20.964), train_loss = 0.90827455, grad/param norm = 2.8284e-01, time/batch = 17.0991s	
6982/16650 (epoch 20.967), train_loss = 1.12596350, grad/param norm = 2.8167e-01, time/batch = 14.8169s	
6983/16650 (epoch 20.970), train_loss = 0.91898002, grad/param norm = 2.4326e-01, time/batch = 16.6743s	
6984/16650 (epoch 20.973), train_loss = 0.94970057, grad/param norm = 2.6351e-01, time/batch = 18.2059s	
6985/16650 (epoch 20.976), train_loss = 0.91556963, grad/param norm = 2.3377e-01, time/batch = 16.6650s	
6986/16650 (epoch 20.979), train_loss = 1.03007697, grad/param norm = 2.7366e-01, time/batch = 17.1222s	
6987/16650 (epoch 20.982), train_loss = 1.04989359, grad/param norm = 2.5167e-01, time/batch = 14.7703s	
6988/16650 (epoch 20.985), train_loss = 0.97762476, grad/param norm = 2.3592e-01, time/batch = 13.4035s	
6989/16650 (epoch 20.988), train_loss = 1.13698312, grad/param norm = 2.7641e-01, time/batch = 13.8144s	
6990/16650 (epoch 20.991), train_loss = 0.92538410, grad/param norm = 2.6407e-01, time/batch = 14.1741s	
6991/16650 (epoch 20.994), train_loss = 0.91875528, grad/param norm = 2.3102e-01, time/batch = 16.3697s	
6992/16650 (epoch 20.997), train_loss = 1.00152251, grad/param norm = 2.6785e-01, time/batch = 17.3495s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
6993/16650 (epoch 21.000), train_loss = 1.07234878, grad/param norm = 2.8968e-01, time/batch = 15.0122s	
6994/16650 (epoch 21.003), train_loss = 1.10807411, grad/param norm = 3.0579e-01, time/batch = 15.2448s	
6995/16650 (epoch 21.006), train_loss = 1.08180999, grad/param norm = 3.0715e-01, time/batch = 16.1648s	
6996/16650 (epoch 21.009), train_loss = 1.17325321, grad/param norm = 2.8291e-01, time/batch = 16.3538s	
6997/16650 (epoch 21.012), train_loss = 1.15579338, grad/param norm = 2.7418e-01, time/batch = 17.8629s	
6998/16650 (epoch 21.015), train_loss = 0.99910532, grad/param norm = 2.5172e-01, time/batch = 16.2068s	
6999/16650 (epoch 21.018), train_loss = 0.83759375, grad/param norm = 2.5982e-01, time/batch = 16.0061s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch21.02_1.8927.t7	
7000/16650 (epoch 21.021), train_loss = 1.12502004, grad/param norm = 2.6474e-01, time/batch = 15.8291s	
7001/16650 (epoch 21.024), train_loss = 1.42287580, grad/param norm = 3.1704e-01, time/batch = 17.7865s	
7002/16650 (epoch 21.027), train_loss = 1.08658447, grad/param norm = 2.6971e-01, time/batch = 17.4424s	
7003/16650 (epoch 21.030), train_loss = 0.89777075, grad/param norm = 2.5087e-01, time/batch = 16.4227s	
7004/16650 (epoch 21.033), train_loss = 1.02132670, grad/param norm = 2.3827e-01, time/batch = 17.2781s	
7005/16650 (epoch 21.036), train_loss = 0.79588277, grad/param norm = 2.9229e-01, time/batch = 16.1871s	
7006/16650 (epoch 21.039), train_loss = 1.10742726, grad/param norm = 2.5265e-01, time/batch = 15.7510s	
7007/16650 (epoch 21.042), train_loss = 1.09275673, grad/param norm = 2.6277e-01, time/batch = 16.3409s	
7008/16650 (epoch 21.045), train_loss = 0.97915833, grad/param norm = 2.5172e-01, time/batch = 15.9222s	
7009/16650 (epoch 21.048), train_loss = 1.10067057, grad/param norm = 2.8870e-01, time/batch = 16.8685s	
7010/16650 (epoch 21.051), train_loss = 0.98190790, grad/param norm = 2.4784e-01, time/batch = 16.0208s	
7011/16650 (epoch 21.054), train_loss = 1.01954375, grad/param norm = 2.6970e-01, time/batch = 17.7837s	
7012/16650 (epoch 21.057), train_loss = 1.02901390, grad/param norm = 2.8856e-01, time/batch = 17.6056s	
7013/16650 (epoch 21.060), train_loss = 0.86199200, grad/param norm = 2.3006e-01, time/batch = 17.2769s	
7014/16650 (epoch 21.063), train_loss = 0.99709835, grad/param norm = 2.6028e-01, time/batch = 16.1046s	
7015/16650 (epoch 21.066), train_loss = 1.17082377, grad/param norm = 2.8140e-01, time/batch = 16.6126s	
7016/16650 (epoch 21.069), train_loss = 1.08813722, grad/param norm = 2.7150e-01, time/batch = 16.9381s	
7017/16650 (epoch 21.072), train_loss = 0.97609769, grad/param norm = 2.5904e-01, time/batch = 15.8495s	
7018/16650 (epoch 21.075), train_loss = 1.06700147, grad/param norm = 2.3369e-01, time/batch = 16.5371s	
7019/16650 (epoch 21.078), train_loss = 1.13185327, grad/param norm = 2.5838e-01, time/batch = 16.5242s	
7020/16650 (epoch 21.081), train_loss = 1.01637981, grad/param norm = 2.6764e-01, time/batch = 15.0509s	
7021/16650 (epoch 21.084), train_loss = 1.06562532, grad/param norm = 2.4680e-01, time/batch = 16.0933s	
7022/16650 (epoch 21.087), train_loss = 1.00292542, grad/param norm = 2.6774e-01, time/batch = 16.4441s	
7023/16650 (epoch 21.090), train_loss = 1.00775118, grad/param norm = 2.4575e-01, time/batch = 16.7976s	
7024/16650 (epoch 21.093), train_loss = 1.22705629, grad/param norm = 2.9446e-01, time/batch = 17.1053s	
7025/16650 (epoch 21.096), train_loss = 0.96394289, grad/param norm = 2.7576e-01, time/batch = 17.0925s	
7026/16650 (epoch 21.099), train_loss = 1.01523845, grad/param norm = 2.4996e-01, time/batch = 14.0029s	
7027/16650 (epoch 21.102), train_loss = 1.04071408, grad/param norm = 2.5450e-01, time/batch = 15.6524s	
7028/16650 (epoch 21.105), train_loss = 1.06563556, grad/param norm = 2.5919e-01, time/batch = 16.5363s	
7029/16650 (epoch 21.108), train_loss = 1.05729241, grad/param norm = 2.6185e-01, time/batch = 17.4617s	
7030/16650 (epoch 21.111), train_loss = 1.11073776, grad/param norm = 2.4164e-01, time/batch = 16.0287s	
7031/16650 (epoch 21.114), train_loss = 1.12510218, grad/param norm = 2.7462e-01, time/batch = 15.8341s	
7032/16650 (epoch 21.117), train_loss = 1.19498218, grad/param norm = 2.8598e-01, time/batch = 16.1924s	
7033/16650 (epoch 21.120), train_loss = 0.93675949, grad/param norm = 2.2757e-01, time/batch = 17.1914s	
7034/16650 (epoch 21.123), train_loss = 0.99283328, grad/param norm = 2.4420e-01, time/batch = 15.9245s	
7035/16650 (epoch 21.126), train_loss = 1.03694553, grad/param norm = 2.3885e-01, time/batch = 17.2701s	
7036/16650 (epoch 21.129), train_loss = 1.04827000, grad/param norm = 2.6379e-01, time/batch = 16.9427s	
7037/16650 (epoch 21.132), train_loss = 1.01192181, grad/param norm = 2.4829e-01, time/batch = 16.8882s	
7038/16650 (epoch 21.135), train_loss = 1.09696916, grad/param norm = 2.4923e-01, time/batch = 16.7884s	
7039/16650 (epoch 21.138), train_loss = 1.08629981, grad/param norm = 2.4357e-01, time/batch = 16.0022s	
7040/16650 (epoch 21.141), train_loss = 1.08263302, grad/param norm = 2.8590e-01, time/batch = 16.6186s	
7041/16650 (epoch 21.144), train_loss = 1.02376658, grad/param norm = 2.6781e-01, time/batch = 17.2904s	
7042/16650 (epoch 21.147), train_loss = 1.16816152, grad/param norm = 2.4709e-01, time/batch = 17.1152s	
7043/16650 (epoch 21.150), train_loss = 1.25091980, grad/param norm = 2.9547e-01, time/batch = 14.8035s	
7044/16650 (epoch 21.153), train_loss = 1.08535776, grad/param norm = 3.4192e-01, time/batch = 17.0289s	
7045/16650 (epoch 21.156), train_loss = 0.93549638, grad/param norm = 2.2919e-01, time/batch = 17.2056s	
7046/16650 (epoch 21.159), train_loss = 1.10116663, grad/param norm = 2.7184e-01, time/batch = 15.9534s	
7047/16650 (epoch 21.162), train_loss = 1.14352906, grad/param norm = 2.6092e-01, time/batch = 16.2716s	
7048/16650 (epoch 21.165), train_loss = 1.15734195, grad/param norm = 2.8549e-01, time/batch = 17.3698s	
7049/16650 (epoch 21.168), train_loss = 0.86265663, grad/param norm = 2.1873e-01, time/batch = 17.5330s	
7050/16650 (epoch 21.171), train_loss = 1.12397299, grad/param norm = 2.4152e-01, time/batch = 15.5960s	
7051/16650 (epoch 21.174), train_loss = 0.86608474, grad/param norm = 2.3980e-01, time/batch = 14.0974s	
7052/16650 (epoch 21.177), train_loss = 1.00689881, grad/param norm = 2.5139e-01, time/batch = 16.3418s	
7053/16650 (epoch 21.180), train_loss = 1.14230284, grad/param norm = 2.4969e-01, time/batch = 17.0135s	
7054/16650 (epoch 21.183), train_loss = 1.27995281, grad/param norm = 2.9209e-01, time/batch = 17.0920s	
7055/16650 (epoch 21.186), train_loss = 1.11618000, grad/param norm = 2.8119e-01, time/batch = 16.1901s	
7056/16650 (epoch 21.189), train_loss = 0.93654833, grad/param norm = 2.3782e-01, time/batch = 17.2878s	
7057/16650 (epoch 21.192), train_loss = 0.97514527, grad/param norm = 2.6185e-01, time/batch = 16.1949s	
7058/16650 (epoch 21.195), train_loss = 0.98872348, grad/param norm = 2.7089e-01, time/batch = 16.5254s	
7059/16650 (epoch 21.198), train_loss = 0.84153829, grad/param norm = 1.9558e-01, time/batch = 17.5290s	
7060/16650 (epoch 21.201), train_loss = 0.98189157, grad/param norm = 2.9368e-01, time/batch = 17.6228s	
7061/16650 (epoch 21.204), train_loss = 1.02378311, grad/param norm = 2.4287e-01, time/batch = 17.5008s	
7062/16650 (epoch 21.207), train_loss = 1.05243185, grad/param norm = 2.8147e-01, time/batch = 17.7792s	
7063/16650 (epoch 21.210), train_loss = 0.99078586, grad/param norm = 2.5936e-01, time/batch = 17.2849s	
7064/16650 (epoch 21.213), train_loss = 1.10933556, grad/param norm = 2.6586e-01, time/batch = 15.7698s	
7065/16650 (epoch 21.216), train_loss = 0.98083398, grad/param norm = 2.3234e-01, time/batch = 14.1600s	
7066/16650 (epoch 21.219), train_loss = 1.02796461, grad/param norm = 2.7319e-01, time/batch = 17.7771s	
7067/16650 (epoch 21.222), train_loss = 1.04612085, grad/param norm = 2.4289e-01, time/batch = 17.6124s	
7068/16650 (epoch 21.225), train_loss = 1.03813485, grad/param norm = 2.6207e-01, time/batch = 16.5116s	
7069/16650 (epoch 21.228), train_loss = 0.91926027, grad/param norm = 2.3614e-01, time/batch = 15.5179s	
7070/16650 (epoch 21.231), train_loss = 1.00716929, grad/param norm = 2.5634e-01, time/batch = 15.2312s	
7071/16650 (epoch 21.234), train_loss = 1.20932314, grad/param norm = 2.7187e-01, time/batch = 16.7832s	
7072/16650 (epoch 21.237), train_loss = 1.08691655, grad/param norm = 2.9004e-01, time/batch = 17.0370s	
7073/16650 (epoch 21.240), train_loss = 1.06765650, grad/param norm = 2.5125e-01, time/batch = 16.7780s	
7074/16650 (epoch 21.243), train_loss = 1.01875896, grad/param norm = 2.7391e-01, time/batch = 16.7972s	
7075/16650 (epoch 21.246), train_loss = 1.15373618, grad/param norm = 2.7214e-01, time/batch = 16.5269s	
7076/16650 (epoch 21.249), train_loss = 0.90599704, grad/param norm = 2.2543e-01, time/batch = 15.8428s	
7077/16650 (epoch 21.252), train_loss = 0.98620472, grad/param norm = 2.3575e-01, time/batch = 16.0919s	
7078/16650 (epoch 21.255), train_loss = 1.10158732, grad/param norm = 2.6609e-01, time/batch = 17.4485s	
7079/16650 (epoch 21.258), train_loss = 1.14312755, grad/param norm = 2.6417e-01, time/batch = 16.2546s	
7080/16650 (epoch 21.261), train_loss = 1.02730714, grad/param norm = 2.3324e-01, time/batch = 16.7005s	
7081/16650 (epoch 21.264), train_loss = 0.98767845, grad/param norm = 2.5486e-01, time/batch = 17.7096s	
7082/16650 (epoch 21.267), train_loss = 1.00793707, grad/param norm = 2.8926e-01, time/batch = 16.9385s	
7083/16650 (epoch 21.270), train_loss = 1.03390607, grad/param norm = 2.4155e-01, time/batch = 16.6088s	
7084/16650 (epoch 21.273), train_loss = 1.14573415, grad/param norm = 2.4286e-01, time/batch = 17.3584s	
7085/16650 (epoch 21.276), train_loss = 1.05193671, grad/param norm = 2.5391e-01, time/batch = 17.2986s	
7086/16650 (epoch 21.279), train_loss = 1.01247311, grad/param norm = 2.3866e-01, time/batch = 15.6706s	
7087/16650 (epoch 21.282), train_loss = 0.92699839, grad/param norm = 2.2708e-01, time/batch = 15.3409s	
7088/16650 (epoch 21.285), train_loss = 0.92658720, grad/param norm = 2.2132e-01, time/batch = 16.9403s	
7089/16650 (epoch 21.288), train_loss = 0.96685704, grad/param norm = 2.9160e-01, time/batch = 15.9392s	
7090/16650 (epoch 21.291), train_loss = 0.79056487, grad/param norm = 2.1185e-01, time/batch = 16.9275s	
7091/16650 (epoch 21.294), train_loss = 0.90676942, grad/param norm = 2.1260e-01, time/batch = 17.7921s	
7092/16650 (epoch 21.297), train_loss = 0.98183083, grad/param norm = 2.2887e-01, time/batch = 16.7880s	
7093/16650 (epoch 21.300), train_loss = 0.79237271, grad/param norm = 2.1450e-01, time/batch = 15.8351s	
7094/16650 (epoch 21.303), train_loss = 0.87790896, grad/param norm = 2.2146e-01, time/batch = 16.5231s	
7095/16650 (epoch 21.306), train_loss = 1.09589131, grad/param norm = 2.4956e-01, time/batch = 18.2915s	
7096/16650 (epoch 21.309), train_loss = 1.10193484, grad/param norm = 2.5290e-01, time/batch = 15.5958s	
7097/16650 (epoch 21.312), train_loss = 0.92337490, grad/param norm = 2.8109e-01, time/batch = 16.6067s	
7098/16650 (epoch 21.315), train_loss = 0.71504814, grad/param norm = 1.9687e-01, time/batch = 14.2524s	
7099/16650 (epoch 21.318), train_loss = 0.82278826, grad/param norm = 2.2774e-01, time/batch = 16.7032s	
7100/16650 (epoch 21.321), train_loss = 1.14237802, grad/param norm = 2.5812e-01, time/batch = 17.0997s	
7101/16650 (epoch 21.324), train_loss = 0.93772577, grad/param norm = 2.5173e-01, time/batch = 17.7793s	
7102/16650 (epoch 21.327), train_loss = 1.07547093, grad/param norm = 2.7564e-01, time/batch = 17.4636s	
7103/16650 (epoch 21.330), train_loss = 1.06064522, grad/param norm = 2.7764e-01, time/batch = 16.9287s	
7104/16650 (epoch 21.333), train_loss = 1.06282162, grad/param norm = 2.6849e-01, time/batch = 17.0053s	
7105/16650 (epoch 21.336), train_loss = 0.90908488, grad/param norm = 2.6285e-01, time/batch = 17.2908s	
7106/16650 (epoch 21.339), train_loss = 0.98063551, grad/param norm = 2.4747e-01, time/batch = 14.9117s	
7107/16650 (epoch 21.342), train_loss = 0.93067563, grad/param norm = 2.5454e-01, time/batch = 15.4301s	
7108/16650 (epoch 21.345), train_loss = 0.86052433, grad/param norm = 2.1736e-01, time/batch = 16.5923s	
7109/16650 (epoch 21.348), train_loss = 1.02544352, grad/param norm = 2.7605e-01, time/batch = 17.7105s	
7110/16650 (epoch 21.351), train_loss = 1.06814035, grad/param norm = 2.5776e-01, time/batch = 16.7005s	
7111/16650 (epoch 21.354), train_loss = 1.08628356, grad/param norm = 2.8068e-01, time/batch = 16.2759s	
7112/16650 (epoch 21.357), train_loss = 1.05022118, grad/param norm = 2.6411e-01, time/batch = 17.6269s	
7113/16650 (epoch 21.360), train_loss = 1.05940283, grad/param norm = 2.7268e-01, time/batch = 16.3583s	
7114/16650 (epoch 21.363), train_loss = 1.12592659, grad/param norm = 2.7267e-01, time/batch = 15.0585s	
7115/16650 (epoch 21.366), train_loss = 1.18218028, grad/param norm = 2.7291e-01, time/batch = 17.1915s	
7116/16650 (epoch 21.369), train_loss = 1.01906093, grad/param norm = 2.4876e-01, time/batch = 15.5865s	
7117/16650 (epoch 21.372), train_loss = 1.01826281, grad/param norm = 2.3634e-01, time/batch = 16.8659s	
7118/16650 (epoch 21.375), train_loss = 1.03567079, grad/param norm = 2.2814e-01, time/batch = 15.8393s	
7119/16650 (epoch 21.378), train_loss = 0.92746157, grad/param norm = 2.2748e-01, time/batch = 16.6924s	
7120/16650 (epoch 21.381), train_loss = 1.02712201, grad/param norm = 2.2639e-01, time/batch = 16.9537s	
7121/16650 (epoch 21.384), train_loss = 1.18142728, grad/param norm = 2.8286e-01, time/batch = 17.9555s	
7122/16650 (epoch 21.387), train_loss = 0.80206872, grad/param norm = 2.0952e-01, time/batch = 15.8442s	
7123/16650 (epoch 21.390), train_loss = 1.10181682, grad/param norm = 2.4299e-01, time/batch = 17.6277s	
7124/16650 (epoch 21.393), train_loss = 0.96932532, grad/param norm = 2.7247e-01, time/batch = 17.7879s	
7125/16650 (epoch 21.396), train_loss = 1.14613808, grad/param norm = 2.9514e-01, time/batch = 15.0823s	
7126/16650 (epoch 21.399), train_loss = 1.06039729, grad/param norm = 2.6748e-01, time/batch = 16.0318s	
7127/16650 (epoch 21.402), train_loss = 0.92720939, grad/param norm = 2.3250e-01, time/batch = 17.6263s	
7128/16650 (epoch 21.405), train_loss = 0.85752966, grad/param norm = 2.8591e-01, time/batch = 17.2960s	
7129/16650 (epoch 21.408), train_loss = 1.07260667, grad/param norm = 3.0213e-01, time/batch = 15.5931s	
7130/16650 (epoch 21.411), train_loss = 0.92027595, grad/param norm = 2.8724e-01, time/batch = 17.4346s	
7131/16650 (epoch 21.414), train_loss = 0.93362046, grad/param norm = 3.0528e-01, time/batch = 18.3771s	
7132/16650 (epoch 21.417), train_loss = 0.87622437, grad/param norm = 2.4514e-01, time/batch = 21.8039s	
7133/16650 (epoch 21.420), train_loss = 0.87879418, grad/param norm = 2.5265e-01, time/batch = 25.1688s	
7134/16650 (epoch 21.423), train_loss = 0.76493960, grad/param norm = 2.2396e-01, time/batch = 17.1003s	
7135/16650 (epoch 21.426), train_loss = 0.88638092, grad/param norm = 2.5729e-01, time/batch = 14.3847s	
7136/16650 (epoch 21.429), train_loss = 1.10782571, grad/param norm = 2.5662e-01, time/batch = 17.5201s	
7137/16650 (epoch 21.432), train_loss = 1.08337011, grad/param norm = 2.7228e-01, time/batch = 17.8700s	
7138/16650 (epoch 21.435), train_loss = 1.19570752, grad/param norm = 2.5922e-01, time/batch = 17.4562s	
7139/16650 (epoch 21.438), train_loss = 1.19233455, grad/param norm = 3.1289e-01, time/batch = 14.4824s	
7140/16650 (epoch 21.441), train_loss = 1.04037918, grad/param norm = 3.1581e-01, time/batch = 17.5353s	
7141/16650 (epoch 21.444), train_loss = 0.92941874, grad/param norm = 2.6417e-01, time/batch = 16.0999s	
7142/16650 (epoch 21.447), train_loss = 0.97654217, grad/param norm = 2.5996e-01, time/batch = 15.9329s	
7143/16650 (epoch 21.450), train_loss = 0.94167019, grad/param norm = 2.4640e-01, time/batch = 16.3456s	
7144/16650 (epoch 21.453), train_loss = 0.95596366, grad/param norm = 2.8565e-01, time/batch = 16.7900s	
7145/16650 (epoch 21.456), train_loss = 0.86541435, grad/param norm = 2.2427e-01, time/batch = 17.0430s	
7146/16650 (epoch 21.459), train_loss = 0.93478699, grad/param norm = 2.4744e-01, time/batch = 16.0207s	
7147/16650 (epoch 21.462), train_loss = 1.14081534, grad/param norm = 2.9902e-01, time/batch = 17.4363s	
7148/16650 (epoch 21.465), train_loss = 0.94042158, grad/param norm = 3.5667e-01, time/batch = 16.8819s	
7149/16650 (epoch 21.468), train_loss = 0.78354323, grad/param norm = 2.3479e-01, time/batch = 16.5241s	
7150/16650 (epoch 21.471), train_loss = 0.65206062, grad/param norm = 1.9380e-01, time/batch = 16.8524s	
7151/16650 (epoch 21.474), train_loss = 0.85652911, grad/param norm = 2.2951e-01, time/batch = 17.4658s	
7152/16650 (epoch 21.477), train_loss = 1.04363562, grad/param norm = 2.6444e-01, time/batch = 15.4429s	
7153/16650 (epoch 21.480), train_loss = 1.07023939, grad/param norm = 3.0437e-01, time/batch = 14.5596s	
7154/16650 (epoch 21.483), train_loss = 1.13625751, grad/param norm = 2.7278e-01, time/batch = 17.3378s	
7155/16650 (epoch 21.486), train_loss = 0.90466972, grad/param norm = 2.2709e-01, time/batch = 17.1121s	
7156/16650 (epoch 21.489), train_loss = 0.94846194, grad/param norm = 2.4312e-01, time/batch = 17.5364s	
7157/16650 (epoch 21.492), train_loss = 0.98031075, grad/param norm = 2.2666e-01, time/batch = 16.1796s	
7158/16650 (epoch 21.495), train_loss = 0.88455205, grad/param norm = 2.5471e-01, time/batch = 17.3781s	
7159/16650 (epoch 21.498), train_loss = 0.95482068, grad/param norm = 2.4820e-01, time/batch = 17.4565s	
7160/16650 (epoch 21.502), train_loss = 1.14482485, grad/param norm = 2.8176e-01, time/batch = 15.7514s	
7161/16650 (epoch 21.505), train_loss = 1.05412487, grad/param norm = 2.4381e-01, time/batch = 17.1093s	
7162/16650 (epoch 21.508), train_loss = 1.03787563, grad/param norm = 2.8731e-01, time/batch = 18.2087s	
7163/16650 (epoch 21.511), train_loss = 1.13894820, grad/param norm = 2.7077e-01, time/batch = 16.9569s	
7164/16650 (epoch 21.514), train_loss = 0.84737265, grad/param norm = 2.4290e-01, time/batch = 15.8362s	
7165/16650 (epoch 21.517), train_loss = 0.98461242, grad/param norm = 2.7224e-01, time/batch = 17.3636s	
7166/16650 (epoch 21.520), train_loss = 0.90932816, grad/param norm = 2.3787e-01, time/batch = 17.6292s	
7167/16650 (epoch 21.523), train_loss = 0.94378862, grad/param norm = 2.3453e-01, time/batch = 16.5140s	
7168/16650 (epoch 21.526), train_loss = 1.08719043, grad/param norm = 2.6932e-01, time/batch = 16.8595s	
7169/16650 (epoch 21.529), train_loss = 1.14257811, grad/param norm = 2.8281e-01, time/batch = 16.5346s	
7170/16650 (epoch 21.532), train_loss = 0.76146423, grad/param norm = 2.2318e-01, time/batch = 15.0809s	
7171/16650 (epoch 21.535), train_loss = 0.85004456, grad/param norm = 2.6561e-01, time/batch = 16.0118s	
7172/16650 (epoch 21.538), train_loss = 0.83962449, grad/param norm = 2.3202e-01, time/batch = 18.3681s	
7173/16650 (epoch 21.541), train_loss = 1.12309076, grad/param norm = 2.5753e-01, time/batch = 16.6999s	
7174/16650 (epoch 21.544), train_loss = 1.16500813, grad/param norm = 2.8724e-01, time/batch = 15.6584s	
7175/16650 (epoch 21.547), train_loss = 0.87231130, grad/param norm = 2.4489e-01, time/batch = 17.1259s	
7176/16650 (epoch 21.550), train_loss = 0.95129981, grad/param norm = 2.5197e-01, time/batch = 17.7038s	
7177/16650 (epoch 21.553), train_loss = 0.97165361, grad/param norm = 2.7342e-01, time/batch = 16.6122s	
7178/16650 (epoch 21.556), train_loss = 0.91064727, grad/param norm = 2.3914e-01, time/batch = 14.9862s	
7179/16650 (epoch 21.559), train_loss = 0.79675900, grad/param norm = 2.2805e-01, time/batch = 17.0294s	
7180/16650 (epoch 21.562), train_loss = 0.93570750, grad/param norm = 2.6117e-01, time/batch = 17.5362s	
7181/16650 (epoch 21.565), train_loss = 0.78450969, grad/param norm = 2.3741e-01, time/batch = 16.5942s	
7182/16650 (epoch 21.568), train_loss = 0.77847515, grad/param norm = 2.1068e-01, time/batch = 17.0284s	
7183/16650 (epoch 21.571), train_loss = 0.82609915, grad/param norm = 2.6026e-01, time/batch = 16.7866s	
7184/16650 (epoch 21.574), train_loss = 0.95537628, grad/param norm = 2.5995e-01, time/batch = 17.8665s	
7185/16650 (epoch 21.577), train_loss = 0.92281616, grad/param norm = 2.4336e-01, time/batch = 16.2595s	
7186/16650 (epoch 21.580), train_loss = 0.80913624, grad/param norm = 2.2312e-01, time/batch = 15.9902s	
7187/16650 (epoch 21.583), train_loss = 0.94281232, grad/param norm = 2.4280e-01, time/batch = 17.1160s	
7188/16650 (epoch 21.586), train_loss = 0.87241306, grad/param norm = 2.6811e-01, time/batch = 17.5470s	
7189/16650 (epoch 21.589), train_loss = 0.83961607, grad/param norm = 2.2384e-01, time/batch = 16.1668s	
7190/16650 (epoch 21.592), train_loss = 0.97123602, grad/param norm = 2.5785e-01, time/batch = 18.5361s	
7191/16650 (epoch 21.595), train_loss = 0.89613219, grad/param norm = 2.5476e-01, time/batch = 18.7841s	
7192/16650 (epoch 21.598), train_loss = 0.94315602, grad/param norm = 2.6349e-01, time/batch = 16.7624s	
7193/16650 (epoch 21.601), train_loss = 0.89677084, grad/param norm = 3.0062e-01, time/batch = 16.9476s	
7194/16650 (epoch 21.604), train_loss = 1.05937201, grad/param norm = 2.6798e-01, time/batch = 16.1739s	
7195/16650 (epoch 21.607), train_loss = 1.01340754, grad/param norm = 2.4240e-01, time/batch = 17.1427s	
7196/16650 (epoch 21.610), train_loss = 0.87058895, grad/param norm = 2.3624e-01, time/batch = 16.5125s	
7197/16650 (epoch 21.613), train_loss = 1.11785946, grad/param norm = 2.7093e-01, time/batch = 18.0985s	
7198/16650 (epoch 21.616), train_loss = 1.11363413, grad/param norm = 3.3464e-01, time/batch = 17.6021s	
7199/16650 (epoch 21.619), train_loss = 0.80425759, grad/param norm = 2.1352e-01, time/batch = 15.1498s	
7200/16650 (epoch 21.622), train_loss = 0.78640018, grad/param norm = 2.2672e-01, time/batch = 16.2703s	
7201/16650 (epoch 21.625), train_loss = 0.89798260, grad/param norm = 2.3824e-01, time/batch = 17.2853s	
7202/16650 (epoch 21.628), train_loss = 0.91885591, grad/param norm = 2.8075e-01, time/batch = 16.7090s	
7203/16650 (epoch 21.631), train_loss = 0.98269008, grad/param norm = 2.8671e-01, time/batch = 15.7357s	
7204/16650 (epoch 21.634), train_loss = 1.17949043, grad/param norm = 3.0969e-01, time/batch = 16.7739s	
7205/16650 (epoch 21.637), train_loss = 1.15410589, grad/param norm = 2.5727e-01, time/batch = 17.2708s	
7206/16650 (epoch 21.640), train_loss = 0.89917264, grad/param norm = 2.4931e-01, time/batch = 16.3420s	
7207/16650 (epoch 21.643), train_loss = 1.03284125, grad/param norm = 2.4364e-01, time/batch = 17.5310s	
7208/16650 (epoch 21.646), train_loss = 1.04049803, grad/param norm = 2.6867e-01, time/batch = 17.1205s	
7209/16650 (epoch 21.649), train_loss = 0.98987547, grad/param norm = 2.8390e-01, time/batch = 17.8804s	
7210/16650 (epoch 21.652), train_loss = 1.06830329, grad/param norm = 2.5547e-01, time/batch = 16.7570s	
7211/16650 (epoch 21.655), train_loss = 1.02540118, grad/param norm = 2.6515e-01, time/batch = 15.5777s	
7212/16650 (epoch 21.658), train_loss = 0.87465034, grad/param norm = 2.9677e-01, time/batch = 15.5477s	
7213/16650 (epoch 21.661), train_loss = 1.03080748, grad/param norm = 2.6946e-01, time/batch = 16.5192s	
7214/16650 (epoch 21.664), train_loss = 0.97691397, grad/param norm = 2.5790e-01, time/batch = 14.9212s	
7215/16650 (epoch 21.667), train_loss = 1.09848463, grad/param norm = 2.5944e-01, time/batch = 17.9620s	
7216/16650 (epoch 21.670), train_loss = 0.83550543, grad/param norm = 2.3965e-01, time/batch = 17.2034s	
7217/16650 (epoch 21.673), train_loss = 0.90554648, grad/param norm = 2.3361e-01, time/batch = 15.4362s	
7218/16650 (epoch 21.676), train_loss = 0.98883698, grad/param norm = 2.7927e-01, time/batch = 15.7599s	
7219/16650 (epoch 21.679), train_loss = 0.86644594, grad/param norm = 2.4359e-01, time/batch = 16.7844s	
7220/16650 (epoch 21.682), train_loss = 0.98462911, grad/param norm = 2.4437e-01, time/batch = 13.8528s	
7221/16650 (epoch 21.685), train_loss = 0.83278650, grad/param norm = 2.5268e-01, time/batch = 14.5609s	
7222/16650 (epoch 21.688), train_loss = 1.03252503, grad/param norm = 2.4907e-01, time/batch = 13.6944s	
7223/16650 (epoch 21.691), train_loss = 1.02396283, grad/param norm = 2.5222e-01, time/batch = 13.9958s	
7224/16650 (epoch 21.694), train_loss = 0.85764875, grad/param norm = 2.2330e-01, time/batch = 17.1869s	
7225/16650 (epoch 21.697), train_loss = 0.83774347, grad/param norm = 2.3473e-01, time/batch = 16.0895s	
7226/16650 (epoch 21.700), train_loss = 1.07464791, grad/param norm = 2.7790e-01, time/batch = 16.6051s	
7227/16650 (epoch 21.703), train_loss = 0.86072147, grad/param norm = 2.4842e-01, time/batch = 17.6242s	
7228/16650 (epoch 21.706), train_loss = 0.98005747, grad/param norm = 2.5199e-01, time/batch = 16.3756s	
7229/16650 (epoch 21.709), train_loss = 0.87335800, grad/param norm = 2.3134e-01, time/batch = 15.0833s	
7230/16650 (epoch 21.712), train_loss = 0.90135852, grad/param norm = 2.6967e-01, time/batch = 15.0411s	
7231/16650 (epoch 21.715), train_loss = 1.05992207, grad/param norm = 2.5961e-01, time/batch = 18.0442s	
7232/16650 (epoch 21.718), train_loss = 1.09362169, grad/param norm = 2.6019e-01, time/batch = 15.5210s	
7233/16650 (epoch 21.721), train_loss = 1.06928348, grad/param norm = 2.5958e-01, time/batch = 16.1970s	
7234/16650 (epoch 21.724), train_loss = 1.07234886, grad/param norm = 2.7478e-01, time/batch = 17.5427s	
7235/16650 (epoch 21.727), train_loss = 1.04642263, grad/param norm = 2.6702e-01, time/batch = 16.7916s	
7236/16650 (epoch 21.730), train_loss = 0.93522602, grad/param norm = 2.4761e-01, time/batch = 16.2448s	
7237/16650 (epoch 21.733), train_loss = 1.07885793, grad/param norm = 2.6848e-01, time/batch = 17.2916s	
7238/16650 (epoch 21.736), train_loss = 0.81919357, grad/param norm = 2.2563e-01, time/batch = 17.2823s	
7239/16650 (epoch 21.739), train_loss = 0.96324513, grad/param norm = 2.4074e-01, time/batch = 16.0680s	
7240/16650 (epoch 21.742), train_loss = 0.97126624, grad/param norm = 2.6604e-01, time/batch = 17.1863s	
7241/16650 (epoch 21.745), train_loss = 0.79548332, grad/param norm = 2.3131e-01, time/batch = 17.2042s	
7242/16650 (epoch 21.748), train_loss = 0.84131768, grad/param norm = 2.5460e-01, time/batch = 15.5838s	
7243/16650 (epoch 21.751), train_loss = 1.01004923, grad/param norm = 3.2829e-01, time/batch = 16.6995s	
7244/16650 (epoch 21.754), train_loss = 1.16341837, grad/param norm = 2.8884e-01, time/batch = 16.7129s	
7245/16650 (epoch 21.757), train_loss = 1.12657852, grad/param norm = 2.8418e-01, time/batch = 17.2040s	
7246/16650 (epoch 21.760), train_loss = 0.96288191, grad/param norm = 2.4832e-01, time/batch = 16.6122s	
7247/16650 (epoch 21.763), train_loss = 0.88553044, grad/param norm = 2.3456e-01, time/batch = 17.1250s	
7248/16650 (epoch 21.766), train_loss = 0.95820111, grad/param norm = 2.4133e-01, time/batch = 16.9382s	
7249/16650 (epoch 21.769), train_loss = 1.01674593, grad/param norm = 2.7343e-01, time/batch = 17.1228s	
7250/16650 (epoch 21.772), train_loss = 0.92958591, grad/param norm = 2.1879e-01, time/batch = 14.5867s	
7251/16650 (epoch 21.775), train_loss = 0.94903923, grad/param norm = 2.4264e-01, time/batch = 16.0998s	
7252/16650 (epoch 21.778), train_loss = 0.98329791, grad/param norm = 2.3944e-01, time/batch = 16.7758s	
7253/16650 (epoch 21.781), train_loss = 1.09165266, grad/param norm = 2.3184e-01, time/batch = 16.6206s	
7254/16650 (epoch 21.784), train_loss = 1.04363599, grad/param norm = 2.5871e-01, time/batch = 17.0020s	
7255/16650 (epoch 21.787), train_loss = 1.04097499, grad/param norm = 2.3070e-01, time/batch = 17.2948s	
7256/16650 (epoch 21.790), train_loss = 0.99920784, grad/param norm = 2.2098e-01, time/batch = 15.0973s	
7257/16650 (epoch 21.793), train_loss = 0.87618769, grad/param norm = 2.4149e-01, time/batch = 15.6528s	
7258/16650 (epoch 21.796), train_loss = 1.29696070, grad/param norm = 2.9513e-01, time/batch = 16.3238s	
7259/16650 (epoch 21.799), train_loss = 1.18828671, grad/param norm = 2.7868e-01, time/batch = 17.0382s	
7260/16650 (epoch 21.802), train_loss = 1.03440872, grad/param norm = 2.5671e-01, time/batch = 18.2873s	
7261/16650 (epoch 21.805), train_loss = 0.97522387, grad/param norm = 2.4358e-01, time/batch = 15.6741s	
7262/16650 (epoch 21.808), train_loss = 1.03534648, grad/param norm = 2.5185e-01, time/batch = 17.3602s	
7263/16650 (epoch 21.811), train_loss = 1.10341970, grad/param norm = 2.6452e-01, time/batch = 17.5301s	
7264/16650 (epoch 21.814), train_loss = 0.87835152, grad/param norm = 2.2701e-01, time/batch = 16.6216s	
7265/16650 (epoch 21.817), train_loss = 0.93290824, grad/param norm = 2.4120e-01, time/batch = 16.9374s	
7266/16650 (epoch 21.820), train_loss = 1.03984322, grad/param norm = 2.6290e-01, time/batch = 15.4254s	
7267/16650 (epoch 21.823), train_loss = 0.94906878, grad/param norm = 2.4617e-01, time/batch = 17.0995s	
7268/16650 (epoch 21.826), train_loss = 0.95484200, grad/param norm = 2.2916e-01, time/batch = 15.8509s	
7269/16650 (epoch 21.829), train_loss = 1.03476038, grad/param norm = 2.5063e-01, time/batch = 16.7132s	
7270/16650 (epoch 21.832), train_loss = 1.08591761, grad/param norm = 2.7463e-01, time/batch = 16.4344s	
7271/16650 (epoch 21.835), train_loss = 1.06528791, grad/param norm = 2.8071e-01, time/batch = 15.2273s	
7272/16650 (epoch 21.838), train_loss = 0.90119807, grad/param norm = 2.5815e-01, time/batch = 15.8301s	
7273/16650 (epoch 21.841), train_loss = 0.93467981, grad/param norm = 2.4479e-01, time/batch = 17.2767s	
7274/16650 (epoch 21.844), train_loss = 0.91455961, grad/param norm = 2.2326e-01, time/batch = 17.2806s	
7275/16650 (epoch 21.847), train_loss = 1.07431326, grad/param norm = 2.5957e-01, time/batch = 15.8484s	
7276/16650 (epoch 21.850), train_loss = 0.87107543, grad/param norm = 2.5061e-01, time/batch = 14.9899s	
7277/16650 (epoch 21.853), train_loss = 0.99654942, grad/param norm = 2.5121e-01, time/batch = 17.3603s	
7278/16650 (epoch 21.856), train_loss = 0.91540074, grad/param norm = 2.4918e-01, time/batch = 16.5359s	
7279/16650 (epoch 21.859), train_loss = 1.07057536, grad/param norm = 2.6701e-01, time/batch = 15.6769s	
7280/16650 (epoch 21.862), train_loss = 0.98400182, grad/param norm = 2.5037e-01, time/batch = 18.1365s	
7281/16650 (epoch 21.865), train_loss = 0.81837858, grad/param norm = 2.2328e-01, time/batch = 17.2042s	
7282/16650 (epoch 21.868), train_loss = 1.05533495, grad/param norm = 2.6120e-01, time/batch = 16.0199s	
7283/16650 (epoch 21.871), train_loss = 1.01843329, grad/param norm = 2.5063e-01, time/batch = 17.0121s	
7284/16650 (epoch 21.874), train_loss = 1.00535329, grad/param norm = 2.3962e-01, time/batch = 17.2927s	
7285/16650 (epoch 21.877), train_loss = 0.99669249, grad/param norm = 2.5236e-01, time/batch = 17.7077s	
7286/16650 (epoch 21.880), train_loss = 0.88704558, grad/param norm = 2.3512e-01, time/batch = 14.8964s	
7287/16650 (epoch 21.883), train_loss = 0.98050561, grad/param norm = 2.4642e-01, time/batch = 17.6983s	
7288/16650 (epoch 21.886), train_loss = 0.99196427, grad/param norm = 2.4612e-01, time/batch = 16.1046s	
7289/16650 (epoch 21.889), train_loss = 0.84920790, grad/param norm = 2.5304e-01, time/batch = 14.3313s	
7290/16650 (epoch 21.892), train_loss = 0.96785513, grad/param norm = 2.2109e-01, time/batch = 15.6787s	
7291/16650 (epoch 21.895), train_loss = 1.01942613, grad/param norm = 2.4509e-01, time/batch = 18.1222s	
7292/16650 (epoch 21.898), train_loss = 1.00440788, grad/param norm = 2.6424e-01, time/batch = 17.5531s	
7293/16650 (epoch 21.901), train_loss = 0.97600166, grad/param norm = 2.4831e-01, time/batch = 15.5984s	
7294/16650 (epoch 21.904), train_loss = 0.90954679, grad/param norm = 2.4726e-01, time/batch = 16.4516s	
7295/16650 (epoch 21.907), train_loss = 1.03647836, grad/param norm = 2.5454e-01, time/batch = 16.1108s	
7296/16650 (epoch 21.910), train_loss = 1.04245710, grad/param norm = 2.7165e-01, time/batch = 17.6000s	
7297/16650 (epoch 21.913), train_loss = 0.90252533, grad/param norm = 2.5129e-01, time/batch = 15.8638s	
7298/16650 (epoch 21.916), train_loss = 0.98208104, grad/param norm = 2.6279e-01, time/batch = 16.7976s	
7299/16650 (epoch 21.919), train_loss = 1.14034376, grad/param norm = 2.6626e-01, time/batch = 17.0389s	
7300/16650 (epoch 21.922), train_loss = 1.07974579, grad/param norm = 2.6676e-01, time/batch = 16.2780s	
7301/16650 (epoch 21.925), train_loss = 0.92857481, grad/param norm = 2.7157e-01, time/batch = 17.1061s	
7302/16650 (epoch 21.928), train_loss = 0.97504085, grad/param norm = 2.5753e-01, time/batch = 16.5134s	
7303/16650 (epoch 21.931), train_loss = 1.04503422, grad/param norm = 2.5262e-01, time/batch = 14.4042s	
7304/16650 (epoch 21.934), train_loss = 0.87250634, grad/param norm = 2.7341e-01, time/batch = 15.6769s	
7305/16650 (epoch 21.937), train_loss = 0.90669410, grad/param norm = 2.6159e-01, time/batch = 16.6011s	
7306/16650 (epoch 21.940), train_loss = 0.93514867, grad/param norm = 2.2531e-01, time/batch = 15.1026s	
7307/16650 (epoch 21.943), train_loss = 1.00779468, grad/param norm = 2.4213e-01, time/batch = 16.8532s	
7308/16650 (epoch 21.946), train_loss = 0.90173530, grad/param norm = 2.9225e-01, time/batch = 16.0191s	
7309/16650 (epoch 21.949), train_loss = 0.90028220, grad/param norm = 3.2280e-01, time/batch = 15.6133s	
7310/16650 (epoch 21.952), train_loss = 0.82849260, grad/param norm = 2.7520e-01, time/batch = 17.6271s	
7311/16650 (epoch 21.955), train_loss = 0.96576381, grad/param norm = 2.3821e-01, time/batch = 17.4190s	
7312/16650 (epoch 21.958), train_loss = 1.05553409, grad/param norm = 4.7513e-01, time/batch = 16.6000s	
7313/16650 (epoch 21.961), train_loss = 0.97778230, grad/param norm = 2.5267e-01, time/batch = 17.3505s	
7314/16650 (epoch 21.964), train_loss = 0.90051797, grad/param norm = 2.6926e-01, time/batch = 17.4532s	
7315/16650 (epoch 21.967), train_loss = 1.11074843, grad/param norm = 3.2791e-01, time/batch = 15.0871s	
7316/16650 (epoch 21.970), train_loss = 0.91568082, grad/param norm = 2.6672e-01, time/batch = 16.2392s	
7317/16650 (epoch 21.973), train_loss = 0.95443419, grad/param norm = 3.0994e-01, time/batch = 16.7882s	
7318/16650 (epoch 21.976), train_loss = 0.90834381, grad/param norm = 2.6312e-01, time/batch = 16.3591s	
7319/16650 (epoch 21.979), train_loss = 1.01360015, grad/param norm = 3.2137e-01, time/batch = 16.1518s	
7320/16650 (epoch 21.982), train_loss = 1.02556140, grad/param norm = 2.5558e-01, time/batch = 17.0396s	
7321/16650 (epoch 21.985), train_loss = 0.96053411, grad/param norm = 2.5931e-01, time/batch = 17.6282s	
7322/16650 (epoch 21.988), train_loss = 1.10762224, grad/param norm = 2.7905e-01, time/batch = 17.0227s	
7323/16650 (epoch 21.991), train_loss = 0.90528751, grad/param norm = 2.6872e-01, time/batch = 15.7743s	
7324/16650 (epoch 21.994), train_loss = 0.90034080, grad/param norm = 2.3256e-01, time/batch = 17.5422s	
7325/16650 (epoch 21.997), train_loss = 0.98959131, grad/param norm = 2.6800e-01, time/batch = 15.8590s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
7326/16650 (epoch 22.000), train_loss = 1.04972254, grad/param norm = 3.0833e-01, time/batch = 14.2493s	
7327/16650 (epoch 22.003), train_loss = 1.09282772, grad/param norm = 3.2749e-01, time/batch = 17.2636s	
7328/16650 (epoch 22.006), train_loss = 1.04818205, grad/param norm = 2.7954e-01, time/batch = 17.1964s	
7329/16650 (epoch 22.009), train_loss = 1.14334353, grad/param norm = 2.6406e-01, time/batch = 16.6844s	
7330/16650 (epoch 22.012), train_loss = 1.12879631, grad/param norm = 2.7639e-01, time/batch = 16.9300s	
7331/16650 (epoch 22.015), train_loss = 0.97828203, grad/param norm = 2.7397e-01, time/batch = 17.8879s	
7332/16650 (epoch 22.018), train_loss = 0.82424801, grad/param norm = 2.4582e-01, time/batch = 16.9646s	
7333/16650 (epoch 22.021), train_loss = 1.11623083, grad/param norm = 2.9974e-01, time/batch = 14.8462s	
7334/16650 (epoch 22.024), train_loss = 0.99124737, grad/param norm = 2.6075e-01, time/batch = 16.7826s	
7335/16650 (epoch 22.027), train_loss = 1.07289914, grad/param norm = 3.0513e-01, time/batch = 17.0313s	
7336/16650 (epoch 22.030), train_loss = 0.86362058, grad/param norm = 2.4077e-01, time/batch = 15.6610s	
7337/16650 (epoch 22.033), train_loss = 0.99412547, grad/param norm = 2.4686e-01, time/batch = 16.3445s	
7338/16650 (epoch 22.036), train_loss = 0.77784737, grad/param norm = 2.8083e-01, time/batch = 17.0206s	
7339/16650 (epoch 22.039), train_loss = 1.08194802, grad/param norm = 2.5071e-01, time/batch = 15.3359s	
7340/16650 (epoch 22.042), train_loss = 1.07070529, grad/param norm = 2.6219e-01, time/batch = 16.9268s	
7341/16650 (epoch 22.045), train_loss = 0.94030692, grad/param norm = 2.4820e-01, time/batch = 17.1201s	
7342/16650 (epoch 22.048), train_loss = 1.07426794, grad/param norm = 2.8283e-01, time/batch = 16.4385s	
7343/16650 (epoch 22.051), train_loss = 0.95141868, grad/param norm = 2.5292e-01, time/batch = 16.7307s	
7344/16650 (epoch 22.054), train_loss = 0.98078911, grad/param norm = 2.6265e-01, time/batch = 16.0860s	
7345/16650 (epoch 22.057), train_loss = 0.99690030, grad/param norm = 2.4963e-01, time/batch = 17.4236s	
7346/16650 (epoch 22.060), train_loss = 0.84355705, grad/param norm = 2.2062e-01, time/batch = 19.1906s	
7347/16650 (epoch 22.063), train_loss = 0.95892655, grad/param norm = 2.5136e-01, time/batch = 19.5001s	
7348/16650 (epoch 22.066), train_loss = 1.15162039, grad/param norm = 2.8893e-01, time/batch = 27.0481s	
7349/16650 (epoch 22.069), train_loss = 1.06347093, grad/param norm = 2.8290e-01, time/batch = 17.4162s	
7350/16650 (epoch 22.072), train_loss = 0.95760879, grad/param norm = 2.6347e-01, time/batch = 15.8112s	
7351/16650 (epoch 22.075), train_loss = 1.05067442, grad/param norm = 2.3587e-01, time/batch = 18.6155s	
7352/16650 (epoch 22.078), train_loss = 1.11250621, grad/param norm = 2.6499e-01, time/batch = 17.0184s	
7353/16650 (epoch 22.081), train_loss = 1.00232202, grad/param norm = 3.0688e-01, time/batch = 17.8206s	
7354/16650 (epoch 22.084), train_loss = 1.05645266, grad/param norm = 2.6904e-01, time/batch = 15.8524s	
7355/16650 (epoch 22.087), train_loss = 0.98055052, grad/param norm = 2.6226e-01, time/batch = 18.3640s	
7356/16650 (epoch 22.090), train_loss = 0.98091682, grad/param norm = 2.4143e-01, time/batch = 18.1923s	
7357/16650 (epoch 22.093), train_loss = 1.20394058, grad/param norm = 2.9909e-01, time/batch = 16.7581s	
7358/16650 (epoch 22.096), train_loss = 0.94188852, grad/param norm = 2.6686e-01, time/batch = 17.6043s	
7359/16650 (epoch 22.099), train_loss = 0.98997424, grad/param norm = 2.5798e-01, time/batch = 18.1040s	
7360/16650 (epoch 22.102), train_loss = 1.01337007, grad/param norm = 2.6006e-01, time/batch = 16.2282s	
7361/16650 (epoch 22.105), train_loss = 1.05190826, grad/param norm = 2.7542e-01, time/batch = 17.9408s	
7362/16650 (epoch 22.108), train_loss = 1.03975326, grad/param norm = 2.9180e-01, time/batch = 17.9474s	
7363/16650 (epoch 22.111), train_loss = 1.07904787, grad/param norm = 2.4718e-01, time/batch = 15.0739s	
7364/16650 (epoch 22.114), train_loss = 1.10001857, grad/param norm = 2.6089e-01, time/batch = 16.4084s	
7365/16650 (epoch 22.117), train_loss = 1.17466700, grad/param norm = 2.7845e-01, time/batch = 17.4378s	
7366/16650 (epoch 22.120), train_loss = 0.91792506, grad/param norm = 2.3020e-01, time/batch = 16.9151s	
7367/16650 (epoch 22.123), train_loss = 0.98033296, grad/param norm = 2.6053e-01, time/batch = 15.1645s	
7368/16650 (epoch 22.126), train_loss = 1.01699070, grad/param norm = 2.5493e-01, time/batch = 13.8591s	
7369/16650 (epoch 22.129), train_loss = 1.03191603, grad/param norm = 2.6689e-01, time/batch = 13.7939s	
7370/16650 (epoch 22.132), train_loss = 0.99514367, grad/param norm = 2.5608e-01, time/batch = 14.0914s	
7371/16650 (epoch 22.135), train_loss = 1.07506097, grad/param norm = 2.5028e-01, time/batch = 17.7132s	
7372/16650 (epoch 22.138), train_loss = 1.07054372, grad/param norm = 2.4905e-01, time/batch = 16.9347s	
7373/16650 (epoch 22.141), train_loss = 1.06243246, grad/param norm = 2.6834e-01, time/batch = 18.1121s	
7374/16650 (epoch 22.144), train_loss = 0.99783016, grad/param norm = 2.6020e-01, time/batch = 18.6987s	
7375/16650 (epoch 22.147), train_loss = 1.16593537, grad/param norm = 2.7671e-01, time/batch = 15.6690s	
7376/16650 (epoch 22.150), train_loss = 1.25905418, grad/param norm = 3.4477e-01, time/batch = 15.4187s	
7377/16650 (epoch 22.153), train_loss = 1.06202351, grad/param norm = 2.9281e-01, time/batch = 17.4319s	
7378/16650 (epoch 22.156), train_loss = 0.91503379, grad/param norm = 2.2442e-01, time/batch = 16.1948s	
7379/16650 (epoch 22.159), train_loss = 1.07985168, grad/param norm = 2.8336e-01, time/batch = 16.2541s	
7380/16650 (epoch 22.162), train_loss = 1.11780586, grad/param norm = 2.6342e-01, time/batch = 17.6063s	
7381/16650 (epoch 22.165), train_loss = 1.12317334, grad/param norm = 2.7780e-01, time/batch = 14.5567s	
7382/16650 (epoch 22.168), train_loss = 0.85246224, grad/param norm = 2.1899e-01, time/batch = 17.0943s	
7383/16650 (epoch 22.171), train_loss = 1.09464506, grad/param norm = 2.3517e-01, time/batch = 17.0385s	
7384/16650 (epoch 22.174), train_loss = 0.84408012, grad/param norm = 2.3404e-01, time/batch = 17.8688s	
7385/16650 (epoch 22.177), train_loss = 0.99894395, grad/param norm = 2.8109e-01, time/batch = 18.7827s	
7386/16650 (epoch 22.180), train_loss = 1.12630512, grad/param norm = 2.6026e-01, time/batch = 16.2513s	
7387/16650 (epoch 22.183), train_loss = 1.24877086, grad/param norm = 2.8195e-01, time/batch = 16.6389s	
7388/16650 (epoch 22.186), train_loss = 1.07693546, grad/param norm = 2.6721e-01, time/batch = 18.6975s	
7389/16650 (epoch 22.189), train_loss = 0.92515035, grad/param norm = 2.3958e-01, time/batch = 16.4189s	
7390/16650 (epoch 22.192), train_loss = 0.96505187, grad/param norm = 2.8487e-01, time/batch = 17.9450s	
7391/16650 (epoch 22.195), train_loss = 0.96193323, grad/param norm = 2.9810e-01, time/batch = 14.8537s	
7392/16650 (epoch 22.198), train_loss = 0.82940056, grad/param norm = 2.0115e-01, time/batch = 18.5188s	
7393/16650 (epoch 22.201), train_loss = 0.94403895, grad/param norm = 2.5697e-01, time/batch = 17.1722s	
7394/16650 (epoch 22.204), train_loss = 1.00309107, grad/param norm = 2.5614e-01, time/batch = 17.5700s	
7395/16650 (epoch 22.207), train_loss = 1.02618795, grad/param norm = 2.7209e-01, time/batch = 16.1955s	
7396/16650 (epoch 22.210), train_loss = 0.97560022, grad/param norm = 2.6057e-01, time/batch = 15.4220s	
7397/16650 (epoch 22.213), train_loss = 1.09947619, grad/param norm = 2.9756e-01, time/batch = 16.6055s	
7398/16650 (epoch 22.216), train_loss = 0.95878319, grad/param norm = 2.4052e-01, time/batch = 17.0411s	
7399/16650 (epoch 22.219), train_loss = 1.02010730, grad/param norm = 2.8005e-01, time/batch = 17.5368s	
7400/16650 (epoch 22.222), train_loss = 1.02307495, grad/param norm = 2.2833e-01, time/batch = 15.7558s	
7401/16650 (epoch 22.225), train_loss = 1.00759594, grad/param norm = 2.6381e-01, time/batch = 18.2225s	
7402/16650 (epoch 22.228), train_loss = 0.90931993, grad/param norm = 2.4475e-01, time/batch = 16.4253s	
7403/16650 (epoch 22.231), train_loss = 0.97574485, grad/param norm = 2.6157e-01, time/batch = 14.7415s	
7404/16650 (epoch 22.234), train_loss = 1.18731919, grad/param norm = 2.6519e-01, time/batch = 13.9076s	
7405/16650 (epoch 22.237), train_loss = 1.05277922, grad/param norm = 2.7229e-01, time/batch = 16.5359s	
7406/16650 (epoch 22.240), train_loss = 1.04536138, grad/param norm = 2.6083e-01, time/batch = 17.7025s	
7407/16650 (epoch 22.243), train_loss = 0.98877143, grad/param norm = 2.5882e-01, time/batch = 15.6008s	
7408/16650 (epoch 22.246), train_loss = 1.11857661, grad/param norm = 2.5662e-01, time/batch = 17.0336s	
7409/16650 (epoch 22.249), train_loss = 0.87508589, grad/param norm = 2.3566e-01, time/batch = 17.6995s	
7410/16650 (epoch 22.252), train_loss = 0.96487866, grad/param norm = 2.5499e-01, time/batch = 17.5228s	
7411/16650 (epoch 22.255), train_loss = 1.06441008, grad/param norm = 2.5548e-01, time/batch = 16.5977s	
7412/16650 (epoch 22.258), train_loss = 1.10847693, grad/param norm = 2.6352e-01, time/batch = 17.7956s	
7413/16650 (epoch 22.261), train_loss = 1.02581837, grad/param norm = 2.5805e-01, time/batch = 14.8305s	
7414/16650 (epoch 22.264), train_loss = 0.96013307, grad/param norm = 2.6026e-01, time/batch = 15.4586s	
7415/16650 (epoch 22.267), train_loss = 0.97467178, grad/param norm = 2.5144e-01, time/batch = 15.9098s	
7416/16650 (epoch 22.270), train_loss = 1.01230079, grad/param norm = 2.4257e-01, time/batch = 17.2815s	
7417/16650 (epoch 22.273), train_loss = 1.12030485, grad/param norm = 2.4096e-01, time/batch = 17.1226s	
7418/16650 (epoch 22.276), train_loss = 1.02645373, grad/param norm = 2.4325e-01, time/batch = 15.6772s	
7419/16650 (epoch 22.279), train_loss = 1.00000362, grad/param norm = 2.5725e-01, time/batch = 15.9574s	
7420/16650 (epoch 22.282), train_loss = 0.89245673, grad/param norm = 2.2592e-01, time/batch = 15.3392s	
7421/16650 (epoch 22.285), train_loss = 0.91187662, grad/param norm = 2.3697e-01, time/batch = 17.0221s	
7422/16650 (epoch 22.288), train_loss = 0.94506225, grad/param norm = 2.5016e-01, time/batch = 16.6016s	
7423/16650 (epoch 22.291), train_loss = 0.77581446, grad/param norm = 2.3493e-01, time/batch = 17.0533s	
7424/16650 (epoch 22.294), train_loss = 0.88599433, grad/param norm = 2.1595e-01, time/batch = 16.8802s	
7425/16650 (epoch 22.297), train_loss = 0.96563456, grad/param norm = 2.2954e-01, time/batch = 15.4080s	
7426/16650 (epoch 22.300), train_loss = 0.77397903, grad/param norm = 2.3033e-01, time/batch = 16.9373s	
7427/16650 (epoch 22.303), train_loss = 0.85505045, grad/param norm = 2.1664e-01, time/batch = 16.5388s	
7428/16650 (epoch 22.306), train_loss = 1.07293405, grad/param norm = 2.4772e-01, time/batch = 17.3658s	
7429/16650 (epoch 22.309), train_loss = 1.07442931, grad/param norm = 2.6389e-01, time/batch = 17.1031s	
7430/16650 (epoch 22.312), train_loss = 0.89649235, grad/param norm = 2.6396e-01, time/batch = 17.1186s	
7431/16650 (epoch 22.315), train_loss = 0.70259152, grad/param norm = 2.1466e-01, time/batch = 17.1195s	
7432/16650 (epoch 22.318), train_loss = 0.81682341, grad/param norm = 2.4285e-01, time/batch = 15.9376s	
7433/16650 (epoch 22.321), train_loss = 1.12624637, grad/param norm = 2.6719e-01, time/batch = 17.2635s	
7434/16650 (epoch 22.324), train_loss = 0.92662521, grad/param norm = 2.8026e-01, time/batch = 17.4556s	
7435/16650 (epoch 22.327), train_loss = 1.05482564, grad/param norm = 2.9118e-01, time/batch = 17.8733s	
7436/16650 (epoch 22.330), train_loss = 1.03706602, grad/param norm = 3.2119e-01, time/batch = 15.2258s	
7437/16650 (epoch 22.333), train_loss = 1.05352464, grad/param norm = 2.9169e-01, time/batch = 16.4300s	
7438/16650 (epoch 22.336), train_loss = 0.89501211, grad/param norm = 2.8455e-01, time/batch = 16.1890s	
7439/16650 (epoch 22.339), train_loss = 0.94435435, grad/param norm = 2.3783e-01, time/batch = 16.6772s	
7440/16650 (epoch 22.342), train_loss = 0.91716496, grad/param norm = 2.6148e-01, time/batch = 17.3753s	
7441/16650 (epoch 22.345), train_loss = 0.84567222, grad/param norm = 2.1775e-01, time/batch = 18.0428s	
7442/16650 (epoch 22.348), train_loss = 0.98386107, grad/param norm = 2.7035e-01, time/batch = 17.1988s	
7443/16650 (epoch 22.351), train_loss = 1.05033931, grad/param norm = 2.5516e-01, time/batch = 15.6373s	
7444/16650 (epoch 22.354), train_loss = 1.06884172, grad/param norm = 2.7736e-01, time/batch = 17.4492s	
7445/16650 (epoch 22.357), train_loss = 1.02212616, grad/param norm = 2.6777e-01, time/batch = 18.1245s	
7446/16650 (epoch 22.360), train_loss = 1.03427244, grad/param norm = 2.6651e-01, time/batch = 16.2741s	
7447/16650 (epoch 22.363), train_loss = 1.12175692, grad/param norm = 2.7627e-01, time/batch = 15.2526s	
7448/16650 (epoch 22.366), train_loss = 1.13808104, grad/param norm = 2.5978e-01, time/batch = 17.0313s	
7449/16650 (epoch 22.369), train_loss = 1.00594267, grad/param norm = 2.6115e-01, time/batch = 17.4648s	
7450/16650 (epoch 22.372), train_loss = 1.00329395, grad/param norm = 2.4033e-01, time/batch = 15.5237s	
7451/16650 (epoch 22.375), train_loss = 1.02331306, grad/param norm = 2.3698e-01, time/batch = 14.6440s	
7452/16650 (epoch 22.378), train_loss = 0.90768936, grad/param norm = 2.2890e-01, time/batch = 17.6205s	
7453/16650 (epoch 22.381), train_loss = 1.01699413, grad/param norm = 2.4581e-01, time/batch = 17.0370s	
7454/16650 (epoch 22.384), train_loss = 1.15169824, grad/param norm = 2.6566e-01, time/batch = 15.7554s	
7455/16650 (epoch 22.387), train_loss = 0.79295294, grad/param norm = 2.1638e-01, time/batch = 16.9568s	
7456/16650 (epoch 22.390), train_loss = 1.08520669, grad/param norm = 2.5381e-01, time/batch = 16.9409s	
7457/16650 (epoch 22.393), train_loss = 0.95192580, grad/param norm = 2.6513e-01, time/batch = 16.2591s	
7458/16650 (epoch 22.396), train_loss = 1.09986521, grad/param norm = 2.6366e-01, time/batch = 16.0537s	
7459/16650 (epoch 22.399), train_loss = 1.03710409, grad/param norm = 2.6289e-01, time/batch = 16.2275s	
7460/16650 (epoch 22.402), train_loss = 0.90993174, grad/param norm = 2.3838e-01, time/batch = 17.8864s	
7461/16650 (epoch 22.405), train_loss = 0.82721110, grad/param norm = 2.9088e-01, time/batch = 16.7557s	
7462/16650 (epoch 22.408), train_loss = 1.05926759, grad/param norm = 3.5457e-01, time/batch = 17.1255s	
7463/16650 (epoch 22.411), train_loss = 0.90937560, grad/param norm = 3.1031e-01, time/batch = 17.2714s	
7464/16650 (epoch 22.414), train_loss = 0.89424649, grad/param norm = 2.6841e-01, time/batch = 16.7737s	
7465/16650 (epoch 22.417), train_loss = 0.85935654, grad/param norm = 2.3312e-01, time/batch = 17.0995s	
7466/16650 (epoch 22.420), train_loss = 0.86156155, grad/param norm = 2.3701e-01, time/batch = 15.8052s	
7467/16650 (epoch 22.423), train_loss = 0.74814252, grad/param norm = 2.0671e-01, time/batch = 13.6739s	
7468/16650 (epoch 22.426), train_loss = 0.87916726, grad/param norm = 2.7106e-01, time/batch = 13.8331s	
7469/16650 (epoch 22.429), train_loss = 1.08595660, grad/param norm = 2.6288e-01, time/batch = 16.5155s	
7470/16650 (epoch 22.432), train_loss = 1.05578857, grad/param norm = 2.7688e-01, time/batch = 16.8558s	
7471/16650 (epoch 22.435), train_loss = 1.17191011, grad/param norm = 2.7046e-01, time/batch = 17.6299s	
7472/16650 (epoch 22.438), train_loss = 1.15992161, grad/param norm = 3.0373e-01, time/batch = 16.0029s	
7473/16650 (epoch 22.441), train_loss = 1.02555899, grad/param norm = 3.3047e-01, time/batch = 16.6917s	
7474/16650 (epoch 22.444), train_loss = 0.91577005, grad/param norm = 2.8820e-01, time/batch = 15.9247s	
7475/16650 (epoch 22.447), train_loss = 0.96465600, grad/param norm = 2.8111e-01, time/batch = 16.6081s	
7476/16650 (epoch 22.450), train_loss = 0.92138600, grad/param norm = 2.4749e-01, time/batch = 14.3280s	
7477/16650 (epoch 22.453), train_loss = 0.92187996, grad/param norm = 2.2687e-01, time/batch = 16.9594s	
7478/16650 (epoch 22.456), train_loss = 0.84728900, grad/param norm = 2.2932e-01, time/batch = 16.0308s	
7479/16650 (epoch 22.459), train_loss = 0.92276285, grad/param norm = 2.6014e-01, time/batch = 15.6806s	
7480/16650 (epoch 22.462), train_loss = 1.11923268, grad/param norm = 3.3782e-01, time/batch = 15.3284s	
7481/16650 (epoch 22.465), train_loss = 0.90007009, grad/param norm = 2.5859e-01, time/batch = 16.8634s	
7482/16650 (epoch 22.468), train_loss = 0.78394590, grad/param norm = 2.4977e-01, time/batch = 17.2013s	
7483/16650 (epoch 22.471), train_loss = 0.63899907, grad/param norm = 1.9284e-01, time/batch = 15.9330s	
7484/16650 (epoch 22.474), train_loss = 0.84718086, grad/param norm = 2.4779e-01, time/batch = 17.0331s	
7485/16650 (epoch 22.477), train_loss = 1.02992927, grad/param norm = 2.8307e-01, time/batch = 16.7729s	
7486/16650 (epoch 22.480), train_loss = 1.05007108, grad/param norm = 3.0236e-01, time/batch = 16.1938s	
7487/16650 (epoch 22.483), train_loss = 1.10199343, grad/param norm = 2.6591e-01, time/batch = 16.4243s	
7488/16650 (epoch 22.486), train_loss = 0.88436671, grad/param norm = 2.2324e-01, time/batch = 16.0121s	
7489/16650 (epoch 22.489), train_loss = 0.92094439, grad/param norm = 2.7524e-01, time/batch = 17.7883s	
7490/16650 (epoch 22.492), train_loss = 0.96224847, grad/param norm = 2.2752e-01, time/batch = 15.6811s	
7491/16650 (epoch 22.495), train_loss = 0.85751993, grad/param norm = 2.5861e-01, time/batch = 17.0145s	
7492/16650 (epoch 22.498), train_loss = 0.93446069, grad/param norm = 2.5993e-01, time/batch = 17.3594s	
7493/16650 (epoch 22.502), train_loss = 1.11357281, grad/param norm = 2.6620e-01, time/batch = 17.6204s	
7494/16650 (epoch 22.505), train_loss = 1.02041926, grad/param norm = 2.4650e-01, time/batch = 16.2667s	
7495/16650 (epoch 22.508), train_loss = 1.00276983, grad/param norm = 2.7627e-01, time/batch = 16.2941s	
7496/16650 (epoch 22.511), train_loss = 1.10033611, grad/param norm = 2.6063e-01, time/batch = 16.8829s	
7497/16650 (epoch 22.514), train_loss = 0.82395398, grad/param norm = 2.3777e-01, time/batch = 16.0907s	
7498/16650 (epoch 22.517), train_loss = 0.97926999, grad/param norm = 2.9141e-01, time/batch = 16.1901s	
7499/16650 (epoch 22.520), train_loss = 0.87792265, grad/param norm = 2.4259e-01, time/batch = 15.8345s	
7500/16650 (epoch 22.523), train_loss = 0.93407887, grad/param norm = 2.5465e-01, time/batch = 17.4572s	
7501/16650 (epoch 22.526), train_loss = 1.06729507, grad/param norm = 2.6033e-01, time/batch = 16.4253s	
7502/16650 (epoch 22.529), train_loss = 1.12161348, grad/param norm = 2.9066e-01, time/batch = 15.4439s	
7503/16650 (epoch 22.532), train_loss = 0.74809146, grad/param norm = 2.3205e-01, time/batch = 16.0608s	
7504/16650 (epoch 22.535), train_loss = 0.82379064, grad/param norm = 2.4742e-01, time/batch = 16.6114s	
7505/16650 (epoch 22.538), train_loss = 0.81965829, grad/param norm = 2.4537e-01, time/batch = 15.9281s	
7506/16650 (epoch 22.541), train_loss = 1.09451763, grad/param norm = 2.6957e-01, time/batch = 15.8598s	
7507/16650 (epoch 22.544), train_loss = 1.14681459, grad/param norm = 3.4068e-01, time/batch = 17.9535s	
7508/16650 (epoch 22.547), train_loss = 0.85266513, grad/param norm = 2.4501e-01, time/batch = 16.0946s	
7509/16650 (epoch 22.550), train_loss = 0.96020418, grad/param norm = 2.6870e-01, time/batch = 16.6979s	
7510/16650 (epoch 22.553), train_loss = 0.94738572, grad/param norm = 2.8989e-01, time/batch = 16.1276s	
7511/16650 (epoch 22.556), train_loss = 0.89023198, grad/param norm = 2.5315e-01, time/batch = 16.4505s	
7512/16650 (epoch 22.559), train_loss = 0.78514245, grad/param norm = 2.3830e-01, time/batch = 14.9105s	
7513/16650 (epoch 22.562), train_loss = 0.91365013, grad/param norm = 2.5885e-01, time/batch = 16.0280s	
7514/16650 (epoch 22.565), train_loss = 0.76710234, grad/param norm = 2.5747e-01, time/batch = 15.2297s	
7515/16650 (epoch 22.568), train_loss = 0.76582214, grad/param norm = 2.2153e-01, time/batch = 17.4365s	
7516/16650 (epoch 22.571), train_loss = 0.81799955, grad/param norm = 2.8441e-01, time/batch = 16.1883s	
7517/16650 (epoch 22.574), train_loss = 0.93368082, grad/param norm = 2.6243e-01, time/batch = 17.6327s	
7518/16650 (epoch 22.577), train_loss = 0.88712522, grad/param norm = 2.2967e-01, time/batch = 17.1002s	
7519/16650 (epoch 22.580), train_loss = 0.80161008, grad/param norm = 2.3691e-01, time/batch = 14.9090s	
7520/16650 (epoch 22.583), train_loss = 0.93157824, grad/param norm = 2.7115e-01, time/batch = 17.8621s	
7521/16650 (epoch 22.586), train_loss = 0.86356427, grad/param norm = 2.9747e-01, time/batch = 16.8667s	
7522/16650 (epoch 22.589), train_loss = 0.81874700, grad/param norm = 2.3246e-01, time/batch = 14.5028s	
7523/16650 (epoch 22.592), train_loss = 0.95270795, grad/param norm = 2.6068e-01, time/batch = 15.6561s	
7524/16650 (epoch 22.595), train_loss = 0.88575862, grad/param norm = 2.6878e-01, time/batch = 16.2496s	
7525/16650 (epoch 22.598), train_loss = 0.90558638, grad/param norm = 2.5496e-01, time/batch = 17.1913s	
7526/16650 (epoch 22.601), train_loss = 0.87798755, grad/param norm = 2.8760e-01, time/batch = 16.8403s	
7527/16650 (epoch 22.604), train_loss = 1.03463628, grad/param norm = 2.7223e-01, time/batch = 16.4480s	
7528/16650 (epoch 22.607), train_loss = 0.98817111, grad/param norm = 2.3583e-01, time/batch = 17.8815s	
7529/16650 (epoch 22.610), train_loss = 0.84684745, grad/param norm = 2.2758e-01, time/batch = 17.1851s	
7530/16650 (epoch 22.613), train_loss = 1.10113335, grad/param norm = 2.9567e-01, time/batch = 14.7671s	
7531/16650 (epoch 22.616), train_loss = 1.08679816, grad/param norm = 3.2425e-01, time/batch = 17.5371s	
7532/16650 (epoch 22.619), train_loss = 0.78904486, grad/param norm = 2.2635e-01, time/batch = 16.6098s	
7533/16650 (epoch 22.622), train_loss = 0.77046806, grad/param norm = 2.3038e-01, time/batch = 15.9220s	
7534/16650 (epoch 22.625), train_loss = 0.87540507, grad/param norm = 2.3518e-01, time/batch = 15.7559s	
7535/16650 (epoch 22.628), train_loss = 0.88853492, grad/param norm = 2.6725e-01, time/batch = 17.0215s	
7536/16650 (epoch 22.631), train_loss = 0.98366995, grad/param norm = 3.0693e-01, time/batch = 17.6241s	
7537/16650 (epoch 22.634), train_loss = 1.13143037, grad/param norm = 2.7451e-01, time/batch = 16.5126s	
7538/16650 (epoch 22.637), train_loss = 1.14598414, grad/param norm = 2.7834e-01, time/batch = 17.6028s	
7539/16650 (epoch 22.640), train_loss = 0.88198473, grad/param norm = 2.6089e-01, time/batch = 15.9537s	
7540/16650 (epoch 22.643), train_loss = 1.01076627, grad/param norm = 2.4757e-01, time/batch = 16.2175s	
7541/16650 (epoch 22.646), train_loss = 1.01451731, grad/param norm = 2.6441e-01, time/batch = 15.0815s	
7542/16650 (epoch 22.649), train_loss = 0.96050815, grad/param norm = 2.5916e-01, time/batch = 15.2476s	
7543/16650 (epoch 22.652), train_loss = 1.04889389, grad/param norm = 2.7170e-01, time/batch = 15.6049s	
7544/16650 (epoch 22.655), train_loss = 0.99526746, grad/param norm = 2.8099e-01, time/batch = 17.4357s	
7545/16650 (epoch 22.658), train_loss = 0.86349164, grad/param norm = 2.7861e-01, time/batch = 16.9327s	
7546/16650 (epoch 22.661), train_loss = 1.01630301, grad/param norm = 2.8984e-01, time/batch = 17.0248s	
7547/16650 (epoch 22.664), train_loss = 0.96689404, grad/param norm = 2.6680e-01, time/batch = 17.4562s	
7548/16650 (epoch 22.667), train_loss = 1.06049390, grad/param norm = 2.4937e-01, time/batch = 15.8478s	
7549/16650 (epoch 22.670), train_loss = 0.82404335, grad/param norm = 2.5073e-01, time/batch = 16.0411s	
7550/16650 (epoch 22.673), train_loss = 0.86211136, grad/param norm = 2.2280e-01, time/batch = 16.6923s	
7551/16650 (epoch 22.676), train_loss = 0.97331503, grad/param norm = 2.7262e-01, time/batch = 17.9565s	
7552/16650 (epoch 22.679), train_loss = 0.83820491, grad/param norm = 2.4769e-01, time/batch = 16.6732s	
7553/16650 (epoch 22.682), train_loss = 0.95958609, grad/param norm = 2.3946e-01, time/batch = 17.7860s	
7554/16650 (epoch 22.685), train_loss = 0.81516677, grad/param norm = 2.5521e-01, time/batch = 15.1912s	
7555/16650 (epoch 22.688), train_loss = 1.00338781, grad/param norm = 2.4167e-01, time/batch = 15.0056s	
7556/16650 (epoch 22.691), train_loss = 1.00244378, grad/param norm = 2.6171e-01, time/batch = 17.3629s	
7557/16650 (epoch 22.694), train_loss = 0.83874982, grad/param norm = 2.2384e-01, time/batch = 15.9936s	
7558/16650 (epoch 22.697), train_loss = 0.81934346, grad/param norm = 2.3071e-01, time/batch = 16.5899s	
7559/16650 (epoch 22.700), train_loss = 1.04685726, grad/param norm = 2.8078e-01, time/batch = 16.3538s	
7560/16650 (epoch 22.703), train_loss = 0.83285400, grad/param norm = 2.3842e-01, time/batch = 16.4616s	
7561/16650 (epoch 22.706), train_loss = 0.96477922, grad/param norm = 2.6647e-01, time/batch = 15.5277s	
7562/16650 (epoch 22.709), train_loss = 0.85407682, grad/param norm = 2.3624e-01, time/batch = 16.2826s	
7563/16650 (epoch 22.712), train_loss = 0.88450033, grad/param norm = 2.6815e-01, time/batch = 31.2644s	
7564/16650 (epoch 22.715), train_loss = 1.03316987, grad/param norm = 2.7268e-01, time/batch = 17.8678s	
7565/16650 (epoch 22.718), train_loss = 1.06670443, grad/param norm = 2.6503e-01, time/batch = 14.3209s	
7566/16650 (epoch 22.721), train_loss = 1.02937434, grad/param norm = 2.5259e-01, time/batch = 15.9536s	
7567/16650 (epoch 22.724), train_loss = 1.05121822, grad/param norm = 2.8001e-01, time/batch = 16.9650s	
7568/16650 (epoch 22.727), train_loss = 1.01450811, grad/param norm = 2.5295e-01, time/batch = 17.5313s	
7569/16650 (epoch 22.730), train_loss = 0.90930924, grad/param norm = 2.4608e-01, time/batch = 15.3465s	
7570/16650 (epoch 22.733), train_loss = 1.06284078, grad/param norm = 3.0343e-01, time/batch = 17.3631s	
7571/16650 (epoch 22.736), train_loss = 0.79994038, grad/param norm = 2.3646e-01, time/batch = 16.8578s	
7572/16650 (epoch 22.739), train_loss = 0.94776992, grad/param norm = 2.6205e-01, time/batch = 16.9354s	
7573/16650 (epoch 22.742), train_loss = 0.94810118, grad/param norm = 2.5400e-01, time/batch = 15.6769s	
7574/16650 (epoch 22.745), train_loss = 0.76701311, grad/param norm = 2.4445e-01, time/batch = 17.7108s	
7575/16650 (epoch 22.748), train_loss = 0.82993162, grad/param norm = 2.6217e-01, time/batch = 15.8435s	
7576/16650 (epoch 22.751), train_loss = 0.99639677, grad/param norm = 3.3441e-01, time/batch = 14.9488s	
7577/16650 (epoch 22.754), train_loss = 1.14934017, grad/param norm = 3.0089e-01, time/batch = 16.4501s	
7578/16650 (epoch 22.757), train_loss = 1.09830290, grad/param norm = 2.9221e-01, time/batch = 17.5386s	
7579/16650 (epoch 22.760), train_loss = 0.93706055, grad/param norm = 2.5049e-01, time/batch = 16.5256s	
7580/16650 (epoch 22.763), train_loss = 0.86315590, grad/param norm = 2.3272e-01, time/batch = 16.1643s	
7581/16650 (epoch 22.766), train_loss = 0.94529800, grad/param norm = 2.3546e-01, time/batch = 17.2731s	
7582/16650 (epoch 22.769), train_loss = 0.99533043, grad/param norm = 2.7528e-01, time/batch = 16.2509s	
7583/16650 (epoch 22.772), train_loss = 0.90918469, grad/param norm = 2.5074e-01, time/batch = 17.0107s	
7584/16650 (epoch 22.775), train_loss = 0.92773673, grad/param norm = 2.4129e-01, time/batch = 17.3669s	
7585/16650 (epoch 22.778), train_loss = 0.95243732, grad/param norm = 2.2950e-01, time/batch = 16.9599s	
7586/16650 (epoch 22.781), train_loss = 1.07211335, grad/param norm = 2.3632e-01, time/batch = 17.3751s	
7587/16650 (epoch 22.784), train_loss = 1.02012584, grad/param norm = 2.6394e-01, time/batch = 15.6919s	
7588/16650 (epoch 22.787), train_loss = 1.02187453, grad/param norm = 2.4323e-01, time/batch = 17.1228s	
7589/16650 (epoch 22.790), train_loss = 0.98802057, grad/param norm = 2.2655e-01, time/batch = 17.1290s	
7590/16650 (epoch 22.793), train_loss = 0.86052496, grad/param norm = 2.4925e-01, time/batch = 16.7876s	
7591/16650 (epoch 22.796), train_loss = 1.26639531, grad/param norm = 2.9444e-01, time/batch = 16.3401s	
7592/16650 (epoch 22.799), train_loss = 1.15327877, grad/param norm = 2.6168e-01, time/batch = 16.7551s	
7593/16650 (epoch 22.802), train_loss = 1.01769439, grad/param norm = 2.5857e-01, time/batch = 15.5264s	
7594/16650 (epoch 22.805), train_loss = 0.96598402, grad/param norm = 2.5221e-01, time/batch = 15.6038s	
7595/16650 (epoch 22.808), train_loss = 1.01800458, grad/param norm = 2.5052e-01, time/batch = 16.4492s	
7596/16650 (epoch 22.811), train_loss = 1.08186480, grad/param norm = 2.5220e-01, time/batch = 18.2991s	
7597/16650 (epoch 22.814), train_loss = 0.86106243, grad/param norm = 2.3258e-01, time/batch = 16.2783s	
7598/16650 (epoch 22.817), train_loss = 0.90124311, grad/param norm = 2.4637e-01, time/batch = 9.5868s	
7599/16650 (epoch 22.820), train_loss = 1.03380454, grad/param norm = 2.9331e-01, time/batch = 0.6226s	
7600/16650 (epoch 22.823), train_loss = 0.94069960, grad/param norm = 2.6350e-01, time/batch = 0.6160s	
7601/16650 (epoch 22.826), train_loss = 0.93535089, grad/param norm = 2.4138e-01, time/batch = 0.6199s	
7602/16650 (epoch 22.829), train_loss = 1.01978287, grad/param norm = 2.6342e-01, time/batch = 0.6270s	
7603/16650 (epoch 22.832), train_loss = 1.06071062, grad/param norm = 2.8661e-01, time/batch = 0.6260s	
7604/16650 (epoch 22.835), train_loss = 1.03537285, grad/param norm = 2.9910e-01, time/batch = 0.6425s	
7605/16650 (epoch 22.838), train_loss = 0.89177568, grad/param norm = 2.6323e-01, time/batch = 0.6452s	
7606/16650 (epoch 22.841), train_loss = 0.91646848, grad/param norm = 2.5359e-01, time/batch = 0.7847s	
7607/16650 (epoch 22.844), train_loss = 0.89199097, grad/param norm = 2.1458e-01, time/batch = 0.9454s	
7608/16650 (epoch 22.847), train_loss = 1.06245664, grad/param norm = 2.8009e-01, time/batch = 0.9396s	
7609/16650 (epoch 22.850), train_loss = 0.85136148, grad/param norm = 2.6086e-01, time/batch = 0.9225s	
7610/16650 (epoch 22.853), train_loss = 0.97313052, grad/param norm = 2.7241e-01, time/batch = 0.9045s	
7611/16650 (epoch 22.856), train_loss = 0.90539418, grad/param norm = 2.6441e-01, time/batch = 1.0055s	
7612/16650 (epoch 22.859), train_loss = 1.06317735, grad/param norm = 2.8705e-01, time/batch = 1.8001s	
7613/16650 (epoch 22.862), train_loss = 0.96446820, grad/param norm = 2.7820e-01, time/batch = 1.7035s	
7614/16650 (epoch 22.865), train_loss = 0.80678918, grad/param norm = 2.2311e-01, time/batch = 4.6766s	
7615/16650 (epoch 22.868), train_loss = 1.02470733, grad/param norm = 2.4556e-01, time/batch = 16.1722s	
7616/16650 (epoch 22.871), train_loss = 0.99354198, grad/param norm = 2.4927e-01, time/batch = 16.8675s	
7617/16650 (epoch 22.874), train_loss = 0.99996173, grad/param norm = 2.6259e-01, time/batch = 15.4093s	
7618/16650 (epoch 22.877), train_loss = 0.98406552, grad/param norm = 2.5539e-01, time/batch = 16.2718s	
7619/16650 (epoch 22.880), train_loss = 0.87054598, grad/param norm = 2.7378e-01, time/batch = 15.4086s	
7620/16650 (epoch 22.883), train_loss = 0.96978389, grad/param norm = 2.8045e-01, time/batch = 15.9246s	
7621/16650 (epoch 22.886), train_loss = 0.96719760, grad/param norm = 2.4717e-01, time/batch = 17.8079s	
7622/16650 (epoch 22.889), train_loss = 0.84533299, grad/param norm = 2.4697e-01, time/batch = 17.5400s	
7623/16650 (epoch 22.892), train_loss = 0.95378017, grad/param norm = 2.3349e-01, time/batch = 16.7966s	
7624/16650 (epoch 22.895), train_loss = 1.00522190, grad/param norm = 2.6483e-01, time/batch = 15.7829s	
7625/16650 (epoch 22.898), train_loss = 0.96860018, grad/param norm = 2.4717e-01, time/batch = 16.6984s	
7626/16650 (epoch 22.901), train_loss = 0.95576532, grad/param norm = 2.4900e-01, time/batch = 17.0330s	
7627/16650 (epoch 22.904), train_loss = 0.89005934, grad/param norm = 2.5099e-01, time/batch = 16.4449s	
7628/16650 (epoch 22.907), train_loss = 1.02465715, grad/param norm = 2.7654e-01, time/batch = 16.7653s	
7629/16650 (epoch 22.910), train_loss = 1.01622820, grad/param norm = 2.6613e-01, time/batch = 17.1994s	
7630/16650 (epoch 22.913), train_loss = 0.90197394, grad/param norm = 2.7150e-01, time/batch = 15.7535s	
7631/16650 (epoch 22.916), train_loss = 0.96058978, grad/param norm = 2.8343e-01, time/batch = 14.5851s	
7632/16650 (epoch 22.919), train_loss = 1.11822197, grad/param norm = 2.5447e-01, time/batch = 17.3598s	
7633/16650 (epoch 22.922), train_loss = 1.04793013, grad/param norm = 2.6479e-01, time/batch = 17.3007s	
7634/16650 (epoch 22.925), train_loss = 0.91813802, grad/param norm = 2.7931e-01, time/batch = 17.8001s	
7635/16650 (epoch 22.928), train_loss = 0.96181451, grad/param norm = 2.6494e-01, time/batch = 14.3018s	
7636/16650 (epoch 22.931), train_loss = 1.02782398, grad/param norm = 2.6795e-01, time/batch = 17.4709s	
7637/16650 (epoch 22.934), train_loss = 0.84475732, grad/param norm = 2.5238e-01, time/batch = 17.7868s	
7638/16650 (epoch 22.937), train_loss = 0.89782972, grad/param norm = 2.7616e-01, time/batch = 15.9419s	
7639/16650 (epoch 22.940), train_loss = 0.92086023, grad/param norm = 2.1987e-01, time/batch = 16.2890s	
7640/16650 (epoch 22.943), train_loss = 0.99996362, grad/param norm = 2.7257e-01, time/batch = 14.2343s	
7641/16650 (epoch 22.946), train_loss = 0.86467861, grad/param norm = 2.4865e-01, time/batch = 15.9278s	
7642/16650 (epoch 22.949), train_loss = 0.85074538, grad/param norm = 2.6153e-01, time/batch = 16.1889s	
7643/16650 (epoch 22.952), train_loss = 0.79793492, grad/param norm = 2.4674e-01, time/batch = 16.8643s	
7644/16650 (epoch 22.955), train_loss = 0.93521331, grad/param norm = 2.5096e-01, time/batch = 15.4367s	
7645/16650 (epoch 22.958), train_loss = 1.01809640, grad/param norm = 2.9886e-01, time/batch = 15.0767s	
7646/16650 (epoch 22.961), train_loss = 0.95062934, grad/param norm = 2.3283e-01, time/batch = 15.0383s	
7647/16650 (epoch 22.964), train_loss = 0.87843449, grad/param norm = 2.8967e-01, time/batch = 16.2732s	
7648/16650 (epoch 22.967), train_loss = 1.08936693, grad/param norm = 3.0389e-01, time/batch = 17.6093s	
7649/16650 (epoch 22.970), train_loss = 0.88777310, grad/param norm = 2.4724e-01, time/batch = 16.0895s	
7650/16650 (epoch 22.973), train_loss = 0.91398619, grad/param norm = 2.7545e-01, time/batch = 14.2267s	
7651/16650 (epoch 22.976), train_loss = 0.89033189, grad/param norm = 2.6110e-01, time/batch = 17.5389s	
7652/16650 (epoch 22.979), train_loss = 0.99180945, grad/param norm = 2.8851e-01, time/batch = 17.6229s	
7653/16650 (epoch 22.982), train_loss = 1.02114688, grad/param norm = 2.8555e-01, time/batch = 15.4231s	
7654/16650 (epoch 22.985), train_loss = 0.93824377, grad/param norm = 2.4932e-01, time/batch = 17.1026s	
7655/16650 (epoch 22.988), train_loss = 1.08759311, grad/param norm = 2.8354e-01, time/batch = 15.8689s	
7656/16650 (epoch 22.991), train_loss = 0.87406397, grad/param norm = 2.5626e-01, time/batch = 15.7519s	
7657/16650 (epoch 22.994), train_loss = 0.88421992, grad/param norm = 2.3597e-01, time/batch = 16.5204s	
7658/16650 (epoch 22.997), train_loss = 0.97472047, grad/param norm = 2.9155e-01, time/batch = 17.5242s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
7659/16650 (epoch 23.000), train_loss = 1.02199894, grad/param norm = 2.9753e-01, time/batch = 15.7043s	
7660/16650 (epoch 23.003), train_loss = 1.07305986, grad/param norm = 3.1063e-01, time/batch = 17.2051s	
7661/16650 (epoch 23.006), train_loss = 1.04141738, grad/param norm = 2.8691e-01, time/batch = 16.4367s	
7662/16650 (epoch 23.009), train_loss = 1.13590704, grad/param norm = 2.6565e-01, time/batch = 17.0277s	
7663/16650 (epoch 23.012), train_loss = 1.09822097, grad/param norm = 2.7456e-01, time/batch = 15.6570s	
7664/16650 (epoch 23.015), train_loss = 0.96000701, grad/param norm = 2.5802e-01, time/batch = 15.3468s	
7665/16650 (epoch 23.018), train_loss = 0.82240354, grad/param norm = 2.7096e-01, time/batch = 16.7797s	
7666/16650 (epoch 23.021), train_loss = 1.07808542, grad/param norm = 2.7731e-01, time/batch = 17.5420s	
7667/16650 (epoch 23.024), train_loss = 0.96993888, grad/param norm = 2.6329e-01, time/batch = 16.9516s	
7668/16650 (epoch 23.027), train_loss = 1.04908583, grad/param norm = 3.0082e-01, time/batch = 15.4873s	
7669/16650 (epoch 23.030), train_loss = 0.84703359, grad/param norm = 2.4403e-01, time/batch = 17.3667s	
7670/16650 (epoch 23.033), train_loss = 0.98775505, grad/param norm = 2.6518e-01, time/batch = 17.4624s	
7671/16650 (epoch 23.036), train_loss = 0.74596135, grad/param norm = 2.5447e-01, time/batch = 16.5313s	
7672/16650 (epoch 23.039), train_loss = 1.07252079, grad/param norm = 2.6334e-01, time/batch = 14.5018s	
7673/16650 (epoch 23.042), train_loss = 1.04878748, grad/param norm = 2.6977e-01, time/batch = 15.8488s	
7674/16650 (epoch 23.045), train_loss = 0.92388499, grad/param norm = 2.5369e-01, time/batch = 17.5419s	
7675/16650 (epoch 23.048), train_loss = 1.05233894, grad/param norm = 2.9369e-01, time/batch = 15.5970s	
7676/16650 (epoch 23.051), train_loss = 0.92891589, grad/param norm = 2.4476e-01, time/batch = 16.1998s	
7677/16650 (epoch 23.054), train_loss = 0.97485293, grad/param norm = 2.8274e-01, time/batch = 17.5462s	
7678/16650 (epoch 23.057), train_loss = 0.97505010, grad/param norm = 2.9502e-01, time/batch = 16.7702s	
7679/16650 (epoch 23.060), train_loss = 0.81956635, grad/param norm = 2.1740e-01, time/batch = 15.7504s	
7680/16650 (epoch 23.063), train_loss = 0.93941201, grad/param norm = 2.5797e-01, time/batch = 16.7897s	
7681/16650 (epoch 23.066), train_loss = 1.12539749, grad/param norm = 2.9117e-01, time/batch = 17.3931s	
7682/16650 (epoch 23.069), train_loss = 1.03613261, grad/param norm = 2.6574e-01, time/batch = 16.1906s	
7683/16650 (epoch 23.072), train_loss = 0.93862419, grad/param norm = 2.8587e-01, time/batch = 16.4342s	
7684/16650 (epoch 23.075), train_loss = 1.03393026, grad/param norm = 2.4761e-01, time/batch = 17.2099s	
7685/16650 (epoch 23.078), train_loss = 1.08387056, grad/param norm = 2.7020e-01, time/batch = 17.5378s	
7686/16650 (epoch 23.081), train_loss = 0.98333044, grad/param norm = 2.8431e-01, time/batch = 16.0747s	
7687/16650 (epoch 23.084), train_loss = 1.03105316, grad/param norm = 2.5372e-01, time/batch = 17.8606s	
7688/16650 (epoch 23.087), train_loss = 0.96069233, grad/param norm = 2.5901e-01, time/batch = 14.6483s	
7689/16650 (epoch 23.090), train_loss = 0.96202070, grad/param norm = 2.6318e-01, time/batch = 16.6207s	
7690/16650 (epoch 23.093), train_loss = 1.17213542, grad/param norm = 3.1024e-01, time/batch = 16.6111s	
7691/16650 (epoch 23.096), train_loss = 0.92427967, grad/param norm = 2.5880e-01, time/batch = 15.3188s	
7692/16650 (epoch 23.099), train_loss = 0.99776837, grad/param norm = 2.7883e-01, time/batch = 16.6224s	
7693/16650 (epoch 23.102), train_loss = 0.99472917, grad/param norm = 2.4961e-01, time/batch = 16.0924s	
7694/16650 (epoch 23.105), train_loss = 1.03018031, grad/param norm = 2.8249e-01, time/batch = 17.2835s	
7695/16650 (epoch 23.108), train_loss = 1.01064446, grad/param norm = 2.6810e-01, time/batch = 15.6612s	
7696/16650 (epoch 23.111), train_loss = 1.07434811, grad/param norm = 2.6242e-01, time/batch = 16.5249s	
7697/16650 (epoch 23.114), train_loss = 1.09736588, grad/param norm = 3.1294e-01, time/batch = 16.6122s	
7698/16650 (epoch 23.117), train_loss = 1.16714752, grad/param norm = 3.0299e-01, time/batch = 17.0436s	
7699/16650 (epoch 23.120), train_loss = 0.91275557, grad/param norm = 2.3543e-01, time/batch = 17.3721s	
7700/16650 (epoch 23.123), train_loss = 0.95866873, grad/param norm = 2.4979e-01, time/batch = 15.3450s	
7701/16650 (epoch 23.126), train_loss = 1.00943462, grad/param norm = 2.6935e-01, time/batch = 16.4384s	
7702/16650 (epoch 23.129), train_loss = 0.99453479, grad/param norm = 2.5646e-01, time/batch = 16.3643s	
7703/16650 (epoch 23.132), train_loss = 0.97325064, grad/param norm = 2.6089e-01, time/batch = 18.2071s	
7704/16650 (epoch 23.135), train_loss = 1.05938362, grad/param norm = 2.5335e-01, time/batch = 14.9973s	
7705/16650 (epoch 23.138), train_loss = 1.04121127, grad/param norm = 2.4811e-01, time/batch = 17.2902s	
7706/16650 (epoch 23.141), train_loss = 1.02578380, grad/param norm = 2.7207e-01, time/batch = 16.8609s	
7707/16650 (epoch 23.144), train_loss = 0.99799358, grad/param norm = 2.8988e-01, time/batch = 15.8380s	
7708/16650 (epoch 23.147), train_loss = 1.13074632, grad/param norm = 2.5907e-01, time/batch = 15.5887s	
7709/16650 (epoch 23.150), train_loss = 1.24098701, grad/param norm = 4.0520e-01, time/batch = 16.1056s	
7710/16650 (epoch 23.153), train_loss = 1.06145372, grad/param norm = 3.1148e-01, time/batch = 15.8493s	
7711/16650 (epoch 23.156), train_loss = 0.91672710, grad/param norm = 2.4964e-01, time/batch = 17.2844s	
7712/16650 (epoch 23.159), train_loss = 1.04450173, grad/param norm = 2.7737e-01, time/batch = 17.0313s	
7713/16650 (epoch 23.162), train_loss = 1.10332150, grad/param norm = 2.6952e-01, time/batch = 17.4627s	
7714/16650 (epoch 23.165), train_loss = 1.11547245, grad/param norm = 2.9034e-01, time/batch = 17.6256s	
7715/16650 (epoch 23.168), train_loss = 0.84508595, grad/param norm = 2.1857e-01, time/batch = 15.1379s	
7716/16650 (epoch 23.171), train_loss = 1.08053083, grad/param norm = 2.4094e-01, time/batch = 16.7810s	
7717/16650 (epoch 23.174), train_loss = 0.82580445, grad/param norm = 2.5068e-01, time/batch = 14.5000s	
7718/16650 (epoch 23.177), train_loss = 0.97775517, grad/param norm = 2.6765e-01, time/batch = 16.3661s	
7719/16650 (epoch 23.180), train_loss = 1.11211887, grad/param norm = 2.9904e-01, time/batch = 16.8673s	
7720/16650 (epoch 23.183), train_loss = 1.22641431, grad/param norm = 3.1897e-01, time/batch = 16.8760s	
7721/16650 (epoch 23.186), train_loss = 1.06332758, grad/param norm = 3.4040e-01, time/batch = 17.1094s	
7722/16650 (epoch 23.189), train_loss = 0.92497865, grad/param norm = 2.7853e-01, time/batch = 15.1638s	
7723/16650 (epoch 23.192), train_loss = 0.94634426, grad/param norm = 2.7854e-01, time/batch = 17.1101s	
7724/16650 (epoch 23.195), train_loss = 0.94445968, grad/param norm = 2.8191e-01, time/batch = 16.6138s	
7725/16650 (epoch 23.198), train_loss = 0.81730558, grad/param norm = 2.0461e-01, time/batch = 17.5332s	
7726/16650 (epoch 23.201), train_loss = 0.92153872, grad/param norm = 2.6294e-01, time/batch = 16.4302s	
7727/16650 (epoch 23.204), train_loss = 0.99256734, grad/param norm = 2.5591e-01, time/batch = 17.1248s	
7728/16650 (epoch 23.207), train_loss = 1.01385373, grad/param norm = 2.9610e-01, time/batch = 16.6178s	
7729/16650 (epoch 23.210), train_loss = 0.94666187, grad/param norm = 2.6856e-01, time/batch = 14.7244s	
7730/16650 (epoch 23.213), train_loss = 1.06931591, grad/param norm = 2.8788e-01, time/batch = 14.6179s	
7731/16650 (epoch 23.216), train_loss = 0.93887445, grad/param norm = 2.5281e-01, time/batch = 17.7672s	
7732/16650 (epoch 23.219), train_loss = 0.98559722, grad/param norm = 2.6907e-01, time/batch = 17.4671s	
7733/16650 (epoch 23.222), train_loss = 1.00893868, grad/param norm = 2.4498e-01, time/batch = 16.3529s	
7734/16650 (epoch 23.225), train_loss = 0.98712524, grad/param norm = 2.6403e-01, time/batch = 16.7827s	
7735/16650 (epoch 23.228), train_loss = 0.88960761, grad/param norm = 2.3994e-01, time/batch = 18.1196s	
7736/16650 (epoch 23.231), train_loss = 0.96257063, grad/param norm = 2.6381e-01, time/batch = 16.5073s	
7737/16650 (epoch 23.234), train_loss = 1.16606835, grad/param norm = 2.8200e-01, time/batch = 17.0165s	
7738/16650 (epoch 23.237), train_loss = 1.03515301, grad/param norm = 2.7237e-01, time/batch = 17.5398s	
7739/16650 (epoch 23.240), train_loss = 1.03053883, grad/param norm = 2.8734e-01, time/batch = 15.7593s	
7740/16650 (epoch 23.243), train_loss = 0.97617318, grad/param norm = 2.6533e-01, time/batch = 14.7367s	
7741/16650 (epoch 23.246), train_loss = 1.11644519, grad/param norm = 2.9258e-01, time/batch = 16.5214s	
7742/16650 (epoch 23.249), train_loss = 0.87601338, grad/param norm = 2.5183e-01, time/batch = 17.7864s	
7743/16650 (epoch 23.252), train_loss = 0.93798245, grad/param norm = 2.4418e-01, time/batch = 15.1678s	
7744/16650 (epoch 23.255), train_loss = 1.05123815, grad/param norm = 2.7448e-01, time/batch = 16.1495s	
7745/16650 (epoch 23.258), train_loss = 1.09748606, grad/param norm = 2.7685e-01, time/batch = 17.7905s	
7746/16650 (epoch 23.261), train_loss = 0.99860332, grad/param norm = 2.4270e-01, time/batch = 14.9312s	
7747/16650 (epoch 23.264), train_loss = 0.93821648, grad/param norm = 2.4269e-01, time/batch = 16.5310s	
7748/16650 (epoch 23.267), train_loss = 0.96346996, grad/param norm = 2.9059e-01, time/batch = 16.8606s	
7749/16650 (epoch 23.270), train_loss = 1.00248869, grad/param norm = 2.5443e-01, time/batch = 16.7908s	
7750/16650 (epoch 23.273), train_loss = 1.10440349, grad/param norm = 2.5844e-01, time/batch = 16.6053s	
7751/16650 (epoch 23.276), train_loss = 1.00362504, grad/param norm = 2.3503e-01, time/batch = 15.9367s	
7752/16650 (epoch 23.279), train_loss = 0.98125444, grad/param norm = 2.4827e-01, time/batch = 15.0966s	
7753/16650 (epoch 23.282), train_loss = 0.87686465, grad/param norm = 2.2388e-01, time/batch = 16.1796s	
7754/16650 (epoch 23.285), train_loss = 0.89422362, grad/param norm = 2.3304e-01, time/batch = 17.1157s	
7755/16650 (epoch 23.288), train_loss = 0.92419974, grad/param norm = 2.5889e-01, time/batch = 15.5765s	
7756/16650 (epoch 23.291), train_loss = 0.75386665, grad/param norm = 2.1492e-01, time/batch = 16.9547s	
7757/16650 (epoch 23.294), train_loss = 0.86396784, grad/param norm = 2.0937e-01, time/batch = 17.7057s	
7758/16650 (epoch 23.297), train_loss = 0.94538130, grad/param norm = 2.2816e-01, time/batch = 16.5104s	
7759/16650 (epoch 23.300), train_loss = 0.75641469, grad/param norm = 2.1794e-01, time/batch = 15.8405s	
7760/16650 (epoch 23.303), train_loss = 0.84051821, grad/param norm = 2.2330e-01, time/batch = 16.8472s	
7761/16650 (epoch 23.306), train_loss = 1.05240103, grad/param norm = 2.5681e-01, time/batch = 16.8557s	
7762/16650 (epoch 23.309), train_loss = 1.05819593, grad/param norm = 2.8997e-01, time/batch = 16.5166s	
7763/16650 (epoch 23.312), train_loss = 0.88301573, grad/param norm = 2.9278e-01, time/batch = 17.6237s	
7764/16650 (epoch 23.315), train_loss = 0.69120238, grad/param norm = 2.1884e-01, time/batch = 17.0444s	
7765/16650 (epoch 23.318), train_loss = 0.79993394, grad/param norm = 2.3099e-01, time/batch = 15.9346s	
7766/16650 (epoch 23.321), train_loss = 1.11136328, grad/param norm = 2.9771e-01, time/batch = 16.8504s	
7767/16650 (epoch 23.324), train_loss = 0.90990761, grad/param norm = 2.6438e-01, time/batch = 17.2089s	
7768/16650 (epoch 23.327), train_loss = 1.02339816, grad/param norm = 3.1332e-01, time/batch = 17.6256s	
7769/16650 (epoch 23.330), train_loss = 1.00549199, grad/param norm = 2.8746e-01, time/batch = 16.1062s	
7770/16650 (epoch 23.333), train_loss = 1.03276623, grad/param norm = 2.8133e-01, time/batch = 17.7840s	
7771/16650 (epoch 23.336), train_loss = 0.87879110, grad/param norm = 2.7740e-01, time/batch = 16.0166s	
7772/16650 (epoch 23.339), train_loss = 0.92663409, grad/param norm = 2.5468e-01, time/batch = 16.0926s	
7773/16650 (epoch 23.342), train_loss = 0.88034248, grad/param norm = 2.5102e-01, time/batch = 16.9508s	
7774/16650 (epoch 23.345), train_loss = 0.84452205, grad/param norm = 2.3922e-01, time/batch = 16.6974s	
7775/16650 (epoch 23.348), train_loss = 0.97508555, grad/param norm = 3.0003e-01, time/batch = 17.3892s	
7776/16650 (epoch 23.351), train_loss = 1.03179613, grad/param norm = 2.7747e-01, time/batch = 16.0035s	
7777/16650 (epoch 23.354), train_loss = 1.03528061, grad/param norm = 2.6996e-01, time/batch = 16.5116s	
7778/16650 (epoch 23.357), train_loss = 0.99377757, grad/param norm = 2.8227e-01, time/batch = 14.8075s	
7779/16650 (epoch 23.360), train_loss = 0.99707420, grad/param norm = 2.6718e-01, time/batch = 17.1886s	
7780/16650 (epoch 23.363), train_loss = 1.09207966, grad/param norm = 2.9326e-01, time/batch = 16.8446s	
7781/16650 (epoch 23.366), train_loss = 1.11781121, grad/param norm = 3.0744e-01, time/batch = 16.6793s	
7782/16650 (epoch 23.369), train_loss = 0.98407832, grad/param norm = 2.7611e-01, time/batch = 17.4598s	
7783/16650 (epoch 23.372), train_loss = 0.97823387, grad/param norm = 2.4434e-01, time/batch = 16.1168s	
7784/16650 (epoch 23.375), train_loss = 0.99271943, grad/param norm = 2.4244e-01, time/batch = 16.7852s	
7785/16650 (epoch 23.378), train_loss = 0.89854187, grad/param norm = 2.2640e-01, time/batch = 18.0373s	
7786/16650 (epoch 23.381), train_loss = 0.98802669, grad/param norm = 2.3838e-01, time/batch = 17.4551s	
7787/16650 (epoch 23.384), train_loss = 1.13058999, grad/param norm = 2.7483e-01, time/batch = 15.9315s	
7788/16650 (epoch 23.387), train_loss = 0.77826018, grad/param norm = 2.1616e-01, time/batch = 17.0328s	
7789/16650 (epoch 23.390), train_loss = 1.06925283, grad/param norm = 2.5704e-01, time/batch = 16.5440s	
7790/16650 (epoch 23.393), train_loss = 0.92802274, grad/param norm = 2.8695e-01, time/batch = 14.0859s	
7791/16650 (epoch 23.396), train_loss = 1.09083257, grad/param norm = 3.0467e-01, time/batch = 13.4246s	
7792/16650 (epoch 23.399), train_loss = 1.02593334, grad/param norm = 2.8071e-01, time/batch = 13.3604s	
7793/16650 (epoch 23.402), train_loss = 0.88740097, grad/param norm = 2.5444e-01, time/batch = 15.9163s	
7794/16650 (epoch 23.405), train_loss = 0.82333097, grad/param norm = 2.7079e-01, time/batch = 17.7520s	
7795/16650 (epoch 23.408), train_loss = 1.03960913, grad/param norm = 2.8725e-01, time/batch = 28.7411s	
7796/16650 (epoch 23.411), train_loss = 0.87362136, grad/param norm = 2.6730e-01, time/batch = 14.9291s	
7797/16650 (epoch 23.414), train_loss = 0.88352655, grad/param norm = 2.7165e-01, time/batch = 15.7767s	
7798/16650 (epoch 23.417), train_loss = 0.84590505, grad/param norm = 2.6191e-01, time/batch = 17.8685s	
7799/16650 (epoch 23.420), train_loss = 0.84800022, grad/param norm = 2.5788e-01, time/batch = 17.0464s	
7800/16650 (epoch 23.423), train_loss = 0.72642023, grad/param norm = 2.1828e-01, time/batch = 17.7742s	
7801/16650 (epoch 23.426), train_loss = 0.84276071, grad/param norm = 2.6279e-01, time/batch = 14.6546s	
7802/16650 (epoch 23.429), train_loss = 1.05982443, grad/param norm = 2.5835e-01, time/batch = 17.0399s	
7803/16650 (epoch 23.432), train_loss = 1.03944853, grad/param norm = 2.7862e-01, time/batch = 15.7634s	
7804/16650 (epoch 23.435), train_loss = 1.15283424, grad/param norm = 2.7958e-01, time/batch = 16.8676s	
7805/16650 (epoch 23.438), train_loss = 1.14989487, grad/param norm = 3.2947e-01, time/batch = 17.2714s	
7806/16650 (epoch 23.441), train_loss = 0.99000036, grad/param norm = 2.9971e-01, time/batch = 16.2554s	
7807/16650 (epoch 23.444), train_loss = 0.90281495, grad/param norm = 2.7182e-01, time/batch = 16.1977s	
7808/16650 (epoch 23.447), train_loss = 0.93849947, grad/param norm = 2.9452e-01, time/batch = 15.6815s	
7809/16650 (epoch 23.450), train_loss = 0.89508067, grad/param norm = 2.4207e-01, time/batch = 15.0177s	
7810/16650 (epoch 23.453), train_loss = 0.89962619, grad/param norm = 2.4200e-01, time/batch = 17.8737s	
7811/16650 (epoch 23.456), train_loss = 0.81580838, grad/param norm = 2.1305e-01, time/batch = 14.0791s	
7812/16650 (epoch 23.459), train_loss = 0.89377573, grad/param norm = 2.5242e-01, time/batch = 15.1710s	
7813/16650 (epoch 23.462), train_loss = 1.10671832, grad/param norm = 3.2483e-01, time/batch = 17.7068s	
7814/16650 (epoch 23.465), train_loss = 0.90518961, grad/param norm = 2.8311e-01, time/batch = 16.4438s	
7815/16650 (epoch 23.468), train_loss = 0.76563664, grad/param norm = 2.3992e-01, time/batch = 16.7020s	
7816/16650 (epoch 23.471), train_loss = 0.62966568, grad/param norm = 2.0079e-01, time/batch = 14.8239s	
7817/16650 (epoch 23.474), train_loss = 0.82260328, grad/param norm = 2.4452e-01, time/batch = 17.6163s	
7818/16650 (epoch 23.477), train_loss = 1.01074558, grad/param norm = 2.7618e-01, time/batch = 17.7906s	
7819/16650 (epoch 23.480), train_loss = 1.02901572, grad/param norm = 2.9597e-01, time/batch = 15.2346s	
7820/16650 (epoch 23.483), train_loss = 1.06701576, grad/param norm = 2.7637e-01, time/batch = 17.3714s	
7821/16650 (epoch 23.486), train_loss = 0.86371064, grad/param norm = 2.2913e-01, time/batch = 17.3728s	
7822/16650 (epoch 23.489), train_loss = 0.89734591, grad/param norm = 2.5126e-01, time/batch = 17.4372s	
7823/16650 (epoch 23.492), train_loss = 0.94895698, grad/param norm = 2.4639e-01, time/batch = 16.6718s	
7824/16650 (epoch 23.495), train_loss = 0.83494816, grad/param norm = 2.5624e-01, time/batch = 17.5349s	
7825/16650 (epoch 23.498), train_loss = 0.91170981, grad/param norm = 2.6191e-01, time/batch = 17.7086s	
7826/16650 (epoch 23.502), train_loss = 1.10283354, grad/param norm = 3.1566e-01, time/batch = 15.9360s	
7827/16650 (epoch 23.505), train_loss = 1.00434548, grad/param norm = 2.5309e-01, time/batch = 16.7030s	
7828/16650 (epoch 23.508), train_loss = 0.99179920, grad/param norm = 2.7140e-01, time/batch = 16.6088s	
7829/16650 (epoch 23.511), train_loss = 1.07272001, grad/param norm = 2.5879e-01, time/batch = 18.0447s	
7830/16650 (epoch 23.514), train_loss = 0.81145436, grad/param norm = 2.5323e-01, time/batch = 14.2950s	
7831/16650 (epoch 23.517), train_loss = 0.93442689, grad/param norm = 2.7384e-01, time/batch = 17.4336s	
7832/16650 (epoch 23.520), train_loss = 0.85894138, grad/param norm = 2.4738e-01, time/batch = 17.0116s	
7833/16650 (epoch 23.523), train_loss = 0.92468296, grad/param norm = 2.5982e-01, time/batch = 16.1869s	
7834/16650 (epoch 23.526), train_loss = 1.03382915, grad/param norm = 2.6642e-01, time/batch = 16.9381s	
7835/16650 (epoch 23.529), train_loss = 1.09968354, grad/param norm = 2.9784e-01, time/batch = 17.6210s	
7836/16650 (epoch 23.532), train_loss = 0.73503483, grad/param norm = 2.3502e-01, time/batch = 16.3687s	
7837/16650 (epoch 23.535), train_loss = 0.82772697, grad/param norm = 3.2381e-01, time/batch = 15.7748s	
7838/16650 (epoch 23.538), train_loss = 0.80780391, grad/param norm = 2.4555e-01, time/batch = 15.8314s	
7839/16650 (epoch 23.541), train_loss = 1.06809637, grad/param norm = 2.6449e-01, time/batch = 17.8803s	
7840/16650 (epoch 23.544), train_loss = 1.14248261, grad/param norm = 4.6960e-01, time/batch = 16.6922s	
7841/16650 (epoch 23.547), train_loss = 0.83751172, grad/param norm = 2.4764e-01, time/batch = 16.2383s	
7842/16650 (epoch 23.550), train_loss = 0.94760048, grad/param norm = 2.7294e-01, time/batch = 17.0334s	
7843/16650 (epoch 23.553), train_loss = 0.93476329, grad/param norm = 2.8474e-01, time/batch = 16.9655s	
7844/16650 (epoch 23.556), train_loss = 0.87482159, grad/param norm = 2.4635e-01, time/batch = 16.0270s	
7845/16650 (epoch 23.559), train_loss = 0.76428560, grad/param norm = 2.4567e-01, time/batch = 18.0188s	
7846/16650 (epoch 23.562), train_loss = 0.89507739, grad/param norm = 2.5698e-01, time/batch = 15.7826s	
7847/16650 (epoch 23.565), train_loss = 0.75561409, grad/param norm = 2.5730e-01, time/batch = 16.7219s	
7848/16650 (epoch 23.568), train_loss = 0.75331471, grad/param norm = 2.3965e-01, time/batch = 15.9181s	
7849/16650 (epoch 23.571), train_loss = 0.80972157, grad/param norm = 3.2490e-01, time/batch = 17.9595s	
7850/16650 (epoch 23.574), train_loss = 0.89704229, grad/param norm = 2.4329e-01, time/batch = 14.6492s	
7851/16650 (epoch 23.577), train_loss = 0.87820771, grad/param norm = 2.4630e-01, time/batch = 16.6895s	
7852/16650 (epoch 23.580), train_loss = 0.77535421, grad/param norm = 2.2899e-01, time/batch = 17.2394s	
7853/16650 (epoch 23.583), train_loss = 0.92308824, grad/param norm = 2.7807e-01, time/batch = 17.6390s	
7854/16650 (epoch 23.586), train_loss = 0.84077261, grad/param norm = 3.1497e-01, time/batch = 17.2970s	
7855/16650 (epoch 23.589), train_loss = 0.80325530, grad/param norm = 2.1038e-01, time/batch = 16.2662s	
7856/16650 (epoch 23.592), train_loss = 0.93965884, grad/param norm = 2.5991e-01, time/batch = 16.2829s	
7857/16650 (epoch 23.595), train_loss = 0.86322649, grad/param norm = 2.6429e-01, time/batch = 16.1233s	
7858/16650 (epoch 23.598), train_loss = 0.89573667, grad/param norm = 2.4904e-01, time/batch = 14.9822s	
7859/16650 (epoch 23.601), train_loss = 0.86743568, grad/param norm = 3.3716e-01, time/batch = 15.8577s	
7860/16650 (epoch 23.604), train_loss = 1.01963840, grad/param norm = 2.8842e-01, time/batch = 14.3998s	
7861/16650 (epoch 23.607), train_loss = 0.97117041, grad/param norm = 2.4948e-01, time/batch = 16.1195s	
7862/16650 (epoch 23.610), train_loss = 0.82851498, grad/param norm = 2.3701e-01, time/batch = 15.7537s	
7863/16650 (epoch 23.613), train_loss = 1.07396529, grad/param norm = 2.8256e-01, time/batch = 15.8551s	
7864/16650 (epoch 23.616), train_loss = 1.05049694, grad/param norm = 3.2711e-01, time/batch = 16.8719s	
7865/16650 (epoch 23.619), train_loss = 0.77615740, grad/param norm = 2.3489e-01, time/batch = 18.2071s	
7866/16650 (epoch 23.622), train_loss = 0.74334351, grad/param norm = 2.3495e-01, time/batch = 15.6692s	
7867/16650 (epoch 23.625), train_loss = 0.87107928, grad/param norm = 2.3526e-01, time/batch = 17.5393s	
7868/16650 (epoch 23.628), train_loss = 0.87690082, grad/param norm = 2.8759e-01, time/batch = 15.9170s	
7869/16650 (epoch 23.631), train_loss = 0.95875558, grad/param norm = 3.0608e-01, time/batch = 17.0813s	
7870/16650 (epoch 23.634), train_loss = 1.12662207, grad/param norm = 3.1361e-01, time/batch = 15.8642s	
7871/16650 (epoch 23.637), train_loss = 1.11452437, grad/param norm = 2.5278e-01, time/batch = 15.6866s	
7872/16650 (epoch 23.640), train_loss = 0.88359483, grad/param norm = 2.9182e-01, time/batch = 15.8417s	
7873/16650 (epoch 23.643), train_loss = 0.99189263, grad/param norm = 2.3865e-01, time/batch = 16.0895s	
7874/16650 (epoch 23.646), train_loss = 1.01573067, grad/param norm = 2.7466e-01, time/batch = 16.0208s	
7875/16650 (epoch 23.649), train_loss = 0.93535616, grad/param norm = 2.6707e-01, time/batch = 17.4491s	
7876/16650 (epoch 23.652), train_loss = 1.02387708, grad/param norm = 2.5338e-01, time/batch = 17.6189s	
7877/16650 (epoch 23.655), train_loss = 0.96760902, grad/param norm = 2.6489e-01, time/batch = 15.2825s	
7878/16650 (epoch 23.658), train_loss = 0.84607363, grad/param norm = 2.8233e-01, time/batch = 17.1857s	
7879/16650 (epoch 23.661), train_loss = 0.98773780, grad/param norm = 2.9356e-01, time/batch = 16.0028s	
7880/16650 (epoch 23.664), train_loss = 0.94816092, grad/param norm = 2.4549e-01, time/batch = 16.8516s	
7881/16650 (epoch 23.667), train_loss = 1.05158896, grad/param norm = 2.7313e-01, time/batch = 17.3468s	
7882/16650 (epoch 23.670), train_loss = 0.80934433, grad/param norm = 2.5059e-01, time/batch = 17.0411s	
7883/16650 (epoch 23.673), train_loss = 0.85538945, grad/param norm = 2.3967e-01, time/batch = 17.9493s	
7884/16650 (epoch 23.676), train_loss = 0.95580554, grad/param norm = 2.8051e-01, time/batch = 15.2515s	
7885/16650 (epoch 23.679), train_loss = 0.82932117, grad/param norm = 2.4228e-01, time/batch = 17.6078s	
7886/16650 (epoch 23.682), train_loss = 0.95195252, grad/param norm = 2.7287e-01, time/batch = 16.4529s	
7887/16650 (epoch 23.685), train_loss = 0.81231070, grad/param norm = 2.8147e-01, time/batch = 16.2809s	
7888/16650 (epoch 23.688), train_loss = 0.98862960, grad/param norm = 2.4108e-01, time/batch = 16.1883s	
7889/16650 (epoch 23.691), train_loss = 0.98624289, grad/param norm = 2.6062e-01, time/batch = 15.9293s	
7890/16650 (epoch 23.694), train_loss = 0.84020078, grad/param norm = 2.5051e-01, time/batch = 16.1825s	
7891/16650 (epoch 23.697), train_loss = 0.79076859, grad/param norm = 2.1894e-01, time/batch = 16.0253s	
7892/16650 (epoch 23.700), train_loss = 1.01627897, grad/param norm = 2.8288e-01, time/batch = 16.9451s	
7893/16650 (epoch 23.703), train_loss = 0.82444750, grad/param norm = 2.6077e-01, time/batch = 15.6038s	
7894/16650 (epoch 23.706), train_loss = 0.92195106, grad/param norm = 2.6455e-01, time/batch = 16.5147s	
7895/16650 (epoch 23.709), train_loss = 0.83722186, grad/param norm = 2.2872e-01, time/batch = 15.3266s	
7896/16650 (epoch 23.712), train_loss = 0.86248619, grad/param norm = 2.7516e-01, time/batch = 17.5311s	
7897/16650 (epoch 23.715), train_loss = 1.00350888, grad/param norm = 2.5720e-01, time/batch = 16.9538s	
7898/16650 (epoch 23.718), train_loss = 1.04099311, grad/param norm = 2.6242e-01, time/batch = 16.1796s	
7899/16650 (epoch 23.721), train_loss = 1.00784363, grad/param norm = 2.5375e-01, time/batch = 16.0210s	
7900/16650 (epoch 23.724), train_loss = 1.04355437, grad/param norm = 3.0904e-01, time/batch = 16.9561s	
7901/16650 (epoch 23.727), train_loss = 0.99383880, grad/param norm = 2.5692e-01, time/batch = 17.3003s	
7902/16650 (epoch 23.730), train_loss = 0.88515348, grad/param norm = 2.5301e-01, time/batch = 15.7749s	
7903/16650 (epoch 23.733), train_loss = 1.03404550, grad/param norm = 2.6987e-01, time/batch = 17.6221s	
7904/16650 (epoch 23.736), train_loss = 0.77750053, grad/param norm = 2.4492e-01, time/batch = 18.0400s	
7905/16650 (epoch 23.739), train_loss = 0.92517529, grad/param norm = 2.5400e-01, time/batch = 16.1918s	
7906/16650 (epoch 23.742), train_loss = 0.92848857, grad/param norm = 2.5698e-01, time/batch = 16.5121s	
7907/16650 (epoch 23.745), train_loss = 0.74411134, grad/param norm = 2.2805e-01, time/batch = 16.0315s	
7908/16650 (epoch 23.748), train_loss = 0.79769988, grad/param norm = 2.3856e-01, time/batch = 17.6267s	
7909/16650 (epoch 23.751), train_loss = 0.96391073, grad/param norm = 3.4145e-01, time/batch = 15.7643s	
7910/16650 (epoch 23.754), train_loss = 1.13823082, grad/param norm = 3.1364e-01, time/batch = 15.9465s	
7911/16650 (epoch 23.757), train_loss = 1.08161488, grad/param norm = 2.9355e-01, time/batch = 17.4530s	
7912/16650 (epoch 23.760), train_loss = 0.91955621, grad/param norm = 2.5900e-01, time/batch = 16.0229s	
7913/16650 (epoch 23.763), train_loss = 0.84847023, grad/param norm = 2.3141e-01, time/batch = 16.0928s	
7914/16650 (epoch 23.766), train_loss = 0.92092812, grad/param norm = 2.4612e-01, time/batch = 16.4566s	
7915/16650 (epoch 23.769), train_loss = 0.96911011, grad/param norm = 2.6007e-01, time/batch = 16.9945s	
7916/16650 (epoch 23.772), train_loss = 0.89525454, grad/param norm = 2.2408e-01, time/batch = 16.5857s	
7917/16650 (epoch 23.775), train_loss = 0.89450443, grad/param norm = 2.2929e-01, time/batch = 15.2543s	
7918/16650 (epoch 23.778), train_loss = 0.93322020, grad/param norm = 2.4363e-01, time/batch = 17.1055s	
7919/16650 (epoch 23.781), train_loss = 1.04510409, grad/param norm = 2.3409e-01, time/batch = 17.1168s	
7920/16650 (epoch 23.784), train_loss = 0.99618578, grad/param norm = 2.5786e-01, time/batch = 15.8455s	
7921/16650 (epoch 23.787), train_loss = 1.01370855, grad/param norm = 2.5836e-01, time/batch = 16.7928s	
7922/16650 (epoch 23.790), train_loss = 0.95915661, grad/param norm = 2.1698e-01, time/batch = 17.4423s	
7923/16650 (epoch 23.793), train_loss = 0.83148757, grad/param norm = 2.4180e-01, time/batch = 16.1977s	
7924/16650 (epoch 23.796), train_loss = 1.22644984, grad/param norm = 2.9880e-01, time/batch = 16.0128s	
7925/16650 (epoch 23.799), train_loss = 1.13609125, grad/param norm = 2.8578e-01, time/batch = 15.2559s	
7926/16650 (epoch 23.802), train_loss = 0.98991140, grad/param norm = 2.5333e-01, time/batch = 17.0329s	
7927/16650 (epoch 23.805), train_loss = 0.93893479, grad/param norm = 2.5130e-01, time/batch = 16.3755s	
7928/16650 (epoch 23.808), train_loss = 0.99204402, grad/param norm = 2.5238e-01, time/batch = 16.1784s	
7929/16650 (epoch 23.811), train_loss = 1.06515726, grad/param norm = 2.6377e-01, time/batch = 17.0161s	
7930/16650 (epoch 23.814), train_loss = 0.83137781, grad/param norm = 2.2782e-01, time/batch = 17.6136s	
7931/16650 (epoch 23.817), train_loss = 0.89305581, grad/param norm = 2.5864e-01, time/batch = 14.9731s	
7932/16650 (epoch 23.820), train_loss = 1.00416991, grad/param norm = 2.6772e-01, time/batch = 16.4080s	
7933/16650 (epoch 23.823), train_loss = 0.92043144, grad/param norm = 2.5692e-01, time/batch = 16.7832s	
7934/16650 (epoch 23.826), train_loss = 0.91439391, grad/param norm = 2.4855e-01, time/batch = 16.6870s	
7935/16650 (epoch 23.829), train_loss = 0.99075945, grad/param norm = 2.6399e-01, time/batch = 16.7683s	
7936/16650 (epoch 23.832), train_loss = 1.04266723, grad/param norm = 2.9727e-01, time/batch = 15.0260s	
7937/16650 (epoch 23.835), train_loss = 1.02526732, grad/param norm = 3.0821e-01, time/batch = 17.4629s	
7938/16650 (epoch 23.838), train_loss = 0.86438940, grad/param norm = 2.4033e-01, time/batch = 16.2540s	
7939/16650 (epoch 23.841), train_loss = 0.89005968, grad/param norm = 2.6111e-01, time/batch = 16.8553s	
7940/16650 (epoch 23.844), train_loss = 0.87922015, grad/param norm = 2.2087e-01, time/batch = 17.2545s	
7941/16650 (epoch 23.847), train_loss = 1.03755886, grad/param norm = 2.8975e-01, time/batch = 16.7902s	
7942/16650 (epoch 23.850), train_loss = 0.82875203, grad/param norm = 2.9681e-01, time/batch = 15.6457s	
7943/16650 (epoch 23.853), train_loss = 0.95493423, grad/param norm = 2.6949e-01, time/batch = 17.0322s	
7944/16650 (epoch 23.856), train_loss = 0.88329217, grad/param norm = 2.6820e-01, time/batch = 17.9488s	
7945/16650 (epoch 23.859), train_loss = 1.04312681, grad/param norm = 2.8347e-01, time/batch = 16.1881s	
7946/16650 (epoch 23.862), train_loss = 0.93368403, grad/param norm = 2.3568e-01, time/batch = 16.6906s	
7947/16650 (epoch 23.865), train_loss = 0.78818955, grad/param norm = 2.2373e-01, time/batch = 16.9144s	
7948/16650 (epoch 23.868), train_loss = 1.00238802, grad/param norm = 2.6206e-01, time/batch = 18.1202s	
7949/16650 (epoch 23.871), train_loss = 0.97279854, grad/param norm = 2.5333e-01, time/batch = 16.4355s	
7950/16650 (epoch 23.874), train_loss = 0.98410628, grad/param norm = 2.5037e-01, time/batch = 17.4602s	
7951/16650 (epoch 23.877), train_loss = 0.96493138, grad/param norm = 2.4912e-01, time/batch = 16.5290s	
7952/16650 (epoch 23.880), train_loss = 0.85190465, grad/param norm = 2.5743e-01, time/batch = 16.4355s	
7953/16650 (epoch 23.883), train_loss = 0.94660975, grad/param norm = 2.5640e-01, time/batch = 17.5348s	
7954/16650 (epoch 23.886), train_loss = 0.95899827, grad/param norm = 2.7471e-01, time/batch = 17.1172s	
7955/16650 (epoch 23.889), train_loss = 0.80509593, grad/param norm = 2.4283e-01, time/batch = 17.6432s	
7956/16650 (epoch 23.892), train_loss = 0.94138925, grad/param norm = 2.5461e-01, time/batch = 14.4700s	
7957/16650 (epoch 23.895), train_loss = 0.97781774, grad/param norm = 2.6677e-01, time/batch = 14.7393s	
7958/16650 (epoch 23.898), train_loss = 0.94925128, grad/param norm = 2.7525e-01, time/batch = 17.7934s	
7959/16650 (epoch 23.901), train_loss = 0.93832181, grad/param norm = 2.5477e-01, time/batch = 16.9486s	
7960/16650 (epoch 23.904), train_loss = 0.87182549, grad/param norm = 2.5469e-01, time/batch = 15.5960s	
7961/16650 (epoch 23.907), train_loss = 0.99645955, grad/param norm = 2.8360e-01, time/batch = 17.1973s	
7962/16650 (epoch 23.910), train_loss = 1.00137911, grad/param norm = 2.8485e-01, time/batch = 18.1245s	
7963/16650 (epoch 23.913), train_loss = 0.88041290, grad/param norm = 2.6244e-01, time/batch = 16.6947s	
7964/16650 (epoch 23.916), train_loss = 0.93154441, grad/param norm = 2.7293e-01, time/batch = 17.5228s	
7965/16650 (epoch 23.919), train_loss = 1.09858523, grad/param norm = 2.7399e-01, time/batch = 15.6185s	
7966/16650 (epoch 23.922), train_loss = 1.03652574, grad/param norm = 2.6969e-01, time/batch = 17.7779s	
7967/16650 (epoch 23.925), train_loss = 0.88930229, grad/param norm = 2.6176e-01, time/batch = 17.0137s	
7968/16650 (epoch 23.928), train_loss = 0.94325971, grad/param norm = 2.5509e-01, time/batch = 17.2818s	
7969/16650 (epoch 23.931), train_loss = 1.01555334, grad/param norm = 2.8090e-01, time/batch = 17.1270s	
7970/16650 (epoch 23.934), train_loss = 0.82599183, grad/param norm = 2.7004e-01, time/batch = 15.8359s	
7971/16650 (epoch 23.937), train_loss = 0.85720454, grad/param norm = 2.5828e-01, time/batch = 16.9418s	
7972/16650 (epoch 23.940), train_loss = 0.89405920, grad/param norm = 2.2027e-01, time/batch = 17.5043s	
7973/16650 (epoch 23.943), train_loss = 0.96493851, grad/param norm = 2.6170e-01, time/batch = 16.6901s	
7974/16650 (epoch 23.946), train_loss = 0.83978443, grad/param norm = 2.1758e-01, time/batch = 16.3331s	
7975/16650 (epoch 23.949), train_loss = 0.84132648, grad/param norm = 2.8526e-01, time/batch = 15.3379s	
7976/16650 (epoch 23.952), train_loss = 0.79091184, grad/param norm = 2.4810e-01, time/batch = 16.8254s	
7977/16650 (epoch 23.955), train_loss = 0.91677869, grad/param norm = 2.4025e-01, time/batch = 15.8572s	
7978/16650 (epoch 23.958), train_loss = 1.00640288, grad/param norm = 3.4278e-01, time/batch = 15.1189s	
7979/16650 (epoch 23.961), train_loss = 0.93325369, grad/param norm = 2.4438e-01, time/batch = 15.1658s	
7980/16650 (epoch 23.964), train_loss = 0.85508774, grad/param norm = 2.7561e-01, time/batch = 18.0518s	
7981/16650 (epoch 23.967), train_loss = 1.06869787, grad/param norm = 2.9302e-01, time/batch = 15.5295s	
7982/16650 (epoch 23.970), train_loss = 0.87075237, grad/param norm = 2.4946e-01, time/batch = 17.5358s	
7983/16650 (epoch 23.973), train_loss = 0.89067211, grad/param norm = 2.6173e-01, time/batch = 17.3671s	
7984/16650 (epoch 23.976), train_loss = 0.86233605, grad/param norm = 2.6848e-01, time/batch = 17.2898s	
7985/16650 (epoch 23.979), train_loss = 0.97399104, grad/param norm = 3.8303e-01, time/batch = 16.5217s	
7986/16650 (epoch 23.982), train_loss = 0.99228760, grad/param norm = 2.6163e-01, time/batch = 16.7850s	
7987/16650 (epoch 23.985), train_loss = 0.93546298, grad/param norm = 2.7750e-01, time/batch = 16.2829s	
7988/16650 (epoch 23.988), train_loss = 1.07186585, grad/param norm = 3.0114e-01, time/batch = 15.3080s	
7989/16650 (epoch 23.991), train_loss = 0.85876078, grad/param norm = 2.6391e-01, time/batch = 25.6285s	
7990/16650 (epoch 23.994), train_loss = 0.86988339, grad/param norm = 2.3560e-01, time/batch = 17.6247s	
7991/16650 (epoch 23.997), train_loss = 0.93670996, grad/param norm = 2.7664e-01, time/batch = 16.7599s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
7992/16650 (epoch 24.000), train_loss = 1.02015630, grad/param norm = 3.1556e-01, time/batch = 15.0767s	
7993/16650 (epoch 24.003), train_loss = 1.05813760, grad/param norm = 3.7377e-01, time/batch = 15.7601s	
7994/16650 (epoch 24.006), train_loss = 1.01628051, grad/param norm = 2.7941e-01, time/batch = 17.1037s	
7995/16650 (epoch 24.009), train_loss = 1.09325050, grad/param norm = 2.4906e-01, time/batch = 15.3449s	
7996/16650 (epoch 24.012), train_loss = 1.08410039, grad/param norm = 2.8751e-01, time/batch = 16.5261s	
7997/16650 (epoch 24.015), train_loss = 0.94377990, grad/param norm = 2.6826e-01, time/batch = 17.7915s	
7998/16650 (epoch 24.018), train_loss = 0.80788199, grad/param norm = 2.5128e-01, time/batch = 17.4503s	
7999/16650 (epoch 24.021), train_loss = 1.04977624, grad/param norm = 2.9000e-01, time/batch = 16.8632s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch24.02_1.9563.t7	
8000/16650 (epoch 24.024), train_loss = 0.94312244, grad/param norm = 2.6805e-01, time/batch = 15.7039s	
8001/16650 (epoch 24.027), train_loss = 1.28087960, grad/param norm = 3.1726e-01, time/batch = 16.4978s	
8002/16650 (epoch 24.030), train_loss = 0.83343233, grad/param norm = 2.4809e-01, time/batch = 15.9273s	
8003/16650 (epoch 24.033), train_loss = 0.97078128, grad/param norm = 2.6017e-01, time/batch = 16.5451s	
8004/16650 (epoch 24.036), train_loss = 0.72298987, grad/param norm = 2.6228e-01, time/batch = 17.3768s	
8005/16650 (epoch 24.039), train_loss = 1.04150846, grad/param norm = 2.5914e-01, time/batch = 19.4638s	
8006/16650 (epoch 24.042), train_loss = 1.03564305, grad/param norm = 2.7906e-01, time/batch = 28.1930s	
8007/16650 (epoch 24.045), train_loss = 0.90402851, grad/param norm = 2.5957e-01, time/batch = 14.9173s	
8008/16650 (epoch 24.048), train_loss = 1.04531904, grad/param norm = 3.1146e-01, time/batch = 15.0099s	
8009/16650 (epoch 24.051), train_loss = 0.91171822, grad/param norm = 2.4371e-01, time/batch = 16.0895s	
8010/16650 (epoch 24.054), train_loss = 0.94940058, grad/param norm = 2.8608e-01, time/batch = 17.5371s	
8011/16650 (epoch 24.057), train_loss = 0.96742715, grad/param norm = 2.7539e-01, time/batch = 17.2111s	
8012/16650 (epoch 24.060), train_loss = 0.80421072, grad/param norm = 2.4171e-01, time/batch = 16.3392s	
8013/16650 (epoch 24.063), train_loss = 0.92008869, grad/param norm = 2.5803e-01, time/batch = 16.1533s	
8014/16650 (epoch 24.066), train_loss = 1.10523714, grad/param norm = 2.8795e-01, time/batch = 14.5789s	
8015/16650 (epoch 24.069), train_loss = 1.02702242, grad/param norm = 3.0773e-01, time/batch = 16.5080s	
8016/16650 (epoch 24.072), train_loss = 0.92204390, grad/param norm = 2.5545e-01, time/batch = 16.8505s	
8017/16650 (epoch 24.075), train_loss = 1.01298388, grad/param norm = 2.5154e-01, time/batch = 16.7841s	
8018/16650 (epoch 24.078), train_loss = 1.07507854, grad/param norm = 2.5822e-01, time/batch = 17.0280s	
8019/16650 (epoch 24.081), train_loss = 0.97371844, grad/param norm = 2.5614e-01, time/batch = 15.4174s	
8020/16650 (epoch 24.084), train_loss = 1.01592566, grad/param norm = 2.6630e-01, time/batch = 17.6972s	
8021/16650 (epoch 24.087), train_loss = 0.94389670, grad/param norm = 2.5843e-01, time/batch = 16.2907s	
8022/16650 (epoch 24.090), train_loss = 0.94668348, grad/param norm = 2.6940e-01, time/batch = 17.3758s	
8023/16650 (epoch 24.093), train_loss = 1.15117304, grad/param norm = 3.0475e-01, time/batch = 16.3336s	
8024/16650 (epoch 24.096), train_loss = 0.89641464, grad/param norm = 2.5199e-01, time/batch = 17.4608s	
8025/16650 (epoch 24.099), train_loss = 0.96491038, grad/param norm = 2.6045e-01, time/batch = 17.6249s	
8026/16650 (epoch 24.102), train_loss = 0.96254499, grad/param norm = 2.6469e-01, time/batch = 16.2768s	
8027/16650 (epoch 24.105), train_loss = 1.00153781, grad/param norm = 2.6759e-01, time/batch = 16.0266s	
8028/16650 (epoch 24.108), train_loss = 0.98152815, grad/param norm = 2.5444e-01, time/batch = 16.2393s	
8029/16650 (epoch 24.111), train_loss = 1.04150795, grad/param norm = 2.4965e-01, time/batch = 16.0786s	
8030/16650 (epoch 24.114), train_loss = 1.05378998, grad/param norm = 3.0584e-01, time/batch = 16.4395s	
8031/16650 (epoch 24.117), train_loss = 1.12986692, grad/param norm = 2.7406e-01, time/batch = 16.0409s	
8032/16650 (epoch 24.120), train_loss = 0.90961703, grad/param norm = 2.4422e-01, time/batch = 17.2240s	
8033/16650 (epoch 24.123), train_loss = 0.93714787, grad/param norm = 2.5379e-01, time/batch = 16.6086s	
8034/16650 (epoch 24.126), train_loss = 0.97641723, grad/param norm = 2.5804e-01, time/batch = 16.8638s	
8035/16650 (epoch 24.129), train_loss = 0.97753196, grad/param norm = 2.7085e-01, time/batch = 17.6235s	
8036/16650 (epoch 24.132), train_loss = 0.95509676, grad/param norm = 2.6548e-01, time/batch = 15.5745s	
8037/16650 (epoch 24.135), train_loss = 1.05333178, grad/param norm = 2.7497e-01, time/batch = 16.3591s	
8038/16650 (epoch 24.138), train_loss = 1.03521815, grad/param norm = 2.4517e-01, time/batch = 16.5149s	
8039/16650 (epoch 24.141), train_loss = 1.00103692, grad/param norm = 2.5726e-01, time/batch = 18.2746s	
8040/16650 (epoch 24.144), train_loss = 0.97000143, grad/param norm = 2.7330e-01, time/batch = 17.5003s	
8041/16650 (epoch 24.147), train_loss = 1.10696614, grad/param norm = 2.6855e-01, time/batch = 17.6741s	
8042/16650 (epoch 24.150), train_loss = 1.18925099, grad/param norm = 3.1650e-01, time/batch = 18.0220s	
8043/16650 (epoch 24.153), train_loss = 0.99883069, grad/param norm = 2.6361e-01, time/batch = 18.7835s	
8044/16650 (epoch 24.156), train_loss = 0.89039856, grad/param norm = 2.5007e-01, time/batch = 16.1843s	
8045/16650 (epoch 24.159), train_loss = 1.02991741, grad/param norm = 3.0458e-01, time/batch = 17.1090s	
8046/16650 (epoch 24.162), train_loss = 1.08045724, grad/param norm = 2.8570e-01, time/batch = 17.1199s	
8047/16650 (epoch 24.165), train_loss = 1.09248617, grad/param norm = 2.8666e-01, time/batch = 17.0264s	
8048/16650 (epoch 24.168), train_loss = 0.83166385, grad/param norm = 2.2060e-01, time/batch = 18.1000s	
8049/16650 (epoch 24.171), train_loss = 1.05040907, grad/param norm = 2.5283e-01, time/batch = 16.0844s	
8050/16650 (epoch 24.174), train_loss = 0.80519308, grad/param norm = 2.4361e-01, time/batch = 17.2796s	
8051/16650 (epoch 24.177), train_loss = 0.96127727, grad/param norm = 2.5761e-01, time/batch = 16.1024s	
8052/16650 (epoch 24.180), train_loss = 1.07254918, grad/param norm = 2.5708e-01, time/batch = 18.5243s	
8053/16650 (epoch 24.183), train_loss = 1.19055717, grad/param norm = 3.1155e-01, time/batch = 15.5486s	
8054/16650 (epoch 24.186), train_loss = 1.04495061, grad/param norm = 3.2186e-01, time/batch = 16.6798s	
8055/16650 (epoch 24.189), train_loss = 0.89908845, grad/param norm = 2.5043e-01, time/batch = 17.4402s	
8056/16650 (epoch 24.192), train_loss = 0.92703270, grad/param norm = 2.9245e-01, time/batch = 19.0411s	
8057/16650 (epoch 24.195), train_loss = 0.91972157, grad/param norm = 2.8828e-01, time/batch = 18.7880s	
8058/16650 (epoch 24.198), train_loss = 0.80094131, grad/param norm = 2.1418e-01, time/batch = 17.5000s	
8059/16650 (epoch 24.201), train_loss = 0.90875903, grad/param norm = 2.8476e-01, time/batch = 17.4546s	
8060/16650 (epoch 24.204), train_loss = 0.97039740, grad/param norm = 2.5995e-01, time/batch = 17.7066s	
8061/16650 (epoch 24.207), train_loss = 1.00077923, grad/param norm = 2.9879e-01, time/batch = 14.3736s	
8062/16650 (epoch 24.210), train_loss = 0.94336164, grad/param norm = 2.5610e-01, time/batch = 17.1870s	
8063/16650 (epoch 24.213), train_loss = 1.05701460, grad/param norm = 2.8741e-01, time/batch = 14.9040s	
8064/16650 (epoch 24.216), train_loss = 0.92086155, grad/param norm = 2.5182e-01, time/batch = 17.2973s	
8065/16650 (epoch 24.219), train_loss = 0.98136483, grad/param norm = 2.9746e-01, time/batch = 15.9221s	
8066/16650 (epoch 24.222), train_loss = 0.99253509, grad/param norm = 2.3771e-01, time/batch = 17.4580s	
8067/16650 (epoch 24.225), train_loss = 0.97098030, grad/param norm = 2.8301e-01, time/batch = 17.8692s	
8068/16650 (epoch 24.228), train_loss = 0.88258464, grad/param norm = 2.5299e-01, time/batch = 16.8620s	
8069/16650 (epoch 24.231), train_loss = 0.94206739, grad/param norm = 2.7901e-01, time/batch = 16.7677s	
8070/16650 (epoch 24.234), train_loss = 1.13574884, grad/param norm = 2.6323e-01, time/batch = 17.3740s	
8071/16650 (epoch 24.237), train_loss = 1.01279024, grad/param norm = 3.3023e-01, time/batch = 16.9427s	
8072/16650 (epoch 24.240), train_loss = 1.00812720, grad/param norm = 2.9518e-01, time/batch = 15.3559s	
8073/16650 (epoch 24.243), train_loss = 0.95560475, grad/param norm = 2.7563e-01, time/batch = 16.1159s	
8074/16650 (epoch 24.246), train_loss = 1.09812542, grad/param norm = 2.8294e-01, time/batch = 16.0241s	
8075/16650 (epoch 24.249), train_loss = 0.84417595, grad/param norm = 2.3104e-01, time/batch = 16.9403s	
8076/16650 (epoch 24.252), train_loss = 0.92188748, grad/param norm = 2.5041e-01, time/batch = 16.5260s	
8077/16650 (epoch 24.255), train_loss = 1.02730074, grad/param norm = 2.7681e-01, time/batch = 16.8120s	
8078/16650 (epoch 24.258), train_loss = 1.07252769, grad/param norm = 2.8426e-01, time/batch = 17.8055s	
8079/16650 (epoch 24.261), train_loss = 0.98940547, grad/param norm = 2.5347e-01, time/batch = 15.9524s	
8080/16650 (epoch 24.264), train_loss = 0.94359467, grad/param norm = 2.5379e-01, time/batch = 16.9439s	
8081/16650 (epoch 24.267), train_loss = 0.93302746, grad/param norm = 2.5006e-01, time/batch = 14.9175s	
8082/16650 (epoch 24.270), train_loss = 0.98063182, grad/param norm = 2.4888e-01, time/batch = 16.6992s	
8083/16650 (epoch 24.273), train_loss = 1.07673747, grad/param norm = 2.4655e-01, time/batch = 16.5938s	
8084/16650 (epoch 24.276), train_loss = 0.98458764, grad/param norm = 2.3441e-01, time/batch = 14.8712s	
8085/16650 (epoch 24.279), train_loss = 0.96486092, grad/param norm = 2.6230e-01, time/batch = 15.8404s	
8086/16650 (epoch 24.282), train_loss = 0.85311633, grad/param norm = 2.2756e-01, time/batch = 16.4348s	
8087/16650 (epoch 24.285), train_loss = 0.87055917, grad/param norm = 2.2748e-01, time/batch = 17.0281s	
8088/16650 (epoch 24.288), train_loss = 0.90788009, grad/param norm = 2.6517e-01, time/batch = 17.7859s	
8089/16650 (epoch 24.291), train_loss = 0.73731248, grad/param norm = 2.2272e-01, time/batch = 15.8634s	
8090/16650 (epoch 24.294), train_loss = 0.84817773, grad/param norm = 2.2275e-01, time/batch = 15.2357s	
8091/16650 (epoch 24.297), train_loss = 0.93714580, grad/param norm = 2.3359e-01, time/batch = 17.6061s	
8092/16650 (epoch 24.300), train_loss = 0.74764009, grad/param norm = 2.2452e-01, time/batch = 17.7907s	
8093/16650 (epoch 24.303), train_loss = 0.83075371, grad/param norm = 2.2802e-01, time/batch = 16.4456s	
8094/16650 (epoch 24.306), train_loss = 1.02568422, grad/param norm = 2.5313e-01, time/batch = 16.1668s	
8095/16650 (epoch 24.309), train_loss = 1.04963168, grad/param norm = 2.8937e-01, time/batch = 16.9451s	
8096/16650 (epoch 24.312), train_loss = 0.85837198, grad/param norm = 3.1460e-01, time/batch = 18.1254s	
8097/16650 (epoch 24.315), train_loss = 0.69113982, grad/param norm = 2.1839e-01, time/batch = 15.3176s	
8098/16650 (epoch 24.318), train_loss = 0.78506329, grad/param norm = 2.2397e-01, time/batch = 14.0736s	
8099/16650 (epoch 24.321), train_loss = 1.08891167, grad/param norm = 3.1308e-01, time/batch = 16.4402s	
8100/16650 (epoch 24.324), train_loss = 0.88524876, grad/param norm = 2.7296e-01, time/batch = 18.2866s	
8101/16650 (epoch 24.327), train_loss = 0.99753325, grad/param norm = 2.9654e-01, time/batch = 15.9881s	
8102/16650 (epoch 24.330), train_loss = 0.98803333, grad/param norm = 2.8001e-01, time/batch = 17.7624s	
8103/16650 (epoch 24.333), train_loss = 1.02744070, grad/param norm = 3.4912e-01, time/batch = 17.1289s	
8104/16650 (epoch 24.336), train_loss = 0.87443210, grad/param norm = 2.9288e-01, time/batch = 16.0191s	
8105/16650 (epoch 24.339), train_loss = 0.91923905, grad/param norm = 2.5833e-01, time/batch = 15.2790s	
8106/16650 (epoch 24.342), train_loss = 0.87186447, grad/param norm = 2.7743e-01, time/batch = 16.9465s	
8107/16650 (epoch 24.345), train_loss = 0.82124229, grad/param norm = 2.2248e-01, time/batch = 13.3514s	
8108/16650 (epoch 24.348), train_loss = 0.94798710, grad/param norm = 2.7899e-01, time/batch = 13.3487s	
8109/16650 (epoch 24.351), train_loss = 0.99326334, grad/param norm = 2.7407e-01, time/batch = 13.7701s	
8110/16650 (epoch 24.354), train_loss = 1.01306181, grad/param norm = 2.9242e-01, time/batch = 15.7830s	
8111/16650 (epoch 24.357), train_loss = 1.00487140, grad/param norm = 3.0495e-01, time/batch = 16.9552s	
8112/16650 (epoch 24.360), train_loss = 0.97859455, grad/param norm = 2.6435e-01, time/batch = 15.9172s	
8113/16650 (epoch 24.363), train_loss = 1.06401936, grad/param norm = 2.8010e-01, time/batch = 14.9038s	
8114/16650 (epoch 24.366), train_loss = 1.09354277, grad/param norm = 2.6948e-01, time/batch = 17.6837s	
8115/16650 (epoch 24.369), train_loss = 0.95741766, grad/param norm = 2.5521e-01, time/batch = 18.0459s	
8116/16650 (epoch 24.372), train_loss = 0.96327806, grad/param norm = 2.5400e-01, time/batch = 16.1827s	
8117/16650 (epoch 24.375), train_loss = 0.98818628, grad/param norm = 2.7313e-01, time/batch = 15.8774s	
8118/16650 (epoch 24.378), train_loss = 0.88665224, grad/param norm = 2.4077e-01, time/batch = 16.3617s	
8119/16650 (epoch 24.381), train_loss = 0.97741666, grad/param norm = 2.7581e-01, time/batch = 17.1007s	
8120/16650 (epoch 24.384), train_loss = 1.10511921, grad/param norm = 2.6677e-01, time/batch = 16.7447s	
8121/16650 (epoch 24.387), train_loss = 0.77244485, grad/param norm = 2.3564e-01, time/batch = 17.5313s	
8122/16650 (epoch 24.390), train_loss = 1.03783104, grad/param norm = 2.5060e-01, time/batch = 15.6660s	
8123/16650 (epoch 24.393), train_loss = 0.91885157, grad/param norm = 2.7118e-01, time/batch = 14.7515s	
8124/16650 (epoch 24.396), train_loss = 1.06293945, grad/param norm = 2.8582e-01, time/batch = 17.3616s	
8125/16650 (epoch 24.399), train_loss = 0.99317106, grad/param norm = 2.5329e-01, time/batch = 17.1229s	
8126/16650 (epoch 24.402), train_loss = 0.88685440, grad/param norm = 2.6543e-01, time/batch = 17.2939s	
8127/16650 (epoch 24.405), train_loss = 0.77569386, grad/param norm = 2.7308e-01, time/batch = 16.6681s	
8128/16650 (epoch 24.408), train_loss = 0.99169828, grad/param norm = 3.1136e-01, time/batch = 16.9547s	
8129/16650 (epoch 24.411), train_loss = 0.86400354, grad/param norm = 3.2031e-01, time/batch = 16.2801s	
8130/16650 (epoch 24.414), train_loss = 0.85586397, grad/param norm = 2.9409e-01, time/batch = 16.0120s	
8131/16650 (epoch 24.417), train_loss = 0.81772768, grad/param norm = 2.5049e-01, time/batch = 14.9183s	
8132/16650 (epoch 24.420), train_loss = 0.83362935, grad/param norm = 2.4585e-01, time/batch = 15.5899s	
8133/16650 (epoch 24.423), train_loss = 0.71945183, grad/param norm = 2.1700e-01, time/batch = 17.6189s	
8134/16650 (epoch 24.426), train_loss = 0.83943091, grad/param norm = 2.7381e-01, time/batch = 15.8438s	
8135/16650 (epoch 24.429), train_loss = 1.04103853, grad/param norm = 2.7583e-01, time/batch = 17.1919s	
8136/16650 (epoch 24.432), train_loss = 1.01948046, grad/param norm = 2.9052e-01, time/batch = 16.7746s	
8137/16650 (epoch 24.435), train_loss = 1.13673380, grad/param norm = 3.0250e-01, time/batch = 16.9319s	
8138/16650 (epoch 24.438), train_loss = 1.12982585, grad/param norm = 3.5845e-01, time/batch = 14.1590s	
8139/16650 (epoch 24.441), train_loss = 0.96951247, grad/param norm = 3.1472e-01, time/batch = 17.3644s	
8140/16650 (epoch 24.444), train_loss = 0.89190750, grad/param norm = 3.1355e-01, time/batch = 17.5274s	
8141/16650 (epoch 24.447), train_loss = 0.91422093, grad/param norm = 2.8761e-01, time/batch = 16.6785s	
8142/16650 (epoch 24.450), train_loss = 0.88763987, grad/param norm = 2.5225e-01, time/batch = 15.1457s	
8143/16650 (epoch 24.453), train_loss = 0.89676749, grad/param norm = 5.2702e-01, time/batch = 17.6193s	
8144/16650 (epoch 24.456), train_loss = 0.80560509, grad/param norm = 2.5630e-01, time/batch = 17.2772s	
8145/16650 (epoch 24.459), train_loss = 0.88107088, grad/param norm = 2.5994e-01, time/batch = 16.7648s	
8146/16650 (epoch 24.462), train_loss = 1.10756687, grad/param norm = 3.3877e-01, time/batch = 16.4543s	
8147/16650 (epoch 24.465), train_loss = 0.89006336, grad/param norm = 3.0771e-01, time/batch = 17.0255s	
8148/16650 (epoch 24.468), train_loss = 0.74746531, grad/param norm = 2.5712e-01, time/batch = 14.1563s	
8149/16650 (epoch 24.471), train_loss = 0.63063517, grad/param norm = 1.9575e-01, time/batch = 16.7612s	
8150/16650 (epoch 24.474), train_loss = 0.80182611, grad/param norm = 2.4755e-01, time/batch = 17.0337s	
8151/16650 (epoch 24.477), train_loss = 0.98690172, grad/param norm = 2.7756e-01, time/batch = 18.2918s	
8152/16650 (epoch 24.480), train_loss = 1.01207870, grad/param norm = 3.0342e-01, time/batch = 15.8584s	
8153/16650 (epoch 24.483), train_loss = 1.04180083, grad/param norm = 2.7434e-01, time/batch = 14.4800s	
8154/16650 (epoch 24.486), train_loss = 0.84825869, grad/param norm = 2.2845e-01, time/batch = 16.4395s	
8155/16650 (epoch 24.489), train_loss = 0.87035465, grad/param norm = 2.5953e-01, time/batch = 15.2649s	
8156/16650 (epoch 24.492), train_loss = 0.92519632, grad/param norm = 2.2851e-01, time/batch = 15.8477s	
8157/16650 (epoch 24.495), train_loss = 0.81595712, grad/param norm = 2.5849e-01, time/batch = 16.6174s	
8158/16650 (epoch 24.498), train_loss = 0.89372603, grad/param norm = 3.1440e-01, time/batch = 17.3700s	
8159/16650 (epoch 24.502), train_loss = 1.08199871, grad/param norm = 3.0483e-01, time/batch = 16.9365s	
8160/16650 (epoch 24.505), train_loss = 0.99299154, grad/param norm = 2.6327e-01, time/batch = 17.1896s	
8161/16650 (epoch 24.508), train_loss = 0.96736392, grad/param norm = 2.7798e-01, time/batch = 16.6218s	
8162/16650 (epoch 24.511), train_loss = 1.04828954, grad/param norm = 2.7398e-01, time/batch = 17.4565s	
8163/16650 (epoch 24.514), train_loss = 0.79456949, grad/param norm = 2.4455e-01, time/batch = 15.7644s	
8164/16650 (epoch 24.517), train_loss = 0.93594637, grad/param norm = 2.9162e-01, time/batch = 17.6271s	
8165/16650 (epoch 24.520), train_loss = 0.83519108, grad/param norm = 2.9664e-01, time/batch = 17.5381s	
8166/16650 (epoch 24.523), train_loss = 0.92866848, grad/param norm = 2.8909e-01, time/batch = 15.9313s	
8167/16650 (epoch 24.526), train_loss = 1.03267573, grad/param norm = 2.8415e-01, time/batch = 16.5025s	
8168/16650 (epoch 24.529), train_loss = 1.08291415, grad/param norm = 2.9923e-01, time/batch = 17.7899s	
8169/16650 (epoch 24.532), train_loss = 0.72099033, grad/param norm = 2.3104e-01, time/batch = 17.4560s	
8170/16650 (epoch 24.535), train_loss = 0.80206450, grad/param norm = 2.5571e-01, time/batch = 16.2674s	
8171/16650 (epoch 24.538), train_loss = 0.78225793, grad/param norm = 2.4624e-01, time/batch = 17.9614s	
8172/16650 (epoch 24.541), train_loss = 1.06211763, grad/param norm = 2.9458e-01, time/batch = 16.2913s	
8173/16650 (epoch 24.544), train_loss = 1.12428257, grad/param norm = 3.5133e-01, time/batch = 14.9349s	
8174/16650 (epoch 24.547), train_loss = 0.83309400, grad/param norm = 2.5191e-01, time/batch = 16.4371s	
8175/16650 (epoch 24.550), train_loss = 0.92188994, grad/param norm = 2.7379e-01, time/batch = 14.4178s	
8176/16650 (epoch 24.553), train_loss = 0.90016071, grad/param norm = 2.7472e-01, time/batch = 15.3356s	
8177/16650 (epoch 24.556), train_loss = 0.85317195, grad/param norm = 2.5065e-01, time/batch = 16.3476s	
8178/16650 (epoch 24.559), train_loss = 0.75479831, grad/param norm = 2.5281e-01, time/batch = 17.1069s	
8179/16650 (epoch 24.562), train_loss = 0.87660381, grad/param norm = 2.7393e-01, time/batch = 16.6865s	
8180/16650 (epoch 24.565), train_loss = 0.73382285, grad/param norm = 2.5529e-01, time/batch = 16.7929s	
8181/16650 (epoch 24.568), train_loss = 0.75282479, grad/param norm = 2.5407e-01, time/batch = 15.5053s	
8182/16650 (epoch 24.571), train_loss = 0.79932256, grad/param norm = 2.9752e-01, time/batch = 17.2913s	
8183/16650 (epoch 24.574), train_loss = 0.88506503, grad/param norm = 2.7738e-01, time/batch = 16.8494s	
8184/16650 (epoch 24.577), train_loss = 0.85542791, grad/param norm = 2.5054e-01, time/batch = 15.7540s	
8185/16650 (epoch 24.580), train_loss = 0.76827060, grad/param norm = 2.3566e-01, time/batch = 16.7648s	
8186/16650 (epoch 24.583), train_loss = 0.89694779, grad/param norm = 2.6040e-01, time/batch = 17.9500s	
8187/16650 (epoch 24.586), train_loss = 0.82676226, grad/param norm = 2.9645e-01, time/batch = 16.3694s	
8188/16650 (epoch 24.589), train_loss = 0.79603682, grad/param norm = 2.4943e-01, time/batch = 16.0177s	
8189/16650 (epoch 24.592), train_loss = 0.91523400, grad/param norm = 2.8120e-01, time/batch = 17.2050s	
8190/16650 (epoch 24.595), train_loss = 0.85666266, grad/param norm = 2.8873e-01, time/batch = 15.1728s	
8191/16650 (epoch 24.598), train_loss = 0.87937537, grad/param norm = 2.8136e-01, time/batch = 16.0495s	
8192/16650 (epoch 24.601), train_loss = 0.84693246, grad/param norm = 3.0563e-01, time/batch = 16.4115s	
8193/16650 (epoch 24.604), train_loss = 0.99465369, grad/param norm = 2.7522e-01, time/batch = 17.0319s	
8194/16650 (epoch 24.607), train_loss = 0.95532425, grad/param norm = 2.5692e-01, time/batch = 16.7853s	
8195/16650 (epoch 24.610), train_loss = 0.81490057, grad/param norm = 2.4294e-01, time/batch = 14.9848s	
8196/16650 (epoch 24.613), train_loss = 1.04459649, grad/param norm = 2.8692e-01, time/batch = 16.6016s	
8197/16650 (epoch 24.616), train_loss = 1.03394970, grad/param norm = 3.4173e-01, time/batch = 16.0310s	
8198/16650 (epoch 24.619), train_loss = 0.76200025, grad/param norm = 2.5484e-01, time/batch = 15.6847s	
8199/16650 (epoch 24.622), train_loss = 0.73159793, grad/param norm = 2.3846e-01, time/batch = 16.6920s	
8200/16650 (epoch 24.625), train_loss = 0.85881429, grad/param norm = 2.4038e-01, time/batch = 16.2727s	
8201/16650 (epoch 24.628), train_loss = 0.84981574, grad/param norm = 2.8661e-01, time/batch = 17.5184s	
8202/16650 (epoch 24.631), train_loss = 0.92772403, grad/param norm = 2.9232e-01, time/batch = 17.5448s	
8203/16650 (epoch 24.634), train_loss = 1.10428172, grad/param norm = 3.1678e-01, time/batch = 17.3507s	
8204/16650 (epoch 24.637), train_loss = 1.09970902, grad/param norm = 2.7465e-01, time/batch = 17.9519s	
8205/16650 (epoch 24.640), train_loss = 0.85696052, grad/param norm = 2.5716e-01, time/batch = 16.0500s	
8206/16650 (epoch 24.643), train_loss = 0.97845288, grad/param norm = 2.5576e-01, time/batch = 16.8480s	
8207/16650 (epoch 24.646), train_loss = 0.98502329, grad/param norm = 2.6990e-01, time/batch = 16.3430s	
8208/16650 (epoch 24.649), train_loss = 0.90959009, grad/param norm = 2.5247e-01, time/batch = 15.7674s	
8209/16650 (epoch 24.652), train_loss = 1.00875654, grad/param norm = 2.6692e-01, time/batch = 17.2855s	
8210/16650 (epoch 24.655), train_loss = 0.94613523, grad/param norm = 2.4309e-01, time/batch = 16.0771s	
8211/16650 (epoch 24.658), train_loss = 0.81866237, grad/param norm = 2.7613e-01, time/batch = 17.6948s	
8212/16650 (epoch 24.661), train_loss = 0.96017706, grad/param norm = 2.9324e-01, time/batch = 16.9571s	
8213/16650 (epoch 24.664), train_loss = 0.92349263, grad/param norm = 2.4528e-01, time/batch = 15.7675s	
8214/16650 (epoch 24.667), train_loss = 1.03215077, grad/param norm = 2.6954e-01, time/batch = 16.6907s	
8215/16650 (epoch 24.670), train_loss = 0.79140982, grad/param norm = 2.4035e-01, time/batch = 17.2895s	
8216/16650 (epoch 24.673), train_loss = 0.83923985, grad/param norm = 2.5714e-01, time/batch = 14.8271s	
8217/16650 (epoch 24.676), train_loss = 0.95041931, grad/param norm = 2.9350e-01, time/batch = 16.6153s	
8218/16650 (epoch 24.679), train_loss = 0.81250838, grad/param norm = 2.5122e-01, time/batch = 16.8687s	
8219/16650 (epoch 24.682), train_loss = 0.93990876, grad/param norm = 2.9442e-01, time/batch = 16.8873s	
8220/16650 (epoch 24.685), train_loss = 0.77610468, grad/param norm = 2.4859e-01, time/batch = 15.0200s	
8221/16650 (epoch 24.688), train_loss = 0.98658027, grad/param norm = 2.6956e-01, time/batch = 29.8383s	
8222/16650 (epoch 24.691), train_loss = 0.97499617, grad/param norm = 2.6480e-01, time/batch = 17.6255s	
8223/16650 (epoch 24.694), train_loss = 0.82120461, grad/param norm = 2.3585e-01, time/batch = 16.3432s	
8224/16650 (epoch 24.697), train_loss = 0.77980078, grad/param norm = 2.2407e-01, time/batch = 16.7132s	
8225/16650 (epoch 24.700), train_loss = 1.00380455, grad/param norm = 2.9345e-01, time/batch = 17.1093s	
8226/16650 (epoch 24.703), train_loss = 0.79651331, grad/param norm = 2.4429e-01, time/batch = 17.0313s	
8227/16650 (epoch 24.706), train_loss = 0.90073488, grad/param norm = 2.5951e-01, time/batch = 15.0810s	
8228/16650 (epoch 24.709), train_loss = 0.82096934, grad/param norm = 2.3632e-01, time/batch = 16.1229s	
8229/16650 (epoch 24.712), train_loss = 0.83684766, grad/param norm = 2.7974e-01, time/batch = 16.8549s	
8230/16650 (epoch 24.715), train_loss = 0.98740081, grad/param norm = 3.1168e-01, time/batch = 16.9570s	
8231/16650 (epoch 24.718), train_loss = 1.02522504, grad/param norm = 2.8340e-01, time/batch = 17.0334s	
8232/16650 (epoch 24.721), train_loss = 0.99427846, grad/param norm = 2.7957e-01, time/batch = 16.8706s	
8233/16650 (epoch 24.724), train_loss = 0.99880789, grad/param norm = 2.7108e-01, time/batch = 16.5217s	
8234/16650 (epoch 24.727), train_loss = 0.98933245, grad/param norm = 2.7370e-01, time/batch = 15.8312s	
8235/16650 (epoch 24.730), train_loss = 0.86154991, grad/param norm = 2.6899e-01, time/batch = 16.1037s	
8236/16650 (epoch 24.733), train_loss = 1.02099526, grad/param norm = 2.8529e-01, time/batch = 17.6453s	
8237/16650 (epoch 24.736), train_loss = 0.77021411, grad/param norm = 2.5161e-01, time/batch = 15.8790s	
8238/16650 (epoch 24.739), train_loss = 0.91537857, grad/param norm = 2.4938e-01, time/batch = 16.2768s	
8239/16650 (epoch 24.742), train_loss = 0.90844574, grad/param norm = 2.4690e-01, time/batch = 15.7622s	
8240/16650 (epoch 24.745), train_loss = 0.72382889, grad/param norm = 2.5614e-01, time/batch = 13.3559s	
8241/16650 (epoch 24.748), train_loss = 0.79309310, grad/param norm = 2.6267e-01, time/batch = 13.4154s	
8242/16650 (epoch 24.751), train_loss = 0.95943441, grad/param norm = 3.9367e-01, time/batch = 14.1214s	
8243/16650 (epoch 24.754), train_loss = 1.10237320, grad/param norm = 3.2228e-01, time/batch = 17.1131s	
8244/16650 (epoch 24.757), train_loss = 1.06342874, grad/param norm = 2.9181e-01, time/batch = 17.0481s	
8245/16650 (epoch 24.760), train_loss = 0.90427809, grad/param norm = 2.4886e-01, time/batch = 15.3233s	
8246/16650 (epoch 24.763), train_loss = 0.84624093, grad/param norm = 2.3793e-01, time/batch = 14.4086s	
8247/16650 (epoch 24.766), train_loss = 0.90522311, grad/param norm = 2.4521e-01, time/batch = 17.3723s	
8248/16650 (epoch 24.769), train_loss = 0.94917121, grad/param norm = 2.6727e-01, time/batch = 17.7055s	
8249/16650 (epoch 24.772), train_loss = 0.88287860, grad/param norm = 2.3078e-01, time/batch = 14.4209s	
8250/16650 (epoch 24.775), train_loss = 0.87606627, grad/param norm = 2.3450e-01, time/batch = 16.8759s	
8251/16650 (epoch 24.778), train_loss = 0.90556552, grad/param norm = 2.4674e-01, time/batch = 17.7889s	
8252/16650 (epoch 24.781), train_loss = 1.02312945, grad/param norm = 2.3547e-01, time/batch = 17.0393s	
8253/16650 (epoch 24.784), train_loss = 0.98023790, grad/param norm = 2.8007e-01, time/batch = 16.3594s	
8254/16650 (epoch 24.787), train_loss = 0.99677945, grad/param norm = 2.5623e-01, time/batch = 16.1929s	
8255/16650 (epoch 24.790), train_loss = 0.96312818, grad/param norm = 2.3020e-01, time/batch = 17.9394s	
8256/16650 (epoch 24.793), train_loss = 0.82393935, grad/param norm = 2.5541e-01, time/batch = 16.0155s	
8257/16650 (epoch 24.796), train_loss = 1.21415201, grad/param norm = 3.1358e-01, time/batch = 16.6851s	
8258/16650 (epoch 24.799), train_loss = 1.11845083, grad/param norm = 2.9184e-01, time/batch = 17.2142s	
8259/16650 (epoch 24.802), train_loss = 0.97818169, grad/param norm = 2.5245e-01, time/batch = 16.8767s	
8260/16650 (epoch 24.805), train_loss = 0.92850197, grad/param norm = 2.6064e-01, time/batch = 15.4347s	
8261/16650 (epoch 24.808), train_loss = 0.98556246, grad/param norm = 2.6059e-01, time/batch = 17.2033s	
8262/16650 (epoch 24.811), train_loss = 1.04330532, grad/param norm = 2.7674e-01, time/batch = 18.0415s	
8263/16650 (epoch 24.814), train_loss = 0.83092452, grad/param norm = 2.3881e-01, time/batch = 15.5133s	
8264/16650 (epoch 24.817), train_loss = 0.86937925, grad/param norm = 2.5410e-01, time/batch = 15.4126s	
8265/16650 (epoch 24.820), train_loss = 1.00008095, grad/param norm = 3.5944e-01, time/batch = 17.2943s	
8266/16650 (epoch 24.823), train_loss = 0.91034204, grad/param norm = 2.5617e-01, time/batch = 15.8278s	
8267/16650 (epoch 24.826), train_loss = 0.90119140, grad/param norm = 2.5070e-01, time/batch = 15.8450s	
8268/16650 (epoch 24.829), train_loss = 0.96640584, grad/param norm = 2.5981e-01, time/batch = 16.6268s	
8269/16650 (epoch 24.832), train_loss = 1.01499544, grad/param norm = 2.8231e-01, time/batch = 15.8481s	
8270/16650 (epoch 24.835), train_loss = 0.99310403, grad/param norm = 2.8547e-01, time/batch = 17.2127s	
8271/16650 (epoch 24.838), train_loss = 0.85252802, grad/param norm = 2.6533e-01, time/batch = 16.0126s	
8272/16650 (epoch 24.841), train_loss = 0.87909524, grad/param norm = 2.6579e-01, time/batch = 16.8548s	
8273/16650 (epoch 24.844), train_loss = 0.86043165, grad/param norm = 2.5378e-01, time/batch = 17.1321s	
8274/16650 (epoch 24.847), train_loss = 1.00239573, grad/param norm = 2.6357e-01, time/batch = 16.4347s	
8275/16650 (epoch 24.850), train_loss = 0.81229568, grad/param norm = 2.6023e-01, time/batch = 17.3418s	
8276/16650 (epoch 24.853), train_loss = 0.92114508, grad/param norm = 2.6032e-01, time/batch = 16.3758s	
8277/16650 (epoch 24.856), train_loss = 0.85626090, grad/param norm = 2.4148e-01, time/batch = 18.0538s	
8278/16650 (epoch 24.859), train_loss = 1.03009321, grad/param norm = 2.9655e-01, time/batch = 15.6603s	
8279/16650 (epoch 24.862), train_loss = 0.91245590, grad/param norm = 2.5218e-01, time/batch = 16.6814s	
8280/16650 (epoch 24.865), train_loss = 0.77039337, grad/param norm = 2.2771e-01, time/batch = 17.5371s	
8281/16650 (epoch 24.868), train_loss = 0.97328901, grad/param norm = 2.5615e-01, time/batch = 17.1882s	
8282/16650 (epoch 24.871), train_loss = 0.95513764, grad/param norm = 2.6055e-01, time/batch = 15.3378s	
8283/16650 (epoch 24.874), train_loss = 0.95975613, grad/param norm = 2.5430e-01, time/batch = 17.0971s	
8284/16650 (epoch 24.877), train_loss = 0.93674059, grad/param norm = 2.4927e-01, time/batch = 16.6983s	
8285/16650 (epoch 24.880), train_loss = 0.81979609, grad/param norm = 2.5191e-01, time/batch = 16.8483s	
8286/16650 (epoch 24.883), train_loss = 0.92859456, grad/param norm = 2.5899e-01, time/batch = 17.1947s	
8287/16650 (epoch 24.886), train_loss = 0.92480865, grad/param norm = 2.6364e-01, time/batch = 16.2644s	
8288/16650 (epoch 24.889), train_loss = 0.79010125, grad/param norm = 2.5314e-01, time/batch = 15.9257s	
8289/16650 (epoch 24.892), train_loss = 0.91080967, grad/param norm = 2.4120e-01, time/batch = 15.5955s	
8290/16650 (epoch 24.895), train_loss = 0.95666189, grad/param norm = 2.6149e-01, time/batch = 16.7085s	
8291/16650 (epoch 24.898), train_loss = 0.93575583, grad/param norm = 2.8589e-01, time/batch = 17.9567s	
8292/16650 (epoch 24.901), train_loss = 0.91818312, grad/param norm = 2.4865e-01, time/batch = 14.5761s	
8293/16650 (epoch 24.904), train_loss = 0.85846331, grad/param norm = 2.4947e-01, time/batch = 5.0748s	
8294/16650 (epoch 24.907), train_loss = 0.97355572, grad/param norm = 2.8353e-01, time/batch = 0.6159s	
8295/16650 (epoch 24.910), train_loss = 0.97912820, grad/param norm = 2.9196e-01, time/batch = 0.6151s	
8296/16650 (epoch 24.913), train_loss = 0.87102786, grad/param norm = 2.6816e-01, time/batch = 0.6157s	
8297/16650 (epoch 24.916), train_loss = 0.90176628, grad/param norm = 2.5765e-01, time/batch = 0.6157s	
8298/16650 (epoch 24.919), train_loss = 1.07510222, grad/param norm = 2.7703e-01, time/batch = 0.6142s	
8299/16650 (epoch 24.922), train_loss = 1.00888727, grad/param norm = 2.7575e-01, time/batch = 0.6164s	
8300/16650 (epoch 24.925), train_loss = 0.88856192, grad/param norm = 3.0929e-01, time/batch = 0.6160s	
8301/16650 (epoch 24.928), train_loss = 0.92142197, grad/param norm = 2.5918e-01, time/batch = 0.7959s	
8302/16650 (epoch 24.931), train_loss = 0.99020250, grad/param norm = 2.6209e-01, time/batch = 0.9124s	
8303/16650 (epoch 24.934), train_loss = 0.81624409, grad/param norm = 2.6983e-01, time/batch = 0.9163s	
8304/16650 (epoch 24.937), train_loss = 0.85570792, grad/param norm = 2.8376e-01, time/batch = 0.9113s	
8305/16650 (epoch 24.940), train_loss = 0.88179967, grad/param norm = 2.1921e-01, time/batch = 0.9069s	
8306/16650 (epoch 24.943), train_loss = 0.95277819, grad/param norm = 3.2865e-01, time/batch = 0.9916s	
8307/16650 (epoch 24.946), train_loss = 0.84459336, grad/param norm = 3.0138e-01, time/batch = 1.7052s	
8308/16650 (epoch 24.949), train_loss = 0.81674787, grad/param norm = 2.6983e-01, time/batch = 1.6799s	
8309/16650 (epoch 24.952), train_loss = 0.77584257, grad/param norm = 2.4759e-01, time/batch = 4.6966s	
8310/16650 (epoch 24.955), train_loss = 0.90021817, grad/param norm = 2.3719e-01, time/batch = 17.0466s	
8311/16650 (epoch 24.958), train_loss = 0.98613573, grad/param norm = 3.5013e-01, time/batch = 16.5286s	
8312/16650 (epoch 24.961), train_loss = 0.92745071, grad/param norm = 2.5063e-01, time/batch = 15.9264s	
8313/16650 (epoch 24.964), train_loss = 0.85073809, grad/param norm = 3.2237e-01, time/batch = 17.8715s	
8314/16650 (epoch 24.967), train_loss = 1.06197771, grad/param norm = 3.2832e-01, time/batch = 15.8474s	
8315/16650 (epoch 24.970), train_loss = 0.84925616, grad/param norm = 2.4479e-01, time/batch = 15.3825s	
8316/16650 (epoch 24.973), train_loss = 0.87222246, grad/param norm = 2.7338e-01, time/batch = 16.6842s	
8317/16650 (epoch 24.976), train_loss = 0.86196430, grad/param norm = 2.6382e-01, time/batch = 17.0324s	
8318/16650 (epoch 24.979), train_loss = 0.96707637, grad/param norm = 3.3769e-01, time/batch = 17.6957s	
8319/16650 (epoch 24.982), train_loss = 0.97591769, grad/param norm = 2.7119e-01, time/batch = 15.8480s	
8320/16650 (epoch 24.985), train_loss = 0.89806875, grad/param norm = 2.4789e-01, time/batch = 18.0383s	
8321/16650 (epoch 24.988), train_loss = 1.07276181, grad/param norm = 3.4081e-01, time/batch = 16.6947s	
8322/16650 (epoch 24.991), train_loss = 0.82758184, grad/param norm = 2.4044e-01, time/batch = 16.6995s	
8323/16650 (epoch 24.994), train_loss = 0.86028300, grad/param norm = 2.3475e-01, time/batch = 16.4445s	
8324/16650 (epoch 24.997), train_loss = 0.91482802, grad/param norm = 2.7302e-01, time/batch = 17.5512s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
8325/16650 (epoch 25.000), train_loss = 0.96848513, grad/param norm = 2.5886e-01, time/batch = 17.7048s	
8326/16650 (epoch 25.003), train_loss = 1.01315182, grad/param norm = 2.8385e-01, time/batch = 15.0022s	
8327/16650 (epoch 25.006), train_loss = 1.00410513, grad/param norm = 2.9602e-01, time/batch = 17.3625s	
8328/16650 (epoch 25.009), train_loss = 1.08178863, grad/param norm = 2.6020e-01, time/batch = 14.6615s	
8329/16650 (epoch 25.012), train_loss = 1.05771265, grad/param norm = 2.6836e-01, time/batch = 16.8557s	
8330/16650 (epoch 25.015), train_loss = 0.92000269, grad/param norm = 2.6661e-01, time/batch = 16.3508s	
8331/16650 (epoch 25.018), train_loss = 0.79080749, grad/param norm = 2.9426e-01, time/batch = 16.1893s	
8332/16650 (epoch 25.021), train_loss = 1.04240839, grad/param norm = 2.8240e-01, time/batch = 15.2637s	
8333/16650 (epoch 25.024), train_loss = 0.91756501, grad/param norm = 2.7039e-01, time/batch = 15.7662s	
8334/16650 (epoch 25.027), train_loss = 1.01710347, grad/param norm = 2.9574e-01, time/batch = 17.3677s	
8335/16650 (epoch 25.030), train_loss = 0.81303824, grad/param norm = 2.4437e-01, time/batch = 16.4439s	
8336/16650 (epoch 25.033), train_loss = 0.94316044, grad/param norm = 2.4010e-01, time/batch = 15.9297s	
8337/16650 (epoch 25.036), train_loss = 0.70935988, grad/param norm = 2.9959e-01, time/batch = 16.5158s	
8338/16650 (epoch 25.039), train_loss = 1.02472700, grad/param norm = 2.5618e-01, time/batch = 17.7921s	
8339/16650 (epoch 25.042), train_loss = 1.01486906, grad/param norm = 2.8919e-01, time/batch = 17.2799s	
8340/16650 (epoch 25.045), train_loss = 0.88335522, grad/param norm = 2.3965e-01, time/batch = 16.5899s	
8341/16650 (epoch 25.048), train_loss = 1.01554568, grad/param norm = 2.9845e-01, time/batch = 16.7001s	
8342/16650 (epoch 25.051), train_loss = 0.89869365, grad/param norm = 2.6906e-01, time/batch = 17.3653s	
8343/16650 (epoch 25.054), train_loss = 0.94009173, grad/param norm = 2.9051e-01, time/batch = 18.1326s	
8344/16650 (epoch 25.057), train_loss = 0.95266422, grad/param norm = 2.9459e-01, time/batch = 14.6419s	
8345/16650 (epoch 25.060), train_loss = 0.78680130, grad/param norm = 2.3448e-01, time/batch = 17.4415s	
8346/16650 (epoch 25.063), train_loss = 0.89109939, grad/param norm = 2.4559e-01, time/batch = 17.7739s	
8347/16650 (epoch 25.066), train_loss = 1.07945266, grad/param norm = 2.6861e-01, time/batch = 17.2731s	
8348/16650 (epoch 25.069), train_loss = 0.99212524, grad/param norm = 2.7853e-01, time/batch = 14.0615s	
8349/16650 (epoch 25.072), train_loss = 0.92173448, grad/param norm = 2.8786e-01, time/batch = 17.1978s	
8350/16650 (epoch 25.075), train_loss = 1.00429536, grad/param norm = 2.5575e-01, time/batch = 16.7800s	
8351/16650 (epoch 25.078), train_loss = 1.04389385, grad/param norm = 2.6578e-01, time/batch = 16.4367s	
8352/16650 (epoch 25.081), train_loss = 0.96144013, grad/param norm = 3.4943e-01, time/batch = 16.3356s	
8353/16650 (epoch 25.084), train_loss = 0.99988671, grad/param norm = 2.7945e-01, time/batch = 16.3642s	
8354/16650 (epoch 25.087), train_loss = 0.93231521, grad/param norm = 2.8822e-01, time/batch = 17.7063s	
8355/16650 (epoch 25.090), train_loss = 0.92451687, grad/param norm = 2.7658e-01, time/batch = 15.8128s	
8356/16650 (epoch 25.093), train_loss = 1.11443626, grad/param norm = 3.1812e-01, time/batch = 17.2869s	
8357/16650 (epoch 25.096), train_loss = 0.89269688, grad/param norm = 2.6234e-01, time/batch = 17.7074s	
8358/16650 (epoch 25.099), train_loss = 0.94631098, grad/param norm = 2.6556e-01, time/batch = 16.8364s	
8359/16650 (epoch 25.102), train_loss = 0.94922160, grad/param norm = 2.4997e-01, time/batch = 15.7427s	
8360/16650 (epoch 25.105), train_loss = 0.97825347, grad/param norm = 2.8026e-01, time/batch = 17.4429s	
8361/16650 (epoch 25.108), train_loss = 0.96375802, grad/param norm = 2.7492e-01, time/batch = 18.4522s	
8362/16650 (epoch 25.111), train_loss = 1.01666850, grad/param norm = 2.4431e-01, time/batch = 16.2413s	
8363/16650 (epoch 25.114), train_loss = 1.03188097, grad/param norm = 2.8577e-01, time/batch = 18.1177s	
8364/16650 (epoch 25.117), train_loss = 1.10666252, grad/param norm = 2.8565e-01, time/batch = 17.8614s	
8365/16650 (epoch 25.120), train_loss = 0.87648077, grad/param norm = 2.3269e-01, time/batch = 16.4465s	
8366/16650 (epoch 25.123), train_loss = 0.93491934, grad/param norm = 2.6585e-01, time/batch = 17.6078s	
8367/16650 (epoch 25.126), train_loss = 0.95600496, grad/param norm = 2.6411e-01, time/batch = 18.1139s	
8368/16650 (epoch 25.129), train_loss = 0.95599261, grad/param norm = 2.7166e-01, time/batch = 17.6128s	
8369/16650 (epoch 25.132), train_loss = 0.94351540, grad/param norm = 2.9665e-01, time/batch = 16.3592s	
8370/16650 (epoch 25.135), train_loss = 1.02151405, grad/param norm = 2.6293e-01, time/batch = 18.0207s	
8371/16650 (epoch 25.138), train_loss = 1.01676142, grad/param norm = 2.5863e-01, time/batch = 15.9994s	
8372/16650 (epoch 25.141), train_loss = 0.98416268, grad/param norm = 2.7114e-01, time/batch = 15.8432s	
8373/16650 (epoch 25.144), train_loss = 0.95220434, grad/param norm = 2.7021e-01, time/batch = 15.5618s	
8374/16650 (epoch 25.147), train_loss = 1.08312276, grad/param norm = 2.7421e-01, time/batch = 18.3501s	
8375/16650 (epoch 25.150), train_loss = 1.19051231, grad/param norm = 3.8870e-01, time/batch = 16.0842s	
8376/16650 (epoch 25.153), train_loss = 1.00414862, grad/param norm = 3.1725e-01, time/batch = 17.0765s	
8377/16650 (epoch 25.156), train_loss = 0.89506374, grad/param norm = 2.5635e-01, time/batch = 17.2631s	
8378/16650 (epoch 25.159), train_loss = 0.99702091, grad/param norm = 2.6841e-01, time/batch = 18.7107s	
8379/16650 (epoch 25.162), train_loss = 1.06372966, grad/param norm = 2.6835e-01, time/batch = 16.4338s	
8380/16650 (epoch 25.165), train_loss = 1.07899165, grad/param norm = 2.9116e-01, time/batch = 15.4141s	
8381/16650 (epoch 25.168), train_loss = 0.81441507, grad/param norm = 2.2328e-01, time/batch = 17.6389s	
8382/16650 (epoch 25.171), train_loss = 1.03141520, grad/param norm = 2.5182e-01, time/batch = 18.2962s	
8383/16650 (epoch 25.174), train_loss = 0.79989502, grad/param norm = 2.5629e-01, time/batch = 17.4349s	
8384/16650 (epoch 25.177), train_loss = 0.94907963, grad/param norm = 2.7859e-01, time/batch = 17.0836s	
8385/16650 (epoch 25.180), train_loss = 1.05709146, grad/param norm = 2.7261e-01, time/batch = 18.8791s	
8386/16650 (epoch 25.183), train_loss = 1.16278698, grad/param norm = 3.0452e-01, time/batch = 16.8398s	
8387/16650 (epoch 25.186), train_loss = 1.01487177, grad/param norm = 2.8070e-01, time/batch = 15.7329s	
8388/16650 (epoch 25.189), train_loss = 0.89040203, grad/param norm = 2.6949e-01, time/batch = 15.9105s	
8389/16650 (epoch 25.192), train_loss = 0.90249062, grad/param norm = 2.6984e-01, time/batch = 18.1987s	
8390/16650 (epoch 25.195), train_loss = 0.90615528, grad/param norm = 2.7069e-01, time/batch = 18.1897s	
8391/16650 (epoch 25.198), train_loss = 0.78942831, grad/param norm = 2.0490e-01, time/batch = 16.1077s	
8392/16650 (epoch 25.201), train_loss = 0.88016448, grad/param norm = 3.2062e-01, time/batch = 18.2835s	
8393/16650 (epoch 25.204), train_loss = 0.95839992, grad/param norm = 2.9183e-01, time/batch = 16.1690s	
8394/16650 (epoch 25.207), train_loss = 0.96359477, grad/param norm = 2.8263e-01, time/batch = 18.5189s	
8395/16650 (epoch 25.210), train_loss = 0.93105556, grad/param norm = 2.7858e-01, time/batch = 17.1825s	
8396/16650 (epoch 25.213), train_loss = 1.05703362, grad/param norm = 2.9325e-01, time/batch = 17.5814s	
8397/16650 (epoch 25.216), train_loss = 0.89849914, grad/param norm = 2.7798e-01, time/batch = 15.2305s	
8398/16650 (epoch 25.219), train_loss = 0.94730567, grad/param norm = 2.7923e-01, time/batch = 17.5257s	
8399/16650 (epoch 25.222), train_loss = 0.97528992, grad/param norm = 2.4271e-01, time/batch = 18.3714s	
8400/16650 (epoch 25.225), train_loss = 0.95904215, grad/param norm = 2.9279e-01, time/batch = 17.0780s	
8401/16650 (epoch 25.228), train_loss = 0.86551879, grad/param norm = 2.6522e-01, time/batch = 17.4426s	
8402/16650 (epoch 25.231), train_loss = 0.91372039, grad/param norm = 2.8181e-01, time/batch = 18.7896s	
8403/16650 (epoch 25.234), train_loss = 1.12874149, grad/param norm = 3.0466e-01, time/batch = 16.2741s	
8404/16650 (epoch 25.237), train_loss = 1.00630909, grad/param norm = 4.5643e-01, time/batch = 17.9416s	
8405/16650 (epoch 25.240), train_loss = 0.99629059, grad/param norm = 2.8440e-01, time/batch = 17.7694s	
8406/16650 (epoch 25.243), train_loss = 0.96673971, grad/param norm = 2.9603e-01, time/batch = 14.9717s	
8407/16650 (epoch 25.246), train_loss = 1.06368636, grad/param norm = 2.8170e-01, time/batch = 15.8348s	
8408/16650 (epoch 25.249), train_loss = 0.82255257, grad/param norm = 2.4016e-01, time/batch = 17.9471s	
8409/16650 (epoch 25.252), train_loss = 0.90720009, grad/param norm = 2.6051e-01, time/batch = 17.9450s	
8410/16650 (epoch 25.255), train_loss = 0.99678154, grad/param norm = 2.6381e-01, time/batch = 15.0727s	
8411/16650 (epoch 25.258), train_loss = 1.04923561, grad/param norm = 2.7590e-01, time/batch = 17.7777s	
8412/16650 (epoch 25.261), train_loss = 0.98307423, grad/param norm = 2.8187e-01, time/batch = 16.6710s	
8413/16650 (epoch 25.264), train_loss = 0.89646402, grad/param norm = 2.5425e-01, time/batch = 18.3637s	
8414/16650 (epoch 25.267), train_loss = 0.91944057, grad/param norm = 2.4621e-01, time/batch = 15.0464s	
8415/16650 (epoch 25.270), train_loss = 0.97345084, grad/param norm = 2.5305e-01, time/batch = 17.0047s	
8416/16650 (epoch 25.273), train_loss = 1.07686705, grad/param norm = 2.7640e-01, time/batch = 17.6198s	
8417/16650 (epoch 25.276), train_loss = 0.97134026, grad/param norm = 2.3671e-01, time/batch = 17.5979s	
8418/16650 (epoch 25.279), train_loss = 0.94085134, grad/param norm = 2.5787e-01, time/batch = 17.2863s	
8419/16650 (epoch 25.282), train_loss = 0.84173493, grad/param norm = 2.3621e-01, time/batch = 18.2018s	
8420/16650 (epoch 25.285), train_loss = 0.86515384, grad/param norm = 2.4214e-01, time/batch = 19.2040s	
8421/16650 (epoch 25.288), train_loss = 0.87996019, grad/param norm = 2.5684e-01, time/batch = 16.1701s	
8422/16650 (epoch 25.291), train_loss = 0.72390660, grad/param norm = 2.1890e-01, time/batch = 17.5195s	
8423/16650 (epoch 25.294), train_loss = 0.81762523, grad/param norm = 2.1579e-01, time/batch = 17.4556s	
8424/16650 (epoch 25.297), train_loss = 0.91467572, grad/param norm = 2.3864e-01, time/batch = 16.3339s	
8425/16650 (epoch 25.300), train_loss = 0.73478204, grad/param norm = 2.2340e-01, time/batch = 17.3518s	
8426/16650 (epoch 25.303), train_loss = 0.80998507, grad/param norm = 2.2061e-01, time/batch = 17.6901s	
8427/16650 (epoch 25.306), train_loss = 1.00436798, grad/param norm = 2.4485e-01, time/batch = 17.5283s	
8428/16650 (epoch 25.309), train_loss = 1.02435013, grad/param norm = 3.0546e-01, time/batch = 17.3423s	
8429/16650 (epoch 25.312), train_loss = 0.83066042, grad/param norm = 2.7327e-01, time/batch = 17.9477s	
8430/16650 (epoch 25.315), train_loss = 0.67568561, grad/param norm = 2.1201e-01, time/batch = 17.6339s	
8431/16650 (epoch 25.318), train_loss = 0.78128811, grad/param norm = 2.3626e-01, time/batch = 16.3471s	
8432/16650 (epoch 25.321), train_loss = 1.06676021, grad/param norm = 2.9792e-01, time/batch = 18.6905s	
8433/16650 (epoch 25.324), train_loss = 0.88042271, grad/param norm = 3.0054e-01, time/batch = 15.0791s	
8434/16650 (epoch 25.327), train_loss = 0.98871849, grad/param norm = 3.1460e-01, time/batch = 18.0423s	
8435/16650 (epoch 25.330), train_loss = 0.96673937, grad/param norm = 2.8487e-01, time/batch = 17.5990s	
8436/16650 (epoch 25.333), train_loss = 1.00436832, grad/param norm = 2.9694e-01, time/batch = 16.5984s	
8437/16650 (epoch 25.336), train_loss = 0.85466214, grad/param norm = 2.9528e-01, time/batch = 17.0859s	
8438/16650 (epoch 25.339), train_loss = 0.89319535, grad/param norm = 2.5259e-01, time/batch = 16.3472s	
8439/16650 (epoch 25.342), train_loss = 0.86064685, grad/param norm = 2.7057e-01, time/batch = 18.1933s	
8440/16650 (epoch 25.345), train_loss = 0.81780262, grad/param norm = 2.3120e-01, time/batch = 17.0878s	
8441/16650 (epoch 25.348), train_loss = 0.91603401, grad/param norm = 2.8636e-01, time/batch = 16.3547s	
8442/16650 (epoch 25.351), train_loss = 0.98362218, grad/param norm = 2.7439e-01, time/batch = 17.1082s	
8443/16650 (epoch 25.354), train_loss = 1.00244114, grad/param norm = 3.0741e-01, time/batch = 14.4156s	
8444/16650 (epoch 25.357), train_loss = 0.96859051, grad/param norm = 2.7200e-01, time/batch = 18.0268s	
8445/16650 (epoch 25.360), train_loss = 0.95161229, grad/param norm = 2.6942e-01, time/batch = 15.9354s	
8446/16650 (epoch 25.363), train_loss = 1.04594312, grad/param norm = 2.9698e-01, time/batch = 17.4388s	
8447/16650 (epoch 25.366), train_loss = 1.07141562, grad/param norm = 2.6886e-01, time/batch = 16.6991s	
8448/16650 (epoch 25.369), train_loss = 0.94315845, grad/param norm = 2.7299e-01, time/batch = 18.8737s	
8449/16650 (epoch 25.372), train_loss = 0.94942658, grad/param norm = 2.4662e-01, time/batch = 31.5941s	
8450/16650 (epoch 25.375), train_loss = 0.96045767, grad/param norm = 2.4965e-01, time/batch = 17.6848s	
8451/16650 (epoch 25.378), train_loss = 0.86243399, grad/param norm = 2.4031e-01, time/batch = 16.9106s	
8452/16650 (epoch 25.381), train_loss = 0.95861128, grad/param norm = 2.6373e-01, time/batch = 17.6069s	
8453/16650 (epoch 25.384), train_loss = 1.09221284, grad/param norm = 2.8912e-01, time/batch = 17.9353s	
8454/16650 (epoch 25.387), train_loss = 0.75652874, grad/param norm = 2.4025e-01, time/batch = 18.1165s	
8455/16650 (epoch 25.390), train_loss = 1.01663195, grad/param norm = 2.5009e-01, time/batch = 17.0963s	
8456/16650 (epoch 25.393), train_loss = 0.88048271, grad/param norm = 2.6661e-01, time/batch = 17.1031s	
8457/16650 (epoch 25.396), train_loss = 1.07104807, grad/param norm = 3.3826e-01, time/batch = 18.2718s	
8458/16650 (epoch 25.399), train_loss = 0.98195802, grad/param norm = 2.5958e-01, time/batch = 15.3274s	
8459/16650 (epoch 25.402), train_loss = 0.87330844, grad/param norm = 2.9413e-01, time/batch = 16.7870s	
8460/16650 (epoch 25.405), train_loss = 0.75587739, grad/param norm = 2.6429e-01, time/batch = 16.6665s	
8461/16650 (epoch 25.408), train_loss = 0.97176899, grad/param norm = 3.0820e-01, time/batch = 16.0476s	
8462/16650 (epoch 25.411), train_loss = 0.82633072, grad/param norm = 2.7757e-01, time/batch = 16.8930s	
8463/16650 (epoch 25.414), train_loss = 0.87139844, grad/param norm = 3.8064e-01, time/batch = 17.1194s	
8464/16650 (epoch 25.417), train_loss = 0.82231325, grad/param norm = 2.7686e-01, time/batch = 18.4297s	
8465/16650 (epoch 25.420), train_loss = 0.82566934, grad/param norm = 2.5986e-01, time/batch = 16.5977s	
8466/16650 (epoch 25.423), train_loss = 0.70563864, grad/param norm = 2.2788e-01, time/batch = 17.4169s	
8467/16650 (epoch 25.426), train_loss = 0.82115939, grad/param norm = 2.7848e-01, time/batch = 18.5258s	
8468/16650 (epoch 25.429), train_loss = 1.03580548, grad/param norm = 2.8943e-01, time/batch = 17.5915s	
8469/16650 (epoch 25.432), train_loss = 1.01735217, grad/param norm = 3.0468e-01, time/batch = 16.5065s	
8470/16650 (epoch 25.435), train_loss = 1.12748482, grad/param norm = 2.8834e-01, time/batch = 18.8566s	
8471/16650 (epoch 25.438), train_loss = 1.12670843, grad/param norm = 3.3792e-01, time/batch = 17.4407s	
8472/16650 (epoch 25.441), train_loss = 0.93131969, grad/param norm = 2.9002e-01, time/batch = 16.4212s	
8473/16650 (epoch 25.444), train_loss = 0.88921010, grad/param norm = 2.9695e-01, time/batch = 16.1481s	
8474/16650 (epoch 25.447), train_loss = 0.91195454, grad/param norm = 3.1399e-01, time/batch = 16.5133s	
8475/16650 (epoch 25.450), train_loss = 0.87147163, grad/param norm = 2.5903e-01, time/batch = 16.8323s	
8476/16650 (epoch 25.453), train_loss = 0.86285650, grad/param norm = 2.8443e-01, time/batch = 16.7356s	
8477/16650 (epoch 25.456), train_loss = 0.79700499, grad/param norm = 2.3318e-01, time/batch = 18.8516s	
8478/16650 (epoch 25.459), train_loss = 0.86648319, grad/param norm = 2.5872e-01, time/batch = 17.7796s	
8479/16650 (epoch 25.462), train_loss = 1.05975702, grad/param norm = 2.8906e-01, time/batch = 16.7740s	
8480/16650 (epoch 25.465), train_loss = 0.86991677, grad/param norm = 2.8443e-01, time/batch = 17.8620s	
8481/16650 (epoch 25.468), train_loss = 0.74004274, grad/param norm = 2.6696e-01, time/batch = 18.4336s	
8482/16650 (epoch 25.471), train_loss = 0.60200787, grad/param norm = 2.0713e-01, time/batch = 16.5899s	
8483/16650 (epoch 25.474), train_loss = 0.79748461, grad/param norm = 2.6078e-01, time/batch = 15.9479s	
8484/16650 (epoch 25.477), train_loss = 0.99230261, grad/param norm = 2.8548e-01, time/batch = 17.3448s	
8485/16650 (epoch 25.480), train_loss = 0.98373735, grad/param norm = 3.2041e-01, time/batch = 16.2487s	
8486/16650 (epoch 25.483), train_loss = 1.01240312, grad/param norm = 2.7805e-01, time/batch = 16.5985s	
8487/16650 (epoch 25.486), train_loss = 0.83507354, grad/param norm = 2.2866e-01, time/batch = 17.6996s	
8488/16650 (epoch 25.489), train_loss = 0.86903524, grad/param norm = 2.6014e-01, time/batch = 17.1973s	
8489/16650 (epoch 25.492), train_loss = 0.91757707, grad/param norm = 2.4378e-01, time/batch = 17.5108s	
8490/16650 (epoch 25.495), train_loss = 0.80531778, grad/param norm = 2.4880e-01, time/batch = 17.5777s	
8491/16650 (epoch 25.498), train_loss = 0.87041121, grad/param norm = 2.7344e-01, time/batch = 18.7854s	
8492/16650 (epoch 25.502), train_loss = 1.07037265, grad/param norm = 3.4197e-01, time/batch = 17.0952s	
8493/16650 (epoch 25.505), train_loss = 0.96313178, grad/param norm = 2.5390e-01, time/batch = 15.9184s	
8494/16650 (epoch 25.508), train_loss = 0.95340742, grad/param norm = 2.9906e-01, time/batch = 17.9583s	
8495/16650 (epoch 25.511), train_loss = 1.03683618, grad/param norm = 2.8811e-01, time/batch = 16.4577s	
8496/16650 (epoch 25.514), train_loss = 0.78507112, grad/param norm = 2.5936e-01, time/batch = 17.1119s	
8497/16650 (epoch 25.517), train_loss = 0.88602584, grad/param norm = 2.6530e-01, time/batch = 16.6775s	
8498/16650 (epoch 25.520), train_loss = 0.82218469, grad/param norm = 2.4455e-01, time/batch = 18.4522s	
8499/16650 (epoch 25.523), train_loss = 0.89688844, grad/param norm = 2.5564e-01, time/batch = 17.2747s	
8500/16650 (epoch 25.526), train_loss = 1.00822300, grad/param norm = 3.0558e-01, time/batch = 15.7914s	
8501/16650 (epoch 25.529), train_loss = 1.06912310, grad/param norm = 3.1020e-01, time/batch = 17.7645s	
8502/16650 (epoch 25.532), train_loss = 0.69901391, grad/param norm = 2.3723e-01, time/batch = 18.7772s	
8503/16650 (epoch 25.535), train_loss = 0.79626612, grad/param norm = 2.8431e-01, time/batch = 16.6797s	
8504/16650 (epoch 25.538), train_loss = 0.77310283, grad/param norm = 2.4268e-01, time/batch = 18.3621s	
8505/16650 (epoch 25.541), train_loss = 1.04298432, grad/param norm = 2.9523e-01, time/batch = 17.8594s	
8506/16650 (epoch 25.544), train_loss = 1.09623063, grad/param norm = 3.3738e-01, time/batch = 17.0292s	
8507/16650 (epoch 25.547), train_loss = 0.80562391, grad/param norm = 2.6408e-01, time/batch = 15.5519s	
8508/16650 (epoch 25.550), train_loss = 0.91535603, grad/param norm = 2.6182e-01, time/batch = 18.2926s	
8509/16650 (epoch 25.553), train_loss = 0.89771947, grad/param norm = 2.7239e-01, time/batch = 16.0668s	
8510/16650 (epoch 25.556), train_loss = 0.83392608, grad/param norm = 2.5370e-01, time/batch = 16.6742s	
8511/16650 (epoch 25.559), train_loss = 0.73508576, grad/param norm = 2.6547e-01, time/batch = 17.8536s	
8512/16650 (epoch 25.562), train_loss = 0.85236526, grad/param norm = 2.5842e-01, time/batch = 17.9474s	
8513/16650 (epoch 25.565), train_loss = 0.73574344, grad/param norm = 2.7873e-01, time/batch = 17.1056s	
8514/16650 (epoch 25.568), train_loss = 0.72003970, grad/param norm = 2.4158e-01, time/batch = 16.8277s	
8515/16650 (epoch 25.571), train_loss = 0.78260934, grad/param norm = 2.8668e-01, time/batch = 17.6062s	
8516/16650 (epoch 25.574), train_loss = 0.86645043, grad/param norm = 2.7467e-01, time/batch = 16.5158s	
8517/16650 (epoch 25.577), train_loss = 0.83118349, grad/param norm = 2.3798e-01, time/batch = 14.9905s	
8518/16650 (epoch 25.580), train_loss = 0.74362229, grad/param norm = 2.2744e-01, time/batch = 16.2566s	
8519/16650 (epoch 25.583), train_loss = 0.87662503, grad/param norm = 2.4856e-01, time/batch = 15.5678s	
8520/16650 (epoch 25.586), train_loss = 0.81403782, grad/param norm = 2.9156e-01, time/batch = 18.7027s	
8521/16650 (epoch 25.589), train_loss = 0.77032905, grad/param norm = 2.2074e-01, time/batch = 17.0813s	
8522/16650 (epoch 25.592), train_loss = 0.88889881, grad/param norm = 2.5844e-01, time/batch = 18.0446s	
8523/16650 (epoch 25.595), train_loss = 0.83595400, grad/param norm = 2.9256e-01, time/batch = 17.9451s	
8524/16650 (epoch 25.598), train_loss = 0.86158970, grad/param norm = 2.6128e-01, time/batch = 16.7682s	
8525/16650 (epoch 25.601), train_loss = 0.82991621, grad/param norm = 3.0913e-01, time/batch = 18.1836s	
8526/16650 (epoch 25.604), train_loss = 0.97330935, grad/param norm = 3.0311e-01, time/batch = 15.9471s	
8527/16650 (epoch 25.607), train_loss = 0.93938452, grad/param norm = 2.6215e-01, time/batch = 17.8578s	
8528/16650 (epoch 25.610), train_loss = 0.81254292, grad/param norm = 2.8801e-01, time/batch = 16.0922s	
8529/16650 (epoch 25.613), train_loss = 1.03468522, grad/param norm = 2.9255e-01, time/batch = 16.4282s	
8530/16650 (epoch 25.616), train_loss = 1.01040297, grad/param norm = 3.5257e-01, time/batch = 17.0824s	
8531/16650 (epoch 25.619), train_loss = 0.74471534, grad/param norm = 2.2430e-01, time/batch = 17.0090s	
8532/16650 (epoch 25.622), train_loss = 0.71046582, grad/param norm = 2.5985e-01, time/batch = 18.1119s	
8533/16650 (epoch 25.625), train_loss = 0.84506646, grad/param norm = 2.4823e-01, time/batch = 15.5828s	
8534/16650 (epoch 25.628), train_loss = 0.83107251, grad/param norm = 3.4038e-01, time/batch = 17.8389s	
8535/16650 (epoch 25.631), train_loss = 0.93525387, grad/param norm = 3.4015e-01, time/batch = 15.7296s	
8536/16650 (epoch 25.634), train_loss = 1.07938443, grad/param norm = 3.1416e-01, time/batch = 18.1189s	
8537/16650 (epoch 25.637), train_loss = 1.08774189, grad/param norm = 2.9827e-01, time/batch = 17.6931s	
8538/16650 (epoch 25.640), train_loss = 0.84407666, grad/param norm = 2.6243e-01, time/batch = 16.0112s	
8539/16650 (epoch 25.643), train_loss = 0.94511607, grad/param norm = 2.4404e-01, time/batch = 18.8564s	
8540/16650 (epoch 25.646), train_loss = 0.96263606, grad/param norm = 2.8915e-01, time/batch = 17.7804s	
8541/16650 (epoch 25.649), train_loss = 0.90479374, grad/param norm = 3.0800e-01, time/batch = 15.2428s	
8542/16650 (epoch 25.652), train_loss = 0.99410039, grad/param norm = 2.8012e-01, time/batch = 17.0139s	
8543/16650 (epoch 25.655), train_loss = 0.92913910, grad/param norm = 2.5474e-01, time/batch = 18.7000s	
8544/16650 (epoch 25.658), train_loss = 0.80450735, grad/param norm = 2.8907e-01, time/batch = 17.5198s	
8545/16650 (epoch 25.661), train_loss = 0.92368507, grad/param norm = 2.6984e-01, time/batch = 16.0835s	
8546/16650 (epoch 25.664), train_loss = 0.91650490, grad/param norm = 2.7341e-01, time/batch = 15.6934s	
8547/16650 (epoch 25.667), train_loss = 1.00709602, grad/param norm = 2.6977e-01, time/batch = 18.1087s	
8548/16650 (epoch 25.670), train_loss = 0.77014855, grad/param norm = 2.6190e-01, time/batch = 17.7674s	
8549/16650 (epoch 25.673), train_loss = 0.82908781, grad/param norm = 2.4380e-01, time/batch = 16.5253s	
8550/16650 (epoch 25.676), train_loss = 0.92081545, grad/param norm = 2.8388e-01, time/batch = 17.1979s	
8551/16650 (epoch 25.679), train_loss = 0.79683186, grad/param norm = 2.5135e-01, time/batch = 18.7854s	
8552/16650 (epoch 25.682), train_loss = 0.91349175, grad/param norm = 2.7023e-01, time/batch = 15.1682s	
8553/16650 (epoch 25.685), train_loss = 0.76748031, grad/param norm = 2.5969e-01, time/batch = 16.3297s	
8554/16650 (epoch 25.688), train_loss = 0.95532751, grad/param norm = 2.5248e-01, time/batch = 17.9438s	
8555/16650 (epoch 25.691), train_loss = 0.95148336, grad/param norm = 2.6843e-01, time/batch = 17.1957s	
8556/16650 (epoch 25.694), train_loss = 0.80131931, grad/param norm = 2.4962e-01, time/batch = 16.8542s	
8557/16650 (epoch 25.697), train_loss = 0.76895689, grad/param norm = 2.3631e-01, time/batch = 14.9322s	
8558/16650 (epoch 25.700), train_loss = 0.95990140, grad/param norm = 2.8341e-01, time/batch = 17.7629s	
8559/16650 (epoch 25.703), train_loss = 0.77773438, grad/param norm = 2.4592e-01, time/batch = 16.6773s	
8560/16650 (epoch 25.706), train_loss = 0.87929893, grad/param norm = 2.5911e-01, time/batch = 18.0313s	
8561/16650 (epoch 25.709), train_loss = 0.80358797, grad/param norm = 2.5095e-01, time/batch = 18.3525s	
8562/16650 (epoch 25.712), train_loss = 0.80157765, grad/param norm = 2.6566e-01, time/batch = 17.3304s	
8563/16650 (epoch 25.715), train_loss = 0.96030346, grad/param norm = 2.7173e-01, time/batch = 17.4390s	
8564/16650 (epoch 25.718), train_loss = 1.01664226, grad/param norm = 2.9632e-01, time/batch = 17.2821s	
8565/16650 (epoch 25.721), train_loss = 0.96354777, grad/param norm = 2.5735e-01, time/batch = 17.2036s	
8566/16650 (epoch 25.724), train_loss = 0.99765390, grad/param norm = 2.9657e-01, time/batch = 16.4056s	
8567/16650 (epoch 25.727), train_loss = 0.97229750, grad/param norm = 2.7864e-01, time/batch = 18.1821s	
8568/16650 (epoch 25.730), train_loss = 0.83135910, grad/param norm = 2.5353e-01, time/batch = 17.3533s	
8569/16650 (epoch 25.733), train_loss = 0.99808703, grad/param norm = 2.7678e-01, time/batch = 14.8091s	
8570/16650 (epoch 25.736), train_loss = 0.76245454, grad/param norm = 2.5613e-01, time/batch = 17.3458s	
8571/16650 (epoch 25.739), train_loss = 0.88144114, grad/param norm = 2.4981e-01, time/batch = 17.0123s	
8572/16650 (epoch 25.742), train_loss = 0.88291096, grad/param norm = 2.4229e-01, time/batch = 16.8721s	
8573/16650 (epoch 25.745), train_loss = 0.69430617, grad/param norm = 2.3163e-01, time/batch = 16.3571s	
8574/16650 (epoch 25.748), train_loss = 0.77069883, grad/param norm = 2.4235e-01, time/batch = 18.0233s	
8575/16650 (epoch 25.751), train_loss = 0.91102167, grad/param norm = 3.3589e-01, time/batch = 17.4462s	
8576/16650 (epoch 25.754), train_loss = 1.09408725, grad/param norm = 3.3927e-01, time/batch = 14.8203s	
8577/16650 (epoch 25.757), train_loss = 1.04015512, grad/param norm = 3.1182e-01, time/batch = 17.1718s	
8578/16650 (epoch 25.760), train_loss = 0.89511995, grad/param norm = 2.7819e-01, time/batch = 18.5844s	
8579/16650 (epoch 25.763), train_loss = 0.84013118, grad/param norm = 2.5199e-01, time/batch = 18.0226s	
8580/16650 (epoch 25.766), train_loss = 0.87789034, grad/param norm = 2.4039e-01, time/batch = 16.2674s	
8581/16650 (epoch 25.769), train_loss = 0.91422449, grad/param norm = 2.5471e-01, time/batch = 17.4252s	
8582/16650 (epoch 25.772), train_loss = 0.87012485, grad/param norm = 2.3682e-01, time/batch = 17.6026s	
8583/16650 (epoch 25.775), train_loss = 0.86883813, grad/param norm = 2.6416e-01, time/batch = 17.1799s	
8584/16650 (epoch 25.778), train_loss = 0.89435131, grad/param norm = 2.3321e-01, time/batch = 16.8644s	
8585/16650 (epoch 25.781), train_loss = 1.02662753, grad/param norm = 2.4659e-01, time/batch = 16.0202s	
8586/16650 (epoch 25.784), train_loss = 0.94908350, grad/param norm = 2.7335e-01, time/batch = 18.6173s	
8587/16650 (epoch 25.787), train_loss = 0.96185862, grad/param norm = 2.4406e-01, time/batch = 15.9977s	
8588/16650 (epoch 25.790), train_loss = 0.94447344, grad/param norm = 2.3086e-01, time/batch = 16.3274s	
8589/16650 (epoch 25.793), train_loss = 0.79971464, grad/param norm = 2.8114e-01, time/batch = 18.2097s	
8590/16650 (epoch 25.796), train_loss = 1.18711965, grad/param norm = 3.1012e-01, time/batch = 17.2715s	
8591/16650 (epoch 25.799), train_loss = 1.10602760, grad/param norm = 3.2132e-01, time/batch = 15.0919s	
8592/16650 (epoch 25.802), train_loss = 0.97748548, grad/param norm = 3.1409e-01, time/batch = 17.5213s	
8593/16650 (epoch 25.805), train_loss = 0.90618803, grad/param norm = 2.4150e-01, time/batch = 17.8626s	
8594/16650 (epoch 25.808), train_loss = 0.96886029, grad/param norm = 2.7044e-01, time/batch = 17.1779s	
8595/16650 (epoch 25.811), train_loss = 1.01916552, grad/param norm = 2.6798e-01, time/batch = 16.6830s	
8596/16650 (epoch 25.814), train_loss = 0.80588389, grad/param norm = 2.4627e-01, time/batch = 18.4331s	
8597/16650 (epoch 25.817), train_loss = 0.85888918, grad/param norm = 2.7589e-01, time/batch = 17.5906s	
8598/16650 (epoch 25.820), train_loss = 0.97132919, grad/param norm = 2.8177e-01, time/batch = 17.0269s	
8599/16650 (epoch 25.823), train_loss = 0.87364206, grad/param norm = 2.3619e-01, time/batch = 17.1814s	
8600/16650 (epoch 25.826), train_loss = 0.87959221, grad/param norm = 2.6911e-01, time/batch = 16.9435s	
8601/16650 (epoch 25.829), train_loss = 0.94515065, grad/param norm = 2.6984e-01, time/batch = 16.6704s	
8602/16650 (epoch 25.832), train_loss = 0.98962232, grad/param norm = 2.7259e-01, time/batch = 17.6095s	
8603/16650 (epoch 25.835), train_loss = 0.97948126, grad/param norm = 3.1363e-01, time/batch = 17.6950s	
8604/16650 (epoch 25.838), train_loss = 0.83373893, grad/param norm = 2.4863e-01, time/batch = 17.2672s	
8605/16650 (epoch 25.841), train_loss = 0.85273500, grad/param norm = 2.5227e-01, time/batch = 15.4990s	
8606/16650 (epoch 25.844), train_loss = 0.84487829, grad/param norm = 2.5192e-01, time/batch = 16.9362s	
8607/16650 (epoch 25.847), train_loss = 0.98790375, grad/param norm = 2.8160e-01, time/batch = 18.2883s	
8608/16650 (epoch 25.850), train_loss = 0.80128616, grad/param norm = 2.6822e-01, time/batch = 16.5190s	
8609/16650 (epoch 25.853), train_loss = 0.90912665, grad/param norm = 2.7307e-01, time/batch = 18.3711s	
8610/16650 (epoch 25.856), train_loss = 0.84900318, grad/param norm = 2.6873e-01, time/batch = 17.5330s	
8611/16650 (epoch 25.859), train_loss = 1.01013766, grad/param norm = 2.7900e-01, time/batch = 16.4787s	
8612/16650 (epoch 25.862), train_loss = 0.87923186, grad/param norm = 2.3205e-01, time/batch = 16.6014s	
8613/16650 (epoch 25.865), train_loss = 0.74619622, grad/param norm = 2.1837e-01, time/batch = 14.9205s	
8614/16650 (epoch 25.868), train_loss = 0.94674694, grad/param norm = 2.6616e-01, time/batch = 17.0465s	
8615/16650 (epoch 25.871), train_loss = 0.93754711, grad/param norm = 2.6099e-01, time/batch = 17.0939s	
8616/16650 (epoch 25.874), train_loss = 0.94931044, grad/param norm = 2.5809e-01, time/batch = 17.0272s	
8617/16650 (epoch 25.877), train_loss = 0.92597371, grad/param norm = 2.6955e-01, time/batch = 16.7736s	
8618/16650 (epoch 25.880), train_loss = 0.80587959, grad/param norm = 2.6135e-01, time/batch = 17.0835s	
8619/16650 (epoch 25.883), train_loss = 0.92306362, grad/param norm = 2.6504e-01, time/batch = 16.5321s	
8620/16650 (epoch 25.886), train_loss = 0.90319742, grad/param norm = 2.5263e-01, time/batch = 17.6290s	
8621/16650 (epoch 25.889), train_loss = 0.76808028, grad/param norm = 2.5249e-01, time/batch = 18.3686s	
8622/16650 (epoch 25.892), train_loss = 0.90665776, grad/param norm = 2.4747e-01, time/batch = 16.1690s	
8623/16650 (epoch 25.895), train_loss = 0.92945152, grad/param norm = 2.8490e-01, time/batch = 16.6037s	
8624/16650 (epoch 25.898), train_loss = 0.91621086, grad/param norm = 2.8908e-01, time/batch = 17.6963s	
8625/16650 (epoch 25.901), train_loss = 0.88490750, grad/param norm = 2.5135e-01, time/batch = 16.1005s	
8626/16650 (epoch 25.904), train_loss = 0.83190330, grad/param norm = 2.5491e-01, time/batch = 18.1217s	
8627/16650 (epoch 25.907), train_loss = 0.94717324, grad/param norm = 2.7069e-01, time/batch = 18.1982s	
8628/16650 (epoch 25.910), train_loss = 0.96031672, grad/param norm = 2.8598e-01, time/batch = 18.2051s	
8629/16650 (epoch 25.913), train_loss = 0.85031250, grad/param norm = 2.7707e-01, time/batch = 15.5598s	
8630/16650 (epoch 25.916), train_loss = 0.88647850, grad/param norm = 2.6863e-01, time/batch = 18.0843s	
8631/16650 (epoch 25.919), train_loss = 1.06267868, grad/param norm = 2.7893e-01, time/batch = 18.9639s	
8632/16650 (epoch 25.922), train_loss = 0.99160068, grad/param norm = 2.9414e-01, time/batch = 16.6006s	
8633/16650 (epoch 25.925), train_loss = 0.84883043, grad/param norm = 2.7965e-01, time/batch = 14.3253s	
8634/16650 (epoch 25.928), train_loss = 0.90455643, grad/param norm = 2.6707e-01, time/batch = 16.9947s	
8635/16650 (epoch 25.931), train_loss = 0.98868243, grad/param norm = 2.8435e-01, time/batch = 17.9344s	
8636/16650 (epoch 25.934), train_loss = 0.79067424, grad/param norm = 2.7460e-01, time/batch = 17.0231s	
8637/16650 (epoch 25.937), train_loss = 0.83120035, grad/param norm = 2.8170e-01, time/batch = 17.5196s	
8638/16650 (epoch 25.940), train_loss = 0.86005841, grad/param norm = 2.1337e-01, time/batch = 17.7034s	
8639/16650 (epoch 25.943), train_loss = 0.94697826, grad/param norm = 3.0160e-01, time/batch = 16.1030s	
8640/16650 (epoch 25.946), train_loss = 0.81963051, grad/param norm = 2.7571e-01, time/batch = 4.0954s	
8641/16650 (epoch 25.949), train_loss = 0.82019525, grad/param norm = 3.1777e-01, time/batch = 0.6386s	
8642/16650 (epoch 25.952), train_loss = 0.76803798, grad/param norm = 2.4676e-01, time/batch = 0.6302s	
8643/16650 (epoch 25.955), train_loss = 0.88247231, grad/param norm = 2.4749e-01, time/batch = 0.6272s	
8644/16650 (epoch 25.958), train_loss = 0.98302005, grad/param norm = 4.7256e-01, time/batch = 0.6303s	
8645/16650 (epoch 25.961), train_loss = 0.90550005, grad/param norm = 2.7047e-01, time/batch = 0.6291s	
8646/16650 (epoch 25.964), train_loss = 0.83564804, grad/param norm = 2.9296e-01, time/batch = 0.6297s	
8647/16650 (epoch 25.967), train_loss = 1.02422576, grad/param norm = 3.0044e-01, time/batch = 0.6348s	
8648/16650 (epoch 25.970), train_loss = 0.85243998, grad/param norm = 2.6358e-01, time/batch = 0.9010s	
8649/16650 (epoch 25.973), train_loss = 0.85649370, grad/param norm = 2.8272e-01, time/batch = 0.9320s	
8650/16650 (epoch 25.976), train_loss = 0.83465975, grad/param norm = 2.5846e-01, time/batch = 0.9235s	
8651/16650 (epoch 25.979), train_loss = 0.92811399, grad/param norm = 2.7632e-01, time/batch = 0.9242s	
8652/16650 (epoch 25.982), train_loss = 0.95448752, grad/param norm = 2.6761e-01, time/batch = 0.9311s	
8653/16650 (epoch 25.985), train_loss = 0.88235924, grad/param norm = 2.9016e-01, time/batch = 1.3798s	
8654/16650 (epoch 25.988), train_loss = 1.00963307, grad/param norm = 2.8043e-01, time/batch = 1.7224s	
8655/16650 (epoch 25.991), train_loss = 0.83280690, grad/param norm = 2.6840e-01, time/batch = 1.7527s	
8656/16650 (epoch 25.994), train_loss = 0.83861359, grad/param norm = 2.4679e-01, time/batch = 13.2794s	
8657/16650 (epoch 25.997), train_loss = 0.89025190, grad/param norm = 2.6699e-01, time/batch = 18.4604s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
8658/16650 (epoch 26.000), train_loss = 0.95960990, grad/param norm = 3.0880e-01, time/batch = 16.8502s	
8659/16650 (epoch 26.003), train_loss = 1.00187911, grad/param norm = 2.9417e-01, time/batch = 14.9050s	
8660/16650 (epoch 26.006), train_loss = 1.00075224, grad/param norm = 3.5388e-01, time/batch = 17.9523s	
8661/16650 (epoch 26.009), train_loss = 1.06210517, grad/param norm = 2.7547e-01, time/batch = 17.3520s	
8662/16650 (epoch 26.012), train_loss = 1.03971520, grad/param norm = 2.7360e-01, time/batch = 17.6931s	
8663/16650 (epoch 26.015), train_loss = 0.91430945, grad/param norm = 2.7800e-01, time/batch = 17.1123s	
8664/16650 (epoch 26.018), train_loss = 0.77780408, grad/param norm = 2.5676e-01, time/batch = 17.7019s	
8665/16650 (epoch 26.021), train_loss = 1.01043031, grad/param norm = 2.8253e-01, time/batch = 15.4199s	
8666/16650 (epoch 26.024), train_loss = 0.89499705, grad/param norm = 2.8493e-01, time/batch = 18.0480s	
8667/16650 (epoch 26.027), train_loss = 0.98940033, grad/param norm = 2.9104e-01, time/batch = 16.7722s	
8668/16650 (epoch 26.030), train_loss = 0.79290233, grad/param norm = 2.4824e-01, time/batch = 16.8141s	
8669/16650 (epoch 26.033), train_loss = 0.92123671, grad/param norm = 2.5334e-01, time/batch = 14.7085s	
8670/16650 (epoch 26.036), train_loss = 0.68331796, grad/param norm = 2.5061e-01, time/batch = 14.1815s	
8671/16650 (epoch 26.039), train_loss = 1.01341977, grad/param norm = 2.6868e-01, time/batch = 14.4969s	
8672/16650 (epoch 26.042), train_loss = 0.98506027, grad/param norm = 2.9182e-01, time/batch = 15.3384s	
8673/16650 (epoch 26.045), train_loss = 0.86515653, grad/param norm = 2.7698e-01, time/batch = 27.6223s	
8674/16650 (epoch 26.048), train_loss = 1.01231062, grad/param norm = 3.3326e-01, time/batch = 14.9003s	
8675/16650 (epoch 26.051), train_loss = 0.87654546, grad/param norm = 2.6962e-01, time/batch = 15.8305s	
8676/16650 (epoch 26.054), train_loss = 0.91300616, grad/param norm = 2.9908e-01, time/batch = 16.9363s	
8677/16650 (epoch 26.057), train_loss = 0.94716569, grad/param norm = 2.9923e-01, time/batch = 16.2498s	
8678/16650 (epoch 26.060), train_loss = 0.77520818, grad/param norm = 2.3180e-01, time/batch = 18.6276s	
8679/16650 (epoch 26.063), train_loss = 0.88862982, grad/param norm = 2.7085e-01, time/batch = 16.4971s	
8680/16650 (epoch 26.066), train_loss = 1.06349708, grad/param norm = 2.8052e-01, time/batch = 17.0328s	
8681/16650 (epoch 26.069), train_loss = 0.98579194, grad/param norm = 3.0078e-01, time/batch = 18.1974s	
8682/16650 (epoch 26.072), train_loss = 0.89915751, grad/param norm = 2.8811e-01, time/batch = 17.0148s	
8683/16650 (epoch 26.075), train_loss = 0.99037815, grad/param norm = 2.6509e-01, time/batch = 17.1874s	
8684/16650 (epoch 26.078), train_loss = 1.03343237, grad/param norm = 2.8876e-01, time/batch = 18.1952s	
8685/16650 (epoch 26.081), train_loss = 0.95021603, grad/param norm = 3.2216e-01, time/batch = 15.8369s	
8686/16650 (epoch 26.084), train_loss = 0.97103210, grad/param norm = 2.7415e-01, time/batch = 16.8181s	
8687/16650 (epoch 26.087), train_loss = 0.91521392, grad/param norm = 2.7966e-01, time/batch = 17.3434s	
8688/16650 (epoch 26.090), train_loss = 0.90434772, grad/param norm = 2.6841e-01, time/batch = 18.4389s	
8689/16650 (epoch 26.093), train_loss = 1.10325281, grad/param norm = 3.4683e-01, time/batch = 17.8446s	
8690/16650 (epoch 26.096), train_loss = 0.87159288, grad/param norm = 2.5137e-01, time/batch = 17.6141s	
8691/16650 (epoch 26.099), train_loss = 0.93649118, grad/param norm = 3.0924e-01, time/batch = 15.6911s	
8692/16650 (epoch 26.102), train_loss = 0.91342912, grad/param norm = 2.5628e-01, time/batch = 15.9121s	
8693/16650 (epoch 26.105), train_loss = 0.96216530, grad/param norm = 3.0390e-01, time/batch = 16.3544s	
8694/16650 (epoch 26.108), train_loss = 0.95402333, grad/param norm = 2.7767e-01, time/batch = 16.0947s	
8695/16650 (epoch 26.111), train_loss = 1.01488390, grad/param norm = 2.6811e-01, time/batch = 17.1780s	
8696/16650 (epoch 26.114), train_loss = 1.00807261, grad/param norm = 3.2969e-01, time/batch = 17.9471s	
8697/16650 (epoch 26.117), train_loss = 1.07715895, grad/param norm = 2.6663e-01, time/batch = 17.6843s	
8698/16650 (epoch 26.120), train_loss = 0.87291160, grad/param norm = 2.4965e-01, time/batch = 16.6854s	
8699/16650 (epoch 26.123), train_loss = 0.90527528, grad/param norm = 2.6391e-01, time/batch = 18.7896s	
8700/16650 (epoch 26.126), train_loss = 0.94379792, grad/param norm = 2.5177e-01, time/batch = 16.8456s	
8701/16650 (epoch 26.129), train_loss = 0.94898398, grad/param norm = 2.9871e-01, time/batch = 17.5294s	
8702/16650 (epoch 26.132), train_loss = 0.92100217, grad/param norm = 2.7329e-01, time/batch = 17.6120s	
8703/16650 (epoch 26.135), train_loss = 1.00813889, grad/param norm = 2.7430e-01, time/batch = 14.4554s	
8704/16650 (epoch 26.138), train_loss = 1.00481857, grad/param norm = 2.5394e-01, time/batch = 16.9370s	
8705/16650 (epoch 26.141), train_loss = 0.96617179, grad/param norm = 2.6522e-01, time/batch = 16.8682s	
8706/16650 (epoch 26.144), train_loss = 0.94315516, grad/param norm = 2.8792e-01, time/batch = 17.9584s	
8707/16650 (epoch 26.147), train_loss = 1.06159849, grad/param norm = 2.5641e-01, time/batch = 15.5064s	
8708/16650 (epoch 26.150), train_loss = 1.16374267, grad/param norm = 3.3962e-01, time/batch = 17.9470s	
8709/16650 (epoch 26.153), train_loss = 0.97082336, grad/param norm = 3.1349e-01, time/batch = 16.9406s	
8710/16650 (epoch 26.156), train_loss = 0.86383712, grad/param norm = 2.6013e-01, time/batch = 16.9442s	
8711/16650 (epoch 26.159), train_loss = 0.98416949, grad/param norm = 2.8904e-01, time/batch = 17.2585s	
8712/16650 (epoch 26.162), train_loss = 1.05462218, grad/param norm = 2.7099e-01, time/batch = 18.1966s	
8713/16650 (epoch 26.165), train_loss = 1.05240149, grad/param norm = 2.9823e-01, time/batch = 16.0147s	
8714/16650 (epoch 26.168), train_loss = 0.80064898, grad/param norm = 2.4538e-01, time/batch = 16.7693s	
8715/16650 (epoch 26.171), train_loss = 1.02090880, grad/param norm = 2.4822e-01, time/batch = 18.5272s	
8716/16650 (epoch 26.174), train_loss = 0.77736632, grad/param norm = 2.6042e-01, time/batch = 14.4921s	
8717/16650 (epoch 26.177), train_loss = 0.92978997, grad/param norm = 2.7798e-01, time/batch = 17.0366s	
8718/16650 (epoch 26.180), train_loss = 1.05028012, grad/param norm = 2.8757e-01, time/batch = 17.4215s	
8719/16650 (epoch 26.183), train_loss = 1.14562711, grad/param norm = 3.1024e-01, time/batch = 18.4529s	
8720/16650 (epoch 26.186), train_loss = 0.99826170, grad/param norm = 2.9849e-01, time/batch = 18.0961s	
8721/16650 (epoch 26.189), train_loss = 0.87363593, grad/param norm = 2.5474e-01, time/batch = 16.1646s	
8722/16650 (epoch 26.192), train_loss = 0.88005443, grad/param norm = 2.7467e-01, time/batch = 18.4447s	
8723/16650 (epoch 26.195), train_loss = 0.87188710, grad/param norm = 2.5522e-01, time/batch = 18.3026s	
8724/16650 (epoch 26.198), train_loss = 0.79563137, grad/param norm = 2.3029e-01, time/batch = 16.0873s	
8725/16650 (epoch 26.201), train_loss = 0.85417829, grad/param norm = 2.6430e-01, time/batch = 16.2670s	
8726/16650 (epoch 26.204), train_loss = 0.94457741, grad/param norm = 2.7145e-01, time/batch = 18.4424s	
8727/16650 (epoch 26.207), train_loss = 0.96744903, grad/param norm = 3.0073e-01, time/batch = 18.2956s	
8728/16650 (epoch 26.210), train_loss = 0.90098124, grad/param norm = 2.6876e-01, time/batch = 16.5081s	
8729/16650 (epoch 26.213), train_loss = 1.01165543, grad/param norm = 2.8517e-01, time/batch = 17.6166s	
8730/16650 (epoch 26.216), train_loss = 0.90051514, grad/param norm = 2.8659e-01, time/batch = 17.7848s	
8731/16650 (epoch 26.219), train_loss = 0.92250328, grad/param norm = 2.7444e-01, time/batch = 17.1932s	
8732/16650 (epoch 26.222), train_loss = 0.96196869, grad/param norm = 2.5705e-01, time/batch = 15.6449s	
8733/16650 (epoch 26.225), train_loss = 0.94182009, grad/param norm = 2.7391e-01, time/batch = 17.3677s	
8734/16650 (epoch 26.228), train_loss = 0.85828723, grad/param norm = 2.6292e-01, time/batch = 17.0304s	
8735/16650 (epoch 26.231), train_loss = 0.90306032, grad/param norm = 2.9950e-01, time/batch = 16.3448s	
8736/16650 (epoch 26.234), train_loss = 1.10525409, grad/param norm = 2.6851e-01, time/batch = 14.6583s	
8737/16650 (epoch 26.237), train_loss = 0.96967926, grad/param norm = 2.9226e-01, time/batch = 15.6837s	
8738/16650 (epoch 26.240), train_loss = 0.96571917, grad/param norm = 2.7809e-01, time/batch = 16.6064s	
8739/16650 (epoch 26.243), train_loss = 0.92310278, grad/param norm = 2.7493e-01, time/batch = 16.3352s	
8740/16650 (epoch 26.246), train_loss = 1.05140930, grad/param norm = 2.7773e-01, time/batch = 16.4627s	
8741/16650 (epoch 26.249), train_loss = 0.80044742, grad/param norm = 2.3197e-01, time/batch = 16.9419s	
8742/16650 (epoch 26.252), train_loss = 0.88433938, grad/param norm = 2.5288e-01, time/batch = 15.7764s	
8743/16650 (epoch 26.255), train_loss = 0.97900019, grad/param norm = 2.6575e-01, time/batch = 13.3678s	
8744/16650 (epoch 26.258), train_loss = 1.02978026, grad/param norm = 2.8682e-01, time/batch = 13.3214s	
8745/16650 (epoch 26.261), train_loss = 0.96445109, grad/param norm = 2.6851e-01, time/batch = 14.0317s	
8746/16650 (epoch 26.264), train_loss = 0.87995719, grad/param norm = 2.5047e-01, time/batch = 15.9975s	
8747/16650 (epoch 26.267), train_loss = 0.90409607, grad/param norm = 2.7588e-01, time/batch = 15.4470s	
8748/16650 (epoch 26.270), train_loss = 0.96062905, grad/param norm = 2.5391e-01, time/batch = 16.0323s	
8749/16650 (epoch 26.273), train_loss = 1.05740512, grad/param norm = 2.6345e-01, time/batch = 17.6264s	
8750/16650 (epoch 26.276), train_loss = 0.95045350, grad/param norm = 2.5389e-01, time/batch = 16.0071s	
8751/16650 (epoch 26.279), train_loss = 0.93547277, grad/param norm = 2.8285e-01, time/batch = 17.2942s	
8752/16650 (epoch 26.282), train_loss = 0.81079988, grad/param norm = 2.3181e-01, time/batch = 16.1198s	
8753/16650 (epoch 26.285), train_loss = 0.84836924, grad/param norm = 2.5317e-01, time/batch = 17.0321s	
8754/16650 (epoch 26.288), train_loss = 0.86096219, grad/param norm = 2.7005e-01, time/batch = 16.4170s	
8755/16650 (epoch 26.291), train_loss = 0.70338879, grad/param norm = 2.1112e-01, time/batch = 17.3731s	
8756/16650 (epoch 26.294), train_loss = 0.80592671, grad/param norm = 2.1671e-01, time/batch = 15.6170s	
8757/16650 (epoch 26.297), train_loss = 0.90576383, grad/param norm = 2.3322e-01, time/batch = 15.8419s	
8758/16650 (epoch 26.300), train_loss = 0.72796993, grad/param norm = 2.1379e-01, time/batch = 17.4275s	
8759/16650 (epoch 26.303), train_loss = 0.80166220, grad/param norm = 2.2633e-01, time/batch = 17.0401s	
8760/16650 (epoch 26.306), train_loss = 0.98980792, grad/param norm = 2.4361e-01, time/batch = 16.2500s	
8761/16650 (epoch 26.309), train_loss = 1.00909443, grad/param norm = 2.8719e-01, time/batch = 16.4150s	
8762/16650 (epoch 26.312), train_loss = 0.80888986, grad/param norm = 2.6697e-01, time/batch = 15.9110s	
8763/16650 (epoch 26.315), train_loss = 0.66824166, grad/param norm = 2.0977e-01, time/batch = 17.1224s	
8764/16650 (epoch 26.318), train_loss = 0.76343183, grad/param norm = 2.3144e-01, time/batch = 16.6062s	
8765/16650 (epoch 26.321), train_loss = 1.05236806, grad/param norm = 3.0352e-01, time/batch = 15.8545s	
8766/16650 (epoch 26.324), train_loss = 0.85784916, grad/param norm = 2.6064e-01, time/batch = 17.9512s	
8767/16650 (epoch 26.327), train_loss = 0.96463229, grad/param norm = 3.0280e-01, time/batch = 17.8685s	
8768/16650 (epoch 26.330), train_loss = 0.95732734, grad/param norm = 3.2946e-01, time/batch = 16.2609s	
8769/16650 (epoch 26.333), train_loss = 0.97104805, grad/param norm = 2.9155e-01, time/batch = 16.1849s	
8770/16650 (epoch 26.336), train_loss = 0.82967509, grad/param norm = 3.0899e-01, time/batch = 17.7929s	
8771/16650 (epoch 26.339), train_loss = 0.89116641, grad/param norm = 2.8748e-01, time/batch = 17.2793s	
8772/16650 (epoch 26.342), train_loss = 0.82577683, grad/param norm = 2.7860e-01, time/batch = 17.6141s	
8773/16650 (epoch 26.345), train_loss = 0.79984492, grad/param norm = 2.4922e-01, time/batch = 16.3710s	
8774/16650 (epoch 26.348), train_loss = 0.89599567, grad/param norm = 3.0115e-01, time/batch = 15.4244s	
8775/16650 (epoch 26.351), train_loss = 0.96073797, grad/param norm = 2.7943e-01, time/batch = 16.0235s	
8776/16650 (epoch 26.354), train_loss = 0.97707689, grad/param norm = 2.7969e-01, time/batch = 16.9335s	
8777/16650 (epoch 26.357), train_loss = 0.96422376, grad/param norm = 2.9833e-01, time/batch = 16.1286s	
8778/16650 (epoch 26.360), train_loss = 0.93017722, grad/param norm = 2.6945e-01, time/batch = 18.1164s	
8779/16650 (epoch 26.363), train_loss = 1.02893768, grad/param norm = 2.9140e-01, time/batch = 15.4867s	
8780/16650 (epoch 26.366), train_loss = 1.04917089, grad/param norm = 3.2133e-01, time/batch = 16.7413s	
8781/16650 (epoch 26.369), train_loss = 0.93193474, grad/param norm = 2.7473e-01, time/batch = 17.6371s	
8782/16650 (epoch 26.372), train_loss = 0.92379454, grad/param norm = 2.5428e-01, time/batch = 15.7429s	
8783/16650 (epoch 26.375), train_loss = 0.92678023, grad/param norm = 2.2759e-01, time/batch = 17.3751s	
8784/16650 (epoch 26.378), train_loss = 0.86265683, grad/param norm = 2.4642e-01, time/batch = 16.8002s	
8785/16650 (epoch 26.381), train_loss = 0.94265023, grad/param norm = 3.0581e-01, time/batch = 16.9606s	
8786/16650 (epoch 26.384), train_loss = 1.05583881, grad/param norm = 2.5790e-01, time/batch = 15.7535s	
8787/16650 (epoch 26.387), train_loss = 0.74357890, grad/param norm = 2.4324e-01, time/batch = 17.8764s	
8788/16650 (epoch 26.390), train_loss = 1.00120522, grad/param norm = 2.5096e-01, time/batch = 16.4502s	
8789/16650 (epoch 26.393), train_loss = 0.87667636, grad/param norm = 2.8516e-01, time/batch = 16.4314s	
8790/16650 (epoch 26.396), train_loss = 1.02628703, grad/param norm = 3.1181e-01, time/batch = 16.7954s	
8791/16650 (epoch 26.399), train_loss = 0.97582100, grad/param norm = 2.9007e-01, time/batch = 16.8609s	
8792/16650 (epoch 26.402), train_loss = 0.84481960, grad/param norm = 2.6571e-01, time/batch = 15.8327s	
8793/16650 (epoch 26.405), train_loss = 0.77139953, grad/param norm = 3.4828e-01, time/batch = 15.7539s	
8794/16650 (epoch 26.408), train_loss = 0.93438985, grad/param norm = 2.7892e-01, time/batch = 16.5114s	
8795/16650 (epoch 26.411), train_loss = 0.81206065, grad/param norm = 2.8837e-01, time/batch = 16.4568s	
8796/16650 (epoch 26.414), train_loss = 0.83209294, grad/param norm = 2.7799e-01, time/batch = 17.4569s	
8797/16650 (epoch 26.417), train_loss = 0.80935229, grad/param norm = 2.8320e-01, time/batch = 15.9098s	
8798/16650 (epoch 26.420), train_loss = 0.80033435, grad/param norm = 2.6035e-01, time/batch = 18.1248s	
8799/16650 (epoch 26.423), train_loss = 0.70571078, grad/param norm = 2.5158e-01, time/batch = 16.2086s	
8800/16650 (epoch 26.426), train_loss = 0.79887029, grad/param norm = 2.8267e-01, time/batch = 16.3425s	
8801/16650 (epoch 26.429), train_loss = 1.00557207, grad/param norm = 2.9146e-01, time/batch = 16.3587s	
8802/16650 (epoch 26.432), train_loss = 0.99851876, grad/param norm = 2.9891e-01, time/batch = 17.5322s	
8803/16650 (epoch 26.435), train_loss = 1.10755162, grad/param norm = 3.2214e-01, time/batch = 17.4744s	
8804/16650 (epoch 26.438), train_loss = 1.10135743, grad/param norm = 3.8532e-01, time/batch = 15.8339s	
8805/16650 (epoch 26.441), train_loss = 0.90946167, grad/param norm = 3.1078e-01, time/batch = 15.9298s	
8806/16650 (epoch 26.444), train_loss = 0.86479546, grad/param norm = 2.9072e-01, time/batch = 17.0148s	
8807/16650 (epoch 26.447), train_loss = 0.87910118, grad/param norm = 2.9502e-01, time/batch = 16.4510s	
8808/16650 (epoch 26.450), train_loss = 0.86955129, grad/param norm = 2.8427e-01, time/batch = 15.7617s	
8809/16650 (epoch 26.453), train_loss = 0.84799802, grad/param norm = 2.9169e-01, time/batch = 17.4504s	
8810/16650 (epoch 26.456), train_loss = 0.79132610, grad/param norm = 2.3735e-01, time/batch = 16.9512s	
8811/16650 (epoch 26.459), train_loss = 0.84070980, grad/param norm = 2.5574e-01, time/batch = 16.5150s	
8812/16650 (epoch 26.462), train_loss = 1.05339857, grad/param norm = 3.4409e-01, time/batch = 16.2659s	
8813/16650 (epoch 26.465), train_loss = 0.84582299, grad/param norm = 2.6839e-01, time/batch = 16.7846s	
8814/16650 (epoch 26.468), train_loss = 0.71489135, grad/param norm = 2.5833e-01, time/batch = 16.7625s	
8815/16650 (epoch 26.471), train_loss = 0.59926569, grad/param norm = 2.0064e-01, time/batch = 16.5238s	
8816/16650 (epoch 26.474), train_loss = 0.77745749, grad/param norm = 2.7976e-01, time/batch = 16.5262s	
8817/16650 (epoch 26.477), train_loss = 0.97249297, grad/param norm = 3.1885e-01, time/batch = 17.4540s	
8818/16650 (epoch 26.480), train_loss = 0.98722815, grad/param norm = 3.7084e-01, time/batch = 15.6496s	
8819/16650 (epoch 26.483), train_loss = 1.00139106, grad/param norm = 2.8182e-01, time/batch = 15.4052s	
8820/16650 (epoch 26.486), train_loss = 0.81429614, grad/param norm = 2.3480e-01, time/batch = 17.6974s	
8821/16650 (epoch 26.489), train_loss = 0.84513294, grad/param norm = 2.6321e-01, time/batch = 17.7818s	
8822/16650 (epoch 26.492), train_loss = 0.89328350, grad/param norm = 2.3382e-01, time/batch = 16.5060s	
8823/16650 (epoch 26.495), train_loss = 0.78483222, grad/param norm = 2.5999e-01, time/batch = 15.2639s	
8824/16650 (epoch 26.498), train_loss = 0.83565148, grad/param norm = 2.6614e-01, time/batch = 17.8638s	
8825/16650 (epoch 26.502), train_loss = 1.05876750, grad/param norm = 3.2402e-01, time/batch = 16.9321s	
8826/16650 (epoch 26.505), train_loss = 0.93405852, grad/param norm = 2.4362e-01, time/batch = 17.1762s	
8827/16650 (epoch 26.508), train_loss = 0.92622633, grad/param norm = 2.8982e-01, time/batch = 17.3773s	
8828/16650 (epoch 26.511), train_loss = 1.00327742, grad/param norm = 2.8402e-01, time/batch = 15.1013s	
8829/16650 (epoch 26.514), train_loss = 0.78508147, grad/param norm = 2.6252e-01, time/batch = 15.6791s	
8830/16650 (epoch 26.517), train_loss = 0.88203987, grad/param norm = 2.9103e-01, time/batch = 16.5239s	
8831/16650 (epoch 26.520), train_loss = 0.79300377, grad/param norm = 2.5969e-01, time/batch = 17.6203s	
8832/16650 (epoch 26.523), train_loss = 0.89181854, grad/param norm = 2.7426e-01, time/batch = 16.5149s	
8833/16650 (epoch 26.526), train_loss = 0.98005850, grad/param norm = 2.8824e-01, time/batch = 16.4371s	
8834/16650 (epoch 26.529), train_loss = 1.04372397, grad/param norm = 3.3250e-01, time/batch = 16.7367s	
8835/16650 (epoch 26.532), train_loss = 0.69492480, grad/param norm = 2.4218e-01, time/batch = 16.5262s	
8836/16650 (epoch 26.535), train_loss = 0.78231065, grad/param norm = 2.9138e-01, time/batch = 16.1069s	
8837/16650 (epoch 26.538), train_loss = 0.75769620, grad/param norm = 2.6468e-01, time/batch = 16.4402s	
8838/16650 (epoch 26.541), train_loss = 1.02421612, grad/param norm = 2.8675e-01, time/batch = 16.3820s	
8839/16650 (epoch 26.544), train_loss = 1.09833771, grad/param norm = 4.3238e-01, time/batch = 17.7859s	
8840/16650 (epoch 26.547), train_loss = 0.79968307, grad/param norm = 2.8191e-01, time/batch = 16.6829s	
8841/16650 (epoch 26.550), train_loss = 0.89387804, grad/param norm = 2.6026e-01, time/batch = 16.4347s	
8842/16650 (epoch 26.553), train_loss = 0.89462826, grad/param norm = 3.2732e-01, time/batch = 17.6997s	
8843/16650 (epoch 26.556), train_loss = 0.81323800, grad/param norm = 2.3938e-01, time/batch = 14.4959s	
8844/16650 (epoch 26.559), train_loss = 0.73225205, grad/param norm = 2.7276e-01, time/batch = 18.1115s	
8845/16650 (epoch 26.562), train_loss = 0.84019379, grad/param norm = 2.6586e-01, time/batch = 16.8695s	
8846/16650 (epoch 26.565), train_loss = 0.71406608, grad/param norm = 2.9857e-01, time/batch = 17.1299s	
8847/16650 (epoch 26.568), train_loss = 0.70741355, grad/param norm = 2.5667e-01, time/batch = 16.2387s	
8848/16650 (epoch 26.571), train_loss = 0.76583356, grad/param norm = 2.5558e-01, time/batch = 16.0991s	
8849/16650 (epoch 26.574), train_loss = 0.84505410, grad/param norm = 2.9710e-01, time/batch = 15.9499s	
8850/16650 (epoch 26.577), train_loss = 0.82010221, grad/param norm = 2.5473e-01, time/batch = 16.7561s	
8851/16650 (epoch 26.580), train_loss = 0.74591962, grad/param norm = 2.5197e-01, time/batch = 14.8206s	
8852/16650 (epoch 26.583), train_loss = 0.86686312, grad/param norm = 2.6489e-01, time/batch = 16.6044s	
8853/16650 (epoch 26.586), train_loss = 0.79286734, grad/param norm = 3.3607e-01, time/batch = 16.5419s	
8854/16650 (epoch 26.589), train_loss = 0.76240537, grad/param norm = 2.3495e-01, time/batch = 16.7796s	
8855/16650 (epoch 26.592), train_loss = 0.88639693, grad/param norm = 2.7085e-01, time/batch = 17.3741s	
8856/16650 (epoch 26.595), train_loss = 0.81693141, grad/param norm = 2.8831e-01, time/batch = 16.6000s	
8857/16650 (epoch 26.598), train_loss = 0.84101590, grad/param norm = 2.5358e-01, time/batch = 17.0261s	
8858/16650 (epoch 26.601), train_loss = 0.81543020, grad/param norm = 3.1036e-01, time/batch = 16.5203s	
8859/16650 (epoch 26.604), train_loss = 0.96583171, grad/param norm = 3.0270e-01, time/batch = 17.3066s	
8860/16650 (epoch 26.607), train_loss = 0.93043685, grad/param norm = 2.6716e-01, time/batch = 16.3784s	
8861/16650 (epoch 26.610), train_loss = 0.79673847, grad/param norm = 2.6992e-01, time/batch = 16.1960s	
8862/16650 (epoch 26.613), train_loss = 1.01655908, grad/param norm = 2.8297e-01, time/batch = 17.3568s	
8863/16650 (epoch 26.616), train_loss = 0.99204606, grad/param norm = 3.5146e-01, time/batch = 17.2966s	
8864/16650 (epoch 26.619), train_loss = 0.73453390, grad/param norm = 2.7011e-01, time/batch = 15.3316s	
8865/16650 (epoch 26.622), train_loss = 0.70941374, grad/param norm = 2.4946e-01, time/batch = 16.3446s	
8866/16650 (epoch 26.625), train_loss = 0.82315336, grad/param norm = 2.4300e-01, time/batch = 16.7723s	
8867/16650 (epoch 26.628), train_loss = 0.83302673, grad/param norm = 3.3449e-01, time/batch = 17.9493s	
8868/16650 (epoch 26.631), train_loss = 0.90530594, grad/param norm = 3.2845e-01, time/batch = 15.4736s	
8869/16650 (epoch 26.634), train_loss = 1.06773410, grad/param norm = 3.1520e-01, time/batch = 17.2849s	
8870/16650 (epoch 26.637), train_loss = 1.06942767, grad/param norm = 2.6956e-01, time/batch = 17.5288s	
8871/16650 (epoch 26.640), train_loss = 0.82706261, grad/param norm = 2.5453e-01, time/batch = 16.7041s	
8872/16650 (epoch 26.643), train_loss = 0.93300933, grad/param norm = 2.4362e-01, time/batch = 15.5017s	
8873/16650 (epoch 26.646), train_loss = 0.94598441, grad/param norm = 2.9720e-01, time/batch = 16.0113s	
8874/16650 (epoch 26.649), train_loss = 0.90369135, grad/param norm = 3.0032e-01, time/batch = 18.0405s	
8875/16650 (epoch 26.652), train_loss = 0.97505479, grad/param norm = 2.8864e-01, time/batch = 17.2057s	
8876/16650 (epoch 26.655), train_loss = 0.90293860, grad/param norm = 2.6882e-01, time/batch = 18.3639s	
8877/16650 (epoch 26.658), train_loss = 0.79339799, grad/param norm = 2.7906e-01, time/batch = 17.5451s	
8878/16650 (epoch 26.661), train_loss = 0.90191608, grad/param norm = 2.8189e-01, time/batch = 16.5457s	
8879/16650 (epoch 26.664), train_loss = 0.90158000, grad/param norm = 2.6680e-01, time/batch = 15.8414s	
8880/16650 (epoch 26.667), train_loss = 0.99809709, grad/param norm = 2.8334e-01, time/batch = 18.1024s	
8881/16650 (epoch 26.670), train_loss = 0.74878939, grad/param norm = 2.3671e-01, time/batch = 14.0809s	
8882/16650 (epoch 26.673), train_loss = 0.79502336, grad/param norm = 2.6551e-01, time/batch = 17.2742s	
8883/16650 (epoch 26.676), train_loss = 0.90165522, grad/param norm = 2.8757e-01, time/batch = 17.1056s	
8884/16650 (epoch 26.679), train_loss = 0.78916982, grad/param norm = 2.7160e-01, time/batch = 15.9535s	
8885/16650 (epoch 26.682), train_loss = 0.89950817, grad/param norm = 2.7468e-01, time/batch = 17.3502s	
8886/16650 (epoch 26.685), train_loss = 0.75403946, grad/param norm = 2.6145e-01, time/batch = 23.7002s	
8887/16650 (epoch 26.688), train_loss = 0.94993675, grad/param norm = 2.6190e-01, time/batch = 23.6607s	
8888/16650 (epoch 26.691), train_loss = 0.93952952, grad/param norm = 2.7399e-01, time/batch = 17.4619s	
8889/16650 (epoch 26.694), train_loss = 0.80041240, grad/param norm = 2.5169e-01, time/batch = 14.7245s	
8890/16650 (epoch 26.697), train_loss = 0.75120663, grad/param norm = 2.2070e-01, time/batch = 17.1025s	
8891/16650 (epoch 26.700), train_loss = 0.94585002, grad/param norm = 2.8421e-01, time/batch = 17.1927s	
8892/16650 (epoch 26.703), train_loss = 0.78372517, grad/param norm = 3.3385e-01, time/batch = 16.5159s	
8893/16650 (epoch 26.706), train_loss = 0.87166531, grad/param norm = 2.8804e-01, time/batch = 17.6134s	
8894/16650 (epoch 26.709), train_loss = 0.78327197, grad/param norm = 2.5516e-01, time/batch = 16.4448s	
8895/16650 (epoch 26.712), train_loss = 0.79096710, grad/param norm = 2.5673e-01, time/batch = 17.7779s	
8896/16650 (epoch 26.715), train_loss = 0.95324973, grad/param norm = 2.7751e-01, time/batch = 15.1007s	
8897/16650 (epoch 26.718), train_loss = 0.97826846, grad/param norm = 2.7261e-01, time/batch = 18.2065s	
8898/16650 (epoch 26.721), train_loss = 0.94325916, grad/param norm = 2.6837e-01, time/batch = 14.5766s	
8899/16650 (epoch 26.724), train_loss = 0.96418999, grad/param norm = 2.9274e-01, time/batch = 16.8594s	
8900/16650 (epoch 26.727), train_loss = 0.96389676, grad/param norm = 2.8772e-01, time/batch = 16.0953s	
8901/16650 (epoch 26.730), train_loss = 0.81722874, grad/param norm = 2.5521e-01, time/batch = 18.2779s	
8902/16650 (epoch 26.733), train_loss = 0.97043887, grad/param norm = 2.7720e-01, time/batch = 16.3446s	
8903/16650 (epoch 26.736), train_loss = 0.73158966, grad/param norm = 2.4094e-01, time/batch = 15.9359s	
8904/16650 (epoch 26.739), train_loss = 0.86900614, grad/param norm = 2.4490e-01, time/batch = 17.3579s	
8905/16650 (epoch 26.742), train_loss = 0.86887462, grad/param norm = 2.4697e-01, time/batch = 14.2417s	
8906/16650 (epoch 26.745), train_loss = 0.68555511, grad/param norm = 2.4053e-01, time/batch = 15.7612s	
8907/16650 (epoch 26.748), train_loss = 0.75066445, grad/param norm = 2.9596e-01, time/batch = 15.6014s	
8908/16650 (epoch 26.751), train_loss = 0.89703244, grad/param norm = 4.2729e-01, time/batch = 17.5297s	
8909/16650 (epoch 26.754), train_loss = 1.07382534, grad/param norm = 3.2796e-01, time/batch = 17.0231s	
8910/16650 (epoch 26.757), train_loss = 1.01867640, grad/param norm = 2.8303e-01, time/batch = 16.5176s	
8911/16650 (epoch 26.760), train_loss = 0.88258174, grad/param norm = 2.7369e-01, time/batch = 17.5068s	
8912/16650 (epoch 26.763), train_loss = 0.82467962, grad/param norm = 2.5435e-01, time/batch = 17.7867s	
8913/16650 (epoch 26.766), train_loss = 0.85470513, grad/param norm = 2.4542e-01, time/batch = 15.8315s	
8914/16650 (epoch 26.769), train_loss = 0.90592917, grad/param norm = 2.6522e-01, time/batch = 16.0178s	
8915/16650 (epoch 26.772), train_loss = 0.85192772, grad/param norm = 2.3438e-01, time/batch = 16.6992s	
8916/16650 (epoch 26.775), train_loss = 0.85472980, grad/param norm = 2.5924e-01, time/batch = 17.5270s	
8917/16650 (epoch 26.778), train_loss = 0.87212269, grad/param norm = 2.2505e-01, time/batch = 17.2731s	
8918/16650 (epoch 26.781), train_loss = 1.00378890, grad/param norm = 2.5047e-01, time/batch = 16.6122s	
8919/16650 (epoch 26.784), train_loss = 0.92022937, grad/param norm = 2.6624e-01, time/batch = 17.1274s	
8920/16650 (epoch 26.787), train_loss = 0.94912846, grad/param norm = 2.5868e-01, time/batch = 15.8448s	
8921/16650 (epoch 26.790), train_loss = 0.93449912, grad/param norm = 2.4349e-01, time/batch = 16.1789s	
8922/16650 (epoch 26.793), train_loss = 0.78615194, grad/param norm = 2.6177e-01, time/batch = 17.2608s	
8923/16650 (epoch 26.796), train_loss = 1.15611260, grad/param norm = 3.2560e-01, time/batch = 16.9352s	
8924/16650 (epoch 26.799), train_loss = 1.06564266, grad/param norm = 2.9338e-01, time/batch = 17.2720s	
8925/16650 (epoch 26.802), train_loss = 0.94834570, grad/param norm = 2.6422e-01, time/batch = 15.9309s	
8926/16650 (epoch 26.805), train_loss = 0.89959984, grad/param norm = 2.7564e-01, time/batch = 18.0318s	
8927/16650 (epoch 26.808), train_loss = 0.94847118, grad/param norm = 2.6051e-01, time/batch = 15.3382s	
8928/16650 (epoch 26.811), train_loss = 1.01167555, grad/param norm = 2.7607e-01, time/batch = 16.1882s	
8929/16650 (epoch 26.814), train_loss = 0.79388369, grad/param norm = 2.4459e-01, time/batch = 17.3534s	
8930/16650 (epoch 26.817), train_loss = 0.84008647, grad/param norm = 2.6521e-01, time/batch = 17.3659s	
8931/16650 (epoch 26.820), train_loss = 0.94031745, grad/param norm = 3.1414e-01, time/batch = 16.3470s	
8932/16650 (epoch 26.823), train_loss = 0.86634426, grad/param norm = 2.5183e-01, time/batch = 15.2529s	
8933/16650 (epoch 26.826), train_loss = 0.85742290, grad/param norm = 2.5496e-01, time/batch = 17.2776s	
8934/16650 (epoch 26.829), train_loss = 0.92297387, grad/param norm = 2.6411e-01, time/batch = 17.0358s	
8935/16650 (epoch 26.832), train_loss = 0.97166439, grad/param norm = 2.6567e-01, time/batch = 15.4792s	
8936/16650 (epoch 26.835), train_loss = 0.95818107, grad/param norm = 2.9265e-01, time/batch = 16.7747s	
8937/16650 (epoch 26.838), train_loss = 0.80990786, grad/param norm = 2.5922e-01, time/batch = 18.0464s	
8938/16650 (epoch 26.841), train_loss = 0.82743066, grad/param norm = 2.5223e-01, time/batch = 16.1034s	
8939/16650 (epoch 26.844), train_loss = 0.82186055, grad/param norm = 2.2511e-01, time/batch = 15.0762s	
8940/16650 (epoch 26.847), train_loss = 0.97915799, grad/param norm = 3.0654e-01, time/batch = 17.9537s	
8941/16650 (epoch 26.850), train_loss = 0.78101422, grad/param norm = 2.8582e-01, time/batch = 16.8520s	
8942/16650 (epoch 26.853), train_loss = 0.88665816, grad/param norm = 2.5665e-01, time/batch = 16.8581s	
8943/16650 (epoch 26.856), train_loss = 0.82383411, grad/param norm = 2.6461e-01, time/batch = 16.9436s	
8944/16650 (epoch 26.859), train_loss = 1.00476845, grad/param norm = 3.1104e-01, time/batch = 17.6214s	
8945/16650 (epoch 26.862), train_loss = 0.88698611, grad/param norm = 3.6622e-01, time/batch = 15.5062s	
8946/16650 (epoch 26.865), train_loss = 0.73629487, grad/param norm = 2.4236e-01, time/batch = 16.3496s	
8947/16650 (epoch 26.868), train_loss = 0.92834513, grad/param norm = 2.5214e-01, time/batch = 18.3817s	
8948/16650 (epoch 26.871), train_loss = 0.92106278, grad/param norm = 2.6177e-01, time/batch = 16.8547s	
8949/16650 (epoch 26.874), train_loss = 0.92237771, grad/param norm = 2.4811e-01, time/batch = 17.0294s	
8950/16650 (epoch 26.877), train_loss = 0.90390724, grad/param norm = 2.5672e-01, time/batch = 14.4842s	
8951/16650 (epoch 26.880), train_loss = 0.79383690, grad/param norm = 2.7262e-01, time/batch = 15.8865s	
8952/16650 (epoch 26.883), train_loss = 0.90926210, grad/param norm = 2.8509e-01, time/batch = 16.7949s	
8953/16650 (epoch 26.886), train_loss = 0.90468588, grad/param norm = 2.6784e-01, time/batch = 16.2563s	
8954/16650 (epoch 26.889), train_loss = 0.75683428, grad/param norm = 2.6535e-01, time/batch = 16.9523s	
8955/16650 (epoch 26.892), train_loss = 0.88790656, grad/param norm = 2.4306e-01, time/batch = 17.1757s	
8956/16650 (epoch 26.895), train_loss = 0.91438404, grad/param norm = 2.6671e-01, time/batch = 16.2657s	
8957/16650 (epoch 26.898), train_loss = 0.89327430, grad/param norm = 2.6770e-01, time/batch = 15.5873s	
8958/16650 (epoch 26.901), train_loss = 0.85665314, grad/param norm = 2.5492e-01, time/batch = 17.5307s	
8959/16650 (epoch 26.904), train_loss = 0.83773142, grad/param norm = 2.7782e-01, time/batch = 16.1009s	
8960/16650 (epoch 26.907), train_loss = 0.93006283, grad/param norm = 2.7320e-01, time/batch = 16.1143s	
8961/16650 (epoch 26.910), train_loss = 0.92715725, grad/param norm = 2.7308e-01, time/batch = 15.6682s	
8962/16650 (epoch 26.913), train_loss = 0.83791155, grad/param norm = 2.5057e-01, time/batch = 17.7129s	
8963/16650 (epoch 26.916), train_loss = 0.86319829, grad/param norm = 3.0584e-01, time/batch = 18.0503s	
8964/16650 (epoch 26.919), train_loss = 1.02968745, grad/param norm = 2.8038e-01, time/batch = 15.9480s	
8965/16650 (epoch 26.922), train_loss = 0.95792574, grad/param norm = 3.0532e-01, time/batch = 16.2842s	
8966/16650 (epoch 26.925), train_loss = 0.83765722, grad/param norm = 3.0907e-01, time/batch = 16.5444s	
8967/16650 (epoch 26.928), train_loss = 0.88026022, grad/param norm = 2.4796e-01, time/batch = 16.1737s	
8968/16650 (epoch 26.931), train_loss = 0.95385300, grad/param norm = 2.7311e-01, time/batch = 14.7338s	
8969/16650 (epoch 26.934), train_loss = 0.78872312, grad/param norm = 2.7223e-01, time/batch = 16.5200s	
8970/16650 (epoch 26.937), train_loss = 0.82342666, grad/param norm = 2.9509e-01, time/batch = 17.8835s	
8971/16650 (epoch 26.940), train_loss = 0.84723931, grad/param norm = 2.3833e-01, time/batch = 16.7738s	
8972/16650 (epoch 26.943), train_loss = 0.92226553, grad/param norm = 2.7880e-01, time/batch = 16.6138s	
8973/16650 (epoch 26.946), train_loss = 0.80385797, grad/param norm = 2.8201e-01, time/batch = 14.1660s	
8974/16650 (epoch 26.949), train_loss = 0.79579852, grad/param norm = 3.2117e-01, time/batch = 17.7030s	
8975/16650 (epoch 26.952), train_loss = 0.76169848, grad/param norm = 2.6119e-01, time/batch = 16.1773s	
8976/16650 (epoch 26.955), train_loss = 0.87482557, grad/param norm = 2.5010e-01, time/batch = 15.2419s	
8977/16650 (epoch 26.958), train_loss = 0.95504991, grad/param norm = 3.1530e-01, time/batch = 17.4469s	
8978/16650 (epoch 26.961), train_loss = 0.89171022, grad/param norm = 2.6138e-01, time/batch = 17.4444s	
8979/16650 (epoch 26.964), train_loss = 0.80195318, grad/param norm = 2.9048e-01, time/batch = 16.0851s	
8980/16650 (epoch 26.967), train_loss = 1.02154687, grad/param norm = 3.0854e-01, time/batch = 17.0198s	
8981/16650 (epoch 26.970), train_loss = 0.82372831, grad/param norm = 2.3969e-01, time/batch = 16.8813s	
8982/16650 (epoch 26.973), train_loss = 0.84362895, grad/param norm = 2.7778e-01, time/batch = 17.0286s	
8983/16650 (epoch 26.976), train_loss = 0.81855761, grad/param norm = 2.4383e-01, time/batch = 17.1916s	
8984/16650 (epoch 26.979), train_loss = 0.92968582, grad/param norm = 2.9573e-01, time/batch = 16.3570s	
8985/16650 (epoch 26.982), train_loss = 0.93565626, grad/param norm = 2.6442e-01, time/batch = 17.5418s	
8986/16650 (epoch 26.985), train_loss = 0.85928193, grad/param norm = 2.6974e-01, time/batch = 14.4040s	
8987/16650 (epoch 26.988), train_loss = 0.98223249, grad/param norm = 2.9921e-01, time/batch = 16.9608s	
8988/16650 (epoch 26.991), train_loss = 0.79372257, grad/param norm = 2.7399e-01, time/batch = 17.6217s	
8989/16650 (epoch 26.994), train_loss = 0.82448156, grad/param norm = 2.3459e-01, time/batch = 16.2801s	
8990/16650 (epoch 26.997), train_loss = 0.86936871, grad/param norm = 2.8277e-01, time/batch = 17.5192s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
8991/16650 (epoch 27.000), train_loss = 0.94557588, grad/param norm = 2.8873e-01, time/batch = 16.0409s	
8992/16650 (epoch 27.003), train_loss = 0.98702932, grad/param norm = 3.2579e-01, time/batch = 18.2893s	
8993/16650 (epoch 27.006), train_loss = 0.96912052, grad/param norm = 3.0565e-01, time/batch = 15.3254s	
8994/16650 (epoch 27.009), train_loss = 1.02737793, grad/param norm = 2.5245e-01, time/batch = 16.6941s	
8995/16650 (epoch 27.012), train_loss = 1.01863192, grad/param norm = 3.0070e-01, time/batch = 15.3399s	
8996/16650 (epoch 27.015), train_loss = 0.88090963, grad/param norm = 2.6349e-01, time/batch = 17.0388s	
8997/16650 (epoch 27.018), train_loss = 0.76446841, grad/param norm = 2.7096e-01, time/batch = 15.4329s	
8998/16650 (epoch 27.021), train_loss = 1.01205423, grad/param norm = 3.0718e-01, time/batch = 14.6000s	
8999/16650 (epoch 27.024), train_loss = 0.88128112, grad/param norm = 2.7962e-01, time/batch = 16.5080s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch27.03_2.0146.t7	
9000/16650 (epoch 27.027), train_loss = 0.95620961, grad/param norm = 2.9211e-01, time/batch = 16.2928s	
9001/16650 (epoch 27.030), train_loss = 1.49962052, grad/param norm = 3.3838e-01, time/batch = 16.8910s	
9002/16650 (epoch 27.033), train_loss = 0.90466638, grad/param norm = 2.6602e-01, time/batch = 17.2695s	
9003/16650 (epoch 27.036), train_loss = 0.66432993, grad/param norm = 2.8301e-01, time/batch = 16.4175s	
9004/16650 (epoch 27.039), train_loss = 1.00061885, grad/param norm = 2.7041e-01, time/batch = 17.2785s	
9005/16650 (epoch 27.042), train_loss = 0.96989302, grad/param norm = 2.9162e-01, time/batch = 16.4578s	
9006/16650 (epoch 27.045), train_loss = 0.85411589, grad/param norm = 2.5781e-01, time/batch = 17.7078s	
9007/16650 (epoch 27.048), train_loss = 0.97907701, grad/param norm = 2.9541e-01, time/batch = 16.0836s	
9008/16650 (epoch 27.051), train_loss = 0.85774491, grad/param norm = 2.6024e-01, time/batch = 17.5404s	
9009/16650 (epoch 27.054), train_loss = 0.89837938, grad/param norm = 2.8742e-01, time/batch = 16.3705s	
9010/16650 (epoch 27.057), train_loss = 0.91415499, grad/param norm = 2.8951e-01, time/batch = 15.9260s	
9011/16650 (epoch 27.060), train_loss = 0.76231229, grad/param norm = 2.5039e-01, time/batch = 16.0083s	
9012/16650 (epoch 27.063), train_loss = 0.86355149, grad/param norm = 2.5131e-01, time/batch = 16.8730s	
9013/16650 (epoch 27.066), train_loss = 1.02315497, grad/param norm = 2.7113e-01, time/batch = 17.7038s	
9014/16650 (epoch 27.069), train_loss = 0.95247047, grad/param norm = 2.8320e-01, time/batch = 15.9547s	
9015/16650 (epoch 27.072), train_loss = 0.88026971, grad/param norm = 2.6793e-01, time/batch = 16.8740s	
9016/16650 (epoch 27.075), train_loss = 0.96633301, grad/param norm = 2.8209e-01, time/batch = 14.6359s	
9017/16650 (epoch 27.078), train_loss = 1.00911270, grad/param norm = 2.7886e-01, time/batch = 16.9355s	
9018/16650 (epoch 27.081), train_loss = 0.94140305, grad/param norm = 3.3872e-01, time/batch = 16.1864s	
9019/16650 (epoch 27.084), train_loss = 0.95145281, grad/param norm = 2.6629e-01, time/batch = 18.0281s	
9020/16650 (epoch 27.087), train_loss = 0.90844962, grad/param norm = 2.6178e-01, time/batch = 16.6298s	
9021/16650 (epoch 27.090), train_loss = 0.88115035, grad/param norm = 2.8244e-01, time/batch = 16.6028s	
9022/16650 (epoch 27.093), train_loss = 1.06086823, grad/param norm = 3.0215e-01, time/batch = 14.8409s	
9023/16650 (epoch 27.096), train_loss = 0.85221115, grad/param norm = 2.5863e-01, time/batch = 17.0152s	
9024/16650 (epoch 27.099), train_loss = 0.91767034, grad/param norm = 2.5912e-01, time/batch = 16.9464s	
9025/16650 (epoch 27.102), train_loss = 0.89774792, grad/param norm = 2.6610e-01, time/batch = 14.4988s	
9026/16650 (epoch 27.105), train_loss = 0.93777239, grad/param norm = 2.8007e-01, time/batch = 16.7104s	
9027/16650 (epoch 27.108), train_loss = 0.92491412, grad/param norm = 2.7065e-01, time/batch = 17.2773s	
9028/16650 (epoch 27.111), train_loss = 0.98734547, grad/param norm = 2.5499e-01, time/batch = 16.9996s	
9029/16650 (epoch 27.114), train_loss = 0.97576543, grad/param norm = 2.8116e-01, time/batch = 16.4254s	
9030/16650 (epoch 27.117), train_loss = 1.06635474, grad/param norm = 2.8520e-01, time/batch = 16.5960s	
9031/16650 (epoch 27.120), train_loss = 0.85612184, grad/param norm = 2.4067e-01, time/batch = 17.6135s	
9032/16650 (epoch 27.123), train_loss = 0.89728820, grad/param norm = 2.7019e-01, time/batch = 16.1143s	
9033/16650 (epoch 27.126), train_loss = 0.91959479, grad/param norm = 2.4315e-01, time/batch = 17.0222s	
9034/16650 (epoch 27.129), train_loss = 0.91862092, grad/param norm = 2.6312e-01, time/batch = 17.1246s	
9035/16650 (epoch 27.132), train_loss = 0.89519155, grad/param norm = 2.7427e-01, time/batch = 17.9640s	
9036/16650 (epoch 27.135), train_loss = 0.99077873, grad/param norm = 2.7351e-01, time/batch = 16.3465s	
9037/16650 (epoch 27.138), train_loss = 0.98951965, grad/param norm = 2.6532e-01, time/batch = 17.6287s	
9038/16650 (epoch 27.141), train_loss = 0.94970983, grad/param norm = 2.6546e-01, time/batch = 16.6292s	
9039/16650 (epoch 27.144), train_loss = 0.92993889, grad/param norm = 2.7596e-01, time/batch = 16.1952s	
9040/16650 (epoch 27.147), train_loss = 1.03048074, grad/param norm = 2.5453e-01, time/batch = 16.6101s	
9041/16650 (epoch 27.150), train_loss = 1.13312032, grad/param norm = 3.5378e-01, time/batch = 16.7895s	
9042/16650 (epoch 27.153), train_loss = 0.96035974, grad/param norm = 3.2460e-01, time/batch = 18.1237s	
9043/16650 (epoch 27.156), train_loss = 0.83962587, grad/param norm = 2.3506e-01, time/batch = 15.5696s	
9044/16650 (epoch 27.159), train_loss = 0.97012407, grad/param norm = 2.8894e-01, time/batch = 16.9715s	
9045/16650 (epoch 27.162), train_loss = 1.03720983, grad/param norm = 2.7352e-01, time/batch = 17.3787s	
9046/16650 (epoch 27.165), train_loss = 1.02942901, grad/param norm = 2.7611e-01, time/batch = 16.2458s	
9047/16650 (epoch 27.168), train_loss = 0.76872783, grad/param norm = 2.2111e-01, time/batch = 15.8339s	
9048/16650 (epoch 27.171), train_loss = 0.99700537, grad/param norm = 2.6686e-01, time/batch = 17.6129s	
9049/16650 (epoch 27.174), train_loss = 0.75514147, grad/param norm = 2.4052e-01, time/batch = 14.2446s	
9050/16650 (epoch 27.177), train_loss = 0.92538055, grad/param norm = 2.7491e-01, time/batch = 16.7696s	
9051/16650 (epoch 27.180), train_loss = 1.01928220, grad/param norm = 2.7678e-01, time/batch = 16.0181s	
9052/16650 (epoch 27.183), train_loss = 1.13029013, grad/param norm = 3.1654e-01, time/batch = 17.7061s	
9053/16650 (epoch 27.186), train_loss = 0.97139853, grad/param norm = 2.8181e-01, time/batch = 16.4339s	
9054/16650 (epoch 27.189), train_loss = 0.86181761, grad/param norm = 2.5312e-01, time/batch = 17.0220s	
9055/16650 (epoch 27.192), train_loss = 0.87808936, grad/param norm = 2.7539e-01, time/batch = 16.2669s	
9056/16650 (epoch 27.195), train_loss = 0.86330210, grad/param norm = 3.0177e-01, time/batch = 17.2775s	
9057/16650 (epoch 27.198), train_loss = 0.76998310, grad/param norm = 2.1744e-01, time/batch = 15.1681s	
9058/16650 (epoch 27.201), train_loss = 0.82932053, grad/param norm = 2.6498e-01, time/batch = 16.7745s	
9059/16650 (epoch 27.204), train_loss = 0.92007005, grad/param norm = 2.7547e-01, time/batch = 16.8673s	
9060/16650 (epoch 27.207), train_loss = 0.94497901, grad/param norm = 3.0103e-01, time/batch = 17.8738s	
9061/16650 (epoch 27.210), train_loss = 0.89098795, grad/param norm = 2.6009e-01, time/batch = 15.1652s	
9062/16650 (epoch 27.213), train_loss = 0.98577530, grad/param norm = 2.7496e-01, time/batch = 17.6862s	
9063/16650 (epoch 27.216), train_loss = 0.86538236, grad/param norm = 2.7469e-01, time/batch = 16.8533s	
9064/16650 (epoch 27.219), train_loss = 0.89574530, grad/param norm = 2.8851e-01, time/batch = 16.4404s	
9065/16650 (epoch 27.222), train_loss = 0.95027481, grad/param norm = 2.5125e-01, time/batch = 14.5683s	
9066/16650 (epoch 27.225), train_loss = 0.93479811, grad/param norm = 2.9189e-01, time/batch = 17.0417s	
9067/16650 (epoch 27.228), train_loss = 0.82682921, grad/param norm = 2.5217e-01, time/batch = 16.1837s	
9068/16650 (epoch 27.231), train_loss = 0.87422354, grad/param norm = 2.7398e-01, time/batch = 15.9369s	
9069/16650 (epoch 27.234), train_loss = 1.08062804, grad/param norm = 2.8082e-01, time/batch = 16.3568s	
9070/16650 (epoch 27.237), train_loss = 0.95398688, grad/param norm = 3.2203e-01, time/batch = 17.1260s	
9071/16650 (epoch 27.240), train_loss = 0.94514198, grad/param norm = 2.6169e-01, time/batch = 17.6070s	
9072/16650 (epoch 27.243), train_loss = 0.90542322, grad/param norm = 2.6630e-01, time/batch = 17.5150s	
9073/16650 (epoch 27.246), train_loss = 1.02628847, grad/param norm = 3.0701e-01, time/batch = 16.2888s	
9074/16650 (epoch 27.249), train_loss = 0.78359874, grad/param norm = 2.3356e-01, time/batch = 16.5433s	
9075/16650 (epoch 27.252), train_loss = 0.86448645, grad/param norm = 2.4875e-01, time/batch = 16.4306s	
9076/16650 (epoch 27.255), train_loss = 0.94876571, grad/param norm = 2.4881e-01, time/batch = 17.3567s	
9077/16650 (epoch 27.258), train_loss = 0.99666419, grad/param norm = 2.5840e-01, time/batch = 14.4135s	
9078/16650 (epoch 27.261), train_loss = 0.94652353, grad/param norm = 2.7671e-01, time/batch = 17.2843s	
9079/16650 (epoch 27.264), train_loss = 0.87025004, grad/param norm = 2.5209e-01, time/batch = 15.0910s	
9080/16650 (epoch 27.267), train_loss = 0.88213099, grad/param norm = 2.5658e-01, time/batch = 14.9832s	
9081/16650 (epoch 27.270), train_loss = 0.94277861, grad/param norm = 2.5706e-01, time/batch = 17.8896s	
9082/16650 (epoch 27.273), train_loss = 1.02794241, grad/param norm = 2.8821e-01, time/batch = 17.0363s	
9083/16650 (epoch 27.276), train_loss = 0.93209658, grad/param norm = 2.4068e-01, time/batch = 16.7685s	
9084/16650 (epoch 27.279), train_loss = 0.90705464, grad/param norm = 2.6882e-01, time/batch = 17.3591s	
9085/16650 (epoch 27.282), train_loss = 0.80136053, grad/param norm = 2.3715e-01, time/batch = 15.0110s	
9086/16650 (epoch 27.285), train_loss = 0.82772092, grad/param norm = 2.3763e-01, time/batch = 16.4316s	
9087/16650 (epoch 27.288), train_loss = 0.85483289, grad/param norm = 2.7735e-01, time/batch = 16.2125s	
9088/16650 (epoch 27.291), train_loss = 0.68608022, grad/param norm = 2.1495e-01, time/batch = 17.4606s	
9089/16650 (epoch 27.294), train_loss = 0.78772228, grad/param norm = 2.1175e-01, time/batch = 17.2188s	
9090/16650 (epoch 27.297), train_loss = 0.88818057, grad/param norm = 2.3714e-01, time/batch = 16.1666s	
9091/16650 (epoch 27.300), train_loss = 0.71280627, grad/param norm = 2.2842e-01, time/batch = 15.4317s	
9092/16650 (epoch 27.303), train_loss = 0.78165447, grad/param norm = 2.2344e-01, time/batch = 16.9298s	
9093/16650 (epoch 27.306), train_loss = 0.96363631, grad/param norm = 2.3684e-01, time/batch = 16.1936s	
9094/16650 (epoch 27.309), train_loss = 0.97744539, grad/param norm = 2.7770e-01, time/batch = 16.9438s	
9095/16650 (epoch 27.312), train_loss = 0.78369910, grad/param norm = 2.7372e-01, time/batch = 16.7794s	
9096/16650 (epoch 27.315), train_loss = 0.65727215, grad/param norm = 2.1315e-01, time/batch = 17.7076s	
9097/16650 (epoch 27.318), train_loss = 0.74898256, grad/param norm = 2.3134e-01, time/batch = 28.0769s	
9098/16650 (epoch 27.321), train_loss = 1.01751875, grad/param norm = 2.9489e-01, time/batch = 19.1631s	
9099/16650 (epoch 27.324), train_loss = 0.82465684, grad/param norm = 2.6173e-01, time/batch = 17.4530s	
9100/16650 (epoch 27.327), train_loss = 0.94611456, grad/param norm = 2.9150e-01, time/batch = 14.3285s	
9101/16650 (epoch 27.330), train_loss = 0.94609503, grad/param norm = 3.4776e-01, time/batch = 13.4053s	
9102/16650 (epoch 27.333), train_loss = 0.96479104, grad/param norm = 2.9183e-01, time/batch = 13.2472s	
9103/16650 (epoch 27.336), train_loss = 0.81833762, grad/param norm = 2.8690e-01, time/batch = 14.1032s	
9104/16650 (epoch 27.339), train_loss = 0.85684054, grad/param norm = 2.8324e-01, time/batch = 15.3352s	
9105/16650 (epoch 27.342), train_loss = 0.82109733, grad/param norm = 3.0720e-01, time/batch = 15.4164s	
9106/16650 (epoch 27.345), train_loss = 0.78633460, grad/param norm = 2.4081e-01, time/batch = 17.4278s	
9107/16650 (epoch 27.348), train_loss = 0.88857466, grad/param norm = 3.1745e-01, time/batch = 16.7638s	
9108/16650 (epoch 27.351), train_loss = 0.94023427, grad/param norm = 2.9671e-01, time/batch = 16.0075s	
9109/16650 (epoch 27.354), train_loss = 0.96310612, grad/param norm = 2.7742e-01, time/batch = 17.3000s	
9110/16650 (epoch 27.357), train_loss = 0.92589727, grad/param norm = 2.7261e-01, time/batch = 17.2999s	
9111/16650 (epoch 27.360), train_loss = 0.91281682, grad/param norm = 2.8961e-01, time/batch = 15.2437s	
9112/16650 (epoch 27.363), train_loss = 0.99222438, grad/param norm = 2.8084e-01, time/batch = 17.6010s	
9113/16650 (epoch 27.366), train_loss = 1.04712703, grad/param norm = 2.8886e-01, time/batch = 16.7757s	
9114/16650 (epoch 27.369), train_loss = 0.90690996, grad/param norm = 2.8618e-01, time/batch = 16.9481s	
9115/16650 (epoch 27.372), train_loss = 0.91068167, grad/param norm = 2.5430e-01, time/batch = 16.1572s	
9116/16650 (epoch 27.375), train_loss = 0.92783628, grad/param norm = 2.5869e-01, time/batch = 15.5810s	
9117/16650 (epoch 27.378), train_loss = 0.83514393, grad/param norm = 2.4314e-01, time/batch = 18.0369s	
9118/16650 (epoch 27.381), train_loss = 0.91928159, grad/param norm = 2.4444e-01, time/batch = 16.0152s	
9119/16650 (epoch 27.384), train_loss = 1.04725999, grad/param norm = 2.7374e-01, time/batch = 16.5355s	
9120/16650 (epoch 27.387), train_loss = 0.71345245, grad/param norm = 2.2094e-01, time/batch = 16.6175s	
9121/16650 (epoch 27.390), train_loss = 0.97483937, grad/param norm = 2.5823e-01, time/batch = 17.8881s	
9122/16650 (epoch 27.393), train_loss = 0.84907248, grad/param norm = 2.6801e-01, time/batch = 16.3349s	
9123/16650 (epoch 27.396), train_loss = 1.01096472, grad/param norm = 3.0484e-01, time/batch = 17.3033s	
9124/16650 (epoch 27.399), train_loss = 0.94246149, grad/param norm = 2.6335e-01, time/batch = 17.1931s	
9125/16650 (epoch 27.402), train_loss = 0.83989480, grad/param norm = 2.9834e-01, time/batch = 16.3585s	
9126/16650 (epoch 27.405), train_loss = 0.72510358, grad/param norm = 2.5682e-01, time/batch = 16.7041s	
9127/16650 (epoch 27.408), train_loss = 0.93550592, grad/param norm = 3.5290e-01, time/batch = 14.8038s	
9128/16650 (epoch 27.411), train_loss = 0.80369741, grad/param norm = 3.1519e-01, time/batch = 17.1918s	
9129/16650 (epoch 27.414), train_loss = 0.82451861, grad/param norm = 3.2143e-01, time/batch = 15.8590s	
9130/16650 (epoch 27.417), train_loss = 0.79353100, grad/param norm = 2.8906e-01, time/batch = 17.6174s	
9131/16650 (epoch 27.420), train_loss = 0.78847986, grad/param norm = 2.7099e-01, time/batch = 16.1119s	
9132/16650 (epoch 27.423), train_loss = 0.68417116, grad/param norm = 2.4094e-01, time/batch = 16.1107s	
9133/16650 (epoch 27.426), train_loss = 0.77870635, grad/param norm = 2.6330e-01, time/batch = 17.4282s	
9134/16650 (epoch 27.429), train_loss = 0.99417022, grad/param norm = 2.7980e-01, time/batch = 16.1083s	
9135/16650 (epoch 27.432), train_loss = 0.97846016, grad/param norm = 3.1290e-01, time/batch = 18.1960s	
9136/16650 (epoch 27.435), train_loss = 1.08476466, grad/param norm = 2.9836e-01, time/batch = 15.3321s	
9137/16650 (epoch 27.438), train_loss = 1.09037363, grad/param norm = 3.6129e-01, time/batch = 17.4495s	
9138/16650 (epoch 27.441), train_loss = 0.91082937, grad/param norm = 4.5272e-01, time/batch = 14.0963s	
9139/16650 (epoch 27.444), train_loss = 0.86743295, grad/param norm = 3.4654e-01, time/batch = 18.3685s	
9140/16650 (epoch 27.447), train_loss = 0.88500894, grad/param norm = 3.4066e-01, time/batch = 16.0023s	
9141/16650 (epoch 27.450), train_loss = 0.84297516, grad/param norm = 2.6191e-01, time/batch = 17.3653s	
9142/16650 (epoch 27.453), train_loss = 0.83009110, grad/param norm = 2.8435e-01, time/batch = 15.5047s	
9143/16650 (epoch 27.456), train_loss = 0.78435714, grad/param norm = 2.4487e-01, time/batch = 16.3550s	
9144/16650 (epoch 27.459), train_loss = 0.83753689, grad/param norm = 2.7451e-01, time/batch = 15.6992s	
9145/16650 (epoch 27.462), train_loss = 1.03417143, grad/param norm = 3.3107e-01, time/batch = 16.7803s	
9146/16650 (epoch 27.465), train_loss = 0.85844521, grad/param norm = 3.0391e-01, time/batch = 17.5306s	
9147/16650 (epoch 27.468), train_loss = 0.71203160, grad/param norm = 2.9324e-01, time/batch = 14.8299s	
9148/16650 (epoch 27.471), train_loss = 0.58857248, grad/param norm = 2.2561e-01, time/batch = 16.0930s	
9149/16650 (epoch 27.474), train_loss = 0.75587232, grad/param norm = 2.6082e-01, time/batch = 16.5378s	
9150/16650 (epoch 27.477), train_loss = 0.95721967, grad/param norm = 2.8679e-01, time/batch = 18.2073s	
9151/16650 (epoch 27.480), train_loss = 0.96677696, grad/param norm = 3.6538e-01, time/batch = 16.6599s	
9152/16650 (epoch 27.483), train_loss = 0.99877529, grad/param norm = 3.3442e-01, time/batch = 16.9430s	
9153/16650 (epoch 27.486), train_loss = 0.80954451, grad/param norm = 2.3273e-01, time/batch = 16.1943s	
9154/16650 (epoch 27.489), train_loss = 0.83014143, grad/param norm = 2.7197e-01, time/batch = 16.5248s	
9155/16650 (epoch 27.492), train_loss = 0.88860715, grad/param norm = 2.5905e-01, time/batch = 17.1006s	
9156/16650 (epoch 27.495), train_loss = 0.76600314, grad/param norm = 2.4403e-01, time/batch = 16.1681s	
9157/16650 (epoch 27.498), train_loss = 0.84845574, grad/param norm = 3.5376e-01, time/batch = 16.5539s	
9158/16650 (epoch 27.502), train_loss = 1.03517863, grad/param norm = 2.9757e-01, time/batch = 16.0923s	
9159/16650 (epoch 27.505), train_loss = 0.92104827, grad/param norm = 2.5496e-01, time/batch = 17.1871s	
9160/16650 (epoch 27.508), train_loss = 0.92531225, grad/param norm = 3.0389e-01, time/batch = 17.4477s	
9161/16650 (epoch 27.511), train_loss = 0.99251554, grad/param norm = 2.7449e-01, time/batch = 15.0816s	
9162/16650 (epoch 27.514), train_loss = 0.75764666, grad/param norm = 2.5860e-01, time/batch = 16.7868s	
9163/16650 (epoch 27.517), train_loss = 0.86417183, grad/param norm = 2.7645e-01, time/batch = 17.1947s	
9164/16650 (epoch 27.520), train_loss = 0.77331811, grad/param norm = 2.5073e-01, time/batch = 14.3253s	
9165/16650 (epoch 27.523), train_loss = 0.87007839, grad/param norm = 2.5887e-01, time/batch = 16.2685s	
9166/16650 (epoch 27.526), train_loss = 0.97341963, grad/param norm = 2.9453e-01, time/batch = 13.5867s	
9167/16650 (epoch 27.529), train_loss = 1.02128373, grad/param norm = 3.0420e-01, time/batch = 13.2388s	
9168/16650 (epoch 27.532), train_loss = 0.67839162, grad/param norm = 2.5144e-01, time/batch = 13.5190s	
9169/16650 (epoch 27.535), train_loss = 0.75746357, grad/param norm = 2.7780e-01, time/batch = 15.3935s	
9170/16650 (epoch 27.538), train_loss = 0.73669445, grad/param norm = 2.6518e-01, time/batch = 15.1833s	
9171/16650 (epoch 27.541), train_loss = 1.00892788, grad/param norm = 3.0184e-01, time/batch = 18.1142s	
9172/16650 (epoch 27.544), train_loss = 1.08179947, grad/param norm = 3.7805e-01, time/batch = 16.8500s	
9173/16650 (epoch 27.547), train_loss = 0.77761364, grad/param norm = 2.6909e-01, time/batch = 15.6700s	
9174/16650 (epoch 27.550), train_loss = 0.87026304, grad/param norm = 2.3993e-01, time/batch = 16.6906s	
9175/16650 (epoch 27.553), train_loss = 0.86144116, grad/param norm = 2.7721e-01, time/batch = 17.2079s	
9176/16650 (epoch 27.556), train_loss = 0.81093779, grad/param norm = 2.7661e-01, time/batch = 16.4446s	
9177/16650 (epoch 27.559), train_loss = 0.70286383, grad/param norm = 2.5931e-01, time/batch = 16.3658s	
9178/16650 (epoch 27.562), train_loss = 0.82328489, grad/param norm = 2.8542e-01, time/batch = 17.1881s	
9179/16650 (epoch 27.565), train_loss = 0.68661210, grad/param norm = 2.4538e-01, time/batch = 15.9674s	
9180/16650 (epoch 27.568), train_loss = 0.70237905, grad/param norm = 2.5154e-01, time/batch = 16.6911s	
9181/16650 (epoch 27.571), train_loss = 0.76040291, grad/param norm = 3.4663e-01, time/batch = 15.3374s	
9182/16650 (epoch 27.574), train_loss = 0.82731930, grad/param norm = 3.0306e-01, time/batch = 18.0348s	
9183/16650 (epoch 27.577), train_loss = 0.79920949, grad/param norm = 2.6099e-01, time/batch = 17.2090s	
9184/16650 (epoch 27.580), train_loss = 0.72794586, grad/param norm = 2.3655e-01, time/batch = 14.2226s	
9185/16650 (epoch 27.583), train_loss = 0.84164123, grad/param norm = 2.5966e-01, time/batch = 17.6969s	
9186/16650 (epoch 27.586), train_loss = 0.79286386, grad/param norm = 3.3505e-01, time/batch = 17.1095s	
9187/16650 (epoch 27.589), train_loss = 0.74544458, grad/param norm = 2.2744e-01, time/batch = 16.5187s	
9188/16650 (epoch 27.592), train_loss = 0.87116691, grad/param norm = 2.7432e-01, time/batch = 16.1726s	
9189/16650 (epoch 27.595), train_loss = 0.81272142, grad/param norm = 2.8768e-01, time/batch = 17.3645s	
9190/16650 (epoch 27.598), train_loss = 0.83762791, grad/param norm = 3.1264e-01, time/batch = 16.2015s	
9191/16650 (epoch 27.601), train_loss = 0.79873823, grad/param norm = 3.3952e-01, time/batch = 16.5141s	
9192/16650 (epoch 27.604), train_loss = 0.92695990, grad/param norm = 3.0551e-01, time/batch = 17.2863s	
9193/16650 (epoch 27.607), train_loss = 0.91063564, grad/param norm = 2.5347e-01, time/batch = 17.0469s	
9194/16650 (epoch 27.610), train_loss = 0.78357056, grad/param norm = 2.5907e-01, time/batch = 17.1162s	
9195/16650 (epoch 27.613), train_loss = 0.98400210, grad/param norm = 3.1509e-01, time/batch = 16.5972s	
9196/16650 (epoch 27.616), train_loss = 0.97413859, grad/param norm = 3.5923e-01, time/batch = 16.2586s	
9197/16650 (epoch 27.619), train_loss = 0.72002835, grad/param norm = 2.5978e-01, time/batch = 17.0444s	
9198/16650 (epoch 27.622), train_loss = 0.68766854, grad/param norm = 2.5154e-01, time/batch = 16.1816s	
9199/16650 (epoch 27.625), train_loss = 0.81415140, grad/param norm = 2.4015e-01, time/batch = 17.7821s	
9200/16650 (epoch 27.628), train_loss = 0.80094523, grad/param norm = 2.8452e-01, time/batch = 17.0338s	
9201/16650 (epoch 27.631), train_loss = 0.89012580, grad/param norm = 3.2362e-01, time/batch = 16.9097s	
9202/16650 (epoch 27.634), train_loss = 1.05359065, grad/param norm = 3.3987e-01, time/batch = 16.4428s	
9203/16650 (epoch 27.637), train_loss = 1.04679835, grad/param norm = 2.6349e-01, time/batch = 17.2858s	
9204/16650 (epoch 27.640), train_loss = 0.81222387, grad/param norm = 2.6995e-01, time/batch = 16.4514s	
9205/16650 (epoch 27.643), train_loss = 0.91901466, grad/param norm = 2.5756e-01, time/batch = 15.0959s	
9206/16650 (epoch 27.646), train_loss = 0.93080568, grad/param norm = 3.0392e-01, time/batch = 16.1940s	
9207/16650 (epoch 27.649), train_loss = 0.91084867, grad/param norm = 3.8034e-01, time/batch = 17.9528s	
9208/16650 (epoch 27.652), train_loss = 0.94974506, grad/param norm = 3.2403e-01, time/batch = 15.8683s	
9209/16650 (epoch 27.655), train_loss = 0.90575367, grad/param norm = 2.9679e-01, time/batch = 14.3329s	
9210/16650 (epoch 27.658), train_loss = 0.78283434, grad/param norm = 3.2472e-01, time/batch = 17.5203s	
9211/16650 (epoch 27.661), train_loss = 0.90608232, grad/param norm = 3.1321e-01, time/batch = 16.6067s	
9212/16650 (epoch 27.664), train_loss = 0.89825879, grad/param norm = 2.9434e-01, time/batch = 16.3593s	
9213/16650 (epoch 27.667), train_loss = 0.98506806, grad/param norm = 2.6501e-01, time/batch = 14.9074s	
9214/16650 (epoch 27.670), train_loss = 0.73985400, grad/param norm = 2.5382e-01, time/batch = 17.2817s	
9215/16650 (epoch 27.673), train_loss = 0.78893180, grad/param norm = 2.4662e-01, time/batch = 18.1257s	
9216/16650 (epoch 27.676), train_loss = 0.89240533, grad/param norm = 2.9326e-01, time/batch = 15.6189s	
9217/16650 (epoch 27.679), train_loss = 0.77652801, grad/param norm = 2.7092e-01, time/batch = 17.1120s	
9218/16650 (epoch 27.682), train_loss = 0.88144468, grad/param norm = 2.6567e-01, time/batch = 16.8763s	
9219/16650 (epoch 27.685), train_loss = 0.75015864, grad/param norm = 2.6120e-01, time/batch = 17.0365s	
9220/16650 (epoch 27.688), train_loss = 0.92447451, grad/param norm = 2.5963e-01, time/batch = 16.2502s	
9221/16650 (epoch 27.691), train_loss = 0.91806900, grad/param norm = 2.7658e-01, time/batch = 17.3723s	
9222/16650 (epoch 27.694), train_loss = 0.78260380, grad/param norm = 2.3843e-01, time/batch = 17.7917s	
9223/16650 (epoch 27.697), train_loss = 0.74072477, grad/param norm = 2.3338e-01, time/batch = 16.5008s	
9224/16650 (epoch 27.700), train_loss = 0.93015616, grad/param norm = 3.1591e-01, time/batch = 16.5327s	
9225/16650 (epoch 27.703), train_loss = 0.75553630, grad/param norm = 2.5392e-01, time/batch = 17.2871s	
9226/16650 (epoch 27.706), train_loss = 0.83926106, grad/param norm = 2.7323e-01, time/batch = 16.6156s	
9227/16650 (epoch 27.709), train_loss = 0.75463664, grad/param norm = 2.3598e-01, time/batch = 15.9138s	
9228/16650 (epoch 27.712), train_loss = 0.77704090, grad/param norm = 2.5908e-01, time/batch = 14.8390s	
9229/16650 (epoch 27.715), train_loss = 0.92522121, grad/param norm = 2.8247e-01, time/batch = 17.1210s	
9230/16650 (epoch 27.718), train_loss = 0.95324193, grad/param norm = 2.9452e-01, time/batch = 16.5290s	
9231/16650 (epoch 27.721), train_loss = 0.92722973, grad/param norm = 2.7577e-01, time/batch = 17.5196s	
9232/16650 (epoch 27.724), train_loss = 0.94811226, grad/param norm = 3.2935e-01, time/batch = 15.3376s	
9233/16650 (epoch 27.727), train_loss = 0.94375085, grad/param norm = 3.0292e-01, time/batch = 17.8681s	
9234/16650 (epoch 27.730), train_loss = 0.79069542, grad/param norm = 2.6224e-01, time/batch = 15.8634s	
9235/16650 (epoch 27.733), train_loss = 0.96243233, grad/param norm = 2.8770e-01, time/batch = 17.1241s	
9236/16650 (epoch 27.736), train_loss = 0.72482285, grad/param norm = 2.3818e-01, time/batch = 14.4839s	
9237/16650 (epoch 27.739), train_loss = 0.86667660, grad/param norm = 2.7897e-01, time/batch = 15.9429s	
9238/16650 (epoch 27.742), train_loss = 0.84014687, grad/param norm = 2.3783e-01, time/batch = 15.0559s	
9239/16650 (epoch 27.745), train_loss = 0.67275838, grad/param norm = 2.3054e-01, time/batch = 17.6953s	
9240/16650 (epoch 27.748), train_loss = 0.74069823, grad/param norm = 2.5209e-01, time/batch = 16.6851s	
9241/16650 (epoch 27.751), train_loss = 0.89057189, grad/param norm = 4.0793e-01, time/batch = 16.0029s	
9242/16650 (epoch 27.754), train_loss = 1.08019813, grad/param norm = 3.9055e-01, time/batch = 17.0171s	
9243/16650 (epoch 27.757), train_loss = 1.02647387, grad/param norm = 3.1198e-01, time/batch = 17.3496s	
9244/16650 (epoch 27.760), train_loss = 0.87161400, grad/param norm = 2.7038e-01, time/batch = 17.5270s	
9245/16650 (epoch 27.763), train_loss = 0.81252738, grad/param norm = 2.5063e-01, time/batch = 14.7982s	
9246/16650 (epoch 27.766), train_loss = 0.83217942, grad/param norm = 2.3549e-01, time/batch = 16.2026s	
9247/16650 (epoch 27.769), train_loss = 0.88964927, grad/param norm = 2.7692e-01, time/batch = 15.3491s	
9248/16650 (epoch 27.772), train_loss = 0.85659067, grad/param norm = 2.4985e-01, time/batch = 17.2795s	
9249/16650 (epoch 27.775), train_loss = 0.83045247, grad/param norm = 2.5066e-01, time/batch = 16.3326s	
9250/16650 (epoch 27.778), train_loss = 0.85844617, grad/param norm = 2.3097e-01, time/batch = 17.1121s	
9251/16650 (epoch 27.781), train_loss = 0.98388001, grad/param norm = 2.4673e-01, time/batch = 17.5480s	
9252/16650 (epoch 27.784), train_loss = 0.91248259, grad/param norm = 2.8949e-01, time/batch = 16.1062s	
9253/16650 (epoch 27.787), train_loss = 0.92713075, grad/param norm = 2.4703e-01, time/batch = 16.8602s	
9254/16650 (epoch 27.790), train_loss = 0.93399096, grad/param norm = 2.3398e-01, time/batch = 14.8346s	
9255/16650 (epoch 27.793), train_loss = 0.76553436, grad/param norm = 2.5791e-01, time/batch = 17.1879s	
9256/16650 (epoch 27.796), train_loss = 1.13398439, grad/param norm = 3.0567e-01, time/batch = 16.5172s	
9257/16650 (epoch 27.799), train_loss = 1.06004807, grad/param norm = 3.0445e-01, time/batch = 16.8899s	
9258/16650 (epoch 27.802), train_loss = 0.95658400, grad/param norm = 3.2587e-01, time/batch = 16.8821s	
9259/16650 (epoch 27.805), train_loss = 0.86359514, grad/param norm = 2.5267e-01, time/batch = 16.3354s	
9260/16650 (epoch 27.808), train_loss = 0.93177177, grad/param norm = 2.5892e-01, time/batch = 16.2656s	
9261/16650 (epoch 27.811), train_loss = 0.97972391, grad/param norm = 2.6864e-01, time/batch = 16.3645s	
9262/16650 (epoch 27.814), train_loss = 0.78193301, grad/param norm = 2.4494e-01, time/batch = 17.2667s	
9263/16650 (epoch 27.817), train_loss = 0.81993767, grad/param norm = 2.5907e-01, time/batch = 15.7501s	
9264/16650 (epoch 27.820), train_loss = 0.91134477, grad/param norm = 2.6765e-01, time/batch = 17.0294s	
9265/16650 (epoch 27.823), train_loss = 0.85230843, grad/param norm = 2.6118e-01, time/batch = 17.3603s	
9266/16650 (epoch 27.826), train_loss = 0.84075887, grad/param norm = 2.5014e-01, time/batch = 16.8827s	
9267/16650 (epoch 27.829), train_loss = 0.89773253, grad/param norm = 2.5916e-01, time/batch = 16.5855s	
9268/16650 (epoch 27.832), train_loss = 0.93463799, grad/param norm = 2.5907e-01, time/batch = 16.9589s	
9269/16650 (epoch 27.835), train_loss = 0.94483386, grad/param norm = 3.1449e-01, time/batch = 18.0428s	
9270/16650 (epoch 27.838), train_loss = 0.81092626, grad/param norm = 2.6764e-01, time/batch = 16.6822s	
9271/16650 (epoch 27.841), train_loss = 0.81665596, grad/param norm = 2.4185e-01, time/batch = 17.7832s	
9272/16650 (epoch 27.844), train_loss = 0.82625287, grad/param norm = 2.8784e-01, time/batch = 17.3573s	
9273/16650 (epoch 27.847), train_loss = 0.95150705, grad/param norm = 2.8494e-01, time/batch = 16.4396s	
9274/16650 (epoch 27.850), train_loss = 0.77386118, grad/param norm = 2.5793e-01, time/batch = 16.7652s	
9275/16650 (epoch 27.853), train_loss = 0.87723764, grad/param norm = 2.6560e-01, time/batch = 17.2226s	
9276/16650 (epoch 27.856), train_loss = 0.80115569, grad/param norm = 2.4133e-01, time/batch = 16.8769s	
9277/16650 (epoch 27.859), train_loss = 0.97040628, grad/param norm = 2.8110e-01, time/batch = 15.7648s	
9278/16650 (epoch 27.862), train_loss = 0.85260577, grad/param norm = 2.4878e-01, time/batch = 17.1144s	
9279/16650 (epoch 27.865), train_loss = 0.72207103, grad/param norm = 2.3727e-01, time/batch = 14.0058s	
9280/16650 (epoch 27.868), train_loss = 0.92291329, grad/param norm = 2.8451e-01, time/batch = 17.9404s	
9281/16650 (epoch 27.871), train_loss = 0.91446601, grad/param norm = 2.6982e-01, time/batch = 15.1623s	
9282/16650 (epoch 27.874), train_loss = 0.91177288, grad/param norm = 2.5570e-01, time/batch = 14.8241s	
9283/16650 (epoch 27.877), train_loss = 0.89208521, grad/param norm = 2.5507e-01, time/batch = 17.2837s	
9284/16650 (epoch 27.880), train_loss = 0.76840720, grad/param norm = 2.6959e-01, time/batch = 16.8668s	
9285/16650 (epoch 27.883), train_loss = 0.89215420, grad/param norm = 2.6373e-01, time/batch = 16.8526s	
9286/16650 (epoch 27.886), train_loss = 0.88036554, grad/param norm = 2.6002e-01, time/batch = 17.2910s	
9287/16650 (epoch 27.889), train_loss = 0.73408262, grad/param norm = 2.6480e-01, time/batch = 17.3571s	
9288/16650 (epoch 27.892), train_loss = 0.86428266, grad/param norm = 2.5271e-01, time/batch = 15.2733s	
9289/16650 (epoch 27.895), train_loss = 0.90165024, grad/param norm = 2.9061e-01, time/batch = 17.0328s	
9290/16650 (epoch 27.898), train_loss = 0.88661928, grad/param norm = 3.1579e-01, time/batch = 17.7117s	
9291/16650 (epoch 27.901), train_loss = 0.85281432, grad/param norm = 2.6767e-01, time/batch = 16.6128s	
9292/16650 (epoch 27.904), train_loss = 0.80857857, grad/param norm = 2.6623e-01, time/batch = 16.8472s	
9293/16650 (epoch 27.907), train_loss = 0.88817233, grad/param norm = 2.6895e-01, time/batch = 17.7907s	
9294/16650 (epoch 27.910), train_loss = 0.92645014, grad/param norm = 2.8997e-01, time/batch = 17.1182s	
9295/16650 (epoch 27.913), train_loss = 0.81799426, grad/param norm = 2.4731e-01, time/batch = 15.9238s	
9296/16650 (epoch 27.916), train_loss = 0.84028310, grad/param norm = 2.8079e-01, time/batch = 16.3524s	
9297/16650 (epoch 27.919), train_loss = 1.01882676, grad/param norm = 2.7842e-01, time/batch = 17.7013s	
9298/16650 (epoch 27.922), train_loss = 0.93950037, grad/param norm = 2.8950e-01, time/batch = 17.6245s	
9299/16650 (epoch 27.925), train_loss = 0.81846222, grad/param norm = 2.9605e-01, time/batch = 15.5776s	
9300/16650 (epoch 27.928), train_loss = 0.85851022, grad/param norm = 2.4263e-01, time/batch = 15.5255s	
9301/16650 (epoch 27.931), train_loss = 0.93491773, grad/param norm = 3.0038e-01, time/batch = 17.7031s	
9302/16650 (epoch 27.934), train_loss = 0.74598603, grad/param norm = 3.2118e-01, time/batch = 14.9344s	
9303/16650 (epoch 27.937), train_loss = 0.79689283, grad/param norm = 3.1549e-01, time/batch = 16.2693s	
9304/16650 (epoch 27.940), train_loss = 0.84391511, grad/param norm = 2.3542e-01, time/batch = 17.7955s	
9305/16650 (epoch 27.943), train_loss = 0.89934635, grad/param norm = 2.8844e-01, time/batch = 17.7778s	
9306/16650 (epoch 27.946), train_loss = 0.80377404, grad/param norm = 2.7362e-01, time/batch = 15.7644s	
9307/16650 (epoch 27.949), train_loss = 0.78567965, grad/param norm = 3.0084e-01, time/batch = 15.7355s	
9308/16650 (epoch 27.952), train_loss = 0.73692128, grad/param norm = 2.5204e-01, time/batch = 17.5517s	
9309/16650 (epoch 27.955), train_loss = 0.85090440, grad/param norm = 2.4297e-01, time/batch = 16.7781s	
9310/16650 (epoch 27.958), train_loss = 0.93086699, grad/param norm = 3.0663e-01, time/batch = 15.7688s	
9311/16650 (epoch 27.961), train_loss = 0.86343993, grad/param norm = 2.5221e-01, time/batch = 18.2889s	
9312/16650 (epoch 27.964), train_loss = 0.78327340, grad/param norm = 2.7300e-01, time/batch = 18.6131s	
9313/16650 (epoch 27.967), train_loss = 0.99880002, grad/param norm = 2.8996e-01, time/batch = 30.1472s	
9314/16650 (epoch 27.970), train_loss = 0.79464678, grad/param norm = 2.3667e-01, time/batch = 19.6093s	
9315/16650 (epoch 27.973), train_loss = 0.82594872, grad/param norm = 2.8177e-01, time/batch = 17.0342s	
9316/16650 (epoch 27.976), train_loss = 0.80297294, grad/param norm = 2.5527e-01, time/batch = 16.7464s	
9317/16650 (epoch 27.979), train_loss = 0.90512102, grad/param norm = 3.1177e-01, time/batch = 18.3748s	
9318/16650 (epoch 27.982), train_loss = 0.91248562, grad/param norm = 2.8545e-01, time/batch = 18.5425s	
9319/16650 (epoch 27.985), train_loss = 0.83866204, grad/param norm = 2.6661e-01, time/batch = 17.5235s	
9320/16650 (epoch 27.988), train_loss = 0.95428876, grad/param norm = 3.0500e-01, time/batch = 16.6687s	
9321/16650 (epoch 27.991), train_loss = 0.78212741, grad/param norm = 2.8643e-01, time/batch = 17.2029s	
9322/16650 (epoch 27.994), train_loss = 0.80755885, grad/param norm = 2.5581e-01, time/batch = 17.7494s	
9323/16650 (epoch 27.997), train_loss = 0.85469813, grad/param norm = 2.7044e-01, time/batch = 18.3483s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
9324/16650 (epoch 28.000), train_loss = 0.92037174, grad/param norm = 2.7988e-01, time/batch = 14.6789s	
9325/16650 (epoch 28.003), train_loss = 0.94691806, grad/param norm = 2.6977e-01, time/batch = 16.4207s	
9326/16650 (epoch 28.006), train_loss = 0.95482330, grad/param norm = 3.0540e-01, time/batch = 15.9910s	
9327/16650 (epoch 28.009), train_loss = 1.01567515, grad/param norm = 2.6495e-01, time/batch = 18.4459s	
9328/16650 (epoch 28.012), train_loss = 1.00292636, grad/param norm = 2.7916e-01, time/batch = 17.8796s	
9329/16650 (epoch 28.015), train_loss = 0.86467456, grad/param norm = 2.7193e-01, time/batch = 16.5799s	
9330/16650 (epoch 28.018), train_loss = 0.74436246, grad/param norm = 2.6514e-01, time/batch = 3.8625s	
9331/16650 (epoch 28.021), train_loss = 0.97332932, grad/param norm = 2.9657e-01, time/batch = 0.6406s	
9332/16650 (epoch 28.024), train_loss = 0.85408020, grad/param norm = 2.7328e-01, time/batch = 0.6398s	
9333/16650 (epoch 28.027), train_loss = 0.93813052, grad/param norm = 2.8950e-01, time/batch = 0.6372s	
9334/16650 (epoch 28.030), train_loss = 0.76760539, grad/param norm = 2.5094e-01, time/batch = 0.6483s	
9335/16650 (epoch 28.033), train_loss = 0.88126544, grad/param norm = 2.6973e-01, time/batch = 0.6350s	
9336/16650 (epoch 28.036), train_loss = 0.65689884, grad/param norm = 2.8461e-01, time/batch = 0.6389s	
9337/16650 (epoch 28.039), train_loss = 0.96987088, grad/param norm = 2.5040e-01, time/batch = 0.6478s	
9338/16650 (epoch 28.042), train_loss = 0.95579560, grad/param norm = 3.2064e-01, time/batch = 0.9396s	
9339/16650 (epoch 28.045), train_loss = 0.83604684, grad/param norm = 2.5332e-01, time/batch = 0.9280s	
9340/16650 (epoch 28.048), train_loss = 0.95823516, grad/param norm = 3.2218e-01, time/batch = 0.9416s	
9341/16650 (epoch 28.051), train_loss = 0.84296549, grad/param norm = 2.5945e-01, time/batch = 0.9426s	
9342/16650 (epoch 28.054), train_loss = 0.88102378, grad/param norm = 2.8124e-01, time/batch = 0.9430s	
9343/16650 (epoch 28.057), train_loss = 0.90149001, grad/param norm = 2.9066e-01, time/batch = 1.5497s	
9344/16650 (epoch 28.060), train_loss = 0.74837488, grad/param norm = 2.4895e-01, time/batch = 1.7546s	
9345/16650 (epoch 28.063), train_loss = 0.84404253, grad/param norm = 2.5145e-01, time/batch = 1.7531s	
9346/16650 (epoch 28.066), train_loss = 1.01606016, grad/param norm = 2.7382e-01, time/batch = 17.3886s	
9347/16650 (epoch 28.069), train_loss = 0.92720840, grad/param norm = 2.6755e-01, time/batch = 17.6089s	
9348/16650 (epoch 28.072), train_loss = 0.86118292, grad/param norm = 2.9635e-01, time/batch = 16.8467s	
9349/16650 (epoch 28.075), train_loss = 0.95732143, grad/param norm = 2.8978e-01, time/batch = 15.2687s	
9350/16650 (epoch 28.078), train_loss = 0.98934957, grad/param norm = 2.9230e-01, time/batch = 17.8654s	
9351/16650 (epoch 28.081), train_loss = 0.90310258, grad/param norm = 2.9730e-01, time/batch = 16.5795s	
9352/16650 (epoch 28.084), train_loss = 0.94670269, grad/param norm = 2.8943e-01, time/batch = 14.8354s	
9353/16650 (epoch 28.087), train_loss = 0.87708545, grad/param norm = 2.9373e-01, time/batch = 18.5338s	
9354/16650 (epoch 28.090), train_loss = 0.86261745, grad/param norm = 2.6907e-01, time/batch = 18.6117s	
9355/16650 (epoch 28.093), train_loss = 1.03378216, grad/param norm = 3.2837e-01, time/batch = 16.3283s	
9356/16650 (epoch 28.096), train_loss = 0.83823143, grad/param norm = 2.5026e-01, time/batch = 18.4535s	
9357/16650 (epoch 28.099), train_loss = 0.90461230, grad/param norm = 2.8240e-01, time/batch = 16.9549s	
9358/16650 (epoch 28.102), train_loss = 0.87943589, grad/param norm = 2.6875e-01, time/batch = 16.0698s	
9359/16650 (epoch 28.105), train_loss = 0.91715871, grad/param norm = 2.6960e-01, time/batch = 17.5157s	
9360/16650 (epoch 28.108), train_loss = 0.90548183, grad/param norm = 2.8547e-01, time/batch = 17.3711s	
9361/16650 (epoch 28.111), train_loss = 0.97570799, grad/param norm = 2.6105e-01, time/batch = 17.5344s	
9362/16650 (epoch 28.114), train_loss = 0.96494186, grad/param norm = 3.3095e-01, time/batch = 17.1809s	
9363/16650 (epoch 28.117), train_loss = 1.03792688, grad/param norm = 2.7470e-01, time/batch = 18.0337s	
9364/16650 (epoch 28.120), train_loss = 0.84701137, grad/param norm = 2.4823e-01, time/batch = 17.6633s	
9365/16650 (epoch 28.123), train_loss = 0.87430793, grad/param norm = 2.7101e-01, time/batch = 16.8537s	
9366/16650 (epoch 28.126), train_loss = 0.91159996, grad/param norm = 2.4859e-01, time/batch = 15.5871s	
9367/16650 (epoch 28.129), train_loss = 0.90623113, grad/param norm = 2.4176e-01, time/batch = 18.4459s	
9368/16650 (epoch 28.132), train_loss = 0.88025531, grad/param norm = 2.7278e-01, time/batch = 16.6092s	
9369/16650 (epoch 28.135), train_loss = 0.97001068, grad/param norm = 2.6293e-01, time/batch = 15.4039s	
9370/16650 (epoch 28.138), train_loss = 0.96329443, grad/param norm = 2.4625e-01, time/batch = 18.3680s	
9371/16650 (epoch 28.141), train_loss = 0.93055711, grad/param norm = 2.6737e-01, time/batch = 18.0298s	
9372/16650 (epoch 28.144), train_loss = 0.90269915, grad/param norm = 2.5910e-01, time/batch = 18.0270s	
9373/16650 (epoch 28.147), train_loss = 1.01492842, grad/param norm = 2.6898e-01, time/batch = 17.2660s	
9374/16650 (epoch 28.150), train_loss = 1.12172821, grad/param norm = 3.5066e-01, time/batch = 18.1180s	
9375/16650 (epoch 28.153), train_loss = 0.94064954, grad/param norm = 2.7448e-01, time/batch = 16.7584s	
9376/16650 (epoch 28.156), train_loss = 0.83664469, grad/param norm = 2.5395e-01, time/batch = 15.3756s	
9377/16650 (epoch 28.159), train_loss = 0.95246358, grad/param norm = 3.4847e-01, time/batch = 18.5356s	
9378/16650 (epoch 28.162), train_loss = 1.01787789, grad/param norm = 2.6960e-01, time/batch = 18.4544s	
9379/16650 (epoch 28.165), train_loss = 1.02357218, grad/param norm = 2.8939e-01, time/batch = 16.3407s	
9380/16650 (epoch 28.168), train_loss = 0.76083505, grad/param norm = 2.3572e-01, time/batch = 16.7913s	
9381/16650 (epoch 28.171), train_loss = 0.96323522, grad/param norm = 2.5315e-01, time/batch = 17.4590s	
9382/16650 (epoch 28.174), train_loss = 0.74381151, grad/param norm = 2.6014e-01, time/batch = 16.4870s	
9383/16650 (epoch 28.177), train_loss = 0.90712377, grad/param norm = 2.9859e-01, time/batch = 16.6159s	
9384/16650 (epoch 28.180), train_loss = 1.00132371, grad/param norm = 2.6802e-01, time/batch = 16.2655s	
9385/16650 (epoch 28.183), train_loss = 1.11162786, grad/param norm = 3.1208e-01, time/batch = 17.6884s	
9386/16650 (epoch 28.186), train_loss = 0.96235137, grad/param norm = 3.4017e-01, time/batch = 16.4415s	
9387/16650 (epoch 28.189), train_loss = 0.84100152, grad/param norm = 2.5028e-01, time/batch = 18.2717s	
9388/16650 (epoch 28.192), train_loss = 0.85878828, grad/param norm = 2.7844e-01, time/batch = 18.0291s	
9389/16650 (epoch 28.195), train_loss = 0.83962140, grad/param norm = 2.8856e-01, time/batch = 15.7339s	
9390/16650 (epoch 28.198), train_loss = 0.77427728, grad/param norm = 2.4367e-01, time/batch = 16.2158s	
9391/16650 (epoch 28.201), train_loss = 0.81298486, grad/param norm = 3.1271e-01, time/batch = 18.6989s	
9392/16650 (epoch 28.204), train_loss = 0.91436283, grad/param norm = 2.9225e-01, time/batch = 18.0324s	
9393/16650 (epoch 28.207), train_loss = 0.93331839, grad/param norm = 3.4074e-01, time/batch = 16.5052s	
9394/16650 (epoch 28.210), train_loss = 0.88642853, grad/param norm = 2.6874e-01, time/batch = 17.4452s	
9395/16650 (epoch 28.213), train_loss = 0.98001358, grad/param norm = 3.0648e-01, time/batch = 16.7742s	
9396/16650 (epoch 28.216), train_loss = 0.85833774, grad/param norm = 2.7125e-01, time/batch = 16.9193s	
9397/16650 (epoch 28.219), train_loss = 0.90582919, grad/param norm = 2.9739e-01, time/batch = 16.7613s	
9398/16650 (epoch 28.222), train_loss = 0.93655727, grad/param norm = 2.6353e-01, time/batch = 17.6994s	
9399/16650 (epoch 28.225), train_loss = 0.91022453, grad/param norm = 2.8443e-01, time/batch = 17.6181s	
9400/16650 (epoch 28.228), train_loss = 0.82123116, grad/param norm = 2.6688e-01, time/batch = 16.0931s	
9401/16650 (epoch 28.231), train_loss = 0.85760089, grad/param norm = 2.8574e-01, time/batch = 17.5209s	
9402/16650 (epoch 28.234), train_loss = 1.05830532, grad/param norm = 2.6329e-01, time/batch = 17.8414s	
9403/16650 (epoch 28.237), train_loss = 0.94067031, grad/param norm = 3.1179e-01, time/batch = 16.1757s	
9404/16650 (epoch 28.240), train_loss = 0.92407436, grad/param norm = 2.7733e-01, time/batch = 17.2750s	
9405/16650 (epoch 28.243), train_loss = 0.89051922, grad/param norm = 2.7692e-01, time/batch = 17.4567s	
9406/16650 (epoch 28.246), train_loss = 1.01694017, grad/param norm = 3.1185e-01, time/batch = 17.8622s	
9407/16650 (epoch 28.249), train_loss = 0.76769254, grad/param norm = 2.3566e-01, time/batch = 16.9443s	
9408/16650 (epoch 28.252), train_loss = 0.85173690, grad/param norm = 2.6400e-01, time/batch = 18.0414s	
9409/16650 (epoch 28.255), train_loss = 0.93182238, grad/param norm = 2.6426e-01, time/batch = 17.0303s	
9410/16650 (epoch 28.258), train_loss = 0.97994879, grad/param norm = 2.6154e-01, time/batch = 17.3446s	
9411/16650 (epoch 28.261), train_loss = 0.93448815, grad/param norm = 2.7391e-01, time/batch = 15.8244s	
9412/16650 (epoch 28.264), train_loss = 0.85547774, grad/param norm = 2.6731e-01, time/batch = 17.8523s	
9413/16650 (epoch 28.267), train_loss = 0.87063814, grad/param norm = 3.0594e-01, time/batch = 18.2898s	
9414/16650 (epoch 28.270), train_loss = 0.93475769, grad/param norm = 2.7123e-01, time/batch = 15.9924s	
9415/16650 (epoch 28.273), train_loss = 1.00970820, grad/param norm = 2.6440e-01, time/batch = 18.3654s	
9416/16650 (epoch 28.276), train_loss = 0.92085927, grad/param norm = 2.5980e-01, time/batch = 17.8669s	
9417/16650 (epoch 28.279), train_loss = 0.88093301, grad/param norm = 2.6997e-01, time/batch = 16.2624s	
9418/16650 (epoch 28.282), train_loss = 0.78945409, grad/param norm = 2.3639e-01, time/batch = 17.2402s	
9419/16650 (epoch 28.285), train_loss = 0.80859724, grad/param norm = 2.2390e-01, time/batch = 16.1885s	
9420/16650 (epoch 28.288), train_loss = 0.83897245, grad/param norm = 3.1501e-01, time/batch = 18.4495s	
9421/16650 (epoch 28.291), train_loss = 0.67509691, grad/param norm = 2.1857e-01, time/batch = 17.8377s	
9422/16650 (epoch 28.294), train_loss = 0.77926765, grad/param norm = 2.2359e-01, time/batch = 14.4030s	
9423/16650 (epoch 28.297), train_loss = 0.87800764, grad/param norm = 2.4382e-01, time/batch = 18.6094s	
9424/16650 (epoch 28.300), train_loss = 0.69568116, grad/param norm = 2.2259e-01, time/batch = 17.1033s	
9425/16650 (epoch 28.303), train_loss = 0.76102667, grad/param norm = 2.2196e-01, time/batch = 18.2073s	
9426/16650 (epoch 28.306), train_loss = 0.95748664, grad/param norm = 2.4876e-01, time/batch = 17.0398s	
9427/16650 (epoch 28.309), train_loss = 0.96637846, grad/param norm = 2.7432e-01, time/batch = 17.2798s	
9428/16650 (epoch 28.312), train_loss = 0.77291617, grad/param norm = 2.9415e-01, time/batch = 16.2257s	
9429/16650 (epoch 28.315), train_loss = 0.63641662, grad/param norm = 2.0778e-01, time/batch = 18.0328s	
9430/16650 (epoch 28.318), train_loss = 0.74114481, grad/param norm = 2.5144e-01, time/batch = 17.7628s	
9431/16650 (epoch 28.321), train_loss = 0.99746817, grad/param norm = 2.8912e-01, time/batch = 16.7635s	
9432/16650 (epoch 28.324), train_loss = 0.83204713, grad/param norm = 3.0440e-01, time/batch = 18.8587s	
9433/16650 (epoch 28.327), train_loss = 0.92614794, grad/param norm = 2.9665e-01, time/batch = 16.4423s	
9434/16650 (epoch 28.330), train_loss = 0.93319575, grad/param norm = 3.1666e-01, time/batch = 17.4359s	
9435/16650 (epoch 28.333), train_loss = 0.93543507, grad/param norm = 2.9426e-01, time/batch = 16.7722s	
9436/16650 (epoch 28.336), train_loss = 0.79688008, grad/param norm = 3.0270e-01, time/batch = 18.3582s	
9437/16650 (epoch 28.339), train_loss = 0.84115963, grad/param norm = 2.7589e-01, time/batch = 18.3721s	
9438/16650 (epoch 28.342), train_loss = 0.77903121, grad/param norm = 2.8321e-01, time/batch = 15.9975s	
9439/16650 (epoch 28.345), train_loss = 0.76137052, grad/param norm = 2.3779e-01, time/batch = 17.0855s	
9440/16650 (epoch 28.348), train_loss = 0.87665592, grad/param norm = 3.4790e-01, time/batch = 18.6325s	
9441/16650 (epoch 28.351), train_loss = 0.91013635, grad/param norm = 2.7064e-01, time/batch = 16.4265s	
9442/16650 (epoch 28.354), train_loss = 0.95258124, grad/param norm = 2.9657e-01, time/batch = 17.3695s	
9443/16650 (epoch 28.357), train_loss = 0.92308964, grad/param norm = 2.8792e-01, time/batch = 15.5873s	
9444/16650 (epoch 28.360), train_loss = 0.88901143, grad/param norm = 2.8880e-01, time/batch = 18.1941s	
9445/16650 (epoch 28.363), train_loss = 0.97985853, grad/param norm = 2.9821e-01, time/batch = 15.4995s	
9446/16650 (epoch 28.366), train_loss = 1.02104615, grad/param norm = 2.7867e-01, time/batch = 17.4355s	
9447/16650 (epoch 28.369), train_loss = 0.90782990, grad/param norm = 2.9286e-01, time/batch = 18.7045s	
9448/16650 (epoch 28.372), train_loss = 0.89726055, grad/param norm = 2.5363e-01, time/batch = 16.8412s	
9449/16650 (epoch 28.375), train_loss = 0.89401387, grad/param norm = 2.3850e-01, time/batch = 18.0907s	
9450/16650 (epoch 28.378), train_loss = 0.82214248, grad/param norm = 2.3806e-01, time/batch = 17.7025s	
9451/16650 (epoch 28.381), train_loss = 0.91420896, grad/param norm = 2.7435e-01, time/batch = 18.1193s	
9452/16650 (epoch 28.384), train_loss = 1.03519942, grad/param norm = 2.8181e-01, time/batch = 16.9154s	
9453/16650 (epoch 28.387), train_loss = 0.70320650, grad/param norm = 2.3818e-01, time/batch = 17.6035s	
9454/16650 (epoch 28.390), train_loss = 0.96095667, grad/param norm = 2.4900e-01, time/batch = 15.4694s	
9455/16650 (epoch 28.393), train_loss = 0.84337932, grad/param norm = 2.9515e-01, time/batch = 17.7633s	
9456/16650 (epoch 28.396), train_loss = 0.99532718, grad/param norm = 3.0514e-01, time/batch = 18.0348s	
9457/16650 (epoch 28.399), train_loss = 0.92039120, grad/param norm = 2.6517e-01, time/batch = 18.6913s	
9458/16650 (epoch 28.402), train_loss = 0.81255263, grad/param norm = 2.5321e-01, time/batch = 17.1135s	
9459/16650 (epoch 28.405), train_loss = 0.73993324, grad/param norm = 3.2121e-01, time/batch = 16.1886s	
9460/16650 (epoch 28.408), train_loss = 0.89565027, grad/param norm = 2.8863e-01, time/batch = 17.5404s	
9461/16650 (epoch 28.411), train_loss = 0.77946855, grad/param norm = 3.0194e-01, time/batch = 15.1415s	
9462/16650 (epoch 28.414), train_loss = 0.79856807, grad/param norm = 2.7119e-01, time/batch = 17.1040s	
9463/16650 (epoch 28.417), train_loss = 0.79136109, grad/param norm = 2.7838e-01, time/batch = 18.1999s	
9464/16650 (epoch 28.420), train_loss = 0.78014645, grad/param norm = 2.6983e-01, time/batch = 16.6169s	
9465/16650 (epoch 28.423), train_loss = 0.66631185, grad/param norm = 2.3443e-01, time/batch = 17.9485s	
9466/16650 (epoch 28.426), train_loss = 0.76570389, grad/param norm = 2.5280e-01, time/batch = 16.0866s	
9467/16650 (epoch 28.429), train_loss = 0.97411915, grad/param norm = 2.8493e-01, time/batch = 17.7838s	
9468/16650 (epoch 28.432), train_loss = 0.95923615, grad/param norm = 3.1478e-01, time/batch = 15.3331s	
9469/16650 (epoch 28.435), train_loss = 1.06598762, grad/param norm = 3.0111e-01, time/batch = 15.8040s	
9470/16650 (epoch 28.438), train_loss = 1.06216773, grad/param norm = 3.7788e-01, time/batch = 16.1182s	
9471/16650 (epoch 28.441), train_loss = 0.88774826, grad/param norm = 3.7727e-01, time/batch = 18.2889s	
9472/16650 (epoch 28.444), train_loss = 0.82661409, grad/param norm = 2.7765e-01, time/batch = 16.3606s	
9473/16650 (epoch 28.447), train_loss = 0.84352053, grad/param norm = 3.4545e-01, time/batch = 17.4340s	
9474/16650 (epoch 28.450), train_loss = 0.84050433, grad/param norm = 2.7011e-01, time/batch = 15.5001s	
9475/16650 (epoch 28.453), train_loss = 0.81179417, grad/param norm = 3.0384e-01, time/batch = 18.4479s	
9476/16650 (epoch 28.456), train_loss = 0.77184054, grad/param norm = 2.3134e-01, time/batch = 16.8501s	
9477/16650 (epoch 28.459), train_loss = 0.81058073, grad/param norm = 2.5905e-01, time/batch = 18.0221s	
9478/16650 (epoch 28.462), train_loss = 1.00863023, grad/param norm = 3.0974e-01, time/batch = 17.3588s	
9479/16650 (epoch 28.465), train_loss = 0.82730947, grad/param norm = 2.8401e-01, time/batch = 18.1205s	
9480/16650 (epoch 28.468), train_loss = 0.68840097, grad/param norm = 2.7434e-01, time/batch = 17.0177s	
9481/16650 (epoch 28.471), train_loss = 0.58120364, grad/param norm = 2.0530e-01, time/batch = 17.4419s	
9482/16650 (epoch 28.474), train_loss = 0.74650147, grad/param norm = 2.6511e-01, time/batch = 18.6976s	
9483/16650 (epoch 28.477), train_loss = 0.95000424, grad/param norm = 3.1600e-01, time/batch = 15.5868s	
9484/16650 (epoch 28.480), train_loss = 0.93331068, grad/param norm = 3.3884e-01, time/batch = 15.0339s	
9485/16650 (epoch 28.483), train_loss = 0.96546343, grad/param norm = 2.7354e-01, time/batch = 13.6313s	
9486/16650 (epoch 28.486), train_loss = 0.78339818, grad/param norm = 2.3623e-01, time/batch = 13.5522s	
9487/16650 (epoch 28.489), train_loss = 0.82323007, grad/param norm = 3.1382e-01, time/batch = 15.5053s	
9488/16650 (epoch 28.492), train_loss = 0.86854952, grad/param norm = 2.5370e-01, time/batch = 16.9371s	
9489/16650 (epoch 28.495), train_loss = 0.74228721, grad/param norm = 2.5501e-01, time/batch = 17.9477s	
9490/16650 (epoch 28.498), train_loss = 0.81985640, grad/param norm = 2.9008e-01, time/batch = 17.2757s	
9491/16650 (epoch 28.502), train_loss = 1.01850370, grad/param norm = 3.1531e-01, time/batch = 16.5018s	
9492/16650 (epoch 28.505), train_loss = 0.88268727, grad/param norm = 2.3217e-01, time/batch = 17.8588s	
9493/16650 (epoch 28.508), train_loss = 0.91105696, grad/param norm = 3.4220e-01, time/batch = 15.8964s	
9494/16650 (epoch 28.511), train_loss = 0.96779281, grad/param norm = 2.9429e-01, time/batch = 15.2084s	
9495/16650 (epoch 28.514), train_loss = 0.75764065, grad/param norm = 2.9015e-01, time/batch = 17.8638s	
9496/16650 (epoch 28.517), train_loss = 0.83930645, grad/param norm = 2.8213e-01, time/batch = 17.7685s	
9497/16650 (epoch 28.520), train_loss = 0.75025164, grad/param norm = 2.5762e-01, time/batch = 17.5324s	
9498/16650 (epoch 28.523), train_loss = 0.85302663, grad/param norm = 2.6284e-01, time/batch = 15.7223s	
9499/16650 (epoch 28.526), train_loss = 0.95004485, grad/param norm = 2.8592e-01, time/batch = 18.7864s	
9500/16650 (epoch 28.529), train_loss = 0.99857402, grad/param norm = 3.1821e-01, time/batch = 17.1835s	
9501/16650 (epoch 28.532), train_loss = 0.66603827, grad/param norm = 2.6097e-01, time/batch = 15.8303s	
9502/16650 (epoch 28.535), train_loss = 0.75849724, grad/param norm = 3.7165e-01, time/batch = 18.5274s	
9503/16650 (epoch 28.538), train_loss = 0.72083647, grad/param norm = 2.6767e-01, time/batch = 17.5461s	
9504/16650 (epoch 28.541), train_loss = 0.98480435, grad/param norm = 3.0816e-01, time/batch = 16.0038s	
9505/16650 (epoch 28.544), train_loss = 1.04270982, grad/param norm = 3.3583e-01, time/batch = 16.1760s	
9506/16650 (epoch 28.547), train_loss = 0.76565785, grad/param norm = 2.6364e-01, time/batch = 17.1152s	
9507/16650 (epoch 28.550), train_loss = 0.85530002, grad/param norm = 2.6152e-01, time/batch = 16.7744s	
9508/16650 (epoch 28.553), train_loss = 0.86521624, grad/param norm = 3.3277e-01, time/batch = 15.6644s	
9509/16650 (epoch 28.556), train_loss = 0.79351628, grad/param norm = 2.8695e-01, time/batch = 17.2623s	
9510/16650 (epoch 28.559), train_loss = 0.70137806, grad/param norm = 2.7517e-01, time/batch = 17.7050s	
9511/16650 (epoch 28.562), train_loss = 0.80811792, grad/param norm = 2.9469e-01, time/batch = 18.3773s	
9512/16650 (epoch 28.565), train_loss = 0.69700650, grad/param norm = 2.9069e-01, time/batch = 16.9209s	
9513/16650 (epoch 28.568), train_loss = 0.68752401, grad/param norm = 2.4567e-01, time/batch = 19.1350s	
9514/16650 (epoch 28.571), train_loss = 0.74370957, grad/param norm = 2.5695e-01, time/batch = 16.7020s	
9515/16650 (epoch 28.574), train_loss = 0.80907978, grad/param norm = 2.9402e-01, time/batch = 14.7264s	
9516/16650 (epoch 28.577), train_loss = 0.78885273, grad/param norm = 2.6343e-01, time/batch = 17.9499s	
9517/16650 (epoch 28.580), train_loss = 0.72630335, grad/param norm = 2.5961e-01, time/batch = 18.1163s	
9518/16650 (epoch 28.583), train_loss = 0.83205872, grad/param norm = 2.5259e-01, time/batch = 18.1204s	
9519/16650 (epoch 28.586), train_loss = 0.76062984, grad/param norm = 3.0024e-01, time/batch = 16.9898s	
9520/16650 (epoch 28.589), train_loss = 0.73549275, grad/param norm = 2.6860e-01, time/batch = 18.5434s	
9521/16650 (epoch 28.592), train_loss = 0.85082882, grad/param norm = 2.8393e-01, time/batch = 18.4579s	
9522/16650 (epoch 28.595), train_loss = 0.78550188, grad/param norm = 3.0837e-01, time/batch = 16.0023s	
9523/16650 (epoch 28.598), train_loss = 0.82936520, grad/param norm = 2.8851e-01, time/batch = 18.2906s	
9524/16650 (epoch 28.601), train_loss = 0.80499303, grad/param norm = 3.3986e-01, time/batch = 18.3725s	
9525/16650 (epoch 28.604), train_loss = 0.90169726, grad/param norm = 3.0174e-01, time/batch = 17.0067s	
9526/16650 (epoch 28.607), train_loss = 0.90839321, grad/param norm = 2.7381e-01, time/batch = 17.1206s	
9527/16650 (epoch 28.610), train_loss = 0.77548395, grad/param norm = 2.7935e-01, time/batch = 17.0236s	
9528/16650 (epoch 28.613), train_loss = 0.97608329, grad/param norm = 2.9749e-01, time/batch = 15.2298s	
9529/16650 (epoch 28.616), train_loss = 0.95428977, grad/param norm = 3.5893e-01, time/batch = 16.2613s	
9530/16650 (epoch 28.619), train_loss = 0.71472711, grad/param norm = 2.5779e-01, time/batch = 17.7954s	
9531/16650 (epoch 28.622), train_loss = 0.68292837, grad/param norm = 2.4487e-01, time/batch = 18.3697s	
9532/16650 (epoch 28.625), train_loss = 0.80384833, grad/param norm = 2.5189e-01, time/batch = 16.5125s	
9533/16650 (epoch 28.628), train_loss = 0.78468337, grad/param norm = 3.2154e-01, time/batch = 18.6042s	
9534/16650 (epoch 28.631), train_loss = 0.86926114, grad/param norm = 3.9304e-01, time/batch = 18.2013s	
9535/16650 (epoch 28.634), train_loss = 1.03650671, grad/param norm = 3.1213e-01, time/batch = 17.4359s	
9536/16650 (epoch 28.637), train_loss = 1.04621966, grad/param norm = 3.1153e-01, time/batch = 30.8510s	
9537/16650 (epoch 28.640), train_loss = 0.81340375, grad/param norm = 2.8027e-01, time/batch = 17.0233s	
9538/16650 (epoch 28.643), train_loss = 0.91534909, grad/param norm = 2.8375e-01, time/batch = 16.3883s	
9539/16650 (epoch 28.646), train_loss = 0.90727393, grad/param norm = 3.0732e-01, time/batch = 16.2038s	
9540/16650 (epoch 28.649), train_loss = 0.88388157, grad/param norm = 2.9004e-01, time/batch = 18.4423s	
9541/16650 (epoch 28.652), train_loss = 0.96732124, grad/param norm = 3.7510e-01, time/batch = 17.8638s	
9542/16650 (epoch 28.655), train_loss = 0.87855481, grad/param norm = 2.7548e-01, time/batch = 16.1659s	
9543/16650 (epoch 28.658), train_loss = 0.75327914, grad/param norm = 2.6073e-01, time/batch = 17.5472s	
9544/16650 (epoch 28.661), train_loss = 0.87982369, grad/param norm = 3.1545e-01, time/batch = 17.7892s	
9545/16650 (epoch 28.664), train_loss = 0.87967199, grad/param norm = 3.1417e-01, time/batch = 16.6819s	
9546/16650 (epoch 28.667), train_loss = 0.97383004, grad/param norm = 2.9640e-01, time/batch = 17.0226s	
9547/16650 (epoch 28.670), train_loss = 0.72293813, grad/param norm = 2.3860e-01, time/batch = 17.8538s	
9548/16650 (epoch 28.673), train_loss = 0.77347250, grad/param norm = 2.4953e-01, time/batch = 18.0299s	
9549/16650 (epoch 28.676), train_loss = 0.89814287, grad/param norm = 2.8658e-01, time/batch = 16.2449s	
9550/16650 (epoch 28.679), train_loss = 0.75280757, grad/param norm = 2.7118e-01, time/batch = 17.6953s	
9551/16650 (epoch 28.682), train_loss = 0.86857063, grad/param norm = 2.9601e-01, time/batch = 18.2024s	
9552/16650 (epoch 28.685), train_loss = 0.73972553, grad/param norm = 2.6713e-01, time/batch = 17.0087s	
9553/16650 (epoch 28.688), train_loss = 0.91914495, grad/param norm = 2.7624e-01, time/batch = 17.1134s	
9554/16650 (epoch 28.691), train_loss = 0.89568826, grad/param norm = 2.7423e-01, time/batch = 17.5438s	
9555/16650 (epoch 28.694), train_loss = 0.78921644, grad/param norm = 2.7272e-01, time/batch = 16.9525s	
9556/16650 (epoch 28.697), train_loss = 0.72397959, grad/param norm = 2.3555e-01, time/batch = 15.0401s	
9557/16650 (epoch 28.700), train_loss = 0.90320520, grad/param norm = 2.9456e-01, time/batch = 17.3413s	
9558/16650 (epoch 28.703), train_loss = 0.75579798, grad/param norm = 2.8983e-01, time/batch = 16.7543s	
9559/16650 (epoch 28.706), train_loss = 0.83607545, grad/param norm = 2.8263e-01, time/batch = 17.1014s	
9560/16650 (epoch 28.709), train_loss = 0.74366523, grad/param norm = 2.7966e-01, time/batch = 16.6790s	
9561/16650 (epoch 28.712), train_loss = 0.76816492, grad/param norm = 2.7345e-01, time/batch = 18.2657s	
9562/16650 (epoch 28.715), train_loss = 0.90845771, grad/param norm = 2.9864e-01, time/batch = 17.7771s	
9563/16650 (epoch 28.718), train_loss = 0.94045431, grad/param norm = 2.9614e-01, time/batch = 17.0215s	
9564/16650 (epoch 28.721), train_loss = 0.90975580, grad/param norm = 2.8628e-01, time/batch = 18.7903s	
9565/16650 (epoch 28.724), train_loss = 0.92999886, grad/param norm = 2.8662e-01, time/batch = 17.3484s	
9566/16650 (epoch 28.727), train_loss = 0.94238329, grad/param norm = 2.9298e-01, time/batch = 16.2730s	
9567/16650 (epoch 28.730), train_loss = 0.77456631, grad/param norm = 2.5432e-01, time/batch = 17.6785s	
9568/16650 (epoch 28.733), train_loss = 0.93370790, grad/param norm = 2.9722e-01, time/batch = 17.8668s	
9569/16650 (epoch 28.736), train_loss = 0.70838748, grad/param norm = 2.4832e-01, time/batch = 17.5090s	
9570/16650 (epoch 28.739), train_loss = 0.85139173, grad/param norm = 2.7131e-01, time/batch = 18.0077s	
9571/16650 (epoch 28.742), train_loss = 0.84105706, grad/param norm = 2.8422e-01, time/batch = 15.9015s	
9572/16650 (epoch 28.745), train_loss = 0.65164777, grad/param norm = 2.3054e-01, time/batch = 17.0510s	
9573/16650 (epoch 28.748), train_loss = 0.73858265, grad/param norm = 3.1450e-01, time/batch = 17.4304s	
9574/16650 (epoch 28.751), train_loss = 0.87676163, grad/param norm = 4.7854e-01, time/batch = 17.3596s	
9575/16650 (epoch 28.754), train_loss = 1.04829178, grad/param norm = 3.8666e-01, time/batch = 15.3326s	
9576/16650 (epoch 28.757), train_loss = 0.97932190, grad/param norm = 2.8711e-01, time/batch = 16.9337s	
9577/16650 (epoch 28.760), train_loss = 0.84629852, grad/param norm = 2.7614e-01, time/batch = 16.3536s	
9578/16650 (epoch 28.763), train_loss = 0.79667722, grad/param norm = 2.6460e-01, time/batch = 17.6096s	
9579/16650 (epoch 28.766), train_loss = 0.81474470, grad/param norm = 2.5409e-01, time/batch = 18.5269s	
9580/16650 (epoch 28.769), train_loss = 0.88226634, grad/param norm = 2.7223e-01, time/batch = 16.5864s	
9581/16650 (epoch 28.772), train_loss = 0.83147301, grad/param norm = 2.4736e-01, time/batch = 17.7708s	
9582/16650 (epoch 28.775), train_loss = 0.83810047, grad/param norm = 2.7989e-01, time/batch = 16.4102s	
9583/16650 (epoch 28.778), train_loss = 0.84910251, grad/param norm = 2.3815e-01, time/batch = 17.4270s	
9584/16650 (epoch 28.781), train_loss = 0.98801679, grad/param norm = 2.6387e-01, time/batch = 14.5798s	
9585/16650 (epoch 28.784), train_loss = 0.89267332, grad/param norm = 2.6814e-01, time/batch = 18.1936s	
9586/16650 (epoch 28.787), train_loss = 0.91254557, grad/param norm = 2.6714e-01, time/batch = 18.4498s	
9587/16650 (epoch 28.790), train_loss = 0.91161190, grad/param norm = 2.4160e-01, time/batch = 16.3354s	
9588/16650 (epoch 28.793), train_loss = 0.74811373, grad/param norm = 2.6205e-01, time/batch = 18.2816s	
9589/16650 (epoch 28.796), train_loss = 1.10095385, grad/param norm = 2.9157e-01, time/batch = 18.5214s	
9590/16650 (epoch 28.799), train_loss = 1.02040559, grad/param norm = 2.9651e-01, time/batch = 17.2647s	
9591/16650 (epoch 28.802), train_loss = 0.94153108, grad/param norm = 2.7721e-01, time/batch = 17.5116s	
9592/16650 (epoch 28.805), train_loss = 0.85251684, grad/param norm = 2.3604e-01, time/batch = 16.9137s	
9593/16650 (epoch 28.808), train_loss = 0.91846091, grad/param norm = 2.6262e-01, time/batch = 18.2480s	
9594/16650 (epoch 28.811), train_loss = 0.98382426, grad/param norm = 3.1264e-01, time/batch = 16.7644s	
9595/16650 (epoch 28.814), train_loss = 0.77200486, grad/param norm = 2.5504e-01, time/batch = 16.8427s	
9596/16650 (epoch 28.817), train_loss = 0.82092775, grad/param norm = 2.9584e-01, time/batch = 16.7684s	
9597/16650 (epoch 28.820), train_loss = 0.89836257, grad/param norm = 2.9641e-01, time/batch = 15.7414s	
9598/16650 (epoch 28.823), train_loss = 0.84263605, grad/param norm = 2.7320e-01, time/batch = 18.1866s	
9599/16650 (epoch 28.826), train_loss = 0.81273811, grad/param norm = 2.7044e-01, time/batch = 18.0344s	
9600/16650 (epoch 28.829), train_loss = 0.88442000, grad/param norm = 2.8722e-01, time/batch = 17.2915s	
9601/16650 (epoch 28.832), train_loss = 0.93804340, grad/param norm = 2.9439e-01, time/batch = 17.5885s	
9602/16650 (epoch 28.835), train_loss = 0.92387727, grad/param norm = 3.0233e-01, time/batch = 17.2809s	
9603/16650 (epoch 28.838), train_loss = 0.78584303, grad/param norm = 2.7080e-01, time/batch = 16.2738s	
9604/16650 (epoch 28.841), train_loss = 0.80002067, grad/param norm = 2.6382e-01, time/batch = 14.8990s	
9605/16650 (epoch 28.844), train_loss = 0.79696481, grad/param norm = 2.4818e-01, time/batch = 15.6967s	
9606/16650 (epoch 28.847), train_loss = 0.93497297, grad/param norm = 2.8591e-01, time/batch = 18.1090s	
9607/16650 (epoch 28.850), train_loss = 0.74809668, grad/param norm = 2.6613e-01, time/batch = 18.2896s	
9608/16650 (epoch 28.853), train_loss = 0.85949163, grad/param norm = 2.6055e-01, time/batch = 16.7722s	
9609/16650 (epoch 28.856), train_loss = 0.79315080, grad/param norm = 2.7242e-01, time/batch = 16.5222s	
9610/16650 (epoch 28.859), train_loss = 0.96772394, grad/param norm = 3.2820e-01, time/batch = 16.4938s	
9611/16650 (epoch 28.862), train_loss = 0.82670048, grad/param norm = 2.2947e-01, time/batch = 15.9362s	
9612/16650 (epoch 28.865), train_loss = 0.69849906, grad/param norm = 2.4880e-01, time/batch = 16.6131s	
9613/16650 (epoch 28.868), train_loss = 0.89661792, grad/param norm = 2.7153e-01, time/batch = 18.1960s	
9614/16650 (epoch 28.871), train_loss = 0.92037189, grad/param norm = 2.9974e-01, time/batch = 15.2493s	
9615/16650 (epoch 28.874), train_loss = 0.90473969, grad/param norm = 2.7779e-01, time/batch = 16.5968s	
9616/16650 (epoch 28.877), train_loss = 0.87191198, grad/param norm = 2.5432e-01, time/batch = 17.9492s	
9617/16650 (epoch 28.880), train_loss = 0.76969948, grad/param norm = 2.9046e-01, time/batch = 17.0094s	
9618/16650 (epoch 28.883), train_loss = 0.88037597, grad/param norm = 2.9355e-01, time/batch = 15.8273s	
9619/16650 (epoch 28.886), train_loss = 0.87691448, grad/param norm = 2.7256e-01, time/batch = 17.9289s	
9620/16650 (epoch 28.889), train_loss = 0.71992565, grad/param norm = 2.7413e-01, time/batch = 18.3740s	
9621/16650 (epoch 28.892), train_loss = 0.85393384, grad/param norm = 2.8201e-01, time/batch = 17.3786s	
9622/16650 (epoch 28.895), train_loss = 0.89120657, grad/param norm = 2.8362e-01, time/batch = 15.9918s	
9623/16650 (epoch 28.898), train_loss = 0.86506974, grad/param norm = 2.7415e-01, time/batch = 17.8536s	
9624/16650 (epoch 28.901), train_loss = 0.82047045, grad/param norm = 2.5698e-01, time/batch = 18.6907s	
9625/16650 (epoch 28.904), train_loss = 0.80695104, grad/param norm = 2.8856e-01, time/batch = 14.9872s	
9626/16650 (epoch 28.907), train_loss = 0.87598716, grad/param norm = 2.7841e-01, time/batch = 16.3358s	
9627/16650 (epoch 28.910), train_loss = 0.89626069, grad/param norm = 2.8317e-01, time/batch = 17.2765s	
9628/16650 (epoch 28.913), train_loss = 0.80945662, grad/param norm = 2.6227e-01, time/batch = 17.4458s	
9629/16650 (epoch 28.916), train_loss = 0.81612865, grad/param norm = 2.8621e-01, time/batch = 16.2321s	
9630/16650 (epoch 28.919), train_loss = 0.99728879, grad/param norm = 2.8695e-01, time/batch = 16.3425s	
9631/16650 (epoch 28.922), train_loss = 0.91125923, grad/param norm = 2.8904e-01, time/batch = 17.3604s	
9632/16650 (epoch 28.925), train_loss = 0.79037080, grad/param norm = 2.6663e-01, time/batch = 18.0168s	
9633/16650 (epoch 28.928), train_loss = 0.85535948, grad/param norm = 2.8356e-01, time/batch = 16.9437s	
9634/16650 (epoch 28.931), train_loss = 0.91925628, grad/param norm = 2.8298e-01, time/batch = 18.3890s	
9635/16650 (epoch 28.934), train_loss = 0.74425567, grad/param norm = 2.6740e-01, time/batch = 15.9333s	
9636/16650 (epoch 28.937), train_loss = 0.78871474, grad/param norm = 3.1052e-01, time/batch = 14.6464s	
9637/16650 (epoch 28.940), train_loss = 0.82877034, grad/param norm = 2.4828e-01, time/batch = 14.2939s	
9638/16650 (epoch 28.943), train_loss = 0.87336987, grad/param norm = 3.0002e-01, time/batch = 17.3261s	
9639/16650 (epoch 28.946), train_loss = 0.77390923, grad/param norm = 2.5655e-01, time/batch = 16.6892s	
9640/16650 (epoch 28.949), train_loss = 0.76669172, grad/param norm = 3.0880e-01, time/batch = 15.8894s	
9641/16650 (epoch 28.952), train_loss = 0.72961341, grad/param norm = 2.6891e-01, time/batch = 17.2007s	
9642/16650 (epoch 28.955), train_loss = 0.83606809, grad/param norm = 2.5011e-01, time/batch = 18.2064s	
9643/16650 (epoch 28.958), train_loss = 0.90958864, grad/param norm = 3.3140e-01, time/batch = 16.1022s	
9644/16650 (epoch 28.961), train_loss = 0.85967343, grad/param norm = 2.7550e-01, time/batch = 15.8162s	
9645/16650 (epoch 28.964), train_loss = 0.77249837, grad/param norm = 2.7940e-01, time/batch = 16.6919s	
9646/16650 (epoch 28.967), train_loss = 0.99475500, grad/param norm = 2.9494e-01, time/batch = 16.9697s	
9647/16650 (epoch 28.970), train_loss = 0.79591590, grad/param norm = 2.5193e-01, time/batch = 15.7799s	
9648/16650 (epoch 28.973), train_loss = 0.82736356, grad/param norm = 2.9613e-01, time/batch = 17.7717s	
9649/16650 (epoch 28.976), train_loss = 0.78106580, grad/param norm = 2.5578e-01, time/batch = 16.5256s	
9650/16650 (epoch 28.979), train_loss = 0.88159475, grad/param norm = 2.8138e-01, time/batch = 15.9966s	
9651/16650 (epoch 28.982), train_loss = 0.91641570, grad/param norm = 2.7069e-01, time/batch = 17.6914s	
9652/16650 (epoch 28.985), train_loss = 0.83515745, grad/param norm = 2.7811e-01, time/batch = 17.8754s	
9653/16650 (epoch 28.988), train_loss = 0.92341257, grad/param norm = 3.0956e-01, time/batch = 17.7712s	
9654/16650 (epoch 28.991), train_loss = 0.76123993, grad/param norm = 2.7744e-01, time/batch = 16.0161s	
9655/16650 (epoch 28.994), train_loss = 0.79665900, grad/param norm = 2.7206e-01, time/batch = 18.1181s	
9656/16650 (epoch 28.997), train_loss = 0.83687464, grad/param norm = 2.7883e-01, time/batch = 16.7741s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
9657/16650 (epoch 29.000), train_loss = 0.89895247, grad/param norm = 2.8139e-01, time/batch = 17.1833s	
9658/16650 (epoch 29.003), train_loss = 0.95816840, grad/param norm = 3.0668e-01, time/batch = 18.2685s	
9659/16650 (epoch 29.006), train_loss = 0.94570838, grad/param norm = 3.1104e-01, time/batch = 18.9587s	
9660/16650 (epoch 29.009), train_loss = 0.99580102, grad/param norm = 2.7781e-01, time/batch = 17.6016s	
9661/16650 (epoch 29.012), train_loss = 0.98350247, grad/param norm = 2.9277e-01, time/batch = 16.4232s	
9662/16650 (epoch 29.015), train_loss = 0.84252983, grad/param norm = 2.9149e-01, time/batch = 18.0082s	
9663/16650 (epoch 29.018), train_loss = 0.72144578, grad/param norm = 2.6890e-01, time/batch = 15.6715s	
9664/16650 (epoch 29.021), train_loss = 0.97825497, grad/param norm = 2.9889e-01, time/batch = 16.0208s	
9665/16650 (epoch 29.024), train_loss = 0.84308808, grad/param norm = 2.9857e-01, time/batch = 17.0251s	
9666/16650 (epoch 29.027), train_loss = 0.91486904, grad/param norm = 2.8079e-01, time/batch = 15.7386s	
9667/16650 (epoch 29.030), train_loss = 0.75098357, grad/param norm = 2.5114e-01, time/batch = 18.1901s	
9668/16650 (epoch 29.033), train_loss = 0.86377141, grad/param norm = 2.6256e-01, time/batch = 16.9375s	
9669/16650 (epoch 29.036), train_loss = 0.62317858, grad/param norm = 2.7645e-01, time/batch = 17.9467s	
9670/16650 (epoch 29.039), train_loss = 0.95802440, grad/param norm = 2.6311e-01, time/batch = 16.9567s	
9671/16650 (epoch 29.042), train_loss = 0.92052291, grad/param norm = 3.1378e-01, time/batch = 15.6427s	
9672/16650 (epoch 29.045), train_loss = 0.84106081, grad/param norm = 2.7293e-01, time/batch = 16.8690s	
9673/16650 (epoch 29.048), train_loss = 0.93578550, grad/param norm = 2.8752e-01, time/batch = 18.5188s	
9674/16650 (epoch 29.051), train_loss = 0.81331385, grad/param norm = 2.4638e-01, time/batch = 17.3564s	
9675/16650 (epoch 29.054), train_loss = 0.86022165, grad/param norm = 3.0316e-01, time/batch = 16.9038s	
9676/16650 (epoch 29.057), train_loss = 0.88266454, grad/param norm = 3.0262e-01, time/batch = 18.1270s	
9677/16650 (epoch 29.060), train_loss = 0.72551598, grad/param norm = 2.5063e-01, time/batch = 17.7930s	
9678/16650 (epoch 29.063), train_loss = 0.81616006, grad/param norm = 2.5989e-01, time/batch = 16.8619s	
9679/16650 (epoch 29.066), train_loss = 1.00141416, grad/param norm = 2.8807e-01, time/batch = 18.3652s	
9680/16650 (epoch 29.069), train_loss = 0.91573989, grad/param norm = 2.7024e-01, time/batch = 14.9002s	
9681/16650 (epoch 29.072), train_loss = 0.86061862, grad/param norm = 2.9941e-01, time/batch = 17.9230s	
9682/16650 (epoch 29.075), train_loss = 0.92072515, grad/param norm = 2.6792e-01, time/batch = 16.4327s	
9683/16650 (epoch 29.078), train_loss = 0.95428040, grad/param norm = 3.0170e-01, time/batch = 18.9567s	
9684/16650 (epoch 29.081), train_loss = 0.91493574, grad/param norm = 4.0180e-01, time/batch = 17.8342s	
9685/16650 (epoch 29.084), train_loss = 0.91196241, grad/param norm = 2.7765e-01, time/batch = 16.4299s	
9686/16650 (epoch 29.087), train_loss = 0.88541792, grad/param norm = 2.7699e-01, time/batch = 18.3756s	
9687/16650 (epoch 29.090), train_loss = 0.85763106, grad/param norm = 3.2241e-01, time/batch = 16.0819s	
9688/16650 (epoch 29.093), train_loss = 1.02745970, grad/param norm = 3.2940e-01, time/batch = 17.4424s	
9689/16650 (epoch 29.096), train_loss = 0.82063999, grad/param norm = 2.7241e-01, time/batch = 17.3482s	
9690/16650 (epoch 29.099), train_loss = 0.89176122, grad/param norm = 2.7045e-01, time/batch = 17.7849s	
9691/16650 (epoch 29.102), train_loss = 0.85777778, grad/param norm = 2.5076e-01, time/batch = 17.6958s	
9692/16650 (epoch 29.105), train_loss = 0.89043442, grad/param norm = 2.9824e-01, time/batch = 15.4956s	
9693/16650 (epoch 29.108), train_loss = 0.88954511, grad/param norm = 2.8457e-01, time/batch = 18.0171s	
9694/16650 (epoch 29.111), train_loss = 0.95570061, grad/param norm = 2.5953e-01, time/batch = 16.7036s	
9695/16650 (epoch 29.114), train_loss = 0.94521417, grad/param norm = 3.3438e-01, time/batch = 17.2765s	
9696/16650 (epoch 29.117), train_loss = 1.04030937, grad/param norm = 2.8611e-01, time/batch = 16.4247s	
9697/16650 (epoch 29.120), train_loss = 0.83041653, grad/param norm = 2.3935e-01, time/batch = 18.0253s	
9698/16650 (epoch 29.123), train_loss = 0.86490903, grad/param norm = 2.8017e-01, time/batch = 17.5223s	
9699/16650 (epoch 29.126), train_loss = 0.90027939, grad/param norm = 2.5731e-01, time/batch = 17.0104s	
9700/16650 (epoch 29.129), train_loss = 0.89868618, grad/param norm = 2.8591e-01, time/batch = 17.5182s	
9701/16650 (epoch 29.132), train_loss = 0.86508975, grad/param norm = 2.5575e-01, time/batch = 14.5054s	
9702/16650 (epoch 29.135), train_loss = 0.95159889, grad/param norm = 2.5607e-01, time/batch = 16.7741s	
9703/16650 (epoch 29.138), train_loss = 0.95917381, grad/param norm = 2.7611e-01, time/batch = 16.3492s	
9704/16650 (epoch 29.141), train_loss = 0.90895306, grad/param norm = 2.9173e-01, time/batch = 17.6243s	
9705/16650 (epoch 29.144), train_loss = 0.90037506, grad/param norm = 2.7490e-01, time/batch = 17.5260s	
9706/16650 (epoch 29.147), train_loss = 1.00539194, grad/param norm = 3.0881e-01, time/batch = 15.1508s	
9707/16650 (epoch 29.150), train_loss = 1.10909522, grad/param norm = 3.5051e-01, time/batch = 16.7517s	
9708/16650 (epoch 29.153), train_loss = 0.91082969, grad/param norm = 2.9762e-01, time/batch = 17.4435s	
9709/16650 (epoch 29.156), train_loss = 0.80547679, grad/param norm = 2.2832e-01, time/batch = 17.6149s	
9710/16650 (epoch 29.159), train_loss = 0.94062301, grad/param norm = 3.3043e-01, time/batch = 15.5920s	
9711/16650 (epoch 29.162), train_loss = 0.99779817, grad/param norm = 2.6888e-01, time/batch = 17.1907s	
9712/16650 (epoch 29.165), train_loss = 1.00787405, grad/param norm = 3.0893e-01, time/batch = 17.1235s	
9713/16650 (epoch 29.168), train_loss = 0.75053255, grad/param norm = 2.4116e-01, time/batch = 16.6900s	
9714/16650 (epoch 29.171), train_loss = 0.95425577, grad/param norm = 2.7819e-01, time/batch = 17.1041s	
9715/16650 (epoch 29.174), train_loss = 0.73067963, grad/param norm = 2.6168e-01, time/batch = 14.8451s	
9716/16650 (epoch 29.177), train_loss = 0.88193280, grad/param norm = 3.1535e-01, time/batch = 17.7020s	
9717/16650 (epoch 29.180), train_loss = 0.97802532, grad/param norm = 3.0222e-01, time/batch = 15.7345s	
9718/16650 (epoch 29.183), train_loss = 1.09726053, grad/param norm = 2.9082e-01, time/batch = 17.8571s	
9719/16650 (epoch 29.186), train_loss = 0.94313604, grad/param norm = 2.8371e-01, time/batch = 16.4232s	
9720/16650 (epoch 29.189), train_loss = 0.82920203, grad/param norm = 2.6921e-01, time/batch = 17.1917s	
9721/16650 (epoch 29.192), train_loss = 0.84397162, grad/param norm = 2.8594e-01, time/batch = 16.6941s	
9722/16650 (epoch 29.195), train_loss = 0.81891879, grad/param norm = 2.8368e-01, time/batch = 17.3784s	
9723/16650 (epoch 29.198), train_loss = 0.74501134, grad/param norm = 2.2315e-01, time/batch = 17.3574s	
9724/16650 (epoch 29.201), train_loss = 0.79248706, grad/param norm = 2.6524e-01, time/batch = 16.6802s	
9725/16650 (epoch 29.204), train_loss = 0.89649022, grad/param norm = 2.9223e-01, time/batch = 17.4524s	
9726/16650 (epoch 29.207), train_loss = 0.91205023, grad/param norm = 3.4379e-01, time/batch = 17.0162s	
9727/16650 (epoch 29.210), train_loss = 0.86961328, grad/param norm = 2.8900e-01, time/batch = 16.2590s	
9728/16650 (epoch 29.213), train_loss = 0.94596261, grad/param norm = 2.7320e-01, time/batch = 15.5297s	
9729/16650 (epoch 29.216), train_loss = 0.83573626, grad/param norm = 2.7415e-01, time/batch = 15.6677s	
9730/16650 (epoch 29.219), train_loss = 0.86587056, grad/param norm = 2.7700e-01, time/batch = 16.6856s	
9731/16650 (epoch 29.222), train_loss = 0.91400837, grad/param norm = 2.7485e-01, time/batch = 14.5685s	
9732/16650 (epoch 29.225), train_loss = 0.89119105, grad/param norm = 2.9230e-01, time/batch = 16.5961s	
9733/16650 (epoch 29.228), train_loss = 0.80240966, grad/param norm = 2.7097e-01, time/batch = 15.2637s	
9734/16650 (epoch 29.231), train_loss = 0.82998928, grad/param norm = 2.7601e-01, time/batch = 17.6256s	
9735/16650 (epoch 29.234), train_loss = 1.06079346, grad/param norm = 2.8990e-01, time/batch = 15.7492s	
9736/16650 (epoch 29.237), train_loss = 0.89164466, grad/param norm = 2.7920e-01, time/batch = 17.8615s	
9737/16650 (epoch 29.240), train_loss = 0.90402912, grad/param norm = 2.6399e-01, time/batch = 18.1121s	
9738/16650 (epoch 29.243), train_loss = 0.86716496, grad/param norm = 2.8606e-01, time/batch = 16.1738s	
9739/16650 (epoch 29.246), train_loss = 0.97541956, grad/param norm = 3.1351e-01, time/batch = 17.0293s	
9740/16650 (epoch 29.249), train_loss = 0.74067015, grad/param norm = 2.3716e-01, time/batch = 18.0467s	
9741/16650 (epoch 29.252), train_loss = 0.83417968, grad/param norm = 2.4377e-01, time/batch = 16.4427s	
9742/16650 (epoch 29.255), train_loss = 0.91665317, grad/param norm = 2.6625e-01, time/batch = 15.1581s	
9743/16650 (epoch 29.258), train_loss = 0.96104063, grad/param norm = 2.6709e-01, time/batch = 16.3480s	
9744/16650 (epoch 29.261), train_loss = 0.91581004, grad/param norm = 2.7372e-01, time/batch = 17.1195s	
9745/16650 (epoch 29.264), train_loss = 0.81923353, grad/param norm = 2.4737e-01, time/batch = 17.2496s	
9746/16650 (epoch 29.267), train_loss = 0.84589721, grad/param norm = 2.8058e-01, time/batch = 31.0098s	
9747/16650 (epoch 29.270), train_loss = 0.91836534, grad/param norm = 2.8260e-01, time/batch = 17.0254s	
9748/16650 (epoch 29.273), train_loss = 0.98792358, grad/param norm = 2.8284e-01, time/batch = 15.6829s	
9749/16650 (epoch 29.276), train_loss = 0.91476206, grad/param norm = 2.9173e-01, time/batch = 16.8626s	
9750/16650 (epoch 29.279), train_loss = 0.88975554, grad/param norm = 2.9019e-01, time/batch = 17.0337s	
9751/16650 (epoch 29.282), train_loss = 0.79632364, grad/param norm = 2.5986e-01, time/batch = 14.8347s	
9752/16650 (epoch 29.285), train_loss = 0.79481639, grad/param norm = 2.6039e-01, time/batch = 15.8432s	
9753/16650 (epoch 29.288), train_loss = 0.80712714, grad/param norm = 2.6824e-01, time/batch = 17.1209s	
9754/16650 (epoch 29.291), train_loss = 0.66088076, grad/param norm = 2.1339e-01, time/batch = 17.3707s	
9755/16650 (epoch 29.294), train_loss = 0.75793753, grad/param norm = 2.2638e-01, time/batch = 15.2525s	
9756/16650 (epoch 29.297), train_loss = 0.86358458, grad/param norm = 2.4658e-01, time/batch = 16.5145s	
9757/16650 (epoch 29.300), train_loss = 0.68282419, grad/param norm = 2.3361e-01, time/batch = 17.3789s	
9758/16650 (epoch 29.303), train_loss = 0.75571308, grad/param norm = 2.3983e-01, time/batch = 16.6213s	
9759/16650 (epoch 29.306), train_loss = 0.94616015, grad/param norm = 2.6255e-01, time/batch = 14.5712s	
9760/16650 (epoch 29.309), train_loss = 0.94199281, grad/param norm = 3.2519e-01, time/batch = 16.5441s	
9761/16650 (epoch 29.312), train_loss = 0.76260968, grad/param norm = 3.0920e-01, time/batch = 17.6271s	
9762/16650 (epoch 29.315), train_loss = 0.63202409, grad/param norm = 2.1028e-01, time/batch = 17.6305s	
9763/16650 (epoch 29.318), train_loss = 0.72559610, grad/param norm = 2.4178e-01, time/batch = 16.7672s	
9764/16650 (epoch 29.321), train_loss = 0.97876370, grad/param norm = 3.3997e-01, time/batch = 17.8656s	
9765/16650 (epoch 29.324), train_loss = 0.81017554, grad/param norm = 3.1401e-01, time/batch = 15.2550s	
9766/16650 (epoch 29.327), train_loss = 0.90873113, grad/param norm = 2.8405e-01, time/batch = 16.0955s	
9767/16650 (epoch 29.330), train_loss = 0.90670004, grad/param norm = 3.1445e-01, time/batch = 17.4496s	
9768/16650 (epoch 29.333), train_loss = 0.93705381, grad/param norm = 3.1806e-01, time/batch = 16.9479s	
9769/16650 (epoch 29.336), train_loss = 0.78639955, grad/param norm = 2.7653e-01, time/batch = 17.1017s	
9770/16650 (epoch 29.339), train_loss = 0.81601299, grad/param norm = 2.7191e-01, time/batch = 15.0030s	
9771/16650 (epoch 29.342), train_loss = 0.78582833, grad/param norm = 2.9472e-01, time/batch = 17.7807s	
9772/16650 (epoch 29.345), train_loss = 0.74668938, grad/param norm = 2.2633e-01, time/batch = 17.3770s	
9773/16650 (epoch 29.348), train_loss = 0.87870119, grad/param norm = 3.4226e-01, time/batch = 15.6673s	
9774/16650 (epoch 29.351), train_loss = 0.89744916, grad/param norm = 2.8024e-01, time/batch = 17.6057s	
9775/16650 (epoch 29.354), train_loss = 0.93250361, grad/param norm = 2.9399e-01, time/batch = 17.3840s	
9776/16650 (epoch 29.357), train_loss = 0.88959311, grad/param norm = 2.8037e-01, time/batch = 17.1925s	
9777/16650 (epoch 29.360), train_loss = 0.87773545, grad/param norm = 3.0553e-01, time/batch = 15.4742s	
9778/16650 (epoch 29.363), train_loss = 0.96192858, grad/param norm = 3.1370e-01, time/batch = 17.7071s	
9779/16650 (epoch 29.366), train_loss = 1.01344566, grad/param norm = 3.1170e-01, time/batch = 15.5264s	
9780/16650 (epoch 29.369), train_loss = 0.88222406, grad/param norm = 2.9389e-01, time/batch = 13.4383s	
9781/16650 (epoch 29.372), train_loss = 0.88402768, grad/param norm = 2.7278e-01, time/batch = 13.9105s	
9782/16650 (epoch 29.375), train_loss = 0.89606969, grad/param norm = 2.7223e-01, time/batch = 15.2063s	
9783/16650 (epoch 29.378), train_loss = 0.80994665, grad/param norm = 2.5415e-01, time/batch = 17.3659s	
9784/16650 (epoch 29.381), train_loss = 0.88592137, grad/param norm = 2.6038e-01, time/batch = 16.6075s	
9785/16650 (epoch 29.384), train_loss = 1.00288618, grad/param norm = 2.8554e-01, time/batch = 17.0083s	
9786/16650 (epoch 29.387), train_loss = 0.68820350, grad/param norm = 2.1595e-01, time/batch = 16.7113s	
9787/16650 (epoch 29.390), train_loss = 0.93542911, grad/param norm = 2.6267e-01, time/batch = 16.4511s	
9788/16650 (epoch 29.393), train_loss = 0.81588764, grad/param norm = 2.6860e-01, time/batch = 16.2782s	
9789/16650 (epoch 29.396), train_loss = 0.97397812, grad/param norm = 3.0005e-01, time/batch = 14.4883s	
9790/16650 (epoch 29.399), train_loss = 0.90363074, grad/param norm = 2.5115e-01, time/batch = 17.3565s	
9791/16650 (epoch 29.402), train_loss = 0.80841671, grad/param norm = 2.7341e-01, time/batch = 17.1106s	
9792/16650 (epoch 29.405), train_loss = 0.69980313, grad/param norm = 2.7906e-01, time/batch = 16.0141s	
9793/16650 (epoch 29.408), train_loss = 0.90071737, grad/param norm = 2.8426e-01, time/batch = 17.2027s	
9794/16650 (epoch 29.411), train_loss = 0.75896366, grad/param norm = 2.8225e-01, time/batch = 16.8720s	
9795/16650 (epoch 29.414), train_loss = 0.77521059, grad/param norm = 2.6409e-01, time/batch = 16.0302s	
9796/16650 (epoch 29.417), train_loss = 0.75466311, grad/param norm = 2.7470e-01, time/batch = 16.9449s	
9797/16650 (epoch 29.420), train_loss = 0.75046062, grad/param norm = 2.5625e-01, time/batch = 16.8733s	
9798/16650 (epoch 29.423), train_loss = 0.64434046, grad/param norm = 2.3383e-01, time/batch = 15.8757s	
9799/16650 (epoch 29.426), train_loss = 0.75766735, grad/param norm = 2.9213e-01, time/batch = 15.6831s	
9800/16650 (epoch 29.429), train_loss = 0.96553336, grad/param norm = 3.1445e-01, time/batch = 17.6965s	
9801/16650 (epoch 29.432), train_loss = 0.95772286, grad/param norm = 3.2180e-01, time/batch = 15.6001s	
9802/16650 (epoch 29.435), train_loss = 1.04302040, grad/param norm = 2.7542e-01, time/batch = 16.3284s	
9803/16650 (epoch 29.438), train_loss = 1.05231842, grad/param norm = 3.5292e-01, time/batch = 15.3981s	
9804/16650 (epoch 29.441), train_loss = 0.85394720, grad/param norm = 3.7752e-01, time/batch = 17.7099s	
9805/16650 (epoch 29.444), train_loss = 0.84388231, grad/param norm = 3.1745e-01, time/batch = 14.9152s	
9806/16650 (epoch 29.447), train_loss = 0.81937608, grad/param norm = 3.1647e-01, time/batch = 16.0999s	
9807/16650 (epoch 29.450), train_loss = 0.82169717, grad/param norm = 2.8298e-01, time/batch = 17.3736s	
9808/16650 (epoch 29.453), train_loss = 0.79996903, grad/param norm = 2.6389e-01, time/batch = 17.2075s	
9809/16650 (epoch 29.456), train_loss = 0.75187900, grad/param norm = 2.3403e-01, time/batch = 16.7913s	
9810/16650 (epoch 29.459), train_loss = 0.79282499, grad/param norm = 2.6751e-01, time/batch = 15.7517s	
9811/16650 (epoch 29.462), train_loss = 0.97891987, grad/param norm = 3.0184e-01, time/batch = 17.5327s	
9812/16650 (epoch 29.465), train_loss = 0.80656835, grad/param norm = 2.9161e-01, time/batch = 16.8009s	
9813/16650 (epoch 29.468), train_loss = 0.67058557, grad/param norm = 2.7017e-01, time/batch = 15.6522s	
9814/16650 (epoch 29.471), train_loss = 0.56398464, grad/param norm = 2.0759e-01, time/batch = 16.0182s	
9815/16650 (epoch 29.474), train_loss = 0.73199016, grad/param norm = 2.6103e-01, time/batch = 17.9723s	
9816/16650 (epoch 29.477), train_loss = 0.92356267, grad/param norm = 2.9250e-01, time/batch = 15.1834s	
9817/16650 (epoch 29.480), train_loss = 0.90741567, grad/param norm = 3.4468e-01, time/batch = 14.4888s	
9818/16650 (epoch 29.483), train_loss = 0.94210615, grad/param norm = 2.9884e-01, time/batch = 16.6212s	
9819/16650 (epoch 29.486), train_loss = 0.75838323, grad/param norm = 2.2494e-01, time/batch = 16.1979s	
9820/16650 (epoch 29.489), train_loss = 0.80972012, grad/param norm = 2.7740e-01, time/batch = 18.1400s	
9821/16650 (epoch 29.492), train_loss = 0.84347295, grad/param norm = 2.6050e-01, time/batch = 15.7591s	
9822/16650 (epoch 29.495), train_loss = 0.75106053, grad/param norm = 2.7900e-01, time/batch = 17.4545s	
9823/16650 (epoch 29.498), train_loss = 0.81309682, grad/param norm = 3.0178e-01, time/batch = 17.7850s	
9824/16650 (epoch 29.502), train_loss = 0.99674432, grad/param norm = 3.3754e-01, time/batch = 16.8696s	
9825/16650 (epoch 29.505), train_loss = 0.89057443, grad/param norm = 2.5605e-01, time/batch = 16.1051s	
9826/16650 (epoch 29.508), train_loss = 0.89402061, grad/param norm = 2.9588e-01, time/batch = 17.2905s	
9827/16650 (epoch 29.511), train_loss = 0.95228745, grad/param norm = 2.9229e-01, time/batch = 17.1172s	
9828/16650 (epoch 29.514), train_loss = 0.73305074, grad/param norm = 2.7539e-01, time/batch = 14.9348s	
9829/16650 (epoch 29.517), train_loss = 0.83338349, grad/param norm = 2.9492e-01, time/batch = 17.2918s	
9830/16650 (epoch 29.520), train_loss = 0.74108557, grad/param norm = 2.6254e-01, time/batch = 16.2471s	
9831/16650 (epoch 29.523), train_loss = 0.83667433, grad/param norm = 2.7070e-01, time/batch = 16.8700s	
9832/16650 (epoch 29.526), train_loss = 0.93728082, grad/param norm = 3.0333e-01, time/batch = 17.1161s	
9833/16650 (epoch 29.529), train_loss = 0.98111232, grad/param norm = 3.2908e-01, time/batch = 17.2150s	
9834/16650 (epoch 29.532), train_loss = 0.66070407, grad/param norm = 2.6677e-01, time/batch = 16.9466s	
9835/16650 (epoch 29.535), train_loss = 0.74964597, grad/param norm = 3.1593e-01, time/batch = 15.0742s	
9836/16650 (epoch 29.538), train_loss = 0.70952488, grad/param norm = 2.5710e-01, time/batch = 17.4474s	
9837/16650 (epoch 29.541), train_loss = 0.99229615, grad/param norm = 3.4433e-01, time/batch = 17.3874s	
9838/16650 (epoch 29.544), train_loss = 1.03635354, grad/param norm = 4.5094e-01, time/batch = 16.9503s	
9839/16650 (epoch 29.547), train_loss = 0.74597523, grad/param norm = 2.9035e-01, time/batch = 15.1603s	
9840/16650 (epoch 29.550), train_loss = 0.84410723, grad/param norm = 2.6663e-01, time/batch = 13.2697s	
9841/16650 (epoch 29.553), train_loss = 0.85414808, grad/param norm = 3.0040e-01, time/batch = 14.0038s	
9842/16650 (epoch 29.556), train_loss = 0.76945904, grad/param norm = 2.4902e-01, time/batch = 14.7290s	
9843/16650 (epoch 29.559), train_loss = 0.68325928, grad/param norm = 2.6403e-01, time/batch = 16.1650s	
9844/16650 (epoch 29.562), train_loss = 0.79801481, grad/param norm = 2.9397e-01, time/batch = 17.8698s	
9845/16650 (epoch 29.565), train_loss = 0.67936723, grad/param norm = 2.7125e-01, time/batch = 17.3715s	
9846/16650 (epoch 29.568), train_loss = 0.67815895, grad/param norm = 2.4850e-01, time/batch = 16.1758s	
9847/16650 (epoch 29.571), train_loss = 0.71786055, grad/param norm = 2.7271e-01, time/batch = 16.5190s	
9848/16650 (epoch 29.574), train_loss = 0.80073261, grad/param norm = 2.9214e-01, time/batch = 15.5913s	
9849/16650 (epoch 29.577), train_loss = 0.78532013, grad/param norm = 2.5307e-01, time/batch = 16.3790s	
9850/16650 (epoch 29.580), train_loss = 0.70083373, grad/param norm = 2.4306e-01, time/batch = 15.6801s	
9851/16650 (epoch 29.583), train_loss = 0.81872702, grad/param norm = 2.5993e-01, time/batch = 18.4697s	
9852/16650 (epoch 29.586), train_loss = 0.74370266, grad/param norm = 2.9728e-01, time/batch = 16.7808s	
9853/16650 (epoch 29.589), train_loss = 0.72154674, grad/param norm = 2.3184e-01, time/batch = 16.7485s	
9854/16650 (epoch 29.592), train_loss = 0.83325607, grad/param norm = 2.7780e-01, time/batch = 16.6907s	
9855/16650 (epoch 29.595), train_loss = 0.76652104, grad/param norm = 2.8203e-01, time/batch = 17.5200s	
9856/16650 (epoch 29.598), train_loss = 0.81931804, grad/param norm = 2.8751e-01, time/batch = 16.6675s	
9857/16650 (epoch 29.601), train_loss = 0.77979029, grad/param norm = 3.2754e-01, time/batch = 15.5238s	
9858/16650 (epoch 29.604), train_loss = 0.89343232, grad/param norm = 3.3654e-01, time/batch = 16.8798s	
9859/16650 (epoch 29.607), train_loss = 0.89741099, grad/param norm = 2.7854e-01, time/batch = 17.0498s	
9860/16650 (epoch 29.610), train_loss = 0.76088485, grad/param norm = 2.8474e-01, time/batch = 15.6847s	
9861/16650 (epoch 29.613), train_loss = 0.97630660, grad/param norm = 3.5389e-01, time/batch = 16.0272s	
9862/16650 (epoch 29.616), train_loss = 0.93579479, grad/param norm = 3.5581e-01, time/batch = 16.6982s	
9863/16650 (epoch 29.619), train_loss = 0.70715108, grad/param norm = 2.9790e-01, time/batch = 17.7174s	
9864/16650 (epoch 29.622), train_loss = 0.66993424, grad/param norm = 2.8060e-01, time/batch = 15.4330s	
9865/16650 (epoch 29.625), train_loss = 0.81164748, grad/param norm = 2.8804e-01, time/batch = 14.2637s	
9866/16650 (epoch 29.628), train_loss = 0.77540224, grad/param norm = 3.4517e-01, time/batch = 17.1263s	
9867/16650 (epoch 29.631), train_loss = 0.83309977, grad/param norm = 3.2761e-01, time/batch = 16.9383s	
9868/16650 (epoch 29.634), train_loss = 1.01263651, grad/param norm = 3.3905e-01, time/batch = 16.1075s	
9869/16650 (epoch 29.637), train_loss = 1.01059027, grad/param norm = 2.5942e-01, time/batch = 17.4450s	
9870/16650 (epoch 29.640), train_loss = 0.80138910, grad/param norm = 3.2727e-01, time/batch = 16.6246s	
9871/16650 (epoch 29.643), train_loss = 0.90243626, grad/param norm = 2.6400e-01, time/batch = 17.0822s	
9872/16650 (epoch 29.646), train_loss = 0.89071346, grad/param norm = 3.6396e-01, time/batch = 16.2246s	
9873/16650 (epoch 29.649), train_loss = 0.88081366, grad/param norm = 3.4770e-01, time/batch = 17.8853s	
9874/16650 (epoch 29.652), train_loss = 0.91996035, grad/param norm = 3.2733e-01, time/batch = 16.8695s	
9875/16650 (epoch 29.655), train_loss = 0.87838671, grad/param norm = 3.2860e-01, time/batch = 16.3499s	
9876/16650 (epoch 29.658), train_loss = 0.75753762, grad/param norm = 3.0187e-01, time/batch = 16.4345s	
9877/16650 (epoch 29.661), train_loss = 0.86647735, grad/param norm = 2.9204e-01, time/batch = 17.7000s	
9878/16650 (epoch 29.664), train_loss = 0.86117934, grad/param norm = 3.0766e-01, time/batch = 16.9387s	
9879/16650 (epoch 29.667), train_loss = 0.94601629, grad/param norm = 2.6506e-01, time/batch = 14.7698s	
9880/16650 (epoch 29.670), train_loss = 0.70231995, grad/param norm = 2.3890e-01, time/batch = 18.1136s	
9881/16650 (epoch 29.673), train_loss = 0.76862347, grad/param norm = 2.8775e-01, time/batch = 17.6251s	
9882/16650 (epoch 29.676), train_loss = 0.88357999, grad/param norm = 2.9062e-01, time/batch = 15.0710s	
9883/16650 (epoch 29.679), train_loss = 0.75608379, grad/param norm = 2.7093e-01, time/batch = 15.9379s	
9884/16650 (epoch 29.682), train_loss = 0.84045933, grad/param norm = 2.9681e-01, time/batch = 16.6259s	
9885/16650 (epoch 29.685), train_loss = 0.71883377, grad/param norm = 2.7628e-01, time/batch = 17.2076s	
9886/16650 (epoch 29.688), train_loss = 0.90827402, grad/param norm = 2.9465e-01, time/batch = 16.4300s	
9887/16650 (epoch 29.691), train_loss = 0.89231669, grad/param norm = 2.7756e-01, time/batch = 17.7885s	
9888/16650 (epoch 29.694), train_loss = 0.75931179, grad/param norm = 2.5995e-01, time/batch = 16.8529s	
9889/16650 (epoch 29.697), train_loss = 0.70995225, grad/param norm = 2.2581e-01, time/batch = 16.3460s	
9890/16650 (epoch 29.700), train_loss = 0.88746139, grad/param norm = 3.0603e-01, time/batch = 15.2625s	
9891/16650 (epoch 29.703), train_loss = 0.74947554, grad/param norm = 2.8801e-01, time/batch = 17.3657s	
9892/16650 (epoch 29.706), train_loss = 0.82649434, grad/param norm = 3.0205e-01, time/batch = 17.7124s	
9893/16650 (epoch 29.709), train_loss = 0.72642289, grad/param norm = 2.6289e-01, time/batch = 14.0665s	
9894/16650 (epoch 29.712), train_loss = 0.75607206, grad/param norm = 2.8568e-01, time/batch = 17.0993s	
9895/16650 (epoch 29.715), train_loss = 0.89137695, grad/param norm = 2.7948e-01, time/batch = 18.0447s	
9896/16650 (epoch 29.718), train_loss = 0.91004762, grad/param norm = 2.8165e-01, time/batch = 16.6865s	
9897/16650 (epoch 29.721), train_loss = 0.89645154, grad/param norm = 2.8032e-01, time/batch = 15.8709s	
9898/16650 (epoch 29.724), train_loss = 0.91152624, grad/param norm = 2.8676e-01, time/batch = 17.4527s	
9899/16650 (epoch 29.727), train_loss = 0.92344721, grad/param norm = 2.9579e-01, time/batch = 17.4563s	
9900/16650 (epoch 29.730), train_loss = 0.76433171, grad/param norm = 2.6309e-01, time/batch = 15.3973s	
9901/16650 (epoch 29.733), train_loss = 0.92043589, grad/param norm = 2.7565e-01, time/batch = 17.2053s	
9902/16650 (epoch 29.736), train_loss = 0.70101652, grad/param norm = 2.3814e-01, time/batch = 17.8689s	
9903/16650 (epoch 29.739), train_loss = 0.83869884, grad/param norm = 2.5584e-01, time/batch = 15.3671s	
9904/16650 (epoch 29.742), train_loss = 0.81545695, grad/param norm = 2.5218e-01, time/batch = 17.3459s	
9905/16650 (epoch 29.745), train_loss = 0.64377639, grad/param norm = 2.4228e-01, time/batch = 15.9508s	
9906/16650 (epoch 29.748), train_loss = 0.73080292, grad/param norm = 2.8710e-01, time/batch = 17.2005s	
9907/16650 (epoch 29.751), train_loss = 0.83012275, grad/param norm = 3.3885e-01, time/batch = 16.6715s	
9908/16650 (epoch 29.754), train_loss = 1.03101880, grad/param norm = 3.5413e-01, time/batch = 16.7747s	
9909/16650 (epoch 29.757), train_loss = 0.97796863, grad/param norm = 3.0425e-01, time/batch = 16.4518s	
9910/16650 (epoch 29.760), train_loss = 0.83504687, grad/param norm = 2.8419e-01, time/batch = 17.9413s	
9911/16650 (epoch 29.763), train_loss = 0.77560273, grad/param norm = 2.5361e-01, time/batch = 17.0210s	
9912/16650 (epoch 29.766), train_loss = 0.80928949, grad/param norm = 2.7525e-01, time/batch = 16.6038s	
9913/16650 (epoch 29.769), train_loss = 0.85238050, grad/param norm = 2.4890e-01, time/batch = 17.5442s	
9914/16650 (epoch 29.772), train_loss = 0.81893208, grad/param norm = 2.4283e-01, time/batch = 17.2740s	
9915/16650 (epoch 29.775), train_loss = 0.81419955, grad/param norm = 2.6929e-01, time/batch = 16.7779s	
9916/16650 (epoch 29.778), train_loss = 0.83768647, grad/param norm = 2.4900e-01, time/batch = 16.1782s	
9917/16650 (epoch 29.781), train_loss = 0.97326782, grad/param norm = 2.5366e-01, time/batch = 15.6325s	
9918/16650 (epoch 29.784), train_loss = 0.86338240, grad/param norm = 2.6158e-01, time/batch = 15.6814s	
9919/16650 (epoch 29.787), train_loss = 0.89130267, grad/param norm = 2.6513e-01, time/batch = 17.7786s	
9920/16650 (epoch 29.790), train_loss = 0.90464190, grad/param norm = 2.5198e-01, time/batch = 15.2455s	
9921/16650 (epoch 29.793), train_loss = 0.73942974, grad/param norm = 2.6002e-01, time/batch = 15.6750s	
9922/16650 (epoch 29.796), train_loss = 1.09519926, grad/param norm = 3.1348e-01, time/batch = 16.1807s	
9923/16650 (epoch 29.799), train_loss = 1.02031025, grad/param norm = 3.0774e-01, time/batch = 16.5176s	
9924/16650 (epoch 29.802), train_loss = 0.92151184, grad/param norm = 3.0278e-01, time/batch = 17.2727s	
9925/16650 (epoch 29.805), train_loss = 0.84068920, grad/param norm = 2.3711e-01, time/batch = 15.4294s	
9926/16650 (epoch 29.808), train_loss = 0.91873179, grad/param norm = 2.7270e-01, time/batch = 17.1183s	
9927/16650 (epoch 29.811), train_loss = 0.96150035, grad/param norm = 2.6463e-01, time/batch = 17.4448s	
9928/16650 (epoch 29.814), train_loss = 0.75880496, grad/param norm = 2.4254e-01, time/batch = 17.2833s	
9929/16650 (epoch 29.817), train_loss = 0.79966859, grad/param norm = 2.6797e-01, time/batch = 16.5989s	
9930/16650 (epoch 29.820), train_loss = 0.89024115, grad/param norm = 2.9035e-01, time/batch = 17.1898s	
9931/16650 (epoch 29.823), train_loss = 0.83197239, grad/param norm = 2.7384e-01, time/batch = 14.8184s	
9932/16650 (epoch 29.826), train_loss = 0.79509610, grad/param norm = 2.4577e-01, time/batch = 16.5862s	
9933/16650 (epoch 29.829), train_loss = 0.85272807, grad/param norm = 2.6707e-01, time/batch = 16.0298s	
9934/16650 (epoch 29.832), train_loss = 0.91819367, grad/param norm = 2.6130e-01, time/batch = 17.8739s	
9935/16650 (epoch 29.835), train_loss = 0.91331896, grad/param norm = 3.3541e-01, time/batch = 17.5455s	
9936/16650 (epoch 29.838), train_loss = 0.77688381, grad/param norm = 2.5335e-01, time/batch = 16.1765s	
9937/16650 (epoch 29.841), train_loss = 0.78736805, grad/param norm = 2.5794e-01, time/batch = 16.0913s	
9938/16650 (epoch 29.844), train_loss = 0.76971865, grad/param norm = 2.3484e-01, time/batch = 14.3933s	
9939/16650 (epoch 29.847), train_loss = 0.92213818, grad/param norm = 2.8176e-01, time/batch = 17.1981s	
9940/16650 (epoch 29.850), train_loss = 0.74670025, grad/param norm = 3.1831e-01, time/batch = 17.3439s	
9941/16650 (epoch 29.853), train_loss = 0.83544499, grad/param norm = 2.6174e-01, time/batch = 16.1020s	
9942/16650 (epoch 29.856), train_loss = 0.77532004, grad/param norm = 2.7453e-01, time/batch = 17.4542s	
9943/16650 (epoch 29.859), train_loss = 0.95004363, grad/param norm = 2.9366e-01, time/batch = 15.7369s	
9944/16650 (epoch 29.862), train_loss = 0.82331540, grad/param norm = 2.4911e-01, time/batch = 16.9503s	
9945/16650 (epoch 29.865), train_loss = 0.67482554, grad/param norm = 2.2496e-01, time/batch = 14.8226s	
9946/16650 (epoch 29.868), train_loss = 0.87425011, grad/param norm = 2.6785e-01, time/batch = 17.9479s	
9947/16650 (epoch 29.871), train_loss = 0.89048612, grad/param norm = 2.8261e-01, time/batch = 15.9267s	
9948/16650 (epoch 29.874), train_loss = 0.89215053, grad/param norm = 2.7578e-01, time/batch = 16.8149s	
9949/16650 (epoch 29.877), train_loss = 0.85430764, grad/param norm = 2.5668e-01, time/batch = 17.2651s	
9950/16650 (epoch 29.880), train_loss = 0.74024087, grad/param norm = 2.6210e-01, time/batch = 16.5237s	
9951/16650 (epoch 29.883), train_loss = 0.86359687, grad/param norm = 2.7655e-01, time/batch = 18.4548s	
9952/16650 (epoch 29.886), train_loss = 0.85719984, grad/param norm = 2.4838e-01, time/batch = 16.0056s	
9953/16650 (epoch 29.889), train_loss = 0.69714677, grad/param norm = 2.6402e-01, time/batch = 13.7368s	
9954/16650 (epoch 29.892), train_loss = 0.84721959, grad/param norm = 2.7136e-01, time/batch = 15.2631s	
9955/16650 (epoch 29.895), train_loss = 0.85843839, grad/param norm = 2.6815e-01, time/batch = 17.4564s	
9956/16650 (epoch 29.898), train_loss = 0.84404685, grad/param norm = 2.9851e-01, time/batch = 15.3474s	
9957/16650 (epoch 29.901), train_loss = 0.82242791, grad/param norm = 2.8798e-01, time/batch = 17.0302s	
9958/16650 (epoch 29.904), train_loss = 0.78469716, grad/param norm = 2.8132e-01, time/batch = 16.3585s	
9959/16650 (epoch 29.907), train_loss = 0.86384315, grad/param norm = 2.6888e-01, time/batch = 17.9573s	
9960/16650 (epoch 29.910), train_loss = 0.89394217, grad/param norm = 2.9282e-01, time/batch = 16.3610s	
9961/16650 (epoch 29.913), train_loss = 0.80116277, grad/param norm = 2.7658e-01, time/batch = 21.8723s	
9962/16650 (epoch 29.916), train_loss = 0.80286576, grad/param norm = 2.9857e-01, time/batch = 26.9822s	
9963/16650 (epoch 29.919), train_loss = 0.98938355, grad/param norm = 2.7305e-01, time/batch = 16.1892s	
9964/16650 (epoch 29.922), train_loss = 0.89651458, grad/param norm = 2.9821e-01, time/batch = 13.9220s	
9965/16650 (epoch 29.925), train_loss = 0.77244812, grad/param norm = 2.6149e-01, time/batch = 17.5477s	
9966/16650 (epoch 29.928), train_loss = 0.82184773, grad/param norm = 2.5145e-01, time/batch = 17.1255s	
9967/16650 (epoch 29.931), train_loss = 0.88977697, grad/param norm = 2.8266e-01, time/batch = 16.2828s	
9968/16650 (epoch 29.934), train_loss = 0.73249027, grad/param norm = 2.9419e-01, time/batch = 15.3993s	
9969/16650 (epoch 29.937), train_loss = 0.77140113, grad/param norm = 2.9940e-01, time/batch = 17.0199s	
9970/16650 (epoch 29.940), train_loss = 0.81966306, grad/param norm = 2.5357e-01, time/batch = 14.5250s	
9971/16650 (epoch 29.943), train_loss = 0.85886991, grad/param norm = 2.9409e-01, time/batch = 16.0840s	
9972/16650 (epoch 29.946), train_loss = 0.76400671, grad/param norm = 2.4532e-01, time/batch = 16.1948s	
9973/16650 (epoch 29.949), train_loss = 0.74385896, grad/param norm = 3.3893e-01, time/batch = 17.7839s	
9974/16650 (epoch 29.952), train_loss = 0.72350181, grad/param norm = 2.8140e-01, time/batch = 15.9199s	
9975/16650 (epoch 29.955), train_loss = 0.83221189, grad/param norm = 2.5351e-01, time/batch = 16.0126s	
9976/16650 (epoch 29.958), train_loss = 0.89316959, grad/param norm = 3.5099e-01, time/batch = 17.5335s	
9977/16650 (epoch 29.961), train_loss = 0.82788680, grad/param norm = 2.4427e-01, time/batch = 17.1161s	
9978/16650 (epoch 29.964), train_loss = 0.75602383, grad/param norm = 2.9653e-01, time/batch = 16.9513s	
9979/16650 (epoch 29.967), train_loss = 0.97367040, grad/param norm = 3.1161e-01, time/batch = 16.7813s	
9980/16650 (epoch 29.970), train_loss = 0.78025069, grad/param norm = 2.4549e-01, time/batch = 17.5286s	
9981/16650 (epoch 29.973), train_loss = 0.80665936, grad/param norm = 3.0021e-01, time/batch = 17.5390s	
9982/16650 (epoch 29.976), train_loss = 0.76378095, grad/param norm = 2.5083e-01, time/batch = 15.4361s	
9983/16650 (epoch 29.979), train_loss = 0.85899831, grad/param norm = 2.7580e-01, time/batch = 15.0033s	
9984/16650 (epoch 29.982), train_loss = 0.89483299, grad/param norm = 2.8778e-01, time/batch = 17.7737s	
9985/16650 (epoch 29.985), train_loss = 0.80499643, grad/param norm = 2.6633e-01, time/batch = 17.8677s	
9986/16650 (epoch 29.988), train_loss = 0.90606572, grad/param norm = 3.1031e-01, time/batch = 14.6431s	
9987/16650 (epoch 29.991), train_loss = 0.76183293, grad/param norm = 2.8010e-01, time/batch = 16.6206s	
9988/16650 (epoch 29.994), train_loss = 0.77847129, grad/param norm = 2.7058e-01, time/batch = 17.2796s	
9989/16650 (epoch 29.997), train_loss = 0.83580000, grad/param norm = 3.1927e-01, time/batch = 16.0187s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
9990/16650 (epoch 30.000), train_loss = 0.90104901, grad/param norm = 3.0553e-01, time/batch = 17.7072s	
9991/16650 (epoch 30.003), train_loss = 0.92873033, grad/param norm = 3.0078e-01, time/batch = 16.4449s	
9992/16650 (epoch 30.006), train_loss = 0.90831042, grad/param norm = 3.0377e-01, time/batch = 15.7668s	
9993/16650 (epoch 30.009), train_loss = 0.97926233, grad/param norm = 2.7188e-01, time/batch = 15.3522s	
9994/16650 (epoch 30.012), train_loss = 0.97761788, grad/param norm = 3.0798e-01, time/batch = 17.6215s	
9995/16650 (epoch 30.015), train_loss = 0.84350887, grad/param norm = 3.0466e-01, time/batch = 15.0196s	
9996/16650 (epoch 30.018), train_loss = 0.72372276, grad/param norm = 2.7759e-01, time/batch = 16.5265s	
9997/16650 (epoch 30.021), train_loss = 0.95538404, grad/param norm = 3.2734e-01, time/batch = 15.1502s	
9998/16650 (epoch 30.024), train_loss = 0.81600809, grad/param norm = 2.6074e-01, time/batch = 17.9420s	
9999/16650 (epoch 30.027), train_loss = 0.91356507, grad/param norm = 3.1273e-01, time/batch = 16.1092s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch30.03_2.0765.t7	
10000/16650 (epoch 30.030), train_loss = 0.74647066, grad/param norm = 2.6783e-01, time/batch = 15.9347s	
10001/16650 (epoch 30.033), train_loss = 1.25538863, grad/param norm = 3.5899e-01, time/batch = 18.3792s	
10002/16650 (epoch 30.036), train_loss = 0.62229366, grad/param norm = 2.9370e-01, time/batch = 17.3754s	
10003/16650 (epoch 30.039), train_loss = 0.95088143, grad/param norm = 2.8225e-01, time/batch = 15.7715s	
10004/16650 (epoch 30.042), train_loss = 0.89977387, grad/param norm = 3.3930e-01, time/batch = 15.0821s	
10005/16650 (epoch 30.045), train_loss = 0.81638061, grad/param norm = 2.6888e-01, time/batch = 17.4300s	
10006/16650 (epoch 30.048), train_loss = 0.92297606, grad/param norm = 2.9947e-01, time/batch = 15.6944s	
10007/16650 (epoch 30.051), train_loss = 0.81201121, grad/param norm = 2.6771e-01, time/batch = 15.5986s	
10008/16650 (epoch 30.054), train_loss = 0.83698599, grad/param norm = 2.7995e-01, time/batch = 17.0377s	
10009/16650 (epoch 30.057), train_loss = 0.86719049, grad/param norm = 3.0569e-01, time/batch = 17.7032s	
10010/16650 (epoch 30.060), train_loss = 0.72091592, grad/param norm = 2.5765e-01, time/batch = 16.8633s	
10011/16650 (epoch 30.063), train_loss = 0.81695715, grad/param norm = 2.6407e-01, time/batch = 6.0985s	
10012/16650 (epoch 30.066), train_loss = 0.98210062, grad/param norm = 2.8343e-01, time/batch = 0.6335s	
10013/16650 (epoch 30.069), train_loss = 0.91287358, grad/param norm = 3.0991e-01, time/batch = 0.6422s	
10014/16650 (epoch 30.072), train_loss = 0.83764362, grad/param norm = 3.1311e-01, time/batch = 0.6221s	
10015/16650 (epoch 30.075), train_loss = 0.93685793, grad/param norm = 2.9302e-01, time/batch = 0.6180s	
10016/16650 (epoch 30.078), train_loss = 0.95032082, grad/param norm = 3.2295e-01, time/batch = 0.6181s	
10017/16650 (epoch 30.081), train_loss = 0.89253780, grad/param norm = 3.3861e-01, time/batch = 0.6174s	
10018/16650 (epoch 30.084), train_loss = 0.91440088, grad/param norm = 3.1313e-01, time/batch = 0.6172s	
10019/16650 (epoch 30.087), train_loss = 0.87090194, grad/param norm = 2.9770e-01, time/batch = 0.7875s	
10020/16650 (epoch 30.090), train_loss = 0.84265166, grad/param norm = 2.9803e-01, time/batch = 0.9138s	
10021/16650 (epoch 30.093), train_loss = 1.00042483, grad/param norm = 3.2163e-01, time/batch = 0.9200s	
10022/16650 (epoch 30.096), train_loss = 0.80986845, grad/param norm = 2.8472e-01, time/batch = 0.9175s	
10023/16650 (epoch 30.099), train_loss = 0.87670241, grad/param norm = 3.2061e-01, time/batch = 0.9127s	
10024/16650 (epoch 30.102), train_loss = 0.84760753, grad/param norm = 2.6508e-01, time/batch = 1.0525s	
10025/16650 (epoch 30.105), train_loss = 0.88201164, grad/param norm = 2.9844e-01, time/batch = 1.6941s	
10026/16650 (epoch 30.108), train_loss = 0.87237191, grad/param norm = 2.9427e-01, time/batch = 1.6985s	
10027/16650 (epoch 30.111), train_loss = 0.95120437, grad/param norm = 2.7996e-01, time/batch = 5.7631s	
10028/16650 (epoch 30.114), train_loss = 0.94165874, grad/param norm = 3.5351e-01, time/batch = 18.0497s	
10029/16650 (epoch 30.117), train_loss = 1.02628120, grad/param norm = 3.3153e-01, time/batch = 16.5919s	
10030/16650 (epoch 30.120), train_loss = 0.82844247, grad/param norm = 2.5768e-01, time/batch = 16.5976s	
10031/16650 (epoch 30.123), train_loss = 0.85925431, grad/param norm = 2.7940e-01, time/batch = 15.3349s	
10032/16650 (epoch 30.126), train_loss = 0.87421236, grad/param norm = 2.4900e-01, time/batch = 17.1998s	
10033/16650 (epoch 30.129), train_loss = 0.89162860, grad/param norm = 2.7275e-01, time/batch = 15.7233s	
10034/16650 (epoch 30.132), train_loss = 0.84639164, grad/param norm = 2.6092e-01, time/batch = 15.1763s	
10035/16650 (epoch 30.135), train_loss = 0.93439146, grad/param norm = 2.6165e-01, time/batch = 16.6375s	
10036/16650 (epoch 30.138), train_loss = 0.93043101, grad/param norm = 2.6095e-01, time/batch = 17.4387s	
10037/16650 (epoch 30.141), train_loss = 0.90965826, grad/param norm = 3.3075e-01, time/batch = 16.3339s	
10038/16650 (epoch 30.144), train_loss = 0.89039537, grad/param norm = 2.8471e-01, time/batch = 17.7064s	
10039/16650 (epoch 30.147), train_loss = 0.97908712, grad/param norm = 2.6420e-01, time/batch = 17.4561s	
10040/16650 (epoch 30.150), train_loss = 1.11006521, grad/param norm = 6.0657e-01, time/batch = 14.8997s	
10041/16650 (epoch 30.153), train_loss = 0.92659315, grad/param norm = 4.0027e-01, time/batch = 17.6116s	
10042/16650 (epoch 30.156), train_loss = 0.84478655, grad/param norm = 2.6537e-01, time/batch = 17.4458s	
10043/16650 (epoch 30.159), train_loss = 0.92433460, grad/param norm = 2.7724e-01, time/batch = 17.2029s	
10044/16650 (epoch 30.162), train_loss = 0.99354212, grad/param norm = 2.6783e-01, time/batch = 16.4283s	
10045/16650 (epoch 30.165), train_loss = 0.99722856, grad/param norm = 3.1679e-01, time/batch = 18.3008s	
10046/16650 (epoch 30.168), train_loss = 0.74639900, grad/param norm = 2.5956e-01, time/batch = 15.9439s	
10047/16650 (epoch 30.171), train_loss = 0.93669816, grad/param norm = 2.7724e-01, time/batch = 15.9394s	
10048/16650 (epoch 30.174), train_loss = 0.72766452, grad/param norm = 2.6931e-01, time/batch = 17.1951s	
10049/16650 (epoch 30.177), train_loss = 0.87809500, grad/param norm = 2.9186e-01, time/batch = 17.0343s	
10050/16650 (epoch 30.180), train_loss = 0.96069741, grad/param norm = 2.9874e-01, time/batch = 17.3679s	
10051/16650 (epoch 30.183), train_loss = 1.10619398, grad/param norm = 3.2956e-01, time/batch = 16.9398s	
10052/16650 (epoch 30.186), train_loss = 0.92744224, grad/param norm = 2.9912e-01, time/batch = 17.1041s	
10053/16650 (epoch 30.189), train_loss = 0.81329148, grad/param norm = 2.5860e-01, time/batch = 15.8994s	
10054/16650 (epoch 30.192), train_loss = 0.84044246, grad/param norm = 2.9369e-01, time/batch = 15.0900s	
10055/16650 (epoch 30.195), train_loss = 0.80379839, grad/param norm = 2.9720e-01, time/batch = 17.0293s	
10056/16650 (epoch 30.198), train_loss = 0.75891391, grad/param norm = 2.6314e-01, time/batch = 15.5172s	
10057/16650 (epoch 30.201), train_loss = 0.77227964, grad/param norm = 2.6116e-01, time/batch = 15.9192s	
10058/16650 (epoch 30.204), train_loss = 0.87793812, grad/param norm = 2.7027e-01, time/batch = 15.9877s	
10059/16650 (epoch 30.207), train_loss = 0.90454445, grad/param norm = 3.2892e-01, time/batch = 17.1220s	
10060/16650 (epoch 30.210), train_loss = 0.84416673, grad/param norm = 2.6845e-01, time/batch = 16.7125s	
10061/16650 (epoch 30.213), train_loss = 0.93348013, grad/param norm = 3.0474e-01, time/batch = 17.6233s	
10062/16650 (epoch 30.216), train_loss = 0.82789741, grad/param norm = 3.1895e-01, time/batch = 16.1553s	
10063/16650 (epoch 30.219), train_loss = 0.85145912, grad/param norm = 2.7133e-01, time/batch = 16.4329s	
10064/16650 (epoch 30.222), train_loss = 0.89840493, grad/param norm = 2.7659e-01, time/batch = 17.2865s	
10065/16650 (epoch 30.225), train_loss = 0.87010436, grad/param norm = 2.8282e-01, time/batch = 17.0073s	
10066/16650 (epoch 30.228), train_loss = 0.77936303, grad/param norm = 2.5495e-01, time/batch = 15.2380s	
10067/16650 (epoch 30.231), train_loss = 0.82900354, grad/param norm = 3.0966e-01, time/batch = 17.1993s	
10068/16650 (epoch 30.234), train_loss = 1.02885311, grad/param norm = 2.6881e-01, time/batch = 17.9512s	
10069/16650 (epoch 30.237), train_loss = 0.90952263, grad/param norm = 4.4635e-01, time/batch = 15.5290s	
10070/16650 (epoch 30.240), train_loss = 0.88688134, grad/param norm = 2.7579e-01, time/batch = 17.9625s	
10071/16650 (epoch 30.243), train_loss = 0.86236422, grad/param norm = 3.0498e-01, time/batch = 17.7702s	
10072/16650 (epoch 30.246), train_loss = 0.98243145, grad/param norm = 3.1734e-01, time/batch = 16.2606s	
10073/16650 (epoch 30.249), train_loss = 0.75213005, grad/param norm = 2.4544e-01, time/batch = 17.0291s	
10074/16650 (epoch 30.252), train_loss = 0.83823574, grad/param norm = 3.1284e-01, time/batch = 17.2851s	
10075/16650 (epoch 30.255), train_loss = 0.90959217, grad/param norm = 2.7887e-01, time/batch = 16.7048s	
10076/16650 (epoch 30.258), train_loss = 0.94226256, grad/param norm = 2.7182e-01, time/batch = 15.3374s	
10077/16650 (epoch 30.261), train_loss = 0.90834114, grad/param norm = 3.0160e-01, time/batch = 17.4548s	
10078/16650 (epoch 30.264), train_loss = 0.81424004, grad/param norm = 2.5494e-01, time/batch = 17.9442s	
10079/16650 (epoch 30.267), train_loss = 0.83258529, grad/param norm = 2.6635e-01, time/batch = 15.5774s	
10080/16650 (epoch 30.270), train_loss = 0.90655675, grad/param norm = 2.8899e-01, time/batch = 15.6573s	
10081/16650 (epoch 30.273), train_loss = 0.97977230, grad/param norm = 2.8680e-01, time/batch = 16.6215s	
10082/16650 (epoch 30.276), train_loss = 0.91296674, grad/param norm = 3.0160e-01, time/batch = 15.2559s	
10083/16650 (epoch 30.279), train_loss = 0.86087401, grad/param norm = 2.9872e-01, time/batch = 16.1629s	
10084/16650 (epoch 30.282), train_loss = 0.77153024, grad/param norm = 2.4932e-01, time/batch = 17.5319s	
10085/16650 (epoch 30.285), train_loss = 0.80025384, grad/param norm = 2.7287e-01, time/batch = 16.2012s	
10086/16650 (epoch 30.288), train_loss = 0.80068237, grad/param norm = 3.0793e-01, time/batch = 17.3752s	
10087/16650 (epoch 30.291), train_loss = 0.63499258, grad/param norm = 2.0431e-01, time/batch = 14.4745s	
10088/16650 (epoch 30.294), train_loss = 0.76691312, grad/param norm = 2.4605e-01, time/batch = 17.4456s	
10089/16650 (epoch 30.297), train_loss = 0.83884410, grad/param norm = 2.4758e-01, time/batch = 17.7897s	
10090/16650 (epoch 30.300), train_loss = 0.66935485, grad/param norm = 2.1742e-01, time/batch = 15.8493s	
10091/16650 (epoch 30.303), train_loss = 0.73818180, grad/param norm = 2.4456e-01, time/batch = 18.1951s	
10092/16650 (epoch 30.306), train_loss = 0.92239205, grad/param norm = 2.4243e-01, time/batch = 16.7843s	
10093/16650 (epoch 30.309), train_loss = 0.93243460, grad/param norm = 3.0199e-01, time/batch = 17.3733s	
10094/16650 (epoch 30.312), train_loss = 0.74830745, grad/param norm = 2.8713e-01, time/batch = 15.1559s	
10095/16650 (epoch 30.315), train_loss = 0.61347942, grad/param norm = 2.1226e-01, time/batch = 17.1104s	
10096/16650 (epoch 30.318), train_loss = 0.72804686, grad/param norm = 2.9117e-01, time/batch = 16.8001s	
10097/16650 (epoch 30.321), train_loss = 0.97305445, grad/param norm = 3.0364e-01, time/batch = 14.4816s	
10098/16650 (epoch 30.324), train_loss = 0.78688154, grad/param norm = 3.1279e-01, time/batch = 15.9182s	
10099/16650 (epoch 30.327), train_loss = 0.89326367, grad/param norm = 3.0423e-01, time/batch = 17.7050s	
10100/16650 (epoch 30.330), train_loss = 0.88309048, grad/param norm = 4.0294e-01, time/batch = 17.1245s	
10101/16650 (epoch 30.333), train_loss = 0.91599298, grad/param norm = 3.1191e-01, time/batch = 16.5113s	
10102/16650 (epoch 30.336), train_loss = 0.75527970, grad/param norm = 2.6179e-01, time/batch = 16.7817s	
10103/16650 (epoch 30.339), train_loss = 0.80303742, grad/param norm = 2.8562e-01, time/batch = 17.3523s	
10104/16650 (epoch 30.342), train_loss = 0.75862691, grad/param norm = 2.8901e-01, time/batch = 17.7167s	
10105/16650 (epoch 30.345), train_loss = 0.73625323, grad/param norm = 2.3986e-01, time/batch = 16.1828s	
10106/16650 (epoch 30.348), train_loss = 0.85231902, grad/param norm = 3.1087e-01, time/batch = 17.7917s	
10107/16650 (epoch 30.351), train_loss = 0.88590389, grad/param norm = 2.7495e-01, time/batch = 16.2722s	
10108/16650 (epoch 30.354), train_loss = 0.91232573, grad/param norm = 2.8611e-01, time/batch = 16.1888s	
10109/16650 (epoch 30.357), train_loss = 0.89932587, grad/param norm = 3.0585e-01, time/batch = 17.7871s	
10110/16650 (epoch 30.360), train_loss = 0.86019336, grad/param norm = 2.9863e-01, time/batch = 16.1166s	
10111/16650 (epoch 30.363), train_loss = 0.95502395, grad/param norm = 2.9851e-01, time/batch = 14.3197s	
10112/16650 (epoch 30.366), train_loss = 1.01005514, grad/param norm = 3.3878e-01, time/batch = 15.7656s	
10113/16650 (epoch 30.369), train_loss = 0.88061742, grad/param norm = 3.1523e-01, time/batch = 16.5151s	
10114/16650 (epoch 30.372), train_loss = 0.87318259, grad/param norm = 2.7540e-01, time/batch = 17.0441s	
10115/16650 (epoch 30.375), train_loss = 0.87340506, grad/param norm = 2.5506e-01, time/batch = 16.1999s	
10116/16650 (epoch 30.378), train_loss = 0.81603075, grad/param norm = 2.6995e-01, time/batch = 16.6792s	
10117/16650 (epoch 30.381), train_loss = 0.87896712, grad/param norm = 2.8014e-01, time/batch = 17.0378s	
10118/16650 (epoch 30.384), train_loss = 0.98943909, grad/param norm = 2.9240e-01, time/batch = 17.0514s	
10119/16650 (epoch 30.387), train_loss = 0.67101895, grad/param norm = 2.2529e-01, time/batch = 16.2736s	
10120/16650 (epoch 30.390), train_loss = 0.93113547, grad/param norm = 2.6148e-01, time/batch = 15.6647s	
10121/16650 (epoch 30.393), train_loss = 0.80842094, grad/param norm = 2.9869e-01, time/batch = 15.2583s	
10122/16650 (epoch 30.396), train_loss = 0.97657031, grad/param norm = 3.4976e-01, time/batch = 17.9323s	
10123/16650 (epoch 30.399), train_loss = 0.88963342, grad/param norm = 2.6035e-01, time/batch = 16.1839s	
10124/16650 (epoch 30.402), train_loss = 0.79129123, grad/param norm = 2.6079e-01, time/batch = 18.1084s	
10125/16650 (epoch 30.405), train_loss = 0.70242703, grad/param norm = 2.9808e-01, time/batch = 17.2086s	
10126/16650 (epoch 30.408), train_loss = 0.87418487, grad/param norm = 2.9025e-01, time/batch = 16.6846s	
10127/16650 (epoch 30.411), train_loss = 0.74678611, grad/param norm = 2.8446e-01, time/batch = 17.1018s	
10128/16650 (epoch 30.414), train_loss = 0.77426488, grad/param norm = 3.6055e-01, time/batch = 17.3723s	
10129/16650 (epoch 30.417), train_loss = 0.75010720, grad/param norm = 2.7781e-01, time/batch = 16.4513s	
10130/16650 (epoch 30.420), train_loss = 0.73372600, grad/param norm = 2.6605e-01, time/batch = 15.1543s	
10131/16650 (epoch 30.423), train_loss = 0.62496214, grad/param norm = 2.3186e-01, time/batch = 16.6892s	
10132/16650 (epoch 30.426), train_loss = 0.73860533, grad/param norm = 2.6115e-01, time/batch = 17.9567s	
10133/16650 (epoch 30.429), train_loss = 0.95387238, grad/param norm = 3.2338e-01, time/batch = 15.5895s	
10134/16650 (epoch 30.432), train_loss = 0.93633721, grad/param norm = 3.0963e-01, time/batch = 17.7026s	
10135/16650 (epoch 30.435), train_loss = 1.03715362, grad/param norm = 2.9402e-01, time/batch = 17.7932s	
10136/16650 (epoch 30.438), train_loss = 1.02608645, grad/param norm = 3.7873e-01, time/batch = 14.9216s	
10137/16650 (epoch 30.441), train_loss = 0.84481775, grad/param norm = 3.5176e-01, time/batch = 15.2577s	
10138/16650 (epoch 30.444), train_loss = 0.80837460, grad/param norm = 2.9931e-01, time/batch = 18.2016s	
10139/16650 (epoch 30.447), train_loss = 0.79315472, grad/param norm = 3.1214e-01, time/batch = 17.8803s	
10140/16650 (epoch 30.450), train_loss = 0.79999082, grad/param norm = 2.7538e-01, time/batch = 16.3518s	
10141/16650 (epoch 30.453), train_loss = 0.77664738, grad/param norm = 2.5916e-01, time/batch = 15.6021s	
10142/16650 (epoch 30.456), train_loss = 0.74440229, grad/param norm = 2.5020e-01, time/batch = 16.6564s	
10143/16650 (epoch 30.459), train_loss = 0.77973707, grad/param norm = 2.6139e-01, time/batch = 17.7076s	
10144/16650 (epoch 30.462), train_loss = 0.96452120, grad/param norm = 3.2603e-01, time/batch = 16.0106s	
10145/16650 (epoch 30.465), train_loss = 0.79233565, grad/param norm = 2.8073e-01, time/batch = 17.8760s	
10146/16650 (epoch 30.468), train_loss = 0.65377649, grad/param norm = 2.5711e-01, time/batch = 16.0292s	
10147/16650 (epoch 30.471), train_loss = 0.55483112, grad/param norm = 2.0176e-01, time/batch = 17.1073s	
10148/16650 (epoch 30.474), train_loss = 0.72893849, grad/param norm = 2.7018e-01, time/batch = 15.4764s	
10149/16650 (epoch 30.477), train_loss = 0.90897448, grad/param norm = 2.9738e-01, time/batch = 16.6934s	
10150/16650 (epoch 30.480), train_loss = 0.88477227, grad/param norm = 3.1902e-01, time/batch = 17.5520s	
10151/16650 (epoch 30.483), train_loss = 0.92586215, grad/param norm = 2.9252e-01, time/batch = 15.6697s	
10152/16650 (epoch 30.486), train_loss = 0.75801550, grad/param norm = 2.4555e-01, time/batch = 16.6037s	
10153/16650 (epoch 30.489), train_loss = 0.79701673, grad/param norm = 2.8720e-01, time/batch = 17.5343s	
10154/16650 (epoch 30.492), train_loss = 0.84125328, grad/param norm = 2.5290e-01, time/batch = 16.7036s	
10155/16650 (epoch 30.495), train_loss = 0.73328846, grad/param norm = 2.5656e-01, time/batch = 16.5935s	
10156/16650 (epoch 30.498), train_loss = 0.78867939, grad/param norm = 4.3663e-01, time/batch = 15.1745s	
10157/16650 (epoch 30.502), train_loss = 0.98640438, grad/param norm = 3.5242e-01, time/batch = 17.5996s	
10158/16650 (epoch 30.505), train_loss = 0.86672054, grad/param norm = 2.7792e-01, time/batch = 16.1126s	
10159/16650 (epoch 30.508), train_loss = 0.90566026, grad/param norm = 3.6489e-01, time/batch = 17.2007s	
10160/16650 (epoch 30.511), train_loss = 0.93403401, grad/param norm = 2.8092e-01, time/batch = 17.2915s	
10161/16650 (epoch 30.514), train_loss = 0.72568961, grad/param norm = 2.8260e-01, time/batch = 15.5114s	
10162/16650 (epoch 30.517), train_loss = 0.82508467, grad/param norm = 3.2591e-01, time/batch = 16.3136s	
10163/16650 (epoch 30.520), train_loss = 0.72368322, grad/param norm = 2.8249e-01, time/batch = 17.1960s	
10164/16650 (epoch 30.523), train_loss = 0.82501020, grad/param norm = 2.7659e-01, time/batch = 16.8675s	
10165/16650 (epoch 30.526), train_loss = 0.90515026, grad/param norm = 2.9420e-01, time/batch = 17.1855s	
10166/16650 (epoch 30.529), train_loss = 0.96675284, grad/param norm = 3.3611e-01, time/batch = 16.6799s	
10167/16650 (epoch 30.532), train_loss = 0.65198755, grad/param norm = 2.5849e-01, time/batch = 16.2605s	
10168/16650 (epoch 30.535), train_loss = 0.72005040, grad/param norm = 2.7703e-01, time/batch = 17.3738s	
10169/16650 (epoch 30.538), train_loss = 0.69589844, grad/param norm = 2.8422e-01, time/batch = 15.9149s	
10170/16650 (epoch 30.541), train_loss = 0.97875340, grad/param norm = 3.2125e-01, time/batch = 17.7810s	
10171/16650 (epoch 30.544), train_loss = 1.00432770, grad/param norm = 3.3560e-01, time/batch = 16.9545s	
10172/16650 (epoch 30.547), train_loss = 0.74415745, grad/param norm = 2.8042e-01, time/batch = 16.7739s	
10173/16650 (epoch 30.550), train_loss = 0.82071617, grad/param norm = 2.5534e-01, time/batch = 15.0820s	
10174/16650 (epoch 30.553), train_loss = 0.82309380, grad/param norm = 3.1141e-01, time/batch = 17.1229s	
10175/16650 (epoch 30.556), train_loss = 0.75614475, grad/param norm = 2.5034e-01, time/batch = 18.2897s	
10176/16650 (epoch 30.559), train_loss = 0.68526735, grad/param norm = 2.7198e-01, time/batch = 16.6927s	
10177/16650 (epoch 30.562), train_loss = 0.76981131, grad/param norm = 2.7143e-01, time/batch = 17.0458s	
10178/16650 (epoch 30.565), train_loss = 0.67052538, grad/param norm = 2.7732e-01, time/batch = 18.2132s	
10179/16650 (epoch 30.568), train_loss = 0.67186967, grad/param norm = 2.7890e-01, time/batch = 15.6724s	
10180/16650 (epoch 30.571), train_loss = 0.71923200, grad/param norm = 3.3320e-01, time/batch = 17.4313s	
10181/16650 (epoch 30.574), train_loss = 0.77242572, grad/param norm = 3.0669e-01, time/batch = 17.7013s	
10182/16650 (epoch 30.577), train_loss = 0.76090709, grad/param norm = 2.5266e-01, time/batch = 16.1864s	
10183/16650 (epoch 30.580), train_loss = 0.70156882, grad/param norm = 2.6286e-01, time/batch = 16.1124s	
10184/16650 (epoch 30.583), train_loss = 0.80924184, grad/param norm = 2.5719e-01, time/batch = 16.7062s	
10185/16650 (epoch 30.586), train_loss = 0.72662699, grad/param norm = 3.1872e-01, time/batch = 16.2796s	
10186/16650 (epoch 30.589), train_loss = 0.70813548, grad/param norm = 2.5699e-01, time/batch = 16.6889s	
10187/16650 (epoch 30.592), train_loss = 0.79801636, grad/param norm = 2.5258e-01, time/batch = 27.7366s	
10188/16650 (epoch 30.595), train_loss = 0.75400539, grad/param norm = 2.8416e-01, time/batch = 19.8561s	
10189/16650 (epoch 30.598), train_loss = 0.79156210, grad/param norm = 2.8018e-01, time/batch = 17.0398s	
10190/16650 (epoch 30.601), train_loss = 0.76095540, grad/param norm = 3.1192e-01, time/batch = 15.6698s	
10191/16650 (epoch 30.604), train_loss = 0.86428628, grad/param norm = 3.5074e-01, time/batch = 17.4646s	
10192/16650 (epoch 30.607), train_loss = 0.86881141, grad/param norm = 2.7078e-01, time/batch = 17.1149s	
10193/16650 (epoch 30.610), train_loss = 0.73807031, grad/param norm = 2.9108e-01, time/batch = 15.4930s	
10194/16650 (epoch 30.613), train_loss = 0.93860451, grad/param norm = 3.1351e-01, time/batch = 16.7027s	
10195/16650 (epoch 30.616), train_loss = 0.93084830, grad/param norm = 3.7206e-01, time/batch = 17.7981s	
10196/16650 (epoch 30.619), train_loss = 0.68645597, grad/param norm = 2.6724e-01, time/batch = 17.2001s	
10197/16650 (epoch 30.622), train_loss = 0.65891720, grad/param norm = 2.5317e-01, time/batch = 15.9929s	
10198/16650 (epoch 30.625), train_loss = 0.77543343, grad/param norm = 2.5573e-01, time/batch = 14.9167s	
10199/16650 (epoch 30.628), train_loss = 0.75960470, grad/param norm = 2.9860e-01, time/batch = 16.6029s	
10200/16650 (epoch 30.631), train_loss = 0.84301800, grad/param norm = 3.8923e-01, time/batch = 16.3585s	
10201/16650 (epoch 30.634), train_loss = 1.00002954, grad/param norm = 3.2125e-01, time/batch = 16.4424s	
10202/16650 (epoch 30.637), train_loss = 0.99520619, grad/param norm = 2.8360e-01, time/batch = 15.8666s	
10203/16650 (epoch 30.640), train_loss = 0.77964889, grad/param norm = 2.6219e-01, time/batch = 17.6986s	
10204/16650 (epoch 30.643), train_loss = 0.88074264, grad/param norm = 2.9317e-01, time/batch = 16.2667s	
10205/16650 (epoch 30.646), train_loss = 0.87018105, grad/param norm = 3.0514e-01, time/batch = 17.2908s	
10206/16650 (epoch 30.649), train_loss = 0.85486618, grad/param norm = 2.8770e-01, time/batch = 17.7067s	
10207/16650 (epoch 30.652), train_loss = 0.90457059, grad/param norm = 3.2463e-01, time/batch = 16.8639s	
10208/16650 (epoch 30.655), train_loss = 0.85682851, grad/param norm = 3.4593e-01, time/batch = 15.9373s	
10209/16650 (epoch 30.658), train_loss = 0.75558208, grad/param norm = 2.8703e-01, time/batch = 18.0384s	
10210/16650 (epoch 30.661), train_loss = 0.83495568, grad/param norm = 2.8325e-01, time/batch = 14.8330s	
10211/16650 (epoch 30.664), train_loss = 0.84040915, grad/param norm = 2.8149e-01, time/batch = 17.1109s	
10212/16650 (epoch 30.667), train_loss = 0.93644735, grad/param norm = 2.8597e-01, time/batch = 15.6831s	
10213/16650 (epoch 30.670), train_loss = 0.70788489, grad/param norm = 2.5549e-01, time/batch = 18.1995s	
10214/16650 (epoch 30.673), train_loss = 0.74153526, grad/param norm = 2.4358e-01, time/batch = 16.9564s	
10215/16650 (epoch 30.676), train_loss = 0.86284434, grad/param norm = 2.6832e-01, time/batch = 16.4139s	
10216/16650 (epoch 30.679), train_loss = 0.74657292, grad/param norm = 2.9818e-01, time/batch = 17.7010s	
10217/16650 (epoch 30.682), train_loss = 0.82589611, grad/param norm = 2.8588e-01, time/batch = 15.1704s	
10218/16650 (epoch 30.685), train_loss = 0.70989053, grad/param norm = 2.5871e-01, time/batch = 16.1053s	
10219/16650 (epoch 30.688), train_loss = 0.88477210, grad/param norm = 2.7615e-01, time/batch = 15.9494s	
10220/16650 (epoch 30.691), train_loss = 0.86090096, grad/param norm = 2.7383e-01, time/batch = 16.4430s	
10221/16650 (epoch 30.694), train_loss = 0.76769279, grad/param norm = 2.7690e-01, time/batch = 16.2816s	
10222/16650 (epoch 30.697), train_loss = 0.69341775, grad/param norm = 2.6018e-01, time/batch = 15.5879s	
10223/16650 (epoch 30.700), train_loss = 0.87426484, grad/param norm = 2.9248e-01, time/batch = 16.2864s	
10224/16650 (epoch 30.703), train_loss = 0.74478985, grad/param norm = 3.4571e-01, time/batch = 16.0271s	
10225/16650 (epoch 30.706), train_loss = 0.81879163, grad/param norm = 3.1066e-01, time/batch = 17.1834s	
10226/16650 (epoch 30.709), train_loss = 0.72417921, grad/param norm = 4.3379e-01, time/batch = 16.1013s	
10227/16650 (epoch 30.712), train_loss = 0.74808464, grad/param norm = 2.7806e-01, time/batch = 17.3652s	
10228/16650 (epoch 30.715), train_loss = 0.87711114, grad/param norm = 3.0070e-01, time/batch = 18.5432s	
10229/16650 (epoch 30.718), train_loss = 0.89933719, grad/param norm = 2.8453e-01, time/batch = 17.0369s	
10230/16650 (epoch 30.721), train_loss = 0.88393337, grad/param norm = 2.8567e-01, time/batch = 17.8765s	
10231/16650 (epoch 30.724), train_loss = 0.91264975, grad/param norm = 3.0488e-01, time/batch = 18.2217s	
10232/16650 (epoch 30.727), train_loss = 0.90958235, grad/param norm = 2.9562e-01, time/batch = 16.5081s	
10233/16650 (epoch 30.730), train_loss = 0.75096186, grad/param norm = 2.8503e-01, time/batch = 17.6780s	
10234/16650 (epoch 30.733), train_loss = 0.92432778, grad/param norm = 3.3897e-01, time/batch = 17.7199s	
10235/16650 (epoch 30.736), train_loss = 0.69290823, grad/param norm = 2.4547e-01, time/batch = 16.4458s	
10236/16650 (epoch 30.739), train_loss = 0.82552215, grad/param norm = 2.5860e-01, time/batch = 14.7848s	
10237/16650 (epoch 30.742), train_loss = 0.81342917, grad/param norm = 2.7238e-01, time/batch = 14.2288s	
10238/16650 (epoch 30.745), train_loss = 0.62585047, grad/param norm = 2.4968e-01, time/batch = 14.3335s	
10239/16650 (epoch 30.748), train_loss = 0.71549250, grad/param norm = 3.2426e-01, time/batch = 14.3189s	
10240/16650 (epoch 30.751), train_loss = 0.82660030, grad/param norm = 3.4616e-01, time/batch = 14.7566s	
10241/16650 (epoch 30.754), train_loss = 1.00586808, grad/param norm = 3.4501e-01, time/batch = 14.5084s	
10242/16650 (epoch 30.757), train_loss = 0.95537690, grad/param norm = 3.1724e-01, time/batch = 14.4305s	
10243/16650 (epoch 30.760), train_loss = 0.83437636, grad/param norm = 2.9849e-01, time/batch = 16.6100s	
10244/16650 (epoch 30.763), train_loss = 0.76579309, grad/param norm = 2.7127e-01, time/batch = 15.9173s	
10245/16650 (epoch 30.766), train_loss = 0.77905976, grad/param norm = 2.4200e-01, time/batch = 15.3351s	
10246/16650 (epoch 30.769), train_loss = 0.85993163, grad/param norm = 2.7510e-01, time/batch = 17.9463s	
10247/16650 (epoch 30.772), train_loss = 0.81158601, grad/param norm = 2.4887e-01, time/batch = 18.4386s	
10248/16650 (epoch 30.775), train_loss = 0.80425498, grad/param norm = 2.7763e-01, time/batch = 17.1862s	
10249/16650 (epoch 30.778), train_loss = 0.83232538, grad/param norm = 2.6042e-01, time/batch = 15.5911s	
10250/16650 (epoch 30.781), train_loss = 0.97581487, grad/param norm = 2.8183e-01, time/batch = 15.1647s	
10251/16650 (epoch 30.784), train_loss = 0.85922234, grad/param norm = 2.8773e-01, time/batch = 15.5796s	
10252/16650 (epoch 30.787), train_loss = 0.88423348, grad/param norm = 2.8289e-01, time/batch = 17.5994s	
10253/16650 (epoch 30.790), train_loss = 0.88442012, grad/param norm = 2.5566e-01, time/batch = 18.4568s	
10254/16650 (epoch 30.793), train_loss = 0.71672068, grad/param norm = 2.6390e-01, time/batch = 17.7861s	
10255/16650 (epoch 30.796), train_loss = 1.07216822, grad/param norm = 2.9462e-01, time/batch = 16.5008s	
10256/16650 (epoch 30.799), train_loss = 1.00259456, grad/param norm = 3.4806e-01, time/batch = 17.7102s	
10257/16650 (epoch 30.802), train_loss = 0.90140849, grad/param norm = 2.6629e-01, time/batch = 17.0300s	
10258/16650 (epoch 30.805), train_loss = 0.82397121, grad/param norm = 2.3615e-01, time/batch = 15.9156s	
10259/16650 (epoch 30.808), train_loss = 0.88393750, grad/param norm = 2.6682e-01, time/batch = 18.0343s	
10260/16650 (epoch 30.811), train_loss = 0.94120783, grad/param norm = 2.9790e-01, time/batch = 17.4428s	
10261/16650 (epoch 30.814), train_loss = 0.73486710, grad/param norm = 2.5418e-01, time/batch = 18.1243s	
10262/16650 (epoch 30.817), train_loss = 0.78526304, grad/param norm = 2.8416e-01, time/batch = 15.8473s	
10263/16650 (epoch 30.820), train_loss = 0.86548776, grad/param norm = 3.0989e-01, time/batch = 15.7358s	
10264/16650 (epoch 30.823), train_loss = 0.82321227, grad/param norm = 2.9526e-01, time/batch = 17.3337s	
10265/16650 (epoch 30.826), train_loss = 0.79147718, grad/param norm = 2.5864e-01, time/batch = 17.3606s	
10266/16650 (epoch 30.829), train_loss = 0.85932477, grad/param norm = 2.8731e-01, time/batch = 18.1090s	
10267/16650 (epoch 30.832), train_loss = 0.89230787, grad/param norm = 2.6942e-01, time/batch = 16.0157s	
10268/16650 (epoch 30.835), train_loss = 0.90382254, grad/param norm = 3.0573e-01, time/batch = 16.8549s	
10269/16650 (epoch 30.838), train_loss = 0.76547048, grad/param norm = 2.7179e-01, time/batch = 17.0084s	
10270/16650 (epoch 30.841), train_loss = 0.76615817, grad/param norm = 2.7122e-01, time/batch = 18.5349s	
10271/16650 (epoch 30.844), train_loss = 0.77638483, grad/param norm = 2.5981e-01, time/batch = 17.7902s	
10272/16650 (epoch 30.847), train_loss = 0.88502053, grad/param norm = 2.7158e-01, time/batch = 16.6737s	
10273/16650 (epoch 30.850), train_loss = 0.73529710, grad/param norm = 2.8299e-01, time/batch = 18.6224s	
10274/16650 (epoch 30.853), train_loss = 0.82253909, grad/param norm = 2.7167e-01, time/batch = 17.2808s	
10275/16650 (epoch 30.856), train_loss = 0.76196665, grad/param norm = 2.5714e-01, time/batch = 16.0950s	
10276/16650 (epoch 30.859), train_loss = 0.92403200, grad/param norm = 3.0232e-01, time/batch = 23.3571s	
10277/16650 (epoch 30.862), train_loss = 0.80153506, grad/param norm = 2.6052e-01, time/batch = 18.6113s	
10278/16650 (epoch 30.865), train_loss = 0.66797981, grad/param norm = 2.3185e-01, time/batch = 20.5274s	
10279/16650 (epoch 30.868), train_loss = 0.87192778, grad/param norm = 2.8905e-01, time/batch = 20.2636s	
10280/16650 (epoch 30.871), train_loss = 0.89007391, grad/param norm = 2.9280e-01, time/batch = 23.2650s	
10281/16650 (epoch 30.874), train_loss = 0.86866087, grad/param norm = 2.6569e-01, time/batch = 20.7577s	
10282/16650 (epoch 30.877), train_loss = 0.83665650, grad/param norm = 2.6711e-01, time/batch = 22.5171s	
10283/16650 (epoch 30.880), train_loss = 0.74104136, grad/param norm = 2.8908e-01, time/batch = 23.9349s	
10284/16650 (epoch 30.883), train_loss = 0.85150779, grad/param norm = 2.8537e-01, time/batch = 19.8591s	
10285/16650 (epoch 30.886), train_loss = 0.84342376, grad/param norm = 2.6941e-01, time/batch = 21.6962s	
10286/16650 (epoch 30.889), train_loss = 0.69543476, grad/param norm = 2.8407e-01, time/batch = 22.2801s	
10287/16650 (epoch 30.892), train_loss = 0.84115686, grad/param norm = 2.9206e-01, time/batch = 19.6116s	
10288/16650 (epoch 30.895), train_loss = 0.86481017, grad/param norm = 3.1428e-01, time/batch = 20.6304s	
10289/16650 (epoch 30.898), train_loss = 0.84983382, grad/param norm = 3.8987e-01, time/batch = 17.8381s	
10290/16650 (epoch 30.901), train_loss = 0.80549182, grad/param norm = 2.9170e-01, time/batch = 19.3451s	
10291/16650 (epoch 30.904), train_loss = 0.78255122, grad/param norm = 3.1887e-01, time/batch = 20.6948s	
10292/16650 (epoch 30.907), train_loss = 0.85806762, grad/param norm = 2.9781e-01, time/batch = 21.5210s	
10293/16650 (epoch 30.910), train_loss = 0.87855567, grad/param norm = 3.3414e-01, time/batch = 20.3773s	
10294/16650 (epoch 30.913), train_loss = 0.78346149, grad/param norm = 2.6898e-01, time/batch = 30.3959s	
10295/16650 (epoch 30.916), train_loss = 0.78593030, grad/param norm = 2.9812e-01, time/batch = 16.2363s	
10296/16650 (epoch 30.919), train_loss = 0.98669456, grad/param norm = 3.0361e-01, time/batch = 17.2772s	
10297/16650 (epoch 30.922), train_loss = 0.89090430, grad/param norm = 3.4209e-01, time/batch = 17.3493s	
10298/16650 (epoch 30.925), train_loss = 0.78564558, grad/param norm = 2.7941e-01, time/batch = 17.5208s	
10299/16650 (epoch 30.928), train_loss = 0.83507328, grad/param norm = 3.0451e-01, time/batch = 17.3395s	
10300/16650 (epoch 30.931), train_loss = 0.87809785, grad/param norm = 2.8223e-01, time/batch = 17.6085s	
10301/16650 (epoch 30.934), train_loss = 0.71166505, grad/param norm = 2.8905e-01, time/batch = 18.2889s	
10302/16650 (epoch 30.937), train_loss = 0.74877744, grad/param norm = 2.8293e-01, time/batch = 15.4955s	
10303/16650 (epoch 30.940), train_loss = 0.81833085, grad/param norm = 2.5583e-01, time/batch = 18.1137s	
10304/16650 (epoch 30.943), train_loss = 0.84941324, grad/param norm = 3.2602e-01, time/batch = 16.3684s	
10305/16650 (epoch 30.946), train_loss = 0.76775314, grad/param norm = 2.8100e-01, time/batch = 16.7714s	
10306/16650 (epoch 30.949), train_loss = 0.73499293, grad/param norm = 3.1334e-01, time/batch = 17.1664s	
10307/16650 (epoch 30.952), train_loss = 0.70493687, grad/param norm = 2.7834e-01, time/batch = 18.3792s	
10308/16650 (epoch 30.955), train_loss = 0.80620471, grad/param norm = 2.8599e-01, time/batch = 17.9545s	
10309/16650 (epoch 30.958), train_loss = 0.88407124, grad/param norm = 4.1630e-01, time/batch = 16.1735s	
10310/16650 (epoch 30.961), train_loss = 0.81934888, grad/param norm = 2.6141e-01, time/batch = 18.1143s	
10311/16650 (epoch 30.964), train_loss = 0.72994293, grad/param norm = 2.7597e-01, time/batch = 18.0471s	
10312/16650 (epoch 30.967), train_loss = 0.96559184, grad/param norm = 3.2670e-01, time/batch = 14.7328s	
10313/16650 (epoch 30.970), train_loss = 0.77427046, grad/param norm = 2.5758e-01, time/batch = 15.9088s	
10314/16650 (epoch 30.973), train_loss = 0.79172823, grad/param norm = 2.7502e-01, time/batch = 16.5982s	
10315/16650 (epoch 30.976), train_loss = 0.75056491, grad/param norm = 2.3891e-01, time/batch = 18.2904s	
10316/16650 (epoch 30.979), train_loss = 0.85362562, grad/param norm = 2.9829e-01, time/batch = 16.0848s	
10317/16650 (epoch 30.982), train_loss = 0.89479189, grad/param norm = 2.8767e-01, time/batch = 17.9413s	
10318/16650 (epoch 30.985), train_loss = 0.78995625, grad/param norm = 2.4767e-01, time/batch = 17.9484s	
10319/16650 (epoch 30.988), train_loss = 0.89544159, grad/param norm = 3.3856e-01, time/batch = 17.6768s	
10320/16650 (epoch 30.991), train_loss = 0.73815971, grad/param norm = 3.0677e-01, time/batch = 16.3529s	
10321/16650 (epoch 30.994), train_loss = 0.76467314, grad/param norm = 2.7630e-01, time/batch = 14.4857s	
10322/16650 (epoch 30.997), train_loss = 0.81809489, grad/param norm = 2.7107e-01, time/batch = 18.2816s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
10323/16650 (epoch 31.000), train_loss = 0.88634116, grad/param norm = 3.3163e-01, time/batch = 15.9818s	
10324/16650 (epoch 31.003), train_loss = 0.91284933, grad/param norm = 3.1506e-01, time/batch = 15.5563s	
10325/16650 (epoch 31.006), train_loss = 0.90098300, grad/param norm = 3.1858e-01, time/batch = 18.2852s	
10326/16650 (epoch 31.009), train_loss = 0.96988664, grad/param norm = 3.0759e-01, time/batch = 18.4397s	
10327/16650 (epoch 31.012), train_loss = 0.96020545, grad/param norm = 2.8902e-01, time/batch = 15.3315s	
10328/16650 (epoch 31.015), train_loss = 0.82087727, grad/param norm = 2.8867e-01, time/batch = 17.5490s	
10329/16650 (epoch 31.018), train_loss = 0.68492393, grad/param norm = 2.5544e-01, time/batch = 18.6943s	
10330/16650 (epoch 31.021), train_loss = 0.94716183, grad/param norm = 3.1545e-01, time/batch = 14.8124s	
10331/16650 (epoch 31.024), train_loss = 0.82041967, grad/param norm = 2.9221e-01, time/batch = 18.1869s	
10332/16650 (epoch 31.027), train_loss = 0.87489288, grad/param norm = 2.6703e-01, time/batch = 16.9424s	
10333/16650 (epoch 31.030), train_loss = 0.72953957, grad/param norm = 2.5056e-01, time/batch = 17.6097s	
10334/16650 (epoch 31.033), train_loss = 0.83078478, grad/param norm = 2.6810e-01, time/batch = 16.9492s	
10335/16650 (epoch 31.036), train_loss = 0.61193994, grad/param norm = 2.8985e-01, time/batch = 17.1992s	
10336/16650 (epoch 31.039), train_loss = 0.93172371, grad/param norm = 2.6934e-01, time/batch = 17.3699s	
10337/16650 (epoch 31.042), train_loss = 0.87844800, grad/param norm = 3.0116e-01, time/batch = 17.0177s	
10338/16650 (epoch 31.045), train_loss = 0.80928483, grad/param norm = 2.7631e-01, time/batch = 17.0305s	
10339/16650 (epoch 31.048), train_loss = 0.90801155, grad/param norm = 3.0108e-01, time/batch = 17.8684s	
10340/16650 (epoch 31.051), train_loss = 0.80377966, grad/param norm = 2.7552e-01, time/batch = 17.8548s	
10341/16650 (epoch 31.054), train_loss = 0.82417055, grad/param norm = 2.8699e-01, time/batch = 17.0978s	
10342/16650 (epoch 31.057), train_loss = 0.84569349, grad/param norm = 3.0915e-01, time/batch = 17.9429s	
10343/16650 (epoch 31.060), train_loss = 0.69802645, grad/param norm = 2.3652e-01, time/batch = 16.2462s	
10344/16650 (epoch 31.063), train_loss = 0.78648793, grad/param norm = 2.5531e-01, time/batch = 16.2650s	
10345/16650 (epoch 31.066), train_loss = 0.96984580, grad/param norm = 2.8100e-01, time/batch = 18.7903s	
10346/16650 (epoch 31.069), train_loss = 0.89021800, grad/param norm = 2.8862e-01, time/batch = 16.8899s	
10347/16650 (epoch 31.072), train_loss = 0.84277115, grad/param norm = 3.3977e-01, time/batch = 15.6740s	
10348/16650 (epoch 31.075), train_loss = 0.91054670, grad/param norm = 3.1403e-01, time/batch = 16.1863s	
10349/16650 (epoch 31.078), train_loss = 0.92250012, grad/param norm = 2.9943e-01, time/batch = 13.6515s	
10350/16650 (epoch 31.081), train_loss = 0.86068565, grad/param norm = 3.1673e-01, time/batch = 13.5113s	
10351/16650 (epoch 31.084), train_loss = 0.88567312, grad/param norm = 2.8804e-01, time/batch = 14.1774s	
10352/16650 (epoch 31.087), train_loss = 0.86628234, grad/param norm = 2.8947e-01, time/batch = 17.2571s	
10353/16650 (epoch 31.090), train_loss = 0.82361658, grad/param norm = 2.9743e-01, time/batch = 18.5147s	
10354/16650 (epoch 31.093), train_loss = 0.98044146, grad/param norm = 3.1990e-01, time/batch = 16.7516s	
10355/16650 (epoch 31.096), train_loss = 0.79978428, grad/param norm = 2.7439e-01, time/batch = 16.5626s	
10356/16650 (epoch 31.099), train_loss = 0.88102019, grad/param norm = 3.0009e-01, time/batch = 18.0135s	
10357/16650 (epoch 31.102), train_loss = 0.83413828, grad/param norm = 2.8271e-01, time/batch = 17.7067s	
10358/16650 (epoch 31.105), train_loss = 0.86287695, grad/param norm = 2.9145e-01, time/batch = 16.3498s	
10359/16650 (epoch 31.108), train_loss = 0.86014761, grad/param norm = 2.9085e-01, time/batch = 16.1763s	
10360/16650 (epoch 31.111), train_loss = 0.93011736, grad/param norm = 2.6180e-01, time/batch = 18.3599s	
10361/16650 (epoch 31.114), train_loss = 0.91541912, grad/param norm = 3.2633e-01, time/batch = 16.8714s	
10362/16650 (epoch 31.117), train_loss = 1.00377267, grad/param norm = 3.9570e-01, time/batch = 16.7583s	
10363/16650 (epoch 31.120), train_loss = 0.81760942, grad/param norm = 2.7071e-01, time/batch = 17.5354s	
10364/16650 (epoch 31.123), train_loss = 0.83557297, grad/param norm = 2.7266e-01, time/batch = 18.7001s	
10365/16650 (epoch 31.126), train_loss = 0.86854145, grad/param norm = 2.6860e-01, time/batch = 17.5967s	
10366/16650 (epoch 31.129), train_loss = 0.85950059, grad/param norm = 2.8782e-01, time/batch = 15.6892s	
10367/16650 (epoch 31.132), train_loss = 0.83906669, grad/param norm = 3.0159e-01, time/batch = 18.2718s	
10368/16650 (epoch 31.135), train_loss = 0.92769045, grad/param norm = 2.7029e-01, time/batch = 17.9582s	
10369/16650 (epoch 31.138), train_loss = 0.92019195, grad/param norm = 2.6344e-01, time/batch = 15.4928s	
10370/16650 (epoch 31.141), train_loss = 0.90011789, grad/param norm = 3.2688e-01, time/batch = 16.3318s	
10371/16650 (epoch 31.144), train_loss = 0.87552452, grad/param norm = 2.8364e-01, time/batch = 18.1135s	
10372/16650 (epoch 31.147), train_loss = 0.97089277, grad/param norm = 3.1808e-01, time/batch = 16.9220s	
10373/16650 (epoch 31.150), train_loss = 1.08684020, grad/param norm = 4.1029e-01, time/batch = 17.8573s	
10374/16650 (epoch 31.153), train_loss = 0.92740680, grad/param norm = 3.4681e-01, time/batch = 15.5022s	
10375/16650 (epoch 31.156), train_loss = 0.83155360, grad/param norm = 3.4065e-01, time/batch = 18.6199s	
10376/16650 (epoch 31.159), train_loss = 0.91635897, grad/param norm = 3.0249e-01, time/batch = 16.3311s	
10377/16650 (epoch 31.162), train_loss = 0.97128115, grad/param norm = 2.6732e-01, time/batch = 17.6153s	
10378/16650 (epoch 31.165), train_loss = 0.96521400, grad/param norm = 2.8851e-01, time/batch = 17.8595s	
10379/16650 (epoch 31.168), train_loss = 0.70987014, grad/param norm = 2.3543e-01, time/batch = 16.2778s	
10380/16650 (epoch 31.171), train_loss = 0.90851844, grad/param norm = 2.6885e-01, time/batch = 16.9359s	
10381/16650 (epoch 31.174), train_loss = 0.69989683, grad/param norm = 2.3990e-01, time/batch = 16.1582s	
10382/16650 (epoch 31.177), train_loss = 0.86334010, grad/param norm = 2.9718e-01, time/batch = 18.4388s	
10383/16650 (epoch 31.180), train_loss = 0.94324068, grad/param norm = 2.8000e-01, time/batch = 16.5170s	
10384/16650 (epoch 31.183), train_loss = 1.07749454, grad/param norm = 3.1500e-01, time/batch = 17.8016s	
10385/16650 (epoch 31.186), train_loss = 0.89811203, grad/param norm = 2.8922e-01, time/batch = 17.7975s	
10386/16650 (epoch 31.189), train_loss = 0.78716183, grad/param norm = 2.6438e-01, time/batch = 17.5210s	
10387/16650 (epoch 31.192), train_loss = 0.82236409, grad/param norm = 2.8816e-01, time/batch = 17.6771s	
10388/16650 (epoch 31.195), train_loss = 0.77077741, grad/param norm = 2.6482e-01, time/batch = 18.1347s	
10389/16650 (epoch 31.198), train_loss = 0.72675412, grad/param norm = 2.3696e-01, time/batch = 16.6861s	
10390/16650 (epoch 31.201), train_loss = 0.75755451, grad/param norm = 2.9167e-01, time/batch = 17.8416s	
10391/16650 (epoch 31.204), train_loss = 0.86376647, grad/param norm = 2.9240e-01, time/batch = 18.2759s	
10392/16650 (epoch 31.207), train_loss = 0.88968655, grad/param norm = 3.3709e-01, time/batch = 17.8627s	
10393/16650 (epoch 31.210), train_loss = 0.84243492, grad/param norm = 2.6689e-01, time/batch = 21.4271s	
10394/16650 (epoch 31.213), train_loss = 0.91616869, grad/param norm = 3.1382e-01, time/batch = 31.2363s	
10395/16650 (epoch 31.216), train_loss = 0.81210448, grad/param norm = 2.7468e-01, time/batch = 16.2649s	
10396/16650 (epoch 31.219), train_loss = 0.83263103, grad/param norm = 2.7325e-01, time/batch = 17.0165s	
10397/16650 (epoch 31.222), train_loss = 0.87131929, grad/param norm = 2.5017e-01, time/batch = 14.5836s	
10398/16650 (epoch 31.225), train_loss = 0.86367527, grad/param norm = 2.9179e-01, time/batch = 17.3368s	
10399/16650 (epoch 31.228), train_loss = 0.78005919, grad/param norm = 2.7913e-01, time/batch = 16.3484s	
10400/16650 (epoch 31.231), train_loss = 0.81005021, grad/param norm = 2.9364e-01, time/batch = 16.8377s	
10401/16650 (epoch 31.234), train_loss = 1.02842531, grad/param norm = 3.1819e-01, time/batch = 18.4418s	
10402/16650 (epoch 31.237), train_loss = 0.88659622, grad/param norm = 4.5705e-01, time/batch = 16.9211s	
10403/16650 (epoch 31.240), train_loss = 0.87603424, grad/param norm = 3.3233e-01, time/batch = 16.7649s	
10404/16650 (epoch 31.243), train_loss = 0.84329591, grad/param norm = 2.6262e-01, time/batch = 18.5211s	
10405/16650 (epoch 31.246), train_loss = 0.96636020, grad/param norm = 3.1925e-01, time/batch = 18.1141s	
10406/16650 (epoch 31.249), train_loss = 0.72265786, grad/param norm = 2.3828e-01, time/batch = 15.6526s	
10407/16650 (epoch 31.252), train_loss = 0.80956148, grad/param norm = 2.4775e-01, time/batch = 17.6144s	
10408/16650 (epoch 31.255), train_loss = 0.88518153, grad/param norm = 2.7388e-01, time/batch = 18.2001s	
10409/16650 (epoch 31.258), train_loss = 0.93659798, grad/param norm = 2.8100e-01, time/batch = 16.4236s	
10410/16650 (epoch 31.261), train_loss = 0.89754295, grad/param norm = 2.7359e-01, time/batch = 17.9379s	
10411/16650 (epoch 31.264), train_loss = 0.78252704, grad/param norm = 2.6428e-01, time/batch = 15.3937s	
10412/16650 (epoch 31.267), train_loss = 0.83733136, grad/param norm = 2.8725e-01, time/batch = 18.6884s	
10413/16650 (epoch 31.270), train_loss = 0.90253901, grad/param norm = 2.8789e-01, time/batch = 15.5585s	
10414/16650 (epoch 31.273), train_loss = 0.95763945, grad/param norm = 2.8307e-01, time/batch = 18.4441s	
10415/16650 (epoch 31.276), train_loss = 0.87367461, grad/param norm = 2.6946e-01, time/batch = 18.2935s	
10416/16650 (epoch 31.279), train_loss = 0.84317879, grad/param norm = 2.7904e-01, time/batch = 17.2587s	
10417/16650 (epoch 31.282), train_loss = 0.78153917, grad/param norm = 2.5479e-01, time/batch = 17.0202s	
10418/16650 (epoch 31.285), train_loss = 0.78239837, grad/param norm = 2.6542e-01, time/batch = 14.0122s	
10419/16650 (epoch 31.288), train_loss = 0.78724818, grad/param norm = 2.9235e-01, time/batch = 18.1065s	
10420/16650 (epoch 31.291), train_loss = 0.62747564, grad/param norm = 2.1224e-01, time/batch = 15.1389s	
10421/16650 (epoch 31.294), train_loss = 0.74459173, grad/param norm = 2.4130e-01, time/batch = 18.7112s	
10422/16650 (epoch 31.297), train_loss = 0.82985964, grad/param norm = 2.5287e-01, time/batch = 18.0237s	
10423/16650 (epoch 31.300), train_loss = 0.65779734, grad/param norm = 2.1894e-01, time/batch = 16.7616s	
10424/16650 (epoch 31.303), train_loss = 0.73181076, grad/param norm = 2.3712e-01, time/batch = 17.7826s	
10425/16650 (epoch 31.306), train_loss = 0.90690348, grad/param norm = 2.5768e-01, time/batch = 18.1947s	
10426/16650 (epoch 31.309), train_loss = 0.90453595, grad/param norm = 2.8252e-01, time/batch = 17.2681s	
10427/16650 (epoch 31.312), train_loss = 0.71659231, grad/param norm = 2.9739e-01, time/batch = 17.7362s	
10428/16650 (epoch 31.315), train_loss = 0.60405346, grad/param norm = 2.0190e-01, time/batch = 16.5374s	
10429/16650 (epoch 31.318), train_loss = 0.70539128, grad/param norm = 2.5663e-01, time/batch = 14.5630s	
10430/16650 (epoch 31.321), train_loss = 0.95156331, grad/param norm = 3.1608e-01, time/batch = 16.9362s	
10431/16650 (epoch 31.324), train_loss = 0.78104474, grad/param norm = 3.4485e-01, time/batch = 17.4426s	
10432/16650 (epoch 31.327), train_loss = 0.88166137, grad/param norm = 3.4881e-01, time/batch = 16.9107s	
10433/16650 (epoch 31.330), train_loss = 0.89432113, grad/param norm = 3.5684e-01, time/batch = 15.9114s	
10434/16650 (epoch 31.333), train_loss = 0.89184453, grad/param norm = 2.8893e-01, time/batch = 15.5916s	
10435/16650 (epoch 31.336), train_loss = 0.76165645, grad/param norm = 3.1310e-01, time/batch = 18.5266s	
10436/16650 (epoch 31.339), train_loss = 0.77735404, grad/param norm = 2.5939e-01, time/batch = 18.2011s	
10437/16650 (epoch 31.342), train_loss = 0.73743861, grad/param norm = 3.0432e-01, time/batch = 17.1079s	
10438/16650 (epoch 31.345), train_loss = 0.72182140, grad/param norm = 2.4016e-01, time/batch = 17.0207s	
10439/16650 (epoch 31.348), train_loss = 0.84565233, grad/param norm = 3.6383e-01, time/batch = 17.0586s	
10440/16650 (epoch 31.351), train_loss = 0.85583869, grad/param norm = 2.9500e-01, time/batch = 16.2658s	
10441/16650 (epoch 31.354), train_loss = 0.91032451, grad/param norm = 3.1313e-01, time/batch = 16.1598s	
10442/16650 (epoch 31.357), train_loss = 0.85932101, grad/param norm = 2.8519e-01, time/batch = 18.1926s	
10443/16650 (epoch 31.360), train_loss = 0.86327832, grad/param norm = 3.1466e-01, time/batch = 17.8606s	
10444/16650 (epoch 31.363), train_loss = 0.93169064, grad/param norm = 3.2535e-01, time/batch = 16.5929s	
10445/16650 (epoch 31.366), train_loss = 0.98349477, grad/param norm = 3.1657e-01, time/batch = 16.5847s	
10446/16650 (epoch 31.369), train_loss = 0.87082240, grad/param norm = 2.9720e-01, time/batch = 14.6312s	
10447/16650 (epoch 31.372), train_loss = 0.84945402, grad/param norm = 2.6857e-01, time/batch = 17.3649s	
10448/16650 (epoch 31.375), train_loss = 0.87093911, grad/param norm = 2.6374e-01, time/batch = 16.4260s	
10449/16650 (epoch 31.378), train_loss = 0.78380943, grad/param norm = 2.5212e-01, time/batch = 17.9365s	
10450/16650 (epoch 31.381), train_loss = 0.86541918, grad/param norm = 2.7128e-01, time/batch = 16.1917s	
10451/16650 (epoch 31.384), train_loss = 0.98473104, grad/param norm = 3.0067e-01, time/batch = 18.0164s	
10452/16650 (epoch 31.387), train_loss = 0.66366083, grad/param norm = 2.2443e-01, time/batch = 16.2675s	
10453/16650 (epoch 31.390), train_loss = 0.91575017, grad/param norm = 2.5630e-01, time/batch = 18.3675s	
10454/16650 (epoch 31.393), train_loss = 0.79450461, grad/param norm = 3.1146e-01, time/batch = 18.5357s	
10455/16650 (epoch 31.396), train_loss = 0.93659464, grad/param norm = 3.1770e-01, time/batch = 16.7508s	
10456/16650 (epoch 31.399), train_loss = 0.88909757, grad/param norm = 2.8862e-01, time/batch = 17.3291s	
10457/16650 (epoch 31.402), train_loss = 0.78721500, grad/param norm = 3.0648e-01, time/batch = 15.4860s	
10458/16650 (epoch 31.405), train_loss = 0.67011925, grad/param norm = 2.7040e-01, time/batch = 16.5905s	
10459/16650 (epoch 31.408), train_loss = 0.87286906, grad/param norm = 3.7157e-01, time/batch = 17.6008s	
10460/16650 (epoch 31.411), train_loss = 0.75537585, grad/param norm = 3.2192e-01, time/batch = 17.8661s	
10461/16650 (epoch 31.414), train_loss = 0.74516396, grad/param norm = 2.9815e-01, time/batch = 17.2773s	
10462/16650 (epoch 31.417), train_loss = 0.73446377, grad/param norm = 2.8899e-01, time/batch = 16.5018s	
10463/16650 (epoch 31.420), train_loss = 0.73409164, grad/param norm = 2.8322e-01, time/batch = 17.8554s	
10464/16650 (epoch 31.423), train_loss = 0.62037981, grad/param norm = 2.1460e-01, time/batch = 14.6483s	
10465/16650 (epoch 31.426), train_loss = 0.73321549, grad/param norm = 2.8891e-01, time/batch = 17.5104s	
10466/16650 (epoch 31.429), train_loss = 0.93027811, grad/param norm = 2.8583e-01, time/batch = 16.4268s	
10467/16650 (epoch 31.432), train_loss = 0.92037403, grad/param norm = 3.3151e-01, time/batch = 18.3011s	
10468/16650 (epoch 31.435), train_loss = 1.01110675, grad/param norm = 2.9648e-01, time/batch = 18.1347s	
10469/16650 (epoch 31.438), train_loss = 1.01288482, grad/param norm = 3.6030e-01, time/batch = 16.1908s	
10470/16650 (epoch 31.441), train_loss = 0.81539515, grad/param norm = 3.2544e-01, time/batch = 16.8770s	
10471/16650 (epoch 31.444), train_loss = 0.80136800, grad/param norm = 3.0312e-01, time/batch = 17.1333s	
10472/16650 (epoch 31.447), train_loss = 0.77373240, grad/param norm = 2.9206e-01, time/batch = 17.1890s	
10473/16650 (epoch 31.450), train_loss = 0.79455824, grad/param norm = 2.8119e-01, time/batch = 15.8441s	
10474/16650 (epoch 31.453), train_loss = 0.76623639, grad/param norm = 2.8641e-01, time/batch = 18.8695s	
10475/16650 (epoch 31.456), train_loss = 0.73611623, grad/param norm = 2.5677e-01, time/batch = 14.9991s	
10476/16650 (epoch 31.459), train_loss = 0.77413847, grad/param norm = 3.0612e-01, time/batch = 15.5018s	
10477/16650 (epoch 31.462), train_loss = 0.94859897, grad/param norm = 3.0413e-01, time/batch = 16.6526s	
10478/16650 (epoch 31.465), train_loss = 0.77090408, grad/param norm = 2.8890e-01, time/batch = 18.0265s	
10479/16650 (epoch 31.468), train_loss = 0.64373304, grad/param norm = 2.6837e-01, time/batch = 17.8538s	
10480/16650 (epoch 31.471), train_loss = 0.55506217, grad/param norm = 2.2210e-01, time/batch = 16.9289s	
10481/16650 (epoch 31.474), train_loss = 0.70878308, grad/param norm = 2.8231e-01, time/batch = 17.7016s	
10482/16650 (epoch 31.477), train_loss = 0.89132264, grad/param norm = 2.9742e-01, time/batch = 17.2744s	
10483/16650 (epoch 31.480), train_loss = 0.87092884, grad/param norm = 3.3640e-01, time/batch = 16.1844s	
10484/16650 (epoch 31.483), train_loss = 0.90845872, grad/param norm = 3.0392e-01, time/batch = 15.8242s	
10485/16650 (epoch 31.486), train_loss = 0.72965748, grad/param norm = 2.3611e-01, time/batch = 17.9516s	
10486/16650 (epoch 31.489), train_loss = 0.77649986, grad/param norm = 2.7913e-01, time/batch = 17.4426s	
10487/16650 (epoch 31.492), train_loss = 0.82086763, grad/param norm = 2.8124e-01, time/batch = 16.9336s	
10488/16650 (epoch 31.495), train_loss = 0.72217459, grad/param norm = 2.6626e-01, time/batch = 18.8589s	
10489/16650 (epoch 31.498), train_loss = 0.79659757, grad/param norm = 3.3746e-01, time/batch = 15.9426s	
10490/16650 (epoch 31.502), train_loss = 0.97991001, grad/param norm = 3.7134e-01, time/batch = 16.4305s	
10491/16650 (epoch 31.505), train_loss = 0.84857842, grad/param norm = 2.5246e-01, time/batch = 17.5293s	
10492/16650 (epoch 31.508), train_loss = 0.86870914, grad/param norm = 3.4325e-01, time/batch = 16.3255s	
10493/16650 (epoch 31.511), train_loss = 0.92812439, grad/param norm = 2.9306e-01, time/batch = 17.1767s	
10494/16650 (epoch 31.514), train_loss = 0.71743547, grad/param norm = 2.8579e-01, time/batch = 16.5831s	
10495/16650 (epoch 31.517), train_loss = 0.80802271, grad/param norm = 3.0489e-01, time/batch = 18.6142s	
10496/16650 (epoch 31.520), train_loss = 0.72035048, grad/param norm = 2.8201e-01, time/batch = 15.8368s	
10497/16650 (epoch 31.523), train_loss = 0.80752669, grad/param norm = 2.6815e-01, time/batch = 15.6607s	
10498/16650 (epoch 31.526), train_loss = 0.89327987, grad/param norm = 3.0116e-01, time/batch = 18.6864s	
10499/16650 (epoch 31.529), train_loss = 0.94348324, grad/param norm = 3.4767e-01, time/batch = 16.9447s	
10500/16650 (epoch 31.532), train_loss = 0.63498437, grad/param norm = 2.7987e-01, time/batch = 17.8412s	
10501/16650 (epoch 31.535), train_loss = 0.72070831, grad/param norm = 3.4346e-01, time/batch = 17.5158s	
10502/16650 (epoch 31.538), train_loss = 0.67422777, grad/param norm = 3.8887e-01, time/batch = 18.0252s	
10503/16650 (epoch 31.541), train_loss = 0.98612748, grad/param norm = 3.8235e-01, time/batch = 17.5657s	
10504/16650 (epoch 31.544), train_loss = 0.99085753, grad/param norm = 4.2477e-01, time/batch = 16.0066s	
10505/16650 (epoch 31.547), train_loss = 0.72399131, grad/param norm = 2.6599e-01, time/batch = 17.6953s	
10506/16650 (epoch 31.550), train_loss = 0.80554404, grad/param norm = 2.7819e-01, time/batch = 17.8634s	
10507/16650 (epoch 31.553), train_loss = 0.81254316, grad/param norm = 2.9315e-01, time/batch = 16.7552s	
10508/16650 (epoch 31.556), train_loss = 0.73409553, grad/param norm = 2.4240e-01, time/batch = 17.6016s	
10509/16650 (epoch 31.559), train_loss = 0.66454973, grad/param norm = 2.8417e-01, time/batch = 17.6071s	
10510/16650 (epoch 31.562), train_loss = 0.77251682, grad/param norm = 2.8594e-01, time/batch = 15.1639s	
10511/16650 (epoch 31.565), train_loss = 0.66481137, grad/param norm = 3.0322e-01, time/batch = 16.5825s	
10512/16650 (epoch 31.568), train_loss = 0.65338680, grad/param norm = 2.4205e-01, time/batch = 17.6172s	
10513/16650 (epoch 31.571), train_loss = 0.70939167, grad/param norm = 2.8910e-01, time/batch = 17.6228s	
10514/16650 (epoch 31.574), train_loss = 0.75118545, grad/param norm = 2.9806e-01, time/batch = 17.4217s	
10515/16650 (epoch 31.577), train_loss = 0.77183256, grad/param norm = 2.8962e-01, time/batch = 17.0369s	
10516/16650 (epoch 31.580), train_loss = 0.68194920, grad/param norm = 2.3348e-01, time/batch = 18.7851s	
10517/16650 (epoch 31.583), train_loss = 0.81193924, grad/param norm = 2.8230e-01, time/batch = 14.5591s	
10518/16650 (epoch 31.586), train_loss = 0.73036838, grad/param norm = 3.5508e-01, time/batch = 15.0399s	
10519/16650 (epoch 31.589), train_loss = 0.71036305, grad/param norm = 2.6939e-01, time/batch = 17.9567s	
10520/16650 (epoch 31.592), train_loss = 0.82193795, grad/param norm = 3.2233e-01, time/batch = 18.7825s	
10521/16650 (epoch 31.595), train_loss = 0.73799464, grad/param norm = 2.9181e-01, time/batch = 17.1944s	
10522/16650 (epoch 31.598), train_loss = 0.78959448, grad/param norm = 3.1733e-01, time/batch = 15.1748s	
10523/16650 (epoch 31.601), train_loss = 0.75458334, grad/param norm = 3.2965e-01, time/batch = 16.2524s	
10524/16650 (epoch 31.604), train_loss = 0.83411172, grad/param norm = 3.0177e-01, time/batch = 18.7843s	
10525/16650 (epoch 31.607), train_loss = 0.87565272, grad/param norm = 2.8262e-01, time/batch = 16.5053s	
10526/16650 (epoch 31.610), train_loss = 0.72032060, grad/param norm = 2.7489e-01, time/batch = 17.7966s	
10527/16650 (epoch 31.613), train_loss = 0.94726293, grad/param norm = 3.9710e-01, time/batch = 16.8695s	
10528/16650 (epoch 31.616), train_loss = 0.91204348, grad/param norm = 3.6336e-01, time/batch = 17.0163s	
10529/16650 (epoch 31.619), train_loss = 0.68642299, grad/param norm = 2.5396e-01, time/batch = 17.8630s	
10530/16650 (epoch 31.622), train_loss = 0.64941915, grad/param norm = 2.6608e-01, time/batch = 18.6332s	
10531/16650 (epoch 31.625), train_loss = 0.78469895, grad/param norm = 2.9499e-01, time/batch = 16.4298s	
10532/16650 (epoch 31.628), train_loss = 0.73760219, grad/param norm = 2.7887e-01, time/batch = 16.2537s	
10533/16650 (epoch 31.631), train_loss = 0.80140166, grad/param norm = 2.9238e-01, time/batch = 17.0965s	
10534/16650 (epoch 31.634), train_loss = 0.97065150, grad/param norm = 3.2136e-01, time/batch = 16.0017s	
10535/16650 (epoch 31.637), train_loss = 0.98052850, grad/param norm = 2.9346e-01, time/batch = 15.7604s	
10536/16650 (epoch 31.640), train_loss = 0.76931391, grad/param norm = 2.8198e-01, time/batch = 16.0047s	
10537/16650 (epoch 31.643), train_loss = 0.87434311, grad/param norm = 2.8240e-01, time/batch = 18.7863s	
10538/16650 (epoch 31.646), train_loss = 0.85543284, grad/param norm = 3.1054e-01, time/batch = 17.8574s	
10539/16650 (epoch 31.649), train_loss = 0.84657386, grad/param norm = 3.6534e-01, time/batch = 16.0039s	
10540/16650 (epoch 31.652), train_loss = 0.90995906, grad/param norm = 3.4720e-01, time/batch = 18.4557s	
10541/16650 (epoch 31.655), train_loss = 0.82529327, grad/param norm = 2.9550e-01, time/batch = 18.7058s	
10542/16650 (epoch 31.658), train_loss = 0.71919272, grad/param norm = 2.5872e-01, time/batch = 16.6833s	
10543/16650 (epoch 31.661), train_loss = 0.82786029, grad/param norm = 3.0614e-01, time/batch = 17.0402s	
10544/16650 (epoch 31.664), train_loss = 0.82853344, grad/param norm = 3.3385e-01, time/batch = 15.1525s	
10545/16650 (epoch 31.667), train_loss = 0.91790900, grad/param norm = 3.0791e-01, time/batch = 17.8514s	
10546/16650 (epoch 31.670), train_loss = 0.69700145, grad/param norm = 2.6864e-01, time/batch = 16.3494s	
10547/16650 (epoch 31.673), train_loss = 0.73802126, grad/param norm = 2.9909e-01, time/batch = 15.2371s	
10548/16650 (epoch 31.676), train_loss = 0.85223153, grad/param norm = 2.8991e-01, time/batch = 17.4485s	
10549/16650 (epoch 31.679), train_loss = 0.71789158, grad/param norm = 2.7634e-01, time/batch = 17.3456s	
10550/16650 (epoch 31.682), train_loss = 0.80033308, grad/param norm = 2.7390e-01, time/batch = 16.7943s	
10551/16650 (epoch 31.685), train_loss = 0.69592767, grad/param norm = 2.6657e-01, time/batch = 16.6817s	
10552/16650 (epoch 31.688), train_loss = 0.87741828, grad/param norm = 2.8423e-01, time/batch = 18.1152s	
10553/16650 (epoch 31.691), train_loss = 0.85392668, grad/param norm = 2.8476e-01, time/batch = 15.8282s	
10554/16650 (epoch 31.694), train_loss = 0.74637804, grad/param norm = 2.7834e-01, time/batch = 17.5323s	
10555/16650 (epoch 31.697), train_loss = 0.67803469, grad/param norm = 2.4926e-01, time/batch = 16.9343s	
10556/16650 (epoch 31.700), train_loss = 0.85720715, grad/param norm = 3.0057e-01, time/batch = 17.2655s	
10557/16650 (epoch 31.703), train_loss = 0.73065101, grad/param norm = 3.2305e-01, time/batch = 15.7538s	
10558/16650 (epoch 31.706), train_loss = 0.78895367, grad/param norm = 3.0363e-01, time/batch = 17.4339s	
10559/16650 (epoch 31.709), train_loss = 0.70562178, grad/param norm = 2.9736e-01, time/batch = 18.1167s	
10560/16650 (epoch 31.712), train_loss = 0.73678209, grad/param norm = 3.0410e-01, time/batch = 16.2540s	
10561/16650 (epoch 31.715), train_loss = 0.85574380, grad/param norm = 2.9010e-01, time/batch = 17.6239s	
10562/16650 (epoch 31.718), train_loss = 0.88371404, grad/param norm = 3.0339e-01, time/batch = 17.7910s	
10563/16650 (epoch 31.721), train_loss = 0.86446541, grad/param norm = 2.7414e-01, time/batch = 16.7438s	
10564/16650 (epoch 31.724), train_loss = 0.87564730, grad/param norm = 2.8653e-01, time/batch = 14.6766s	
10565/16650 (epoch 31.727), train_loss = 0.89351249, grad/param norm = 2.8737e-01, time/batch = 16.2549s	
10566/16650 (epoch 31.730), train_loss = 0.74197910, grad/param norm = 2.7272e-01, time/batch = 18.2596s	
10567/16650 (epoch 31.733), train_loss = 0.89096331, grad/param norm = 2.9718e-01, time/batch = 15.6716s	
10568/16650 (epoch 31.736), train_loss = 0.69328354, grad/param norm = 2.7922e-01, time/batch = 18.0322s	
10569/16650 (epoch 31.739), train_loss = 0.81973647, grad/param norm = 2.8262e-01, time/batch = 18.1082s	
10570/16650 (epoch 31.742), train_loss = 0.80414328, grad/param norm = 2.7564e-01, time/batch = 17.3461s	
10571/16650 (epoch 31.745), train_loss = 0.62335943, grad/param norm = 2.4002e-01, time/batch = 17.2668s	
10572/16650 (epoch 31.748), train_loss = 0.69884638, grad/param norm = 2.7380e-01, time/batch = 17.1895s	
10573/16650 (epoch 31.751), train_loss = 0.81313082, grad/param norm = 3.8311e-01, time/batch = 17.3524s	
10574/16650 (epoch 31.754), train_loss = 0.98920187, grad/param norm = 3.8906e-01, time/batch = 15.8806s	
10575/16650 (epoch 31.757), train_loss = 0.94708313, grad/param norm = 3.0485e-01, time/batch = 17.6945s	
10576/16650 (epoch 31.760), train_loss = 0.81835816, grad/param norm = 2.8577e-01, time/batch = 18.6986s	
10577/16650 (epoch 31.763), train_loss = 0.76589745, grad/param norm = 2.7046e-01, time/batch = 16.4386s	
10578/16650 (epoch 31.766), train_loss = 0.78138529, grad/param norm = 2.5857e-01, time/batch = 16.9336s	
10579/16650 (epoch 31.769), train_loss = 0.84221088, grad/param norm = 2.7137e-01, time/batch = 18.1182s	
10580/16650 (epoch 31.772), train_loss = 0.78412278, grad/param norm = 2.2409e-01, time/batch = 16.4379s	
10581/16650 (epoch 31.775), train_loss = 0.79231203, grad/param norm = 2.5578e-01, time/batch = 16.1555s	
10582/16650 (epoch 31.778), train_loss = 0.81497508, grad/param norm = 2.6674e-01, time/batch = 17.6149s	
10583/16650 (epoch 31.781), train_loss = 0.94435087, grad/param norm = 2.6187e-01, time/batch = 18.9648s	
10584/16650 (epoch 31.784), train_loss = 0.83561646, grad/param norm = 2.7442e-01, time/batch = 16.7776s	
10585/16650 (epoch 31.787), train_loss = 0.86997515, grad/param norm = 2.8050e-01, time/batch = 14.9690s	
10586/16650 (epoch 31.790), train_loss = 0.87764874, grad/param norm = 2.8390e-01, time/batch = 18.4327s	
10587/16650 (epoch 31.793), train_loss = 0.70141441, grad/param norm = 2.5899e-01, time/batch = 18.1969s	
10588/16650 (epoch 31.796), train_loss = 1.06678038, grad/param norm = 3.3511e-01, time/batch = 16.0720s	
10589/16650 (epoch 31.799), train_loss = 0.97121548, grad/param norm = 2.9586e-01, time/batch = 18.1041s	
10590/16650 (epoch 31.802), train_loss = 0.89113180, grad/param norm = 2.9201e-01, time/batch = 17.5209s	
10591/16650 (epoch 31.805), train_loss = 0.82068201, grad/param norm = 2.5478e-01, time/batch = 17.0278s	
10592/16650 (epoch 31.808), train_loss = 0.89709509, grad/param norm = 2.7356e-01, time/batch = 17.7777s	
10593/16650 (epoch 31.811), train_loss = 0.92065667, grad/param norm = 2.5712e-01, time/batch = 17.2748s	
10594/16650 (epoch 31.814), train_loss = 0.72269895, grad/param norm = 2.3488e-01, time/batch = 15.0064s	
10595/16650 (epoch 31.817), train_loss = 0.76860548, grad/param norm = 2.9339e-01, time/batch = 17.2742s	
10596/16650 (epoch 31.820), train_loss = 0.85455354, grad/param norm = 2.8929e-01, time/batch = 17.1223s	
10597/16650 (epoch 31.823), train_loss = 0.81415793, grad/param norm = 2.8289e-01, time/batch = 17.6254s	
10598/16650 (epoch 31.826), train_loss = 0.77823750, grad/param norm = 2.7639e-01, time/batch = 16.5155s	
10599/16650 (epoch 31.829), train_loss = 0.82996516, grad/param norm = 2.8453e-01, time/batch = 16.7751s	
10600/16650 (epoch 31.832), train_loss = 0.88002753, grad/param norm = 2.7681e-01, time/batch = 16.6186s	
10601/16650 (epoch 31.835), train_loss = 0.87436468, grad/param norm = 2.9978e-01, time/batch = 18.4479s	
10602/16650 (epoch 31.838), train_loss = 0.73831905, grad/param norm = 2.4680e-01, time/batch = 32.5493s	
10603/16650 (epoch 31.841), train_loss = 0.74162115, grad/param norm = 2.5017e-01, time/batch = 16.9277s	
10604/16650 (epoch 31.844), train_loss = 0.75478750, grad/param norm = 2.5205e-01, time/batch = 16.2726s	
10605/16650 (epoch 31.847), train_loss = 0.88050027, grad/param norm = 2.8591e-01, time/batch = 16.0054s	
10606/16650 (epoch 31.850), train_loss = 0.70961271, grad/param norm = 2.7044e-01, time/batch = 18.6071s	
10607/16650 (epoch 31.853), train_loss = 0.80098870, grad/param norm = 2.6643e-01, time/batch = 17.7819s	
10608/16650 (epoch 31.856), train_loss = 0.75144903, grad/param norm = 2.5012e-01, time/batch = 15.7166s	
10609/16650 (epoch 31.859), train_loss = 0.92146365, grad/param norm = 3.0438e-01, time/batch = 18.1936s	
10610/16650 (epoch 31.862), train_loss = 0.79687881, grad/param norm = 2.5819e-01, time/batch = 18.2098s	
10611/16650 (epoch 31.865), train_loss = 0.64678870, grad/param norm = 2.2830e-01, time/batch = 16.2602s	
10612/16650 (epoch 31.868), train_loss = 0.85498273, grad/param norm = 2.8281e-01, time/batch = 16.9441s	
10613/16650 (epoch 31.871), train_loss = 0.86797940, grad/param norm = 2.9698e-01, time/batch = 18.0435s	
10614/16650 (epoch 31.874), train_loss = 0.86043138, grad/param norm = 2.7899e-01, time/batch = 18.1039s	
10615/16650 (epoch 31.877), train_loss = 0.83182333, grad/param norm = 2.7381e-01, time/batch = 15.8869s	
10616/16650 (epoch 31.880), train_loss = 0.73643732, grad/param norm = 3.0450e-01, time/batch = 16.8428s	
10617/16650 (epoch 31.883), train_loss = 0.83764867, grad/param norm = 2.7927e-01, time/batch = 17.8547s	
10618/16650 (epoch 31.886), train_loss = 0.83939529, grad/param norm = 2.6400e-01, time/batch = 16.3236s	
10619/16650 (epoch 31.889), train_loss = 0.68680107, grad/param norm = 2.7731e-01, time/batch = 16.4104s	
10620/16650 (epoch 31.892), train_loss = 0.80543495, grad/param norm = 2.3910e-01, time/batch = 18.0253s	
10621/16650 (epoch 31.895), train_loss = 0.83957199, grad/param norm = 2.6823e-01, time/batch = 18.8717s	
10622/16650 (epoch 31.898), train_loss = 0.82143941, grad/param norm = 2.6748e-01, time/batch = 15.9964s	
10623/16650 (epoch 31.901), train_loss = 0.78834542, grad/param norm = 2.8086e-01, time/batch = 19.0426s	
10624/16650 (epoch 31.904), train_loss = 0.76615393, grad/param norm = 3.0951e-01, time/batch = 18.2910s	
10625/16650 (epoch 31.907), train_loss = 0.83312590, grad/param norm = 2.8221e-01, time/batch = 16.9469s	
10626/16650 (epoch 31.910), train_loss = 0.85683636, grad/param norm = 2.9372e-01, time/batch = 17.5148s	
10627/16650 (epoch 31.913), train_loss = 0.77379797, grad/param norm = 3.0497e-01, time/batch = 17.6178s	
10628/16650 (epoch 31.916), train_loss = 0.78114345, grad/param norm = 3.1917e-01, time/batch = 17.4467s	
10629/16650 (epoch 31.919), train_loss = 0.96128223, grad/param norm = 2.9630e-01, time/batch = 17.1991s	
10630/16650 (epoch 31.922), train_loss = 0.86425468, grad/param norm = 3.2178e-01, time/batch = 17.6019s	
10631/16650 (epoch 31.925), train_loss = 0.76399457, grad/param norm = 2.9619e-01, time/batch = 17.0959s	
10632/16650 (epoch 31.928), train_loss = 0.80443871, grad/param norm = 2.6742e-01, time/batch = 15.5093s	
10633/16650 (epoch 31.931), train_loss = 0.86115367, grad/param norm = 3.2648e-01, time/batch = 16.7741s	
10634/16650 (epoch 31.934), train_loss = 0.71598286, grad/param norm = 3.5852e-01, time/batch = 18.5370s	
10635/16650 (epoch 31.937), train_loss = 0.74246915, grad/param norm = 3.0427e-01, time/batch = 16.0067s	
10636/16650 (epoch 31.940), train_loss = 0.79797870, grad/param norm = 2.7142e-01, time/batch = 17.0020s	
10637/16650 (epoch 31.943), train_loss = 0.82058779, grad/param norm = 2.9054e-01, time/batch = 16.9317s	
10638/16650 (epoch 31.946), train_loss = 0.75595120, grad/param norm = 2.9304e-01, time/batch = 14.2528s	
10639/16650 (epoch 31.949), train_loss = 0.71178117, grad/param norm = 3.0116e-01, time/batch = 17.2791s	
10640/16650 (epoch 31.952), train_loss = 0.68569387, grad/param norm = 2.8998e-01, time/batch = 16.5879s	
10641/16650 (epoch 31.955), train_loss = 0.80217695, grad/param norm = 2.8371e-01, time/batch = 16.7669s	
10642/16650 (epoch 31.958), train_loss = 0.88323373, grad/param norm = 3.6200e-01, time/batch = 18.3665s	
10643/16650 (epoch 31.961), train_loss = 0.80915372, grad/param norm = 2.6646e-01, time/batch = 16.8452s	
10644/16650 (epoch 31.964), train_loss = 0.71066571, grad/param norm = 2.7986e-01, time/batch = 18.4522s	
10645/16650 (epoch 31.967), train_loss = 0.94996507, grad/param norm = 3.0044e-01, time/batch = 18.0322s	
10646/16650 (epoch 31.970), train_loss = 0.76187958, grad/param norm = 2.6005e-01, time/batch = 15.7468s	
10647/16650 (epoch 31.973), train_loss = 0.77139973, grad/param norm = 3.0700e-01, time/batch = 17.9331s	
10648/16650 (epoch 31.976), train_loss = 0.73361968, grad/param norm = 2.5366e-01, time/batch = 18.2021s	
10649/16650 (epoch 31.979), train_loss = 0.83568802, grad/param norm = 3.1046e-01, time/batch = 17.0096s	
10650/16650 (epoch 31.982), train_loss = 0.86401930, grad/param norm = 2.6850e-01, time/batch = 17.0915s	
10651/16650 (epoch 31.985), train_loss = 0.77681337, grad/param norm = 2.5863e-01, time/batch = 18.7855s	
10652/16650 (epoch 31.988), train_loss = 0.86545006, grad/param norm = 3.3722e-01, time/batch = 17.3624s	
10653/16650 (epoch 31.991), train_loss = 0.74030514, grad/param norm = 3.0386e-01, time/batch = 16.0013s	
10654/16650 (epoch 31.994), train_loss = 0.74679275, grad/param norm = 2.5903e-01, time/batch = 17.9536s	
10655/16650 (epoch 31.997), train_loss = 0.79014437, grad/param norm = 2.8728e-01, time/batch = 17.3678s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
10656/16650 (epoch 32.000), train_loss = 0.87316215, grad/param norm = 4.2274e-01, time/batch = 17.9399s	
10657/16650 (epoch 32.003), train_loss = 0.93283034, grad/param norm = 3.6804e-01, time/batch = 16.1846s	
10658/16650 (epoch 32.006), train_loss = 0.90179603, grad/param norm = 2.9374e-01, time/batch = 18.5995s	
10659/16650 (epoch 32.009), train_loss = 0.95982665, grad/param norm = 2.9844e-01, time/batch = 18.2110s	
10660/16650 (epoch 32.012), train_loss = 0.92563124, grad/param norm = 2.9335e-01, time/batch = 15.9194s	
10661/16650 (epoch 32.015), train_loss = 0.81492495, grad/param norm = 3.1997e-01, time/batch = 15.6713s	
10662/16650 (epoch 32.018), train_loss = 0.68807360, grad/param norm = 2.5446e-01, time/batch = 18.5289s	
10663/16650 (epoch 32.021), train_loss = 0.93431739, grad/param norm = 3.4885e-01, time/batch = 15.9267s	
10664/16650 (epoch 32.024), train_loss = 0.80133197, grad/param norm = 2.7634e-01, time/batch = 16.3377s	
10665/16650 (epoch 32.027), train_loss = 0.86452924, grad/param norm = 2.9335e-01, time/batch = 16.2490s	
10666/16650 (epoch 32.030), train_loss = 0.71102261, grad/param norm = 2.4796e-01, time/batch = 17.5344s	
10667/16650 (epoch 32.033), train_loss = 0.82852415, grad/param norm = 2.7946e-01, time/batch = 15.7490s	
10668/16650 (epoch 32.036), train_loss = 0.59430897, grad/param norm = 2.8808e-01, time/batch = 18.4523s	
10669/16650 (epoch 32.039), train_loss = 0.91918170, grad/param norm = 2.7286e-01, time/batch = 17.4530s	
10670/16650 (epoch 32.042), train_loss = 0.86355404, grad/param norm = 3.3661e-01, time/batch = 16.4283s	
10671/16650 (epoch 32.045), train_loss = 0.78688714, grad/param norm = 2.5221e-01, time/batch = 17.5161s	
10672/16650 (epoch 32.048), train_loss = 0.88832112, grad/param norm = 3.2048e-01, time/batch = 18.2080s	
10673/16650 (epoch 32.051), train_loss = 0.78063676, grad/param norm = 2.7544e-01, time/batch = 14.4126s	
10674/16650 (epoch 32.054), train_loss = 0.79696702, grad/param norm = 2.7306e-01, time/batch = 16.5292s	
10675/16650 (epoch 32.057), train_loss = 0.82704516, grad/param norm = 2.8616e-01, time/batch = 16.9534s	
10676/16650 (epoch 32.060), train_loss = 0.68591475, grad/param norm = 2.4248e-01, time/batch = 17.4318s	
10677/16650 (epoch 32.063), train_loss = 0.77464099, grad/param norm = 2.6690e-01, time/batch = 17.3443s	
10678/16650 (epoch 32.066), train_loss = 0.96163428, grad/param norm = 2.9490e-01, time/batch = 17.5285s	
10679/16650 (epoch 32.069), train_loss = 0.87496914, grad/param norm = 2.8871e-01, time/batch = 18.2884s	
10680/16650 (epoch 32.072), train_loss = 0.83730664, grad/param norm = 3.0445e-01, time/batch = 15.0645s	
10681/16650 (epoch 32.075), train_loss = 0.88706821, grad/param norm = 2.6809e-01, time/batch = 16.1737s	
10682/16650 (epoch 32.078), train_loss = 0.90969623, grad/param norm = 2.8551e-01, time/batch = 17.1877s	
10683/16650 (epoch 32.081), train_loss = 0.85594921, grad/param norm = 3.4952e-01, time/batch = 18.1866s	
10684/16650 (epoch 32.084), train_loss = 0.87460480, grad/param norm = 3.2487e-01, time/batch = 16.5056s	
10685/16650 (epoch 32.087), train_loss = 0.85349019, grad/param norm = 3.2530e-01, time/batch = 17.6203s	
10686/16650 (epoch 32.090), train_loss = 0.80486451, grad/param norm = 2.9308e-01, time/batch = 17.7863s	
10687/16650 (epoch 32.093), train_loss = 0.97281818, grad/param norm = 3.6602e-01, time/batch = 17.6248s	
10688/16650 (epoch 32.096), train_loss = 0.78200515, grad/param norm = 2.8132e-01, time/batch = 9.2687s	
10689/16650 (epoch 32.099), train_loss = 0.86326773, grad/param norm = 3.0622e-01, time/batch = 0.6464s	
10690/16650 (epoch 32.102), train_loss = 0.82208736, grad/param norm = 2.7865e-01, time/batch = 0.6504s	
10691/16650 (epoch 32.105), train_loss = 0.84519246, grad/param norm = 2.9683e-01, time/batch = 0.6506s	
10692/16650 (epoch 32.108), train_loss = 0.85530191, grad/param norm = 3.3049e-01, time/batch = 0.6472s	
10693/16650 (epoch 32.111), train_loss = 0.94374244, grad/param norm = 3.0500e-01, time/batch = 0.6605s	
10694/16650 (epoch 32.114), train_loss = 0.89500496, grad/param norm = 3.7038e-01, time/batch = 0.6615s	
10695/16650 (epoch 32.117), train_loss = 0.97971083, grad/param norm = 2.8817e-01, time/batch = 0.6622s	
10696/16650 (epoch 32.120), train_loss = 0.79304236, grad/param norm = 2.4869e-01, time/batch = 0.9118s	
10697/16650 (epoch 32.123), train_loss = 0.83026262, grad/param norm = 2.9995e-01, time/batch = 0.9579s	
10698/16650 (epoch 32.126), train_loss = 0.84440227, grad/param norm = 2.6379e-01, time/batch = 0.9482s	
10699/16650 (epoch 32.129), train_loss = 0.85690071, grad/param norm = 2.9632e-01, time/batch = 0.9534s	
10700/16650 (epoch 32.132), train_loss = 0.82222074, grad/param norm = 2.7834e-01, time/batch = 0.9643s	
10701/16650 (epoch 32.135), train_loss = 0.90429830, grad/param norm = 2.7685e-01, time/batch = 1.4354s	
10702/16650 (epoch 32.138), train_loss = 0.90471493, grad/param norm = 2.8517e-01, time/batch = 1.8235s	
10703/16650 (epoch 32.141), train_loss = 0.89025706, grad/param norm = 3.3097e-01, time/batch = 1.7527s	
10704/16650 (epoch 32.144), train_loss = 0.85763175, grad/param norm = 2.8734e-01, time/batch = 15.2220s	
10705/16650 (epoch 32.147), train_loss = 0.95237447, grad/param norm = 3.2104e-01, time/batch = 18.6276s	
10706/16650 (epoch 32.150), train_loss = 1.08799116, grad/param norm = 3.7612e-01, time/batch = 15.9262s	
10707/16650 (epoch 32.153), train_loss = 0.88918533, grad/param norm = 3.2679e-01, time/batch = 14.9165s	
10708/16650 (epoch 32.156), train_loss = 0.80822765, grad/param norm = 2.8774e-01, time/batch = 17.1064s	
10709/16650 (epoch 32.159), train_loss = 0.88701875, grad/param norm = 2.7351e-01, time/batch = 16.9432s	
10710/16650 (epoch 32.162), train_loss = 0.95754148, grad/param norm = 2.7564e-01, time/batch = 16.0808s	
10711/16650 (epoch 32.165), train_loss = 0.95460108, grad/param norm = 3.1238e-01, time/batch = 18.2864s	
10712/16650 (epoch 32.168), train_loss = 0.70884660, grad/param norm = 2.3698e-01, time/batch = 18.3812s	
10713/16650 (epoch 32.171), train_loss = 0.90001328, grad/param norm = 2.8803e-01, time/batch = 15.9321s	
10714/16650 (epoch 32.174), train_loss = 0.69934456, grad/param norm = 2.7205e-01, time/batch = 16.9408s	
10715/16650 (epoch 32.177), train_loss = 0.84665839, grad/param norm = 3.0822e-01, time/batch = 17.6934s	
10716/16650 (epoch 32.180), train_loss = 0.93571972, grad/param norm = 2.7894e-01, time/batch = 16.7653s	
10717/16650 (epoch 32.183), train_loss = 1.08068824, grad/param norm = 3.3760e-01, time/batch = 16.3932s	
10718/16650 (epoch 32.186), train_loss = 0.89088537, grad/param norm = 3.3137e-01, time/batch = 17.8629s	
10719/16650 (epoch 32.189), train_loss = 0.77778095, grad/param norm = 2.5604e-01, time/batch = 18.6194s	
10720/16650 (epoch 32.192), train_loss = 0.81866840, grad/param norm = 2.9572e-01, time/batch = 15.3114s	
10721/16650 (epoch 32.195), train_loss = 0.76195359, grad/param norm = 2.6304e-01, time/batch = 17.4417s	
10722/16650 (epoch 32.198), train_loss = 0.71876634, grad/param norm = 2.4415e-01, time/batch = 18.2041s	
10723/16650 (epoch 32.201), train_loss = 0.73174026, grad/param norm = 2.4657e-01, time/batch = 17.5195s	
10724/16650 (epoch 32.204), train_loss = 0.85798803, grad/param norm = 2.9528e-01, time/batch = 18.2728s	
10725/16650 (epoch 32.207), train_loss = 0.88364954, grad/param norm = 3.5886e-01, time/batch = 16.1618s	
10726/16650 (epoch 32.210), train_loss = 0.81915159, grad/param norm = 2.7517e-01, time/batch = 16.9142s	
10727/16650 (epoch 32.213), train_loss = 0.89753656, grad/param norm = 2.9778e-01, time/batch = 16.7663s	
10728/16650 (epoch 32.216), train_loss = 0.80154041, grad/param norm = 2.9086e-01, time/batch = 17.6159s	
10729/16650 (epoch 32.219), train_loss = 0.81934464, grad/param norm = 2.6928e-01, time/batch = 17.7833s	
10730/16650 (epoch 32.222), train_loss = 0.86680181, grad/param norm = 2.7732e-01, time/batch = 15.4337s	
10731/16650 (epoch 32.225), train_loss = 0.84427803, grad/param norm = 3.0899e-01, time/batch = 18.0261s	
10732/16650 (epoch 32.228), train_loss = 0.75919240, grad/param norm = 2.7332e-01, time/batch = 15.3104s	
10733/16650 (epoch 32.231), train_loss = 0.77646087, grad/param norm = 2.8164e-01, time/batch = 17.6264s	
10734/16650 (epoch 32.234), train_loss = 0.99411497, grad/param norm = 2.7234e-01, time/batch = 16.1706s	
10735/16650 (epoch 32.237), train_loss = 0.86586375, grad/param norm = 3.5198e-01, time/batch = 18.1986s	
10736/16650 (epoch 32.240), train_loss = 0.85565176, grad/param norm = 2.7567e-01, time/batch = 17.9285s	
10737/16650 (epoch 32.243), train_loss = 0.83953284, grad/param norm = 3.1419e-01, time/batch = 16.7745s	
10738/16650 (epoch 32.246), train_loss = 0.96357055, grad/param norm = 3.3892e-01, time/batch = 16.8317s	
10739/16650 (epoch 32.249), train_loss = 0.70931443, grad/param norm = 2.4723e-01, time/batch = 18.6110s	
10740/16650 (epoch 32.252), train_loss = 0.81221031, grad/param norm = 3.1413e-01, time/batch = 19.0497s	
10741/16650 (epoch 32.255), train_loss = 0.86318411, grad/param norm = 2.7133e-01, time/batch = 16.0832s	
10742/16650 (epoch 32.258), train_loss = 0.91417313, grad/param norm = 2.8249e-01, time/batch = 18.5298s	
10743/16650 (epoch 32.261), train_loss = 0.87187425, grad/param norm = 2.8410e-01, time/batch = 16.3472s	
10744/16650 (epoch 32.264), train_loss = 0.79709414, grad/param norm = 2.7306e-01, time/batch = 15.6439s	
10745/16650 (epoch 32.267), train_loss = 0.81563394, grad/param norm = 3.3500e-01, time/batch = 17.2672s	
10746/16650 (epoch 32.270), train_loss = 0.88315751, grad/param norm = 2.8913e-01, time/batch = 18.6145s	
10747/16650 (epoch 32.273), train_loss = 0.94801185, grad/param norm = 2.8310e-01, time/batch = 17.9259s	
10748/16650 (epoch 32.276), train_loss = 0.86658471, grad/param norm = 2.8312e-01, time/batch = 15.0652s	
10749/16650 (epoch 32.279), train_loss = 0.82074702, grad/param norm = 2.9367e-01, time/batch = 17.6758s	
10750/16650 (epoch 32.282), train_loss = 0.75924770, grad/param norm = 2.4871e-01, time/batch = 17.6080s	
10751/16650 (epoch 32.285), train_loss = 0.77529247, grad/param norm = 2.7604e-01, time/batch = 16.7640s	
10752/16650 (epoch 32.288), train_loss = 0.75311536, grad/param norm = 2.7021e-01, time/batch = 18.2893s	
10753/16650 (epoch 32.291), train_loss = 0.61617768, grad/param norm = 2.1857e-01, time/batch = 16.6164s	
10754/16650 (epoch 32.294), train_loss = 0.73022856, grad/param norm = 2.4238e-01, time/batch = 18.5345s	
10755/16650 (epoch 32.297), train_loss = 0.80942193, grad/param norm = 2.4893e-01, time/batch = 16.1709s	
10756/16650 (epoch 32.300), train_loss = 0.65099863, grad/param norm = 2.3188e-01, time/batch = 16.1720s	
10757/16650 (epoch 32.303), train_loss = 0.71468075, grad/param norm = 2.5362e-01, time/batch = 18.1143s	
10758/16650 (epoch 32.306), train_loss = 0.88894794, grad/param norm = 2.5325e-01, time/batch = 16.7754s	
10759/16650 (epoch 32.309), train_loss = 0.89864603, grad/param norm = 2.9014e-01, time/batch = 17.9545s	
10760/16650 (epoch 32.312), train_loss = 0.70637980, grad/param norm = 2.6751e-01, time/batch = 16.4502s	
10761/16650 (epoch 32.315), train_loss = 0.60114903, grad/param norm = 2.0142e-01, time/batch = 18.5133s	
10762/16650 (epoch 32.318), train_loss = 0.69157507, grad/param norm = 2.4434e-01, time/batch = 17.6056s	
10763/16650 (epoch 32.321), train_loss = 0.92578694, grad/param norm = 3.3118e-01, time/batch = 18.3711s	
10764/16650 (epoch 32.324), train_loss = 0.75640953, grad/param norm = 4.2901e-01, time/batch = 17.1560s	
10765/16650 (epoch 32.327), train_loss = 0.86540384, grad/param norm = 3.0905e-01, time/batch = 14.9947s	
10766/16650 (epoch 32.330), train_loss = 0.85067157, grad/param norm = 3.2321e-01, time/batch = 17.0276s	
10767/16650 (epoch 32.333), train_loss = 0.87743914, grad/param norm = 3.0767e-01, time/batch = 17.0357s	
10768/16650 (epoch 32.336), train_loss = 0.73900981, grad/param norm = 3.1208e-01, time/batch = 17.4591s	
10769/16650 (epoch 32.339), train_loss = 0.76098882, grad/param norm = 2.9682e-01, time/batch = 16.0950s	
10770/16650 (epoch 32.342), train_loss = 0.72360665, grad/param norm = 2.9343e-01, time/batch = 17.5312s	
10771/16650 (epoch 32.345), train_loss = 0.70230306, grad/param norm = 2.0820e-01, time/batch = 17.3585s	
10772/16650 (epoch 32.348), train_loss = 0.82491154, grad/param norm = 3.1579e-01, time/batch = 15.4214s	
10773/16650 (epoch 32.351), train_loss = 0.85739596, grad/param norm = 2.6047e-01, time/batch = 17.8716s	
10774/16650 (epoch 32.354), train_loss = 0.88518155, grad/param norm = 2.8347e-01, time/batch = 17.5421s	
10775/16650 (epoch 32.357), train_loss = 0.86714735, grad/param norm = 3.0595e-01, time/batch = 17.5264s	
10776/16650 (epoch 32.360), train_loss = 0.82056777, grad/param norm = 2.8600e-01, time/batch = 14.5248s	
10777/16650 (epoch 32.363), train_loss = 0.91094677, grad/param norm = 2.8654e-01, time/batch = 17.2877s	
10778/16650 (epoch 32.366), train_loss = 0.96369654, grad/param norm = 3.0417e-01, time/batch = 16.5349s	
10779/16650 (epoch 32.369), train_loss = 0.84789729, grad/param norm = 2.6789e-01, time/batch = 16.4384s	
10780/16650 (epoch 32.372), train_loss = 0.84553617, grad/param norm = 2.9739e-01, time/batch = 17.6154s	
10781/16650 (epoch 32.375), train_loss = 0.85256926, grad/param norm = 2.6502e-01, time/batch = 16.9586s	
10782/16650 (epoch 32.378), train_loss = 0.78965765, grad/param norm = 2.9446e-01, time/batch = 16.3667s	
10783/16650 (epoch 32.381), train_loss = 0.86262666, grad/param norm = 2.8623e-01, time/batch = 15.1400s	
10784/16650 (epoch 32.384), train_loss = 0.96189889, grad/param norm = 2.8102e-01, time/batch = 17.8641s	
10785/16650 (epoch 32.387), train_loss = 0.65421505, grad/param norm = 2.3701e-01, time/batch = 16.7817s	
10786/16650 (epoch 32.390), train_loss = 0.90697515, grad/param norm = 2.6502e-01, time/batch = 16.5035s	
10787/16650 (epoch 32.393), train_loss = 0.78049496, grad/param norm = 2.9251e-01, time/batch = 16.2801s	
10788/16650 (epoch 32.396), train_loss = 0.93009362, grad/param norm = 3.0630e-01, time/batch = 17.2982s	
10789/16650 (epoch 32.399), train_loss = 0.87611916, grad/param norm = 2.7784e-01, time/batch = 17.7002s	
10790/16650 (epoch 32.402), train_loss = 0.79224390, grad/param norm = 3.0531e-01, time/batch = 14.7409s	
10791/16650 (epoch 32.405), train_loss = 0.67893916, grad/param norm = 3.3862e-01, time/batch = 15.9128s	
10792/16650 (epoch 32.408), train_loss = 0.85674189, grad/param norm = 3.4764e-01, time/batch = 16.8617s	
10793/16650 (epoch 32.411), train_loss = 0.73994040, grad/param norm = 3.0932e-01, time/batch = 17.7763s	
10794/16650 (epoch 32.414), train_loss = 0.75390728, grad/param norm = 3.7876e-01, time/batch = 16.0928s	
10795/16650 (epoch 32.417), train_loss = 0.73028275, grad/param norm = 2.9972e-01, time/batch = 17.2824s	
10796/16650 (epoch 32.420), train_loss = 0.72607010, grad/param norm = 2.9378e-01, time/batch = 16.9217s	
10797/16650 (epoch 32.423), train_loss = 0.61527607, grad/param norm = 2.4454e-01, time/batch = 15.8425s	
10798/16650 (epoch 32.426), train_loss = 0.70700844, grad/param norm = 2.4990e-01, time/batch = 16.3817s	
10799/16650 (epoch 32.429), train_loss = 0.91227599, grad/param norm = 3.3699e-01, time/batch = 17.6991s	
10800/16650 (epoch 32.432), train_loss = 0.89580814, grad/param norm = 3.0291e-01, time/batch = 15.2750s	
10801/16650 (epoch 32.435), train_loss = 0.99736147, grad/param norm = 2.8675e-01, time/batch = 15.8239s	
10802/16650 (epoch 32.438), train_loss = 0.98539342, grad/param norm = 3.3722e-01, time/batch = 17.1143s	
10803/16650 (epoch 32.441), train_loss = 0.80754015, grad/param norm = 3.0455e-01, time/batch = 15.3712s	
10804/16650 (epoch 32.444), train_loss = 0.77863076, grad/param norm = 2.9285e-01, time/batch = 14.3011s	
10805/16650 (epoch 32.447), train_loss = 0.75751703, grad/param norm = 2.8591e-01, time/batch = 17.0065s	
10806/16650 (epoch 32.450), train_loss = 0.77617342, grad/param norm = 2.8900e-01, time/batch = 17.2800s	
10807/16650 (epoch 32.453), train_loss = 0.75092809, grad/param norm = 2.5413e-01, time/batch = 17.1299s	
10808/16650 (epoch 32.456), train_loss = 0.71492168, grad/param norm = 2.3498e-01, time/batch = 14.9377s	
10809/16650 (epoch 32.459), train_loss = 0.75025061, grad/param norm = 2.8524e-01, time/batch = 13.8921s	
10810/16650 (epoch 32.462), train_loss = 0.92068829, grad/param norm = 3.2159e-01, time/batch = 13.2365s	
10811/16650 (epoch 32.465), train_loss = 0.74751267, grad/param norm = 2.7745e-01, time/batch = 15.5240s	
10812/16650 (epoch 32.468), train_loss = 0.62449541, grad/param norm = 2.5766e-01, time/batch = 16.5052s	
10813/16650 (epoch 32.471), train_loss = 0.55492781, grad/param norm = 2.2777e-01, time/batch = 16.5415s	
10814/16650 (epoch 32.474), train_loss = 0.70015272, grad/param norm = 2.8019e-01, time/batch = 17.9541s	
10815/16650 (epoch 32.477), train_loss = 0.87971023, grad/param norm = 3.1568e-01, time/batch = 16.6338s	
10816/16650 (epoch 32.480), train_loss = 0.83381228, grad/param norm = 3.2503e-01, time/batch = 16.0057s	
10817/16650 (epoch 32.483), train_loss = 0.88731275, grad/param norm = 2.9303e-01, time/batch = 15.6028s	
10818/16650 (epoch 32.486), train_loss = 0.70843187, grad/param norm = 2.3749e-01, time/batch = 17.8551s	
10819/16650 (epoch 32.489), train_loss = 0.78456308, grad/param norm = 3.1950e-01, time/batch = 17.1924s	
10820/16650 (epoch 32.492), train_loss = 0.80957382, grad/param norm = 2.6552e-01, time/batch = 16.7845s	
10821/16650 (epoch 32.495), train_loss = 0.70424032, grad/param norm = 2.8046e-01, time/batch = 18.0144s	
10822/16650 (epoch 32.498), train_loss = 0.76586648, grad/param norm = 3.0744e-01, time/batch = 16.4475s	
10823/16650 (epoch 32.502), train_loss = 0.94733657, grad/param norm = 3.2558e-01, time/batch = 15.6745s	
10824/16650 (epoch 32.505), train_loss = 0.82747117, grad/param norm = 2.5771e-01, time/batch = 16.8550s	
10825/16650 (epoch 32.508), train_loss = 0.85048139, grad/param norm = 2.9516e-01, time/batch = 14.6061s	
10826/16650 (epoch 32.511), train_loss = 0.89241834, grad/param norm = 3.0075e-01, time/batch = 17.1032s	
10827/16650 (epoch 32.514), train_loss = 0.69908708, grad/param norm = 2.7185e-01, time/batch = 30.6086s	
10828/16650 (epoch 32.517), train_loss = 0.79383750, grad/param norm = 2.9242e-01, time/batch = 17.6289s	
10829/16650 (epoch 32.520), train_loss = 0.69591444, grad/param norm = 2.6287e-01, time/batch = 15.6677s	
10830/16650 (epoch 32.523), train_loss = 0.80281136, grad/param norm = 2.8440e-01, time/batch = 16.1584s	
10831/16650 (epoch 32.526), train_loss = 0.88602465, grad/param norm = 3.1845e-01, time/batch = 17.5262s	
10832/16650 (epoch 32.529), train_loss = 0.93425490, grad/param norm = 3.6605e-01, time/batch = 15.9402s	
10833/16650 (epoch 32.532), train_loss = 0.62490214, grad/param norm = 2.5942e-01, time/batch = 16.1732s	
10834/16650 (epoch 32.535), train_loss = 0.70252576, grad/param norm = 2.9587e-01, time/batch = 17.6328s	
10835/16650 (epoch 32.538), train_loss = 0.67457499, grad/param norm = 3.1501e-01, time/batch = 17.1990s	
10836/16650 (epoch 32.541), train_loss = 0.95127272, grad/param norm = 3.3629e-01, time/batch = 16.6145s	
10837/16650 (epoch 32.544), train_loss = 0.97546307, grad/param norm = 4.5611e-01, time/batch = 16.5144s	
10838/16650 (epoch 32.547), train_loss = 0.70767203, grad/param norm = 2.8860e-01, time/batch = 14.7633s	
10839/16650 (epoch 32.550), train_loss = 0.81144383, grad/param norm = 3.3268e-01, time/batch = 17.2861s	
10840/16650 (epoch 32.553), train_loss = 0.81710715, grad/param norm = 3.3305e-01, time/batch = 16.1823s	
10841/16650 (epoch 32.556), train_loss = 0.73247660, grad/param norm = 3.0477e-01, time/batch = 16.8688s	
10842/16650 (epoch 32.559), train_loss = 0.65639689, grad/param norm = 2.6220e-01, time/batch = 17.1944s	
10843/16650 (epoch 32.562), train_loss = 0.74643048, grad/param norm = 2.7010e-01, time/batch = 17.2872s	
10844/16650 (epoch 32.565), train_loss = 0.64662321, grad/param norm = 3.1579e-01, time/batch = 15.6600s	
10845/16650 (epoch 32.568), train_loss = 0.65723153, grad/param norm = 2.7795e-01, time/batch = 17.0336s	
10846/16650 (epoch 32.571), train_loss = 0.70314762, grad/param norm = 3.2295e-01, time/batch = 17.3829s	
10847/16650 (epoch 32.574), train_loss = 0.75005068, grad/param norm = 3.0283e-01, time/batch = 16.7830s	
10848/16650 (epoch 32.577), train_loss = 0.74489884, grad/param norm = 2.4852e-01, time/batch = 16.7854s	
10849/16650 (epoch 32.580), train_loss = 0.68345420, grad/param norm = 2.5459e-01, time/batch = 16.3198s	
10850/16650 (epoch 32.583), train_loss = 0.78589046, grad/param norm = 2.5429e-01, time/batch = 18.1145s	
10851/16650 (epoch 32.586), train_loss = 0.71915645, grad/param norm = 3.2187e-01, time/batch = 15.5139s	
10852/16650 (epoch 32.589), train_loss = 0.69830631, grad/param norm = 2.4862e-01, time/batch = 18.1158s	
10853/16650 (epoch 32.592), train_loss = 0.77514613, grad/param norm = 2.6099e-01, time/batch = 18.6154s	
10854/16650 (epoch 32.595), train_loss = 0.71325930, grad/param norm = 3.0275e-01, time/batch = 16.2631s	
10855/16650 (epoch 32.598), train_loss = 0.76453204, grad/param norm = 2.8688e-01, time/batch = 17.9417s	
10856/16650 (epoch 32.601), train_loss = 0.75791568, grad/param norm = 3.1495e-01, time/batch = 16.7632s	
10857/16650 (epoch 32.604), train_loss = 0.82983851, grad/param norm = 2.9206e-01, time/batch = 16.6625s	
10858/16650 (epoch 32.607), train_loss = 0.84306817, grad/param norm = 2.7916e-01, time/batch = 15.7541s	
10859/16650 (epoch 32.610), train_loss = 0.69854368, grad/param norm = 2.4564e-01, time/batch = 18.1224s	
10860/16650 (epoch 32.613), train_loss = 0.90984900, grad/param norm = 3.3541e-01, time/batch = 18.7881s	
10861/16650 (epoch 32.616), train_loss = 0.89124318, grad/param norm = 3.8403e-01, time/batch = 15.7534s	
10862/16650 (epoch 32.619), train_loss = 0.65884229, grad/param norm = 2.7325e-01, time/batch = 17.6932s	
10863/16650 (epoch 32.622), train_loss = 0.64302626, grad/param norm = 2.7228e-01, time/batch = 14.7504s	
10864/16650 (epoch 32.625), train_loss = 0.75338185, grad/param norm = 2.6830e-01, time/batch = 18.0241s	
10865/16650 (epoch 32.628), train_loss = 0.74239581, grad/param norm = 3.2999e-01, time/batch = 17.2570s	
10866/16650 (epoch 32.631), train_loss = 0.79898292, grad/param norm = 3.1123e-01, time/batch = 17.1988s	
10867/16650 (epoch 32.634), train_loss = 0.98145096, grad/param norm = 3.3439e-01, time/batch = 18.1992s	
10868/16650 (epoch 32.637), train_loss = 0.96062600, grad/param norm = 2.8623e-01, time/batch = 16.9237s	
10869/16650 (epoch 32.640), train_loss = 0.75109344, grad/param norm = 2.8721e-01, time/batch = 17.5977s	
10870/16650 (epoch 32.643), train_loss = 0.85360464, grad/param norm = 2.6670e-01, time/batch = 17.3739s	
10871/16650 (epoch 32.646), train_loss = 0.82952572, grad/param norm = 3.1478e-01, time/batch = 17.9520s	
10872/16650 (epoch 32.649), train_loss = 0.84284951, grad/param norm = 3.5224e-01, time/batch = 17.6811s	
10873/16650 (epoch 32.652), train_loss = 0.89132435, grad/param norm = 3.6162e-01, time/batch = 16.7619s	
10874/16650 (epoch 32.655), train_loss = 0.82034574, grad/param norm = 3.2125e-01, time/batch = 17.2476s	
10875/16650 (epoch 32.658), train_loss = 0.73473906, grad/param norm = 2.8509e-01, time/batch = 14.9738s	
10876/16650 (epoch 32.661), train_loss = 0.83487150, grad/param norm = 3.6591e-01, time/batch = 17.5936s	
10877/16650 (epoch 32.664), train_loss = 0.80929607, grad/param norm = 3.0773e-01, time/batch = 16.8594s	
10878/16650 (epoch 32.667), train_loss = 0.91095746, grad/param norm = 2.8568e-01, time/batch = 17.9389s	
10879/16650 (epoch 32.670), train_loss = 0.69088058, grad/param norm = 3.1938e-01, time/batch = 14.9603s	
10880/16650 (epoch 32.673), train_loss = 0.71583585, grad/param norm = 2.5347e-01, time/batch = 16.5293s	
10881/16650 (epoch 32.676), train_loss = 0.84789661, grad/param norm = 2.8490e-01, time/batch = 17.6830s	
10882/16650 (epoch 32.679), train_loss = 0.71767926, grad/param norm = 2.7251e-01, time/batch = 16.5934s	
10883/16650 (epoch 32.682), train_loss = 0.77855503, grad/param norm = 2.7251e-01, time/batch = 18.3580s	
10884/16650 (epoch 32.685), train_loss = 0.68627558, grad/param norm = 2.5362e-01, time/batch = 17.5399s	
10885/16650 (epoch 32.688), train_loss = 0.85538292, grad/param norm = 2.7552e-01, time/batch = 15.4129s	
10886/16650 (epoch 32.691), train_loss = 0.81708780, grad/param norm = 2.5555e-01, time/batch = 15.8966s	
10887/16650 (epoch 32.694), train_loss = 0.73796281, grad/param norm = 2.7829e-01, time/batch = 18.2084s	
10888/16650 (epoch 32.697), train_loss = 0.67582990, grad/param norm = 2.3929e-01, time/batch = 18.6064s	
10889/16650 (epoch 32.700), train_loss = 0.84203746, grad/param norm = 3.1759e-01, time/batch = 16.6031s	
10890/16650 (epoch 32.703), train_loss = 0.72728748, grad/param norm = 3.2462e-01, time/batch = 17.2698s	
10891/16650 (epoch 32.706), train_loss = 0.78986114, grad/param norm = 3.0542e-01, time/batch = 18.0336s	
10892/16650 (epoch 32.709), train_loss = 0.67578638, grad/param norm = 2.6178e-01, time/batch = 16.9491s	
10893/16650 (epoch 32.712), train_loss = 0.71595033, grad/param norm = 2.9291e-01, time/batch = 16.8343s	
10894/16650 (epoch 32.715), train_loss = 0.83889228, grad/param norm = 2.7313e-01, time/batch = 17.7582s	
10895/16650 (epoch 32.718), train_loss = 0.86904796, grad/param norm = 2.9983e-01, time/batch = 16.2466s	
10896/16650 (epoch 32.721), train_loss = 0.86092822, grad/param norm = 2.7820e-01, time/batch = 16.3194s	
10897/16650 (epoch 32.724), train_loss = 0.87823221, grad/param norm = 3.2671e-01, time/batch = 16.6325s	
10898/16650 (epoch 32.727), train_loss = 0.88629568, grad/param norm = 3.1305e-01, time/batch = 18.8038s	
10899/16650 (epoch 32.730), train_loss = 0.72104134, grad/param norm = 2.7916e-01, time/batch = 17.3530s	
10900/16650 (epoch 32.733), train_loss = 0.89465479, grad/param norm = 2.9868e-01, time/batch = 15.9834s	
10901/16650 (epoch 32.736), train_loss = 0.68033505, grad/param norm = 2.7148e-01, time/batch = 18.0954s	
10902/16650 (epoch 32.739), train_loss = 0.81462203, grad/param norm = 3.4857e-01, time/batch = 18.7784s	
10903/16650 (epoch 32.742), train_loss = 0.77428918, grad/param norm = 2.5690e-01, time/batch = 16.3414s	
10904/16650 (epoch 32.745), train_loss = 0.62405954, grad/param norm = 2.6023e-01, time/batch = 16.2392s	
10905/16650 (epoch 32.748), train_loss = 0.68020601, grad/param norm = 2.6841e-01, time/batch = 17.7007s	
10906/16650 (epoch 32.751), train_loss = 0.80007006, grad/param norm = 3.7126e-01, time/batch = 17.5964s	
10907/16650 (epoch 32.754), train_loss = 0.97909389, grad/param norm = 3.5183e-01, time/batch = 18.0288s	
10908/16650 (epoch 32.757), train_loss = 0.93189762, grad/param norm = 3.0368e-01, time/batch = 17.6976s	
10909/16650 (epoch 32.760), train_loss = 0.80673154, grad/param norm = 3.0122e-01, time/batch = 16.1815s	
10910/16650 (epoch 32.763), train_loss = 0.72991826, grad/param norm = 2.6178e-01, time/batch = 16.0921s	
10911/16650 (epoch 32.766), train_loss = 0.75336343, grad/param norm = 2.2913e-01, time/batch = 17.7747s	
10912/16650 (epoch 32.769), train_loss = 0.82492352, grad/param norm = 2.6239e-01, time/batch = 18.2848s	
10913/16650 (epoch 32.772), train_loss = 0.78471396, grad/param norm = 2.3920e-01, time/batch = 17.3473s	
10914/16650 (epoch 32.775), train_loss = 0.77664677, grad/param norm = 2.9243e-01, time/batch = 16.9362s	
10915/16650 (epoch 32.778), train_loss = 0.80254454, grad/param norm = 2.4569e-01, time/batch = 17.5231s	
10916/16650 (epoch 32.781), train_loss = 0.94156856, grad/param norm = 2.7702e-01, time/batch = 18.4396s	
10917/16650 (epoch 32.784), train_loss = 0.82567543, grad/param norm = 3.0254e-01, time/batch = 16.7628s	
10918/16650 (epoch 32.787), train_loss = 0.85398421, grad/param norm = 2.8972e-01, time/batch = 14.4823s	
10919/16650 (epoch 32.790), train_loss = 0.86158822, grad/param norm = 2.5829e-01, time/batch = 18.1118s	
10920/16650 (epoch 32.793), train_loss = 0.70545951, grad/param norm = 2.9968e-01, time/batch = 16.3584s	
10921/16650 (epoch 32.796), train_loss = 1.05717428, grad/param norm = 3.1956e-01, time/batch = 16.6790s	
10922/16650 (epoch 32.799), train_loss = 0.96187047, grad/param norm = 3.2252e-01, time/batch = 17.6909s	
10923/16650 (epoch 32.802), train_loss = 0.86679378, grad/param norm = 2.7242e-01, time/batch = 15.3926s	
10924/16650 (epoch 32.805), train_loss = 0.80146461, grad/param norm = 2.4730e-01, time/batch = 16.6039s	
10925/16650 (epoch 32.808), train_loss = 0.87765332, grad/param norm = 2.6901e-01, time/batch = 18.4505s	
10926/16650 (epoch 32.811), train_loss = 0.90541463, grad/param norm = 2.8887e-01, time/batch = 16.3579s	
10927/16650 (epoch 32.814), train_loss = 0.71289359, grad/param norm = 2.4275e-01, time/batch = 16.4453s	
10928/16650 (epoch 32.817), train_loss = 0.76324287, grad/param norm = 2.8101e-01, time/batch = 17.1885s	
10929/16650 (epoch 32.820), train_loss = 0.84253694, grad/param norm = 3.0703e-01, time/batch = 17.6906s	
10930/16650 (epoch 32.823), train_loss = 0.80492902, grad/param norm = 2.9851e-01, time/batch = 18.9466s	
10931/16650 (epoch 32.826), train_loss = 0.76470811, grad/param norm = 2.8365e-01, time/batch = 16.4790s	
10932/16650 (epoch 32.829), train_loss = 0.82362713, grad/param norm = 2.9762e-01, time/batch = 17.7688s	
10933/16650 (epoch 32.832), train_loss = 0.87520179, grad/param norm = 2.9269e-01, time/batch = 15.3207s	
10934/16650 (epoch 32.835), train_loss = 0.86354112, grad/param norm = 3.1049e-01, time/batch = 16.9218s	
10935/16650 (epoch 32.838), train_loss = 0.73236529, grad/param norm = 2.6830e-01, time/batch = 17.5144s	
10936/16650 (epoch 32.841), train_loss = 0.73277903, grad/param norm = 2.6941e-01, time/batch = 18.2739s	
10937/16650 (epoch 32.844), train_loss = 0.75042104, grad/param norm = 2.4784e-01, time/batch = 18.6916s	
10938/16650 (epoch 32.847), train_loss = 0.87086361, grad/param norm = 3.1373e-01, time/batch = 16.7557s	
10939/16650 (epoch 32.850), train_loss = 0.71425736, grad/param norm = 3.2972e-01, time/batch = 17.0119s	
10940/16650 (epoch 32.853), train_loss = 0.80429147, grad/param norm = 3.3547e-01, time/batch = 17.5182s	
10941/16650 (epoch 32.856), train_loss = 0.74330830, grad/param norm = 3.0884e-01, time/batch = 15.8096s	
10942/16650 (epoch 32.859), train_loss = 0.91345863, grad/param norm = 3.1784e-01, time/batch = 17.0162s	
10943/16650 (epoch 32.862), train_loss = 0.79275559, grad/param norm = 3.4929e-01, time/batch = 16.2467s	
10944/16650 (epoch 32.865), train_loss = 0.64861345, grad/param norm = 2.6169e-01, time/batch = 17.7903s	
10945/16650 (epoch 32.868), train_loss = 0.83392198, grad/param norm = 2.9521e-01, time/batch = 16.2508s	
10946/16650 (epoch 32.871), train_loss = 0.85255030, grad/param norm = 3.0351e-01, time/batch = 16.9555s	
10947/16650 (epoch 32.874), train_loss = 0.84944206, grad/param norm = 2.7670e-01, time/batch = 16.6980s	
10948/16650 (epoch 32.877), train_loss = 0.82396014, grad/param norm = 2.8312e-01, time/batch = 16.9253s	
10949/16650 (epoch 32.880), train_loss = 0.72256345, grad/param norm = 2.7809e-01, time/batch = 17.4418s	
10950/16650 (epoch 32.883), train_loss = 0.83426997, grad/param norm = 3.1122e-01, time/batch = 17.4432s	
10951/16650 (epoch 32.886), train_loss = 0.83786806, grad/param norm = 2.8271e-01, time/batch = 17.4038s	
10952/16650 (epoch 32.889), train_loss = 0.67503616, grad/param norm = 2.7035e-01, time/batch = 16.9268s	
10953/16650 (epoch 32.892), train_loss = 0.80694784, grad/param norm = 2.6270e-01, time/batch = 17.8623s	
10954/16650 (epoch 32.895), train_loss = 0.82932945, grad/param norm = 2.8835e-01, time/batch = 16.5292s	
10955/16650 (epoch 32.898), train_loss = 0.81391839, grad/param norm = 3.0305e-01, time/batch = 16.5082s	
10956/16650 (epoch 32.901), train_loss = 0.76949926, grad/param norm = 3.0421e-01, time/batch = 15.6908s	
10957/16650 (epoch 32.904), train_loss = 0.75463475, grad/param norm = 2.8019e-01, time/batch = 17.1845s	
10958/16650 (epoch 32.907), train_loss = 0.82594035, grad/param norm = 2.9322e-01, time/batch = 16.6164s	
10959/16650 (epoch 32.910), train_loss = 0.83927530, grad/param norm = 2.8421e-01, time/batch = 16.3226s	
10960/16650 (epoch 32.913), train_loss = 0.75802531, grad/param norm = 2.8345e-01, time/batch = 18.6182s	
10961/16650 (epoch 32.916), train_loss = 0.75819116, grad/param norm = 3.1654e-01, time/batch = 17.0255s	
10962/16650 (epoch 32.919), train_loss = 0.93209033, grad/param norm = 2.7861e-01, time/batch = 16.4242s	
10963/16650 (epoch 32.922), train_loss = 0.84698304, grad/param norm = 3.5565e-01, time/batch = 17.1081s	
10964/16650 (epoch 32.925), train_loss = 0.75029398, grad/param norm = 2.9917e-01, time/batch = 18.7875s	
10965/16650 (epoch 32.928), train_loss = 0.80904072, grad/param norm = 2.8192e-01, time/batch = 18.2017s	
10966/16650 (epoch 32.931), train_loss = 0.84351089, grad/param norm = 3.0101e-01, time/batch = 16.9231s	
10967/16650 (epoch 32.934), train_loss = 0.68744784, grad/param norm = 2.9608e-01, time/batch = 17.2048s	
10968/16650 (epoch 32.937), train_loss = 0.73565446, grad/param norm = 3.2340e-01, time/batch = 18.2957s	
10969/16650 (epoch 32.940), train_loss = 0.78058794, grad/param norm = 2.5530e-01, time/batch = 16.1033s	
10970/16650 (epoch 32.943), train_loss = 0.81033342, grad/param norm = 3.0024e-01, time/batch = 16.6801s	
10971/16650 (epoch 32.946), train_loss = 0.74105003, grad/param norm = 2.7192e-01, time/batch = 19.1238s	
10972/16650 (epoch 32.949), train_loss = 0.71320470, grad/param norm = 3.2513e-01, time/batch = 17.5189s	
10973/16650 (epoch 32.952), train_loss = 0.67284186, grad/param norm = 2.5949e-01, time/batch = 16.7660s	
10974/16650 (epoch 32.955), train_loss = 0.80975017, grad/param norm = 3.5761e-01, time/batch = 15.8443s	
10975/16650 (epoch 32.958), train_loss = 0.85949930, grad/param norm = 3.4799e-01, time/batch = 17.5143s	
10976/16650 (epoch 32.961), train_loss = 0.78221956, grad/param norm = 2.4242e-01, time/batch = 15.9792s	
10977/16650 (epoch 32.964), train_loss = 0.70517703, grad/param norm = 2.7077e-01, time/batch = 17.5116s	
10978/16650 (epoch 32.967), train_loss = 0.94259838, grad/param norm = 3.3887e-01, time/batch = 15.3374s	
10979/16650 (epoch 32.970), train_loss = 0.73794936, grad/param norm = 2.4774e-01, time/batch = 17.6804s	
10980/16650 (epoch 32.973), train_loss = 0.74166952, grad/param norm = 2.9002e-01, time/batch = 17.0949s	
10981/16650 (epoch 32.976), train_loss = 0.72553827, grad/param norm = 2.5721e-01, time/batch = 18.4539s	
10982/16650 (epoch 32.979), train_loss = 0.82561143, grad/param norm = 2.8802e-01, time/batch = 18.4479s	
10983/16650 (epoch 32.982), train_loss = 0.85250015, grad/param norm = 2.8357e-01, time/batch = 15.6468s	
10984/16650 (epoch 32.985), train_loss = 0.76328624, grad/param norm = 2.5501e-01, time/batch = 16.6683s	
10985/16650 (epoch 32.988), train_loss = 0.85732905, grad/param norm = 3.3990e-01, time/batch = 18.1288s	
10986/16650 (epoch 32.991), train_loss = 0.72753130, grad/param norm = 2.8906e-01, time/batch = 17.6963s	
10987/16650 (epoch 32.994), train_loss = 0.75606999, grad/param norm = 3.9846e-01, time/batch = 17.7725s	
10988/16650 (epoch 32.997), train_loss = 0.78177793, grad/param norm = 3.0647e-01, time/batch = 17.4460s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
10989/16650 (epoch 33.000), train_loss = 0.86862517, grad/param norm = 3.2269e-01, time/batch = 15.6630s	
10990/16650 (epoch 33.003), train_loss = 0.89111915, grad/param norm = 3.2494e-01, time/batch = 16.8449s	
10991/16650 (epoch 33.006), train_loss = 0.88795732, grad/param norm = 4.1480e-01, time/batch = 17.8655s	
10992/16650 (epoch 33.009), train_loss = 0.93736539, grad/param norm = 2.9369e-01, time/batch = 15.8499s	
10993/16650 (epoch 33.012), train_loss = 0.92771856, grad/param norm = 3.1027e-01, time/batch = 16.3250s	
10994/16650 (epoch 33.015), train_loss = 0.80813531, grad/param norm = 2.8822e-01, time/batch = 16.8224s	
10995/16650 (epoch 33.018), train_loss = 0.69475580, grad/param norm = 2.7069e-01, time/batch = 18.1256s	
10996/16650 (epoch 33.021), train_loss = 0.92542945, grad/param norm = 3.2987e-01, time/batch = 17.7756s	
10997/16650 (epoch 33.024), train_loss = 0.79342236, grad/param norm = 3.0840e-01, time/batch = 15.9232s	
10998/16650 (epoch 33.027), train_loss = 0.85412305, grad/param norm = 3.1539e-01, time/batch = 18.4480s	
10999/16650 (epoch 33.030), train_loss = 0.68946840, grad/param norm = 2.5482e-01, time/batch = 15.5925s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch33.03_2.1232.t7	
11000/16650 (epoch 33.033), train_loss = 0.79823195, grad/param norm = 2.6817e-01, time/batch = 17.7559s	
11001/16650 (epoch 33.036), train_loss = 1.20536939, grad/param norm = 5.1349e-01, time/batch = 19.0320s	
11002/16650 (epoch 33.039), train_loss = 0.91537712, grad/param norm = 2.6824e-01, time/batch = 17.6985s	
11003/16650 (epoch 33.042), train_loss = 0.84374702, grad/param norm = 3.2415e-01, time/batch = 15.3188s	
11004/16650 (epoch 33.045), train_loss = 0.78187271, grad/param norm = 2.7537e-01, time/batch = 17.6184s	
11005/16650 (epoch 33.048), train_loss = 0.88534824, grad/param norm = 3.0651e-01, time/batch = 18.3646s	
11006/16650 (epoch 33.051), train_loss = 0.77295796, grad/param norm = 2.8755e-01, time/batch = 18.5949s	
11007/16650 (epoch 33.054), train_loss = 0.81347371, grad/param norm = 3.0841e-01, time/batch = 17.9243s	
11008/16650 (epoch 33.057), train_loss = 0.82079037, grad/param norm = 3.3713e-01, time/batch = 18.6018s	
11009/16650 (epoch 33.060), train_loss = 0.67925710, grad/param norm = 2.4833e-01, time/batch = 16.6936s	
11010/16650 (epoch 33.063), train_loss = 0.75853860, grad/param norm = 2.6890e-01, time/batch = 16.1894s	
11011/16650 (epoch 33.066), train_loss = 0.94559832, grad/param norm = 2.9123e-01, time/batch = 17.0948s	
11012/16650 (epoch 33.069), train_loss = 0.86944326, grad/param norm = 2.9649e-01, time/batch = 17.2628s	
11013/16650 (epoch 33.072), train_loss = 0.80722342, grad/param norm = 3.4497e-01, time/batch = 16.7495s	
11014/16650 (epoch 33.075), train_loss = 0.88169309, grad/param norm = 2.8219e-01, time/batch = 16.3298s	
11015/16650 (epoch 33.078), train_loss = 0.89512906, grad/param norm = 3.5582e-01, time/batch = 17.6101s	
11016/16650 (epoch 33.081), train_loss = 0.85317195, grad/param norm = 3.4655e-01, time/batch = 15.1623s	
11017/16650 (epoch 33.084), train_loss = 0.87196023, grad/param norm = 3.2210e-01, time/batch = 16.9510s	
11018/16650 (epoch 33.087), train_loss = 0.85617420, grad/param norm = 3.2875e-01, time/batch = 17.2876s	
11019/16650 (epoch 33.090), train_loss = 0.79535094, grad/param norm = 2.8998e-01, time/batch = 17.0134s	
11020/16650 (epoch 33.093), train_loss = 0.95166994, grad/param norm = 3.3448e-01, time/batch = 18.7076s	
11021/16650 (epoch 33.096), train_loss = 0.77131504, grad/param norm = 2.9491e-01, time/batch = 17.8440s	
11022/16650 (epoch 33.099), train_loss = 0.84840914, grad/param norm = 3.0006e-01, time/batch = 17.1999s	
11023/16650 (epoch 33.102), train_loss = 0.81130771, grad/param norm = 2.6609e-01, time/batch = 17.0180s	
11024/16650 (epoch 33.105), train_loss = 0.83537578, grad/param norm = 3.1440e-01, time/batch = 17.3635s	
11025/16650 (epoch 33.108), train_loss = 0.83468886, grad/param norm = 2.9977e-01, time/batch = 16.6122s	
11026/16650 (epoch 33.111), train_loss = 0.90893739, grad/param norm = 2.9068e-01, time/batch = 17.6944s	
11027/16650 (epoch 33.114), train_loss = 0.89679577, grad/param norm = 3.9592e-01, time/batch = 16.8312s	
11028/16650 (epoch 33.117), train_loss = 0.96828902, grad/param norm = 4.0517e-01, time/batch = 15.8079s	
11029/16650 (epoch 33.120), train_loss = 0.80355225, grad/param norm = 2.6942e-01, time/batch = 17.2925s	
11030/16650 (epoch 33.123), train_loss = 0.80568272, grad/param norm = 2.7549e-01, time/batch = 17.1902s	
11031/16650 (epoch 33.126), train_loss = 0.84076401, grad/param norm = 2.7573e-01, time/batch = 22.6006s	
11032/16650 (epoch 33.129), train_loss = 0.85043335, grad/param norm = 3.1501e-01, time/batch = 26.4328s	
11033/16650 (epoch 33.132), train_loss = 0.81653989, grad/param norm = 3.0259e-01, time/batch = 17.6122s	
11034/16650 (epoch 33.135), train_loss = 0.89963235, grad/param norm = 2.7648e-01, time/batch = 15.4901s	
11035/16650 (epoch 33.138), train_loss = 0.88436002, grad/param norm = 3.0024e-01, time/batch = 18.0241s	
11036/16650 (epoch 33.141), train_loss = 0.86327089, grad/param norm = 2.8239e-01, time/batch = 17.9522s	
11037/16650 (epoch 33.144), train_loss = 0.85473485, grad/param norm = 2.9104e-01, time/batch = 16.6798s	
11038/16650 (epoch 33.147), train_loss = 0.94530376, grad/param norm = 2.9234e-01, time/batch = 17.6015s	
11039/16650 (epoch 33.150), train_loss = 1.07977985, grad/param norm = 4.0492e-01, time/batch = 18.6286s	
11040/16650 (epoch 33.153), train_loss = 0.85866392, grad/param norm = 3.2398e-01, time/batch = 16.7871s	
11041/16650 (epoch 33.156), train_loss = 0.79780552, grad/param norm = 2.7912e-01, time/batch = 16.7446s	
11042/16650 (epoch 33.159), train_loss = 0.87590055, grad/param norm = 2.7369e-01, time/batch = 17.5359s	
11043/16650 (epoch 33.162), train_loss = 0.94845977, grad/param norm = 2.7959e-01, time/batch = 18.3570s	
11044/16650 (epoch 33.165), train_loss = 0.93612693, grad/param norm = 3.1160e-01, time/batch = 15.8326s	
11045/16650 (epoch 33.168), train_loss = 0.70323209, grad/param norm = 2.4031e-01, time/batch = 18.0162s	
11046/16650 (epoch 33.171), train_loss = 0.88574606, grad/param norm = 2.8095e-01, time/batch = 18.5481s	
11047/16650 (epoch 33.174), train_loss = 0.68203905, grad/param norm = 2.6574e-01, time/batch = 18.0037s	
11048/16650 (epoch 33.177), train_loss = 0.83692467, grad/param norm = 2.9360e-01, time/batch = 16.6020s	
11049/16650 (epoch 33.180), train_loss = 0.91826699, grad/param norm = 2.9092e-01, time/batch = 16.6748s	
11050/16650 (epoch 33.183), train_loss = 1.05943347, grad/param norm = 3.8158e-01, time/batch = 15.5783s	
11051/16650 (epoch 33.186), train_loss = 0.88842148, grad/param norm = 3.9956e-01, time/batch = 16.0022s	
11052/16650 (epoch 33.189), train_loss = 0.75293173, grad/param norm = 2.5604e-01, time/batch = 17.9501s	
11053/16650 (epoch 33.192), train_loss = 0.80915653, grad/param norm = 2.8755e-01, time/batch = 18.2757s	
11054/16650 (epoch 33.195), train_loss = 0.76501022, grad/param norm = 3.7367e-01, time/batch = 16.6029s	
11055/16650 (epoch 33.198), train_loss = 0.71720804, grad/param norm = 2.4487e-01, time/batch = 17.4899s	
11056/16650 (epoch 33.201), train_loss = 0.73358242, grad/param norm = 2.7417e-01, time/batch = 16.3288s	
11057/16650 (epoch 33.204), train_loss = 0.84232728, grad/param norm = 2.8098e-01, time/batch = 18.0288s	
11058/16650 (epoch 33.207), train_loss = 0.87677669, grad/param norm = 3.6872e-01, time/batch = 16.8384s	
11059/16650 (epoch 33.210), train_loss = 0.81477513, grad/param norm = 2.7373e-01, time/batch = 16.7717s	
11060/16650 (epoch 33.213), train_loss = 0.89156740, grad/param norm = 2.9225e-01, time/batch = 18.4528s	
11061/16650 (epoch 33.216), train_loss = 0.79123018, grad/param norm = 2.8743e-01, time/batch = 17.0918s	
11062/16650 (epoch 33.219), train_loss = 0.81712770, grad/param norm = 3.1906e-01, time/batch = 17.1033s	
11063/16650 (epoch 33.222), train_loss = 0.85537455, grad/param norm = 2.8004e-01, time/batch = 18.1901s	
11064/16650 (epoch 33.225), train_loss = 0.84171462, grad/param norm = 3.3783e-01, time/batch = 19.0313s	
11065/16650 (epoch 33.228), train_loss = 0.75344936, grad/param norm = 2.6608e-01, time/batch = 14.8678s	
11066/16650 (epoch 33.231), train_loss = 0.76130087, grad/param norm = 2.8530e-01, time/batch = 14.7763s	
11067/16650 (epoch 33.234), train_loss = 0.97875892, grad/param norm = 2.7865e-01, time/batch = 17.6829s	
11068/16650 (epoch 33.237), train_loss = 0.84394492, grad/param norm = 3.2872e-01, time/batch = 17.6873s	
11069/16650 (epoch 33.240), train_loss = 0.82497398, grad/param norm = 2.3817e-01, time/batch = 17.3475s	
11070/16650 (epoch 33.243), train_loss = 0.81799607, grad/param norm = 2.8692e-01, time/batch = 17.8718s	
11071/16650 (epoch 33.246), train_loss = 0.94075505, grad/param norm = 3.2614e-01, time/batch = 17.6281s	
11072/16650 (epoch 33.249), train_loss = 0.69351927, grad/param norm = 2.2675e-01, time/batch = 15.5466s	
11073/16650 (epoch 33.252), train_loss = 0.77808547, grad/param norm = 2.7897e-01, time/batch = 18.1183s	
11074/16650 (epoch 33.255), train_loss = 0.86707579, grad/param norm = 3.0119e-01, time/batch = 18.1780s	
11075/16650 (epoch 33.258), train_loss = 0.89667082, grad/param norm = 2.8297e-01, time/batch = 16.0806s	
11076/16650 (epoch 33.261), train_loss = 0.86098820, grad/param norm = 3.0541e-01, time/batch = 18.3577s	
11077/16650 (epoch 33.264), train_loss = 0.74333681, grad/param norm = 2.5092e-01, time/batch = 17.2038s	
11078/16650 (epoch 33.267), train_loss = 0.80883987, grad/param norm = 3.2010e-01, time/batch = 16.6897s	
11079/16650 (epoch 33.270), train_loss = 0.87172423, grad/param norm = 2.7350e-01, time/batch = 15.8376s	
11080/16650 (epoch 33.273), train_loss = 0.92757429, grad/param norm = 3.2152e-01, time/batch = 18.4337s	
11081/16650 (epoch 33.276), train_loss = 0.85635066, grad/param norm = 2.9744e-01, time/batch = 17.3696s	
11082/16650 (epoch 33.279), train_loss = 0.80989426, grad/param norm = 2.9623e-01, time/batch = 16.9375s	
11083/16650 (epoch 33.282), train_loss = 0.75218664, grad/param norm = 2.5035e-01, time/batch = 16.8248s	
11084/16650 (epoch 33.285), train_loss = 0.76025963, grad/param norm = 2.6060e-01, time/batch = 18.0309s	
11085/16650 (epoch 33.288), train_loss = 0.76100085, grad/param norm = 2.9226e-01, time/batch = 18.4509s	
11086/16650 (epoch 33.291), train_loss = 0.60701087, grad/param norm = 2.2912e-01, time/batch = 16.3388s	
11087/16650 (epoch 33.294), train_loss = 0.73346485, grad/param norm = 2.5865e-01, time/batch = 18.7143s	
11088/16650 (epoch 33.297), train_loss = 0.79086627, grad/param norm = 2.4758e-01, time/batch = 17.0159s	
11089/16650 (epoch 33.300), train_loss = 0.64202150, grad/param norm = 2.3114e-01, time/batch = 15.5717s	
11090/16650 (epoch 33.303), train_loss = 0.69787788, grad/param norm = 2.5065e-01, time/batch = 16.9568s	
11091/16650 (epoch 33.306), train_loss = 0.87744236, grad/param norm = 2.5062e-01, time/batch = 15.8420s	
11092/16650 (epoch 33.309), train_loss = 0.86488202, grad/param norm = 2.6269e-01, time/batch = 18.0207s	
11093/16650 (epoch 33.312), train_loss = 0.70693927, grad/param norm = 2.7717e-01, time/batch = 16.8228s	
11094/16650 (epoch 33.315), train_loss = 0.58327440, grad/param norm = 2.1095e-01, time/batch = 17.6189s	
11095/16650 (epoch 33.318), train_loss = 0.68298726, grad/param norm = 2.5467e-01, time/batch = 17.2778s	
11096/16650 (epoch 33.321), train_loss = 0.91785728, grad/param norm = 3.1519e-01, time/batch = 16.9307s	
11097/16650 (epoch 33.324), train_loss = 0.74404243, grad/param norm = 3.1598e-01, time/batch = 17.8449s	
11098/16650 (epoch 33.327), train_loss = 0.85088350, grad/param norm = 3.4169e-01, time/batch = 18.5256s	
11099/16650 (epoch 33.330), train_loss = 0.84145155, grad/param norm = 3.1903e-01, time/batch = 17.7799s	
11100/16650 (epoch 33.333), train_loss = 0.87887586, grad/param norm = 3.3620e-01, time/batch = 16.5820s	
11101/16650 (epoch 33.336), train_loss = 0.73687411, grad/param norm = 2.9283e-01, time/batch = 17.6074s	
11102/16650 (epoch 33.339), train_loss = 0.74584097, grad/param norm = 2.7470e-01, time/batch = 17.1927s	
11103/16650 (epoch 33.342), train_loss = 0.70115331, grad/param norm = 2.9628e-01, time/batch = 16.4186s	
11104/16650 (epoch 33.345), train_loss = 0.70534976, grad/param norm = 2.2911e-01, time/batch = 17.9445s	
11105/16650 (epoch 33.348), train_loss = 0.80810480, grad/param norm = 3.1266e-01, time/batch = 15.8377s	
11106/16650 (epoch 33.351), train_loss = 0.82183873, grad/param norm = 2.7529e-01, time/batch = 17.9409s	
11107/16650 (epoch 33.354), train_loss = 0.86844801, grad/param norm = 2.8516e-01, time/batch = 17.5108s	
11108/16650 (epoch 33.357), train_loss = 0.83700623, grad/param norm = 2.7674e-01, time/batch = 16.8425s	
11109/16650 (epoch 33.360), train_loss = 0.80520252, grad/param norm = 2.9748e-01, time/batch = 15.9276s	
11110/16650 (epoch 33.363), train_loss = 0.90888862, grad/param norm = 3.5602e-01, time/batch = 15.9280s	
11111/16650 (epoch 33.366), train_loss = 0.93912516, grad/param norm = 3.0382e-01, time/batch = 17.4519s	
11112/16650 (epoch 33.369), train_loss = 0.84113958, grad/param norm = 2.7437e-01, time/batch = 17.4575s	
11113/16650 (epoch 33.372), train_loss = 0.83716980, grad/param norm = 2.8446e-01, time/batch = 17.1754s	
11114/16650 (epoch 33.375), train_loss = 0.82980832, grad/param norm = 2.4638e-01, time/batch = 17.0138s	
11115/16650 (epoch 33.378), train_loss = 0.77031682, grad/param norm = 2.7720e-01, time/batch = 17.4445s	
11116/16650 (epoch 33.381), train_loss = 0.84710239, grad/param norm = 2.6986e-01, time/batch = 17.0908s	
11117/16650 (epoch 33.384), train_loss = 0.95315247, grad/param norm = 2.9704e-01, time/batch = 15.9998s	
11118/16650 (epoch 33.387), train_loss = 0.63019792, grad/param norm = 2.1470e-01, time/batch = 17.9550s	
11119/16650 (epoch 33.390), train_loss = 0.87991622, grad/param norm = 2.6075e-01, time/batch = 18.8799s	
11120/16650 (epoch 33.393), train_loss = 0.75850908, grad/param norm = 2.9593e-01, time/batch = 17.1014s	
11121/16650 (epoch 33.396), train_loss = 0.91054228, grad/param norm = 3.0040e-01, time/batch = 17.1023s	
11122/16650 (epoch 33.399), train_loss = 0.86565711, grad/param norm = 2.7550e-01, time/batch = 15.3356s	
11123/16650 (epoch 33.402), train_loss = 0.77164441, grad/param norm = 3.1147e-01, time/batch = 15.8511s	
11124/16650 (epoch 33.405), train_loss = 0.65426160, grad/param norm = 3.0391e-01, time/batch = 15.0092s	
11125/16650 (epoch 33.408), train_loss = 0.84682055, grad/param norm = 2.8905e-01, time/batch = 17.3759s	
11126/16650 (epoch 33.411), train_loss = 0.72080182, grad/param norm = 3.0463e-01, time/batch = 17.1031s	
11127/16650 (epoch 33.414), train_loss = 0.71884433, grad/param norm = 3.1494e-01, time/batch = 17.2043s	
11128/16650 (epoch 33.417), train_loss = 0.69530335, grad/param norm = 2.7605e-01, time/batch = 16.3330s	
11129/16650 (epoch 33.420), train_loss = 0.70979534, grad/param norm = 2.9202e-01, time/batch = 18.5350s	
11130/16650 (epoch 33.423), train_loss = 0.59877488, grad/param norm = 2.3435e-01, time/batch = 16.4397s	
11131/16650 (epoch 33.426), train_loss = 0.70509789, grad/param norm = 2.8693e-01, time/batch = 16.2654s	
11132/16650 (epoch 33.429), train_loss = 0.88152073, grad/param norm = 2.9823e-01, time/batch = 17.5284s	
11133/16650 (epoch 33.432), train_loss = 0.88714493, grad/param norm = 3.3894e-01, time/batch = 18.7966s	
11134/16650 (epoch 33.435), train_loss = 0.98132936, grad/param norm = 2.9533e-01, time/batch = 17.6084s	
11135/16650 (epoch 33.438), train_loss = 0.97636238, grad/param norm = 3.4574e-01, time/batch = 16.9077s	
11136/16650 (epoch 33.441), train_loss = 0.78764352, grad/param norm = 3.3541e-01, time/batch = 17.4477s	
11137/16650 (epoch 33.444), train_loss = 0.77360323, grad/param norm = 3.3218e-01, time/batch = 18.2866s	
11138/16650 (epoch 33.447), train_loss = 0.74316790, grad/param norm = 3.0155e-01, time/batch = 16.3584s	
11139/16650 (epoch 33.450), train_loss = 0.75840016, grad/param norm = 2.9267e-01, time/batch = 17.2857s	
11140/16650 (epoch 33.453), train_loss = 0.73301189, grad/param norm = 2.6432e-01, time/batch = 15.3762s	
11141/16650 (epoch 33.456), train_loss = 0.72117713, grad/param norm = 2.5795e-01, time/batch = 17.7574s	
11142/16650 (epoch 33.459), train_loss = 0.74212385, grad/param norm = 3.2045e-01, time/batch = 17.6851s	
11143/16650 (epoch 33.462), train_loss = 0.90348670, grad/param norm = 3.1871e-01, time/batch = 18.1136s	
11144/16650 (epoch 33.465), train_loss = 0.73640996, grad/param norm = 2.8107e-01, time/batch = 17.2114s	
11145/16650 (epoch 33.468), train_loss = 0.62145453, grad/param norm = 2.7960e-01, time/batch = 15.9217s	
11146/16650 (epoch 33.471), train_loss = 0.53735998, grad/param norm = 2.2225e-01, time/batch = 14.2398s	
11147/16650 (epoch 33.474), train_loss = 0.69568113, grad/param norm = 2.9065e-01, time/batch = 15.6640s	
11148/16650 (epoch 33.477), train_loss = 0.86622883, grad/param norm = 2.9315e-01, time/batch = 13.5648s	
11149/16650 (epoch 33.480), train_loss = 0.82149701, grad/param norm = 3.4326e-01, time/batch = 14.0957s	
11150/16650 (epoch 33.483), train_loss = 0.86119321, grad/param norm = 2.9976e-01, time/batch = 13.7965s	
11151/16650 (epoch 33.486), train_loss = 0.72584728, grad/param norm = 2.5679e-01, time/batch = 15.8624s	
11152/16650 (epoch 33.489), train_loss = 0.77109356, grad/param norm = 3.2561e-01, time/batch = 13.5445s	
11153/16650 (epoch 33.492), train_loss = 0.79523849, grad/param norm = 2.6437e-01, time/batch = 14.1452s	
11154/16650 (epoch 33.495), train_loss = 0.68291880, grad/param norm = 2.8615e-01, time/batch = 15.7036s	
11155/16650 (epoch 33.498), train_loss = 0.73657022, grad/param norm = 3.5519e-01, time/batch = 17.2791s	
11156/16650 (epoch 33.502), train_loss = 0.96362673, grad/param norm = 3.8220e-01, time/batch = 17.9483s	
11157/16650 (epoch 33.505), train_loss = 0.81786686, grad/param norm = 2.5874e-01, time/batch = 16.3200s	
11158/16650 (epoch 33.508), train_loss = 0.84448006, grad/param norm = 3.4252e-01, time/batch = 17.8628s	
11159/16650 (epoch 33.511), train_loss = 0.87844905, grad/param norm = 2.8023e-01, time/batch = 17.8044s	
11160/16650 (epoch 33.514), train_loss = 0.69347307, grad/param norm = 2.7211e-01, time/batch = 16.3326s	
11161/16650 (epoch 33.517), train_loss = 0.78181473, grad/param norm = 3.0244e-01, time/batch = 17.6174s	
11162/16650 (epoch 33.520), train_loss = 0.67329589, grad/param norm = 2.8399e-01, time/batch = 16.7677s	
11163/16650 (epoch 33.523), train_loss = 0.77612958, grad/param norm = 2.7164e-01, time/batch = 18.0025s	
11164/16650 (epoch 33.526), train_loss = 0.85257005, grad/param norm = 2.9889e-01, time/batch = 17.7530s	
11165/16650 (epoch 33.529), train_loss = 0.91799567, grad/param norm = 3.4569e-01, time/batch = 15.9136s	
11166/16650 (epoch 33.532), train_loss = 0.61254299, grad/param norm = 2.7849e-01, time/batch = 16.8635s	
11167/16650 (epoch 33.535), train_loss = 0.69080585, grad/param norm = 3.0889e-01, time/batch = 17.0984s	
11168/16650 (epoch 33.538), train_loss = 0.65110676, grad/param norm = 2.9474e-01, time/batch = 17.6800s	
11169/16650 (epoch 33.541), train_loss = 0.91828924, grad/param norm = 3.3828e-01, time/batch = 16.7745s	
11170/16650 (epoch 33.544), train_loss = 0.96907090, grad/param norm = 4.0482e-01, time/batch = 16.2813s	
11171/16650 (epoch 33.547), train_loss = 0.70293039, grad/param norm = 2.9969e-01, time/batch = 15.9539s	
11172/16650 (epoch 33.550), train_loss = 0.76890170, grad/param norm = 2.6240e-01, time/batch = 17.8436s	
11173/16650 (epoch 33.553), train_loss = 0.78731046, grad/param norm = 3.0766e-01, time/batch = 17.9532s	
11174/16650 (epoch 33.556), train_loss = 0.70484281, grad/param norm = 2.7024e-01, time/batch = 17.5262s	
11175/16650 (epoch 33.559), train_loss = 0.64854756, grad/param norm = 2.9680e-01, time/batch = 17.0167s	
11176/16650 (epoch 33.562), train_loss = 0.73424565, grad/param norm = 2.9316e-01, time/batch = 18.1943s	
11177/16650 (epoch 33.565), train_loss = 0.63153705, grad/param norm = 2.7446e-01, time/batch = 17.8657s	
11178/16650 (epoch 33.568), train_loss = 0.63404215, grad/param norm = 2.5291e-01, time/batch = 17.1702s	
11179/16650 (epoch 33.571), train_loss = 0.69776755, grad/param norm = 3.7736e-01, time/batch = 17.7074s	
11180/16650 (epoch 33.574), train_loss = 0.73700450, grad/param norm = 3.3830e-01, time/batch = 16.9317s	
11181/16650 (epoch 33.577), train_loss = 0.75446452, grad/param norm = 3.0551e-01, time/batch = 17.0033s	
11182/16650 (epoch 33.580), train_loss = 0.67614350, grad/param norm = 2.7198e-01, time/batch = 17.0208s	
11183/16650 (epoch 33.583), train_loss = 0.78217714, grad/param norm = 3.0024e-01, time/batch = 16.5906s	
11184/16650 (epoch 33.586), train_loss = 0.71076721, grad/param norm = 3.6434e-01, time/batch = 17.4378s	
11185/16650 (epoch 33.589), train_loss = 0.68366043, grad/param norm = 2.9896e-01, time/batch = 18.1975s	
11186/16650 (epoch 33.592), train_loss = 0.78623248, grad/param norm = 3.1916e-01, time/batch = 17.5293s	
11187/16650 (epoch 33.595), train_loss = 0.71973923, grad/param norm = 3.2446e-01, time/batch = 17.2001s	
11188/16650 (epoch 33.598), train_loss = 0.76246772, grad/param norm = 3.1666e-01, time/batch = 16.6001s	
11189/16650 (epoch 33.601), train_loss = 0.74651977, grad/param norm = 3.2954e-01, time/batch = 18.4522s	
11190/16650 (epoch 33.604), train_loss = 0.80014960, grad/param norm = 3.0115e-01, time/batch = 15.1550s	
11191/16650 (epoch 33.607), train_loss = 0.84866626, grad/param norm = 2.7239e-01, time/batch = 17.2642s	
11192/16650 (epoch 33.610), train_loss = 0.70162026, grad/param norm = 2.7228e-01, time/batch = 17.1833s	
11193/16650 (epoch 33.613), train_loss = 0.89563997, grad/param norm = 3.3782e-01, time/batch = 18.0398s	
11194/16650 (epoch 33.616), train_loss = 0.87065328, grad/param norm = 3.5627e-01, time/batch = 17.6077s	
11195/16650 (epoch 33.619), train_loss = 0.66393525, grad/param norm = 2.4653e-01, time/batch = 14.9000s	
11196/16650 (epoch 33.622), train_loss = 0.63601033, grad/param norm = 2.7333e-01, time/batch = 18.7855s	
11197/16650 (epoch 33.625), train_loss = 0.74158886, grad/param norm = 2.7121e-01, time/batch = 17.7792s	
11198/16650 (epoch 33.628), train_loss = 0.74198595, grad/param norm = 3.6128e-01, time/batch = 15.6509s	
11199/16650 (epoch 33.631), train_loss = 0.80347296, grad/param norm = 3.4680e-01, time/batch = 14.0750s	
11200/16650 (epoch 33.634), train_loss = 0.95069813, grad/param norm = 3.3534e-01, time/batch = 14.3916s	
11201/16650 (epoch 33.637), train_loss = 0.94222588, grad/param norm = 2.9560e-01, time/batch = 14.2713s	
11202/16650 (epoch 33.640), train_loss = 0.74712980, grad/param norm = 2.9595e-01, time/batch = 14.7420s	
11203/16650 (epoch 33.643), train_loss = 0.85237589, grad/param norm = 3.0156e-01, time/batch = 14.4601s	
11204/16650 (epoch 33.646), train_loss = 0.82616941, grad/param norm = 3.2744e-01, time/batch = 13.9430s	
11205/16650 (epoch 33.649), train_loss = 0.80049170, grad/param norm = 3.0979e-01, time/batch = 14.2443s	
11206/16650 (epoch 33.652), train_loss = 0.86081416, grad/param norm = 3.5157e-01, time/batch = 14.7572s	
11207/16650 (epoch 33.655), train_loss = 0.81101119, grad/param norm = 3.0553e-01, time/batch = 15.8953s	
11208/16650 (epoch 33.658), train_loss = 0.71941973, grad/param norm = 3.0721e-01, time/batch = 18.9400s	
11209/16650 (epoch 33.661), train_loss = 0.81232587, grad/param norm = 3.2269e-01, time/batch = 18.1326s	
11210/16650 (epoch 33.664), train_loss = 0.78360650, grad/param norm = 2.8819e-01, time/batch = 16.6139s	
11211/16650 (epoch 33.667), train_loss = 0.89987597, grad/param norm = 3.1901e-01, time/batch = 17.1854s	
11212/16650 (epoch 33.670), train_loss = 0.67156474, grad/param norm = 2.6012e-01, time/batch = 18.6260s	
11213/16650 (epoch 33.673), train_loss = 0.69717647, grad/param norm = 2.5105e-01, time/batch = 17.1606s	
11214/16650 (epoch 33.676), train_loss = 0.83936170, grad/param norm = 3.0480e-01, time/batch = 18.2474s	
11215/16650 (epoch 33.679), train_loss = 0.71432222, grad/param norm = 3.0837e-01, time/batch = 18.4481s	
11216/16650 (epoch 33.682), train_loss = 0.78026263, grad/param norm = 3.1009e-01, time/batch = 18.1780s	
11217/16650 (epoch 33.685), train_loss = 0.66691261, grad/param norm = 2.6841e-01, time/batch = 17.2650s	
11218/16650 (epoch 33.688), train_loss = 0.84057363, grad/param norm = 2.9825e-01, time/batch = 16.6702s	
11219/16650 (epoch 33.691), train_loss = 0.80693949, grad/param norm = 2.7287e-01, time/batch = 17.7625s	
11220/16650 (epoch 33.694), train_loss = 0.72411087, grad/param norm = 2.6469e-01, time/batch = 16.2735s	
11221/16650 (epoch 33.697), train_loss = 0.66305783, grad/param norm = 2.4027e-01, time/batch = 16.9389s	
11222/16650 (epoch 33.700), train_loss = 0.83641568, grad/param norm = 3.4514e-01, time/batch = 17.0412s	
11223/16650 (epoch 33.703), train_loss = 0.69768617, grad/param norm = 2.8102e-01, time/batch = 17.4576s	
11224/16650 (epoch 33.706), train_loss = 0.76413674, grad/param norm = 3.2326e-01, time/batch = 16.5043s	
11225/16650 (epoch 33.709), train_loss = 0.68299672, grad/param norm = 3.0198e-01, time/batch = 15.6533s	
11226/16650 (epoch 33.712), train_loss = 0.70360314, grad/param norm = 2.8891e-01, time/batch = 17.6045s	
11227/16650 (epoch 33.715), train_loss = 0.81996314, grad/param norm = 3.0734e-01, time/batch = 15.1616s	
11228/16650 (epoch 33.718), train_loss = 0.84195353, grad/param norm = 2.7863e-01, time/batch = 17.0285s	
11229/16650 (epoch 33.721), train_loss = 0.85238888, grad/param norm = 2.8128e-01, time/batch = 18.5263s	
11230/16650 (epoch 33.724), train_loss = 0.85971696, grad/param norm = 3.3225e-01, time/batch = 17.0238s	
11231/16650 (epoch 33.727), train_loss = 0.88006020, grad/param norm = 3.2740e-01, time/batch = 16.9430s	
11232/16650 (epoch 33.730), train_loss = 0.71303417, grad/param norm = 2.6838e-01, time/batch = 16.3104s	
11233/16650 (epoch 33.733), train_loss = 0.86904327, grad/param norm = 2.9562e-01, time/batch = 17.4069s	
11234/16650 (epoch 33.736), train_loss = 0.64854133, grad/param norm = 2.7437e-01, time/batch = 17.2732s	
11235/16650 (epoch 33.739), train_loss = 0.79526266, grad/param norm = 2.6034e-01, time/batch = 15.5746s	
11236/16650 (epoch 33.742), train_loss = 0.77165928, grad/param norm = 2.6893e-01, time/batch = 17.0934s	
11237/16650 (epoch 33.745), train_loss = 0.59933439, grad/param norm = 2.3650e-01, time/batch = 16.6835s	
11238/16650 (epoch 33.748), train_loss = 0.69367912, grad/param norm = 4.2772e-01, time/batch = 17.0051s	
11239/16650 (epoch 33.751), train_loss = 0.80025955, grad/param norm = 4.4663e-01, time/batch = 18.3631s	
11240/16650 (epoch 33.754), train_loss = 0.93840850, grad/param norm = 3.5551e-01, time/batch = 16.8268s	
11241/16650 (epoch 33.757), train_loss = 0.91453307, grad/param norm = 3.2445e-01, time/batch = 19.1007s	
11242/16650 (epoch 33.760), train_loss = 0.78129726, grad/param norm = 2.8097e-01, time/batch = 31.6677s	
11243/16650 (epoch 33.763), train_loss = 0.73546819, grad/param norm = 2.7769e-01, time/batch = 18.2020s	
11244/16650 (epoch 33.766), train_loss = 0.75838565, grad/param norm = 2.5784e-01, time/batch = 15.5570s	
11245/16650 (epoch 33.769), train_loss = 0.81478882, grad/param norm = 2.8131e-01, time/batch = 17.6088s	
11246/16650 (epoch 33.772), train_loss = 0.78067069, grad/param norm = 3.4788e-01, time/batch = 18.1981s	
11247/16650 (epoch 33.775), train_loss = 0.76981724, grad/param norm = 2.9175e-01, time/batch = 18.0255s	
11248/16650 (epoch 33.778), train_loss = 0.77961388, grad/param norm = 2.4145e-01, time/batch = 16.1636s	
11249/16650 (epoch 33.781), train_loss = 0.92862047, grad/param norm = 2.7148e-01, time/batch = 18.5197s	
11250/16650 (epoch 33.784), train_loss = 0.80761317, grad/param norm = 2.6895e-01, time/batch = 18.1950s	
11251/16650 (epoch 33.787), train_loss = 0.86126976, grad/param norm = 3.3031e-01, time/batch = 15.8988s	
11252/16650 (epoch 33.790), train_loss = 0.85980369, grad/param norm = 2.5725e-01, time/batch = 18.8622s	
11253/16650 (epoch 33.793), train_loss = 0.67126870, grad/param norm = 2.6429e-01, time/batch = 15.7744s	
11254/16650 (epoch 33.796), train_loss = 1.02314462, grad/param norm = 3.2624e-01, time/batch = 17.0895s	
11255/16650 (epoch 33.799), train_loss = 0.95408764, grad/param norm = 3.6903e-01, time/batch = 18.5235s	
11256/16650 (epoch 33.802), train_loss = 0.85102280, grad/param norm = 2.9412e-01, time/batch = 18.0909s	
11257/16650 (epoch 33.805), train_loss = 0.79675336, grad/param norm = 2.5971e-01, time/batch = 15.4276s	
11258/16650 (epoch 33.808), train_loss = 0.86369748, grad/param norm = 2.8444e-01, time/batch = 17.3182s	
11259/16650 (epoch 33.811), train_loss = 0.90270437, grad/param norm = 2.7560e-01, time/batch = 18.1053s	
11260/16650 (epoch 33.814), train_loss = 0.70063501, grad/param norm = 2.4438e-01, time/batch = 18.2050s	
11261/16650 (epoch 33.817), train_loss = 0.74780238, grad/param norm = 3.0318e-01, time/batch = 17.3660s	
11262/16650 (epoch 33.820), train_loss = 0.83896189, grad/param norm = 3.0701e-01, time/batch = 18.6214s	
11263/16650 (epoch 33.823), train_loss = 0.77935830, grad/param norm = 2.8307e-01, time/batch = 16.9571s	
11264/16650 (epoch 33.826), train_loss = 0.74539122, grad/param norm = 2.5758e-01, time/batch = 16.3531s	
11265/16650 (epoch 33.829), train_loss = 0.79763688, grad/param norm = 2.8412e-01, time/batch = 17.2617s	
11266/16650 (epoch 33.832), train_loss = 0.85658066, grad/param norm = 2.7983e-01, time/batch = 16.8318s	
11267/16650 (epoch 33.835), train_loss = 0.86141207, grad/param norm = 3.5455e-01, time/batch = 17.0071s	
11268/16650 (epoch 33.838), train_loss = 0.71195693, grad/param norm = 2.7357e-01, time/batch = 15.9900s	
11269/16650 (epoch 33.841), train_loss = 0.72373925, grad/param norm = 2.5000e-01, time/batch = 17.6097s	
11270/16650 (epoch 33.844), train_loss = 0.73464200, grad/param norm = 2.4576e-01, time/batch = 17.4574s	
11271/16650 (epoch 33.847), train_loss = 0.85615252, grad/param norm = 2.8836e-01, time/batch = 17.0956s	
11272/16650 (epoch 33.850), train_loss = 0.69340874, grad/param norm = 2.7465e-01, time/batch = 17.1109s	
11273/16650 (epoch 33.853), train_loss = 0.78108425, grad/param norm = 2.6305e-01, time/batch = 18.5195s	
11274/16650 (epoch 33.856), train_loss = 0.72276288, grad/param norm = 2.5872e-01, time/batch = 18.2053s	
11275/16650 (epoch 33.859), train_loss = 0.91289318, grad/param norm = 3.6927e-01, time/batch = 15.7421s	
11276/16650 (epoch 33.862), train_loss = 0.77451666, grad/param norm = 2.6535e-01, time/batch = 18.2680s	
11277/16650 (epoch 33.865), train_loss = 0.63962787, grad/param norm = 2.4955e-01, time/batch = 18.9583s	
11278/16650 (epoch 33.868), train_loss = 0.82003630, grad/param norm = 2.7229e-01, time/batch = 17.8431s	
11279/16650 (epoch 33.871), train_loss = 0.85960783, grad/param norm = 3.3341e-01, time/batch = 16.6718s	
11280/16650 (epoch 33.874), train_loss = 0.83600765, grad/param norm = 2.6443e-01, time/batch = 16.0630s	
11281/16650 (epoch 33.877), train_loss = 0.79982966, grad/param norm = 2.7731e-01, time/batch = 18.4382s	
11282/16650 (epoch 33.880), train_loss = 0.70644778, grad/param norm = 2.8095e-01, time/batch = 16.3172s	
11283/16650 (epoch 33.883), train_loss = 0.81953732, grad/param norm = 2.7234e-01, time/batch = 18.0112s	
11284/16650 (epoch 33.886), train_loss = 0.81804090, grad/param norm = 2.7427e-01, time/batch = 17.1760s	
11285/16650 (epoch 33.889), train_loss = 0.66438275, grad/param norm = 2.7547e-01, time/batch = 16.8543s	
11286/16650 (epoch 33.892), train_loss = 0.79699053, grad/param norm = 2.7310e-01, time/batch = 17.1060s	
11287/16650 (epoch 33.895), train_loss = 0.81523549, grad/param norm = 2.8087e-01, time/batch = 19.2721s	
11288/16650 (epoch 33.898), train_loss = 0.79994749, grad/param norm = 2.6725e-01, time/batch = 16.5974s	
11289/16650 (epoch 33.901), train_loss = 0.74925798, grad/param norm = 2.8535e-01, time/batch = 17.0037s	
11290/16650 (epoch 33.904), train_loss = 0.75235421, grad/param norm = 3.3952e-01, time/batch = 18.2107s	
11291/16650 (epoch 33.907), train_loss = 0.81894170, grad/param norm = 2.9317e-01, time/batch = 18.7981s	
11292/16650 (epoch 33.910), train_loss = 0.82195437, grad/param norm = 2.9847e-01, time/batch = 16.9230s	
11293/16650 (epoch 33.913), train_loss = 0.74265775, grad/param norm = 2.6567e-01, time/batch = 15.6639s	
11294/16650 (epoch 33.916), train_loss = 0.73537010, grad/param norm = 3.0246e-01, time/batch = 18.0970s	
11295/16650 (epoch 33.919), train_loss = 0.93521723, grad/param norm = 3.1161e-01, time/batch = 17.6153s	
11296/16650 (epoch 33.922), train_loss = 0.83940678, grad/param norm = 3.7995e-01, time/batch = 16.7599s	
11297/16650 (epoch 33.925), train_loss = 0.74225296, grad/param norm = 3.0766e-01, time/batch = 18.2629s	
11298/16650 (epoch 33.928), train_loss = 0.79849941, grad/param norm = 3.2122e-01, time/batch = 19.0297s	
11299/16650 (epoch 33.931), train_loss = 0.82764434, grad/param norm = 3.3896e-01, time/batch = 15.0782s	
11300/16650 (epoch 33.934), train_loss = 0.69475259, grad/param norm = 3.3173e-01, time/batch = 17.9511s	
11301/16650 (epoch 33.937), train_loss = 0.73742372, grad/param norm = 3.3869e-01, time/batch = 18.2065s	
11302/16650 (epoch 33.940), train_loss = 0.75939053, grad/param norm = 2.6174e-01, time/batch = 14.4919s	
11303/16650 (epoch 33.943), train_loss = 0.78696904, grad/param norm = 2.9913e-01, time/batch = 18.3468s	
11304/16650 (epoch 33.946), train_loss = 0.71958934, grad/param norm = 2.6346e-01, time/batch = 18.5482s	
11305/16650 (epoch 33.949), train_loss = 0.66536071, grad/param norm = 2.7217e-01, time/batch = 16.1743s	
11306/16650 (epoch 33.952), train_loss = 0.66404606, grad/param norm = 2.5342e-01, time/batch = 15.9149s	
11307/16650 (epoch 33.955), train_loss = 0.78502020, grad/param norm = 3.1274e-01, time/batch = 18.2034s	
11308/16650 (epoch 33.958), train_loss = 0.84967109, grad/param norm = 3.6677e-01, time/batch = 18.7990s	
11309/16650 (epoch 33.961), train_loss = 0.77130901, grad/param norm = 2.8194e-01, time/batch = 16.4296s	
11310/16650 (epoch 33.964), train_loss = 0.70260279, grad/param norm = 3.1618e-01, time/batch = 18.0121s	
11311/16650 (epoch 33.967), train_loss = 0.92456442, grad/param norm = 3.4897e-01, time/batch = 18.2516s	
11312/16650 (epoch 33.970), train_loss = 0.74007374, grad/param norm = 2.6256e-01, time/batch = 17.5880s	
11313/16650 (epoch 33.973), train_loss = 0.73422567, grad/param norm = 2.7933e-01, time/batch = 16.4833s	
11314/16650 (epoch 33.976), train_loss = 0.70489568, grad/param norm = 2.3798e-01, time/batch = 18.9611s	
11315/16650 (epoch 33.979), train_loss = 0.80043797, grad/param norm = 2.7839e-01, time/batch = 17.5015s	
11316/16650 (epoch 33.982), train_loss = 0.84159142, grad/param norm = 2.7914e-01, time/batch = 16.0985s	
11317/16650 (epoch 33.985), train_loss = 0.76493458, grad/param norm = 2.7294e-01, time/batch = 18.1963s	
11318/16650 (epoch 33.988), train_loss = 0.83471911, grad/param norm = 3.1766e-01, time/batch = 16.0452s	
11319/16650 (epoch 33.991), train_loss = 0.71568711, grad/param norm = 2.9461e-01, time/batch = 14.5954s	
11320/16650 (epoch 33.994), train_loss = 0.72373022, grad/param norm = 2.9373e-01, time/batch = 16.9489s	
11321/16650 (epoch 33.997), train_loss = 0.77696216, grad/param norm = 4.1430e-01, time/batch = 19.1088s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
11322/16650 (epoch 34.000), train_loss = 0.84812223, grad/param norm = 3.1453e-01, time/batch = 17.7711s	
11323/16650 (epoch 34.003), train_loss = 0.88760231, grad/param norm = 3.2655e-01, time/batch = 16.4958s	
11324/16650 (epoch 34.006), train_loss = 0.86748549, grad/param norm = 2.9395e-01, time/batch = 16.5203s	
11325/16650 (epoch 34.009), train_loss = 0.92630256, grad/param norm = 2.9858e-01, time/batch = 18.1141s	
11326/16650 (epoch 34.012), train_loss = 0.89964204, grad/param norm = 3.0981e-01, time/batch = 17.7677s	
11327/16650 (epoch 34.015), train_loss = 0.80948498, grad/param norm = 2.7832e-01, time/batch = 17.2716s	
11328/16650 (epoch 34.018), train_loss = 0.69123677, grad/param norm = 3.3142e-01, time/batch = 18.6228s	
11329/16650 (epoch 34.021), train_loss = 0.89845676, grad/param norm = 2.9482e-01, time/batch = 19.4692s	
11330/16650 (epoch 34.024), train_loss = 0.77943991, grad/param norm = 2.9809e-01, time/batch = 16.9966s	
11331/16650 (epoch 34.027), train_loss = 0.84614378, grad/param norm = 2.9171e-01, time/batch = 17.8712s	
11332/16650 (epoch 34.030), train_loss = 0.68885555, grad/param norm = 2.6206e-01, time/batch = 18.4585s	
11333/16650 (epoch 34.033), train_loss = 0.77247674, grad/param norm = 2.5021e-01, time/batch = 16.4293s	
11334/16650 (epoch 34.036), train_loss = 0.59786942, grad/param norm = 3.2206e-01, time/batch = 17.7719s	
11335/16650 (epoch 34.039), train_loss = 0.89197358, grad/param norm = 2.6757e-01, time/batch = 16.7867s	
11336/16650 (epoch 34.042), train_loss = 0.83201924, grad/param norm = 2.9317e-01, time/batch = 16.4848s	
11337/16650 (epoch 34.045), train_loss = 0.77188785, grad/param norm = 2.7961e-01, time/batch = 17.4170s	
11338/16650 (epoch 34.048), train_loss = 0.86223580, grad/param norm = 3.1501e-01, time/batch = 18.1133s	
11339/16650 (epoch 34.051), train_loss = 0.76265228, grad/param norm = 2.8393e-01, time/batch = 14.6682s	
11340/16650 (epoch 34.054), train_loss = 0.78850549, grad/param norm = 2.9863e-01, time/batch = 17.0910s	
11341/16650 (epoch 34.057), train_loss = 0.80217520, grad/param norm = 3.2105e-01, time/batch = 18.7770s	
11342/16650 (epoch 34.060), train_loss = 0.65505846, grad/param norm = 2.3233e-01, time/batch = 17.7640s	
11343/16650 (epoch 34.063), train_loss = 0.74507449, grad/param norm = 2.7891e-01, time/batch = 17.7526s	
11344/16650 (epoch 34.066), train_loss = 0.93357792, grad/param norm = 3.0549e-01, time/batch = 16.6375s	
11345/16650 (epoch 34.069), train_loss = 0.84717093, grad/param norm = 3.1001e-01, time/batch = 18.9598s	
11346/16650 (epoch 34.072), train_loss = 0.78186306, grad/param norm = 3.0124e-01, time/batch = 18.4568s	
11347/16650 (epoch 34.075), train_loss = 0.88314186, grad/param norm = 3.1301e-01, time/batch = 16.9264s	
11348/16650 (epoch 34.078), train_loss = 0.86460714, grad/param norm = 3.1432e-01, time/batch = 17.2862s	
11349/16650 (epoch 34.081), train_loss = 0.84265126, grad/param norm = 3.4546e-01, time/batch = 17.1310s	
11350/16650 (epoch 34.084), train_loss = 0.83744029, grad/param norm = 3.0057e-01, time/batch = 17.1855s	
11351/16650 (epoch 34.087), train_loss = 0.82834722, grad/param norm = 3.1137e-01, time/batch = 17.8560s	
11352/16650 (epoch 34.090), train_loss = 0.76962632, grad/param norm = 2.7456e-01, time/batch = 15.9144s	
11353/16650 (epoch 34.093), train_loss = 0.93256616, grad/param norm = 3.5001e-01, time/batch = 18.4456s	
11354/16650 (epoch 34.096), train_loss = 0.74924714, grad/param norm = 2.9759e-01, time/batch = 15.8241s	
11355/16650 (epoch 34.099), train_loss = 0.84564539, grad/param norm = 3.0899e-01, time/batch = 19.1134s	
11356/16650 (epoch 34.102), train_loss = 0.79701646, grad/param norm = 2.7394e-01, time/batch = 18.3502s	
11357/16650 (epoch 34.105), train_loss = 0.80679830, grad/param norm = 3.0273e-01, time/batch = 16.0741s	
11358/16650 (epoch 34.108), train_loss = 0.80788975, grad/param norm = 2.9174e-01, time/batch = 18.0004s	
11359/16650 (epoch 34.111), train_loss = 0.90627229, grad/param norm = 3.1543e-01, time/batch = 18.0294s	
11360/16650 (epoch 34.114), train_loss = 0.87532572, grad/param norm = 3.9349e-01, time/batch = 16.9998s	
11361/16650 (epoch 34.117), train_loss = 0.98007661, grad/param norm = 3.7636e-01, time/batch = 15.7948s	
11362/16650 (epoch 34.120), train_loss = 0.78376080, grad/param norm = 2.7132e-01, time/batch = 14.6460s	
11363/16650 (epoch 34.123), train_loss = 0.77802546, grad/param norm = 2.6090e-01, time/batch = 18.2805s	
11364/16650 (epoch 34.126), train_loss = 0.83179743, grad/param norm = 2.7169e-01, time/batch = 16.3453s	
11365/16650 (epoch 34.129), train_loss = 0.83154264, grad/param norm = 3.2140e-01, time/batch = 15.5852s	
11366/16650 (epoch 34.132), train_loss = 0.79429109, grad/param norm = 3.0309e-01, time/batch = 17.3691s	
11367/16650 (epoch 34.135), train_loss = 0.89134638, grad/param norm = 2.7105e-01, time/batch = 18.1127s	
11368/16650 (epoch 34.138), train_loss = 0.87220508, grad/param norm = 2.8434e-01, time/batch = 16.9140s	
11369/16650 (epoch 34.141), train_loss = 0.84076782, grad/param norm = 2.8160e-01, time/batch = 18.3720s	
11370/16650 (epoch 34.144), train_loss = 0.82787529, grad/param norm = 2.8681e-01, time/batch = 18.8741s	
11371/16650 (epoch 34.147), train_loss = 0.92437907, grad/param norm = 2.9900e-01, time/batch = 17.2647s	
11372/16650 (epoch 34.150), train_loss = 1.04611859, grad/param norm = 3.4239e-01, time/batch = 17.1820s	
11373/16650 (epoch 34.153), train_loss = 0.83665508, grad/param norm = 3.0433e-01, time/batch = 17.9340s	
11374/16650 (epoch 34.156), train_loss = 0.80122057, grad/param norm = 2.8208e-01, time/batch = 18.1851s	
11375/16650 (epoch 34.159), train_loss = 0.87045573, grad/param norm = 2.8452e-01, time/batch = 17.2628s	
11376/16650 (epoch 34.162), train_loss = 0.92396322, grad/param norm = 2.6688e-01, time/batch = 16.7954s	
11377/16650 (epoch 34.165), train_loss = 0.92193428, grad/param norm = 3.1792e-01, time/batch = 16.5075s	
11378/16650 (epoch 34.168), train_loss = 0.69178361, grad/param norm = 2.6012e-01, time/batch = 15.6385s	
11379/16650 (epoch 34.171), train_loss = 0.85843603, grad/param norm = 2.7975e-01, time/batch = 17.7903s	
11380/16650 (epoch 34.174), train_loss = 0.66379105, grad/param norm = 2.4805e-01, time/batch = 18.1149s	
11381/16650 (epoch 34.177), train_loss = 0.80317650, grad/param norm = 2.9091e-01, time/batch = 18.0164s	
11382/16650 (epoch 34.180), train_loss = 0.91348987, grad/param norm = 2.9876e-01, time/batch = 17.4276s	
11383/16650 (epoch 34.183), train_loss = 1.04072612, grad/param norm = 3.4508e-01, time/batch = 16.1593s	
11384/16650 (epoch 34.186), train_loss = 0.87006131, grad/param norm = 3.3883e-01, time/batch = 17.6042s	
11385/16650 (epoch 34.189), train_loss = 0.75650106, grad/param norm = 2.7093e-01, time/batch = 16.6705s	
11386/16650 (epoch 34.192), train_loss = 0.80122196, grad/param norm = 2.9193e-01, time/batch = 18.3540s	
11387/16650 (epoch 34.195), train_loss = 0.74574365, grad/param norm = 3.0209e-01, time/batch = 18.1911s	
11388/16650 (epoch 34.198), train_loss = 0.69995522, grad/param norm = 2.4252e-01, time/batch = 16.3440s	
11389/16650 (epoch 34.201), train_loss = 0.71918893, grad/param norm = 2.7053e-01, time/batch = 18.5355s	
11390/16650 (epoch 34.204), train_loss = 0.82606541, grad/param norm = 2.8963e-01, time/batch = 18.7997s	
11391/16650 (epoch 34.207), train_loss = 0.84627233, grad/param norm = 3.2530e-01, time/batch = 17.8415s	
11392/16650 (epoch 34.210), train_loss = 0.81520171, grad/param norm = 2.9264e-01, time/batch = 17.0881s	
11393/16650 (epoch 34.213), train_loss = 0.87072443, grad/param norm = 3.0840e-01, time/batch = 18.4456s	
11394/16650 (epoch 34.216), train_loss = 0.75688703, grad/param norm = 2.6571e-01, time/batch = 18.0364s	
11395/16650 (epoch 34.219), train_loss = 0.79228222, grad/param norm = 2.8022e-01, time/batch = 15.0918s	
11396/16650 (epoch 34.222), train_loss = 0.83350879, grad/param norm = 2.7888e-01, time/batch = 18.0348s	
11397/16650 (epoch 34.225), train_loss = 0.84534772, grad/param norm = 3.7039e-01, time/batch = 17.3706s	
11398/16650 (epoch 34.228), train_loss = 0.75278253, grad/param norm = 3.1147e-01, time/batch = 16.8660s	
11399/16650 (epoch 34.231), train_loss = 0.75592396, grad/param norm = 2.7023e-01, time/batch = 16.0242s	
11400/16650 (epoch 34.234), train_loss = 0.97074697, grad/param norm = 2.9764e-01, time/batch = 14.4241s	
11401/16650 (epoch 34.237), train_loss = 0.84063397, grad/param norm = 3.3427e-01, time/batch = 17.9523s	
11402/16650 (epoch 34.240), train_loss = 0.80837391, grad/param norm = 2.7445e-01, time/batch = 15.3726s	
11403/16650 (epoch 34.243), train_loss = 0.79628236, grad/param norm = 2.7950e-01, time/batch = 15.9461s	
11404/16650 (epoch 34.246), train_loss = 0.93079358, grad/param norm = 3.1879e-01, time/batch = 17.6212s	
11405/16650 (epoch 34.249), train_loss = 0.68015194, grad/param norm = 2.3901e-01, time/batch = 17.8842s	
11406/16650 (epoch 34.252), train_loss = 0.77408766, grad/param norm = 2.6892e-01, time/batch = 14.7978s	
11407/16650 (epoch 34.255), train_loss = 0.84374921, grad/param norm = 2.7491e-01, time/batch = 16.5082s	
11408/16650 (epoch 34.258), train_loss = 0.87757147, grad/param norm = 2.6731e-01, time/batch = 16.7840s	
11409/16650 (epoch 34.261), train_loss = 0.84914855, grad/param norm = 2.8225e-01, time/batch = 16.0211s	
11410/16650 (epoch 34.264), train_loss = 0.77762746, grad/param norm = 2.7457e-01, time/batch = 15.9339s	
11411/16650 (epoch 34.267), train_loss = 0.78090223, grad/param norm = 3.2655e-01, time/batch = 17.2185s	
11412/16650 (epoch 34.270), train_loss = 0.84667326, grad/param norm = 2.9294e-01, time/batch = 17.1158s	
11413/16650 (epoch 34.273), train_loss = 0.89784977, grad/param norm = 2.9607e-01, time/batch = 15.3307s	
11414/16650 (epoch 34.276), train_loss = 0.84451442, grad/param norm = 3.1189e-01, time/batch = 17.0319s	
11415/16650 (epoch 34.279), train_loss = 0.80384887, grad/param norm = 2.9778e-01, time/batch = 17.5562s	
11416/16650 (epoch 34.282), train_loss = 0.74134054, grad/param norm = 2.6050e-01, time/batch = 16.0162s	
11417/16650 (epoch 34.285), train_loss = 0.74653573, grad/param norm = 2.7533e-01, time/batch = 16.8658s	
11418/16650 (epoch 34.288), train_loss = 0.73670596, grad/param norm = 2.7577e-01, time/batch = 17.6190s	
11419/16650 (epoch 34.291), train_loss = 0.59242429, grad/param norm = 2.1775e-01, time/batch = 14.0053s	
11420/16650 (epoch 34.294), train_loss = 0.72105032, grad/param norm = 2.4141e-01, time/batch = 16.4460s	
11421/16650 (epoch 34.297), train_loss = 0.78399765, grad/param norm = 2.6407e-01, time/batch = 14.9874s	
11422/16650 (epoch 34.300), train_loss = 0.63620601, grad/param norm = 2.3211e-01, time/batch = 16.5187s	
11423/16650 (epoch 34.303), train_loss = 0.68657973, grad/param norm = 2.6551e-01, time/batch = 17.2177s	
11424/16650 (epoch 34.306), train_loss = 0.86694610, grad/param norm = 2.6900e-01, time/batch = 16.6979s	
11425/16650 (epoch 34.309), train_loss = 0.85671795, grad/param norm = 2.9473e-01, time/batch = 17.2753s	
11426/16650 (epoch 34.312), train_loss = 0.68067406, grad/param norm = 2.8332e-01, time/batch = 16.7876s	
11427/16650 (epoch 34.315), train_loss = 0.57818028, grad/param norm = 1.9990e-01, time/batch = 16.5989s	
11428/16650 (epoch 34.318), train_loss = 0.66742639, grad/param norm = 2.5471e-01, time/batch = 15.6816s	
11429/16650 (epoch 34.321), train_loss = 0.89398108, grad/param norm = 2.9116e-01, time/batch = 16.4207s	
11430/16650 (epoch 34.324), train_loss = 0.71791634, grad/param norm = 3.1817e-01, time/batch = 17.3621s	
11431/16650 (epoch 34.327), train_loss = 0.82289936, grad/param norm = 3.0053e-01, time/batch = 15.8494s	
11432/16650 (epoch 34.330), train_loss = 0.82639594, grad/param norm = 3.6853e-01, time/batch = 16.8648s	
11433/16650 (epoch 34.333), train_loss = 0.83236278, grad/param norm = 2.8384e-01, time/batch = 17.2916s	
11434/16650 (epoch 34.336), train_loss = 0.71792550, grad/param norm = 3.5023e-01, time/batch = 16.0974s	
11435/16650 (epoch 34.339), train_loss = 0.74020523, grad/param norm = 2.8930e-01, time/batch = 16.4288s	
11436/16650 (epoch 34.342), train_loss = 0.67696925, grad/param norm = 2.8365e-01, time/batch = 17.1353s	
11437/16650 (epoch 34.345), train_loss = 0.68973252, grad/param norm = 2.2852e-01, time/batch = 17.0314s	
11438/16650 (epoch 34.348), train_loss = 0.79345254, grad/param norm = 3.4096e-01, time/batch = 16.3772s	
11439/16650 (epoch 34.351), train_loss = 0.81062699, grad/param norm = 2.7749e-01, time/batch = 13.8295s	
11440/16650 (epoch 34.354), train_loss = 0.86053081, grad/param norm = 3.0721e-01, time/batch = 15.8571s	
11441/16650 (epoch 34.357), train_loss = 0.84737205, grad/param norm = 2.8947e-01, time/batch = 18.0224s	
11442/16650 (epoch 34.360), train_loss = 0.79371132, grad/param norm = 2.7963e-01, time/batch = 15.9320s	
11443/16650 (epoch 34.363), train_loss = 0.89272274, grad/param norm = 3.2783e-01, time/batch = 16.9496s	
11444/16650 (epoch 34.366), train_loss = 0.93886390, grad/param norm = 3.2981e-01, time/batch = 17.2075s	
11445/16650 (epoch 34.369), train_loss = 0.84673437, grad/param norm = 3.2572e-01, time/batch = 16.0191s	
11446/16650 (epoch 34.372), train_loss = 0.81971454, grad/param norm = 2.9032e-01, time/batch = 17.3602s	
11447/16650 (epoch 34.375), train_loss = 0.81488254, grad/param norm = 2.5224e-01, time/batch = 15.2815s	
11448/16650 (epoch 34.378), train_loss = 0.76112997, grad/param norm = 2.7217e-01, time/batch = 18.1234s	
11449/16650 (epoch 34.381), train_loss = 0.84061027, grad/param norm = 3.1296e-01, time/batch = 24.5267s	
11450/16650 (epoch 34.384), train_loss = 0.93470989, grad/param norm = 2.9707e-01, time/batch = 22.5627s	
11451/16650 (epoch 34.387), train_loss = 0.63339449, grad/param norm = 2.3585e-01, time/batch = 13.3200s	
11452/16650 (epoch 34.390), train_loss = 0.86492855, grad/param norm = 2.7714e-01, time/batch = 13.7737s	
11453/16650 (epoch 34.393), train_loss = 0.75449446, grad/param norm = 3.2226e-01, time/batch = 14.3006s	
11454/16650 (epoch 34.396), train_loss = 0.91039264, grad/param norm = 3.2162e-01, time/batch = 16.8014s	
11455/16650 (epoch 34.399), train_loss = 0.85936761, grad/param norm = 2.9781e-01, time/batch = 16.0375s	
11456/16650 (epoch 34.402), train_loss = 0.77752135, grad/param norm = 3.2264e-01, time/batch = 14.9111s	
11457/16650 (epoch 34.405), train_loss = 0.65593257, grad/param norm = 3.2063e-01, time/batch = 17.2934s	
11458/16650 (epoch 34.408), train_loss = 0.82281818, grad/param norm = 3.2891e-01, time/batch = 17.1821s	
11459/16650 (epoch 34.411), train_loss = 0.71308186, grad/param norm = 3.2338e-01, time/batch = 16.7852s	
11460/16650 (epoch 34.414), train_loss = 0.70256992, grad/param norm = 2.9897e-01, time/batch = 15.9998s	
11461/16650 (epoch 34.417), train_loss = 0.70121850, grad/param norm = 2.9313e-01, time/batch = 17.7945s	
11462/16650 (epoch 34.420), train_loss = 0.69078999, grad/param norm = 2.6848e-01, time/batch = 17.1908s	
11463/16650 (epoch 34.423), train_loss = 0.59013127, grad/param norm = 2.4131e-01, time/batch = 16.0146s	
11464/16650 (epoch 34.426), train_loss = 0.71119036, grad/param norm = 3.3665e-01, time/batch = 17.3636s	
11465/16650 (epoch 34.429), train_loss = 0.86821954, grad/param norm = 3.0809e-01, time/batch = 16.5255s	
11466/16650 (epoch 34.432), train_loss = 0.86912966, grad/param norm = 3.0007e-01, time/batch = 17.1027s	
11467/16650 (epoch 34.435), train_loss = 0.99377560, grad/param norm = 3.7424e-01, time/batch = 16.9956s	
11468/16650 (epoch 34.438), train_loss = 0.96219636, grad/param norm = 4.2807e-01, time/batch = 17.9560s	
11469/16650 (epoch 34.441), train_loss = 0.77616497, grad/param norm = 3.4107e-01, time/batch = 17.7059s	
11470/16650 (epoch 34.444), train_loss = 0.75296079, grad/param norm = 3.0712e-01, time/batch = 15.3272s	
11471/16650 (epoch 34.447), train_loss = 0.73505691, grad/param norm = 2.9786e-01, time/batch = 15.0709s	
11472/16650 (epoch 34.450), train_loss = 0.74697835, grad/param norm = 2.8878e-01, time/batch = 16.8623s	
11473/16650 (epoch 34.453), train_loss = 0.73325019, grad/param norm = 2.7168e-01, time/batch = 17.9632s	
11474/16650 (epoch 34.456), train_loss = 0.69853020, grad/param norm = 2.3938e-01, time/batch = 16.0202s	
11475/16650 (epoch 34.459), train_loss = 0.73464088, grad/param norm = 2.8962e-01, time/batch = 17.9527s	
11476/16650 (epoch 34.462), train_loss = 0.89733105, grad/param norm = 3.6615e-01, time/batch = 16.7071s	
11477/16650 (epoch 34.465), train_loss = 0.73092903, grad/param norm = 2.9789e-01, time/batch = 16.3343s	
11478/16650 (epoch 34.468), train_loss = 0.60998702, grad/param norm = 2.6741e-01, time/batch = 16.0645s	
11479/16650 (epoch 34.471), train_loss = 0.53913912, grad/param norm = 2.3312e-01, time/batch = 17.9627s	
11480/16650 (epoch 34.474), train_loss = 0.68529845, grad/param norm = 2.8770e-01, time/batch = 16.8736s	
11481/16650 (epoch 34.477), train_loss = 0.85448827, grad/param norm = 3.1261e-01, time/batch = 16.0079s	
11482/16650 (epoch 34.480), train_loss = 0.80238577, grad/param norm = 3.6010e-01, time/batch = 16.9545s	
11483/16650 (epoch 34.483), train_loss = 0.85625894, grad/param norm = 3.3280e-01, time/batch = 15.9408s	
11484/16650 (epoch 34.486), train_loss = 0.70158971, grad/param norm = 2.5574e-01, time/batch = 16.5266s	
11485/16650 (epoch 34.489), train_loss = 0.76786628, grad/param norm = 2.9479e-01, time/batch = 14.5741s	
11486/16650 (epoch 34.492), train_loss = 0.77661729, grad/param norm = 2.6357e-01, time/batch = 17.0274s	
11487/16650 (epoch 34.495), train_loss = 0.69328212, grad/param norm = 2.9835e-01, time/batch = 16.9462s	
11488/16650 (epoch 34.498), train_loss = 0.74655569, grad/param norm = 3.2793e-01, time/batch = 14.7401s	
11489/16650 (epoch 34.502), train_loss = 0.92366712, grad/param norm = 3.4816e-01, time/batch = 17.2022s	
11490/16650 (epoch 34.505), train_loss = 0.82282377, grad/param norm = 3.0016e-01, time/batch = 17.2133s	
11491/16650 (epoch 34.508), train_loss = 0.82232988, grad/param norm = 3.1880e-01, time/batch = 15.9242s	
11492/16650 (epoch 34.511), train_loss = 0.87039995, grad/param norm = 3.2308e-01, time/batch = 15.9993s	
11493/16650 (epoch 34.514), train_loss = 0.69163675, grad/param norm = 3.0054e-01, time/batch = 16.8800s	
11494/16650 (epoch 34.517), train_loss = 0.78225106, grad/param norm = 3.6165e-01, time/batch = 16.5398s	
11495/16650 (epoch 34.520), train_loss = 0.68673646, grad/param norm = 3.2722e-01, time/batch = 17.1871s	
11496/16650 (epoch 34.523), train_loss = 0.76594802, grad/param norm = 2.7620e-01, time/batch = 16.9475s	
11497/16650 (epoch 34.526), train_loss = 0.83098092, grad/param norm = 2.7745e-01, time/batch = 17.4557s	
11498/16650 (epoch 34.529), train_loss = 0.90205690, grad/param norm = 3.5473e-01, time/batch = 16.4394s	
11499/16650 (epoch 34.532), train_loss = 0.61457838, grad/param norm = 3.2178e-01, time/batch = 16.5160s	
11500/16650 (epoch 34.535), train_loss = 0.68067549, grad/param norm = 3.5518e-01, time/batch = 17.2744s	
11501/16650 (epoch 34.538), train_loss = 0.63567812, grad/param norm = 2.6329e-01, time/batch = 15.1740s	
11502/16650 (epoch 34.541), train_loss = 0.92610409, grad/param norm = 3.3462e-01, time/batch = 17.3167s	
11503/16650 (epoch 34.544), train_loss = 0.95546699, grad/param norm = 4.8664e-01, time/batch = 15.1185s	
11504/16650 (epoch 34.547), train_loss = 0.69548409, grad/param norm = 2.9137e-01, time/batch = 17.5327s	
11505/16650 (epoch 34.550), train_loss = 0.77054428, grad/param norm = 2.9750e-01, time/batch = 18.0945s	
11506/16650 (epoch 34.553), train_loss = 0.77748347, grad/param norm = 2.9333e-01, time/batch = 15.4215s	
11507/16650 (epoch 34.556), train_loss = 0.70010633, grad/param norm = 2.8690e-01, time/batch = 17.5133s	
11508/16650 (epoch 34.559), train_loss = 0.64170684, grad/param norm = 3.1010e-01, time/batch = 18.8658s	
11509/16650 (epoch 34.562), train_loss = 0.71796532, grad/param norm = 2.6931e-01, time/batch = 17.3564s	
11510/16650 (epoch 34.565), train_loss = 0.62511647, grad/param norm = 3.0036e-01, time/batch = 16.7570s	
11511/16650 (epoch 34.568), train_loss = 0.63016861, grad/param norm = 2.7359e-01, time/batch = 19.1158s	
11512/16650 (epoch 34.571), train_loss = 0.70325162, grad/param norm = 3.6047e-01, time/batch = 18.6221s	
11513/16650 (epoch 34.574), train_loss = 0.71512371, grad/param norm = 3.1126e-01, time/batch = 16.2423s	
11514/16650 (epoch 34.577), train_loss = 0.73815110, grad/param norm = 2.7617e-01, time/batch = 18.5919s	
11515/16650 (epoch 34.580), train_loss = 0.67013939, grad/param norm = 2.5662e-01, time/batch = 13.7960s	
11516/16650 (epoch 34.583), train_loss = 0.76214089, grad/param norm = 2.7169e-01, time/batch = 13.8214s	
11517/16650 (epoch 34.586), train_loss = 0.70206741, grad/param norm = 3.3525e-01, time/batch = 14.4242s	
11518/16650 (epoch 34.589), train_loss = 0.66631928, grad/param norm = 2.5564e-01, time/batch = 19.1166s	
11519/16650 (epoch 34.592), train_loss = 0.76989349, grad/param norm = 2.8089e-01, time/batch = 17.1840s	
11520/16650 (epoch 34.595), train_loss = 0.69736456, grad/param norm = 3.0978e-01, time/batch = 17.0115s	
11521/16650 (epoch 34.598), train_loss = 0.73489988, grad/param norm = 3.0593e-01, time/batch = 17.2623s	
11522/16650 (epoch 34.601), train_loss = 0.72705876, grad/param norm = 3.2801e-01, time/batch = 17.7006s	
11523/16650 (epoch 34.604), train_loss = 0.79115342, grad/param norm = 2.8743e-01, time/batch = 17.2633s	
11524/16650 (epoch 34.607), train_loss = 0.82340932, grad/param norm = 2.8306e-01, time/batch = 16.2382s	
11525/16650 (epoch 34.610), train_loss = 0.67240429, grad/param norm = 2.6502e-01, time/batch = 18.8691s	
11526/16650 (epoch 34.613), train_loss = 0.88398679, grad/param norm = 3.4525e-01, time/batch = 17.5322s	
11527/16650 (epoch 34.616), train_loss = 0.84931420, grad/param norm = 3.6264e-01, time/batch = 16.4345s	
11528/16650 (epoch 34.619), train_loss = 0.65386710, grad/param norm = 3.0955e-01, time/batch = 16.5048s	
11529/16650 (epoch 34.622), train_loss = 0.61666945, grad/param norm = 2.6398e-01, time/batch = 16.1504s	
11530/16650 (epoch 34.625), train_loss = 0.73053074, grad/param norm = 2.5711e-01, time/batch = 18.0161s	
11531/16650 (epoch 34.628), train_loss = 0.71975961, grad/param norm = 3.3514e-01, time/batch = 17.6883s	
11532/16650 (epoch 34.631), train_loss = 0.76621497, grad/param norm = 3.1592e-01, time/batch = 16.5119s	
11533/16650 (epoch 34.634), train_loss = 0.92896007, grad/param norm = 3.3008e-01, time/batch = 16.2700s	
11534/16650 (epoch 34.637), train_loss = 0.91649703, grad/param norm = 2.8532e-01, time/batch = 16.7610s	
11535/16650 (epoch 34.640), train_loss = 0.73115979, grad/param norm = 2.7846e-01, time/batch = 18.9489s	
11536/16650 (epoch 34.643), train_loss = 0.83400181, grad/param norm = 2.7978e-01, time/batch = 17.3547s	
11537/16650 (epoch 34.646), train_loss = 0.80926282, grad/param norm = 3.0440e-01, time/batch = 17.0727s	
11538/16650 (epoch 34.649), train_loss = 0.79993792, grad/param norm = 2.9163e-01, time/batch = 17.7575s	
11539/16650 (epoch 34.652), train_loss = 0.83121223, grad/param norm = 3.2605e-01, time/batch = 18.6141s	
11540/16650 (epoch 34.655), train_loss = 0.78894124, grad/param norm = 3.3972e-01, time/batch = 18.2888s	
11541/16650 (epoch 34.658), train_loss = 0.70004008, grad/param norm = 2.7951e-01, time/batch = 16.5964s	
11542/16650 (epoch 34.661), train_loss = 0.80227379, grad/param norm = 3.0619e-01, time/batch = 17.4341s	
11543/16650 (epoch 34.664), train_loss = 0.78746528, grad/param norm = 3.3527e-01, time/batch = 16.5677s	
11544/16650 (epoch 34.667), train_loss = 0.87190652, grad/param norm = 2.8197e-01, time/batch = 16.3307s	
11545/16650 (epoch 34.670), train_loss = 0.65479740, grad/param norm = 2.6287e-01, time/batch = 17.5860s	
11546/16650 (epoch 34.673), train_loss = 0.68351583, grad/param norm = 2.4612e-01, time/batch = 19.2802s	
11547/16650 (epoch 34.676), train_loss = 0.82355228, grad/param norm = 2.9711e-01, time/batch = 17.7044s	
11548/16650 (epoch 34.679), train_loss = 0.68314881, grad/param norm = 2.9282e-01, time/batch = 17.2555s	
11549/16650 (epoch 34.682), train_loss = 0.76858304, grad/param norm = 3.1693e-01, time/batch = 16.5107s	
11550/16650 (epoch 34.685), train_loss = 0.65018509, grad/param norm = 2.8680e-01, time/batch = 18.0357s	
11551/16650 (epoch 34.688), train_loss = 0.84449240, grad/param norm = 3.2107e-01, time/batch = 16.9269s	
11552/16650 (epoch 34.691), train_loss = 0.81016598, grad/param norm = 2.9807e-01, time/batch = 18.0117s	
11553/16650 (epoch 34.694), train_loss = 0.71745865, grad/param norm = 2.7945e-01, time/batch = 18.8633s	
11554/16650 (epoch 34.697), train_loss = 0.64819275, grad/param norm = 2.4924e-01, time/batch = 16.9159s	
11555/16650 (epoch 34.700), train_loss = 0.81061128, grad/param norm = 2.9310e-01, time/batch = 16.7705s	
11556/16650 (epoch 34.703), train_loss = 0.68997272, grad/param norm = 2.9389e-01, time/batch = 18.2016s	
11557/16650 (epoch 34.706), train_loss = 0.75052973, grad/param norm = 3.0030e-01, time/batch = 16.4486s	
11558/16650 (epoch 34.709), train_loss = 0.64870457, grad/param norm = 2.5176e-01, time/batch = 15.8953s	
11559/16650 (epoch 34.712), train_loss = 0.68502554, grad/param norm = 2.8929e-01, time/batch = 16.7786s	
11560/16650 (epoch 34.715), train_loss = 0.80480900, grad/param norm = 2.8854e-01, time/batch = 18.1983s	
11561/16650 (epoch 34.718), train_loss = 0.81507729, grad/param norm = 2.6805e-01, time/batch = 15.0711s	
11562/16650 (epoch 34.721), train_loss = 0.84786817, grad/param norm = 2.9718e-01, time/batch = 17.1746s	
11563/16650 (epoch 34.724), train_loss = 0.84373103, grad/param norm = 3.2230e-01, time/batch = 17.8691s	
11564/16650 (epoch 34.727), train_loss = 0.86219307, grad/param norm = 3.1119e-01, time/batch = 18.0501s	
11565/16650 (epoch 34.730), train_loss = 0.70473344, grad/param norm = 2.8368e-01, time/batch = 15.9191s	
11566/16650 (epoch 34.733), train_loss = 0.86135054, grad/param norm = 3.1673e-01, time/batch = 18.3385s	
11567/16650 (epoch 34.736), train_loss = 0.65195372, grad/param norm = 2.6162e-01, time/batch = 16.6589s	
11568/16650 (epoch 34.739), train_loss = 0.78589580, grad/param norm = 2.5834e-01, time/batch = 16.9401s	
11569/16650 (epoch 34.742), train_loss = 0.76223392, grad/param norm = 2.7487e-01, time/batch = 14.6582s	
11570/16650 (epoch 34.745), train_loss = 0.60984876, grad/param norm = 2.7613e-01, time/batch = 17.8733s	
11571/16650 (epoch 34.748), train_loss = 0.66080304, grad/param norm = 2.8666e-01, time/batch = 16.8573s	
11572/16650 (epoch 34.751), train_loss = 0.78026851, grad/param norm = 3.9580e-01, time/batch = 16.1598s	
11573/16650 (epoch 34.754), train_loss = 0.93323757, grad/param norm = 3.2752e-01, time/batch = 18.2731s	
11574/16650 (epoch 34.757), train_loss = 0.91587261, grad/param norm = 3.1975e-01, time/batch = 17.3563s	
11575/16650 (epoch 34.760), train_loss = 0.76727253, grad/param norm = 2.7373e-01, time/batch = 17.8398s	
11576/16650 (epoch 34.763), train_loss = 0.71826043, grad/param norm = 3.1507e-01, time/batch = 17.5156s	
11577/16650 (epoch 34.766), train_loss = 0.74172407, grad/param norm = 2.7001e-01, time/batch = 18.2657s	
11578/16650 (epoch 34.769), train_loss = 0.79927877, grad/param norm = 2.8045e-01, time/batch = 18.6953s	
11579/16650 (epoch 34.772), train_loss = 0.76749158, grad/param norm = 2.4902e-01, time/batch = 15.9997s	
11580/16650 (epoch 34.775), train_loss = 0.74339127, grad/param norm = 2.7673e-01, time/batch = 15.3993s	
11581/16650 (epoch 34.778), train_loss = 0.77476784, grad/param norm = 2.5828e-01, time/batch = 19.2700s	
11582/16650 (epoch 34.781), train_loss = 0.91362981, grad/param norm = 2.7227e-01, time/batch = 17.2817s	
11583/16650 (epoch 34.784), train_loss = 0.78079065, grad/param norm = 2.5845e-01, time/batch = 17.9452s	
11584/16650 (epoch 34.787), train_loss = 0.84312660, grad/param norm = 3.0331e-01, time/batch = 16.1712s	
11585/16650 (epoch 34.790), train_loss = 0.85131581, grad/param norm = 3.0415e-01, time/batch = 15.4299s	
11586/16650 (epoch 34.793), train_loss = 0.67795506, grad/param norm = 3.2541e-01, time/batch = 16.5825s	
11587/16650 (epoch 34.796), train_loss = 1.01985204, grad/param norm = 3.3589e-01, time/batch = 17.6045s	
11588/16650 (epoch 34.799), train_loss = 0.93265344, grad/param norm = 3.5548e-01, time/batch = 18.0347s	
11589/16650 (epoch 34.802), train_loss = 0.85952282, grad/param norm = 3.4071e-01, time/batch = 15.4125s	
11590/16650 (epoch 34.805), train_loss = 0.79120656, grad/param norm = 2.8369e-01, time/batch = 3.1418s	
11591/16650 (epoch 34.808), train_loss = 0.84096986, grad/param norm = 2.6619e-01, time/batch = 0.6361s	
11592/16650 (epoch 34.811), train_loss = 0.88810472, grad/param norm = 3.1670e-01, time/batch = 0.6298s	
11593/16650 (epoch 34.814), train_loss = 0.70199183, grad/param norm = 2.7416e-01, time/batch = 0.6313s	
11594/16650 (epoch 34.817), train_loss = 0.73784988, grad/param norm = 3.0021e-01, time/batch = 0.6290s	
11595/16650 (epoch 34.820), train_loss = 0.82620372, grad/param norm = 2.9438e-01, time/batch = 0.6614s	
11596/16650 (epoch 34.823), train_loss = 0.78246845, grad/param norm = 2.8759e-01, time/batch = 0.6675s	
11597/16650 (epoch 34.826), train_loss = 0.73480040, grad/param norm = 2.8716e-01, time/batch = 0.6852s	
11598/16650 (epoch 34.829), train_loss = 0.80230731, grad/param norm = 3.0750e-01, time/batch = 0.9360s	
11599/16650 (epoch 34.832), train_loss = 0.83927020, grad/param norm = 2.6382e-01, time/batch = 0.9732s	
11600/16650 (epoch 34.835), train_loss = 0.83800130, grad/param norm = 3.5187e-01, time/batch = 0.9453s	
11601/16650 (epoch 34.838), train_loss = 0.70885946, grad/param norm = 2.7159e-01, time/batch = 0.9255s	
11602/16650 (epoch 34.841), train_loss = 0.71283793, grad/param norm = 2.4489e-01, time/batch = 0.9412s	
11603/16650 (epoch 34.844), train_loss = 0.72009604, grad/param norm = 2.4588e-01, time/batch = 1.6279s	
11604/16650 (epoch 34.847), train_loss = 0.85181894, grad/param norm = 3.5148e-01, time/batch = 1.7605s	
11605/16650 (epoch 34.850), train_loss = 0.69501247, grad/param norm = 2.8408e-01, time/batch = 2.0354s	
11606/16650 (epoch 34.853), train_loss = 0.76806763, grad/param norm = 2.7955e-01, time/batch = 17.0984s	
11607/16650 (epoch 34.856), train_loss = 0.71543959, grad/param norm = 2.6906e-01, time/batch = 18.1013s	
11608/16650 (epoch 34.859), train_loss = 0.90540486, grad/param norm = 3.9627e-01, time/batch = 16.0138s	
11609/16650 (epoch 34.862), train_loss = 0.75536728, grad/param norm = 3.1702e-01, time/batch = 17.6231s	
11610/16650 (epoch 34.865), train_loss = 0.62333132, grad/param norm = 2.6427e-01, time/batch = 17.9456s	
11611/16650 (epoch 34.868), train_loss = 0.81004202, grad/param norm = 3.1019e-01, time/batch = 16.9326s	
11612/16650 (epoch 34.871), train_loss = 0.82378929, grad/param norm = 2.8822e-01, time/batch = 17.1785s	
11613/16650 (epoch 34.874), train_loss = 0.82172810, grad/param norm = 2.7817e-01, time/batch = 18.1205s	
11614/16650 (epoch 34.877), train_loss = 0.79169356, grad/param norm = 2.6459e-01, time/batch = 17.9704s	
11615/16650 (epoch 34.880), train_loss = 0.71150127, grad/param norm = 3.1231e-01, time/batch = 17.3384s	
11616/16650 (epoch 34.883), train_loss = 0.80356896, grad/param norm = 3.0955e-01, time/batch = 18.0442s	
11617/16650 (epoch 34.886), train_loss = 0.79459491, grad/param norm = 2.8158e-01, time/batch = 15.9130s	
11618/16650 (epoch 34.889), train_loss = 0.66276487, grad/param norm = 3.1194e-01, time/batch = 16.5226s	
11619/16650 (epoch 34.892), train_loss = 0.77109584, grad/param norm = 2.4702e-01, time/batch = 17.7797s	
11620/16650 (epoch 34.895), train_loss = 0.80483560, grad/param norm = 3.1862e-01, time/batch = 14.3995s	
11621/16650 (epoch 34.898), train_loss = 0.79266794, grad/param norm = 3.4230e-01, time/batch = 18.4642s	
11622/16650 (epoch 34.901), train_loss = 0.73029604, grad/param norm = 2.6705e-01, time/batch = 16.7199s	
11623/16650 (epoch 34.904), train_loss = 0.72805761, grad/param norm = 2.8115e-01, time/batch = 17.7839s	
11624/16650 (epoch 34.907), train_loss = 0.79283458, grad/param norm = 3.0053e-01, time/batch = 18.2842s	
11625/16650 (epoch 34.910), train_loss = 0.83302887, grad/param norm = 3.8447e-01, time/batch = 16.0972s	
11626/16650 (epoch 34.913), train_loss = 0.74009189, grad/param norm = 3.1083e-01, time/batch = 18.6068s	
11627/16650 (epoch 34.916), train_loss = 0.73318543, grad/param norm = 3.3019e-01, time/batch = 15.9972s	
11628/16650 (epoch 34.919), train_loss = 0.90822257, grad/param norm = 3.2303e-01, time/batch = 18.3582s	
11629/16650 (epoch 34.922), train_loss = 0.82033356, grad/param norm = 3.4182e-01, time/batch = 17.7671s	
11630/16650 (epoch 34.925), train_loss = 0.73474320, grad/param norm = 3.1509e-01, time/batch = 18.2021s	
11631/16650 (epoch 34.928), train_loss = 0.77768251, grad/param norm = 2.7059e-01, time/batch = 17.5272s	
11632/16650 (epoch 34.931), train_loss = 0.82536608, grad/param norm = 3.7370e-01, time/batch = 14.8249s	
11633/16650 (epoch 34.934), train_loss = 0.66686879, grad/param norm = 3.2118e-01, time/batch = 16.9479s	
11634/16650 (epoch 34.937), train_loss = 0.69223626, grad/param norm = 3.1179e-01, time/batch = 14.1756s	
11635/16650 (epoch 34.940), train_loss = 0.75314090, grad/param norm = 2.5954e-01, time/batch = 17.6248s	
11636/16650 (epoch 34.943), train_loss = 0.78771061, grad/param norm = 3.4223e-01, time/batch = 16.4081s	
11637/16650 (epoch 34.946), train_loss = 0.73517227, grad/param norm = 3.6899e-01, time/batch = 18.6135s	
11638/16650 (epoch 34.949), train_loss = 0.67892991, grad/param norm = 3.0642e-01, time/batch = 17.7761s	
11639/16650 (epoch 34.952), train_loss = 0.66352142, grad/param norm = 2.5777e-01, time/batch = 14.2877s	
11640/16650 (epoch 34.955), train_loss = 0.77156581, grad/param norm = 2.9479e-01, time/batch = 0.6412s	
11641/16650 (epoch 34.958), train_loss = 0.82603205, grad/param norm = 3.4883e-01, time/batch = 0.6458s	
11642/16650 (epoch 34.961), train_loss = 0.75250996, grad/param norm = 2.5382e-01, time/batch = 0.6387s	
11643/16650 (epoch 34.964), train_loss = 0.68211192, grad/param norm = 2.9104e-01, time/batch = 0.6298s	
11644/16650 (epoch 34.967), train_loss = 0.90189913, grad/param norm = 3.0777e-01, time/batch = 0.6297s	
11645/16650 (epoch 34.970), train_loss = 0.72027323, grad/param norm = 2.5537e-01, time/batch = 0.6317s	
11646/16650 (epoch 34.973), train_loss = 0.71863770, grad/param norm = 2.9578e-01, time/batch = 0.6504s	
11647/16650 (epoch 34.976), train_loss = 0.70340303, grad/param norm = 2.6691e-01, time/batch = 0.7874s	
11648/16650 (epoch 34.979), train_loss = 0.80290327, grad/param norm = 3.0116e-01, time/batch = 0.9446s	
11649/16650 (epoch 34.982), train_loss = 0.81631345, grad/param norm = 2.7079e-01, time/batch = 0.9390s	
11650/16650 (epoch 34.985), train_loss = 0.74442889, grad/param norm = 2.6765e-01, time/batch = 0.9615s	
11651/16650 (epoch 34.988), train_loss = 0.80867869, grad/param norm = 3.0890e-01, time/batch = 0.9133s	
11652/16650 (epoch 34.991), train_loss = 0.70332279, grad/param norm = 2.8287e-01, time/batch = 0.9806s	
11653/16650 (epoch 34.994), train_loss = 0.71155964, grad/param norm = 2.4815e-01, time/batch = 1.6969s	
11654/16650 (epoch 34.997), train_loss = 0.75025441, grad/param norm = 2.8728e-01, time/batch = 1.7478s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
11655/16650 (epoch 35.000), train_loss = 0.83502358, grad/param norm = 3.2229e-01, time/batch = 4.1867s	
11656/16650 (epoch 35.003), train_loss = 0.90156481, grad/param norm = 4.1656e-01, time/batch = 17.7210s	
11657/16650 (epoch 35.006), train_loss = 0.86907069, grad/param norm = 3.6295e-01, time/batch = 17.1310s	
11658/16650 (epoch 35.009), train_loss = 0.90520168, grad/param norm = 3.0926e-01, time/batch = 16.5150s	
11659/16650 (epoch 35.012), train_loss = 0.90122294, grad/param norm = 3.1809e-01, time/batch = 17.7148s	
11660/16650 (epoch 35.015), train_loss = 0.77973445, grad/param norm = 2.7255e-01, time/batch = 17.4753s	
11661/16650 (epoch 35.018), train_loss = 0.66070886, grad/param norm = 2.7515e-01, time/batch = 15.9404s	
11662/16650 (epoch 35.021), train_loss = 0.91071894, grad/param norm = 3.7662e-01, time/batch = 17.7776s	
11663/16650 (epoch 35.024), train_loss = 0.77202938, grad/param norm = 3.0845e-01, time/batch = 16.8505s	
11664/16650 (epoch 35.027), train_loss = 0.81953641, grad/param norm = 2.7289e-01, time/batch = 16.2922s	
11665/16650 (epoch 35.030), train_loss = 0.67109908, grad/param norm = 2.5282e-01, time/batch = 14.7354s	
11666/16650 (epoch 35.033), train_loss = 0.76562619, grad/param norm = 2.7450e-01, time/batch = 17.3496s	
11667/16650 (epoch 35.036), train_loss = 0.57358976, grad/param norm = 3.1769e-01, time/batch = 17.1113s	
11668/16650 (epoch 35.039), train_loss = 0.87051155, grad/param norm = 2.6271e-01, time/batch = 16.4393s	
11669/16650 (epoch 35.042), train_loss = 0.80875421, grad/param norm = 3.2385e-01, time/batch = 17.2032s	
11670/16650 (epoch 35.045), train_loss = 0.74274997, grad/param norm = 2.6750e-01, time/batch = 18.0371s	
11671/16650 (epoch 35.048), train_loss = 0.85369709, grad/param norm = 3.4072e-01, time/batch = 15.6067s	
11672/16650 (epoch 35.051), train_loss = 0.75632923, grad/param norm = 2.7033e-01, time/batch = 15.0838s	
11673/16650 (epoch 35.054), train_loss = 0.78452993, grad/param norm = 3.2254e-01, time/batch = 18.0221s	
11674/16650 (epoch 35.057), train_loss = 0.79258826, grad/param norm = 3.1642e-01, time/batch = 16.8516s	
11675/16650 (epoch 35.060), train_loss = 0.65435826, grad/param norm = 2.3506e-01, time/batch = 17.8716s	
11676/16650 (epoch 35.063), train_loss = 0.73639495, grad/param norm = 2.7810e-01, time/batch = 17.1587s	
11677/16650 (epoch 35.066), train_loss = 0.91506167, grad/param norm = 2.9319e-01, time/batch = 16.6710s	
11678/16650 (epoch 35.069), train_loss = 0.84998501, grad/param norm = 3.3290e-01, time/batch = 16.3343s	
11679/16650 (epoch 35.072), train_loss = 0.78530085, grad/param norm = 3.4663e-01, time/batch = 16.0688s	
11680/16650 (epoch 35.075), train_loss = 0.86288915, grad/param norm = 3.3891e-01, time/batch = 16.5983s	
11681/16650 (epoch 35.078), train_loss = 0.85149448, grad/param norm = 3.1112e-01, time/batch = 17.9601s	
11682/16650 (epoch 35.081), train_loss = 0.83136690, grad/param norm = 3.4257e-01, time/batch = 17.0189s	
11683/16650 (epoch 35.084), train_loss = 0.82222791, grad/param norm = 3.0978e-01, time/batch = 17.5216s	
11684/16650 (epoch 35.087), train_loss = 0.81671298, grad/param norm = 2.8633e-01, time/batch = 18.3640s	
11685/16650 (epoch 35.090), train_loss = 0.76171396, grad/param norm = 2.9971e-01, time/batch = 17.8487s	
11686/16650 (epoch 35.093), train_loss = 0.90669831, grad/param norm = 3.7484e-01, time/batch = 16.9362s	
11687/16650 (epoch 35.096), train_loss = 0.73441121, grad/param norm = 2.9299e-01, time/batch = 18.2040s	
11688/16650 (epoch 35.099), train_loss = 0.81715677, grad/param norm = 3.1328e-01, time/batch = 16.8526s	
11689/16650 (epoch 35.102), train_loss = 0.79415845, grad/param norm = 2.8901e-01, time/batch = 21.2762s	
11690/16650 (epoch 35.105), train_loss = 0.79404483, grad/param norm = 3.1424e-01, time/batch = 28.4052s	
11691/16650 (epoch 35.108), train_loss = 0.79958108, grad/param norm = 2.7900e-01, time/batch = 18.1192s	
11692/16650 (epoch 35.111), train_loss = 0.86551468, grad/param norm = 2.9607e-01, time/batch = 16.2593s	
11693/16650 (epoch 35.114), train_loss = 0.84535759, grad/param norm = 3.3477e-01, time/batch = 18.1073s	
11694/16650 (epoch 35.117), train_loss = 0.94552405, grad/param norm = 2.9983e-01, time/batch = 18.5259s	
11695/16650 (epoch 35.120), train_loss = 0.77883774, grad/param norm = 2.6092e-01, time/batch = 15.4179s	
11696/16650 (epoch 35.123), train_loss = 0.77112130, grad/param norm = 2.7372e-01, time/batch = 16.5131s	
11697/16650 (epoch 35.126), train_loss = 0.81684502, grad/param norm = 2.7240e-01, time/batch = 17.0012s	
11698/16650 (epoch 35.129), train_loss = 0.82567028, grad/param norm = 3.1366e-01, time/batch = 18.7843s	
11699/16650 (epoch 35.132), train_loss = 0.78584731, grad/param norm = 2.9135e-01, time/batch = 16.1700s	
11700/16650 (epoch 35.135), train_loss = 0.87517892, grad/param norm = 2.6341e-01, time/batch = 18.0040s	
11701/16650 (epoch 35.138), train_loss = 0.85123992, grad/param norm = 2.8943e-01, time/batch = 17.3704s	
11702/16650 (epoch 35.141), train_loss = 0.83715301, grad/param norm = 3.3273e-01, time/batch = 16.5998s	
11703/16650 (epoch 35.144), train_loss = 0.82772966, grad/param norm = 2.9322e-01, time/batch = 16.4349s	
11704/16650 (epoch 35.147), train_loss = 0.91515353, grad/param norm = 2.8216e-01, time/batch = 18.1294s	
11705/16650 (epoch 35.150), train_loss = 1.00607576, grad/param norm = 3.2868e-01, time/batch = 18.4609s	
11706/16650 (epoch 35.153), train_loss = 0.82362616, grad/param norm = 2.9336e-01, time/batch = 17.5028s	
11707/16650 (epoch 35.156), train_loss = 0.76413142, grad/param norm = 2.7005e-01, time/batch = 17.8475s	
11708/16650 (epoch 35.159), train_loss = 0.84897349, grad/param norm = 2.6751e-01, time/batch = 16.9408s	
11709/16650 (epoch 35.162), train_loss = 0.91912586, grad/param norm = 2.9203e-01, time/batch = 16.5064s	
11710/16650 (epoch 35.165), train_loss = 0.89709203, grad/param norm = 2.9180e-01, time/batch = 18.0240s	
11711/16650 (epoch 35.168), train_loss = 0.67949382, grad/param norm = 2.5328e-01, time/batch = 18.1919s	
11712/16650 (epoch 35.171), train_loss = 0.84752356, grad/param norm = 2.8989e-01, time/batch = 16.5081s	
11713/16650 (epoch 35.174), train_loss = 0.66473924, grad/param norm = 2.7632e-01, time/batch = 15.3138s	
11714/16650 (epoch 35.177), train_loss = 0.80769125, grad/param norm = 3.1858e-01, time/batch = 15.0323s	
11715/16650 (epoch 35.180), train_loss = 0.88532240, grad/param norm = 2.8791e-01, time/batch = 14.3191s	
11716/16650 (epoch 35.183), train_loss = 1.03688131, grad/param norm = 3.5920e-01, time/batch = 14.4726s	
11717/16650 (epoch 35.186), train_loss = 0.85552230, grad/param norm = 3.9535e-01, time/batch = 15.3085s	
11718/16650 (epoch 35.189), train_loss = 0.73770913, grad/param norm = 2.5451e-01, time/batch = 18.2044s	
11719/16650 (epoch 35.192), train_loss = 0.79660359, grad/param norm = 2.9842e-01, time/batch = 17.1032s	
11720/16650 (epoch 35.195), train_loss = 0.74017913, grad/param norm = 3.0810e-01, time/batch = 16.4318s	
11721/16650 (epoch 35.198), train_loss = 0.69196555, grad/param norm = 2.5123e-01, time/batch = 18.6921s	
11722/16650 (epoch 35.201), train_loss = 0.71150205, grad/param norm = 2.7913e-01, time/batch = 18.3728s	
11723/16650 (epoch 35.204), train_loss = 0.80789120, grad/param norm = 2.7209e-01, time/batch = 16.2431s	
11724/16650 (epoch 35.207), train_loss = 0.83023880, grad/param norm = 3.1914e-01, time/batch = 16.5128s	
11725/16650 (epoch 35.210), train_loss = 0.78409492, grad/param norm = 2.7811e-01, time/batch = 16.8490s	
11726/16650 (epoch 35.213), train_loss = 0.84589142, grad/param norm = 2.8508e-01, time/batch = 17.5805s	
11727/16650 (epoch 35.216), train_loss = 0.75285450, grad/param norm = 2.9732e-01, time/batch = 17.3282s	
11728/16650 (epoch 35.219), train_loss = 0.78503267, grad/param norm = 2.9071e-01, time/batch = 16.6863s	
11729/16650 (epoch 35.222), train_loss = 0.81650496, grad/param norm = 2.7580e-01, time/batch = 18.6222s	
11730/16650 (epoch 35.225), train_loss = 0.82583731, grad/param norm = 3.2424e-01, time/batch = 17.1065s	
11731/16650 (epoch 35.228), train_loss = 0.74046308, grad/param norm = 3.0832e-01, time/batch = 16.6770s	
11732/16650 (epoch 35.231), train_loss = 0.72839253, grad/param norm = 2.8409e-01, time/batch = 17.6816s	
11733/16650 (epoch 35.234), train_loss = 0.95089080, grad/param norm = 3.0021e-01, time/batch = 15.9356s	
11734/16650 (epoch 35.237), train_loss = 0.80923837, grad/param norm = 2.8735e-01, time/batch = 15.8404s	
11735/16650 (epoch 35.240), train_loss = 0.81834446, grad/param norm = 2.6919e-01, time/batch = 18.7526s	
11736/16650 (epoch 35.243), train_loss = 0.78349419, grad/param norm = 2.7494e-01, time/batch = 18.2684s	
11737/16650 (epoch 35.246), train_loss = 0.91907332, grad/param norm = 3.4516e-01, time/batch = 16.0957s	
11738/16650 (epoch 35.249), train_loss = 0.66523295, grad/param norm = 2.3232e-01, time/batch = 17.5230s	
11739/16650 (epoch 35.252), train_loss = 0.76792862, grad/param norm = 2.7460e-01, time/batch = 17.7863s	
11740/16650 (epoch 35.255), train_loss = 0.82684167, grad/param norm = 2.9908e-01, time/batch = 17.1893s	
11741/16650 (epoch 35.258), train_loss = 0.86146822, grad/param norm = 2.7607e-01, time/batch = 16.8264s	
11742/16650 (epoch 35.261), train_loss = 0.83672245, grad/param norm = 2.8754e-01, time/batch = 16.8481s	
11743/16650 (epoch 35.264), train_loss = 0.74419581, grad/param norm = 2.6462e-01, time/batch = 18.0251s	
11744/16650 (epoch 35.267), train_loss = 0.78308569, grad/param norm = 3.7036e-01, time/batch = 16.2544s	
11745/16650 (epoch 35.270), train_loss = 0.83074969, grad/param norm = 2.7034e-01, time/batch = 17.3540s	
11746/16650 (epoch 35.273), train_loss = 0.88954223, grad/param norm = 2.7915e-01, time/batch = 17.8349s	
11747/16650 (epoch 35.276), train_loss = 0.82804736, grad/param norm = 3.0492e-01, time/batch = 17.6156s	
11748/16650 (epoch 35.279), train_loss = 0.78351929, grad/param norm = 2.7706e-01, time/batch = 15.8118s	
11749/16650 (epoch 35.282), train_loss = 0.73114806, grad/param norm = 2.6991e-01, time/batch = 16.3548s	
11750/16650 (epoch 35.285), train_loss = 0.75668617, grad/param norm = 2.9944e-01, time/batch = 14.7528s	
11751/16650 (epoch 35.288), train_loss = 0.72014077, grad/param norm = 3.0807e-01, time/batch = 15.2773s	
11752/16650 (epoch 35.291), train_loss = 0.59074669, grad/param norm = 2.3231e-01, time/batch = 15.4873s	
11753/16650 (epoch 35.294), train_loss = 0.71416429, grad/param norm = 2.6568e-01, time/batch = 16.1206s	
11754/16650 (epoch 35.297), train_loss = 0.76848079, grad/param norm = 2.6469e-01, time/batch = 15.3141s	
11755/16650 (epoch 35.300), train_loss = 0.62224601, grad/param norm = 2.3168e-01, time/batch = 15.7866s	
11756/16650 (epoch 35.303), train_loss = 0.66238244, grad/param norm = 2.4303e-01, time/batch = 16.1645s	
11757/16650 (epoch 35.306), train_loss = 0.85792029, grad/param norm = 2.7365e-01, time/batch = 18.4558s	
11758/16650 (epoch 35.309), train_loss = 0.85041364, grad/param norm = 2.9789e-01, time/batch = 18.2755s	
11759/16650 (epoch 35.312), train_loss = 0.67107575, grad/param norm = 2.8723e-01, time/batch = 16.5913s	
11760/16650 (epoch 35.315), train_loss = 0.55898271, grad/param norm = 2.1287e-01, time/batch = 18.3496s	
11761/16650 (epoch 35.318), train_loss = 0.66220077, grad/param norm = 2.5449e-01, time/batch = 17.6989s	
11762/16650 (epoch 35.321), train_loss = 0.87008913, grad/param norm = 3.2252e-01, time/batch = 16.4415s	
11763/16650 (epoch 35.324), train_loss = 0.71540071, grad/param norm = 3.5469e-01, time/batch = 15.0491s	
11764/16650 (epoch 35.327), train_loss = 0.80396722, grad/param norm = 3.2617e-01, time/batch = 16.9334s	
11765/16650 (epoch 35.330), train_loss = 0.80337138, grad/param norm = 3.4328e-01, time/batch = 18.7896s	
11766/16650 (epoch 35.333), train_loss = 0.83608473, grad/param norm = 3.2100e-01, time/batch = 17.2630s	
11767/16650 (epoch 35.336), train_loss = 0.69381331, grad/param norm = 2.8698e-01, time/batch = 17.3578s	
11768/16650 (epoch 35.339), train_loss = 0.72655843, grad/param norm = 2.9779e-01, time/batch = 15.2029s	
11769/16650 (epoch 35.342), train_loss = 0.67390445, grad/param norm = 3.0190e-01, time/batch = 14.7757s	
11770/16650 (epoch 35.345), train_loss = 0.69386071, grad/param norm = 2.6657e-01, time/batch = 17.5181s	
11771/16650 (epoch 35.348), train_loss = 0.78019716, grad/param norm = 3.0366e-01, time/batch = 18.6930s	
11772/16650 (epoch 35.351), train_loss = 0.81392050, grad/param norm = 3.0323e-01, time/batch = 17.5266s	
11773/16650 (epoch 35.354), train_loss = 0.86336675, grad/param norm = 3.7914e-01, time/batch = 15.6581s	
11774/16650 (epoch 35.357), train_loss = 0.82114159, grad/param norm = 3.0077e-01, time/batch = 16.2829s	
11775/16650 (epoch 35.360), train_loss = 0.80516800, grad/param norm = 3.4185e-01, time/batch = 18.1908s	
11776/16650 (epoch 35.363), train_loss = 0.86903131, grad/param norm = 3.5537e-01, time/batch = 15.9769s	
11777/16650 (epoch 35.366), train_loss = 0.92703091, grad/param norm = 3.1003e-01, time/batch = 16.1644s	
11778/16650 (epoch 35.369), train_loss = 0.82498172, grad/param norm = 3.0070e-01, time/batch = 16.7706s	
11779/16650 (epoch 35.372), train_loss = 0.80280325, grad/param norm = 2.9506e-01, time/batch = 18.8628s	
11780/16650 (epoch 35.375), train_loss = 0.80910659, grad/param norm = 2.5904e-01, time/batch = 15.0527s	
11781/16650 (epoch 35.378), train_loss = 0.75583150, grad/param norm = 2.7208e-01, time/batch = 18.0369s	
11782/16650 (epoch 35.381), train_loss = 0.83270620, grad/param norm = 3.3853e-01, time/batch = 17.5280s	
11783/16650 (epoch 35.384), train_loss = 0.92284439, grad/param norm = 3.2355e-01, time/batch = 17.9304s	
11784/16650 (epoch 35.387), train_loss = 0.61993912, grad/param norm = 2.7628e-01, time/batch = 16.7678s	
11785/16650 (epoch 35.390), train_loss = 0.85583861, grad/param norm = 2.8274e-01, time/batch = 18.7100s	
11786/16650 (epoch 35.393), train_loss = 0.74412765, grad/param norm = 3.1097e-01, time/batch = 17.6006s	
11787/16650 (epoch 35.396), train_loss = 0.88481038, grad/param norm = 3.2097e-01, time/batch = 15.9098s	
11788/16650 (epoch 35.399), train_loss = 0.84765361, grad/param norm = 2.8210e-01, time/batch = 17.5433s	
11789/16650 (epoch 35.402), train_loss = 0.76319346, grad/param norm = 2.7925e-01, time/batch = 18.2175s	
11790/16650 (epoch 35.405), train_loss = 0.63899867, grad/param norm = 3.1170e-01, time/batch = 16.9492s	
11791/16650 (epoch 35.408), train_loss = 0.81026298, grad/param norm = 3.3351e-01, time/batch = 17.5023s	
11792/16650 (epoch 35.411), train_loss = 0.70453499, grad/param norm = 3.4867e-01, time/batch = 16.6860s	
11793/16650 (epoch 35.414), train_loss = 0.70935251, grad/param norm = 3.0646e-01, time/batch = 16.8236s	
11794/16650 (epoch 35.417), train_loss = 0.67251551, grad/param norm = 2.7743e-01, time/batch = 15.9079s	
11795/16650 (epoch 35.420), train_loss = 0.68970229, grad/param norm = 2.8805e-01, time/batch = 18.7655s	
11796/16650 (epoch 35.423), train_loss = 0.58133173, grad/param norm = 2.6492e-01, time/batch = 15.2584s	
11797/16650 (epoch 35.426), train_loss = 0.69622623, grad/param norm = 2.9639e-01, time/batch = 14.8381s	
11798/16650 (epoch 35.429), train_loss = 0.85533736, grad/param norm = 3.1197e-01, time/batch = 15.5689s	
11799/16650 (epoch 35.432), train_loss = 0.86512711, grad/param norm = 3.4300e-01, time/batch = 16.8876s	
11800/16650 (epoch 35.435), train_loss = 0.95578848, grad/param norm = 3.1009e-01, time/batch = 15.1710s	
11801/16650 (epoch 35.438), train_loss = 0.94235406, grad/param norm = 3.5060e-01, time/batch = 16.6056s	
11802/16650 (epoch 35.441), train_loss = 0.77642387, grad/param norm = 3.3694e-01, time/batch = 16.8364s	
11803/16650 (epoch 35.444), train_loss = 0.74490433, grad/param norm = 3.0473e-01, time/batch = 17.7103s	
11804/16650 (epoch 35.447), train_loss = 0.72274245, grad/param norm = 2.9823e-01, time/batch = 13.6752s	
11805/16650 (epoch 35.450), train_loss = 0.73457062, grad/param norm = 2.8602e-01, time/batch = 14.3888s	
11806/16650 (epoch 35.453), train_loss = 0.71473090, grad/param norm = 3.0509e-01, time/batch = 14.2029s	
11807/16650 (epoch 35.456), train_loss = 0.69547334, grad/param norm = 2.4905e-01, time/batch = 14.3050s	
11808/16650 (epoch 35.459), train_loss = 0.72039272, grad/param norm = 3.1582e-01, time/batch = 15.1477s	
11809/16650 (epoch 35.462), train_loss = 0.86935080, grad/param norm = 3.0807e-01, time/batch = 14.8841s	
11810/16650 (epoch 35.465), train_loss = 0.71186182, grad/param norm = 3.1969e-01, time/batch = 15.4371s	
11811/16650 (epoch 35.468), train_loss = 0.59447331, grad/param norm = 2.5928e-01, time/batch = 15.7448s	
11812/16650 (epoch 35.471), train_loss = 0.53499538, grad/param norm = 2.4757e-01, time/batch = 18.6094s	
11813/16650 (epoch 35.474), train_loss = 0.65739807, grad/param norm = 2.5995e-01, time/batch = 16.7483s	
11814/16650 (epoch 35.477), train_loss = 0.83928057, grad/param norm = 3.1151e-01, time/batch = 17.4316s	
11815/16650 (epoch 35.480), train_loss = 0.78391668, grad/param norm = 3.4296e-01, time/batch = 16.4904s	
11816/16650 (epoch 35.483), train_loss = 0.84657795, grad/param norm = 2.9967e-01, time/batch = 17.0183s	
11817/16650 (epoch 35.486), train_loss = 0.68148528, grad/param norm = 2.4276e-01, time/batch = 17.2578s	
11818/16650 (epoch 35.489), train_loss = 0.74484610, grad/param norm = 2.8374e-01, time/batch = 16.8484s	
11819/16650 (epoch 35.492), train_loss = 0.75947371, grad/param norm = 2.5882e-01, time/batch = 17.6641s	
11820/16650 (epoch 35.495), train_loss = 0.66590023, grad/param norm = 3.2848e-01, time/batch = 16.5927s	
11821/16650 (epoch 35.498), train_loss = 0.71065227, grad/param norm = 3.0403e-01, time/batch = 18.0315s	
11822/16650 (epoch 35.502), train_loss = 0.91656785, grad/param norm = 3.4919e-01, time/batch = 18.8779s	
11823/16650 (epoch 35.505), train_loss = 0.79566923, grad/param norm = 2.7526e-01, time/batch = 15.7587s	
11824/16650 (epoch 35.508), train_loss = 0.82793779, grad/param norm = 3.2742e-01, time/batch = 18.1139s	
11825/16650 (epoch 35.511), train_loss = 0.84182677, grad/param norm = 2.7772e-01, time/batch = 14.8664s	
11826/16650 (epoch 35.514), train_loss = 0.67717654, grad/param norm = 2.7900e-01, time/batch = 14.7436s	
11827/16650 (epoch 35.517), train_loss = 0.74780010, grad/param norm = 2.9798e-01, time/batch = 15.3276s	
11828/16650 (epoch 35.520), train_loss = 0.65138017, grad/param norm = 2.5965e-01, time/batch = 16.0079s	
11829/16650 (epoch 35.523), train_loss = 0.74583177, grad/param norm = 2.7974e-01, time/batch = 15.4427s	
11830/16650 (epoch 35.526), train_loss = 0.82917543, grad/param norm = 2.9424e-01, time/batch = 16.0957s	
11831/16650 (epoch 35.529), train_loss = 0.87320524, grad/param norm = 3.3064e-01, time/batch = 14.8084s	
11832/16650 (epoch 35.532), train_loss = 0.58564977, grad/param norm = 2.6712e-01, time/batch = 17.8627s	
11833/16650 (epoch 35.535), train_loss = 0.68801143, grad/param norm = 3.3659e-01, time/batch = 17.0211s	
11834/16650 (epoch 35.538), train_loss = 0.63117724, grad/param norm = 3.1639e-01, time/batch = 16.1770s	
11835/16650 (epoch 35.541), train_loss = 0.90142091, grad/param norm = 3.4536e-01, time/batch = 17.7719s	
11836/16650 (epoch 35.544), train_loss = 0.94696164, grad/param norm = 4.9816e-01, time/batch = 17.4137s	
11837/16650 (epoch 35.547), train_loss = 0.68121096, grad/param norm = 2.9834e-01, time/batch = 18.3629s	
11838/16650 (epoch 35.550), train_loss = 0.75558659, grad/param norm = 2.6288e-01, time/batch = 17.2453s	
11839/16650 (epoch 35.553), train_loss = 0.77643912, grad/param norm = 3.2142e-01, time/batch = 14.5622s	
11840/16650 (epoch 35.556), train_loss = 0.68514242, grad/param norm = 2.8742e-01, time/batch = 16.9490s	
11841/16650 (epoch 35.559), train_loss = 0.62678821, grad/param norm = 2.8833e-01, time/batch = 16.9399s	
11842/16650 (epoch 35.562), train_loss = 0.71000140, grad/param norm = 2.8074e-01, time/batch = 15.7451s	
11843/16650 (epoch 35.565), train_loss = 0.61584640, grad/param norm = 2.8923e-01, time/batch = 18.3599s	
11844/16650 (epoch 35.568), train_loss = 0.61942860, grad/param norm = 2.9622e-01, time/batch = 17.8780s	
11845/16650 (epoch 35.571), train_loss = 0.68498288, grad/param norm = 3.0527e-01, time/batch = 16.5093s	
11846/16650 (epoch 35.574), train_loss = 0.70294359, grad/param norm = 3.2968e-01, time/batch = 18.4356s	
11847/16650 (epoch 35.577), train_loss = 0.72161075, grad/param norm = 2.6178e-01, time/batch = 17.5337s	
11848/16650 (epoch 35.580), train_loss = 0.66087441, grad/param norm = 2.7696e-01, time/batch = 16.4332s	
11849/16650 (epoch 35.583), train_loss = 0.75932983, grad/param norm = 2.9299e-01, time/batch = 15.4166s	
11850/16650 (epoch 35.586), train_loss = 0.68179227, grad/param norm = 3.3762e-01, time/batch = 14.3648s	
11851/16650 (epoch 35.589), train_loss = 0.66345128, grad/param norm = 2.6835e-01, time/batch = 15.8311s	
11852/16650 (epoch 35.592), train_loss = 0.75473819, grad/param norm = 2.9367e-01, time/batch = 16.5080s	
11853/16650 (epoch 35.595), train_loss = 0.69909792, grad/param norm = 3.1395e-01, time/batch = 17.2635s	
11854/16650 (epoch 35.598), train_loss = 0.72755472, grad/param norm = 3.0243e-01, time/batch = 17.5228s	
11855/16650 (epoch 35.601), train_loss = 0.71119986, grad/param norm = 3.5906e-01, time/batch = 15.9980s	
11856/16650 (epoch 35.604), train_loss = 0.78300536, grad/param norm = 3.0460e-01, time/batch = 15.4819s	
11857/16650 (epoch 35.607), train_loss = 0.80435114, grad/param norm = 2.8098e-01, time/batch = 16.1567s	
11858/16650 (epoch 35.610), train_loss = 0.67998809, grad/param norm = 2.7493e-01, time/batch = 17.7050s	
11859/16650 (epoch 35.613), train_loss = 0.86864136, grad/param norm = 4.0267e-01, time/batch = 16.6832s	
11860/16650 (epoch 35.616), train_loss = 0.82403468, grad/param norm = 3.1628e-01, time/batch = 17.5098s	
11861/16650 (epoch 35.619), train_loss = 0.62995524, grad/param norm = 2.6501e-01, time/batch = 17.7836s	
11862/16650 (epoch 35.622), train_loss = 0.61012619, grad/param norm = 2.6671e-01, time/batch = 16.9542s	
11863/16650 (epoch 35.625), train_loss = 0.71228641, grad/param norm = 2.3626e-01, time/batch = 14.8547s	
11864/16650 (epoch 35.628), train_loss = 0.69962083, grad/param norm = 3.3703e-01, time/batch = 13.7305s	
11865/16650 (epoch 35.631), train_loss = 0.75128698, grad/param norm = 3.0233e-01, time/batch = 14.2265s	
11866/16650 (epoch 35.634), train_loss = 0.92307165, grad/param norm = 3.2966e-01, time/batch = 13.5828s	
11867/16650 (epoch 35.637), train_loss = 0.90262723, grad/param norm = 3.0678e-01, time/batch = 15.3150s	
11868/16650 (epoch 35.640), train_loss = 0.72306970, grad/param norm = 3.1108e-01, time/batch = 14.9099s	
11869/16650 (epoch 35.643), train_loss = 0.81728026, grad/param norm = 2.7683e-01, time/batch = 16.5548s	
11870/16650 (epoch 35.646), train_loss = 0.79532396, grad/param norm = 3.1605e-01, time/batch = 16.2547s	
11871/16650 (epoch 35.649), train_loss = 0.78310738, grad/param norm = 3.5025e-01, time/batch = 15.5551s	
11872/16650 (epoch 35.652), train_loss = 0.81535589, grad/param norm = 3.2836e-01, time/batch = 18.1977s	
11873/16650 (epoch 35.655), train_loss = 0.78248667, grad/param norm = 3.1820e-01, time/batch = 18.8731s	
11874/16650 (epoch 35.658), train_loss = 0.70407275, grad/param norm = 3.4883e-01, time/batch = 15.8383s	
11875/16650 (epoch 35.661), train_loss = 0.78284309, grad/param norm = 3.2270e-01, time/batch = 17.5879s	
11876/16650 (epoch 35.664), train_loss = 0.76390661, grad/param norm = 3.1498e-01, time/batch = 15.4362s	
11877/16650 (epoch 35.667), train_loss = 0.86935192, grad/param norm = 3.0680e-01, time/batch = 15.1095s	
11878/16650 (epoch 35.670), train_loss = 0.64879573, grad/param norm = 2.5465e-01, time/batch = 15.2772s	
11879/16650 (epoch 35.673), train_loss = 0.66959342, grad/param norm = 2.6571e-01, time/batch = 16.4287s	
11880/16650 (epoch 35.676), train_loss = 0.79597109, grad/param norm = 2.8410e-01, time/batch = 18.1137s	
11881/16650 (epoch 35.679), train_loss = 0.67673211, grad/param norm = 2.6793e-01, time/batch = 16.6659s	
11882/16650 (epoch 35.682), train_loss = 0.75282844, grad/param norm = 3.0351e-01, time/batch = 14.4849s	
11883/16650 (epoch 35.685), train_loss = 0.64328912, grad/param norm = 2.6763e-01, time/batch = 16.9135s	
11884/16650 (epoch 35.688), train_loss = 0.82069420, grad/param norm = 2.8740e-01, time/batch = 17.3699s	
11885/16650 (epoch 35.691), train_loss = 0.78801886, grad/param norm = 3.1078e-01, time/batch = 15.8387s	
11886/16650 (epoch 35.694), train_loss = 0.69973217, grad/param norm = 2.9776e-01, time/batch = 15.0902s	
11887/16650 (epoch 35.697), train_loss = 0.64599405, grad/param norm = 2.5725e-01, time/batch = 17.2549s	
11888/16650 (epoch 35.700), train_loss = 0.78720388, grad/param norm = 3.0391e-01, time/batch = 17.6154s	
11889/16650 (epoch 35.703), train_loss = 0.67522165, grad/param norm = 3.0284e-01, time/batch = 16.3298s	
11890/16650 (epoch 35.706), train_loss = 0.74023511, grad/param norm = 3.5314e-01, time/batch = 18.1235s	
11891/16650 (epoch 35.709), train_loss = 0.64536635, grad/param norm = 2.9817e-01, time/batch = 16.5141s	
11892/16650 (epoch 35.712), train_loss = 0.68377256, grad/param norm = 3.1380e-01, time/batch = 16.3622s	
11893/16650 (epoch 35.715), train_loss = 0.79049020, grad/param norm = 3.0010e-01, time/batch = 17.0329s	
11894/16650 (epoch 35.718), train_loss = 0.81220088, grad/param norm = 3.1869e-01, time/batch = 17.2708s	
11895/16650 (epoch 35.721), train_loss = 0.83080709, grad/param norm = 2.6941e-01, time/batch = 16.0170s	
11896/16650 (epoch 35.724), train_loss = 0.81388739, grad/param norm = 2.9968e-01, time/batch = 14.7668s	
11897/16650 (epoch 35.727), train_loss = 0.84094546, grad/param norm = 3.0875e-01, time/batch = 14.1979s	
11898/16650 (epoch 35.730), train_loss = 0.68773111, grad/param norm = 2.6519e-01, time/batch = 14.1407s	
11899/16650 (epoch 35.733), train_loss = 0.84909452, grad/param norm = 3.2602e-01, time/batch = 16.0180s	
11900/16650 (epoch 35.736), train_loss = 0.63648608, grad/param norm = 2.7099e-01, time/batch = 15.4195s	
11901/16650 (epoch 35.739), train_loss = 0.77581433, grad/param norm = 2.6906e-01, time/batch = 15.0741s	
11902/16650 (epoch 35.742), train_loss = 0.75890026, grad/param norm = 2.6816e-01, time/batch = 16.4385s	
11903/16650 (epoch 35.745), train_loss = 0.59217747, grad/param norm = 2.5178e-01, time/batch = 17.0877s	
11904/16650 (epoch 35.748), train_loss = 0.64553628, grad/param norm = 2.7605e-01, time/batch = 30.0529s	
11905/16650 (epoch 35.751), train_loss = 0.78408874, grad/param norm = 4.7206e-01, time/batch = 17.0099s	
11906/16650 (epoch 35.754), train_loss = 0.91898207, grad/param norm = 3.8989e-01, time/batch = 15.3544s	
11907/16650 (epoch 35.757), train_loss = 0.90869742, grad/param norm = 3.1373e-01, time/batch = 14.4763s	
11908/16650 (epoch 35.760), train_loss = 0.77652172, grad/param norm = 3.3122e-01, time/batch = 15.0661s	
11909/16650 (epoch 35.763), train_loss = 0.71168224, grad/param norm = 2.9073e-01, time/batch = 17.9471s	
11910/16650 (epoch 35.766), train_loss = 0.73379854, grad/param norm = 2.6712e-01, time/batch = 15.5849s	
11911/16650 (epoch 35.769), train_loss = 0.78534721, grad/param norm = 2.7784e-01, time/batch = 17.4412s	
11912/16650 (epoch 35.772), train_loss = 0.76316434, grad/param norm = 2.4681e-01, time/batch = 15.7651s	
11913/16650 (epoch 35.775), train_loss = 0.73769280, grad/param norm = 2.6823e-01, time/batch = 15.7441s	
11914/16650 (epoch 35.778), train_loss = 0.76746474, grad/param norm = 2.5474e-01, time/batch = 15.5037s	
11915/16650 (epoch 35.781), train_loss = 0.90088892, grad/param norm = 2.6504e-01, time/batch = 16.8655s	
11916/16650 (epoch 35.784), train_loss = 0.77695694, grad/param norm = 2.9816e-01, time/batch = 16.8005s	
11917/16650 (epoch 35.787), train_loss = 0.82020815, grad/param norm = 2.9197e-01, time/batch = 16.0749s	
11918/16650 (epoch 35.790), train_loss = 0.84984376, grad/param norm = 2.8556e-01, time/batch = 16.1990s	
11919/16650 (epoch 35.793), train_loss = 0.66121257, grad/param norm = 2.7659e-01, time/batch = 17.6130s	
11920/16650 (epoch 35.796), train_loss = 1.00384651, grad/param norm = 3.3628e-01, time/batch = 16.6199s	
11921/16650 (epoch 35.799), train_loss = 0.93025453, grad/param norm = 3.9840e-01, time/batch = 16.6726s	
11922/16650 (epoch 35.802), train_loss = 0.83767133, grad/param norm = 3.0878e-01, time/batch = 17.9546s	
11923/16650 (epoch 35.805), train_loss = 0.79135120, grad/param norm = 2.8626e-01, time/batch = 15.4047s	
11924/16650 (epoch 35.808), train_loss = 0.84465362, grad/param norm = 2.8088e-01, time/batch = 14.0407s	
11925/16650 (epoch 35.811), train_loss = 0.87270369, grad/param norm = 2.9795e-01, time/batch = 14.2239s	
11926/16650 (epoch 35.814), train_loss = 0.68539916, grad/param norm = 2.6944e-01, time/batch = 14.8304s	
11927/16650 (epoch 35.817), train_loss = 0.73588419, grad/param norm = 3.2664e-01, time/batch = 16.3549s	
11928/16650 (epoch 35.820), train_loss = 0.82910364, grad/param norm = 3.2271e-01, time/batch = 16.4396s	
11929/16650 (epoch 35.823), train_loss = 0.77402919, grad/param norm = 3.1147e-01, time/batch = 15.1794s	
11930/16650 (epoch 35.826), train_loss = 0.72854005, grad/param norm = 2.6898e-01, time/batch = 17.2715s	
11931/16650 (epoch 35.829), train_loss = 0.77440728, grad/param norm = 2.8584e-01, time/batch = 16.5926s	
11932/16650 (epoch 35.832), train_loss = 0.83228705, grad/param norm = 2.7255e-01, time/batch = 16.5115s	
11933/16650 (epoch 35.835), train_loss = 0.83268588, grad/param norm = 3.4628e-01, time/batch = 16.3589s	
11934/16650 (epoch 35.838), train_loss = 0.68240805, grad/param norm = 2.7309e-01, time/batch = 16.9461s	
11935/16650 (epoch 35.841), train_loss = 0.70788303, grad/param norm = 2.5823e-01, time/batch = 17.1236s	
11936/16650 (epoch 35.844), train_loss = 0.72140168, grad/param norm = 2.5717e-01, time/batch = 15.5953s	
11937/16650 (epoch 35.847), train_loss = 0.83967720, grad/param norm = 3.3974e-01, time/batch = 17.1923s	
11938/16650 (epoch 35.850), train_loss = 0.68673844, grad/param norm = 2.9124e-01, time/batch = 16.6096s	
11939/16650 (epoch 35.853), train_loss = 0.75125808, grad/param norm = 2.8075e-01, time/batch = 16.9409s	
11940/16650 (epoch 35.856), train_loss = 0.70936241, grad/param norm = 2.6995e-01, time/batch = 15.4262s	
11941/16650 (epoch 35.859), train_loss = 0.88043571, grad/param norm = 3.5631e-01, time/batch = 17.8718s	
11942/16650 (epoch 35.862), train_loss = 0.74665713, grad/param norm = 2.5088e-01, time/batch = 16.4636s	
11943/16650 (epoch 35.865), train_loss = 0.60463752, grad/param norm = 2.4133e-01, time/batch = 15.8611s	
11944/16650 (epoch 35.868), train_loss = 0.79003318, grad/param norm = 2.8532e-01, time/batch = 15.1010s	
11945/16650 (epoch 35.871), train_loss = 0.80444793, grad/param norm = 2.9557e-01, time/batch = 17.9629s	
11946/16650 (epoch 35.874), train_loss = 0.80792082, grad/param norm = 2.6787e-01, time/batch = 14.9015s	
11947/16650 (epoch 35.877), train_loss = 0.76857870, grad/param norm = 2.8275e-01, time/batch = 16.1846s	
11948/16650 (epoch 35.880), train_loss = 0.69720852, grad/param norm = 3.0960e-01, time/batch = 15.9818s	
11949/16650 (epoch 35.883), train_loss = 0.78925203, grad/param norm = 2.6993e-01, time/batch = 16.4522s	
11950/16650 (epoch 35.886), train_loss = 0.78668528, grad/param norm = 2.8814e-01, time/batch = 16.7713s	
11951/16650 (epoch 35.889), train_loss = 0.65056726, grad/param norm = 3.0802e-01, time/batch = 16.6127s	
11952/16650 (epoch 35.892), train_loss = 0.78434447, grad/param norm = 3.0927e-01, time/batch = 17.0523s	
11953/16650 (epoch 35.895), train_loss = 0.79396187, grad/param norm = 3.0205e-01, time/batch = 16.0221s	
11954/16650 (epoch 35.898), train_loss = 0.78940061, grad/param norm = 2.8819e-01, time/batch = 15.1743s	
11955/16650 (epoch 35.901), train_loss = 0.71070436, grad/param norm = 2.6143e-01, time/batch = 15.4906s	
11956/16650 (epoch 35.904), train_loss = 0.72093269, grad/param norm = 3.2941e-01, time/batch = 15.9544s	
11957/16650 (epoch 35.907), train_loss = 0.79246448, grad/param norm = 2.8833e-01, time/batch = 14.0511s	
11958/16650 (epoch 35.910), train_loss = 0.80136534, grad/param norm = 3.0691e-01, time/batch = 15.7348s	
11959/16650 (epoch 35.913), train_loss = 0.72163743, grad/param norm = 2.8977e-01, time/batch = 17.3631s	
11960/16650 (epoch 35.916), train_loss = 0.71272166, grad/param norm = 3.0279e-01, time/batch = 15.7690s	
11961/16650 (epoch 35.919), train_loss = 0.90026626, grad/param norm = 3.1432e-01, time/batch = 16.7655s	
11962/16650 (epoch 35.922), train_loss = 0.79623935, grad/param norm = 3.5964e-01, time/batch = 16.8403s	
11963/16650 (epoch 35.925), train_loss = 0.71237553, grad/param norm = 2.7789e-01, time/batch = 15.9287s	
11964/16650 (epoch 35.928), train_loss = 0.76298015, grad/param norm = 2.8640e-01, time/batch = 17.1220s	
11965/16650 (epoch 35.931), train_loss = 0.78559683, grad/param norm = 3.4047e-01, time/batch = 16.7670s	
11966/16650 (epoch 35.934), train_loss = 0.65313565, grad/param norm = 2.8214e-01, time/batch = 17.0269s	
11967/16650 (epoch 35.937), train_loss = 0.69111169, grad/param norm = 3.0053e-01, time/batch = 17.1077s	
11968/16650 (epoch 35.940), train_loss = 0.73993941, grad/param norm = 2.5970e-01, time/batch = 16.9669s	
11969/16650 (epoch 35.943), train_loss = 0.77814349, grad/param norm = 3.3879e-01, time/batch = 16.2474s	
11970/16650 (epoch 35.946), train_loss = 0.70296374, grad/param norm = 2.5703e-01, time/batch = 16.1802s	
11971/16650 (epoch 35.949), train_loss = 0.66376586, grad/param norm = 3.2176e-01, time/batch = 14.1709s	
11972/16650 (epoch 35.952), train_loss = 0.63540450, grad/param norm = 2.6534e-01, time/batch = 14.1535s	
11973/16650 (epoch 35.955), train_loss = 0.76021284, grad/param norm = 2.8525e-01, time/batch = 16.2312s	
11974/16650 (epoch 35.958), train_loss = 0.80259970, grad/param norm = 3.1892e-01, time/batch = 16.4429s	
11975/16650 (epoch 35.961), train_loss = 0.73555199, grad/param norm = 2.4917e-01, time/batch = 16.5326s	
11976/16650 (epoch 35.964), train_loss = 0.66942810, grad/param norm = 2.9085e-01, time/batch = 16.3366s	
11977/16650 (epoch 35.967), train_loss = 0.91036233, grad/param norm = 6.6762e-01, time/batch = 14.4313s	
11978/16650 (epoch 35.970), train_loss = 0.72721628, grad/param norm = 3.0722e-01, time/batch = 13.5450s	
11979/16650 (epoch 35.973), train_loss = 0.73084708, grad/param norm = 3.4011e-01, time/batch = 14.7119s	
11980/16650 (epoch 35.976), train_loss = 0.70882285, grad/param norm = 2.8019e-01, time/batch = 14.6566s	
11981/16650 (epoch 35.979), train_loss = 0.78531983, grad/param norm = 3.0443e-01, time/batch = 14.3156s	
11982/16650 (epoch 35.982), train_loss = 0.82163593, grad/param norm = 2.8681e-01, time/batch = 15.3891s	
11983/16650 (epoch 35.985), train_loss = 0.74076713, grad/param norm = 2.5959e-01, time/batch = 15.8987s	
11984/16650 (epoch 35.988), train_loss = 0.81504332, grad/param norm = 3.3204e-01, time/batch = 16.5998s	
11985/16650 (epoch 35.991), train_loss = 0.70252097, grad/param norm = 2.9740e-01, time/batch = 17.0293s	
11986/16650 (epoch 35.994), train_loss = 0.70006649, grad/param norm = 2.7504e-01, time/batch = 16.8699s	
11987/16650 (epoch 35.997), train_loss = 0.73050157, grad/param norm = 2.7068e-01, time/batch = 16.8680s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
11988/16650 (epoch 36.000), train_loss = 0.82895154, grad/param norm = 3.0687e-01, time/batch = 16.6905s	
11989/16650 (epoch 36.003), train_loss = 0.86840775, grad/param norm = 3.4836e-01, time/batch = 14.2504s	
11990/16650 (epoch 36.006), train_loss = 0.86099930, grad/param norm = 3.6378e-01, time/batch = 16.6165s	
11991/16650 (epoch 36.009), train_loss = 0.90227662, grad/param norm = 3.1597e-01, time/batch = 15.1742s	
11992/16650 (epoch 36.012), train_loss = 0.87988327, grad/param norm = 3.0230e-01, time/batch = 16.7605s	
11993/16650 (epoch 36.015), train_loss = 0.76585540, grad/param norm = 2.6518e-01, time/batch = 16.4448s	
11994/16650 (epoch 36.018), train_loss = 0.64640917, grad/param norm = 2.4589e-01, time/batch = 17.5300s	
11995/16650 (epoch 36.021), train_loss = 0.88272083, grad/param norm = 3.0506e-01, time/batch = 15.6487s	
11996/16650 (epoch 36.024), train_loss = 0.74968021, grad/param norm = 3.3599e-01, time/batch = 15.2263s	
11997/16650 (epoch 36.027), train_loss = 0.80989654, grad/param norm = 3.2042e-01, time/batch = 16.0131s	
11998/16650 (epoch 36.030), train_loss = 0.65248166, grad/param norm = 2.5046e-01, time/batch = 18.2626s	
11999/16650 (epoch 36.033), train_loss = 0.75263398, grad/param norm = 2.4747e-01, time/batch = 15.7627s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch36.04_2.1899.t7	
12000/16650 (epoch 36.036), train_loss = 0.55759665, grad/param norm = 3.2164e-01, time/batch = 17.3508s	
12001/16650 (epoch 36.039), train_loss = 1.47513787, grad/param norm = 3.8266e-01, time/batch = 15.7533s	
12002/16650 (epoch 36.042), train_loss = 0.80323965, grad/param norm = 3.1300e-01, time/batch = 15.1677s	
12003/16650 (epoch 36.045), train_loss = 0.74872551, grad/param norm = 2.7361e-01, time/batch = 16.7938s	
12004/16650 (epoch 36.048), train_loss = 0.84130713, grad/param norm = 3.5691e-01, time/batch = 18.2035s	
12005/16650 (epoch 36.051), train_loss = 0.73885671, grad/param norm = 2.7125e-01, time/batch = 16.7582s	
12006/16650 (epoch 36.054), train_loss = 0.76752721, grad/param norm = 3.0004e-01, time/batch = 16.5778s	
12007/16650 (epoch 36.057), train_loss = 0.77968891, grad/param norm = 3.8599e-01, time/batch = 15.5465s	
12008/16650 (epoch 36.060), train_loss = 0.65104135, grad/param norm = 2.5509e-01, time/batch = 17.3317s	
12009/16650 (epoch 36.063), train_loss = 0.72547133, grad/param norm = 2.8973e-01, time/batch = 14.7688s	
12010/16650 (epoch 36.066), train_loss = 0.91313455, grad/param norm = 2.9333e-01, time/batch = 14.4065s	
12011/16650 (epoch 36.069), train_loss = 0.82591940, grad/param norm = 3.1322e-01, time/batch = 14.4087s	
12012/16650 (epoch 36.072), train_loss = 0.79284673, grad/param norm = 3.3255e-01, time/batch = 13.7251s	
12013/16650 (epoch 36.075), train_loss = 0.84386896, grad/param norm = 2.8568e-01, time/batch = 14.8588s	
12014/16650 (epoch 36.078), train_loss = 0.85317569, grad/param norm = 3.4601e-01, time/batch = 13.7856s	
12015/16650 (epoch 36.081), train_loss = 0.80023759, grad/param norm = 3.0003e-01, time/batch = 13.4889s	
12016/16650 (epoch 36.084), train_loss = 0.81564895, grad/param norm = 3.2203e-01, time/batch = 13.7077s	
12017/16650 (epoch 36.087), train_loss = 0.80740815, grad/param norm = 3.1944e-01, time/batch = 13.6473s	
12018/16650 (epoch 36.090), train_loss = 0.76354999, grad/param norm = 3.0121e-01, time/batch = 13.7854s	
12019/16650 (epoch 36.093), train_loss = 0.90732480, grad/param norm = 4.0490e-01, time/batch = 14.0040s	
12020/16650 (epoch 36.096), train_loss = 0.73579518, grad/param norm = 2.8681e-01, time/batch = 13.3200s	
12021/16650 (epoch 36.099), train_loss = 0.80816627, grad/param norm = 3.0427e-01, time/batch = 13.7423s	
12022/16650 (epoch 36.102), train_loss = 0.77544470, grad/param norm = 2.7737e-01, time/batch = 14.1121s	
12023/16650 (epoch 36.105), train_loss = 0.78259986, grad/param norm = 3.1172e-01, time/batch = 13.8711s	
12024/16650 (epoch 36.108), train_loss = 0.80076234, grad/param norm = 3.4841e-01, time/batch = 13.4200s	
12025/16650 (epoch 36.111), train_loss = 0.87549841, grad/param norm = 3.1450e-01, time/batch = 13.4959s	
12026/16650 (epoch 36.114), train_loss = 0.83225757, grad/param norm = 4.1880e-01, time/batch = 14.0361s	
12027/16650 (epoch 36.117), train_loss = 0.92799416, grad/param norm = 3.4597e-01, time/batch = 13.7244s	
12028/16650 (epoch 36.120), train_loss = 0.77018905, grad/param norm = 2.6024e-01, time/batch = 13.6374s	
12029/16650 (epoch 36.123), train_loss = 0.75970401, grad/param norm = 2.8669e-01, time/batch = 13.5585s	
12030/16650 (epoch 36.126), train_loss = 0.80824687, grad/param norm = 2.9017e-01, time/batch = 13.8103s	
12031/16650 (epoch 36.129), train_loss = 0.81352690, grad/param norm = 2.9090e-01, time/batch = 14.4076s	
12032/16650 (epoch 36.132), train_loss = 0.77114705, grad/param norm = 3.0614e-01, time/batch = 13.4939s	
12033/16650 (epoch 36.135), train_loss = 0.88352477, grad/param norm = 3.0799e-01, time/batch = 13.4927s	
12034/16650 (epoch 36.138), train_loss = 0.84861798, grad/param norm = 3.1233e-01, time/batch = 13.9572s	
12035/16650 (epoch 36.141), train_loss = 0.82456471, grad/param norm = 3.1115e-01, time/batch = 14.1929s	
12036/16650 (epoch 36.144), train_loss = 0.83213690, grad/param norm = 3.5542e-01, time/batch = 15.0260s	
12037/16650 (epoch 36.147), train_loss = 0.91708428, grad/param norm = 3.0063e-01, time/batch = 13.3768s	
12038/16650 (epoch 36.150), train_loss = 1.00432110, grad/param norm = 3.3279e-01, time/batch = 14.1305s	
12039/16650 (epoch 36.153), train_loss = 0.80441737, grad/param norm = 3.0749e-01, time/batch = 14.5045s	
12040/16650 (epoch 36.156), train_loss = 0.75770594, grad/param norm = 2.6586e-01, time/batch = 13.5559s	
12041/16650 (epoch 36.159), train_loss = 0.84809866, grad/param norm = 3.0519e-01, time/batch = 14.3472s	
12042/16650 (epoch 36.162), train_loss = 0.91485195, grad/param norm = 2.8511e-01, time/batch = 14.0879s	
12043/16650 (epoch 36.165), train_loss = 0.89374100, grad/param norm = 3.2759e-01, time/batch = 13.8726s	
12044/16650 (epoch 36.168), train_loss = 0.66976028, grad/param norm = 2.5959e-01, time/batch = 13.6422s	
12045/16650 (epoch 36.171), train_loss = 0.83528970, grad/param norm = 2.5948e-01, time/batch = 13.8734s	
12046/16650 (epoch 36.174), train_loss = 0.64719570, grad/param norm = 2.7628e-01, time/batch = 13.7353s	
12047/16650 (epoch 36.177), train_loss = 0.78076637, grad/param norm = 2.6080e-01, time/batch = 13.4959s	
12048/16650 (epoch 36.180), train_loss = 0.89489444, grad/param norm = 2.9889e-01, time/batch = 13.9505s	
12049/16650 (epoch 36.183), train_loss = 1.02900192, grad/param norm = 3.6221e-01, time/batch = 13.6377s	
12050/16650 (epoch 36.186), train_loss = 0.82333548, grad/param norm = 3.3805e-01, time/batch = 13.5594s	
12051/16650 (epoch 36.189), train_loss = 0.72771141, grad/param norm = 2.6041e-01, time/batch = 13.6508s	
12052/16650 (epoch 36.192), train_loss = 0.78034128, grad/param norm = 2.8784e-01, time/batch = 14.0317s	
12053/16650 (epoch 36.195), train_loss = 0.72494091, grad/param norm = 3.1222e-01, time/batch = 13.9741s	
12054/16650 (epoch 36.198), train_loss = 0.67990144, grad/param norm = 2.3513e-01, time/batch = 14.2491s	
12055/16650 (epoch 36.201), train_loss = 0.69363490, grad/param norm = 2.6059e-01, time/batch = 13.6421s	
12056/16650 (epoch 36.204), train_loss = 0.80231183, grad/param norm = 3.2766e-01, time/batch = 13.8904s	
12057/16650 (epoch 36.207), train_loss = 0.83751760, grad/param norm = 3.6184e-01, time/batch = 14.0967s	
12058/16650 (epoch 36.210), train_loss = 0.78751822, grad/param norm = 3.0502e-01, time/batch = 13.6955s	
12059/16650 (epoch 36.213), train_loss = 0.84283811, grad/param norm = 2.9733e-01, time/batch = 13.6545s	
12060/16650 (epoch 36.216), train_loss = 0.72904162, grad/param norm = 2.8294e-01, time/batch = 13.5501s	
12061/16650 (epoch 36.219), train_loss = 0.77723716, grad/param norm = 3.0002e-01, time/batch = 14.1739s	
12062/16650 (epoch 36.222), train_loss = 0.79361609, grad/param norm = 2.6443e-01, time/batch = 13.6360s	
12063/16650 (epoch 36.225), train_loss = 0.82596265, grad/param norm = 5.1220e-01, time/batch = 13.6553s	
12064/16650 (epoch 36.228), train_loss = 0.71647969, grad/param norm = 2.9927e-01, time/batch = 13.5786s	
12065/16650 (epoch 36.231), train_loss = 0.72429525, grad/param norm = 3.7822e-01, time/batch = 13.8682s	
12066/16650 (epoch 36.234), train_loss = 0.94528746, grad/param norm = 3.0270e-01, time/batch = 13.3947s	
12067/16650 (epoch 36.237), train_loss = 0.79946975, grad/param norm = 3.2586e-01, time/batch = 13.8151s	
12068/16650 (epoch 36.240), train_loss = 0.78391811, grad/param norm = 2.8499e-01, time/batch = 13.5721s	
12069/16650 (epoch 36.243), train_loss = 0.77237952, grad/param norm = 2.8227e-01, time/batch = 13.7878s	
12070/16650 (epoch 36.246), train_loss = 0.89851433, grad/param norm = 3.1735e-01, time/batch = 13.8055s	
12071/16650 (epoch 36.249), train_loss = 0.65821783, grad/param norm = 2.3434e-01, time/batch = 13.7333s	
12072/16650 (epoch 36.252), train_loss = 0.76520147, grad/param norm = 3.1183e-01, time/batch = 14.9514s	
12073/16650 (epoch 36.255), train_loss = 0.81970611, grad/param norm = 3.0320e-01, time/batch = 14.2647s	
12074/16650 (epoch 36.258), train_loss = 0.85073011, grad/param norm = 3.0435e-01, time/batch = 15.5488s	
12075/16650 (epoch 36.261), train_loss = 0.83474027, grad/param norm = 3.0281e-01, time/batch = 14.3342s	
12076/16650 (epoch 36.264), train_loss = 0.72979280, grad/param norm = 2.7494e-01, time/batch = 14.4460s	
12077/16650 (epoch 36.267), train_loss = 0.76804557, grad/param norm = 3.7107e-01, time/batch = 14.6770s	
12078/16650 (epoch 36.270), train_loss = 0.83125458, grad/param norm = 2.9121e-01, time/batch = 14.3315s	
12079/16650 (epoch 36.273), train_loss = 0.88050497, grad/param norm = 3.2789e-01, time/batch = 13.8641s	
12080/16650 (epoch 36.276), train_loss = 0.83465056, grad/param norm = 3.2335e-01, time/batch = 14.0352s	
12081/16650 (epoch 36.279), train_loss = 0.77158424, grad/param norm = 3.0867e-01, time/batch = 14.3478s	
12082/16650 (epoch 36.282), train_loss = 0.72696863, grad/param norm = 2.7849e-01, time/batch = 14.4298s	
12083/16650 (epoch 36.285), train_loss = 0.74097773, grad/param norm = 2.8875e-01, time/batch = 13.9662s	
12084/16650 (epoch 36.288), train_loss = 0.72434203, grad/param norm = 3.0051e-01, time/batch = 14.5142s	
12085/16650 (epoch 36.291), train_loss = 0.59223447, grad/param norm = 2.4733e-01, time/batch = 14.5066s	
12086/16650 (epoch 36.294), train_loss = 0.70286809, grad/param norm = 2.5099e-01, time/batch = 14.4370s	
12087/16650 (epoch 36.297), train_loss = 0.76660498, grad/param norm = 2.7034e-01, time/batch = 14.3541s	
12088/16650 (epoch 36.300), train_loss = 0.61911296, grad/param norm = 2.2717e-01, time/batch = 13.7363s	
12089/16650 (epoch 36.303), train_loss = 0.66685931, grad/param norm = 2.7406e-01, time/batch = 13.7113s	
12090/16650 (epoch 36.306), train_loss = 0.84745403, grad/param norm = 2.7720e-01, time/batch = 14.0241s	
12091/16650 (epoch 36.309), train_loss = 0.82791967, grad/param norm = 2.8421e-01, time/batch = 13.7229s	
12092/16650 (epoch 36.312), train_loss = 0.66909285, grad/param norm = 3.2601e-01, time/batch = 13.4899s	
12093/16650 (epoch 36.315), train_loss = 0.56246947, grad/param norm = 2.1688e-01, time/batch = 13.6587s	
12094/16650 (epoch 36.318), train_loss = 0.64543053, grad/param norm = 2.4263e-01, time/batch = 13.6445s	
12095/16650 (epoch 36.321), train_loss = 0.87319714, grad/param norm = 4.1416e-01, time/batch = 14.4240s	
12096/16650 (epoch 36.324), train_loss = 0.72408764, grad/param norm = 3.7249e-01, time/batch = 13.6378s	
12097/16650 (epoch 36.327), train_loss = 0.81248815, grad/param norm = 3.2842e-01, time/batch = 13.7294s	
12098/16650 (epoch 36.330), train_loss = 0.80010030, grad/param norm = 3.7247e-01, time/batch = 13.8551s	
12099/16650 (epoch 36.333), train_loss = 0.82574596, grad/param norm = 3.3488e-01, time/batch = 13.8644s	
12100/16650 (epoch 36.336), train_loss = 0.68790447, grad/param norm = 3.4774e-01, time/batch = 13.5751s	
12101/16650 (epoch 36.339), train_loss = 0.72210618, grad/param norm = 3.1198e-01, time/batch = 13.4885s	
12102/16650 (epoch 36.342), train_loss = 0.65714386, grad/param norm = 2.8941e-01, time/batch = 13.6532s	
12103/16650 (epoch 36.345), train_loss = 0.67495974, grad/param norm = 2.5203e-01, time/batch = 14.1873s	
12104/16650 (epoch 36.348), train_loss = 0.76753582, grad/param norm = 3.0855e-01, time/batch = 13.7242s	
12105/16650 (epoch 36.351), train_loss = 0.79978770, grad/param norm = 3.1353e-01, time/batch = 14.1256s	
12106/16650 (epoch 36.354), train_loss = 0.83355157, grad/param norm = 3.1604e-01, time/batch = 13.5759s	
12107/16650 (epoch 36.357), train_loss = 0.81138487, grad/param norm = 2.9197e-01, time/batch = 13.9953s	
12108/16650 (epoch 36.360), train_loss = 0.78568743, grad/param norm = 3.2814e-01, time/batch = 14.2803s	
12109/16650 (epoch 36.363), train_loss = 0.86708035, grad/param norm = 3.5251e-01, time/batch = 13.5476s	
12110/16650 (epoch 36.366), train_loss = 0.91693969, grad/param norm = 3.0889e-01, time/batch = 14.6490s	
12111/16650 (epoch 36.369), train_loss = 0.81602619, grad/param norm = 2.8162e-01, time/batch = 13.5630s	
12112/16650 (epoch 36.372), train_loss = 0.79135486, grad/param norm = 3.2346e-01, time/batch = 14.0989s	
12113/16650 (epoch 36.375), train_loss = 0.80038210, grad/param norm = 3.3448e-01, time/batch = 13.3967s	
12114/16650 (epoch 36.378), train_loss = 0.74226873, grad/param norm = 2.8929e-01, time/batch = 14.3273s	
12115/16650 (epoch 36.381), train_loss = 0.82405252, grad/param norm = 3.5351e-01, time/batch = 13.6314s	
12116/16650 (epoch 36.384), train_loss = 0.92091558, grad/param norm = 3.0649e-01, time/batch = 14.2765s	
12117/16650 (epoch 36.387), train_loss = 0.61119404, grad/param norm = 2.4980e-01, time/batch = 17.1046s	
12118/16650 (epoch 36.390), train_loss = 0.84538861, grad/param norm = 2.8159e-01, time/batch = 16.1891s	
12119/16650 (epoch 36.393), train_loss = 0.73557012, grad/param norm = 3.0006e-01, time/batch = 17.3010s	
12120/16650 (epoch 36.396), train_loss = 0.87958810, grad/param norm = 3.3948e-01, time/batch = 16.0846s	
12121/16650 (epoch 36.399), train_loss = 0.84933307, grad/param norm = 2.8685e-01, time/batch = 16.0783s	
12122/16650 (epoch 36.402), train_loss = 0.75421307, grad/param norm = 2.8248e-01, time/batch = 18.1217s	
12123/16650 (epoch 36.405), train_loss = 0.62309238, grad/param norm = 2.7967e-01, time/batch = 16.2469s	
12124/16650 (epoch 36.408), train_loss = 0.80314281, grad/param norm = 3.4060e-01, time/batch = 19.0029s	
12125/16650 (epoch 36.411), train_loss = 0.70700818, grad/param norm = 3.4985e-01, time/batch = 18.7725s	
12126/16650 (epoch 36.414), train_loss = 0.69225618, grad/param norm = 3.4751e-01, time/batch = 17.8642s	
12127/16650 (epoch 36.417), train_loss = 0.67230982, grad/param norm = 2.9958e-01, time/batch = 17.9947s	
12128/16650 (epoch 36.420), train_loss = 0.69171441, grad/param norm = 2.9967e-01, time/batch = 16.6414s	
12129/16650 (epoch 36.423), train_loss = 0.57426238, grad/param norm = 2.4928e-01, time/batch = 17.6143s	
12130/16650 (epoch 36.426), train_loss = 0.68571272, grad/param norm = 3.2277e-01, time/batch = 16.9431s	
12131/16650 (epoch 36.429), train_loss = 0.83463357, grad/param norm = 3.1023e-01, time/batch = 17.9364s	
12132/16650 (epoch 36.432), train_loss = 0.85369987, grad/param norm = 3.5725e-01, time/batch = 18.7838s	
12133/16650 (epoch 36.435), train_loss = 0.94164332, grad/param norm = 3.2311e-01, time/batch = 16.7213s	
12134/16650 (epoch 36.438), train_loss = 0.92699690, grad/param norm = 3.6118e-01, time/batch = 28.1302s	
12135/16650 (epoch 36.441), train_loss = 0.74127946, grad/param norm = 3.3876e-01, time/batch = 14.8846s	
12136/16650 (epoch 36.444), train_loss = 0.72751667, grad/param norm = 3.2106e-01, time/batch = 16.0436s	
12137/16650 (epoch 36.447), train_loss = 0.71838273, grad/param norm = 3.2736e-01, time/batch = 16.6726s	
12138/16650 (epoch 36.450), train_loss = 0.73122244, grad/param norm = 3.3120e-01, time/batch = 15.1816s	
12139/16650 (epoch 36.453), train_loss = 0.70786997, grad/param norm = 2.6723e-01, time/batch = 14.7856s	
12140/16650 (epoch 36.456), train_loss = 0.68366261, grad/param norm = 3.2549e-01, time/batch = 14.7824s	
12141/16650 (epoch 36.459), train_loss = 0.70565141, grad/param norm = 2.8762e-01, time/batch = 17.1501s	
12142/16650 (epoch 36.462), train_loss = 0.86510821, grad/param norm = 3.7178e-01, time/batch = 18.0176s	
12143/16650 (epoch 36.465), train_loss = 0.69865666, grad/param norm = 2.7813e-01, time/batch = 17.6094s	
12144/16650 (epoch 36.468), train_loss = 0.60579502, grad/param norm = 3.1030e-01, time/batch = 15.7341s	
12145/16650 (epoch 36.471), train_loss = 0.52756910, grad/param norm = 2.5547e-01, time/batch = 17.9203s	
12146/16650 (epoch 36.474), train_loss = 0.66067565, grad/param norm = 2.7572e-01, time/batch = 17.7754s	
12147/16650 (epoch 36.477), train_loss = 0.83393709, grad/param norm = 3.1458e-01, time/batch = 16.2233s	
12148/16650 (epoch 36.480), train_loss = 0.77335329, grad/param norm = 3.5912e-01, time/batch = 17.5899s	
12149/16650 (epoch 36.483), train_loss = 0.84714895, grad/param norm = 3.3345e-01, time/batch = 18.1890s	
12150/16650 (epoch 36.486), train_loss = 0.68657765, grad/param norm = 2.5816e-01, time/batch = 17.9471s	
12151/16650 (epoch 36.489), train_loss = 0.74681516, grad/param norm = 3.0610e-01, time/batch = 16.1346s	
12152/16650 (epoch 36.492), train_loss = 0.76096711, grad/param norm = 3.1884e-01, time/batch = 15.6741s	
12153/16650 (epoch 36.495), train_loss = 0.65254076, grad/param norm = 2.7588e-01, time/batch = 16.4147s	
12154/16650 (epoch 36.498), train_loss = 0.71736275, grad/param norm = 3.4720e-01, time/batch = 17.1868s	
12155/16650 (epoch 36.502), train_loss = 0.91094480, grad/param norm = 3.5885e-01, time/batch = 17.3552s	
12156/16650 (epoch 36.505), train_loss = 0.80137999, grad/param norm = 2.7303e-01, time/batch = 18.1178s	
12157/16650 (epoch 36.508), train_loss = 0.81271122, grad/param norm = 3.6649e-01, time/batch = 18.5366s	
12158/16650 (epoch 36.511), train_loss = 0.83667595, grad/param norm = 3.1764e-01, time/batch = 15.9756s	
12159/16650 (epoch 36.514), train_loss = 0.65664063, grad/param norm = 2.7078e-01, time/batch = 17.8471s	
12160/16650 (epoch 36.517), train_loss = 0.74592884, grad/param norm = 3.1823e-01, time/batch = 17.5366s	
12161/16650 (epoch 36.520), train_loss = 0.66126109, grad/param norm = 2.8151e-01, time/batch = 17.4206s	
12162/16650 (epoch 36.523), train_loss = 0.74328544, grad/param norm = 2.8227e-01, time/batch = 18.2622s	
12163/16650 (epoch 36.526), train_loss = 0.82393951, grad/param norm = 3.2762e-01, time/batch = 18.0948s	
12164/16650 (epoch 36.529), train_loss = 0.85792906, grad/param norm = 3.3384e-01, time/batch = 15.6897s	
12165/16650 (epoch 36.532), train_loss = 0.58003919, grad/param norm = 2.9886e-01, time/batch = 17.6141s	
12166/16650 (epoch 36.535), train_loss = 0.65049106, grad/param norm = 2.8132e-01, time/batch = 16.3430s	
12167/16650 (epoch 36.538), train_loss = 0.62000714, grad/param norm = 3.0314e-01, time/batch = 17.0019s	
12168/16650 (epoch 36.541), train_loss = 0.88973225, grad/param norm = 3.5155e-01, time/batch = 16.1661s	
12169/16650 (epoch 36.544), train_loss = 0.93223158, grad/param norm = 4.5989e-01, time/batch = 17.2850s	
12170/16650 (epoch 36.547), train_loss = 0.65901011, grad/param norm = 2.7268e-01, time/batch = 15.7581s	
12171/16650 (epoch 36.550), train_loss = 0.74359645, grad/param norm = 2.6883e-01, time/batch = 17.9485s	
12172/16650 (epoch 36.553), train_loss = 0.75562475, grad/param norm = 3.1258e-01, time/batch = 18.0111s	
12173/16650 (epoch 36.556), train_loss = 0.67461165, grad/param norm = 3.2255e-01, time/batch = 17.6064s	
12174/16650 (epoch 36.559), train_loss = 0.60364328, grad/param norm = 2.8867e-01, time/batch = 17.4040s	
12175/16650 (epoch 36.562), train_loss = 0.68750598, grad/param norm = 2.7504e-01, time/batch = 15.5858s	
12176/16650 (epoch 36.565), train_loss = 0.61189296, grad/param norm = 3.4033e-01, time/batch = 16.2686s	
12177/16650 (epoch 36.568), train_loss = 0.61358765, grad/param norm = 2.8173e-01, time/batch = 16.6839s	
12178/16650 (epoch 36.571), train_loss = 0.67032229, grad/param norm = 3.4358e-01, time/batch = 18.0873s	
12179/16650 (epoch 36.574), train_loss = 0.70325337, grad/param norm = 3.6187e-01, time/batch = 14.9240s	
12180/16650 (epoch 36.577), train_loss = 0.72813491, grad/param norm = 2.9439e-01, time/batch = 14.7983s	
12181/16650 (epoch 36.580), train_loss = 0.66133425, grad/param norm = 2.7152e-01, time/batch = 15.2477s	
12182/16650 (epoch 36.583), train_loss = 0.76428862, grad/param norm = 3.0411e-01, time/batch = 16.9950s	
12183/16650 (epoch 36.586), train_loss = 0.67372492, grad/param norm = 3.4075e-01, time/batch = 16.9300s	
12184/16650 (epoch 36.589), train_loss = 0.65512189, grad/param norm = 2.5757e-01, time/batch = 16.9407s	
12185/16650 (epoch 36.592), train_loss = 0.75042459, grad/param norm = 2.9324e-01, time/batch = 17.8588s	
12186/16650 (epoch 36.595), train_loss = 0.66314047, grad/param norm = 2.8525e-01, time/batch = 16.0695s	
12187/16650 (epoch 36.598), train_loss = 0.70705623, grad/param norm = 3.1725e-01, time/batch = 18.6098s	
12188/16650 (epoch 36.601), train_loss = 0.70670219, grad/param norm = 3.3809e-01, time/batch = 18.0920s	
12189/16650 (epoch 36.604), train_loss = 0.76884743, grad/param norm = 3.2200e-01, time/batch = 17.1562s	
12190/16650 (epoch 36.607), train_loss = 0.80039113, grad/param norm = 2.9460e-01, time/batch = 16.5930s	
12191/16650 (epoch 36.610), train_loss = 0.67532300, grad/param norm = 2.7923e-01, time/batch = 15.3718s	
12192/16650 (epoch 36.613), train_loss = 0.84511059, grad/param norm = 3.2709e-01, time/batch = 19.1132s	
12193/16650 (epoch 36.616), train_loss = 0.83326464, grad/param norm = 4.6561e-01, time/batch = 17.0900s	
12194/16650 (epoch 36.619), train_loss = 0.64388722, grad/param norm = 2.8693e-01, time/batch = 14.5509s	
12195/16650 (epoch 36.622), train_loss = 0.59837581, grad/param norm = 2.6670e-01, time/batch = 18.4435s	
12196/16650 (epoch 36.625), train_loss = 0.70599442, grad/param norm = 2.7839e-01, time/batch = 16.9306s	
12197/16650 (epoch 36.628), train_loss = 0.69557040, grad/param norm = 3.6749e-01, time/batch = 15.7533s	
12198/16650 (epoch 36.631), train_loss = 0.75399570, grad/param norm = 3.1333e-01, time/batch = 17.6785s	
12199/16650 (epoch 36.634), train_loss = 0.89938031, grad/param norm = 3.1226e-01, time/batch = 17.3507s	
12200/16650 (epoch 36.637), train_loss = 0.89401193, grad/param norm = 2.9756e-01, time/batch = 15.8879s	
12201/16650 (epoch 36.640), train_loss = 0.71668220, grad/param norm = 2.9546e-01, time/batch = 19.4475s	
12202/16650 (epoch 36.643), train_loss = 0.80038679, grad/param norm = 2.5665e-01, time/batch = 17.7111s	
12203/16650 (epoch 36.646), train_loss = 0.77114502, grad/param norm = 3.0240e-01, time/batch = 17.0046s	
12204/16650 (epoch 36.649), train_loss = 0.77340504, grad/param norm = 2.8717e-01, time/batch = 15.2323s	
12205/16650 (epoch 36.652), train_loss = 0.79464995, grad/param norm = 3.3134e-01, time/batch = 19.0140s	
12206/16650 (epoch 36.655), train_loss = 0.75382993, grad/param norm = 2.9985e-01, time/batch = 18.1866s	
12207/16650 (epoch 36.658), train_loss = 0.69116401, grad/param norm = 3.0053e-01, time/batch = 16.9083s	
12208/16650 (epoch 36.661), train_loss = 0.78116380, grad/param norm = 3.1470e-01, time/batch = 17.6952s	
12209/16650 (epoch 36.664), train_loss = 0.72630382, grad/param norm = 3.0097e-01, time/batch = 16.3377s	
12210/16650 (epoch 36.667), train_loss = 0.83807097, grad/param norm = 2.7435e-01, time/batch = 15.6542s	
12211/16650 (epoch 36.670), train_loss = 0.63268528, grad/param norm = 2.7129e-01, time/batch = 15.3664s	
12212/16650 (epoch 36.673), train_loss = 0.66641359, grad/param norm = 2.8826e-01, time/batch = 16.6405s	
12213/16650 (epoch 36.676), train_loss = 0.80005531, grad/param norm = 3.0186e-01, time/batch = 18.0417s	
12214/16650 (epoch 36.679), train_loss = 0.66254413, grad/param norm = 2.7978e-01, time/batch = 16.6024s	
12215/16650 (epoch 36.682), train_loss = 0.73316350, grad/param norm = 3.1940e-01, time/batch = 18.6927s	
12216/16650 (epoch 36.685), train_loss = 0.64310942, grad/param norm = 2.8965e-01, time/batch = 15.6599s	
12217/16650 (epoch 36.688), train_loss = 0.81242577, grad/param norm = 3.0596e-01, time/batch = 16.7519s	
12218/16650 (epoch 36.691), train_loss = 0.77622700, grad/param norm = 2.8996e-01, time/batch = 17.5204s	
12219/16650 (epoch 36.694), train_loss = 0.68918662, grad/param norm = 2.7495e-01, time/batch = 18.3540s	
12220/16650 (epoch 36.697), train_loss = 0.61685312, grad/param norm = 2.2464e-01, time/batch = 18.5312s	
12221/16650 (epoch 36.700), train_loss = 0.79446911, grad/param norm = 3.4518e-01, time/batch = 16.0647s	
12222/16650 (epoch 36.703), train_loss = 0.67631092, grad/param norm = 4.6507e-01, time/batch = 17.9435s	
12223/16650 (epoch 36.706), train_loss = 0.72719324, grad/param norm = 3.0579e-01, time/batch = 17.3334s	
12224/16650 (epoch 36.709), train_loss = 0.64309761, grad/param norm = 2.7146e-01, time/batch = 16.4303s	
12225/16650 (epoch 36.712), train_loss = 0.67616717, grad/param norm = 3.0815e-01, time/batch = 17.4430s	
12226/16650 (epoch 36.715), train_loss = 0.76873872, grad/param norm = 3.0579e-01, time/batch = 16.7823s	
12227/16650 (epoch 36.718), train_loss = 0.81377096, grad/param norm = 3.3281e-01, time/batch = 16.4338s	
12228/16650 (epoch 36.721), train_loss = 0.83579874, grad/param norm = 2.9711e-01, time/batch = 16.6569s	
12229/16650 (epoch 36.724), train_loss = 0.80576352, grad/param norm = 3.2011e-01, time/batch = 14.5307s	
12230/16650 (epoch 36.727), train_loss = 0.82465163, grad/param norm = 3.0705e-01, time/batch = 17.5275s	
12231/16650 (epoch 36.730), train_loss = 0.67299721, grad/param norm = 3.0242e-01, time/batch = 17.6704s	
12232/16650 (epoch 36.733), train_loss = 0.84396142, grad/param norm = 3.3927e-01, time/batch = 18.5279s	
12233/16650 (epoch 36.736), train_loss = 0.62738762, grad/param norm = 2.9157e-01, time/batch = 18.1916s	
12234/16650 (epoch 36.739), train_loss = 0.76471692, grad/param norm = 2.8427e-01, time/batch = 15.6553s	
12235/16650 (epoch 36.742), train_loss = 0.74612894, grad/param norm = 2.7227e-01, time/batch = 16.5975s	
12236/16650 (epoch 36.745), train_loss = 0.58377176, grad/param norm = 2.8429e-01, time/batch = 17.5097s	
12237/16650 (epoch 36.748), train_loss = 0.64508270, grad/param norm = 3.4001e-01, time/batch = 18.7007s	
12238/16650 (epoch 36.751), train_loss = 0.77927069, grad/param norm = 4.0009e-01, time/batch = 17.1719s	
12239/16650 (epoch 36.754), train_loss = 0.94357896, grad/param norm = 4.7461e-01, time/batch = 17.4313s	
12240/16650 (epoch 36.757), train_loss = 0.89824548, grad/param norm = 3.5615e-01, time/batch = 18.6215s	
12241/16650 (epoch 36.760), train_loss = 0.76323895, grad/param norm = 3.1736e-01, time/batch = 17.3494s	
12242/16650 (epoch 36.763), train_loss = 0.69427667, grad/param norm = 3.0399e-01, time/batch = 18.5099s	
12243/16650 (epoch 36.766), train_loss = 0.71516832, grad/param norm = 2.7318e-01, time/batch = 19.3685s	
12244/16650 (epoch 36.769), train_loss = 0.77831455, grad/param norm = 2.9356e-01, time/batch = 16.9531s	
12245/16650 (epoch 36.772), train_loss = 0.74349680, grad/param norm = 2.5154e-01, time/batch = 16.8466s	
12246/16650 (epoch 36.775), train_loss = 0.72333599, grad/param norm = 2.6679e-01, time/batch = 18.2708s	
12247/16650 (epoch 36.778), train_loss = 0.76561182, grad/param norm = 2.6448e-01, time/batch = 17.1706s	
12248/16650 (epoch 36.781), train_loss = 0.88645410, grad/param norm = 2.7652e-01, time/batch = 17.0280s	
12249/16650 (epoch 36.784), train_loss = 0.77801583, grad/param norm = 3.1051e-01, time/batch = 17.6709s	
12250/16650 (epoch 36.787), train_loss = 0.83064466, grad/param norm = 3.2299e-01, time/batch = 18.1966s	
12251/16650 (epoch 36.790), train_loss = 0.83446155, grad/param norm = 2.8370e-01, time/batch = 15.0194s	
12252/16650 (epoch 36.793), train_loss = 0.65066330, grad/param norm = 2.6184e-01, time/batch = 15.4517s	
12253/16650 (epoch 36.796), train_loss = 0.99321430, grad/param norm = 3.2364e-01, time/batch = 18.1045s	
12254/16650 (epoch 36.799), train_loss = 0.90846740, grad/param norm = 3.3452e-01, time/batch = 18.9546s	
12255/16650 (epoch 36.802), train_loss = 0.81716682, grad/param norm = 2.9622e-01, time/batch = 17.3474s	
12256/16650 (epoch 36.805), train_loss = 0.77476291, grad/param norm = 2.9017e-01, time/batch = 15.3284s	
12257/16650 (epoch 36.808), train_loss = 0.82559613, grad/param norm = 2.8375e-01, time/batch = 14.5408s	
12258/16650 (epoch 36.811), train_loss = 0.85698776, grad/param norm = 2.7673e-01, time/batch = 18.1866s	
12259/16650 (epoch 36.814), train_loss = 0.68076046, grad/param norm = 2.6076e-01, time/batch = 16.2509s	
12260/16650 (epoch 36.817), train_loss = 0.71109512, grad/param norm = 2.9688e-01, time/batch = 18.3674s	
12261/16650 (epoch 36.820), train_loss = 0.81298817, grad/param norm = 2.9478e-01, time/batch = 16.0033s	
12262/16650 (epoch 36.823), train_loss = 0.75723706, grad/param norm = 2.8081e-01, time/batch = 16.9147s	
12263/16650 (epoch 36.826), train_loss = 0.71272244, grad/param norm = 2.7412e-01, time/batch = 18.2513s	
12264/16650 (epoch 36.829), train_loss = 0.76815183, grad/param norm = 2.9209e-01, time/batch = 18.9280s	
12265/16650 (epoch 36.832), train_loss = 0.81372556, grad/param norm = 2.8054e-01, time/batch = 17.5239s	
12266/16650 (epoch 36.835), train_loss = 0.81825011, grad/param norm = 3.2751e-01, time/batch = 17.3240s	
12267/16650 (epoch 36.838), train_loss = 0.67112004, grad/param norm = 2.6267e-01, time/batch = 17.9261s	
12268/16650 (epoch 36.841), train_loss = 0.69332791, grad/param norm = 2.5579e-01, time/batch = 15.5774s	
12269/16650 (epoch 36.844), train_loss = 0.70387363, grad/param norm = 2.4250e-01, time/batch = 14.4673s	
12270/16650 (epoch 36.847), train_loss = 0.82740913, grad/param norm = 3.2484e-01, time/batch = 14.5887s	
12271/16650 (epoch 36.850), train_loss = 0.67343562, grad/param norm = 3.2067e-01, time/batch = 15.0869s	
12272/16650 (epoch 36.853), train_loss = 0.74839181, grad/param norm = 3.0182e-01, time/batch = 14.5710s	
12273/16650 (epoch 36.856), train_loss = 0.68837466, grad/param norm = 2.5778e-01, time/batch = 14.6154s	
12274/16650 (epoch 36.859), train_loss = 0.86144263, grad/param norm = 3.4279e-01, time/batch = 14.4023s	
12275/16650 (epoch 36.862), train_loss = 0.73756521, grad/param norm = 3.1816e-01, time/batch = 14.8314s	
12276/16650 (epoch 36.865), train_loss = 0.61730417, grad/param norm = 2.9702e-01, time/batch = 17.5968s	
12277/16650 (epoch 36.868), train_loss = 0.78034800, grad/param norm = 2.9183e-01, time/batch = 16.5796s	
12278/16650 (epoch 36.871), train_loss = 0.80341003, grad/param norm = 3.0920e-01, time/batch = 15.8153s	
12279/16650 (epoch 36.874), train_loss = 0.79166320, grad/param norm = 3.0907e-01, time/batch = 18.6727s	
12280/16650 (epoch 36.877), train_loss = 0.76038389, grad/param norm = 2.7875e-01, time/batch = 18.1045s	
12281/16650 (epoch 36.880), train_loss = 0.69228108, grad/param norm = 3.0409e-01, time/batch = 16.6706s	
12282/16650 (epoch 36.883), train_loss = 0.77738812, grad/param norm = 3.2310e-01, time/batch = 15.4161s	
12283/16650 (epoch 36.886), train_loss = 0.77109348, grad/param norm = 2.6898e-01, time/batch = 16.7838s	
12284/16650 (epoch 36.889), train_loss = 0.63291090, grad/param norm = 2.8596e-01, time/batch = 16.8377s	
12285/16650 (epoch 36.892), train_loss = 0.75405994, grad/param norm = 2.6893e-01, time/batch = 16.5906s	
12286/16650 (epoch 36.895), train_loss = 0.77819496, grad/param norm = 2.8932e-01, time/batch = 18.7529s	
12287/16650 (epoch 36.898), train_loss = 0.76988594, grad/param norm = 3.1367e-01, time/batch = 16.8476s	
12288/16650 (epoch 36.901), train_loss = 0.70743245, grad/param norm = 2.9833e-01, time/batch = 16.0114s	
12289/16650 (epoch 36.904), train_loss = 0.70915800, grad/param norm = 3.1519e-01, time/batch = 17.6959s	
12290/16650 (epoch 36.907), train_loss = 0.77180792, grad/param norm = 2.9010e-01, time/batch = 18.1817s	
12291/16650 (epoch 36.910), train_loss = 0.79394205, grad/param norm = 2.9352e-01, time/batch = 17.1576s	
12292/16650 (epoch 36.913), train_loss = 0.71927513, grad/param norm = 3.0176e-01, time/batch = 17.6806s	
12293/16650 (epoch 36.916), train_loss = 0.69614580, grad/param norm = 2.7076e-01, time/batch = 18.2767s	
12294/16650 (epoch 36.919), train_loss = 0.89104595, grad/param norm = 2.8792e-01, time/batch = 17.8470s	
12295/16650 (epoch 36.922), train_loss = 0.80138033, grad/param norm = 3.9299e-01, time/batch = 17.5287s	
12296/16650 (epoch 36.925), train_loss = 0.70486035, grad/param norm = 3.0992e-01, time/batch = 17.9386s	
12297/16650 (epoch 36.928), train_loss = 0.76114742, grad/param norm = 2.7556e-01, time/batch = 18.1037s	
12298/16650 (epoch 36.931), train_loss = 0.78855713, grad/param norm = 3.1769e-01, time/batch = 15.8685s	
12299/16650 (epoch 36.934), train_loss = 0.64270560, grad/param norm = 3.0121e-01, time/batch = 16.6165s	
12300/16650 (epoch 36.937), train_loss = 0.66794300, grad/param norm = 3.0268e-01, time/batch = 18.1194s	
12301/16650 (epoch 36.940), train_loss = 0.72617617, grad/param norm = 2.7477e-01, time/batch = 16.5812s	
12302/16650 (epoch 36.943), train_loss = 0.76340657, grad/param norm = 3.3815e-01, time/batch = 16.4333s	
12303/16650 (epoch 36.946), train_loss = 0.70344813, grad/param norm = 3.1791e-01, time/batch = 18.1195s	
12304/16650 (epoch 36.949), train_loss = 0.63414655, grad/param norm = 2.5895e-01, time/batch = 17.6202s	
12305/16650 (epoch 36.952), train_loss = 0.63574233, grad/param norm = 2.6602e-01, time/batch = 14.8087s	
12306/16650 (epoch 36.955), train_loss = 0.74847186, grad/param norm = 2.5713e-01, time/batch = 16.4072s	
12307/16650 (epoch 36.958), train_loss = 0.79995648, grad/param norm = 3.2134e-01, time/batch = 19.1274s	
12308/16650 (epoch 36.961), train_loss = 0.72191291, grad/param norm = 2.3641e-01, time/batch = 17.4322s	
12309/16650 (epoch 36.964), train_loss = 0.67190639, grad/param norm = 3.9212e-01, time/batch = 16.6835s	
12310/16650 (epoch 36.967), train_loss = 0.91848538, grad/param norm = 3.8452e-01, time/batch = 18.2890s	
12311/16650 (epoch 36.970), train_loss = 0.70495945, grad/param norm = 2.6567e-01, time/batch = 17.5940s	
12312/16650 (epoch 36.973), train_loss = 0.71046590, grad/param norm = 3.0880e-01, time/batch = 18.0851s	
12313/16650 (epoch 36.976), train_loss = 0.67174067, grad/param norm = 2.6761e-01, time/batch = 16.8828s	
12314/16650 (epoch 36.979), train_loss = 0.78310312, grad/param norm = 3.1073e-01, time/batch = 17.2641s	
12315/16650 (epoch 36.982), train_loss = 0.81948466, grad/param norm = 3.1747e-01, time/batch = 16.8414s	
12316/16650 (epoch 36.985), train_loss = 0.74550112, grad/param norm = 2.7849e-01, time/batch = 25.5707s	
12317/16650 (epoch 36.988), train_loss = 0.78582294, grad/param norm = 3.6229e-01, time/batch = 33.9246s	
12318/16650 (epoch 36.991), train_loss = 0.68419108, grad/param norm = 3.0414e-01, time/batch = 30.6060s	
12319/16650 (epoch 36.994), train_loss = 0.69887692, grad/param norm = 2.8075e-01, time/batch = 35.8725s	
12320/16650 (epoch 36.997), train_loss = 0.71298255, grad/param norm = 2.8752e-01, time/batch = 37.2730s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
12321/16650 (epoch 37.000), train_loss = 0.79343195, grad/param norm = 3.0703e-01, time/batch = 34.1037s	
12322/16650 (epoch 37.003), train_loss = 0.86534567, grad/param norm = 3.5684e-01, time/batch = 34.5635s	
12323/16650 (epoch 37.006), train_loss = 0.82765943, grad/param norm = 3.1554e-01, time/batch = 39.7615s	
12324/16650 (epoch 37.009), train_loss = 0.88504253, grad/param norm = 3.1761e-01, time/batch = 38.4947s	
12325/16650 (epoch 37.012), train_loss = 0.85856080, grad/param norm = 3.0464e-01, time/batch = 40.2810s	
12326/16650 (epoch 37.015), train_loss = 0.76382256, grad/param norm = 2.7814e-01, time/batch = 37.5678s	
12327/16650 (epoch 37.018), train_loss = 0.66400081, grad/param norm = 2.9634e-01, time/batch = 23.8718s	
12328/16650 (epoch 37.021), train_loss = 0.88949371, grad/param norm = 4.2654e-01, time/batch = 16.2554s	
12329/16650 (epoch 37.024), train_loss = 0.74643810, grad/param norm = 3.1230e-01, time/batch = 17.2911s	
12330/16650 (epoch 37.027), train_loss = 0.80319665, grad/param norm = 3.4555e-01, time/batch = 18.6865s	
12331/16650 (epoch 37.030), train_loss = 0.65077349, grad/param norm = 2.5785e-01, time/batch = 18.6865s	
12332/16650 (epoch 37.033), train_loss = 0.73968274, grad/param norm = 2.5514e-01, time/batch = 31.0535s	
12333/16650 (epoch 37.036), train_loss = 0.55517906, grad/param norm = 3.1285e-01, time/batch = 18.0185s	
12334/16650 (epoch 37.039), train_loss = 0.88061571, grad/param norm = 3.0642e-01, time/batch = 16.5151s	
12335/16650 (epoch 37.042), train_loss = 0.78419818, grad/param norm = 3.1634e-01, time/batch = 16.7832s	
12336/16650 (epoch 37.045), train_loss = 0.73013386, grad/param norm = 2.7601e-01, time/batch = 16.8079s	
12337/16650 (epoch 37.048), train_loss = 0.82223072, grad/param norm = 3.0677e-01, time/batch = 16.9350s	
12338/16650 (epoch 37.051), train_loss = 0.72184331, grad/param norm = 2.7256e-01, time/batch = 18.4521s	
12339/16650 (epoch 37.054), train_loss = 0.74667210, grad/param norm = 2.8822e-01, time/batch = 18.1139s	
12340/16650 (epoch 37.057), train_loss = 0.75698023, grad/param norm = 3.2883e-01, time/batch = 17.8446s	
12341/16650 (epoch 37.060), train_loss = 0.64298568, grad/param norm = 2.7911e-01, time/batch = 16.2207s	
12342/16650 (epoch 37.063), train_loss = 0.72883282, grad/param norm = 2.9883e-01, time/batch = 18.4579s	
12343/16650 (epoch 37.066), train_loss = 0.88272694, grad/param norm = 3.0496e-01, time/batch = 18.2961s	
12344/16650 (epoch 37.069), train_loss = 0.82049130, grad/param norm = 3.3205e-01, time/batch = 15.5883s	
12345/16650 (epoch 37.072), train_loss = 0.76962608, grad/param norm = 3.3891e-01, time/batch = 18.5295s	
12346/16650 (epoch 37.075), train_loss = 0.83310591, grad/param norm = 3.1579e-01, time/batch = 18.1229s	
12347/16650 (epoch 37.078), train_loss = 0.83178385, grad/param norm = 3.3010e-01, time/batch = 17.5159s	
12348/16650 (epoch 37.081), train_loss = 0.78980847, grad/param norm = 3.7527e-01, time/batch = 18.3597s	
12349/16650 (epoch 37.084), train_loss = 0.78598718, grad/param norm = 3.1985e-01, time/batch = 18.0140s	
12350/16650 (epoch 37.087), train_loss = 0.79920159, grad/param norm = 3.2101e-01, time/batch = 15.4268s	
12351/16650 (epoch 37.090), train_loss = 0.75521725, grad/param norm = 3.3769e-01, time/batch = 18.0758s	
12352/16650 (epoch 37.093), train_loss = 0.87951636, grad/param norm = 3.7409e-01, time/batch = 17.2761s	
12353/16650 (epoch 37.096), train_loss = 0.71223445, grad/param norm = 2.9168e-01, time/batch = 19.1345s	
12354/16650 (epoch 37.099), train_loss = 0.79078690, grad/param norm = 3.2080e-01, time/batch = 16.0142s	
12355/16650 (epoch 37.102), train_loss = 0.77410896, grad/param norm = 3.0277e-01, time/batch = 18.8012s	
12356/16650 (epoch 37.105), train_loss = 0.76912394, grad/param norm = 3.2409e-01, time/batch = 17.1230s	
12357/16650 (epoch 37.108), train_loss = 0.77989324, grad/param norm = 3.0143e-01, time/batch = 17.7779s	
12358/16650 (epoch 37.111), train_loss = 0.85229364, grad/param norm = 2.9489e-01, time/batch = 15.4591s	
12359/16650 (epoch 37.114), train_loss = 0.82401785, grad/param norm = 5.0854e-01, time/batch = 17.6869s	
12360/16650 (epoch 37.117), train_loss = 0.91197600, grad/param norm = 3.4443e-01, time/batch = 16.9127s	
12361/16650 (epoch 37.120), train_loss = 0.78001593, grad/param norm = 2.9708e-01, time/batch = 15.8097s	
12362/16650 (epoch 37.123), train_loss = 0.75311435, grad/param norm = 2.7840e-01, time/batch = 18.3572s	
12363/16650 (epoch 37.126), train_loss = 0.80426502, grad/param norm = 2.9312e-01, time/batch = 17.7166s	
12364/16650 (epoch 37.129), train_loss = 0.81245478, grad/param norm = 3.7109e-01, time/batch = 17.4349s	
12365/16650 (epoch 37.132), train_loss = 0.76371824, grad/param norm = 2.8173e-01, time/batch = 16.7610s	
12366/16650 (epoch 37.135), train_loss = 0.86144995, grad/param norm = 2.7557e-01, time/batch = 16.8440s	
12367/16650 (epoch 37.138), train_loss = 0.83405071, grad/param norm = 2.9992e-01, time/batch = 17.2573s	
12368/16650 (epoch 37.141), train_loss = 0.80831833, grad/param norm = 3.6824e-01, time/batch = 15.7524s	
12369/16650 (epoch 37.144), train_loss = 0.82102930, grad/param norm = 3.2762e-01, time/batch = 18.4528s	
12370/16650 (epoch 37.147), train_loss = 0.90161607, grad/param norm = 3.0321e-01, time/batch = 18.1894s	
12371/16650 (epoch 37.150), train_loss = 0.97122330, grad/param norm = 3.4003e-01, time/batch = 17.6821s	
12372/16650 (epoch 37.153), train_loss = 0.77858935, grad/param norm = 3.0772e-01, time/batch = 18.9570s	
12373/16650 (epoch 37.156), train_loss = 0.76328847, grad/param norm = 3.1151e-01, time/batch = 17.6235s	
12374/16650 (epoch 37.159), train_loss = 0.83252853, grad/param norm = 2.9185e-01, time/batch = 17.6088s	
12375/16650 (epoch 37.162), train_loss = 0.90002432, grad/param norm = 2.9834e-01, time/batch = 16.8319s	
12376/16650 (epoch 37.165), train_loss = 0.86930582, grad/param norm = 3.0704e-01, time/batch = 16.4175s	
12377/16650 (epoch 37.168), train_loss = 0.64607173, grad/param norm = 2.5463e-01, time/batch = 17.4014s	
12378/16650 (epoch 37.171), train_loss = 0.83194933, grad/param norm = 3.0147e-01, time/batch = 17.5150s	
12379/16650 (epoch 37.174), train_loss = 0.63319495, grad/param norm = 2.6938e-01, time/batch = 16.4198s	
12380/16650 (epoch 37.177), train_loss = 0.77119191, grad/param norm = 3.1270e-01, time/batch = 17.5864s	
12381/16650 (epoch 37.180), train_loss = 0.87613537, grad/param norm = 2.9883e-01, time/batch = 18.1068s	
12382/16650 (epoch 37.183), train_loss = 1.00832233, grad/param norm = 3.9485e-01, time/batch = 17.0020s	
12383/16650 (epoch 37.186), train_loss = 0.81612834, grad/param norm = 2.9353e-01, time/batch = 17.8651s	
12384/16650 (epoch 37.189), train_loss = 0.71012063, grad/param norm = 2.5052e-01, time/batch = 17.1990s	
12385/16650 (epoch 37.192), train_loss = 0.77266809, grad/param norm = 3.1212e-01, time/batch = 16.4240s	
12386/16650 (epoch 37.195), train_loss = 0.71789583, grad/param norm = 3.0402e-01, time/batch = 16.6454s	
12387/16650 (epoch 37.198), train_loss = 0.67488708, grad/param norm = 2.3832e-01, time/batch = 17.0296s	
12388/16650 (epoch 37.201), train_loss = 0.68906737, grad/param norm = 2.8440e-01, time/batch = 17.7792s	
12389/16650 (epoch 37.204), train_loss = 0.79662587, grad/param norm = 3.2938e-01, time/batch = 17.7716s	
12390/16650 (epoch 37.207), train_loss = 0.82841142, grad/param norm = 3.8590e-01, time/batch = 18.2733s	
12391/16650 (epoch 37.210), train_loss = 0.76490176, grad/param norm = 2.8206e-01, time/batch = 18.2799s	
12392/16650 (epoch 37.213), train_loss = 0.83429163, grad/param norm = 3.0392e-01, time/batch = 16.1733s	
12393/16650 (epoch 37.216), train_loss = 0.71760535, grad/param norm = 2.7251e-01, time/batch = 15.7980s	
12394/16650 (epoch 37.219), train_loss = 0.75581264, grad/param norm = 3.1315e-01, time/batch = 18.2677s	
12395/16650 (epoch 37.222), train_loss = 0.77671316, grad/param norm = 2.6247e-01, time/batch = 16.7631s	
12396/16650 (epoch 37.225), train_loss = 0.82367817, grad/param norm = 3.5009e-01, time/batch = 18.2756s	
12397/16650 (epoch 37.228), train_loss = 0.71544778, grad/param norm = 3.1019e-01, time/batch = 17.5405s	
12398/16650 (epoch 37.231), train_loss = 0.71887550, grad/param norm = 3.3385e-01, time/batch = 17.9346s	
12399/16650 (epoch 37.234), train_loss = 0.92383438, grad/param norm = 2.9790e-01, time/batch = 16.8198s	
12400/16650 (epoch 37.237), train_loss = 0.78962509, grad/param norm = 3.4296e-01, time/batch = 17.7747s	
12401/16650 (epoch 37.240), train_loss = 0.78631750, grad/param norm = 2.7300e-01, time/batch = 18.0220s	
12402/16650 (epoch 37.243), train_loss = 0.75689786, grad/param norm = 2.8042e-01, time/batch = 16.6759s	
12403/16650 (epoch 37.246), train_loss = 0.89660201, grad/param norm = 3.8852e-01, time/batch = 18.1897s	
12404/16650 (epoch 37.249), train_loss = 0.65623370, grad/param norm = 2.4436e-01, time/batch = 17.5263s	
12405/16650 (epoch 37.252), train_loss = 0.74503218, grad/param norm = 2.6893e-01, time/batch = 14.6275s	
12406/16650 (epoch 37.255), train_loss = 0.81409156, grad/param norm = 3.3255e-01, time/batch = 16.8300s	
12407/16650 (epoch 37.258), train_loss = 0.85517451, grad/param norm = 3.1296e-01, time/batch = 17.6846s	
12408/16650 (epoch 37.261), train_loss = 0.80141276, grad/param norm = 2.6063e-01, time/batch = 17.3705s	
12409/16650 (epoch 37.264), train_loss = 0.71681596, grad/param norm = 2.8723e-01, time/batch = 16.7720s	
12410/16650 (epoch 37.267), train_loss = 0.74013772, grad/param norm = 2.9285e-01, time/batch = 16.2589s	
12411/16650 (epoch 37.270), train_loss = 0.81634413, grad/param norm = 3.0199e-01, time/batch = 17.0900s	
12412/16650 (epoch 37.273), train_loss = 0.86497072, grad/param norm = 3.1156e-01, time/batch = 18.0952s	
12413/16650 (epoch 37.276), train_loss = 0.81330552, grad/param norm = 3.1485e-01, time/batch = 17.6683s	
12414/16650 (epoch 37.279), train_loss = 0.77109533, grad/param norm = 2.9931e-01, time/batch = 18.4470s	
12415/16650 (epoch 37.282), train_loss = 0.72130720, grad/param norm = 2.8019e-01, time/batch = 18.5136s	
12416/16650 (epoch 37.285), train_loss = 0.73171427, grad/param norm = 2.8525e-01, time/batch = 15.7394s	
12417/16650 (epoch 37.288), train_loss = 0.70477158, grad/param norm = 3.4966e-01, time/batch = 14.2583s	
12418/16650 (epoch 37.291), train_loss = 0.56555839, grad/param norm = 2.1780e-01, time/batch = 14.4859s	
12419/16650 (epoch 37.294), train_loss = 0.69219458, grad/param norm = 2.7889e-01, time/batch = 14.0854s	
12420/16650 (epoch 37.297), train_loss = 0.73674407, grad/param norm = 2.6034e-01, time/batch = 14.6380s	
12421/16650 (epoch 37.300), train_loss = 0.61070714, grad/param norm = 2.5458e-01, time/batch = 17.7615s	
12422/16650 (epoch 37.303), train_loss = 0.64451988, grad/param norm = 2.4242e-01, time/batch = 17.8629s	
12423/16650 (epoch 37.306), train_loss = 0.83020299, grad/param norm = 2.6793e-01, time/batch = 17.4356s	
12424/16650 (epoch 37.309), train_loss = 0.81622320, grad/param norm = 2.7408e-01, time/batch = 15.2278s	
12425/16650 (epoch 37.312), train_loss = 0.66226353, grad/param norm = 2.9923e-01, time/batch = 18.5220s	
12426/16650 (epoch 37.315), train_loss = 0.55535008, grad/param norm = 2.1593e-01, time/batch = 16.2584s	
12427/16650 (epoch 37.318), train_loss = 0.63175826, grad/param norm = 2.4296e-01, time/batch = 14.9856s	
12428/16650 (epoch 37.321), train_loss = 0.85925629, grad/param norm = 3.2669e-01, time/batch = 18.3624s	
12429/16650 (epoch 37.324), train_loss = 0.70249080, grad/param norm = 3.6294e-01, time/batch = 17.5914s	
12430/16650 (epoch 37.327), train_loss = 0.79175514, grad/param norm = 3.5775e-01, time/batch = 17.5244s	
12431/16650 (epoch 37.330), train_loss = 0.77761149, grad/param norm = 4.1143e-01, time/batch = 15.4049s	
12432/16650 (epoch 37.333), train_loss = 0.80979229, grad/param norm = 3.1334e-01, time/batch = 14.0967s	
12433/16650 (epoch 37.336), train_loss = 0.67513771, grad/param norm = 2.9517e-01, time/batch = 14.3427s	
12434/16650 (epoch 37.339), train_loss = 0.69479545, grad/param norm = 2.7812e-01, time/batch = 14.2600s	
12435/16650 (epoch 37.342), train_loss = 0.65486733, grad/param norm = 2.9257e-01, time/batch = 15.0601s	
12436/16650 (epoch 37.345), train_loss = 0.67350925, grad/param norm = 2.5451e-01, time/batch = 17.0095s	
12437/16650 (epoch 37.348), train_loss = 0.76462862, grad/param norm = 3.2836e-01, time/batch = 17.4927s	
12438/16650 (epoch 37.351), train_loss = 0.78662540, grad/param norm = 2.7496e-01, time/batch = 16.8460s	
12439/16650 (epoch 37.354), train_loss = 0.82954605, grad/param norm = 3.2393e-01, time/batch = 16.2609s	
12440/16650 (epoch 37.357), train_loss = 0.78944083, grad/param norm = 2.9869e-01, time/batch = 18.7863s	
12441/16650 (epoch 37.360), train_loss = 0.78067421, grad/param norm = 3.3263e-01, time/batch = 18.6122s	
12442/16650 (epoch 37.363), train_loss = 0.84598033, grad/param norm = 3.4917e-01, time/batch = 15.7922s	
12443/16650 (epoch 37.366), train_loss = 0.91387410, grad/param norm = 3.4059e-01, time/batch = 17.1813s	
12444/16650 (epoch 37.369), train_loss = 0.80227837, grad/param norm = 2.9909e-01, time/batch = 18.5310s	
12445/16650 (epoch 37.372), train_loss = 0.78952408, grad/param norm = 3.0736e-01, time/batch = 16.9316s	
12446/16650 (epoch 37.375), train_loss = 0.79283236, grad/param norm = 2.9342e-01, time/batch = 17.2463s	
12447/16650 (epoch 37.378), train_loss = 0.73395889, grad/param norm = 2.8736e-01, time/batch = 17.0214s	
12448/16650 (epoch 37.381), train_loss = 0.81917003, grad/param norm = 3.5501e-01, time/batch = 17.8650s	
12449/16650 (epoch 37.384), train_loss = 0.89397123, grad/param norm = 2.9999e-01, time/batch = 15.1733s	
12450/16650 (epoch 37.387), train_loss = 0.60286731, grad/param norm = 2.3931e-01, time/batch = 14.1292s	
12451/16650 (epoch 37.390), train_loss = 0.81403039, grad/param norm = 2.6604e-01, time/batch = 14.3076s	
12452/16650 (epoch 37.393), train_loss = 0.73514121, grad/param norm = 3.3347e-01, time/batch = 15.5732s	
12453/16650 (epoch 37.396), train_loss = 0.88134361, grad/param norm = 3.7528e-01, time/batch = 6.5848s	
12454/16650 (epoch 37.399), train_loss = 0.83138558, grad/param norm = 2.9922e-01, time/batch = 0.6672s	
12455/16650 (epoch 37.402), train_loss = 0.74356590, grad/param norm = 3.3335e-01, time/batch = 0.6465s	
12456/16650 (epoch 37.405), train_loss = 0.61768957, grad/param norm = 3.2216e-01, time/batch = 0.6647s	
12457/16650 (epoch 37.408), train_loss = 0.79280844, grad/param norm = 2.9296e-01, time/batch = 0.6672s	
12458/16650 (epoch 37.411), train_loss = 0.68625867, grad/param norm = 3.3771e-01, time/batch = 0.6504s	
12459/16650 (epoch 37.414), train_loss = 0.67378337, grad/param norm = 3.0486e-01, time/batch = 0.6417s	
12460/16650 (epoch 37.417), train_loss = 0.66798068, grad/param norm = 3.1533e-01, time/batch = 0.6397s	
12461/16650 (epoch 37.420), train_loss = 0.68777839, grad/param norm = 2.9354e-01, time/batch = 0.9458s	
12462/16650 (epoch 37.423), train_loss = 0.56948350, grad/param norm = 2.6141e-01, time/batch = 0.9555s	
12463/16650 (epoch 37.426), train_loss = 0.68297746, grad/param norm = 4.0730e-01, time/batch = 0.9514s	
12464/16650 (epoch 37.429), train_loss = 0.83795484, grad/param norm = 3.4558e-01, time/batch = 0.9396s	
12465/16650 (epoch 37.432), train_loss = 0.83100168, grad/param norm = 3.4216e-01, time/batch = 0.9351s	
12466/16650 (epoch 37.435), train_loss = 0.94002321, grad/param norm = 3.2733e-01, time/batch = 1.4931s	
12467/16650 (epoch 37.438), train_loss = 0.91372116, grad/param norm = 3.9164e-01, time/batch = 1.7529s	
12468/16650 (epoch 37.441), train_loss = 0.74298070, grad/param norm = 3.6110e-01, time/batch = 1.8028s	
12469/16650 (epoch 37.444), train_loss = 0.71520949, grad/param norm = 2.8970e-01, time/batch = 16.4418s	
12470/16650 (epoch 37.447), train_loss = 0.70044415, grad/param norm = 2.8093e-01, time/batch = 15.7502s	
12471/16650 (epoch 37.450), train_loss = 0.72088805, grad/param norm = 2.9367e-01, time/batch = 16.0881s	
12472/16650 (epoch 37.453), train_loss = 0.71172433, grad/param norm = 2.8778e-01, time/batch = 16.8671s	
12473/16650 (epoch 37.456), train_loss = 0.67642603, grad/param norm = 2.4131e-01, time/batch = 17.8518s	
12474/16650 (epoch 37.459), train_loss = 0.69855371, grad/param norm = 3.0787e-01, time/batch = 17.0120s	
12475/16650 (epoch 37.462), train_loss = 0.86052282, grad/param norm = 3.4619e-01, time/batch = 17.9320s	
12476/16650 (epoch 37.465), train_loss = 0.70574586, grad/param norm = 3.1183e-01, time/batch = 17.7630s	
12477/16650 (epoch 37.468), train_loss = 0.58191338, grad/param norm = 2.7210e-01, time/batch = 18.5354s	
12478/16650 (epoch 37.471), train_loss = 0.52227628, grad/param norm = 2.4387e-01, time/batch = 16.4952s	
12479/16650 (epoch 37.474), train_loss = 0.65017326, grad/param norm = 3.1084e-01, time/batch = 17.4395s	
12480/16650 (epoch 37.477), train_loss = 0.81780144, grad/param norm = 3.1405e-01, time/batch = 16.4724s	
12481/16650 (epoch 37.480), train_loss = 0.77431770, grad/param norm = 4.3193e-01, time/batch = 16.4256s	
12482/16650 (epoch 37.483), train_loss = 0.82772807, grad/param norm = 3.3149e-01, time/batch = 17.6906s	
12483/16650 (epoch 37.486), train_loss = 0.66363874, grad/param norm = 2.6640e-01, time/batch = 14.5728s	
12484/16650 (epoch 37.489), train_loss = 0.73372285, grad/param norm = 3.1285e-01, time/batch = 18.9592s	
12485/16650 (epoch 37.492), train_loss = 0.72467920, grad/param norm = 2.4977e-01, time/batch = 14.8873s	
12486/16650 (epoch 37.495), train_loss = 0.64006322, grad/param norm = 3.2514e-01, time/batch = 17.8514s	
12487/16650 (epoch 37.498), train_loss = 0.70136551, grad/param norm = 3.4082e-01, time/batch = 17.2009s	
12488/16650 (epoch 37.502), train_loss = 0.89670559, grad/param norm = 3.3602e-01, time/batch = 17.1036s	
12489/16650 (epoch 37.505), train_loss = 0.78470963, grad/param norm = 2.7896e-01, time/batch = 15.7579s	
12490/16650 (epoch 37.508), train_loss = 0.80474707, grad/param norm = 4.5652e-01, time/batch = 17.2671s	
12491/16650 (epoch 37.511), train_loss = 0.82797280, grad/param norm = 3.0267e-01, time/batch = 18.5470s	
12492/16650 (epoch 37.514), train_loss = 0.65943324, grad/param norm = 3.0303e-01, time/batch = 16.7593s	
12493/16650 (epoch 37.517), train_loss = 0.74012892, grad/param norm = 3.4165e-01, time/batch = 18.3404s	
12494/16650 (epoch 37.520), train_loss = 0.62872859, grad/param norm = 2.6242e-01, time/batch = 19.0365s	
12495/16650 (epoch 37.523), train_loss = 0.74112446, grad/param norm = 2.8550e-01, time/batch = 16.7616s	
12496/16650 (epoch 37.526), train_loss = 0.81481530, grad/param norm = 3.1866e-01, time/batch = 17.3587s	
12497/16650 (epoch 37.529), train_loss = 0.85683769, grad/param norm = 3.6702e-01, time/batch = 16.6906s	
12498/16650 (epoch 37.532), train_loss = 0.56270907, grad/param norm = 2.6527e-01, time/batch = 16.3148s	
12499/16650 (epoch 37.535), train_loss = 0.66449505, grad/param norm = 3.1905e-01, time/batch = 17.0138s	
12500/16650 (epoch 37.538), train_loss = 0.60419514, grad/param norm = 2.7006e-01, time/batch = 17.6972s	
12501/16650 (epoch 37.541), train_loss = 0.88239209, grad/param norm = 3.8189e-01, time/batch = 16.1491s	
12502/16650 (epoch 37.544), train_loss = 0.89929363, grad/param norm = 4.5502e-01, time/batch = 16.6855s	
12503/16650 (epoch 37.547), train_loss = 0.65039281, grad/param norm = 2.9642e-01, time/batch = 16.6755s	
12504/16650 (epoch 37.550), train_loss = 0.74111203, grad/param norm = 2.7689e-01, time/batch = 16.9191s	
12505/16650 (epoch 37.553), train_loss = 0.73750557, grad/param norm = 2.8702e-01, time/batch = 18.3765s	
12506/16650 (epoch 37.556), train_loss = 0.67271948, grad/param norm = 3.0142e-01, time/batch = 16.5958s	
12507/16650 (epoch 37.559), train_loss = 0.60374416, grad/param norm = 2.8289e-01, time/batch = 17.9552s	
12508/16650 (epoch 37.562), train_loss = 0.69121244, grad/param norm = 2.9973e-01, time/batch = 17.8483s	
12509/16650 (epoch 37.565), train_loss = 0.58864755, grad/param norm = 2.8801e-01, time/batch = 18.0235s	
12510/16650 (epoch 37.568), train_loss = 0.59643914, grad/param norm = 2.8083e-01, time/batch = 17.8559s	
12511/16650 (epoch 37.571), train_loss = 0.67334005, grad/param norm = 4.8619e-01, time/batch = 17.0168s	
12512/16650 (epoch 37.574), train_loss = 0.68244750, grad/param norm = 3.8846e-01, time/batch = 17.4183s	
12513/16650 (epoch 37.577), train_loss = 0.71957623, grad/param norm = 2.9993e-01, time/batch = 16.0961s	
12514/16650 (epoch 37.580), train_loss = 0.64712690, grad/param norm = 2.7735e-01, time/batch = 18.6120s	
12515/16650 (epoch 37.583), train_loss = 0.74307673, grad/param norm = 3.0348e-01, time/batch = 16.4385s	
12516/16650 (epoch 37.586), train_loss = 0.66185571, grad/param norm = 3.2737e-01, time/batch = 15.0492s	
12517/16650 (epoch 37.589), train_loss = 0.64594569, grad/param norm = 2.5359e-01, time/batch = 18.1965s	
12518/16650 (epoch 37.592), train_loss = 0.72935471, grad/param norm = 2.8748e-01, time/batch = 18.1997s	
12519/16650 (epoch 37.595), train_loss = 0.66737248, grad/param norm = 3.1553e-01, time/batch = 17.5214s	
12520/16650 (epoch 37.598), train_loss = 0.70250922, grad/param norm = 2.8984e-01, time/batch = 18.2586s	
12521/16650 (epoch 37.601), train_loss = 0.68584725, grad/param norm = 3.5736e-01, time/batch = 16.9291s	
12522/16650 (epoch 37.604), train_loss = 0.73451526, grad/param norm = 3.0260e-01, time/batch = 18.4522s	
12523/16650 (epoch 37.607), train_loss = 0.78850746, grad/param norm = 2.8984e-01, time/batch = 15.1989s	
12524/16650 (epoch 37.610), train_loss = 0.67114777, grad/param norm = 2.6318e-01, time/batch = 18.7641s	
12525/16650 (epoch 37.613), train_loss = 0.83726319, grad/param norm = 3.0679e-01, time/batch = 17.7727s	
12526/16650 (epoch 37.616), train_loss = 0.80596650, grad/param norm = 3.4445e-01, time/batch = 16.9244s	
12527/16650 (epoch 37.619), train_loss = 0.62731296, grad/param norm = 2.8139e-01, time/batch = 17.7768s	
12528/16650 (epoch 37.622), train_loss = 0.60689898, grad/param norm = 2.9136e-01, time/batch = 17.6150s	
12529/16650 (epoch 37.625), train_loss = 0.70591322, grad/param norm = 2.7924e-01, time/batch = 18.6193s	
12530/16650 (epoch 37.628), train_loss = 0.68534502, grad/param norm = 4.0722e-01, time/batch = 16.4119s	
12531/16650 (epoch 37.631), train_loss = 0.73772838, grad/param norm = 4.4236e-01, time/batch = 18.8585s	
12532/16650 (epoch 37.634), train_loss = 0.91070861, grad/param norm = 3.5330e-01, time/batch = 16.9410s	
12533/16650 (epoch 37.637), train_loss = 0.89640187, grad/param norm = 3.3646e-01, time/batch = 16.7628s	
12534/16650 (epoch 37.640), train_loss = 0.69902285, grad/param norm = 2.9453e-01, time/batch = 18.0188s	
12535/16650 (epoch 37.643), train_loss = 0.80295801, grad/param norm = 3.2051e-01, time/batch = 17.6825s	
12536/16650 (epoch 37.646), train_loss = 0.78236541, grad/param norm = 3.7041e-01, time/batch = 16.6727s	
12537/16650 (epoch 37.649), train_loss = 0.77156966, grad/param norm = 3.3938e-01, time/batch = 18.1558s	
12538/16650 (epoch 37.652), train_loss = 0.79744926, grad/param norm = 3.2866e-01, time/batch = 17.2722s	
12539/16650 (epoch 37.655), train_loss = 0.74575577, grad/param norm = 3.2376e-01, time/batch = 18.6982s	
12540/16650 (epoch 37.658), train_loss = 0.67897863, grad/param norm = 2.8708e-01, time/batch = 16.9287s	
12541/16650 (epoch 37.661), train_loss = 0.75965853, grad/param norm = 3.0761e-01, time/batch = 16.5006s	
12542/16650 (epoch 37.664), train_loss = 0.74934989, grad/param norm = 3.3378e-01, time/batch = 18.6039s	
12543/16650 (epoch 37.667), train_loss = 0.84172377, grad/param norm = 3.4805e-01, time/batch = 17.6899s	
12544/16650 (epoch 37.670), train_loss = 0.62883712, grad/param norm = 2.7936e-01, time/batch = 17.0812s	
12545/16650 (epoch 37.673), train_loss = 0.65512430, grad/param norm = 2.7232e-01, time/batch = 18.4605s	
12546/16650 (epoch 37.676), train_loss = 0.78440316, grad/param norm = 2.8819e-01, time/batch = 18.6163s	
12547/16650 (epoch 37.679), train_loss = 0.66264288, grad/param norm = 2.6981e-01, time/batch = 17.0695s	
12548/16650 (epoch 37.682), train_loss = 0.71679826, grad/param norm = 3.2667e-01, time/batch = 16.0753s	
12549/16650 (epoch 37.685), train_loss = 0.61983889, grad/param norm = 2.7726e-01, time/batch = 17.8536s	
12550/16650 (epoch 37.688), train_loss = 0.78790273, grad/param norm = 2.8956e-01, time/batch = 15.8129s	
12551/16650 (epoch 37.691), train_loss = 0.76130010, grad/param norm = 3.0106e-01, time/batch = 17.4305s	
12552/16650 (epoch 37.694), train_loss = 0.68056123, grad/param norm = 3.3289e-01, time/batch = 18.6979s	
12553/16650 (epoch 37.697), train_loss = 0.62160087, grad/param norm = 2.3477e-01, time/batch = 17.8574s	
12554/16650 (epoch 37.700), train_loss = 0.78383054, grad/param norm = 3.4562e-01, time/batch = 30.2953s	
12555/16650 (epoch 37.703), train_loss = 0.66819721, grad/param norm = 3.6426e-01, time/batch = 17.6798s	
12556/16650 (epoch 37.706), train_loss = 0.72224251, grad/param norm = 3.4969e-01, time/batch = 16.4242s	
12557/16650 (epoch 37.709), train_loss = 0.63512099, grad/param norm = 2.9217e-01, time/batch = 18.0112s	
12558/16650 (epoch 37.712), train_loss = 0.66091377, grad/param norm = 3.0519e-01, time/batch = 16.0629s	
12559/16650 (epoch 37.715), train_loss = 0.77057414, grad/param norm = 3.2562e-01, time/batch = 18.5385s	
12560/16650 (epoch 37.718), train_loss = 0.79716659, grad/param norm = 3.3270e-01, time/batch = 16.7417s	
12561/16650 (epoch 37.721), train_loss = 0.82656573, grad/param norm = 3.2514e-01, time/batch = 19.0345s	
12562/16650 (epoch 37.724), train_loss = 0.79710154, grad/param norm = 3.2059e-01, time/batch = 18.6767s	
12563/16650 (epoch 37.727), train_loss = 0.82026609, grad/param norm = 2.8596e-01, time/batch = 15.5699s	
12564/16650 (epoch 37.730), train_loss = 0.67344092, grad/param norm = 2.9085e-01, time/batch = 16.4800s	
12565/16650 (epoch 37.733), train_loss = 0.83198541, grad/param norm = 3.0922e-01, time/batch = 18.2001s	
12566/16650 (epoch 37.736), train_loss = 0.62598109, grad/param norm = 2.7651e-01, time/batch = 15.9854s	
12567/16650 (epoch 37.739), train_loss = 0.75529497, grad/param norm = 3.1129e-01, time/batch = 17.3272s	
12568/16650 (epoch 37.742), train_loss = 0.72426377, grad/param norm = 2.7260e-01, time/batch = 16.6876s	
12569/16650 (epoch 37.745), train_loss = 0.57190998, grad/param norm = 2.6528e-01, time/batch = 17.2804s	
12570/16650 (epoch 37.748), train_loss = 0.62275853, grad/param norm = 2.8553e-01, time/batch = 16.0728s	
12571/16650 (epoch 37.751), train_loss = 0.76809813, grad/param norm = 4.8746e-01, time/batch = 16.4690s	
12572/16650 (epoch 37.754), train_loss = 0.89687267, grad/param norm = 3.5589e-01, time/batch = 18.3774s	
12573/16650 (epoch 37.757), train_loss = 0.88244690, grad/param norm = 3.3327e-01, time/batch = 17.9463s	
12574/16650 (epoch 37.760), train_loss = 0.74351457, grad/param norm = 3.0259e-01, time/batch = 15.6712s	
12575/16650 (epoch 37.763), train_loss = 0.70331798, grad/param norm = 3.1427e-01, time/batch = 18.1918s	
12576/16650 (epoch 37.766), train_loss = 0.70442861, grad/param norm = 2.5375e-01, time/batch = 17.6126s	
12577/16650 (epoch 37.769), train_loss = 0.77197628, grad/param norm = 3.0198e-01, time/batch = 14.5395s	
12578/16650 (epoch 37.772), train_loss = 0.73207274, grad/param norm = 2.4748e-01, time/batch = 14.1720s	
12579/16650 (epoch 37.775), train_loss = 0.71403606, grad/param norm = 2.6170e-01, time/batch = 13.5999s	
12580/16650 (epoch 37.778), train_loss = 0.75505745, grad/param norm = 2.7325e-01, time/batch = 17.5279s	
12581/16650 (epoch 37.781), train_loss = 0.87432285, grad/param norm = 2.7942e-01, time/batch = 16.3602s	
12582/16650 (epoch 37.784), train_loss = 0.74765478, grad/param norm = 2.9404e-01, time/batch = 17.2841s	
12583/16650 (epoch 37.787), train_loss = 0.80561017, grad/param norm = 2.9160e-01, time/batch = 16.8664s	
12584/16650 (epoch 37.790), train_loss = 0.81955156, grad/param norm = 2.8430e-01, time/batch = 16.0142s	
12585/16650 (epoch 37.793), train_loss = 0.63439623, grad/param norm = 2.7690e-01, time/batch = 18.0811s	
12586/16650 (epoch 37.796), train_loss = 0.97440091, grad/param norm = 3.4459e-01, time/batch = 17.7684s	
12587/16650 (epoch 37.799), train_loss = 0.87966517, grad/param norm = 3.3860e-01, time/batch = 17.5358s	
12588/16650 (epoch 37.802), train_loss = 0.81256515, grad/param norm = 2.9425e-01, time/batch = 15.7596s	
12589/16650 (epoch 37.805), train_loss = 0.75701229, grad/param norm = 2.5780e-01, time/batch = 15.6874s	
12590/16650 (epoch 37.808), train_loss = 0.81942870, grad/param norm = 3.0546e-01, time/batch = 18.3686s	
12591/16650 (epoch 37.811), train_loss = 0.85327828, grad/param norm = 3.1852e-01, time/batch = 17.9466s	
12592/16650 (epoch 37.814), train_loss = 0.66645735, grad/param norm = 2.6036e-01, time/batch = 17.0089s	
12593/16650 (epoch 37.817), train_loss = 0.70634796, grad/param norm = 3.1390e-01, time/batch = 15.2397s	
12594/16650 (epoch 37.820), train_loss = 0.80190504, grad/param norm = 2.8671e-01, time/batch = 15.9119s	
12595/16650 (epoch 37.823), train_loss = 0.75184163, grad/param norm = 2.7653e-01, time/batch = 16.8084s	
12596/16650 (epoch 37.826), train_loss = 0.70543221, grad/param norm = 2.8390e-01, time/batch = 17.6836s	
12597/16650 (epoch 37.829), train_loss = 0.75811312, grad/param norm = 2.8862e-01, time/batch = 17.2710s	
12598/16650 (epoch 37.832), train_loss = 0.80317308, grad/param norm = 2.7448e-01, time/batch = 16.4083s	
12599/16650 (epoch 37.835), train_loss = 0.79834971, grad/param norm = 3.1095e-01, time/batch = 16.2611s	
12600/16650 (epoch 37.838), train_loss = 0.68678691, grad/param norm = 2.9370e-01, time/batch = 18.5245s	
12601/16650 (epoch 37.841), train_loss = 0.67568054, grad/param norm = 2.3891e-01, time/batch = 17.0938s	
12602/16650 (epoch 37.844), train_loss = 0.69440234, grad/param norm = 2.4100e-01, time/batch = 16.7517s	
12603/16650 (epoch 37.847), train_loss = 0.82415150, grad/param norm = 3.5409e-01, time/batch = 16.5065s	
12604/16650 (epoch 37.850), train_loss = 0.65953168, grad/param norm = 3.0229e-01, time/batch = 18.9598s	
12605/16650 (epoch 37.853), train_loss = 0.72609763, grad/param norm = 2.7386e-01, time/batch = 18.4354s	
12606/16650 (epoch 37.856), train_loss = 0.68657993, grad/param norm = 2.5864e-01, time/batch = 17.1630s	
12607/16650 (epoch 37.859), train_loss = 0.84683773, grad/param norm = 3.3222e-01, time/batch = 15.8337s	
12608/16650 (epoch 37.862), train_loss = 0.72549477, grad/param norm = 2.9455e-01, time/batch = 17.5084s	
12609/16650 (epoch 37.865), train_loss = 0.59676931, grad/param norm = 2.5129e-01, time/batch = 16.9251s	
12610/16650 (epoch 37.868), train_loss = 0.76086210, grad/param norm = 2.7783e-01, time/batch = 17.0928s	
12611/16650 (epoch 37.871), train_loss = 0.78916780, grad/param norm = 2.9929e-01, time/batch = 14.6532s	
12612/16650 (epoch 37.874), train_loss = 0.77879225, grad/param norm = 2.9434e-01, time/batch = 16.9190s	
12613/16650 (epoch 37.877), train_loss = 0.74001068, grad/param norm = 2.6266e-01, time/batch = 17.1529s	
12614/16650 (epoch 37.880), train_loss = 0.68387569, grad/param norm = 3.9104e-01, time/batch = 16.2826s	
12615/16650 (epoch 37.883), train_loss = 0.77957481, grad/param norm = 2.9911e-01, time/batch = 18.9371s	
12616/16650 (epoch 37.886), train_loss = 0.76369570, grad/param norm = 3.0234e-01, time/batch = 17.2693s	
12617/16650 (epoch 37.889), train_loss = 0.62952975, grad/param norm = 2.9019e-01, time/batch = 17.6678s	
12618/16650 (epoch 37.892), train_loss = 0.75280624, grad/param norm = 2.6955e-01, time/batch = 18.6095s	
12619/16650 (epoch 37.895), train_loss = 0.76080238, grad/param norm = 3.0315e-01, time/batch = 16.9183s	
12620/16650 (epoch 37.898), train_loss = 0.76609932, grad/param norm = 3.5671e-01, time/batch = 16.0626s	
12621/16650 (epoch 37.901), train_loss = 0.70483948, grad/param norm = 3.1474e-01, time/batch = 17.9386s	
12622/16650 (epoch 37.904), train_loss = 0.71590733, grad/param norm = 3.4889e-01, time/batch = 18.0971s	
12623/16650 (epoch 37.907), train_loss = 0.76441599, grad/param norm = 3.4366e-01, time/batch = 15.3969s	
12624/16650 (epoch 37.910), train_loss = 0.78804750, grad/param norm = 3.1744e-01, time/batch = 15.5684s	
12625/16650 (epoch 37.913), train_loss = 0.69824785, grad/param norm = 2.8681e-01, time/batch = 17.9353s	
12626/16650 (epoch 37.916), train_loss = 0.69236165, grad/param norm = 3.0186e-01, time/batch = 17.6076s	
12627/16650 (epoch 37.919), train_loss = 0.87676311, grad/param norm = 3.0560e-01, time/batch = 17.1835s	
12628/16650 (epoch 37.922), train_loss = 0.77741663, grad/param norm = 3.9597e-01, time/batch = 19.1162s	
12629/16650 (epoch 37.925), train_loss = 0.68572160, grad/param norm = 2.8817e-01, time/batch = 15.0088s	
12630/16650 (epoch 37.928), train_loss = 0.74826956, grad/param norm = 2.9255e-01, time/batch = 16.3400s	
12631/16650 (epoch 37.931), train_loss = 0.76617421, grad/param norm = 3.5081e-01, time/batch = 18.5226s	
12632/16650 (epoch 37.934), train_loss = 0.63413429, grad/param norm = 3.3765e-01, time/batch = 17.2876s	
12633/16650 (epoch 37.937), train_loss = 0.68256099, grad/param norm = 3.3648e-01, time/batch = 17.1858s	
12634/16650 (epoch 37.940), train_loss = 0.73594263, grad/param norm = 3.1619e-01, time/batch = 17.1797s	
12635/16650 (epoch 37.943), train_loss = 0.75541593, grad/param norm = 3.1822e-01, time/batch = 17.5160s	
12636/16650 (epoch 37.946), train_loss = 0.69634182, grad/param norm = 3.1815e-01, time/batch = 18.2587s	
12637/16650 (epoch 37.949), train_loss = 0.64422209, grad/param norm = 2.9091e-01, time/batch = 17.0916s	
12638/16650 (epoch 37.952), train_loss = 0.63269486, grad/param norm = 2.9344e-01, time/batch = 16.3144s	
12639/16650 (epoch 37.955), train_loss = 0.73150796, grad/param norm = 2.9757e-01, time/batch = 17.6721s	
12640/16650 (epoch 37.958), train_loss = 0.81137106, grad/param norm = 5.2977e-01, time/batch = 17.4066s	
12641/16650 (epoch 37.961), train_loss = 0.71603090, grad/param norm = 2.4915e-01, time/batch = 17.8591s	
12642/16650 (epoch 37.964), train_loss = 0.65109641, grad/param norm = 3.1334e-01, time/batch = 17.3675s	
12643/16650 (epoch 37.967), train_loss = 0.89081723, grad/param norm = 3.4676e-01, time/batch = 19.0272s	
12644/16650 (epoch 37.970), train_loss = 0.70582612, grad/param norm = 2.7130e-01, time/batch = 16.4170s	
12645/16650 (epoch 37.973), train_loss = 0.69493217, grad/param norm = 3.6327e-01, time/batch = 16.6775s	
12646/16650 (epoch 37.976), train_loss = 0.68996605, grad/param norm = 3.2008e-01, time/batch = 18.1929s	
12647/16650 (epoch 37.979), train_loss = 0.77147883, grad/param norm = 3.0112e-01, time/batch = 16.1604s	
12648/16650 (epoch 37.982), train_loss = 0.79074777, grad/param norm = 2.8627e-01, time/batch = 17.0718s	
12649/16650 (epoch 37.985), train_loss = 0.72270240, grad/param norm = 2.6838e-01, time/batch = 18.7703s	
12650/16650 (epoch 37.988), train_loss = 0.77845393, grad/param norm = 3.2656e-01, time/batch = 17.6892s	
12651/16650 (epoch 37.991), train_loss = 0.68502752, grad/param norm = 3.3913e-01, time/batch = 17.0759s	
12652/16650 (epoch 37.994), train_loss = 0.68345098, grad/param norm = 2.9045e-01, time/batch = 18.6082s	
12653/16650 (epoch 37.997), train_loss = 0.70107734, grad/param norm = 2.7951e-01, time/batch = 17.3610s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
12654/16650 (epoch 38.000), train_loss = 0.81036649, grad/param norm = 3.4571e-01, time/batch = 16.9148s	
12655/16650 (epoch 38.003), train_loss = 0.83925556, grad/param norm = 3.6749e-01, time/batch = 15.7437s	
12656/16650 (epoch 38.006), train_loss = 0.81859218, grad/param norm = 3.5262e-01, time/batch = 17.1475s	
12657/16650 (epoch 38.009), train_loss = 0.86792906, grad/param norm = 3.5339e-01, time/batch = 16.9265s	
12658/16650 (epoch 38.012), train_loss = 0.85076526, grad/param norm = 3.1082e-01, time/batch = 16.9146s	
12659/16650 (epoch 38.015), train_loss = 0.75932977, grad/param norm = 2.9057e-01, time/batch = 16.0530s	
12660/16650 (epoch 38.018), train_loss = 0.64570748, grad/param norm = 2.8804e-01, time/batch = 17.5292s	
12661/16650 (epoch 38.021), train_loss = 0.86644032, grad/param norm = 3.2208e-01, time/batch = 17.1746s	
12662/16650 (epoch 38.024), train_loss = 0.73650036, grad/param norm = 3.1876e-01, time/batch = 17.8643s	
12663/16650 (epoch 38.027), train_loss = 0.80196434, grad/param norm = 3.5615e-01, time/batch = 17.1914s	
12664/16650 (epoch 38.030), train_loss = 0.63603553, grad/param norm = 2.7665e-01, time/batch = 17.2561s	
12665/16650 (epoch 38.033), train_loss = 0.72553567, grad/param norm = 2.4556e-01, time/batch = 16.3296s	
12666/16650 (epoch 38.036), train_loss = 0.53850333, grad/param norm = 3.1525e-01, time/batch = 18.3759s	
12667/16650 (epoch 38.039), train_loss = 0.84955503, grad/param norm = 2.6685e-01, time/batch = 17.4447s	
12668/16650 (epoch 38.042), train_loss = 0.78393157, grad/param norm = 3.2027e-01, time/batch = 16.6578s	
12669/16650 (epoch 38.045), train_loss = 0.73586479, grad/param norm = 2.7243e-01, time/batch = 18.0169s	
12670/16650 (epoch 38.048), train_loss = 0.81211133, grad/param norm = 3.0630e-01, time/batch = 14.6963s	
12671/16650 (epoch 38.051), train_loss = 0.71830995, grad/param norm = 2.9108e-01, time/batch = 14.1494s	
12672/16650 (epoch 38.054), train_loss = 0.73503469, grad/param norm = 2.8682e-01, time/batch = 14.3750s	
12673/16650 (epoch 38.057), train_loss = 0.73337694, grad/param norm = 3.4248e-01, time/batch = 13.9460s	
12674/16650 (epoch 38.060), train_loss = 0.64049729, grad/param norm = 2.9749e-01, time/batch = 17.5884s	
12675/16650 (epoch 38.063), train_loss = 0.70760387, grad/param norm = 2.8681e-01, time/batch = 16.9162s	
12676/16650 (epoch 38.066), train_loss = 0.86298539, grad/param norm = 2.7197e-01, time/batch = 16.0520s	
12677/16650 (epoch 38.069), train_loss = 0.78483359, grad/param norm = 3.1172e-01, time/batch = 13.7914s	
12678/16650 (epoch 38.072), train_loss = 0.75783326, grad/param norm = 3.3032e-01, time/batch = 15.8827s	
12679/16650 (epoch 38.075), train_loss = 0.82268362, grad/param norm = 3.5631e-01, time/batch = 16.7886s	
12680/16650 (epoch 38.078), train_loss = 0.81711388, grad/param norm = 3.1334e-01, time/batch = 17.6930s	
12681/16650 (epoch 38.081), train_loss = 0.78043415, grad/param norm = 3.4899e-01, time/batch = 18.9542s	
12682/16650 (epoch 38.084), train_loss = 0.77892347, grad/param norm = 2.9866e-01, time/batch = 17.3612s	
12683/16650 (epoch 38.087), train_loss = 0.78031509, grad/param norm = 2.7708e-01, time/batch = 15.0173s	
12684/16650 (epoch 38.090), train_loss = 0.73249742, grad/param norm = 3.2391e-01, time/batch = 18.7105s	
12685/16650 (epoch 38.093), train_loss = 0.87717640, grad/param norm = 4.1560e-01, time/batch = 18.1997s	
12686/16650 (epoch 38.096), train_loss = 0.69953036, grad/param norm = 3.6057e-01, time/batch = 16.3462s	
12687/16650 (epoch 38.099), train_loss = 0.78344666, grad/param norm = 3.4404e-01, time/batch = 17.1915s	
12688/16650 (epoch 38.102), train_loss = 0.75381557, grad/param norm = 2.7896e-01, time/batch = 17.7750s	
12689/16650 (epoch 38.105), train_loss = 0.74783952, grad/param norm = 3.0563e-01, time/batch = 16.3575s	
12690/16650 (epoch 38.108), train_loss = 0.77310237, grad/param norm = 3.5477e-01, time/batch = 17.0745s	
12691/16650 (epoch 38.111), train_loss = 0.83827521, grad/param norm = 3.1633e-01, time/batch = 15.9222s	
12692/16650 (epoch 38.114), train_loss = 0.79967163, grad/param norm = 3.9123e-01, time/batch = 19.0350s	
12693/16650 (epoch 38.117), train_loss = 0.91212360, grad/param norm = 3.3041e-01, time/batch = 15.9957s	
12694/16650 (epoch 38.120), train_loss = 0.75875246, grad/param norm = 2.9724e-01, time/batch = 16.8568s	
12695/16650 (epoch 38.123), train_loss = 0.72368735, grad/param norm = 2.9115e-01, time/batch = 18.6884s	
12696/16650 (epoch 38.126), train_loss = 0.78306986, grad/param norm = 3.0709e-01, time/batch = 17.5264s	
12697/16650 (epoch 38.129), train_loss = 0.80312488, grad/param norm = 3.3806e-01, time/batch = 17.7602s	
12698/16650 (epoch 38.132), train_loss = 0.75066226, grad/param norm = 2.8537e-01, time/batch = 16.2579s	
12699/16650 (epoch 38.135), train_loss = 0.85522583, grad/param norm = 3.0467e-01, time/batch = 15.1533s	
12700/16650 (epoch 38.138), train_loss = 0.81438369, grad/param norm = 2.8336e-01, time/batch = 17.4205s	
12701/16650 (epoch 38.141), train_loss = 0.79384387, grad/param norm = 3.1892e-01, time/batch = 18.8587s	
12702/16650 (epoch 38.144), train_loss = 0.80170920, grad/param norm = 2.9982e-01, time/batch = 16.5953s	
12703/16650 (epoch 38.147), train_loss = 0.88928091, grad/param norm = 2.9144e-01, time/batch = 16.1397s	
12704/16650 (epoch 38.150), train_loss = 0.95985665, grad/param norm = 4.0183e-01, time/batch = 18.0804s	
12705/16650 (epoch 38.153), train_loss = 0.78172815, grad/param norm = 3.3623e-01, time/batch = 18.1173s	
12706/16650 (epoch 38.156), train_loss = 0.75736613, grad/param norm = 2.9834e-01, time/batch = 17.4263s	
12707/16650 (epoch 38.159), train_loss = 0.80976163, grad/param norm = 2.7885e-01, time/batch = 15.8101s	
12708/16650 (epoch 38.162), train_loss = 0.87905742, grad/param norm = 2.8879e-01, time/batch = 18.7760s	
12709/16650 (epoch 38.165), train_loss = 0.86678635, grad/param norm = 3.2032e-01, time/batch = 16.5239s	
12710/16650 (epoch 38.168), train_loss = 0.64131474, grad/param norm = 2.4200e-01, time/batch = 17.3398s	
12711/16650 (epoch 38.171), train_loss = 0.80930128, grad/param norm = 2.7496e-01, time/batch = 18.3472s	
12712/16650 (epoch 38.174), train_loss = 0.62564720, grad/param norm = 2.6323e-01, time/batch = 17.1146s	
12713/16650 (epoch 38.177), train_loss = 0.76310547, grad/param norm = 3.0851e-01, time/batch = 15.0727s	
12714/16650 (epoch 38.180), train_loss = 0.85230280, grad/param norm = 3.0136e-01, time/batch = 16.1622s	
12715/16650 (epoch 38.183), train_loss = 0.99569628, grad/param norm = 3.3156e-01, time/batch = 19.0411s	
12716/16650 (epoch 38.186), train_loss = 0.80174628, grad/param norm = 3.4628e-01, time/batch = 17.3701s	
12717/16650 (epoch 38.189), train_loss = 0.70106664, grad/param norm = 2.6216e-01, time/batch = 14.9109s	
12718/16650 (epoch 38.192), train_loss = 0.75889021, grad/param norm = 2.7780e-01, time/batch = 17.0008s	
12719/16650 (epoch 38.195), train_loss = 0.70306944, grad/param norm = 3.1485e-01, time/batch = 18.1886s	
12720/16650 (epoch 38.198), train_loss = 0.65897712, grad/param norm = 2.4002e-01, time/batch = 18.6051s	
12721/16650 (epoch 38.201), train_loss = 0.67183215, grad/param norm = 2.9225e-01, time/batch = 16.0906s	
12722/16650 (epoch 38.204), train_loss = 0.77736124, grad/param norm = 2.7549e-01, time/batch = 18.3374s	
12723/16650 (epoch 38.207), train_loss = 0.81077273, grad/param norm = 3.3935e-01, time/batch = 16.1582s	
12724/16650 (epoch 38.210), train_loss = 0.76101690, grad/param norm = 3.1181e-01, time/batch = 17.2506s	
12725/16650 (epoch 38.213), train_loss = 0.81400900, grad/param norm = 2.9547e-01, time/batch = 16.9488s	
12726/16650 (epoch 38.216), train_loss = 0.70225421, grad/param norm = 2.9161e-01, time/batch = 17.0159s	
12727/16650 (epoch 38.219), train_loss = 0.73272824, grad/param norm = 2.7690e-01, time/batch = 17.4541s	
12728/16650 (epoch 38.222), train_loss = 0.76967506, grad/param norm = 2.6843e-01, time/batch = 15.9966s	
12729/16650 (epoch 38.225), train_loss = 0.79571924, grad/param norm = 3.2529e-01, time/batch = 16.9514s	
12730/16650 (epoch 38.228), train_loss = 0.70692170, grad/param norm = 3.0117e-01, time/batch = 18.2037s	
12731/16650 (epoch 38.231), train_loss = 0.69420519, grad/param norm = 3.3075e-01, time/batch = 16.1486s	
12732/16650 (epoch 38.234), train_loss = 0.90999719, grad/param norm = 3.2815e-01, time/batch = 17.3215s	
12733/16650 (epoch 38.237), train_loss = 0.78240486, grad/param norm = 3.5693e-01, time/batch = 15.8790s	
12734/16650 (epoch 38.240), train_loss = 0.77646905, grad/param norm = 2.4854e-01, time/batch = 18.9499s	
12735/16650 (epoch 38.243), train_loss = 0.75004184, grad/param norm = 2.8153e-01, time/batch = 15.3335s	
12736/16650 (epoch 38.246), train_loss = 0.87455293, grad/param norm = 3.4189e-01, time/batch = 18.1845s	
12737/16650 (epoch 38.249), train_loss = 0.64221453, grad/param norm = 2.5015e-01, time/batch = 15.0588s	
12738/16650 (epoch 38.252), train_loss = 0.75753242, grad/param norm = 3.1095e-01, time/batch = 17.3237s	
12739/16650 (epoch 38.255), train_loss = 0.79732887, grad/param norm = 2.6979e-01, time/batch = 16.5019s	
12740/16650 (epoch 38.258), train_loss = 0.82571159, grad/param norm = 2.7341e-01, time/batch = 18.3757s	
12741/16650 (epoch 38.261), train_loss = 0.80802727, grad/param norm = 3.1366e-01, time/batch = 18.2819s	
12742/16650 (epoch 38.264), train_loss = 0.70032594, grad/param norm = 2.6380e-01, time/batch = 16.8367s	
12743/16650 (epoch 38.267), train_loss = 0.73842607, grad/param norm = 3.0328e-01, time/batch = 16.7809s	
12744/16650 (epoch 38.270), train_loss = 0.80828289, grad/param norm = 3.2690e-01, time/batch = 16.2686s	
12745/16650 (epoch 38.273), train_loss = 0.83448622, grad/param norm = 3.2507e-01, time/batch = 17.2542s	
12746/16650 (epoch 38.276), train_loss = 0.81123808, grad/param norm = 3.0070e-01, time/batch = 16.2652s	
12747/16650 (epoch 38.279), train_loss = 0.75200309, grad/param norm = 2.7289e-01, time/batch = 17.6091s	
12748/16650 (epoch 38.282), train_loss = 0.71001006, grad/param norm = 2.7192e-01, time/batch = 17.2688s	
12749/16650 (epoch 38.285), train_loss = 0.73914377, grad/param norm = 3.0312e-01, time/batch = 15.3641s	
12750/16650 (epoch 38.288), train_loss = 0.68529101, grad/param norm = 2.9711e-01, time/batch = 17.8458s	
12751/16650 (epoch 38.291), train_loss = 0.57297788, grad/param norm = 2.5109e-01, time/batch = 15.3532s	
12752/16650 (epoch 38.294), train_loss = 0.68693104, grad/param norm = 2.9275e-01, time/batch = 17.0227s	
12753/16650 (epoch 38.297), train_loss = 0.75173703, grad/param norm = 2.8619e-01, time/batch = 17.7599s	
12754/16650 (epoch 38.300), train_loss = 0.59697300, grad/param norm = 2.4648e-01, time/batch = 18.1234s	
12755/16650 (epoch 38.303), train_loss = 0.64611860, grad/param norm = 2.6855e-01, time/batch = 18.5414s	
12756/16650 (epoch 38.306), train_loss = 0.82185905, grad/param norm = 2.9436e-01, time/batch = 15.2977s	
12757/16650 (epoch 38.309), train_loss = 0.81714402, grad/param norm = 2.9036e-01, time/batch = 17.6806s	
12758/16650 (epoch 38.312), train_loss = 0.62783656, grad/param norm = 2.6883e-01, time/batch = 18.8477s	
12759/16650 (epoch 38.315), train_loss = 0.54677952, grad/param norm = 2.5474e-01, time/batch = 17.1741s	
12760/16650 (epoch 38.318), train_loss = 0.62600737, grad/param norm = 2.6312e-01, time/batch = 18.6910s	
12761/16650 (epoch 38.321), train_loss = 0.83903390, grad/param norm = 3.3717e-01, time/batch = 18.4584s	
12762/16650 (epoch 38.324), train_loss = 0.69519907, grad/param norm = 3.3973e-01, time/batch = 17.2617s	
12763/16650 (epoch 38.327), train_loss = 0.77939844, grad/param norm = 3.7145e-01, time/batch = 31.1228s	
12764/16650 (epoch 38.330), train_loss = 0.77807326, grad/param norm = 5.5494e-01, time/batch = 16.7695s	
12765/16650 (epoch 38.333), train_loss = 0.84356758, grad/param norm = 3.5360e-01, time/batch = 17.0941s	
12766/16650 (epoch 38.336), train_loss = 0.67515429, grad/param norm = 3.0896e-01, time/batch = 16.0753s	
12767/16650 (epoch 38.339), train_loss = 0.68680141, grad/param norm = 3.2997e-01, time/batch = 19.0368s	
12768/16650 (epoch 38.342), train_loss = 0.64075247, grad/param norm = 2.9154e-01, time/batch = 18.7774s	
12769/16650 (epoch 38.345), train_loss = 0.66328498, grad/param norm = 2.5745e-01, time/batch = 16.2417s	
12770/16650 (epoch 38.348), train_loss = 0.77784213, grad/param norm = 3.5058e-01, time/batch = 17.0197s	
12771/16650 (epoch 38.351), train_loss = 0.76997256, grad/param norm = 3.0371e-01, time/batch = 17.2566s	
12772/16650 (epoch 38.354), train_loss = 0.81360904, grad/param norm = 3.0697e-01, time/batch = 15.3921s	
12773/16650 (epoch 38.357), train_loss = 0.76038987, grad/param norm = 2.7537e-01, time/batch = 16.3236s	
12774/16650 (epoch 38.360), train_loss = 0.76325146, grad/param norm = 3.3926e-01, time/batch = 18.4436s	
12775/16650 (epoch 38.363), train_loss = 0.83649800, grad/param norm = 3.7542e-01, time/batch = 15.1366s	
12776/16650 (epoch 38.366), train_loss = 0.88157532, grad/param norm = 3.0532e-01, time/batch = 15.9190s	
12777/16650 (epoch 38.369), train_loss = 0.80658674, grad/param norm = 3.1450e-01, time/batch = 16.8456s	
12778/16650 (epoch 38.372), train_loss = 0.76651564, grad/param norm = 3.1312e-01, time/batch = 18.3592s	
12779/16650 (epoch 38.375), train_loss = 0.75879322, grad/param norm = 2.6316e-01, time/batch = 16.1723s	
12780/16650 (epoch 38.378), train_loss = 0.72596156, grad/param norm = 3.3842e-01, time/batch = 15.4377s	
12781/16650 (epoch 38.381), train_loss = 0.80797003, grad/param norm = 3.8580e-01, time/batch = 18.2077s	
12782/16650 (epoch 38.384), train_loss = 0.89216419, grad/param norm = 3.0172e-01, time/batch = 18.4582s	
12783/16650 (epoch 38.387), train_loss = 0.59720166, grad/param norm = 2.6377e-01, time/batch = 16.7544s	
12784/16650 (epoch 38.390), train_loss = 0.82792601, grad/param norm = 2.9808e-01, time/batch = 18.0244s	
12785/16650 (epoch 38.393), train_loss = 0.71245572, grad/param norm = 3.0147e-01, time/batch = 16.2524s	
12786/16650 (epoch 38.396), train_loss = 0.86434675, grad/param norm = 3.1283e-01, time/batch = 16.9232s	
12787/16650 (epoch 38.399), train_loss = 0.82286163, grad/param norm = 3.1328e-01, time/batch = 14.9798s	
12788/16650 (epoch 38.402), train_loss = 0.73272344, grad/param norm = 3.0966e-01, time/batch = 17.0867s	
12789/16650 (epoch 38.405), train_loss = 0.61389278, grad/param norm = 3.1773e-01, time/batch = 17.9342s	
12790/16650 (epoch 38.408), train_loss = 0.77894124, grad/param norm = 2.9551e-01, time/batch = 15.9273s	
12791/16650 (epoch 38.411), train_loss = 0.69677430, grad/param norm = 3.4118e-01, time/batch = 17.6197s	
12792/16650 (epoch 38.414), train_loss = 0.68314871, grad/param norm = 3.8286e-01, time/batch = 17.4470s	
12793/16650 (epoch 38.417), train_loss = 0.65535357, grad/param norm = 2.7981e-01, time/batch = 17.3428s	
12794/16650 (epoch 38.420), train_loss = 0.68731783, grad/param norm = 3.2749e-01, time/batch = 17.1881s	
12795/16650 (epoch 38.423), train_loss = 0.55684507, grad/param norm = 2.5756e-01, time/batch = 18.1071s	
12796/16650 (epoch 38.426), train_loss = 0.65988684, grad/param norm = 3.0980e-01, time/batch = 17.7850s	
12797/16650 (epoch 38.429), train_loss = 0.82233017, grad/param norm = 3.2316e-01, time/batch = 16.0709s	
12798/16650 (epoch 38.432), train_loss = 0.83329608, grad/param norm = 3.3135e-01, time/batch = 16.7748s	
12799/16650 (epoch 38.435), train_loss = 0.94544138, grad/param norm = 3.6180e-01, time/batch = 15.6469s	
12800/16650 (epoch 38.438), train_loss = 0.89041714, grad/param norm = 3.3307e-01, time/batch = 14.9993s	
12801/16650 (epoch 38.441), train_loss = 0.71496269, grad/param norm = 3.2395e-01, time/batch = 16.1767s	
12802/16650 (epoch 38.444), train_loss = 0.71748045, grad/param norm = 3.1599e-01, time/batch = 17.9517s	
12803/16650 (epoch 38.447), train_loss = 0.69252633, grad/param norm = 2.9168e-01, time/batch = 16.1887s	
12804/16650 (epoch 38.450), train_loss = 0.70629855, grad/param norm = 3.0565e-01, time/batch = 16.2679s	
12805/16650 (epoch 38.453), train_loss = 0.68668161, grad/param norm = 2.6230e-01, time/batch = 17.1920s	
12806/16650 (epoch 38.456), train_loss = 0.65762311, grad/param norm = 2.4389e-01, time/batch = 17.5673s	
12807/16650 (epoch 38.459), train_loss = 0.69401930, grad/param norm = 3.3578e-01, time/batch = 18.3641s	
12808/16650 (epoch 38.462), train_loss = 0.84503130, grad/param norm = 3.6140e-01, time/batch = 16.9139s	
12809/16650 (epoch 38.465), train_loss = 0.69940041, grad/param norm = 2.9491e-01, time/batch = 18.0213s	
12810/16650 (epoch 38.468), train_loss = 0.57266007, grad/param norm = 2.8433e-01, time/batch = 18.2893s	
12811/16650 (epoch 38.471), train_loss = 0.49725684, grad/param norm = 2.4939e-01, time/batch = 16.6845s	
12812/16650 (epoch 38.474), train_loss = 0.63526339, grad/param norm = 2.7796e-01, time/batch = 17.5163s	
12813/16650 (epoch 38.477), train_loss = 0.79836678, grad/param norm = 3.1756e-01, time/batch = 14.9228s	
12814/16650 (epoch 38.480), train_loss = 0.72251632, grad/param norm = 3.1664e-01, time/batch = 17.1039s	
12815/16650 (epoch 38.483), train_loss = 0.81726362, grad/param norm = 3.3113e-01, time/batch = 17.6565s	
12816/16650 (epoch 38.486), train_loss = 0.64762783, grad/param norm = 2.5692e-01, time/batch = 18.1928s	
12817/16650 (epoch 38.489), train_loss = 0.71938638, grad/param norm = 3.1219e-01, time/batch = 18.2073s	
12818/16650 (epoch 38.492), train_loss = 0.72438859, grad/param norm = 2.6341e-01, time/batch = 16.2069s	
12819/16650 (epoch 38.495), train_loss = 0.63159130, grad/param norm = 3.0040e-01, time/batch = 16.7738s	
12820/16650 (epoch 38.498), train_loss = 0.69751093, grad/param norm = 3.5528e-01, time/batch = 18.2805s	
12821/16650 (epoch 38.502), train_loss = 0.89037908, grad/param norm = 4.0803e-01, time/batch = 16.7618s	
12822/16650 (epoch 38.505), train_loss = 0.78273928, grad/param norm = 3.1860e-01, time/batch = 17.0270s	
12823/16650 (epoch 38.508), train_loss = 0.80371481, grad/param norm = 4.1766e-01, time/batch = 17.9485s	
12824/16650 (epoch 38.511), train_loss = 0.79725026, grad/param norm = 2.8892e-01, time/batch = 17.4455s	
12825/16650 (epoch 38.514), train_loss = 0.64379804, grad/param norm = 2.7347e-01, time/batch = 15.5795s	
12826/16650 (epoch 38.517), train_loss = 0.71656472, grad/param norm = 3.0836e-01, time/batch = 16.5128s	
12827/16650 (epoch 38.520), train_loss = 0.62774529, grad/param norm = 2.7771e-01, time/batch = 17.9342s	
12828/16650 (epoch 38.523), train_loss = 0.71831228, grad/param norm = 2.5862e-01, time/batch = 16.4157s	
12829/16650 (epoch 38.526), train_loss = 0.79551167, grad/param norm = 3.0876e-01, time/batch = 17.3706s	
12830/16650 (epoch 38.529), train_loss = 0.84469193, grad/param norm = 3.4159e-01, time/batch = 17.8679s	
12831/16650 (epoch 38.532), train_loss = 0.56324763, grad/param norm = 2.9692e-01, time/batch = 15.8978s	
12832/16650 (epoch 38.535), train_loss = 0.64916022, grad/param norm = 3.5510e-01, time/batch = 14.8319s	
12833/16650 (epoch 38.538), train_loss = 0.58959124, grad/param norm = 3.1644e-01, time/batch = 16.8505s	
12834/16650 (epoch 38.541), train_loss = 0.85738529, grad/param norm = 3.6109e-01, time/batch = 15.9810s	
12835/16650 (epoch 38.544), train_loss = 0.89363808, grad/param norm = 4.8820e-01, time/batch = 18.2832s	
12836/16650 (epoch 38.547), train_loss = 0.64610594, grad/param norm = 2.9550e-01, time/batch = 17.1858s	
12837/16650 (epoch 38.550), train_loss = 0.72460326, grad/param norm = 2.8284e-01, time/batch = 16.7674s	
12838/16650 (epoch 38.553), train_loss = 0.73336876, grad/param norm = 3.1912e-01, time/batch = 18.6209s	
12839/16650 (epoch 38.556), train_loss = 0.65675183, grad/param norm = 2.9740e-01, time/batch = 16.0879s	
12840/16650 (epoch 38.559), train_loss = 0.59027081, grad/param norm = 3.3334e-01, time/batch = 18.0997s	
12841/16650 (epoch 38.562), train_loss = 0.66682351, grad/param norm = 2.8629e-01, time/batch = 17.1359s	
12842/16650 (epoch 38.565), train_loss = 0.57354815, grad/param norm = 2.8105e-01, time/batch = 14.9156s	
12843/16650 (epoch 38.568), train_loss = 0.58949936, grad/param norm = 2.5083e-01, time/batch = 16.4292s	
12844/16650 (epoch 38.571), train_loss = 0.66627423, grad/param norm = 4.2252e-01, time/batch = 16.7616s	
12845/16650 (epoch 38.574), train_loss = 0.65807847, grad/param norm = 3.3962e-01, time/batch = 18.1027s	
12846/16650 (epoch 38.577), train_loss = 0.68903736, grad/param norm = 2.8351e-01, time/batch = 15.9317s	
12847/16650 (epoch 38.580), train_loss = 0.63943341, grad/param norm = 2.6092e-01, time/batch = 17.9453s	
12848/16650 (epoch 38.583), train_loss = 0.74636920, grad/param norm = 3.0777e-01, time/batch = 18.5260s	
12849/16650 (epoch 38.586), train_loss = 0.63808097, grad/param norm = 3.3750e-01, time/batch = 17.7623s	
12850/16650 (epoch 38.589), train_loss = 0.64333757, grad/param norm = 2.8981e-01, time/batch = 16.2673s	
12851/16650 (epoch 38.592), train_loss = 0.72046996, grad/param norm = 2.9629e-01, time/batch = 17.5212s	
12852/16650 (epoch 38.595), train_loss = 0.67089618, grad/param norm = 3.2956e-01, time/batch = 18.6020s	
12853/16650 (epoch 38.598), train_loss = 0.69017134, grad/param norm = 3.0471e-01, time/batch = 15.5605s	
12854/16650 (epoch 38.601), train_loss = 0.67152971, grad/param norm = 3.1473e-01, time/batch = 17.9372s	
12855/16650 (epoch 38.604), train_loss = 0.72784664, grad/param norm = 2.9033e-01, time/batch = 15.9455s	
12856/16650 (epoch 38.607), train_loss = 0.77984349, grad/param norm = 3.0140e-01, time/batch = 16.8548s	
12857/16650 (epoch 38.610), train_loss = 0.64882505, grad/param norm = 2.8927e-01, time/batch = 17.9346s	
12858/16650 (epoch 38.613), train_loss = 0.82447385, grad/param norm = 3.2169e-01, time/batch = 18.5294s	
12859/16650 (epoch 38.616), train_loss = 0.79047742, grad/param norm = 3.9558e-01, time/batch = 17.3646s	
12860/16650 (epoch 38.619), train_loss = 0.60371366, grad/param norm = 2.5007e-01, time/batch = 15.8478s	
12861/16650 (epoch 38.622), train_loss = 0.58631818, grad/param norm = 2.6210e-01, time/batch = 18.5295s	
12862/16650 (epoch 38.625), train_loss = 0.69462257, grad/param norm = 2.6385e-01, time/batch = 15.7013s	
12863/16650 (epoch 38.628), train_loss = 0.69147232, grad/param norm = 3.5248e-01, time/batch = 13.7121s	
12864/16650 (epoch 38.631), train_loss = 0.75274085, grad/param norm = 3.8052e-01, time/batch = 13.9324s	
12865/16650 (epoch 38.634), train_loss = 0.88009158, grad/param norm = 3.3554e-01, time/batch = 15.4475s	
12866/16650 (epoch 38.637), train_loss = 0.87835337, grad/param norm = 3.3473e-01, time/batch = 17.5271s	
12867/16650 (epoch 38.640), train_loss = 0.70393900, grad/param norm = 3.2993e-01, time/batch = 15.2419s	
12868/16650 (epoch 38.643), train_loss = 0.77782392, grad/param norm = 2.6717e-01, time/batch = 15.7639s	
12869/16650 (epoch 38.646), train_loss = 0.77125636, grad/param norm = 3.4068e-01, time/batch = 16.9361s	
12870/16650 (epoch 38.649), train_loss = 0.76619016, grad/param norm = 3.5485e-01, time/batch = 18.0304s	
12871/16650 (epoch 38.652), train_loss = 0.77129215, grad/param norm = 2.9901e-01, time/batch = 17.1691s	
12872/16650 (epoch 38.655), train_loss = 0.74411069, grad/param norm = 3.3947e-01, time/batch = 17.8476s	
12873/16650 (epoch 38.658), train_loss = 0.67441745, grad/param norm = 3.1276e-01, time/batch = 18.9552s	
12874/16650 (epoch 38.661), train_loss = 0.75126119, grad/param norm = 3.4021e-01, time/batch = 16.5203s	
12875/16650 (epoch 38.664), train_loss = 0.71124159, grad/param norm = 3.2382e-01, time/batch = 16.3483s	
12876/16650 (epoch 38.667), train_loss = 0.82378639, grad/param norm = 3.0833e-01, time/batch = 16.3040s	
12877/16650 (epoch 38.670), train_loss = 0.62057838, grad/param norm = 2.9516e-01, time/batch = 18.6102s	
12878/16650 (epoch 38.673), train_loss = 0.62997658, grad/param norm = 2.5192e-01, time/batch = 16.1771s	
12879/16650 (epoch 38.676), train_loss = 0.78782844, grad/param norm = 3.2763e-01, time/batch = 18.1626s	
12880/16650 (epoch 38.679), train_loss = 0.66447982, grad/param norm = 2.9862e-01, time/batch = 17.6058s	
12881/16650 (epoch 38.682), train_loss = 0.71549459, grad/param norm = 2.9156e-01, time/batch = 16.4072s	
12882/16650 (epoch 38.685), train_loss = 0.61702698, grad/param norm = 2.9195e-01, time/batch = 15.7583s	
12883/16650 (epoch 38.688), train_loss = 0.77200415, grad/param norm = 2.9290e-01, time/batch = 17.8527s	
12884/16650 (epoch 38.691), train_loss = 0.75800818, grad/param norm = 3.1933e-01, time/batch = 16.5161s	
12885/16650 (epoch 38.694), train_loss = 0.66489374, grad/param norm = 2.8952e-01, time/batch = 15.8884s	
12886/16650 (epoch 38.697), train_loss = 0.61117975, grad/param norm = 2.5966e-01, time/batch = 15.3064s	
12887/16650 (epoch 38.700), train_loss = 0.74925918, grad/param norm = 3.1373e-01, time/batch = 18.9468s	
12888/16650 (epoch 38.703), train_loss = 0.65409230, grad/param norm = 3.6544e-01, time/batch = 17.5161s	
12889/16650 (epoch 38.706), train_loss = 0.72609747, grad/param norm = 3.8949e-01, time/batch = 16.9368s	
12890/16650 (epoch 38.709), train_loss = 0.61240207, grad/param norm = 2.6860e-01, time/batch = 17.7750s	
12891/16650 (epoch 38.712), train_loss = 0.65395738, grad/param norm = 3.0460e-01, time/batch = 16.6832s	
12892/16650 (epoch 38.715), train_loss = 0.75971700, grad/param norm = 3.5695e-01, time/batch = 16.7608s	
12893/16650 (epoch 38.718), train_loss = 0.79685763, grad/param norm = 3.7558e-01, time/batch = 17.9562s	
12894/16650 (epoch 38.721), train_loss = 0.80715937, grad/param norm = 2.8170e-01, time/batch = 18.0059s	
12895/16650 (epoch 38.724), train_loss = 0.78286355, grad/param norm = 3.3027e-01, time/batch = 14.3206s	
12896/16650 (epoch 38.727), train_loss = 0.79819540, grad/param norm = 3.2900e-01, time/batch = 17.2875s	
12897/16650 (epoch 38.730), train_loss = 0.66270863, grad/param norm = 2.8689e-01, time/batch = 17.7730s	
12898/16650 (epoch 38.733), train_loss = 0.82800095, grad/param norm = 3.3411e-01, time/batch = 17.9423s	
12899/16650 (epoch 38.736), train_loss = 0.61976703, grad/param norm = 3.0505e-01, time/batch = 16.6774s	
12900/16650 (epoch 38.739), train_loss = 0.74125399, grad/param norm = 3.0060e-01, time/batch = 18.3655s	
12901/16650 (epoch 38.742), train_loss = 0.72844717, grad/param norm = 2.6707e-01, time/batch = 18.1076s	
12902/16650 (epoch 38.745), train_loss = 0.57308968, grad/param norm = 3.0005e-01, time/batch = 15.8267s	
12903/16650 (epoch 38.748), train_loss = 0.59859369, grad/param norm = 2.6228e-01, time/batch = 15.5768s	
12904/16650 (epoch 38.751), train_loss = 0.73815313, grad/param norm = 4.9478e-01, time/batch = 17.1872s	
12905/16650 (epoch 38.754), train_loss = 0.89998733, grad/param norm = 4.6045e-01, time/batch = 17.7044s	
12906/16650 (epoch 38.757), train_loss = 0.87199017, grad/param norm = 3.2912e-01, time/batch = 17.1684s	
12907/16650 (epoch 38.760), train_loss = 0.72289911, grad/param norm = 3.0032e-01, time/batch = 19.1204s	
12908/16650 (epoch 38.763), train_loss = 0.68916311, grad/param norm = 2.7710e-01, time/batch = 17.5361s	
12909/16650 (epoch 38.766), train_loss = 0.69390981, grad/param norm = 2.5618e-01, time/batch = 16.6711s	
12910/16650 (epoch 38.769), train_loss = 0.75716708, grad/param norm = 3.1044e-01, time/batch = 18.0203s	
12911/16650 (epoch 38.772), train_loss = 0.74184792, grad/param norm = 2.7807e-01, time/batch = 16.3942s	
12912/16650 (epoch 38.775), train_loss = 0.70956622, grad/param norm = 3.1592e-01, time/batch = 18.1856s	
12913/16650 (epoch 38.778), train_loss = 0.74542268, grad/param norm = 2.7803e-01, time/batch = 16.5000s	
12914/16650 (epoch 38.781), train_loss = 0.86839476, grad/param norm = 2.9860e-01, time/batch = 18.2081s	
12915/16650 (epoch 38.784), train_loss = 0.74957782, grad/param norm = 3.1119e-01, time/batch = 16.3262s	
12916/16650 (epoch 38.787), train_loss = 0.78735301, grad/param norm = 3.0823e-01, time/batch = 15.5448s	
12917/16650 (epoch 38.790), train_loss = 0.81518296, grad/param norm = 2.9156e-01, time/batch = 18.0212s	
12918/16650 (epoch 38.793), train_loss = 0.63210719, grad/param norm = 3.7739e-01, time/batch = 17.9543s	
12919/16650 (epoch 38.796), train_loss = 0.95584683, grad/param norm = 3.2424e-01, time/batch = 18.1217s	
12920/16650 (epoch 38.799), train_loss = 0.87558243, grad/param norm = 3.3594e-01, time/batch = 17.6979s	
12921/16650 (epoch 38.802), train_loss = 0.80102347, grad/param norm = 2.9115e-01, time/batch = 16.1068s	
12922/16650 (epoch 38.805), train_loss = 0.75644164, grad/param norm = 2.9424e-01, time/batch = 18.7783s	
12923/16650 (epoch 38.808), train_loss = 0.81176949, grad/param norm = 2.8588e-01, time/batch = 15.7652s	
12924/16650 (epoch 38.811), train_loss = 0.83960722, grad/param norm = 2.9067e-01, time/batch = 17.2570s	
12925/16650 (epoch 38.814), train_loss = 0.65687549, grad/param norm = 2.7652e-01, time/batch = 17.8731s	
12926/16650 (epoch 38.817), train_loss = 0.68421106, grad/param norm = 3.3326e-01, time/batch = 17.1686s	
12927/16650 (epoch 38.820), train_loss = 0.81446228, grad/param norm = 3.3801e-01, time/batch = 17.8522s	
12928/16650 (epoch 38.823), train_loss = 0.76142976, grad/param norm = 3.1207e-01, time/batch = 14.8181s	
12929/16650 (epoch 38.826), train_loss = 0.68497670, grad/param norm = 2.5052e-01, time/batch = 18.3721s	
12930/16650 (epoch 38.829), train_loss = 0.75095108, grad/param norm = 3.3611e-01, time/batch = 15.2347s	
12931/16650 (epoch 38.832), train_loss = 0.79085222, grad/param norm = 2.8483e-01, time/batch = 17.9137s	
12932/16650 (epoch 38.835), train_loss = 0.78792356, grad/param norm = 3.3637e-01, time/batch = 17.9350s	
12933/16650 (epoch 38.838), train_loss = 0.64483902, grad/param norm = 2.6815e-01, time/batch = 17.0033s	
12934/16650 (epoch 38.841), train_loss = 0.67601841, grad/param norm = 2.9369e-01, time/batch = 17.6852s	
12935/16650 (epoch 38.844), train_loss = 0.69685613, grad/param norm = 2.7036e-01, time/batch = 18.0494s	
12936/16650 (epoch 38.847), train_loss = 0.81055663, grad/param norm = 3.8932e-01, time/batch = 18.3651s	
12937/16650 (epoch 38.850), train_loss = 0.68625091, grad/param norm = 3.4694e-01, time/batch = 16.2439s	
12938/16650 (epoch 38.853), train_loss = 0.71860022, grad/param norm = 3.1143e-01, time/batch = 17.5162s	
12939/16650 (epoch 38.856), train_loss = 0.67697079, grad/param norm = 2.5626e-01, time/batch = 16.3427s	
12940/16650 (epoch 38.859), train_loss = 0.83456539, grad/param norm = 3.7269e-01, time/batch = 17.5201s	
12941/16650 (epoch 38.862), train_loss = 0.73007719, grad/param norm = 2.7379e-01, time/batch = 15.9148s	
12942/16650 (epoch 38.865), train_loss = 0.58533353, grad/param norm = 2.8318e-01, time/batch = 18.1017s	
12943/16650 (epoch 38.868), train_loss = 0.76181627, grad/param norm = 3.4150e-01, time/batch = 17.5192s	
12944/16650 (epoch 38.871), train_loss = 0.76504425, grad/param norm = 2.8182e-01, time/batch = 17.2594s	
12945/16650 (epoch 38.874), train_loss = 0.75181711, grad/param norm = 2.7589e-01, time/batch = 16.1750s	
12946/16650 (epoch 38.877), train_loss = 0.72733604, grad/param norm = 2.8523e-01, time/batch = 17.5045s	
12947/16650 (epoch 38.880), train_loss = 0.66856692, grad/param norm = 2.7073e-01, time/batch = 17.1024s	
12948/16650 (epoch 38.883), train_loss = 0.76004302, grad/param norm = 3.1286e-01, time/batch = 16.9340s	
12949/16650 (epoch 38.886), train_loss = 0.73703743, grad/param norm = 3.1278e-01, time/batch = 17.7730s	
12950/16650 (epoch 38.889), train_loss = 0.62551315, grad/param norm = 2.9518e-01, time/batch = 17.8601s	
12951/16650 (epoch 38.892), train_loss = 0.74555979, grad/param norm = 2.8627e-01, time/batch = 17.1737s	
12952/16650 (epoch 38.895), train_loss = 0.76045390, grad/param norm = 3.0113e-01, time/batch = 18.0247s	
12953/16650 (epoch 38.898), train_loss = 0.73698793, grad/param norm = 3.5952e-01, time/batch = 15.0730s	
12954/16650 (epoch 38.901), train_loss = 0.66413468, grad/param norm = 2.6553e-01, time/batch = 16.6740s	
12955/16650 (epoch 38.904), train_loss = 0.68912118, grad/param norm = 2.9082e-01, time/batch = 15.1471s	
12956/16650 (epoch 38.907), train_loss = 0.75759304, grad/param norm = 3.7657e-01, time/batch = 17.5210s	
12957/16650 (epoch 38.910), train_loss = 0.77584213, grad/param norm = 3.3706e-01, time/batch = 18.6070s	
12958/16650 (epoch 38.913), train_loss = 0.70053247, grad/param norm = 3.1809e-01, time/batch = 17.0130s	
12959/16650 (epoch 38.916), train_loss = 0.67472884, grad/param norm = 2.8877e-01, time/batch = 16.6056s	
12960/16650 (epoch 38.919), train_loss = 0.87048369, grad/param norm = 3.4820e-01, time/batch = 17.8398s	
12961/16650 (epoch 38.922), train_loss = 0.77769794, grad/param norm = 3.9054e-01, time/batch = 16.5874s	
12962/16650 (epoch 38.925), train_loss = 0.68885571, grad/param norm = 2.8467e-01, time/batch = 17.0285s	
12963/16650 (epoch 38.928), train_loss = 0.72446806, grad/param norm = 2.7433e-01, time/batch = 17.2106s	
12964/16650 (epoch 38.931), train_loss = 0.75909133, grad/param norm = 3.6937e-01, time/batch = 17.1169s	
12965/16650 (epoch 38.934), train_loss = 0.61230306, grad/param norm = 3.3021e-01, time/batch = 15.9364s	
12966/16650 (epoch 38.937), train_loss = 0.64936395, grad/param norm = 2.9964e-01, time/batch = 17.9554s	
12967/16650 (epoch 38.940), train_loss = 0.72828091, grad/param norm = 3.1935e-01, time/batch = 16.8699s	
12968/16650 (epoch 38.943), train_loss = 0.76245642, grad/param norm = 3.7674e-01, time/batch = 16.1877s	
12969/16650 (epoch 38.946), train_loss = 0.68728581, grad/param norm = 3.1027e-01, time/batch = 17.3661s	
12970/16650 (epoch 38.949), train_loss = 0.62725640, grad/param norm = 2.8030e-01, time/batch = 17.9633s	
12971/16650 (epoch 38.952), train_loss = 0.61091262, grad/param norm = 2.5087e-01, time/batch = 16.2934s	
12972/16650 (epoch 38.955), train_loss = 0.72575831, grad/param norm = 3.1403e-01, time/batch = 28.6883s	
12973/16650 (epoch 38.958), train_loss = 0.80759083, grad/param norm = 4.8166e-01, time/batch = 16.5931s	
12974/16650 (epoch 38.961), train_loss = 0.69613166, grad/param norm = 2.5583e-01, time/batch = 17.5115s	
12975/16650 (epoch 38.964), train_loss = 0.64797151, grad/param norm = 3.3365e-01, time/batch = 15.7470s	
12976/16650 (epoch 38.967), train_loss = 0.86013298, grad/param norm = 3.4074e-01, time/batch = 15.8326s	
12977/16650 (epoch 38.970), train_loss = 0.68092764, grad/param norm = 2.6766e-01, time/batch = 17.5091s	
12978/16650 (epoch 38.973), train_loss = 0.69306495, grad/param norm = 3.0497e-01, time/batch = 16.4525s	
12979/16650 (epoch 38.976), train_loss = 0.65518813, grad/param norm = 2.6852e-01, time/batch = 16.1884s	
12980/16650 (epoch 38.979), train_loss = 0.75758016, grad/param norm = 2.8698e-01, time/batch = 17.7898s	
12981/16650 (epoch 38.982), train_loss = 0.78016986, grad/param norm = 2.8767e-01, time/batch = 17.7144s	
12982/16650 (epoch 38.985), train_loss = 0.72154191, grad/param norm = 2.5448e-01, time/batch = 16.3460s	
12983/16650 (epoch 38.988), train_loss = 0.75889234, grad/param norm = 2.9916e-01, time/batch = 15.5809s	
12984/16650 (epoch 38.991), train_loss = 0.66112241, grad/param norm = 3.1737e-01, time/batch = 16.5308s	
12985/16650 (epoch 38.994), train_loss = 0.68638374, grad/param norm = 2.7041e-01, time/batch = 13.8040s	
12986/16650 (epoch 38.997), train_loss = 0.69027789, grad/param norm = 3.1066e-01, time/batch = 16.8461s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
12987/16650 (epoch 39.000), train_loss = 0.78167533, grad/param norm = 2.7295e-01, time/batch = 17.4716s	
12988/16650 (epoch 39.003), train_loss = 0.83942808, grad/param norm = 3.4851e-01, time/batch = 17.6986s	
12989/16650 (epoch 39.006), train_loss = 0.82129346, grad/param norm = 3.9322e-01, time/batch = 16.1832s	
12990/16650 (epoch 39.009), train_loss = 0.85029915, grad/param norm = 3.4399e-01, time/batch = 16.4335s	
12991/16650 (epoch 39.012), train_loss = 0.82901817, grad/param norm = 3.0487e-01, time/batch = 17.3561s	
12992/16650 (epoch 39.015), train_loss = 0.73346557, grad/param norm = 2.9505e-01, time/batch = 16.9323s	
12993/16650 (epoch 39.018), train_loss = 0.64436277, grad/param norm = 2.8296e-01, time/batch = 16.4968s	
12994/16650 (epoch 39.021), train_loss = 0.86468088, grad/param norm = 3.5431e-01, time/batch = 17.6283s	
12995/16650 (epoch 39.024), train_loss = 0.71649897, grad/param norm = 3.1788e-01, time/batch = 17.9679s	
12996/16650 (epoch 39.027), train_loss = 0.78502062, grad/param norm = 3.2248e-01, time/batch = 15.9393s	
12997/16650 (epoch 39.030), train_loss = 0.62720414, grad/param norm = 2.7225e-01, time/batch = 17.4516s	
12998/16650 (epoch 39.033), train_loss = 0.71197551, grad/param norm = 2.5558e-01, time/batch = 18.2015s	
12999/16650 (epoch 39.036), train_loss = 0.52787362, grad/param norm = 3.2369e-01, time/batch = 17.1881s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch39.04_2.2454.t7	
13000/16650 (epoch 39.039), train_loss = 0.83469021, grad/param norm = 2.7829e-01, time/batch = 17.4483s	
13001/16650 (epoch 39.042), train_loss = 1.31656543, grad/param norm = 4.5175e-01, time/batch = 17.8658s	
13002/16650 (epoch 39.045), train_loss = 0.72166706, grad/param norm = 2.9275e-01, time/batch = 17.0147s	
13003/16650 (epoch 39.048), train_loss = 0.80701694, grad/param norm = 3.1529e-01, time/batch = 16.4451s	
13004/16650 (epoch 39.051), train_loss = 0.70211743, grad/param norm = 2.6781e-01, time/batch = 15.2295s	
13005/16650 (epoch 39.054), train_loss = 0.71980921, grad/param norm = 2.8240e-01, time/batch = 16.5019s	
13006/16650 (epoch 39.057), train_loss = 0.72765626, grad/param norm = 3.4305e-01, time/batch = 16.7558s	
13007/16650 (epoch 39.060), train_loss = 0.61949893, grad/param norm = 2.6296e-01, time/batch = 17.6679s	
13008/16650 (epoch 39.063), train_loss = 0.70043011, grad/param norm = 3.2426e-01, time/batch = 18.1304s	
13009/16650 (epoch 39.066), train_loss = 0.87148105, grad/param norm = 2.9965e-01, time/batch = 17.0154s	
13010/16650 (epoch 39.069), train_loss = 0.78698495, grad/param norm = 3.5167e-01, time/batch = 17.0288s	
13011/16650 (epoch 39.072), train_loss = 0.73191384, grad/param norm = 3.3534e-01, time/batch = 17.4426s	
13012/16650 (epoch 39.075), train_loss = 0.81379643, grad/param norm = 3.0369e-01, time/batch = 18.0340s	
13013/16650 (epoch 39.078), train_loss = 0.81017845, grad/param norm = 3.4358e-01, time/batch = 17.0180s	
13014/16650 (epoch 39.081), train_loss = 0.75474501, grad/param norm = 3.2591e-01, time/batch = 17.1109s	
13015/16650 (epoch 39.084), train_loss = 0.74721523, grad/param norm = 2.8587e-01, time/batch = 16.0791s	
13016/16650 (epoch 39.087), train_loss = 0.77710416, grad/param norm = 3.1414e-01, time/batch = 16.5746s	
13017/16650 (epoch 39.090), train_loss = 0.72139821, grad/param norm = 3.3075e-01, time/batch = 17.1851s	
13018/16650 (epoch 39.093), train_loss = 0.85861802, grad/param norm = 4.0239e-01, time/batch = 18.5381s	
13019/16650 (epoch 39.096), train_loss = 0.69381183, grad/param norm = 3.0475e-01, time/batch = 18.6936s	
13020/16650 (epoch 39.099), train_loss = 0.76336768, grad/param norm = 3.0168e-01, time/batch = 16.4890s	
13021/16650 (epoch 39.102), train_loss = 0.74344713, grad/param norm = 2.9425e-01, time/batch = 16.1953s	
13022/16650 (epoch 39.105), train_loss = 0.75415960, grad/param norm = 3.7167e-01, time/batch = 18.0333s	
13023/16650 (epoch 39.108), train_loss = 0.77260199, grad/param norm = 3.1984e-01, time/batch = 15.4283s	
13024/16650 (epoch 39.111), train_loss = 0.83097873, grad/param norm = 3.0907e-01, time/batch = 17.5152s	
13025/16650 (epoch 39.114), train_loss = 0.77259524, grad/param norm = 3.8115e-01, time/batch = 18.5175s	
13026/16650 (epoch 39.117), train_loss = 0.88918585, grad/param norm = 3.6035e-01, time/batch = 15.2342s	
13027/16650 (epoch 39.120), train_loss = 0.74248364, grad/param norm = 2.7998e-01, time/batch = 15.9106s	
13028/16650 (epoch 39.123), train_loss = 0.71701913, grad/param norm = 2.7780e-01, time/batch = 18.0984s	
13029/16650 (epoch 39.126), train_loss = 0.78447795, grad/param norm = 2.8200e-01, time/batch = 17.6830s	
13030/16650 (epoch 39.129), train_loss = 0.78189718, grad/param norm = 2.8432e-01, time/batch = 17.4296s	
13031/16650 (epoch 39.132), train_loss = 0.74918658, grad/param norm = 3.3268e-01, time/batch = 16.0786s	
13032/16650 (epoch 39.135), train_loss = 0.83331725, grad/param norm = 3.0141e-01, time/batch = 18.1709s	
13033/16650 (epoch 39.138), train_loss = 0.80549056, grad/param norm = 3.1150e-01, time/batch = 16.2371s	
13034/16650 (epoch 39.141), train_loss = 0.78676130, grad/param norm = 3.1737e-01, time/batch = 16.6747s	
13035/16650 (epoch 39.144), train_loss = 0.78865624, grad/param norm = 3.1573e-01, time/batch = 17.1852s	
13036/16650 (epoch 39.147), train_loss = 0.86380676, grad/param norm = 2.7864e-01, time/batch = 18.4397s	
13037/16650 (epoch 39.150), train_loss = 0.94363775, grad/param norm = 3.7779e-01, time/batch = 16.9307s	
13038/16650 (epoch 39.153), train_loss = 0.75259153, grad/param norm = 3.5400e-01, time/batch = 17.4407s	
13039/16650 (epoch 39.156), train_loss = 0.74742539, grad/param norm = 2.9072e-01, time/batch = 15.8383s	
13040/16650 (epoch 39.159), train_loss = 0.81815287, grad/param norm = 3.6279e-01, time/batch = 18.1771s	
13041/16650 (epoch 39.162), train_loss = 0.86259040, grad/param norm = 2.7887e-01, time/batch = 17.6615s	
13042/16650 (epoch 39.165), train_loss = 0.85869991, grad/param norm = 3.2745e-01, time/batch = 17.8573s	
13043/16650 (epoch 39.168), train_loss = 0.63782920, grad/param norm = 2.6013e-01, time/batch = 15.8566s	
13044/16650 (epoch 39.171), train_loss = 0.80153485, grad/param norm = 2.9329e-01, time/batch = 15.8558s	
13045/16650 (epoch 39.174), train_loss = 0.62094123, grad/param norm = 2.7355e-01, time/batch = 16.6897s	
13046/16650 (epoch 39.177), train_loss = 0.74145257, grad/param norm = 2.8353e-01, time/batch = 17.5506s	
13047/16650 (epoch 39.180), train_loss = 0.84192910, grad/param norm = 2.8330e-01, time/batch = 17.4728s	
13048/16650 (epoch 39.183), train_loss = 1.00528393, grad/param norm = 4.2955e-01, time/batch = 15.8584s	
13049/16650 (epoch 39.186), train_loss = 0.78561073, grad/param norm = 3.2025e-01, time/batch = 17.2059s	
13050/16650 (epoch 39.189), train_loss = 0.69004621, grad/param norm = 2.5509e-01, time/batch = 17.0427s	
13051/16650 (epoch 39.192), train_loss = 0.75624530, grad/param norm = 3.0657e-01, time/batch = 14.4070s	
13052/16650 (epoch 39.195), train_loss = 0.68970108, grad/param norm = 2.8861e-01, time/batch = 16.7586s	
13053/16650 (epoch 39.198), train_loss = 0.66472414, grad/param norm = 2.5862e-01, time/batch = 17.7754s	
13054/16650 (epoch 39.201), train_loss = 0.67333047, grad/param norm = 3.1614e-01, time/batch = 17.2852s	
13055/16650 (epoch 39.204), train_loss = 0.76230742, grad/param norm = 3.0378e-01, time/batch = 15.7537s	
13056/16650 (epoch 39.207), train_loss = 0.79576913, grad/param norm = 3.7650e-01, time/batch = 17.6132s	
13057/16650 (epoch 39.210), train_loss = 0.74636716, grad/param norm = 2.9440e-01, time/batch = 15.9315s	
13058/16650 (epoch 39.213), train_loss = 0.81923939, grad/param norm = 3.9501e-01, time/batch = 16.5977s	
13059/16650 (epoch 39.216), train_loss = 0.70167447, grad/param norm = 2.9029e-01, time/batch = 14.7102s	
13060/16650 (epoch 39.219), train_loss = 0.74717693, grad/param norm = 3.1845e-01, time/batch = 17.0208s	
13061/16650 (epoch 39.222), train_loss = 0.75760142, grad/param norm = 2.5483e-01, time/batch = 18.3879s	
13062/16650 (epoch 39.225), train_loss = 0.79353889, grad/param norm = 3.4089e-01, time/batch = 15.9287s	
13063/16650 (epoch 39.228), train_loss = 0.69113245, grad/param norm = 3.0291e-01, time/batch = 16.4197s	
13064/16650 (epoch 39.231), train_loss = 0.67803436, grad/param norm = 3.4039e-01, time/batch = 18.3620s	
13065/16650 (epoch 39.234), train_loss = 0.88764308, grad/param norm = 2.8540e-01, time/batch = 17.2852s	
13066/16650 (epoch 39.237), train_loss = 0.75847310, grad/param norm = 3.2817e-01, time/batch = 15.6728s	
13067/16650 (epoch 39.240), train_loss = 0.76372692, grad/param norm = 2.8548e-01, time/batch = 15.6868s	
13068/16650 (epoch 39.243), train_loss = 0.73944219, grad/param norm = 3.1300e-01, time/batch = 17.2851s	
13069/16650 (epoch 39.246), train_loss = 0.86521331, grad/param norm = 3.8475e-01, time/batch = 16.4402s	
13070/16650 (epoch 39.249), train_loss = 0.63869199, grad/param norm = 2.6995e-01, time/batch = 16.7478s	
13071/16650 (epoch 39.252), train_loss = 0.73075822, grad/param norm = 3.1143e-01, time/batch = 17.2043s	
13072/16650 (epoch 39.255), train_loss = 0.79766430, grad/param norm = 3.3956e-01, time/batch = 18.2830s	
13073/16650 (epoch 39.258), train_loss = 0.81874900, grad/param norm = 2.8462e-01, time/batch = 15.5758s	
13074/16650 (epoch 39.261), train_loss = 0.78847921, grad/param norm = 2.9074e-01, time/batch = 16.9428s	
13075/16650 (epoch 39.264), train_loss = 0.68270824, grad/param norm = 2.7326e-01, time/batch = 14.2228s	
13076/16650 (epoch 39.267), train_loss = 0.71912528, grad/param norm = 2.8620e-01, time/batch = 17.0340s	
13077/16650 (epoch 39.270), train_loss = 0.80555248, grad/param norm = 3.5797e-01, time/batch = 15.6443s	
13078/16650 (epoch 39.273), train_loss = 0.84965846, grad/param norm = 3.2456e-01, time/batch = 17.7047s	
13079/16650 (epoch 39.276), train_loss = 0.79503721, grad/param norm = 3.5926e-01, time/batch = 18.1183s	
13080/16650 (epoch 39.279), train_loss = 0.72950917, grad/param norm = 2.8001e-01, time/batch = 14.5800s	
13081/16650 (epoch 39.282), train_loss = 0.69751251, grad/param norm = 2.5383e-01, time/batch = 17.2917s	
13082/16650 (epoch 39.285), train_loss = 0.73341027, grad/param norm = 3.1911e-01, time/batch = 16.7056s	
13083/16650 (epoch 39.288), train_loss = 0.68150012, grad/param norm = 3.0726e-01, time/batch = 17.6165s	
13084/16650 (epoch 39.291), train_loss = 0.54633454, grad/param norm = 2.2700e-01, time/batch = 16.0041s	
13085/16650 (epoch 39.294), train_loss = 0.68188371, grad/param norm = 2.8392e-01, time/batch = 16.3550s	
13086/16650 (epoch 39.297), train_loss = 0.72672841, grad/param norm = 2.6748e-01, time/batch = 16.4587s	
13087/16650 (epoch 39.300), train_loss = 0.57899564, grad/param norm = 2.3126e-01, time/batch = 15.5948s	
13088/16650 (epoch 39.303), train_loss = 0.63096462, grad/param norm = 2.6385e-01, time/batch = 17.2857s	
13089/16650 (epoch 39.306), train_loss = 0.81389058, grad/param norm = 2.7924e-01, time/batch = 16.8716s	
13090/16650 (epoch 39.309), train_loss = 0.79586310, grad/param norm = 3.0243e-01, time/batch = 17.3803s	
13091/16650 (epoch 39.312), train_loss = 0.62563943, grad/param norm = 3.0511e-01, time/batch = 14.9040s	
13092/16650 (epoch 39.315), train_loss = 0.52939902, grad/param norm = 2.0863e-01, time/batch = 16.1072s	
13093/16650 (epoch 39.318), train_loss = 0.61957871, grad/param norm = 2.7630e-01, time/batch = 17.8635s	
13094/16650 (epoch 39.321), train_loss = 0.81094829, grad/param norm = 3.3350e-01, time/batch = 16.8715s	
13095/16650 (epoch 39.324), train_loss = 0.66986607, grad/param norm = 2.9283e-01, time/batch = 15.5886s	
13096/16650 (epoch 39.327), train_loss = 0.76087453, grad/param norm = 3.5786e-01, time/batch = 17.9692s	
13097/16650 (epoch 39.330), train_loss = 0.76812822, grad/param norm = 4.1407e-01, time/batch = 17.7058s	
13098/16650 (epoch 39.333), train_loss = 0.78466411, grad/param norm = 3.2309e-01, time/batch = 15.6864s	
13099/16650 (epoch 39.336), train_loss = 0.65341126, grad/param norm = 3.0192e-01, time/batch = 18.2843s	
13100/16650 (epoch 39.339), train_loss = 0.67826480, grad/param norm = 3.3180e-01, time/batch = 17.0402s	
13101/16650 (epoch 39.342), train_loss = 0.62617063, grad/param norm = 3.0460e-01, time/batch = 14.8218s	
13102/16650 (epoch 39.345), train_loss = 0.66618663, grad/param norm = 2.7543e-01, time/batch = 16.4200s	
13103/16650 (epoch 39.348), train_loss = 0.74896657, grad/param norm = 2.9523e-01, time/batch = 18.2871s	
13104/16650 (epoch 39.351), train_loss = 0.76639000, grad/param norm = 3.1979e-01, time/batch = 15.1003s	
13105/16650 (epoch 39.354), train_loss = 0.81584439, grad/param norm = 3.9286e-01, time/batch = 16.1477s	
13106/16650 (epoch 39.357), train_loss = 0.78623503, grad/param norm = 3.1191e-01, time/batch = 16.0822s	
13107/16650 (epoch 39.360), train_loss = 0.75259164, grad/param norm = 3.1760e-01, time/batch = 17.6225s	
13108/16650 (epoch 39.363), train_loss = 0.81412242, grad/param norm = 3.4126e-01, time/batch = 16.6964s	
13109/16650 (epoch 39.366), train_loss = 0.87617227, grad/param norm = 3.1615e-01, time/batch = 15.7460s	
13110/16650 (epoch 39.369), train_loss = 0.78547317, grad/param norm = 2.8935e-01, time/batch = 17.3634s	
13111/16650 (epoch 39.372), train_loss = 0.75587132, grad/param norm = 3.2016e-01, time/batch = 17.8584s	
13112/16650 (epoch 39.375), train_loss = 0.76165589, grad/param norm = 2.5945e-01, time/batch = 16.0950s	
13113/16650 (epoch 39.378), train_loss = 0.71923520, grad/param norm = 2.9247e-01, time/batch = 15.9434s	
13114/16650 (epoch 39.381), train_loss = 0.80530643, grad/param norm = 3.3349e-01, time/batch = 17.9483s	
13115/16650 (epoch 39.384), train_loss = 0.86784783, grad/param norm = 3.2309e-01, time/batch = 17.4632s	
13116/16650 (epoch 39.387), train_loss = 0.58328276, grad/param norm = 2.4832e-01, time/batch = 14.8289s	
13117/16650 (epoch 39.390), train_loss = 0.79507667, grad/param norm = 2.7171e-01, time/batch = 16.0905s	
13118/16650 (epoch 39.393), train_loss = 0.70986737, grad/param norm = 3.3585e-01, time/batch = 15.4998s	
13119/16650 (epoch 39.396), train_loss = 0.84767752, grad/param norm = 3.2607e-01, time/batch = 17.4568s	
13120/16650 (epoch 39.399), train_loss = 0.79953651, grad/param norm = 2.7784e-01, time/batch = 15.8403s	
13121/16650 (epoch 39.402), train_loss = 0.70573365, grad/param norm = 2.7463e-01, time/batch = 17.8580s	
13122/16650 (epoch 39.405), train_loss = 0.59070651, grad/param norm = 2.8192e-01, time/batch = 17.1049s	
13123/16650 (epoch 39.408), train_loss = 0.76371705, grad/param norm = 2.7878e-01, time/batch = 15.2299s	
13124/16650 (epoch 39.411), train_loss = 0.66320106, grad/param norm = 2.9153e-01, time/batch = 17.4643s	
13125/16650 (epoch 39.414), train_loss = 0.65091068, grad/param norm = 2.9987e-01, time/batch = 17.3033s	
13126/16650 (epoch 39.417), train_loss = 0.64485508, grad/param norm = 3.1153e-01, time/batch = 17.9620s	
13127/16650 (epoch 39.420), train_loss = 0.67243862, grad/param norm = 3.1284e-01, time/batch = 10.4789s	
13128/16650 (epoch 39.423), train_loss = 0.54916652, grad/param norm = 2.3803e-01, time/batch = 0.6190s	
13129/16650 (epoch 39.426), train_loss = 0.65282999, grad/param norm = 3.0929e-01, time/batch = 0.6178s	
13130/16650 (epoch 39.429), train_loss = 0.80614100, grad/param norm = 3.0966e-01, time/batch = 0.6203s	
13131/16650 (epoch 39.432), train_loss = 0.80896555, grad/param norm = 3.1896e-01, time/batch = 0.6225s	
13132/16650 (epoch 39.435), train_loss = 0.90403881, grad/param norm = 3.2390e-01, time/batch = 0.6186s	
13133/16650 (epoch 39.438), train_loss = 0.88330750, grad/param norm = 3.5844e-01, time/batch = 0.6200s	
13134/16650 (epoch 39.441), train_loss = 0.72006377, grad/param norm = 3.4101e-01, time/batch = 0.6301s	
13135/16650 (epoch 39.444), train_loss = 0.68799302, grad/param norm = 2.9830e-01, time/batch = 0.7482s	
13136/16650 (epoch 39.447), train_loss = 0.67563002, grad/param norm = 2.8631e-01, time/batch = 0.9181s	
13137/16650 (epoch 39.450), train_loss = 0.69337276, grad/param norm = 3.0910e-01, time/batch = 0.9149s	
13138/16650 (epoch 39.453), train_loss = 0.67974480, grad/param norm = 2.5497e-01, time/batch = 0.9108s	
13139/16650 (epoch 39.456), train_loss = 0.65271589, grad/param norm = 2.3960e-01, time/batch = 0.9114s	
13140/16650 (epoch 39.459), train_loss = 0.66977346, grad/param norm = 3.0343e-01, time/batch = 0.9030s	
13141/16650 (epoch 39.462), train_loss = 0.82873733, grad/param norm = 3.5672e-01, time/batch = 1.7081s	
13142/16650 (epoch 39.465), train_loss = 0.66892454, grad/param norm = 2.9230e-01, time/batch = 1.6878s	
13143/16650 (epoch 39.468), train_loss = 0.56258238, grad/param norm = 2.6675e-01, time/batch = 2.8978s	
13144/16650 (epoch 39.471), train_loss = 0.48396237, grad/param norm = 2.0852e-01, time/batch = 16.7082s	
13145/16650 (epoch 39.474), train_loss = 0.63635671, grad/param norm = 3.1094e-01, time/batch = 15.9899s	
13146/16650 (epoch 39.477), train_loss = 0.78766825, grad/param norm = 2.8609e-01, time/batch = 16.0902s	
13147/16650 (epoch 39.480), train_loss = 0.71141124, grad/param norm = 3.3725e-01, time/batch = 14.3980s	
13148/16650 (epoch 39.483), train_loss = 0.79705512, grad/param norm = 3.1658e-01, time/batch = 16.5282s	
13149/16650 (epoch 39.486), train_loss = 0.65181628, grad/param norm = 2.5243e-01, time/batch = 16.9331s	
13150/16650 (epoch 39.489), train_loss = 0.70079557, grad/param norm = 2.7145e-01, time/batch = 16.1956s	
13151/16650 (epoch 39.492), train_loss = 0.71087501, grad/param norm = 2.5548e-01, time/batch = 18.3730s	
13152/16650 (epoch 39.495), train_loss = 0.62375765, grad/param norm = 2.9932e-01, time/batch = 17.6266s	
13153/16650 (epoch 39.498), train_loss = 0.68125651, grad/param norm = 3.5312e-01, time/batch = 15.7692s	
13154/16650 (epoch 39.502), train_loss = 0.87897608, grad/param norm = 3.6217e-01, time/batch = 16.8494s	
13155/16650 (epoch 39.505), train_loss = 0.76946194, grad/param norm = 2.9497e-01, time/batch = 17.2046s	
13156/16650 (epoch 39.508), train_loss = 0.80485704, grad/param norm = 4.6918e-01, time/batch = 16.7692s	
13157/16650 (epoch 39.511), train_loss = 0.80685402, grad/param norm = 3.3009e-01, time/batch = 15.4939s	
13158/16650 (epoch 39.514), train_loss = 0.62808763, grad/param norm = 2.7798e-01, time/batch = 18.0393s	
13159/16650 (epoch 39.517), train_loss = 0.71783665, grad/param norm = 3.6408e-01, time/batch = 15.0891s	
13160/16650 (epoch 39.520), train_loss = 0.61526299, grad/param norm = 2.8826e-01, time/batch = 15.5880s	
13161/16650 (epoch 39.523), train_loss = 0.71770580, grad/param norm = 3.2005e-01, time/batch = 16.7652s	
13162/16650 (epoch 39.526), train_loss = 0.77725893, grad/param norm = 2.9437e-01, time/batch = 17.7018s	
13163/16650 (epoch 39.529), train_loss = 0.81490273, grad/param norm = 3.6199e-01, time/batch = 17.5349s	
13164/16650 (epoch 39.532), train_loss = 0.53230870, grad/param norm = 2.3762e-01, time/batch = 16.7644s	
13165/16650 (epoch 39.535), train_loss = 0.64487512, grad/param norm = 3.2425e-01, time/batch = 16.2706s	
13166/16650 (epoch 39.538), train_loss = 0.58212675, grad/param norm = 2.7389e-01, time/batch = 17.9716s	
13167/16650 (epoch 39.541), train_loss = 0.83383261, grad/param norm = 3.0427e-01, time/batch = 16.5251s	
13168/16650 (epoch 39.544), train_loss = 0.89387339, grad/param norm = 4.3748e-01, time/batch = 15.0874s	
13169/16650 (epoch 39.547), train_loss = 0.63280944, grad/param norm = 3.0002e-01, time/batch = 17.6014s	
13170/16650 (epoch 39.550), train_loss = 0.72544198, grad/param norm = 2.8511e-01, time/batch = 18.2020s	
13171/16650 (epoch 39.553), train_loss = 0.73924823, grad/param norm = 3.8010e-01, time/batch = 16.6746s	
13172/16650 (epoch 39.556), train_loss = 0.64629220, grad/param norm = 3.2606e-01, time/batch = 17.3610s	
13173/16650 (epoch 39.559), train_loss = 0.57507741, grad/param norm = 2.8694e-01, time/batch = 17.5498s	
13174/16650 (epoch 39.562), train_loss = 0.67471554, grad/param norm = 3.0900e-01, time/batch = 15.8197s	
13175/16650 (epoch 39.565), train_loss = 0.57795298, grad/param norm = 3.1626e-01, time/batch = 16.3341s	
13176/16650 (epoch 39.568), train_loss = 0.58073108, grad/param norm = 2.9453e-01, time/batch = 16.1039s	
13177/16650 (epoch 39.571), train_loss = 0.64884642, grad/param norm = 3.5125e-01, time/batch = 13.7948s	
13178/16650 (epoch 39.574), train_loss = 0.65117578, grad/param norm = 3.4943e-01, time/batch = 13.9860s	
13179/16650 (epoch 39.577), train_loss = 0.69889358, grad/param norm = 2.8778e-01, time/batch = 13.7805s	
13180/16650 (epoch 39.580), train_loss = 0.63415463, grad/param norm = 2.6085e-01, time/batch = 15.5180s	
13181/16650 (epoch 39.583), train_loss = 0.73361111, grad/param norm = 3.1342e-01, time/batch = 18.1166s	
13182/16650 (epoch 39.586), train_loss = 0.64320292, grad/param norm = 4.1905e-01, time/batch = 15.5766s	
13183/16650 (epoch 39.589), train_loss = 0.63249709, grad/param norm = 2.6435e-01, time/batch = 16.5296s	
13184/16650 (epoch 39.592), train_loss = 0.72588571, grad/param norm = 3.5793e-01, time/batch = 16.0322s	
13185/16650 (epoch 39.595), train_loss = 0.65355453, grad/param norm = 3.0871e-01, time/batch = 17.5337s	
13186/16650 (epoch 39.598), train_loss = 0.67982389, grad/param norm = 3.1327e-01, time/batch = 16.0007s	
13187/16650 (epoch 39.601), train_loss = 0.67027639, grad/param norm = 3.5410e-01, time/batch = 14.4898s	
13188/16650 (epoch 39.604), train_loss = 0.70264662, grad/param norm = 2.9942e-01, time/batch = 18.6116s	
13189/16650 (epoch 39.607), train_loss = 0.76544057, grad/param norm = 3.0139e-01, time/batch = 16.3402s	
13190/16650 (epoch 39.610), train_loss = 0.64897741, grad/param norm = 2.7462e-01, time/batch = 17.4311s	
13191/16650 (epoch 39.613), train_loss = 0.82344504, grad/param norm = 3.1190e-01, time/batch = 18.2710s	
13192/16650 (epoch 39.616), train_loss = 0.77093503, grad/param norm = 3.7502e-01, time/batch = 16.7049s	
13193/16650 (epoch 39.619), train_loss = 0.59291340, grad/param norm = 2.6743e-01, time/batch = 17.3404s	
13194/16650 (epoch 39.622), train_loss = 0.57420175, grad/param norm = 2.7919e-01, time/batch = 16.8790s	
13195/16650 (epoch 39.625), train_loss = 0.67670486, grad/param norm = 2.6541e-01, time/batch = 18.1236s	
13196/16650 (epoch 39.628), train_loss = 0.65416391, grad/param norm = 3.7120e-01, time/batch = 21.1207s	
13197/16650 (epoch 39.631), train_loss = 0.72230613, grad/param norm = 3.2571e-01, time/batch = 24.5375s	
13198/16650 (epoch 39.634), train_loss = 0.87915239, grad/param norm = 3.4614e-01, time/batch = 14.9164s	
13199/16650 (epoch 39.637), train_loss = 0.85915616, grad/param norm = 3.0097e-01, time/batch = 15.4324s	
13200/16650 (epoch 39.640), train_loss = 0.69435241, grad/param norm = 3.0397e-01, time/batch = 17.7699s	
13201/16650 (epoch 39.643), train_loss = 0.76605023, grad/param norm = 2.7781e-01, time/batch = 17.0990s	
13202/16650 (epoch 39.646), train_loss = 0.75324098, grad/param norm = 3.4713e-01, time/batch = 17.2754s	
13203/16650 (epoch 39.649), train_loss = 0.74929095, grad/param norm = 2.9548e-01, time/batch = 16.4151s	
13204/16650 (epoch 39.652), train_loss = 0.75090451, grad/param norm = 3.0399e-01, time/batch = 15.0617s	
13205/16650 (epoch 39.655), train_loss = 0.71910017, grad/param norm = 3.0067e-01, time/batch = 17.6084s	
13206/16650 (epoch 39.658), train_loss = 0.65151329, grad/param norm = 2.6473e-01, time/batch = 16.1896s	
13207/16650 (epoch 39.661), train_loss = 0.73108690, grad/param norm = 3.4051e-01, time/batch = 16.4362s	
13208/16650 (epoch 39.664), train_loss = 0.71715932, grad/param norm = 3.4245e-01, time/batch = 16.7667s	
13209/16650 (epoch 39.667), train_loss = 0.81357359, grad/param norm = 3.0113e-01, time/batch = 16.8748s	
13210/16650 (epoch 39.670), train_loss = 0.60046952, grad/param norm = 2.5241e-01, time/batch = 15.9083s	
13211/16650 (epoch 39.673), train_loss = 0.63773270, grad/param norm = 3.0909e-01, time/batch = 17.4522s	
13212/16650 (epoch 39.676), train_loss = 0.75687464, grad/param norm = 2.9097e-01, time/batch = 14.8492s	
13213/16650 (epoch 39.679), train_loss = 0.63762601, grad/param norm = 2.8006e-01, time/batch = 16.1200s	
13214/16650 (epoch 39.682), train_loss = 0.69346342, grad/param norm = 2.6531e-01, time/batch = 16.8428s	
13215/16650 (epoch 39.685), train_loss = 0.60095152, grad/param norm = 2.9547e-01, time/batch = 17.1191s	
13216/16650 (epoch 39.688), train_loss = 0.77369475, grad/param norm = 2.9060e-01, time/batch = 17.2942s	
13217/16650 (epoch 39.691), train_loss = 0.73586740, grad/param norm = 3.0572e-01, time/batch = 15.0740s	
13218/16650 (epoch 39.694), train_loss = 0.65311682, grad/param norm = 3.0291e-01, time/batch = 15.4678s	
13219/16650 (epoch 39.697), train_loss = 0.60893495, grad/param norm = 2.5958e-01, time/batch = 15.1082s	
13220/16650 (epoch 39.700), train_loss = 0.75687760, grad/param norm = 3.1943e-01, time/batch = 17.6033s	
13221/16650 (epoch 39.703), train_loss = 0.63616267, grad/param norm = 3.2651e-01, time/batch = 15.5098s	
13222/16650 (epoch 39.706), train_loss = 0.71455458, grad/param norm = 3.6280e-01, time/batch = 17.6120s	
13223/16650 (epoch 39.709), train_loss = 0.62351823, grad/param norm = 4.2343e-01, time/batch = 17.2913s	
13224/16650 (epoch 39.712), train_loss = 0.65380117, grad/param norm = 3.4589e-01, time/batch = 14.5412s	
13225/16650 (epoch 39.715), train_loss = 0.74608330, grad/param norm = 4.0982e-01, time/batch = 17.0914s	
13226/16650 (epoch 39.718), train_loss = 0.77514161, grad/param norm = 3.2305e-01, time/batch = 17.1995s	
13227/16650 (epoch 39.721), train_loss = 0.80461869, grad/param norm = 3.1903e-01, time/batch = 16.3631s	
13228/16650 (epoch 39.724), train_loss = 0.76496925, grad/param norm = 3.2764e-01, time/batch = 15.8544s	
13229/16650 (epoch 39.727), train_loss = 0.79147154, grad/param norm = 3.1987e-01, time/batch = 17.5322s	
13230/16650 (epoch 39.730), train_loss = 0.66501980, grad/param norm = 3.1220e-01, time/batch = 16.5461s	
13231/16650 (epoch 39.733), train_loss = 0.82517638, grad/param norm = 3.8897e-01, time/batch = 16.8678s	
13232/16650 (epoch 39.736), train_loss = 0.59720161, grad/param norm = 2.7719e-01, time/batch = 14.5182s	
13233/16650 (epoch 39.739), train_loss = 0.73621281, grad/param norm = 3.2593e-01, time/batch = 13.3959s	
13234/16650 (epoch 39.742), train_loss = 0.71594416, grad/param norm = 2.7299e-01, time/batch = 13.4673s	
13235/16650 (epoch 39.745), train_loss = 0.55206157, grad/param norm = 2.4682e-01, time/batch = 15.3426s	
13236/16650 (epoch 39.748), train_loss = 0.60110540, grad/param norm = 2.9503e-01, time/batch = 15.5113s	
13237/16650 (epoch 39.751), train_loss = 0.72734716, grad/param norm = 3.9489e-01, time/batch = 17.8698s	
13238/16650 (epoch 39.754), train_loss = 0.86934723, grad/param norm = 3.9460e-01, time/batch = 16.9399s	
13239/16650 (epoch 39.757), train_loss = 0.85155476, grad/param norm = 3.3354e-01, time/batch = 16.1899s	
13240/16650 (epoch 39.760), train_loss = 0.72687860, grad/param norm = 2.8957e-01, time/batch = 14.3109s	
13241/16650 (epoch 39.763), train_loss = 0.66535133, grad/param norm = 3.0890e-01, time/batch = 18.0338s	
13242/16650 (epoch 39.766), train_loss = 0.67916110, grad/param norm = 2.5893e-01, time/batch = 18.1171s	
13243/16650 (epoch 39.769), train_loss = 0.74276780, grad/param norm = 3.0368e-01, time/batch = 16.1021s	
13244/16650 (epoch 39.772), train_loss = 0.71248266, grad/param norm = 2.4335e-01, time/batch = 16.9441s	
13245/16650 (epoch 39.775), train_loss = 0.69478455, grad/param norm = 2.8385e-01, time/batch = 15.2685s	
13246/16650 (epoch 39.778), train_loss = 0.73731841, grad/param norm = 2.7420e-01, time/batch = 16.7826s	
13247/16650 (epoch 39.781), train_loss = 0.85460003, grad/param norm = 2.9781e-01, time/batch = 14.8230s	
13248/16650 (epoch 39.784), train_loss = 0.73592545, grad/param norm = 3.1486e-01, time/batch = 17.0128s	
13249/16650 (epoch 39.787), train_loss = 0.79121491, grad/param norm = 3.3706e-01, time/batch = 17.5266s	
13250/16650 (epoch 39.790), train_loss = 0.81018073, grad/param norm = 2.8720e-01, time/batch = 16.3597s	
13251/16650 (epoch 39.793), train_loss = 0.61343429, grad/param norm = 2.6807e-01, time/batch = 16.5256s	
13252/16650 (epoch 39.796), train_loss = 0.94244630, grad/param norm = 3.4368e-01, time/batch = 17.7010s	
13253/16650 (epoch 39.799), train_loss = 0.85962211, grad/param norm = 3.5441e-01, time/batch = 17.7103s	
13254/16650 (epoch 39.802), train_loss = 0.80061469, grad/param norm = 3.0700e-01, time/batch = 17.3569s	
13255/16650 (epoch 39.805), train_loss = 0.74264368, grad/param norm = 2.6165e-01, time/batch = 15.0034s	
13256/16650 (epoch 39.808), train_loss = 0.80402473, grad/param norm = 3.6471e-01, time/batch = 17.7012s	
13257/16650 (epoch 39.811), train_loss = 0.82981287, grad/param norm = 3.2610e-01, time/batch = 16.1642s	
13258/16650 (epoch 39.814), train_loss = 0.64325764, grad/param norm = 2.5499e-01, time/batch = 15.4343s	
13259/16650 (epoch 39.817), train_loss = 0.67919674, grad/param norm = 2.9939e-01, time/batch = 16.0998s	
13260/16650 (epoch 39.820), train_loss = 0.78367644, grad/param norm = 2.7680e-01, time/batch = 17.9411s	
13261/16650 (epoch 39.823), train_loss = 0.73440717, grad/param norm = 3.0156e-01, time/batch = 16.1060s	
13262/16650 (epoch 39.826), train_loss = 0.68512035, grad/param norm = 2.9010e-01, time/batch = 15.6257s	
13263/16650 (epoch 39.829), train_loss = 0.72831295, grad/param norm = 2.8125e-01, time/batch = 17.1854s	
13264/16650 (epoch 39.832), train_loss = 0.79610583, grad/param norm = 3.2330e-01, time/batch = 17.1068s	
13265/16650 (epoch 39.835), train_loss = 0.78709358, grad/param norm = 3.7615e-01, time/batch = 15.8412s	
13266/16650 (epoch 39.838), train_loss = 0.67006602, grad/param norm = 3.3173e-01, time/batch = 18.2104s	
13267/16650 (epoch 39.841), train_loss = 0.66803662, grad/param norm = 2.5902e-01, time/batch = 18.2093s	
13268/16650 (epoch 39.844), train_loss = 0.69316022, grad/param norm = 2.6560e-01, time/batch = 15.3293s	
13269/16650 (epoch 39.847), train_loss = 0.79994418, grad/param norm = 2.9787e-01, time/batch = 16.5796s	
13270/16650 (epoch 39.850), train_loss = 0.66809324, grad/param norm = 3.6366e-01, time/batch = 16.1061s	
13271/16650 (epoch 39.853), train_loss = 0.70953431, grad/param norm = 2.8875e-01, time/batch = 18.4413s	
13272/16650 (epoch 39.856), train_loss = 0.66526987, grad/param norm = 2.6078e-01, time/batch = 15.9353s	
13273/16650 (epoch 39.859), train_loss = 0.80637755, grad/param norm = 3.3769e-01, time/batch = 17.3663s	
13274/16650 (epoch 39.862), train_loss = 0.74445605, grad/param norm = 3.1734e-01, time/batch = 16.0110s	
13275/16650 (epoch 39.865), train_loss = 0.57459414, grad/param norm = 2.4467e-01, time/batch = 16.0076s	
13276/16650 (epoch 39.868), train_loss = 0.73335757, grad/param norm = 2.7937e-01, time/batch = 16.6176s	
13277/16650 (epoch 39.871), train_loss = 0.75756400, grad/param norm = 3.1357e-01, time/batch = 17.3632s	
13278/16650 (epoch 39.874), train_loss = 0.74616628, grad/param norm = 2.7368e-01, time/batch = 17.2037s	
13279/16650 (epoch 39.877), train_loss = 0.71805992, grad/param norm = 2.6965e-01, time/batch = 16.8492s	
13280/16650 (epoch 39.880), train_loss = 0.65783140, grad/param norm = 2.9727e-01, time/batch = 14.8309s	
13281/16650 (epoch 39.883), train_loss = 0.74192882, grad/param norm = 2.5761e-01, time/batch = 16.1599s	
13282/16650 (epoch 39.886), train_loss = 0.74212697, grad/param norm = 3.0158e-01, time/batch = 16.9358s	
13283/16650 (epoch 39.889), train_loss = 0.60109928, grad/param norm = 2.8275e-01, time/batch = 17.1141s	
13284/16650 (epoch 39.892), train_loss = 0.72626986, grad/param norm = 2.6833e-01, time/batch = 17.6234s	
13285/16650 (epoch 39.895), train_loss = 0.73773106, grad/param norm = 2.6217e-01, time/batch = 17.7755s	
13286/16650 (epoch 39.898), train_loss = 0.73621362, grad/param norm = 3.4832e-01, time/batch = 15.3185s	
13287/16650 (epoch 39.901), train_loss = 0.66391731, grad/param norm = 2.7478e-01, time/batch = 16.5739s	
13288/16650 (epoch 39.904), train_loss = 0.68247569, grad/param norm = 3.1017e-01, time/batch = 17.1106s	
13289/16650 (epoch 39.907), train_loss = 0.72724089, grad/param norm = 2.9517e-01, time/batch = 17.1807s	
13290/16650 (epoch 39.910), train_loss = 0.77639524, grad/param norm = 3.2087e-01, time/batch = 17.1089s	
13291/16650 (epoch 39.913), train_loss = 0.68141845, grad/param norm = 2.7521e-01, time/batch = 16.6129s	
13292/16650 (epoch 39.916), train_loss = 0.65327420, grad/param norm = 3.2690e-01, time/batch = 17.2852s	
13293/16650 (epoch 39.919), train_loss = 0.86320986, grad/param norm = 3.1547e-01, time/batch = 15.2549s	
13294/16650 (epoch 39.922), train_loss = 0.74461286, grad/param norm = 3.5133e-01, time/batch = 16.8349s	
13295/16650 (epoch 39.925), train_loss = 0.68279905, grad/param norm = 3.2322e-01, time/batch = 14.4108s	
13296/16650 (epoch 39.928), train_loss = 0.72985289, grad/param norm = 2.9814e-01, time/batch = 17.8618s	
13297/16650 (epoch 39.931), train_loss = 0.74604982, grad/param norm = 3.3608e-01, time/batch = 16.1772s	
13298/16650 (epoch 39.934), train_loss = 0.61274462, grad/param norm = 3.0759e-01, time/batch = 17.8813s	
13299/16650 (epoch 39.937), train_loss = 0.66224810, grad/param norm = 3.3362e-01, time/batch = 16.8440s	
13300/16650 (epoch 39.940), train_loss = 0.71169746, grad/param norm = 2.6241e-01, time/batch = 15.5775s	
13301/16650 (epoch 39.943), train_loss = 0.74225694, grad/param norm = 3.4934e-01, time/batch = 17.5238s	
13302/16650 (epoch 39.946), train_loss = 0.66825652, grad/param norm = 2.8385e-01, time/batch = 17.6975s	
13303/16650 (epoch 39.949), train_loss = 0.62264541, grad/param norm = 2.9722e-01, time/batch = 17.4474s	
13304/16650 (epoch 39.952), train_loss = 0.62638105, grad/param norm = 2.9058e-01, time/batch = 15.9870s	
13305/16650 (epoch 39.955), train_loss = 0.72318689, grad/param norm = 2.7228e-01, time/batch = 17.5369s	
13306/16650 (epoch 39.958), train_loss = 0.78345203, grad/param norm = 3.3156e-01, time/batch = 16.9442s	
13307/16650 (epoch 39.961), train_loss = 0.68569189, grad/param norm = 2.4171e-01, time/batch = 16.1854s	
13308/16650 (epoch 39.964), train_loss = 0.63311812, grad/param norm = 3.3853e-01, time/batch = 16.8572s	
13309/16650 (epoch 39.967), train_loss = 0.84131854, grad/param norm = 3.7154e-01, time/batch = 16.6122s	
13310/16650 (epoch 39.970), train_loss = 0.69366674, grad/param norm = 3.0340e-01, time/batch = 17.8614s	
13311/16650 (epoch 39.973), train_loss = 0.67301086, grad/param norm = 3.2219e-01, time/batch = 14.9665s	
13312/16650 (epoch 39.976), train_loss = 0.65929220, grad/param norm = 3.0488e-01, time/batch = 17.5277s	
13313/16650 (epoch 39.979), train_loss = 0.73827012, grad/param norm = 3.8604e-01, time/batch = 17.0296s	
13314/16650 (epoch 39.982), train_loss = 0.76656294, grad/param norm = 3.3109e-01, time/batch = 17.0169s	
13315/16650 (epoch 39.985), train_loss = 0.72339526, grad/param norm = 2.8616e-01, time/batch = 16.5219s	
13316/16650 (epoch 39.988), train_loss = 0.74455498, grad/param norm = 3.0951e-01, time/batch = 18.0303s	
13317/16650 (epoch 39.991), train_loss = 0.67134049, grad/param norm = 4.0086e-01, time/batch = 16.9428s	
13318/16650 (epoch 39.994), train_loss = 0.67396909, grad/param norm = 2.7497e-01, time/batch = 15.5869s	
13319/16650 (epoch 39.997), train_loss = 0.68134680, grad/param norm = 3.1841e-01, time/batch = 16.1856s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
13320/16650 (epoch 40.000), train_loss = 0.77085267, grad/param norm = 3.2610e-01, time/batch = 17.8651s	
13321/16650 (epoch 40.003), train_loss = 0.82341599, grad/param norm = 3.5908e-01, time/batch = 16.9201s	
13322/16650 (epoch 40.006), train_loss = 0.80881437, grad/param norm = 4.1615e-01, time/batch = 15.9877s	
13323/16650 (epoch 40.009), train_loss = 0.83308394, grad/param norm = 3.1920e-01, time/batch = 17.0411s	
13324/16650 (epoch 40.012), train_loss = 0.82560332, grad/param norm = 3.2338e-01, time/batch = 17.0366s	
13325/16650 (epoch 40.015), train_loss = 0.73333160, grad/param norm = 3.0332e-01, time/batch = 15.6155s	
13326/16650 (epoch 40.018), train_loss = 0.63984451, grad/param norm = 3.3324e-01, time/batch = 17.3745s	
13327/16650 (epoch 40.021), train_loss = 0.84278023, grad/param norm = 3.2757e-01, time/batch = 17.7881s	
13328/16650 (epoch 40.024), train_loss = 0.73870198, grad/param norm = 3.5586e-01, time/batch = 17.4568s	
13329/16650 (epoch 40.027), train_loss = 0.76275474, grad/param norm = 3.2749e-01, time/batch = 16.5797s	
13330/16650 (epoch 40.030), train_loss = 0.60539667, grad/param norm = 2.4786e-01, time/batch = 17.4436s	
13331/16650 (epoch 40.033), train_loss = 0.70865538, grad/param norm = 2.9725e-01, time/batch = 16.0126s	
13332/16650 (epoch 40.036), train_loss = 0.53066218, grad/param norm = 3.3716e-01, time/batch = 15.9293s	
13333/16650 (epoch 40.039), train_loss = 0.82111242, grad/param norm = 2.8073e-01, time/batch = 16.9342s	
13334/16650 (epoch 40.042), train_loss = 0.77000117, grad/param norm = 3.2823e-01, time/batch = 17.7095s	
13335/16650 (epoch 40.045), train_loss = 0.71669770, grad/param norm = 2.8343e-01, time/batch = 16.2774s	
13336/16650 (epoch 40.048), train_loss = 0.78430684, grad/param norm = 3.2175e-01, time/batch = 16.3283s	
13337/16650 (epoch 40.051), train_loss = 0.70051792, grad/param norm = 2.9787e-01, time/batch = 17.5299s	
13338/16650 (epoch 40.054), train_loss = 0.71673076, grad/param norm = 2.9835e-01, time/batch = 17.4424s	
13339/16650 (epoch 40.057), train_loss = 0.71400305, grad/param norm = 3.0987e-01, time/batch = 15.7655s	
13340/16650 (epoch 40.060), train_loss = 0.61869417, grad/param norm = 2.6875e-01, time/batch = 17.3680s	
13341/16650 (epoch 40.063), train_loss = 0.66991405, grad/param norm = 2.6817e-01, time/batch = 14.7456s	
13342/16650 (epoch 40.066), train_loss = 0.85140619, grad/param norm = 2.9063e-01, time/batch = 17.4419s	
13343/16650 (epoch 40.069), train_loss = 0.77010812, grad/param norm = 3.0964e-01, time/batch = 16.5234s	
13344/16650 (epoch 40.072), train_loss = 0.72348572, grad/param norm = 3.1327e-01, time/batch = 17.3558s	
13345/16650 (epoch 40.075), train_loss = 0.80072019, grad/param norm = 3.1053e-01, time/batch = 15.9080s	
13346/16650 (epoch 40.078), train_loss = 0.80018682, grad/param norm = 4.2835e-01, time/batch = 17.0808s	
13347/16650 (epoch 40.081), train_loss = 0.75961426, grad/param norm = 3.3155e-01, time/batch = 15.3517s	
13348/16650 (epoch 40.084), train_loss = 0.73553192, grad/param norm = 3.1124e-01, time/batch = 17.0281s	
13349/16650 (epoch 40.087), train_loss = 0.76656640, grad/param norm = 3.1589e-01, time/batch = 17.2050s	
13350/16650 (epoch 40.090), train_loss = 0.70101345, grad/param norm = 3.1699e-01, time/batch = 16.4400s	
13351/16650 (epoch 40.093), train_loss = 0.84754924, grad/param norm = 3.7840e-01, time/batch = 17.8683s	
13352/16650 (epoch 40.096), train_loss = 0.67670083, grad/param norm = 2.9445e-01, time/batch = 17.9633s	
13353/16650 (epoch 40.099), train_loss = 0.76229084, grad/param norm = 3.3884e-01, time/batch = 16.0112s	
13354/16650 (epoch 40.102), train_loss = 0.73234032, grad/param norm = 3.0676e-01, time/batch = 16.7830s	
13355/16650 (epoch 40.105), train_loss = 0.73352459, grad/param norm = 3.4577e-01, time/batch = 16.6174s	
13356/16650 (epoch 40.108), train_loss = 0.75599402, grad/param norm = 3.0593e-01, time/batch = 18.1275s	
13357/16650 (epoch 40.111), train_loss = 0.81132405, grad/param norm = 3.1824e-01, time/batch = 16.3518s	
13358/16650 (epoch 40.114), train_loss = 0.76546188, grad/param norm = 3.5602e-01, time/batch = 17.1086s	
13359/16650 (epoch 40.117), train_loss = 0.88188135, grad/param norm = 3.0508e-01, time/batch = 15.8429s	
13360/16650 (epoch 40.120), train_loss = 0.73318847, grad/param norm = 2.6054e-01, time/batch = 16.6746s	
13361/16650 (epoch 40.123), train_loss = 0.69918607, grad/param norm = 2.9202e-01, time/batch = 15.2200s	
13362/16650 (epoch 40.126), train_loss = 0.77528222, grad/param norm = 3.0616e-01, time/batch = 16.7827s	
13363/16650 (epoch 40.129), train_loss = 0.78515057, grad/param norm = 3.0703e-01, time/batch = 17.5342s	
13364/16650 (epoch 40.132), train_loss = 0.74726266, grad/param norm = 3.8077e-01, time/batch = 15.4413s	
13365/16650 (epoch 40.135), train_loss = 0.84836652, grad/param norm = 3.0309e-01, time/batch = 16.1027s	
13366/16650 (epoch 40.138), train_loss = 0.79382645, grad/param norm = 3.0488e-01, time/batch = 16.9402s	
13367/16650 (epoch 40.141), train_loss = 0.76984417, grad/param norm = 3.8194e-01, time/batch = 17.1948s	
13368/16650 (epoch 40.144), train_loss = 0.78258027, grad/param norm = 2.9610e-01, time/batch = 16.5189s	
13369/16650 (epoch 40.147), train_loss = 0.86699898, grad/param norm = 2.9727e-01, time/batch = 17.7546s	
13370/16650 (epoch 40.150), train_loss = 0.92593257, grad/param norm = 3.4419e-01, time/batch = 17.5339s	
13371/16650 (epoch 40.153), train_loss = 0.75349692, grad/param norm = 3.3358e-01, time/batch = 15.2156s	
13372/16650 (epoch 40.156), train_loss = 0.73270802, grad/param norm = 2.7902e-01, time/batch = 17.9239s	
13373/16650 (epoch 40.159), train_loss = 0.78944811, grad/param norm = 3.1319e-01, time/batch = 17.6899s	
13374/16650 (epoch 40.162), train_loss = 0.85962530, grad/param norm = 3.0041e-01, time/batch = 17.5263s	
13375/16650 (epoch 40.165), train_loss = 0.84640846, grad/param norm = 3.8129e-01, time/batch = 16.1526s	
13376/16650 (epoch 40.168), train_loss = 0.63452040, grad/param norm = 2.8757e-01, time/batch = 16.7890s	
13377/16650 (epoch 40.171), train_loss = 0.79003142, grad/param norm = 2.8188e-01, time/batch = 14.7281s	
13378/16650 (epoch 40.174), train_loss = 0.61980579, grad/param norm = 3.0256e-01, time/batch = 17.0825s	
13379/16650 (epoch 40.177), train_loss = 0.73427871, grad/param norm = 2.9995e-01, time/batch = 16.8372s	
13380/16650 (epoch 40.180), train_loss = 0.83996638, grad/param norm = 3.1908e-01, time/batch = 17.7008s	
13381/16650 (epoch 40.183), train_loss = 0.97471354, grad/param norm = 3.4775e-01, time/batch = 19.2051s	
13382/16650 (epoch 40.186), train_loss = 0.77064385, grad/param norm = 3.0502e-01, time/batch = 16.8397s	
13383/16650 (epoch 40.189), train_loss = 0.68081490, grad/param norm = 2.7012e-01, time/batch = 16.9394s	
13384/16650 (epoch 40.192), train_loss = 0.74146649, grad/param norm = 2.7791e-01, time/batch = 17.8733s	
13385/16650 (epoch 40.195), train_loss = 0.67994207, grad/param norm = 2.8107e-01, time/batch = 18.1052s	
13386/16650 (epoch 40.198), train_loss = 0.64080033, grad/param norm = 2.3210e-01, time/batch = 18.5216s	
13387/16650 (epoch 40.201), train_loss = 0.64693335, grad/param norm = 2.7934e-01, time/batch = 17.1030s	
13388/16650 (epoch 40.204), train_loss = 0.75629492, grad/param norm = 2.8477e-01, time/batch = 18.4440s	
13389/16650 (epoch 40.207), train_loss = 0.78090399, grad/param norm = 3.5533e-01, time/batch = 16.8498s	
13390/16650 (epoch 40.210), train_loss = 0.73997523, grad/param norm = 3.1440e-01, time/batch = 17.1883s	
13391/16650 (epoch 40.213), train_loss = 0.79017980, grad/param norm = 2.8241e-01, time/batch = 19.3649s	
13392/16650 (epoch 40.216), train_loss = 0.67763751, grad/param norm = 2.8811e-01, time/batch = 15.8283s	
13393/16650 (epoch 40.219), train_loss = 0.72858724, grad/param norm = 3.0753e-01, time/batch = 18.7709s	
13394/16650 (epoch 40.222), train_loss = 0.75063315, grad/param norm = 2.5190e-01, time/batch = 17.2718s	
13395/16650 (epoch 40.225), train_loss = 0.76525976, grad/param norm = 3.7112e-01, time/batch = 17.4374s	
13396/16650 (epoch 40.228), train_loss = 0.68752315, grad/param norm = 2.9876e-01, time/batch = 17.6156s	
13397/16650 (epoch 40.231), train_loss = 0.67324614, grad/param norm = 3.3058e-01, time/batch = 15.5689s	
13398/16650 (epoch 40.234), train_loss = 0.88486597, grad/param norm = 3.4802e-01, time/batch = 17.7721s	
13399/16650 (epoch 40.237), train_loss = 0.76062084, grad/param norm = 3.2027e-01, time/batch = 16.6802s	
13400/16650 (epoch 40.240), train_loss = 0.75271206, grad/param norm = 2.3782e-01, time/batch = 16.9369s	
13401/16650 (epoch 40.243), train_loss = 0.73271955, grad/param norm = 2.9910e-01, time/batch = 16.6211s	
13402/16650 (epoch 40.246), train_loss = 0.84815444, grad/param norm = 3.6023e-01, time/batch = 17.5872s	
13403/16650 (epoch 40.249), train_loss = 0.61975746, grad/param norm = 2.7011e-01, time/batch = 16.4835s	
13404/16650 (epoch 40.252), train_loss = 0.72336824, grad/param norm = 2.8813e-01, time/batch = 18.1956s	
13405/16650 (epoch 40.255), train_loss = 0.77857321, grad/param norm = 2.9645e-01, time/batch = 17.0904s	
13406/16650 (epoch 40.258), train_loss = 0.82380569, grad/param norm = 3.2289e-01, time/batch = 16.6729s	
13407/16650 (epoch 40.261), train_loss = 0.77133451, grad/param norm = 2.7389e-01, time/batch = 18.6058s	
13408/16650 (epoch 40.264), train_loss = 0.67383956, grad/param norm = 2.8321e-01, time/batch = 17.8806s	
13409/16650 (epoch 40.267), train_loss = 0.71729883, grad/param norm = 3.3282e-01, time/batch = 19.3820s	
13410/16650 (epoch 40.270), train_loss = 0.78435673, grad/param norm = 3.0843e-01, time/batch = 28.0960s	
13411/16650 (epoch 40.273), train_loss = 0.83769862, grad/param norm = 3.1180e-01, time/batch = 16.4259s	
13412/16650 (epoch 40.276), train_loss = 0.79128235, grad/param norm = 3.1714e-01, time/batch = 14.0458s	
13413/16650 (epoch 40.279), train_loss = 0.73824531, grad/param norm = 3.0476e-01, time/batch = 17.2694s	
13414/16650 (epoch 40.282), train_loss = 0.68208753, grad/param norm = 2.9031e-01, time/batch = 15.9175s	
13415/16650 (epoch 40.285), train_loss = 0.71501185, grad/param norm = 3.1305e-01, time/batch = 15.7622s	
13416/16650 (epoch 40.288), train_loss = 0.64961727, grad/param norm = 2.8296e-01, time/batch = 15.3282s	
13417/16650 (epoch 40.291), train_loss = 0.54412360, grad/param norm = 2.4802e-01, time/batch = 16.8762s	
13418/16650 (epoch 40.294), train_loss = 0.65791086, grad/param norm = 3.2405e-01, time/batch = 17.2876s	
13419/16650 (epoch 40.297), train_loss = 0.72389470, grad/param norm = 3.2047e-01, time/batch = 16.7746s	
13420/16650 (epoch 40.300), train_loss = 0.57510623, grad/param norm = 2.3154e-01, time/batch = 14.5078s	
13421/16650 (epoch 40.303), train_loss = 0.61949805, grad/param norm = 2.3291e-01, time/batch = 16.9303s	
13422/16650 (epoch 40.306), train_loss = 0.79862334, grad/param norm = 2.6950e-01, time/batch = 16.5248s	
13423/16650 (epoch 40.309), train_loss = 0.79425371, grad/param norm = 3.3092e-01, time/batch = 15.9872s	
13424/16650 (epoch 40.312), train_loss = 0.61801110, grad/param norm = 3.0575e-01, time/batch = 17.2747s	
13425/16650 (epoch 40.315), train_loss = 0.51537726, grad/param norm = 2.0303e-01, time/batch = 16.6976s	
13426/16650 (epoch 40.318), train_loss = 0.61210049, grad/param norm = 2.7698e-01, time/batch = 18.0279s	
13427/16650 (epoch 40.321), train_loss = 0.81067113, grad/param norm = 4.1473e-01, time/batch = 15.8752s	
13428/16650 (epoch 40.324), train_loss = 0.67224933, grad/param norm = 4.7989e-01, time/batch = 16.9473s	
13429/16650 (epoch 40.327), train_loss = 0.78242356, grad/param norm = 4.5059e-01, time/batch = 17.5570s	
13430/16650 (epoch 40.330), train_loss = 0.75388150, grad/param norm = 3.8716e-01, time/batch = 16.4524s	
13431/16650 (epoch 40.333), train_loss = 0.79618903, grad/param norm = 3.3494e-01, time/batch = 15.8552s	
13432/16650 (epoch 40.336), train_loss = 0.64287335, grad/param norm = 3.2988e-01, time/batch = 17.2075s	
13433/16650 (epoch 40.339), train_loss = 0.67085844, grad/param norm = 3.1234e-01, time/batch = 18.2857s	
13434/16650 (epoch 40.342), train_loss = 0.62580888, grad/param norm = 3.1523e-01, time/batch = 16.1662s	
13435/16650 (epoch 40.345), train_loss = 0.65757010, grad/param norm = 2.5767e-01, time/batch = 17.0209s	
13436/16650 (epoch 40.348), train_loss = 0.75465630, grad/param norm = 3.1913e-01, time/batch = 16.6798s	
13437/16650 (epoch 40.351), train_loss = 0.75647633, grad/param norm = 3.3713e-01, time/batch = 13.6219s	
13438/16650 (epoch 40.354), train_loss = 0.78414156, grad/param norm = 3.0990e-01, time/batch = 13.9116s	
13439/16650 (epoch 40.357), train_loss = 0.76069398, grad/param norm = 3.4850e-01, time/batch = 13.3756s	
13440/16650 (epoch 40.360), train_loss = 0.74920304, grad/param norm = 3.4813e-01, time/batch = 15.8688s	
13441/16650 (epoch 40.363), train_loss = 0.81792239, grad/param norm = 3.6979e-01, time/batch = 17.1915s	
13442/16650 (epoch 40.366), train_loss = 0.86266575, grad/param norm = 3.2745e-01, time/batch = 16.3546s	
13443/16650 (epoch 40.369), train_loss = 0.77446830, grad/param norm = 3.0481e-01, time/batch = 17.8621s	
13444/16650 (epoch 40.372), train_loss = 0.73189796, grad/param norm = 2.7157e-01, time/batch = 17.8660s	
13445/16650 (epoch 40.375), train_loss = 0.74625659, grad/param norm = 2.6438e-01, time/batch = 15.9296s	
13446/16650 (epoch 40.378), train_loss = 0.70041980, grad/param norm = 2.8035e-01, time/batch = 17.6824s	
13447/16650 (epoch 40.381), train_loss = 0.77917990, grad/param norm = 3.1115e-01, time/batch = 16.3598s	
13448/16650 (epoch 40.384), train_loss = 0.85970514, grad/param norm = 3.0885e-01, time/batch = 16.4279s	
13449/16650 (epoch 40.387), train_loss = 0.58430602, grad/param norm = 2.6070e-01, time/batch = 16.6952s	
13450/16650 (epoch 40.390), train_loss = 0.78588270, grad/param norm = 2.8802e-01, time/batch = 16.9213s	
13451/16650 (epoch 40.393), train_loss = 0.72547867, grad/param norm = 3.7938e-01, time/batch = 16.6130s	
13452/16650 (epoch 40.396), train_loss = 0.86775759, grad/param norm = 4.4536e-01, time/batch = 16.2652s	
13453/16650 (epoch 40.399), train_loss = 0.80388577, grad/param norm = 2.8883e-01, time/batch = 17.5416s	
13454/16650 (epoch 40.402), train_loss = 0.71041722, grad/param norm = 2.8019e-01, time/batch = 14.7234s	
13455/16650 (epoch 40.405), train_loss = 0.57967109, grad/param norm = 2.9684e-01, time/batch = 17.3836s	
13456/16650 (epoch 40.408), train_loss = 0.76998456, grad/param norm = 2.9495e-01, time/batch = 17.1770s	
13457/16650 (epoch 40.411), train_loss = 0.66826396, grad/param norm = 3.2200e-01, time/batch = 16.9698s	
13458/16650 (epoch 40.414), train_loss = 0.64613411, grad/param norm = 3.1678e-01, time/batch = 16.7861s	
13459/16650 (epoch 40.417), train_loss = 0.64093469, grad/param norm = 3.3023e-01, time/batch = 15.3166s	
13460/16650 (epoch 40.420), train_loss = 0.66625092, grad/param norm = 3.1156e-01, time/batch = 17.0292s	
13461/16650 (epoch 40.423), train_loss = 0.55533564, grad/param norm = 2.6666e-01, time/batch = 17.0135s	
13462/16650 (epoch 40.426), train_loss = 0.65710631, grad/param norm = 3.5365e-01, time/batch = 17.3770s	
13463/16650 (epoch 40.429), train_loss = 0.80171265, grad/param norm = 3.2756e-01, time/batch = 15.9218s	
13464/16650 (epoch 40.432), train_loss = 0.79674748, grad/param norm = 3.3718e-01, time/batch = 14.4981s	
13465/16650 (epoch 40.435), train_loss = 0.90364496, grad/param norm = 3.1459e-01, time/batch = 17.6904s	
13466/16650 (epoch 40.438), train_loss = 0.89094663, grad/param norm = 4.2174e-01, time/batch = 17.1875s	
13467/16650 (epoch 40.441), train_loss = 0.69815799, grad/param norm = 3.4774e-01, time/batch = 15.3164s	
13468/16650 (epoch 40.444), train_loss = 0.68303454, grad/param norm = 3.4146e-01, time/batch = 16.1796s	
13469/16650 (epoch 40.447), train_loss = 0.68750897, grad/param norm = 3.6052e-01, time/batch = 16.4358s	
13470/16650 (epoch 40.450), train_loss = 0.67928766, grad/param norm = 3.0593e-01, time/batch = 16.4406s	
13471/16650 (epoch 40.453), train_loss = 0.67025531, grad/param norm = 2.8223e-01, time/batch = 16.7798s	
13472/16650 (epoch 40.456), train_loss = 0.63982707, grad/param norm = 2.6337e-01, time/batch = 17.2766s	
13473/16650 (epoch 40.459), train_loss = 0.66810639, grad/param norm = 3.1642e-01, time/batch = 17.6079s	
13474/16650 (epoch 40.462), train_loss = 0.80241634, grad/param norm = 3.3740e-01, time/batch = 16.9999s	
13475/16650 (epoch 40.465), train_loss = 0.67542161, grad/param norm = 2.7649e-01, time/batch = 15.7741s	
13476/16650 (epoch 40.468), train_loss = 0.56652242, grad/param norm = 2.7653e-01, time/batch = 14.7425s	
13477/16650 (epoch 40.471), train_loss = 0.48102636, grad/param norm = 2.3291e-01, time/batch = 16.6684s	
13478/16650 (epoch 40.474), train_loss = 0.62693461, grad/param norm = 2.9177e-01, time/batch = 17.0247s	
13479/16650 (epoch 40.477), train_loss = 0.78004635, grad/param norm = 3.3853e-01, time/batch = 16.9589s	
13480/16650 (epoch 40.480), train_loss = 0.70511584, grad/param norm = 3.7222e-01, time/batch = 17.3625s	
13481/16650 (epoch 40.483), train_loss = 0.78720018, grad/param norm = 3.3429e-01, time/batch = 16.0813s	
13482/16650 (epoch 40.486), train_loss = 0.62835257, grad/param norm = 2.5336e-01, time/batch = 15.7600s	
13483/16650 (epoch 40.489), train_loss = 0.71195008, grad/param norm = 3.2683e-01, time/batch = 15.7725s	
13484/16650 (epoch 40.492), train_loss = 0.71109956, grad/param norm = 2.8015e-01, time/batch = 16.5087s	
13485/16650 (epoch 40.495), train_loss = 0.60283432, grad/param norm = 2.8474e-01, time/batch = 16.5980s	
13486/16650 (epoch 40.498), train_loss = 0.67835848, grad/param norm = 3.9309e-01, time/batch = 17.2048s	
13487/16650 (epoch 40.502), train_loss = 0.85396341, grad/param norm = 3.4565e-01, time/batch = 17.9626s	
13488/16650 (epoch 40.505), train_loss = 0.75731984, grad/param norm = 2.9088e-01, time/batch = 16.0097s	
13489/16650 (epoch 40.508), train_loss = 0.78847070, grad/param norm = 4.1518e-01, time/batch = 17.1135s	
13490/16650 (epoch 40.511), train_loss = 0.78522272, grad/param norm = 3.3258e-01, time/batch = 16.1350s	
13491/16650 (epoch 40.514), train_loss = 0.63142722, grad/param norm = 2.8586e-01, time/batch = 16.6835s	
13492/16650 (epoch 40.517), train_loss = 0.70354364, grad/param norm = 3.1862e-01, time/batch = 17.1652s	
13493/16650 (epoch 40.520), train_loss = 0.61012436, grad/param norm = 2.9102e-01, time/batch = 18.1130s	
13494/16650 (epoch 40.523), train_loss = 0.71048387, grad/param norm = 2.7910e-01, time/batch = 16.7796s	
13495/16650 (epoch 40.526), train_loss = 0.79271190, grad/param norm = 3.8110e-01, time/batch = 16.6131s	
13496/16650 (epoch 40.529), train_loss = 0.81957947, grad/param norm = 3.6776e-01, time/batch = 14.1688s	
13497/16650 (epoch 40.532), train_loss = 0.55243710, grad/param norm = 2.9732e-01, time/batch = 18.0318s	
13498/16650 (epoch 40.535), train_loss = 0.62404848, grad/param norm = 3.0700e-01, time/batch = 16.4479s	
13499/16650 (epoch 40.538), train_loss = 0.57581202, grad/param norm = 3.0204e-01, time/batch = 15.3361s	
13500/16650 (epoch 40.541), train_loss = 0.82612643, grad/param norm = 3.2285e-01, time/batch = 16.8553s	
13501/16650 (epoch 40.544), train_loss = 0.84699213, grad/param norm = 3.6588e-01, time/batch = 18.2940s	
13502/16650 (epoch 40.547), train_loss = 0.60680771, grad/param norm = 2.9526e-01, time/batch = 16.4383s	
13503/16650 (epoch 40.550), train_loss = 0.70357834, grad/param norm = 2.8023e-01, time/batch = 16.3380s	
13504/16650 (epoch 40.553), train_loss = 0.71266793, grad/param norm = 2.9626e-01, time/batch = 18.1183s	
13505/16650 (epoch 40.556), train_loss = 0.65040046, grad/param norm = 3.2024e-01, time/batch = 17.6231s	
13506/16650 (epoch 40.559), train_loss = 0.57412120, grad/param norm = 3.0842e-01, time/batch = 15.9236s	
13507/16650 (epoch 40.562), train_loss = 0.63976971, grad/param norm = 2.9263e-01, time/batch = 17.5316s	
13508/16650 (epoch 40.565), train_loss = 0.56350428, grad/param norm = 2.8858e-01, time/batch = 16.2988s	
13509/16650 (epoch 40.568), train_loss = 0.57355695, grad/param norm = 2.8811e-01, time/batch = 15.5869s	
13510/16650 (epoch 40.571), train_loss = 0.61356068, grad/param norm = 3.1353e-01, time/batch = 15.9291s	
13511/16650 (epoch 40.574), train_loss = 0.63822821, grad/param norm = 3.2882e-01, time/batch = 16.0914s	
13512/16650 (epoch 40.577), train_loss = 0.67500792, grad/param norm = 2.7372e-01, time/batch = 16.9293s	
13513/16650 (epoch 40.580), train_loss = 0.62154032, grad/param norm = 2.6695e-01, time/batch = 15.8628s	
13514/16650 (epoch 40.583), train_loss = 0.71939064, grad/param norm = 2.8872e-01, time/batch = 17.7756s	
13515/16650 (epoch 40.586), train_loss = 0.62653259, grad/param norm = 3.4064e-01, time/batch = 16.9402s	
13516/16650 (epoch 40.589), train_loss = 0.61651896, grad/param norm = 2.7596e-01, time/batch = 17.6247s	
13517/16650 (epoch 40.592), train_loss = 0.68989953, grad/param norm = 2.5826e-01, time/batch = 15.1644s	
13518/16650 (epoch 40.595), train_loss = 0.64751689, grad/param norm = 3.0653e-01, time/batch = 17.6138s	
13519/16650 (epoch 40.598), train_loss = 0.66289124, grad/param norm = 3.0681e-01, time/batch = 15.2455s	
13520/16650 (epoch 40.601), train_loss = 0.65058345, grad/param norm = 3.1196e-01, time/batch = 16.5178s	
13521/16650 (epoch 40.604), train_loss = 0.69876706, grad/param norm = 3.0473e-01, time/batch = 16.4117s	
13522/16650 (epoch 40.607), train_loss = 0.75368363, grad/param norm = 3.1876e-01, time/batch = 17.5539s	
13523/16650 (epoch 40.610), train_loss = 0.62801530, grad/param norm = 2.7074e-01, time/batch = 16.4553s	
13524/16650 (epoch 40.613), train_loss = 0.78518600, grad/param norm = 2.8842e-01, time/batch = 16.2805s	
13525/16650 (epoch 40.616), train_loss = 0.75984075, grad/param norm = 3.7365e-01, time/batch = 16.4316s	
13526/16650 (epoch 40.619), train_loss = 0.58903442, grad/param norm = 2.5484e-01, time/batch = 17.6130s	
13527/16650 (epoch 40.622), train_loss = 0.57191909, grad/param norm = 2.6126e-01, time/batch = 15.5253s	
13528/16650 (epoch 40.625), train_loss = 0.68047274, grad/param norm = 2.8705e-01, time/batch = 17.7760s	
13529/16650 (epoch 40.628), train_loss = 0.64921009, grad/param norm = 3.6874e-01, time/batch = 17.1728s	
13530/16650 (epoch 40.631), train_loss = 0.69751096, grad/param norm = 3.0768e-01, time/batch = 16.8690s	
13531/16650 (epoch 40.634), train_loss = 0.86967857, grad/param norm = 3.3820e-01, time/batch = 15.8331s	
13532/16650 (epoch 40.637), train_loss = 0.82645724, grad/param norm = 3.0710e-01, time/batch = 17.8668s	
13533/16650 (epoch 40.640), train_loss = 0.67396849, grad/param norm = 2.8321e-01, time/batch = 16.2806s	
13534/16650 (epoch 40.643), train_loss = 0.76155474, grad/param norm = 2.9648e-01, time/batch = 16.9465s	
13535/16650 (epoch 40.646), train_loss = 0.74108802, grad/param norm = 3.1784e-01, time/batch = 16.7388s	
13536/16650 (epoch 40.649), train_loss = 0.74780957, grad/param norm = 3.6570e-01, time/batch = 17.6045s	
13537/16650 (epoch 40.652), train_loss = 0.74491853, grad/param norm = 3.0245e-01, time/batch = 17.1347s	
13538/16650 (epoch 40.655), train_loss = 0.70867384, grad/param norm = 3.3140e-01, time/batch = 15.6110s	
13539/16650 (epoch 40.658), train_loss = 0.65099972, grad/param norm = 3.1711e-01, time/batch = 14.3214s	
13540/16650 (epoch 40.661), train_loss = 0.71476990, grad/param norm = 3.0136e-01, time/batch = 17.7088s	
13541/16650 (epoch 40.664), train_loss = 0.70564978, grad/param norm = 3.1844e-01, time/batch = 17.9511s	
13542/16650 (epoch 40.667), train_loss = 0.79797622, grad/param norm = 3.0316e-01, time/batch = 15.8428s	
13543/16650 (epoch 40.670), train_loss = 0.58964168, grad/param norm = 2.6597e-01, time/batch = 17.5276s	
13544/16650 (epoch 40.673), train_loss = 0.63409690, grad/param norm = 2.9100e-01, time/batch = 17.8655s	
13545/16650 (epoch 40.676), train_loss = 0.75748126, grad/param norm = 3.0060e-01, time/batch = 15.6814s	
13546/16650 (epoch 40.679), train_loss = 0.64064762, grad/param norm = 2.6802e-01, time/batch = 15.0679s	
13547/16650 (epoch 40.682), train_loss = 0.67862011, grad/param norm = 2.9688e-01, time/batch = 17.2715s	
13548/16650 (epoch 40.685), train_loss = 0.58188268, grad/param norm = 2.7895e-01, time/batch = 17.4615s	
13549/16650 (epoch 40.688), train_loss = 0.75612851, grad/param norm = 3.0738e-01, time/batch = 15.5102s	
13550/16650 (epoch 40.691), train_loss = 0.71072772, grad/param norm = 2.8053e-01, time/batch = 17.5383s	
13551/16650 (epoch 40.694), train_loss = 0.64783793, grad/param norm = 3.0575e-01, time/batch = 17.2089s	
13552/16650 (epoch 40.697), train_loss = 0.59560049, grad/param norm = 2.4121e-01, time/batch = 16.5039s	
13553/16650 (epoch 40.700), train_loss = 0.73231091, grad/param norm = 3.1493e-01, time/batch = 16.6908s	
13554/16650 (epoch 40.703), train_loss = 0.62044559, grad/param norm = 3.0544e-01, time/batch = 17.1179s	
13555/16650 (epoch 40.706), train_loss = 0.68180078, grad/param norm = 3.2852e-01, time/batch = 18.1180s	
13556/16650 (epoch 40.709), train_loss = 0.61287394, grad/param norm = 3.3078e-01, time/batch = 16.2562s	
13557/16650 (epoch 40.712), train_loss = 0.63788865, grad/param norm = 3.2390e-01, time/batch = 14.8248s	
13558/16650 (epoch 40.715), train_loss = 0.73245871, grad/param norm = 3.5538e-01, time/batch = 16.1012s	
13559/16650 (epoch 40.718), train_loss = 0.76323902, grad/param norm = 3.3451e-01, time/batch = 17.6945s	
13560/16650 (epoch 40.721), train_loss = 0.79170126, grad/param norm = 3.0032e-01, time/batch = 17.0114s	
13561/16650 (epoch 40.724), train_loss = 0.76689327, grad/param norm = 3.7377e-01, time/batch = 18.2937s	
13562/16650 (epoch 40.727), train_loss = 0.77232743, grad/param norm = 3.1212e-01, time/batch = 15.0046s	
13563/16650 (epoch 40.730), train_loss = 0.63849235, grad/param norm = 2.8590e-01, time/batch = 15.9148s	
13564/16650 (epoch 40.733), train_loss = 0.79843209, grad/param norm = 3.2921e-01, time/batch = 17.6923s	
13565/16650 (epoch 40.736), train_loss = 0.58855716, grad/param norm = 3.0360e-01, time/batch = 15.4322s	
13566/16650 (epoch 40.739), train_loss = 0.70585282, grad/param norm = 3.0209e-01, time/batch = 16.9314s	
13567/16650 (epoch 40.742), train_loss = 0.71109766, grad/param norm = 2.7211e-01, time/batch = 15.5075s	
13568/16650 (epoch 40.745), train_loss = 0.55644514, grad/param norm = 2.9546e-01, time/batch = 17.0498s	
13569/16650 (epoch 40.748), train_loss = 0.59444281, grad/param norm = 2.9223e-01, time/batch = 16.4541s	
13570/16650 (epoch 40.751), train_loss = 0.71316979, grad/param norm = 3.8528e-01, time/batch = 17.0947s	
13571/16650 (epoch 40.754), train_loss = 0.86915040, grad/param norm = 3.9083e-01, time/batch = 15.5796s	
13572/16650 (epoch 40.757), train_loss = 0.83942951, grad/param norm = 3.1610e-01, time/batch = 18.2053s	
13573/16650 (epoch 40.760), train_loss = 0.70788132, grad/param norm = 3.2670e-01, time/batch = 17.0996s	
13574/16650 (epoch 40.763), train_loss = 0.66324535, grad/param norm = 2.8490e-01, time/batch = 16.2803s	
13575/16650 (epoch 40.766), train_loss = 0.69247394, grad/param norm = 3.0525e-01, time/batch = 17.3509s	
13576/16650 (epoch 40.769), train_loss = 0.72983408, grad/param norm = 2.8882e-01, time/batch = 16.2699s	
13577/16650 (epoch 40.772), train_loss = 0.70653340, grad/param norm = 2.5434e-01, time/batch = 16.6073s	
13578/16650 (epoch 40.775), train_loss = 0.69753747, grad/param norm = 2.8254e-01, time/batch = 15.5086s	
13579/16650 (epoch 40.778), train_loss = 0.72160423, grad/param norm = 2.7739e-01, time/batch = 17.3493s	
13580/16650 (epoch 40.781), train_loss = 0.85724051, grad/param norm = 3.0018e-01, time/batch = 15.2772s	
13581/16650 (epoch 40.784), train_loss = 0.71923597, grad/param norm = 3.1170e-01, time/batch = 16.1873s	
13582/16650 (epoch 40.787), train_loss = 0.77714966, grad/param norm = 3.0725e-01, time/batch = 16.0021s	
13583/16650 (epoch 40.790), train_loss = 0.80284431, grad/param norm = 3.1040e-01, time/batch = 15.9020s	
13584/16650 (epoch 40.793), train_loss = 0.59759311, grad/param norm = 2.6128e-01, time/batch = 17.2142s	
13585/16650 (epoch 40.796), train_loss = 0.93371866, grad/param norm = 3.6249e-01, time/batch = 15.5151s	
13586/16650 (epoch 40.799), train_loss = 0.84834413, grad/param norm = 3.8314e-01, time/batch = 17.1939s	
13587/16650 (epoch 40.802), train_loss = 0.76901292, grad/param norm = 2.9214e-01, time/batch = 18.0310s	
13588/16650 (epoch 40.805), train_loss = 0.73773300, grad/param norm = 3.0306e-01, time/batch = 17.0076s	
13589/16650 (epoch 40.808), train_loss = 0.78700914, grad/param norm = 2.9296e-01, time/batch = 16.1070s	
13590/16650 (epoch 40.811), train_loss = 0.82262850, grad/param norm = 3.3385e-01, time/batch = 17.1818s	
13591/16650 (epoch 40.814), train_loss = 0.65786677, grad/param norm = 2.8852e-01, time/batch = 18.5206s	
13592/16650 (epoch 40.817), train_loss = 0.65962135, grad/param norm = 2.9650e-01, time/batch = 16.9276s	
13593/16650 (epoch 40.820), train_loss = 0.78288235, grad/param norm = 3.3288e-01, time/batch = 14.9086s	
13594/16650 (epoch 40.823), train_loss = 0.73820395, grad/param norm = 2.7963e-01, time/batch = 16.5644s	
13595/16650 (epoch 40.826), train_loss = 0.67667316, grad/param norm = 2.8324e-01, time/batch = 17.5951s	
13596/16650 (epoch 40.829), train_loss = 0.72063565, grad/param norm = 3.4013e-01, time/batch = 18.0233s	
13597/16650 (epoch 40.832), train_loss = 0.77709966, grad/param norm = 3.0159e-01, time/batch = 18.3597s	
13598/16650 (epoch 40.835), train_loss = 0.78665009, grad/param norm = 3.9206e-01, time/batch = 18.8586s	
13599/16650 (epoch 40.838), train_loss = 0.63542707, grad/param norm = 2.6510e-01, time/batch = 15.9949s	
13600/16650 (epoch 40.841), train_loss = 0.66298331, grad/param norm = 2.7888e-01, time/batch = 18.3591s	
13601/16650 (epoch 40.844), train_loss = 0.68563614, grad/param norm = 2.6779e-01, time/batch = 15.5741s	
13602/16650 (epoch 40.847), train_loss = 0.76721311, grad/param norm = 2.9114e-01, time/batch = 16.5019s	
13603/16650 (epoch 40.850), train_loss = 0.64956459, grad/param norm = 3.2208e-01, time/batch = 18.0416s	
13604/16650 (epoch 40.853), train_loss = 0.69378535, grad/param norm = 3.0899e-01, time/batch = 18.7056s	
13605/16650 (epoch 40.856), train_loss = 0.66060326, grad/param norm = 2.5766e-01, time/batch = 17.4625s	
13606/16650 (epoch 40.859), train_loss = 0.79933475, grad/param norm = 3.5199e-01, time/batch = 17.2481s	
13607/16650 (epoch 40.862), train_loss = 0.72020478, grad/param norm = 2.9973e-01, time/batch = 18.2677s	
13608/16650 (epoch 40.865), train_loss = 0.58119700, grad/param norm = 2.5834e-01, time/batch = 16.6750s	
13609/16650 (epoch 40.868), train_loss = 0.72121094, grad/param norm = 2.9500e-01, time/batch = 16.4308s	
13610/16650 (epoch 40.871), train_loss = 0.74674251, grad/param norm = 2.9724e-01, time/batch = 17.1980s	
13611/16650 (epoch 40.874), train_loss = 0.72637205, grad/param norm = 2.7372e-01, time/batch = 15.7684s	
13612/16650 (epoch 40.877), train_loss = 0.70366943, grad/param norm = 2.6926e-01, time/batch = 18.3783s	
13613/16650 (epoch 40.880), train_loss = 0.64649030, grad/param norm = 3.2103e-01, time/batch = 17.2595s	
13614/16650 (epoch 40.883), train_loss = 0.72990518, grad/param norm = 2.9253e-01, time/batch = 18.1107s	
13615/16650 (epoch 40.886), train_loss = 0.72537758, grad/param norm = 3.0235e-01, time/batch = 15.4936s	
13616/16650 (epoch 40.889), train_loss = 0.61548289, grad/param norm = 3.2462e-01, time/batch = 17.6548s	
13617/16650 (epoch 40.892), train_loss = 0.72598516, grad/param norm = 2.8481e-01, time/batch = 16.9315s	
13618/16650 (epoch 40.895), train_loss = 0.73683174, grad/param norm = 3.0480e-01, time/batch = 18.5991s	
13619/16650 (epoch 40.898), train_loss = 0.72843497, grad/param norm = 3.5228e-01, time/batch = 17.5962s	
13620/16650 (epoch 40.901), train_loss = 0.65594519, grad/param norm = 2.8332e-01, time/batch = 18.0278s	
13621/16650 (epoch 40.904), train_loss = 0.66499835, grad/param norm = 3.2424e-01, time/batch = 17.5280s	
13622/16650 (epoch 40.907), train_loss = 0.72530391, grad/param norm = 3.0202e-01, time/batch = 18.2814s	
13623/16650 (epoch 40.910), train_loss = 0.74663997, grad/param norm = 3.2302e-01, time/batch = 30.2371s	
13624/16650 (epoch 40.913), train_loss = 0.66624969, grad/param norm = 2.7646e-01, time/batch = 17.0211s	
13625/16650 (epoch 40.916), train_loss = 0.63868952, grad/param norm = 2.8753e-01, time/batch = 17.0319s	
13626/16650 (epoch 40.919), train_loss = 0.83428833, grad/param norm = 2.9923e-01, time/batch = 15.4194s	
13627/16650 (epoch 40.922), train_loss = 0.72347246, grad/param norm = 3.5383e-01, time/batch = 14.8590s	
13628/16650 (epoch 40.925), train_loss = 0.65841469, grad/param norm = 2.6539e-01, time/batch = 17.3673s	
13629/16650 (epoch 40.928), train_loss = 0.71936458, grad/param norm = 2.9431e-01, time/batch = 14.3193s	
13630/16650 (epoch 40.931), train_loss = 0.73010658, grad/param norm = 3.0421e-01, time/batch = 16.6091s	
13631/16650 (epoch 40.934), train_loss = 0.58937197, grad/param norm = 2.9297e-01, time/batch = 17.8702s	
13632/16650 (epoch 40.937), train_loss = 0.64389239, grad/param norm = 3.3612e-01, time/batch = 17.5377s	
13633/16650 (epoch 40.940), train_loss = 0.71070917, grad/param norm = 3.0156e-01, time/batch = 14.8394s	
13634/16650 (epoch 40.943), train_loss = 0.72501300, grad/param norm = 3.4193e-01, time/batch = 14.9827s	
13635/16650 (epoch 40.946), train_loss = 0.68187108, grad/param norm = 3.7743e-01, time/batch = 16.5154s	
13636/16650 (epoch 40.949), train_loss = 0.61672328, grad/param norm = 2.9403e-01, time/batch = 17.2097s	
13637/16650 (epoch 40.952), train_loss = 0.61082876, grad/param norm = 3.1110e-01, time/batch = 16.5752s	
13638/16650 (epoch 40.955), train_loss = 0.70676021, grad/param norm = 2.6404e-01, time/batch = 17.5315s	
13639/16650 (epoch 40.958), train_loss = 0.76324496, grad/param norm = 3.3395e-01, time/batch = 17.7901s	
13640/16650 (epoch 40.961), train_loss = 0.67901750, grad/param norm = 2.4324e-01, time/batch = 15.3306s	
13641/16650 (epoch 40.964), train_loss = 0.60833279, grad/param norm = 3.0052e-01, time/batch = 17.6174s	
13642/16650 (epoch 40.967), train_loss = 0.83029451, grad/param norm = 3.2303e-01, time/batch = 17.9580s	
13643/16650 (epoch 40.970), train_loss = 0.66445698, grad/param norm = 2.7461e-01, time/batch = 17.4474s	
13644/16650 (epoch 40.973), train_loss = 0.65082998, grad/param norm = 2.8832e-01, time/batch = 15.2551s	
13645/16650 (epoch 40.976), train_loss = 0.65114188, grad/param norm = 3.1932e-01, time/batch = 17.8777s	
13646/16650 (epoch 40.979), train_loss = 0.73999359, grad/param norm = 3.1715e-01, time/batch = 17.7799s	
13647/16650 (epoch 40.982), train_loss = 0.75009527, grad/param norm = 3.1297e-01, time/batch = 15.2283s	
13648/16650 (epoch 40.985), train_loss = 0.70655104, grad/param norm = 2.7325e-01, time/batch = 17.0233s	
13649/16650 (epoch 40.988), train_loss = 0.74595853, grad/param norm = 3.6265e-01, time/batch = 17.8706s	
13650/16650 (epoch 40.991), train_loss = 0.64675290, grad/param norm = 3.3258e-01, time/batch = 15.6802s	
13651/16650 (epoch 40.994), train_loss = 0.65525115, grad/param norm = 2.8318e-01, time/batch = 14.9995s	
13652/16650 (epoch 40.997), train_loss = 0.66767091, grad/param norm = 3.0762e-01, time/batch = 15.2599s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
13653/16650 (epoch 41.000), train_loss = 0.77516104, grad/param norm = 3.7992e-01, time/batch = 17.5267s	
13654/16650 (epoch 41.003), train_loss = 0.82237127, grad/param norm = 3.6087e-01, time/batch = 16.6036s	
13655/16650 (epoch 41.006), train_loss = 0.80728398, grad/param norm = 3.4972e-01, time/batch = 17.1932s	
13656/16650 (epoch 41.009), train_loss = 0.81778139, grad/param norm = 3.2211e-01, time/batch = 15.2075s	
13657/16650 (epoch 41.012), train_loss = 0.80980285, grad/param norm = 3.2252e-01, time/batch = 17.7857s	
13658/16650 (epoch 41.015), train_loss = 0.70964290, grad/param norm = 2.8892e-01, time/batch = 15.0101s	
13659/16650 (epoch 41.018), train_loss = 0.63763383, grad/param norm = 3.0369e-01, time/batch = 17.6191s	
13660/16650 (epoch 41.021), train_loss = 0.83248176, grad/param norm = 3.4428e-01, time/batch = 15.8110s	
13661/16650 (epoch 41.024), train_loss = 0.71654332, grad/param norm = 3.0991e-01, time/batch = 17.7025s	
13662/16650 (epoch 41.027), train_loss = 0.75190903, grad/param norm = 2.9936e-01, time/batch = 16.6775s	
13663/16650 (epoch 41.030), train_loss = 0.62209214, grad/param norm = 3.1691e-01, time/batch = 16.9540s	
13664/16650 (epoch 41.033), train_loss = 0.69660249, grad/param norm = 2.5959e-01, time/batch = 15.2736s	
13665/16650 (epoch 41.036), train_loss = 0.52467373, grad/param norm = 3.8699e-01, time/batch = 16.1831s	
13666/16650 (epoch 41.039), train_loss = 0.82083260, grad/param norm = 2.8097e-01, time/batch = 16.1876s	
13667/16650 (epoch 41.042), train_loss = 0.74861289, grad/param norm = 3.3718e-01, time/batch = 17.6934s	
13668/16650 (epoch 41.045), train_loss = 0.70866470, grad/param norm = 2.8660e-01, time/batch = 16.1798s	
13669/16650 (epoch 41.048), train_loss = 0.79810561, grad/param norm = 3.1243e-01, time/batch = 16.6543s	
13670/16650 (epoch 41.051), train_loss = 0.69819098, grad/param norm = 3.0563e-01, time/batch = 17.7744s	
13671/16650 (epoch 41.054), train_loss = 0.69810868, grad/param norm = 2.9424e-01, time/batch = 17.3570s	
13672/16650 (epoch 41.057), train_loss = 0.71115066, grad/param norm = 3.3618e-01, time/batch = 17.1828s	
13673/16650 (epoch 41.060), train_loss = 0.60055824, grad/param norm = 2.4675e-01, time/batch = 17.3549s	
13674/16650 (epoch 41.063), train_loss = 0.66870650, grad/param norm = 2.7525e-01, time/batch = 18.5303s	
13675/16650 (epoch 41.066), train_loss = 0.83653640, grad/param norm = 2.9410e-01, time/batch = 17.9470s	
13676/16650 (epoch 41.069), train_loss = 0.75613644, grad/param norm = 3.1796e-01, time/batch = 16.1520s	
13677/16650 (epoch 41.072), train_loss = 0.72356619, grad/param norm = 3.5623e-01, time/batch = 14.0902s	
13678/16650 (epoch 41.075), train_loss = 0.79274667, grad/param norm = 3.5532e-01, time/batch = 13.7109s	
13679/16650 (epoch 41.078), train_loss = 0.81268782, grad/param norm = 4.0385e-01, time/batch = 13.7202s	
13680/16650 (epoch 41.081), train_loss = 0.74845096, grad/param norm = 3.4754e-01, time/batch = 16.9221s	
13681/16650 (epoch 41.084), train_loss = 0.73761735, grad/param norm = 3.3839e-01, time/batch = 16.8724s	
13682/16650 (epoch 41.087), train_loss = 0.74937748, grad/param norm = 3.0100e-01, time/batch = 19.0327s	
13683/16650 (epoch 41.090), train_loss = 0.72060746, grad/param norm = 3.4797e-01, time/batch = 16.2541s	
13684/16650 (epoch 41.093), train_loss = 0.82591410, grad/param norm = 3.2670e-01, time/batch = 17.4206s	
13685/16650 (epoch 41.096), train_loss = 0.67165555, grad/param norm = 2.9680e-01, time/batch = 17.6951s	
13686/16650 (epoch 41.099), train_loss = 0.74991662, grad/param norm = 4.0215e-01, time/batch = 18.1160s	
13687/16650 (epoch 41.102), train_loss = 0.72269637, grad/param norm = 2.7397e-01, time/batch = 17.2244s	
13688/16650 (epoch 41.105), train_loss = 0.72254364, grad/param norm = 3.2004e-01, time/batch = 17.1083s	
13689/16650 (epoch 41.108), train_loss = 0.75306897, grad/param norm = 3.1550e-01, time/batch = 16.5849s	
13690/16650 (epoch 41.111), train_loss = 0.78937028, grad/param norm = 2.8617e-01, time/batch = 16.9154s	
13691/16650 (epoch 41.114), train_loss = 0.74830000, grad/param norm = 3.8822e-01, time/batch = 18.1073s	
13692/16650 (epoch 41.117), train_loss = 0.85966502, grad/param norm = 3.2321e-01, time/batch = 17.8585s	
13693/16650 (epoch 41.120), train_loss = 0.72769478, grad/param norm = 2.6252e-01, time/batch = 17.7739s	
13694/16650 (epoch 41.123), train_loss = 0.68970087, grad/param norm = 2.8826e-01, time/batch = 16.8290s	
13695/16650 (epoch 41.126), train_loss = 0.76984840, grad/param norm = 3.1592e-01, time/batch = 17.3741s	
13696/16650 (epoch 41.129), train_loss = 0.76485640, grad/param norm = 3.3246e-01, time/batch = 17.8702s	
13697/16650 (epoch 41.132), train_loss = 0.71419094, grad/param norm = 2.9464e-01, time/batch = 15.8359s	
13698/16650 (epoch 41.135), train_loss = 0.82237515, grad/param norm = 3.1238e-01, time/batch = 14.7065s	
13699/16650 (epoch 41.138), train_loss = 0.78866565, grad/param norm = 2.8539e-01, time/batch = 18.5294s	
13700/16650 (epoch 41.141), train_loss = 0.76185990, grad/param norm = 3.4150e-01, time/batch = 17.6076s	
13701/16650 (epoch 41.144), train_loss = 0.77736023, grad/param norm = 3.7754e-01, time/batch = 17.5266s	
13702/16650 (epoch 41.147), train_loss = 0.84872850, grad/param norm = 3.0662e-01, time/batch = 18.1729s	
13703/16650 (epoch 41.150), train_loss = 0.90990952, grad/param norm = 3.5568e-01, time/batch = 16.0970s	
13704/16650 (epoch 41.153), train_loss = 0.73198506, grad/param norm = 3.3440e-01, time/batch = 15.8344s	
13705/16650 (epoch 41.156), train_loss = 0.71601318, grad/param norm = 2.8279e-01, time/batch = 18.1034s	
13706/16650 (epoch 41.159), train_loss = 0.78299371, grad/param norm = 3.1528e-01, time/batch = 17.2704s	
13707/16650 (epoch 41.162), train_loss = 0.85295324, grad/param norm = 3.2541e-01, time/batch = 17.6063s	
13708/16650 (epoch 41.165), train_loss = 0.82737058, grad/param norm = 3.2377e-01, time/batch = 17.9474s	
13709/16650 (epoch 41.168), train_loss = 0.62280329, grad/param norm = 2.6049e-01, time/batch = 18.7094s	
13710/16650 (epoch 41.171), train_loss = 0.78088308, grad/param norm = 2.8843e-01, time/batch = 14.6543s	
13711/16650 (epoch 41.174), train_loss = 0.59712616, grad/param norm = 2.9149e-01, time/batch = 15.6586s	
13712/16650 (epoch 41.177), train_loss = 0.73525936, grad/param norm = 3.3192e-01, time/batch = 18.1145s	
13713/16650 (epoch 41.180), train_loss = 0.82451412, grad/param norm = 2.9188e-01, time/batch = 17.8711s	
13714/16650 (epoch 41.183), train_loss = 0.95082723, grad/param norm = 3.3974e-01, time/batch = 17.1430s	
13715/16650 (epoch 41.186), train_loss = 0.74584864, grad/param norm = 2.8774e-01, time/batch = 16.4238s	
13716/16650 (epoch 41.189), train_loss = 0.67479114, grad/param norm = 2.6050e-01, time/batch = 18.4473s	
13717/16650 (epoch 41.192), train_loss = 0.72747915, grad/param norm = 3.0168e-01, time/batch = 18.4426s	
13718/16650 (epoch 41.195), train_loss = 0.66203008, grad/param norm = 2.9306e-01, time/batch = 16.7563s	
13719/16650 (epoch 41.198), train_loss = 0.64590591, grad/param norm = 2.7988e-01, time/batch = 17.6973s	
13720/16650 (epoch 41.201), train_loss = 0.65411885, grad/param norm = 3.0540e-01, time/batch = 15.4202s	
13721/16650 (epoch 41.204), train_loss = 0.72985921, grad/param norm = 2.6335e-01, time/batch = 16.9075s	
13722/16650 (epoch 41.207), train_loss = 0.76057614, grad/param norm = 3.2603e-01, time/batch = 16.5333s	
13723/16650 (epoch 41.210), train_loss = 0.72025564, grad/param norm = 3.0531e-01, time/batch = 17.3718s	
13724/16650 (epoch 41.213), train_loss = 0.77518471, grad/param norm = 3.0545e-01, time/batch = 16.8516s	
13725/16650 (epoch 41.216), train_loss = 0.66082881, grad/param norm = 2.8541e-01, time/batch = 16.3428s	
13726/16650 (epoch 41.219), train_loss = 0.71858118, grad/param norm = 3.2453e-01, time/batch = 18.4212s	
13727/16650 (epoch 41.222), train_loss = 0.74422102, grad/param norm = 2.8177e-01, time/batch = 17.3585s	
13728/16650 (epoch 41.225), train_loss = 0.76996325, grad/param norm = 3.4097e-01, time/batch = 16.9306s	
13729/16650 (epoch 41.228), train_loss = 0.68634633, grad/param norm = 3.1961e-01, time/batch = 17.4300s	
13730/16650 (epoch 41.231), train_loss = 0.64923645, grad/param norm = 3.0644e-01, time/batch = 15.2473s	
13731/16650 (epoch 41.234), train_loss = 0.86527285, grad/param norm = 3.2102e-01, time/batch = 19.1843s	
13732/16650 (epoch 41.237), train_loss = 0.74024535, grad/param norm = 2.8009e-01, time/batch = 17.1672s	
13733/16650 (epoch 41.240), train_loss = 0.74749021, grad/param norm = 2.8258e-01, time/batch = 15.7495s	
13734/16650 (epoch 41.243), train_loss = 0.71267957, grad/param norm = 3.0224e-01, time/batch = 17.9158s	
13735/16650 (epoch 41.246), train_loss = 0.83122352, grad/param norm = 4.0740e-01, time/batch = 16.6006s	
13736/16650 (epoch 41.249), train_loss = 0.61749127, grad/param norm = 2.3248e-01, time/batch = 16.9474s	
13737/16650 (epoch 41.252), train_loss = 0.70722996, grad/param norm = 2.9263e-01, time/batch = 18.7730s	
13738/16650 (epoch 41.255), train_loss = 0.76832299, grad/param norm = 2.9782e-01, time/batch = 18.1865s	
13739/16650 (epoch 41.258), train_loss = 0.79910761, grad/param norm = 3.1722e-01, time/batch = 16.0676s	
13740/16650 (epoch 41.261), train_loss = 0.74990429, grad/param norm = 2.5826e-01, time/batch = 16.1664s	
13741/16650 (epoch 41.264), train_loss = 0.67747429, grad/param norm = 2.8055e-01, time/batch = 16.6049s	
13742/16650 (epoch 41.267), train_loss = 0.69652306, grad/param norm = 3.1320e-01, time/batch = 16.3327s	
13743/16650 (epoch 41.270), train_loss = 0.77952806, grad/param norm = 2.9376e-01, time/batch = 17.4568s	
13744/16650 (epoch 41.273), train_loss = 0.81243834, grad/param norm = 3.0614e-01, time/batch = 18.9291s	
13745/16650 (epoch 41.276), train_loss = 0.78529955, grad/param norm = 3.2924e-01, time/batch = 17.4442s	
13746/16650 (epoch 41.279), train_loss = 0.69581884, grad/param norm = 2.8190e-01, time/batch = 16.2552s	
13747/16650 (epoch 41.282), train_loss = 0.66800856, grad/param norm = 2.9312e-01, time/batch = 18.1112s	
13748/16650 (epoch 41.285), train_loss = 0.70348481, grad/param norm = 2.7529e-01, time/batch = 16.1785s	
13749/16650 (epoch 41.288), train_loss = 0.64815431, grad/param norm = 3.1747e-01, time/batch = 17.3624s	
13750/16650 (epoch 41.291), train_loss = 0.54206095, grad/param norm = 2.4892e-01, time/batch = 17.5160s	
13751/16650 (epoch 41.294), train_loss = 0.65294632, grad/param norm = 2.7382e-01, time/batch = 18.1984s	
13752/16650 (epoch 41.297), train_loss = 0.71085624, grad/param norm = 3.0395e-01, time/batch = 16.9426s	
13753/16650 (epoch 41.300), train_loss = 0.57641779, grad/param norm = 2.5302e-01, time/batch = 15.9354s	
13754/16650 (epoch 41.303), train_loss = 0.61074220, grad/param norm = 2.9394e-01, time/batch = 17.2841s	
13755/16650 (epoch 41.306), train_loss = 0.78689922, grad/param norm = 2.7288e-01, time/batch = 17.8726s	
13756/16650 (epoch 41.309), train_loss = 0.77090489, grad/param norm = 2.7651e-01, time/batch = 17.1022s	
13757/16650 (epoch 41.312), train_loss = 0.60464738, grad/param norm = 3.1208e-01, time/batch = 16.4299s	
13758/16650 (epoch 41.315), train_loss = 0.52023918, grad/param norm = 2.4327e-01, time/batch = 15.0683s	
13759/16650 (epoch 41.318), train_loss = 0.58639586, grad/param norm = 2.5992e-01, time/batch = 15.8546s	
13760/16650 (epoch 41.321), train_loss = 0.78129413, grad/param norm = 3.3169e-01, time/batch = 15.8736s	
13761/16650 (epoch 41.324), train_loss = 0.65635248, grad/param norm = 3.1166e-01, time/batch = 17.0416s	
13762/16650 (epoch 41.327), train_loss = 0.73270242, grad/param norm = 3.2182e-01, time/batch = 16.7234s	
13763/16650 (epoch 41.330), train_loss = 0.75224965, grad/param norm = 3.6220e-01, time/batch = 16.9347s	
13764/16650 (epoch 41.333), train_loss = 0.77581513, grad/param norm = 3.2989e-01, time/batch = 16.7001s	
13765/16650 (epoch 41.336), train_loss = 0.63917371, grad/param norm = 3.2469e-01, time/batch = 16.2913s	
13766/16650 (epoch 41.339), train_loss = 0.65902549, grad/param norm = 3.1594e-01, time/batch = 17.7095s	
13767/16650 (epoch 41.342), train_loss = 0.61775822, grad/param norm = 2.9543e-01, time/batch = 15.9429s	
13768/16650 (epoch 41.345), train_loss = 0.65517852, grad/param norm = 2.7161e-01, time/batch = 16.7045s	
13769/16650 (epoch 41.348), train_loss = 0.73460522, grad/param norm = 3.2706e-01, time/batch = 16.4494s	
13770/16650 (epoch 41.351), train_loss = 0.73682571, grad/param norm = 3.2256e-01, time/batch = 17.0440s	
13771/16650 (epoch 41.354), train_loss = 0.78862176, grad/param norm = 3.3952e-01, time/batch = 16.3644s	
13772/16650 (epoch 41.357), train_loss = 0.75345914, grad/param norm = 3.3261e-01, time/batch = 14.2366s	
13773/16650 (epoch 41.360), train_loss = 0.73401209, grad/param norm = 3.2347e-01, time/batch = 16.7758s	
13774/16650 (epoch 41.363), train_loss = 0.78889415, grad/param norm = 3.9369e-01, time/batch = 16.8628s	
13775/16650 (epoch 41.366), train_loss = 0.86825115, grad/param norm = 3.5035e-01, time/batch = 16.6014s	
13776/16650 (epoch 41.369), train_loss = 0.77537413, grad/param norm = 2.9739e-01, time/batch = 16.3623s	
13777/16650 (epoch 41.372), train_loss = 0.72788870, grad/param norm = 3.1630e-01, time/batch = 16.6062s	
13778/16650 (epoch 41.375), train_loss = 0.73846258, grad/param norm = 2.6460e-01, time/batch = 15.8867s	
13779/16650 (epoch 41.378), train_loss = 0.69855557, grad/param norm = 3.6152e-01, time/batch = 13.7310s	
13780/16650 (epoch 41.381), train_loss = 0.77451987, grad/param norm = 2.9323e-01, time/batch = 14.3138s	
13781/16650 (epoch 41.384), train_loss = 0.83518254, grad/param norm = 3.0431e-01, time/batch = 13.6870s	
13782/16650 (epoch 41.387), train_loss = 0.57082891, grad/param norm = 2.6406e-01, time/batch = 15.4026s	
13783/16650 (epoch 41.390), train_loss = 0.78619710, grad/param norm = 2.9660e-01, time/batch = 17.8585s	
13784/16650 (epoch 41.393), train_loss = 0.70817493, grad/param norm = 3.6004e-01, time/batch = 18.2778s	
13785/16650 (epoch 41.396), train_loss = 0.83743649, grad/param norm = 3.4700e-01, time/batch = 17.1075s	
13786/16650 (epoch 41.399), train_loss = 0.79022421, grad/param norm = 2.9268e-01, time/batch = 17.9439s	
13787/16650 (epoch 41.402), train_loss = 0.70223948, grad/param norm = 2.7551e-01, time/batch = 17.7027s	
13788/16650 (epoch 41.405), train_loss = 0.57134190, grad/param norm = 2.8510e-01, time/batch = 18.1955s	
13789/16650 (epoch 41.408), train_loss = 0.75517557, grad/param norm = 2.9753e-01, time/batch = 14.9784s	
13790/16650 (epoch 41.411), train_loss = 0.65420286, grad/param norm = 3.2664e-01, time/batch = 14.5217s	
13791/16650 (epoch 41.414), train_loss = 0.64205267, grad/param norm = 3.2682e-01, time/batch = 16.0123s	
13792/16650 (epoch 41.417), train_loss = 0.62756543, grad/param norm = 3.1546e-01, time/batch = 18.2893s	
13793/16650 (epoch 41.420), train_loss = 0.66563648, grad/param norm = 3.2636e-01, time/batch = 17.5956s	
13794/16650 (epoch 41.423), train_loss = 0.53285322, grad/param norm = 2.5010e-01, time/batch = 17.6696s	
13795/16650 (epoch 41.426), train_loss = 0.62389365, grad/param norm = 3.0761e-01, time/batch = 16.9379s	
13796/16650 (epoch 41.429), train_loss = 0.78336834, grad/param norm = 3.2866e-01, time/batch = 16.0024s	
13797/16650 (epoch 41.432), train_loss = 0.78550352, grad/param norm = 3.1864e-01, time/batch = 17.5279s	
13798/16650 (epoch 41.435), train_loss = 0.87685876, grad/param norm = 3.3141e-01, time/batch = 17.1222s	
13799/16650 (epoch 41.438), train_loss = 0.85881060, grad/param norm = 3.5933e-01, time/batch = 17.3580s	
13800/16650 (epoch 41.441), train_loss = 0.69632793, grad/param norm = 3.6472e-01, time/batch = 18.2553s	
13801/16650 (epoch 41.444), train_loss = 0.67867837, grad/param norm = 3.0131e-01, time/batch = 16.0176s	
13802/16650 (epoch 41.447), train_loss = 0.66953693, grad/param norm = 3.1066e-01, time/batch = 17.5894s	
13803/16650 (epoch 41.450), train_loss = 0.67738581, grad/param norm = 3.1048e-01, time/batch = 16.2582s	
13804/16650 (epoch 41.453), train_loss = 0.66926686, grad/param norm = 2.8565e-01, time/batch = 17.6924s	
13805/16650 (epoch 41.456), train_loss = 0.62548827, grad/param norm = 2.2826e-01, time/batch = 17.9266s	
13806/16650 (epoch 41.459), train_loss = 0.66201119, grad/param norm = 3.0583e-01, time/batch = 17.1135s	
13807/16650 (epoch 41.462), train_loss = 0.81106588, grad/param norm = 3.9526e-01, time/batch = 18.1954s	
13808/16650 (epoch 41.465), train_loss = 0.66931434, grad/param norm = 3.6861e-01, time/batch = 17.6275s	
13809/16650 (epoch 41.468), train_loss = 0.54976135, grad/param norm = 2.9671e-01, time/batch = 18.7089s	
13810/16650 (epoch 41.471), train_loss = 0.47329568, grad/param norm = 2.4720e-01, time/batch = 17.0105s	
13811/16650 (epoch 41.474), train_loss = 0.62987578, grad/param norm = 3.1105e-01, time/batch = 16.5938s	
13812/16650 (epoch 41.477), train_loss = 0.76700591, grad/param norm = 3.0657e-01, time/batch = 16.7761s	
13813/16650 (epoch 41.480), train_loss = 0.69199270, grad/param norm = 3.4600e-01, time/batch = 14.5560s	
13814/16650 (epoch 41.483), train_loss = 0.76466398, grad/param norm = 3.2610e-01, time/batch = 16.4870s	
13815/16650 (epoch 41.486), train_loss = 0.63319598, grad/param norm = 2.7577e-01, time/batch = 18.1987s	
13816/16650 (epoch 41.489), train_loss = 0.70010566, grad/param norm = 3.2054e-01, time/batch = 18.7044s	
13817/16650 (epoch 41.492), train_loss = 0.71150072, grad/param norm = 3.0409e-01, time/batch = 15.5764s	
13818/16650 (epoch 41.495), train_loss = 0.59808661, grad/param norm = 2.8150e-01, time/batch = 18.7037s	
13819/16650 (epoch 41.498), train_loss = 0.65819313, grad/param norm = 3.4271e-01, time/batch = 18.7037s	
13820/16650 (epoch 41.502), train_loss = 0.85219583, grad/param norm = 3.8055e-01, time/batch = 16.4383s	
13821/16650 (epoch 41.505), train_loss = 0.73596754, grad/param norm = 2.7175e-01, time/batch = 17.2042s	
13822/16650 (epoch 41.508), train_loss = 0.76600417, grad/param norm = 3.4519e-01, time/batch = 18.4436s	
13823/16650 (epoch 41.511), train_loss = 0.76244016, grad/param norm = 2.9634e-01, time/batch = 18.1905s	
13824/16650 (epoch 41.514), train_loss = 0.60970026, grad/param norm = 2.9466e-01, time/batch = 15.2488s	
13825/16650 (epoch 41.517), train_loss = 0.68302728, grad/param norm = 3.1542e-01, time/batch = 14.5839s	
13826/16650 (epoch 41.520), train_loss = 0.59635291, grad/param norm = 2.7537e-01, time/batch = 17.4252s	
13827/16650 (epoch 41.523), train_loss = 0.69248388, grad/param norm = 2.9259e-01, time/batch = 16.8478s	
13828/16650 (epoch 41.526), train_loss = 0.76279436, grad/param norm = 2.9819e-01, time/batch = 16.0031s	
13829/16650 (epoch 41.529), train_loss = 0.80485279, grad/param norm = 3.8667e-01, time/batch = 18.3613s	
13830/16650 (epoch 41.532), train_loss = 0.53210607, grad/param norm = 2.7353e-01, time/batch = 18.4565s	
13831/16650 (epoch 41.535), train_loss = 0.62558121, grad/param norm = 3.1768e-01, time/batch = 16.4071s	
13832/16650 (epoch 41.538), train_loss = 0.56174016, grad/param norm = 2.6852e-01, time/batch = 18.3692s	
13833/16650 (epoch 41.541), train_loss = 0.81254822, grad/param norm = 3.0923e-01, time/batch = 17.2068s	
13834/16650 (epoch 41.544), train_loss = 0.84621222, grad/param norm = 5.2303e-01, time/batch = 23.2897s	
13835/16650 (epoch 41.547), train_loss = 0.60353835, grad/param norm = 3.0126e-01, time/batch = 24.3059s	
13836/16650 (epoch 41.550), train_loss = 0.70434685, grad/param norm = 2.9576e-01, time/batch = 19.0390s	
13837/16650 (epoch 41.553), train_loss = 0.69321372, grad/param norm = 3.1881e-01, time/batch = 16.1091s	
13838/16650 (epoch 41.556), train_loss = 0.63633452, grad/param norm = 3.1775e-01, time/batch = 16.6101s	
13839/16650 (epoch 41.559), train_loss = 0.56327698, grad/param norm = 3.0403e-01, time/batch = 17.9453s	
13840/16650 (epoch 41.562), train_loss = 0.64756412, grad/param norm = 3.4989e-01, time/batch = 17.5960s	
13841/16650 (epoch 41.565), train_loss = 0.54918703, grad/param norm = 3.2743e-01, time/batch = 17.5160s	
13842/16650 (epoch 41.568), train_loss = 0.55700313, grad/param norm = 2.6084e-01, time/batch = 15.4053s	
13843/16650 (epoch 41.571), train_loss = 0.63935694, grad/param norm = 3.7326e-01, time/batch = 18.8746s	
13844/16650 (epoch 41.574), train_loss = 0.60224725, grad/param norm = 3.1254e-01, time/batch = 16.4108s	
13845/16650 (epoch 41.577), train_loss = 0.66690750, grad/param norm = 2.8301e-01, time/batch = 16.3477s	
13846/16650 (epoch 41.580), train_loss = 0.62896484, grad/param norm = 2.5797e-01, time/batch = 17.0849s	
13847/16650 (epoch 41.583), train_loss = 0.71568924, grad/param norm = 2.9586e-01, time/batch = 17.4195s	
13848/16650 (epoch 41.586), train_loss = 0.60784577, grad/param norm = 2.9916e-01, time/batch = 16.4299s	
13849/16650 (epoch 41.589), train_loss = 0.61639743, grad/param norm = 3.4546e-01, time/batch = 16.6181s	
13850/16650 (epoch 41.592), train_loss = 0.67663859, grad/param norm = 2.8902e-01, time/batch = 17.7736s	
13851/16650 (epoch 41.595), train_loss = 0.62607709, grad/param norm = 2.8032e-01, time/batch = 16.9173s	
13852/16650 (epoch 41.598), train_loss = 0.65928943, grad/param norm = 3.1542e-01, time/batch = 18.2102s	
13853/16650 (epoch 41.601), train_loss = 0.64063504, grad/param norm = 3.4240e-01, time/batch = 17.3541s	
13854/16650 (epoch 41.604), train_loss = 0.67281283, grad/param norm = 2.8849e-01, time/batch = 17.1005s	
13855/16650 (epoch 41.607), train_loss = 0.74050187, grad/param norm = 2.8580e-01, time/batch = 15.4962s	
13856/16650 (epoch 41.610), train_loss = 0.62580348, grad/param norm = 2.6218e-01, time/batch = 17.6098s	
13857/16650 (epoch 41.613), train_loss = 0.79382289, grad/param norm = 3.4682e-01, time/batch = 17.0329s	
13858/16650 (epoch 41.616), train_loss = 0.74606901, grad/param norm = 3.6405e-01, time/batch = 16.9180s	
13859/16650 (epoch 41.619), train_loss = 0.59214086, grad/param norm = 3.0196e-01, time/batch = 18.3679s	
13860/16650 (epoch 41.622), train_loss = 0.58427721, grad/param norm = 2.9405e-01, time/batch = 16.1620s	
13861/16650 (epoch 41.625), train_loss = 0.67204166, grad/param norm = 2.8604e-01, time/batch = 17.1800s	
13862/16650 (epoch 41.628), train_loss = 0.64130651, grad/param norm = 4.2794e-01, time/batch = 18.8729s	
13863/16650 (epoch 41.631), train_loss = 0.70511380, grad/param norm = 3.6055e-01, time/batch = 15.2298s	
13864/16650 (epoch 41.634), train_loss = 0.86275044, grad/param norm = 3.8584e-01, time/batch = 18.4461s	
13865/16650 (epoch 41.637), train_loss = 0.82317353, grad/param norm = 2.8420e-01, time/batch = 16.8426s	
13866/16650 (epoch 41.640), train_loss = 0.66514519, grad/param norm = 2.9459e-01, time/batch = 18.0103s	
13867/16650 (epoch 41.643), train_loss = 0.75109772, grad/param norm = 3.1679e-01, time/batch = 18.8591s	
13868/16650 (epoch 41.646), train_loss = 0.73179031, grad/param norm = 3.4755e-01, time/batch = 16.1716s	
13869/16650 (epoch 41.649), train_loss = 0.73577821, grad/param norm = 3.6474e-01, time/batch = 18.4496s	
13870/16650 (epoch 41.652), train_loss = 0.74751894, grad/param norm = 3.3303e-01, time/batch = 17.5344s	
13871/16650 (epoch 41.655), train_loss = 0.69876510, grad/param norm = 3.2152e-01, time/batch = 18.2748s	
13872/16650 (epoch 41.658), train_loss = 0.64436268, grad/param norm = 3.0071e-01, time/batch = 17.4470s	
13873/16650 (epoch 41.661), train_loss = 0.70226826, grad/param norm = 3.0477e-01, time/batch = 16.9192s	
13874/16650 (epoch 41.664), train_loss = 0.69448736, grad/param norm = 3.5833e-01, time/batch = 18.2019s	
13875/16650 (epoch 41.667), train_loss = 0.78638477, grad/param norm = 2.9538e-01, time/batch = 15.9905s	
13876/16650 (epoch 41.670), train_loss = 0.59806136, grad/param norm = 3.2990e-01, time/batch = 18.3634s	
13877/16650 (epoch 41.673), train_loss = 0.61822410, grad/param norm = 2.7398e-01, time/batch = 18.8702s	
13878/16650 (epoch 41.676), train_loss = 0.75910196, grad/param norm = 3.0873e-01, time/batch = 17.3453s	
13879/16650 (epoch 41.679), train_loss = 0.62741298, grad/param norm = 3.0230e-01, time/batch = 17.5097s	
13880/16650 (epoch 41.682), train_loss = 0.67800611, grad/param norm = 3.0947e-01, time/batch = 17.0296s	
13881/16650 (epoch 41.685), train_loss = 0.58179039, grad/param norm = 2.9950e-01, time/batch = 15.8415s	
13882/16650 (epoch 41.688), train_loss = 0.75114149, grad/param norm = 2.9400e-01, time/batch = 17.0790s	
13883/16650 (epoch 41.691), train_loss = 0.72729185, grad/param norm = 3.5705e-01, time/batch = 17.0212s	
13884/16650 (epoch 41.694), train_loss = 0.63287571, grad/param norm = 2.9063e-01, time/batch = 14.9120s	
13885/16650 (epoch 41.697), train_loss = 0.59001463, grad/param norm = 2.4360e-01, time/batch = 16.9895s	
13886/16650 (epoch 41.700), train_loss = 0.74075414, grad/param norm = 3.3313e-01, time/batch = 16.1439s	
13887/16650 (epoch 41.703), train_loss = 0.61321932, grad/param norm = 3.1182e-01, time/batch = 14.1011s	
13888/16650 (epoch 41.706), train_loss = 0.67139849, grad/param norm = 3.2153e-01, time/batch = 14.7383s	
13889/16650 (epoch 41.709), train_loss = 0.59533362, grad/param norm = 2.8027e-01, time/batch = 15.9211s	
13890/16650 (epoch 41.712), train_loss = 0.60796992, grad/param norm = 2.9641e-01, time/batch = 16.2567s	
13891/16650 (epoch 41.715), train_loss = 0.70434226, grad/param norm = 3.1088e-01, time/batch = 16.4215s	
13892/16650 (epoch 41.718), train_loss = 0.75747836, grad/param norm = 3.3065e-01, time/batch = 17.9738s	
13893/16650 (epoch 41.721), train_loss = 0.77622326, grad/param norm = 2.9117e-01, time/batch = 15.3781s	
13894/16650 (epoch 41.724), train_loss = 0.74968744, grad/param norm = 3.2967e-01, time/batch = 18.0159s	
13895/16650 (epoch 41.727), train_loss = 0.78168845, grad/param norm = 3.0985e-01, time/batch = 17.5951s	
13896/16650 (epoch 41.730), train_loss = 0.63103276, grad/param norm = 2.9767e-01, time/batch = 15.2474s	
13897/16650 (epoch 41.733), train_loss = 0.79094184, grad/param norm = 3.4120e-01, time/batch = 16.4239s	
13898/16650 (epoch 41.736), train_loss = 0.58405744, grad/param norm = 2.9269e-01, time/batch = 18.7644s	
13899/16650 (epoch 41.739), train_loss = 0.71285301, grad/param norm = 3.2000e-01, time/batch = 17.6998s	
13900/16650 (epoch 41.742), train_loss = 0.69512759, grad/param norm = 2.7393e-01, time/batch = 15.9867s	
13901/16650 (epoch 41.745), train_loss = 0.55147647, grad/param norm = 2.7310e-01, time/batch = 17.5196s	
13902/16650 (epoch 41.748), train_loss = 0.58102416, grad/param norm = 3.0273e-01, time/batch = 18.3673s	
13903/16650 (epoch 41.751), train_loss = 0.69619716, grad/param norm = 4.8827e-01, time/batch = 16.0806s	
13904/16650 (epoch 41.754), train_loss = 0.85027316, grad/param norm = 3.8354e-01, time/batch = 16.7349s	
13905/16650 (epoch 41.757), train_loss = 0.81765461, grad/param norm = 3.3745e-01, time/batch = 16.3829s	
13906/16650 (epoch 41.760), train_loss = 0.69604366, grad/param norm = 2.9017e-01, time/batch = 18.9332s	
13907/16650 (epoch 41.763), train_loss = 0.64769417, grad/param norm = 2.8791e-01, time/batch = 15.5857s	
13908/16650 (epoch 41.766), train_loss = 0.66373189, grad/param norm = 2.7695e-01, time/batch = 15.0966s	
13909/16650 (epoch 41.769), train_loss = 0.72165747, grad/param norm = 2.9537e-01, time/batch = 14.4918s	
13910/16650 (epoch 41.772), train_loss = 0.69939206, grad/param norm = 2.5153e-01, time/batch = 15.2438s	
13911/16650 (epoch 41.775), train_loss = 0.68748349, grad/param norm = 3.5757e-01, time/batch = 14.8426s	
13912/16650 (epoch 41.778), train_loss = 0.71605616, grad/param norm = 2.7642e-01, time/batch = 14.4373s	
13913/16650 (epoch 41.781), train_loss = 0.83303374, grad/param norm = 3.0225e-01, time/batch = 15.0328s	
13914/16650 (epoch 41.784), train_loss = 0.70196634, grad/param norm = 2.8124e-01, time/batch = 14.3039s	
13915/16650 (epoch 41.787), train_loss = 0.77046721, grad/param norm = 3.3530e-01, time/batch = 14.2178s	
13916/16650 (epoch 41.790), train_loss = 0.78036250, grad/param norm = 2.8798e-01, time/batch = 14.9207s	
13917/16650 (epoch 41.793), train_loss = 0.59560608, grad/param norm = 3.2099e-01, time/batch = 17.5211s	
13918/16650 (epoch 41.796), train_loss = 0.92392334, grad/param norm = 3.6221e-01, time/batch = 15.8177s	
13919/16650 (epoch 41.799), train_loss = 0.84361999, grad/param norm = 4.1098e-01, time/batch = 15.9130s	
13920/16650 (epoch 41.802), train_loss = 0.79304482, grad/param norm = 3.4506e-01, time/batch = 16.6666s	
13921/16650 (epoch 41.805), train_loss = 0.72954607, grad/param norm = 2.6879e-01, time/batch = 17.4278s	
13922/16650 (epoch 41.808), train_loss = 0.78944736, grad/param norm = 3.5603e-01, time/batch = 17.0141s	
13923/16650 (epoch 41.811), train_loss = 0.81859467, grad/param norm = 3.7614e-01, time/batch = 14.6519s	
13924/16650 (epoch 41.814), train_loss = 0.64825039, grad/param norm = 2.9344e-01, time/batch = 17.6043s	
13925/16650 (epoch 41.817), train_loss = 0.65976913, grad/param norm = 3.1876e-01, time/batch = 17.6940s	
13926/16650 (epoch 41.820), train_loss = 0.76123131, grad/param norm = 3.0647e-01, time/batch = 16.6593s	
13927/16650 (epoch 41.823), train_loss = 0.72008181, grad/param norm = 2.9383e-01, time/batch = 17.7030s	
13928/16650 (epoch 41.826), train_loss = 0.66496707, grad/param norm = 2.8728e-01, time/batch = 18.4416s	
13929/16650 (epoch 41.829), train_loss = 0.71725295, grad/param norm = 3.1413e-01, time/batch = 16.5973s	
13930/16650 (epoch 41.832), train_loss = 0.76451523, grad/param norm = 3.0586e-01, time/batch = 15.9029s	
13931/16650 (epoch 41.835), train_loss = 0.76788371, grad/param norm = 3.5384e-01, time/batch = 15.6423s	
13932/16650 (epoch 41.838), train_loss = 0.63852122, grad/param norm = 2.7474e-01, time/batch = 14.1908s	
13933/16650 (epoch 41.841), train_loss = 0.64818175, grad/param norm = 2.7828e-01, time/batch = 14.9872s	
13934/16650 (epoch 41.844), train_loss = 0.68230092, grad/param norm = 2.6061e-01, time/batch = 14.6731s	
13935/16650 (epoch 41.847), train_loss = 0.76802704, grad/param norm = 3.4427e-01, time/batch = 16.8306s	
13936/16650 (epoch 41.850), train_loss = 0.65199212, grad/param norm = 3.4109e-01, time/batch = 15.4950s	
13937/16650 (epoch 41.853), train_loss = 0.69298111, grad/param norm = 3.3427e-01, time/batch = 16.4142s	
13938/16650 (epoch 41.856), train_loss = 0.65511351, grad/param norm = 3.0480e-01, time/batch = 17.7632s	
13939/16650 (epoch 41.859), train_loss = 0.77371213, grad/param norm = 3.1415e-01, time/batch = 16.5210s	
13940/16650 (epoch 41.862), train_loss = 0.70337103, grad/param norm = 2.7214e-01, time/batch = 16.9913s	
13941/16650 (epoch 41.865), train_loss = 0.56924606, grad/param norm = 2.7117e-01, time/batch = 16.0683s	
13942/16650 (epoch 41.868), train_loss = 0.71565050, grad/param norm = 2.9722e-01, time/batch = 17.1657s	
13943/16650 (epoch 41.871), train_loss = 0.73025517, grad/param norm = 3.0525e-01, time/batch = 15.4862s	
13944/16650 (epoch 41.874), train_loss = 0.72090284, grad/param norm = 3.1055e-01, time/batch = 14.9404s	
13945/16650 (epoch 41.877), train_loss = 0.69575325, grad/param norm = 2.8017e-01, time/batch = 18.0255s	
13946/16650 (epoch 41.880), train_loss = 0.64434761, grad/param norm = 3.4040e-01, time/batch = 18.7946s	
13947/16650 (epoch 41.883), train_loss = 0.72383881, grad/param norm = 2.9881e-01, time/batch = 17.4381s	
13948/16650 (epoch 41.886), train_loss = 0.71076327, grad/param norm = 2.9284e-01, time/batch = 16.8437s	
13949/16650 (epoch 41.889), train_loss = 0.59850277, grad/param norm = 3.0448e-01, time/batch = 15.0555s	
13950/16650 (epoch 41.892), train_loss = 0.71234931, grad/param norm = 2.5741e-01, time/batch = 14.1111s	
13951/16650 (epoch 41.895), train_loss = 0.73000674, grad/param norm = 3.1298e-01, time/batch = 15.1998s	
13952/16650 (epoch 41.898), train_loss = 0.70814348, grad/param norm = 3.3399e-01, time/batch = 14.3942s	
13953/16650 (epoch 41.901), train_loss = 0.65111709, grad/param norm = 3.2839e-01, time/batch = 16.1570s	
13954/16650 (epoch 41.904), train_loss = 0.68185358, grad/param norm = 3.5593e-01, time/batch = 17.5131s	
13955/16650 (epoch 41.907), train_loss = 0.71513520, grad/param norm = 3.2651e-01, time/batch = 15.8286s	
13956/16650 (epoch 41.910), train_loss = 0.73914422, grad/param norm = 3.1775e-01, time/batch = 17.4462s	
13957/16650 (epoch 41.913), train_loss = 0.66678028, grad/param norm = 2.8479e-01, time/batch = 16.9148s	
13958/16650 (epoch 41.916), train_loss = 0.62567229, grad/param norm = 2.7264e-01, time/batch = 16.9085s	
13959/16650 (epoch 41.919), train_loss = 0.82235906, grad/param norm = 2.9993e-01, time/batch = 16.1473s	
13960/16650 (epoch 41.922), train_loss = 0.72099781, grad/param norm = 3.3250e-01, time/batch = 16.1350s	
13961/16650 (epoch 41.925), train_loss = 0.66914897, grad/param norm = 3.1034e-01, time/batch = 19.2728s	
13962/16650 (epoch 41.928), train_loss = 0.71265825, grad/param norm = 2.7873e-01, time/batch = 18.0919s	
13963/16650 (epoch 41.931), train_loss = 0.71352730, grad/param norm = 3.1781e-01, time/batch = 17.5193s	
13964/16650 (epoch 41.934), train_loss = 0.59206061, grad/param norm = 4.3405e-01, time/batch = 17.4253s	
13965/16650 (epoch 41.937), train_loss = 0.64413275, grad/param norm = 3.7643e-01, time/batch = 17.3448s	
13966/16650 (epoch 41.940), train_loss = 0.69482109, grad/param norm = 2.8247e-01, time/batch = 14.9634s	
13967/16650 (epoch 41.943), train_loss = 0.71978288, grad/param norm = 3.6153e-01, time/batch = 18.1652s	
13968/16650 (epoch 41.946), train_loss = 0.67293964, grad/param norm = 3.9399e-01, time/batch = 18.1070s	
13969/16650 (epoch 41.949), train_loss = 0.60832163, grad/param norm = 2.9733e-01, time/batch = 17.5118s	
13970/16650 (epoch 41.952), train_loss = 0.60598740, grad/param norm = 2.8700e-01, time/batch = 18.6078s	
13971/16650 (epoch 41.955), train_loss = 0.69627634, grad/param norm = 2.9908e-01, time/batch = 16.8617s	
13972/16650 (epoch 41.958), train_loss = 0.75128532, grad/param norm = 3.2728e-01, time/batch = 16.6734s	
13973/16650 (epoch 41.961), train_loss = 0.67830317, grad/param norm = 2.5445e-01, time/batch = 18.0215s	
13974/16650 (epoch 41.964), train_loss = 0.60747926, grad/param norm = 3.6253e-01, time/batch = 17.7045s	
13975/16650 (epoch 41.967), train_loss = 0.81702250, grad/param norm = 3.2686e-01, time/batch = 15.6969s	
13976/16650 (epoch 41.970), train_loss = 0.65700860, grad/param norm = 2.8983e-01, time/batch = 16.2591s	
13977/16650 (epoch 41.973), train_loss = 0.66479949, grad/param norm = 3.2854e-01, time/batch = 17.8740s	
13978/16650 (epoch 41.976), train_loss = 0.64229785, grad/param norm = 3.1954e-01, time/batch = 15.7826s	
13979/16650 (epoch 41.979), train_loss = 0.71579138, grad/param norm = 3.0352e-01, time/batch = 15.6795s	
13980/16650 (epoch 41.982), train_loss = 0.74759163, grad/param norm = 3.1714e-01, time/batch = 14.8189s	
13981/16650 (epoch 41.985), train_loss = 0.70861842, grad/param norm = 2.8423e-01, time/batch = 17.4490s	
13982/16650 (epoch 41.988), train_loss = 0.71515690, grad/param norm = 3.3338e-01, time/batch = 17.6149s	
13983/16650 (epoch 41.991), train_loss = 0.64082859, grad/param norm = 3.0493e-01, time/batch = 14.9080s	
13984/16650 (epoch 41.994), train_loss = 0.64922267, grad/param norm = 2.7684e-01, time/batch = 15.6640s	
13985/16650 (epoch 41.997), train_loss = 0.67275550, grad/param norm = 3.5267e-01, time/batch = 16.9493s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
13986/16650 (epoch 42.000), train_loss = 0.75761072, grad/param norm = 3.6953e-01, time/batch = 17.0194s	
13987/16650 (epoch 42.003), train_loss = 0.82811150, grad/param norm = 3.9454e-01, time/batch = 14.8156s	
13988/16650 (epoch 42.006), train_loss = 0.80268640, grad/param norm = 3.8592e-01, time/batch = 15.8517s	
13989/16650 (epoch 42.009), train_loss = 0.83963922, grad/param norm = 4.2062e-01, time/batch = 17.6957s	
13990/16650 (epoch 42.012), train_loss = 0.81620093, grad/param norm = 3.3636e-01, time/batch = 16.6060s	
13991/16650 (epoch 42.015), train_loss = 0.71169259, grad/param norm = 3.2268e-01, time/batch = 17.2766s	
13992/16650 (epoch 42.018), train_loss = 0.63102471, grad/param norm = 2.9429e-01, time/batch = 16.7095s	
13993/16650 (epoch 42.021), train_loss = 0.83059728, grad/param norm = 3.6839e-01, time/batch = 15.8471s	
13994/16650 (epoch 42.024), train_loss = 0.69714944, grad/param norm = 3.1656e-01, time/batch = 15.9079s	
13995/16650 (epoch 42.027), train_loss = 0.75487711, grad/param norm = 3.7400e-01, time/batch = 16.0972s	
13996/16650 (epoch 42.030), train_loss = 0.59727025, grad/param norm = 2.8034e-01, time/batch = 17.2141s	
13997/16650 (epoch 42.033), train_loss = 0.69168272, grad/param norm = 2.8386e-01, time/batch = 17.2874s	
13998/16650 (epoch 42.036), train_loss = 0.51150136, grad/param norm = 3.4634e-01, time/batch = 15.5958s	
13999/16650 (epoch 42.039), train_loss = 0.79464098, grad/param norm = 2.9003e-01, time/batch = 15.5836s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch42.04_2.3047.t7	
14000/16650 (epoch 42.042), train_loss = 0.73624432, grad/param norm = 3.4089e-01, time/batch = 16.9312s	
14001/16650 (epoch 42.045), train_loss = 1.17844706, grad/param norm = 4.4089e-01, time/batch = 16.7335s	
14002/16650 (epoch 42.048), train_loss = 0.78415618, grad/param norm = 3.3200e-01, time/batch = 15.6652s	
14003/16650 (epoch 42.051), train_loss = 0.70019178, grad/param norm = 3.0729e-01, time/batch = 16.3644s	
14004/16650 (epoch 42.054), train_loss = 0.69373462, grad/param norm = 2.8186e-01, time/batch = 16.0810s	
14005/16650 (epoch 42.057), train_loss = 0.69205373, grad/param norm = 3.6181e-01, time/batch = 16.3583s	
14006/16650 (epoch 42.060), train_loss = 0.59800730, grad/param norm = 2.6337e-01, time/batch = 17.2164s	
14007/16650 (epoch 42.063), train_loss = 0.66969038, grad/param norm = 3.1769e-01, time/batch = 18.7226s	
14008/16650 (epoch 42.066), train_loss = 0.84480138, grad/param norm = 3.2311e-01, time/batch = 15.4744s	
14009/16650 (epoch 42.069), train_loss = 0.75465787, grad/param norm = 3.2863e-01, time/batch = 18.0431s	
14010/16650 (epoch 42.072), train_loss = 0.71031153, grad/param norm = 3.3647e-01, time/batch = 16.8618s	
14011/16650 (epoch 42.075), train_loss = 0.77869796, grad/param norm = 3.1041e-01, time/batch = 16.4277s	
14012/16650 (epoch 42.078), train_loss = 0.79550763, grad/param norm = 3.8590e-01, time/batch = 14.4125s	
14013/16650 (epoch 42.081), train_loss = 0.73845728, grad/param norm = 3.5039e-01, time/batch = 17.1208s	
14014/16650 (epoch 42.084), train_loss = 0.72692699, grad/param norm = 3.3027e-01, time/batch = 17.1299s	
14015/16650 (epoch 42.087), train_loss = 0.72546989, grad/param norm = 2.9847e-01, time/batch = 16.3461s	
14016/16650 (epoch 42.090), train_loss = 0.69513394, grad/param norm = 3.4426e-01, time/batch = 16.0233s	
14017/16650 (epoch 42.093), train_loss = 0.82293152, grad/param norm = 3.7808e-01, time/batch = 18.0409s	
14018/16650 (epoch 42.096), train_loss = 0.68196002, grad/param norm = 3.5809e-01, time/batch = 17.2906s	
14019/16650 (epoch 42.099), train_loss = 0.74584300, grad/param norm = 3.5486e-01, time/batch = 17.8403s	
14020/16650 (epoch 42.102), train_loss = 0.71928873, grad/param norm = 3.4611e-01, time/batch = 14.5627s	
14021/16650 (epoch 42.105), train_loss = 0.72040822, grad/param norm = 3.1913e-01, time/batch = 16.7083s	
14022/16650 (epoch 42.108), train_loss = 0.73211207, grad/param norm = 3.1353e-01, time/batch = 14.3030s	
14023/16650 (epoch 42.111), train_loss = 0.80363013, grad/param norm = 3.4519e-01, time/batch = 16.2711s	
14024/16650 (epoch 42.114), train_loss = 0.72533543, grad/param norm = 4.4129e-01, time/batch = 17.2060s	
14025/16650 (epoch 42.117), train_loss = 0.84771720, grad/param norm = 3.6919e-01, time/batch = 18.2993s	
14026/16650 (epoch 42.120), train_loss = 0.73030866, grad/param norm = 3.1032e-01, time/batch = 15.7186s	
14027/16650 (epoch 42.123), train_loss = 0.68367768, grad/param norm = 2.8698e-01, time/batch = 18.3768s	
14028/16650 (epoch 42.126), train_loss = 0.75009418, grad/param norm = 2.9899e-01, time/batch = 15.0901s	
14029/16650 (epoch 42.129), train_loss = 0.75308463, grad/param norm = 3.1098e-01, time/batch = 17.2785s	
14030/16650 (epoch 42.132), train_loss = 0.70936909, grad/param norm = 3.0097e-01, time/batch = 17.0421s	
14031/16650 (epoch 42.135), train_loss = 0.80593271, grad/param norm = 2.8424e-01, time/batch = 17.7008s	
14032/16650 (epoch 42.138), train_loss = 0.76979053, grad/param norm = 2.9703e-01, time/batch = 17.2056s	
14033/16650 (epoch 42.141), train_loss = 0.73599083, grad/param norm = 3.4462e-01, time/batch = 16.0112s	
14034/16650 (epoch 42.144), train_loss = 0.75771121, grad/param norm = 3.5421e-01, time/batch = 18.3048s	
14035/16650 (epoch 42.147), train_loss = 0.84639589, grad/param norm = 3.1309e-01, time/batch = 17.2038s	
14036/16650 (epoch 42.150), train_loss = 0.90172455, grad/param norm = 4.0427e-01, time/batch = 16.3472s	
14037/16650 (epoch 42.153), train_loss = 0.71861827, grad/param norm = 5.7636e-01, time/batch = 16.8866s	
14038/16650 (epoch 42.156), train_loss = 0.72874822, grad/param norm = 2.7849e-01, time/batch = 15.1505s	
14039/16650 (epoch 42.159), train_loss = 0.76613468, grad/param norm = 2.9092e-01, time/batch = 14.9249s	
14040/16650 (epoch 42.162), train_loss = 0.85506129, grad/param norm = 2.9755e-01, time/batch = 16.8319s	
14041/16650 (epoch 42.165), train_loss = 0.82517061, grad/param norm = 3.3152e-01, time/batch = 16.7851s	
14042/16650 (epoch 42.168), train_loss = 0.61458107, grad/param norm = 2.5216e-01, time/batch = 17.0436s	
14043/16650 (epoch 42.171), train_loss = 0.78838241, grad/param norm = 3.4449e-01, time/batch = 17.7851s	
14044/16650 (epoch 42.174), train_loss = 0.60179214, grad/param norm = 2.7634e-01, time/batch = 30.6762s	
14045/16650 (epoch 42.177), train_loss = 0.71688879, grad/param norm = 3.3024e-01, time/batch = 17.9374s	
14046/16650 (epoch 42.180), train_loss = 0.81350609, grad/param norm = 2.8611e-01, time/batch = 16.9201s	
14047/16650 (epoch 42.183), train_loss = 0.95349596, grad/param norm = 3.6943e-01, time/batch = 15.8236s	
14048/16650 (epoch 42.186), train_loss = 0.75681307, grad/param norm = 3.3890e-01, time/batch = 18.6006s	
14049/16650 (epoch 42.189), train_loss = 0.67237257, grad/param norm = 2.5866e-01, time/batch = 18.8571s	
14050/16650 (epoch 42.192), train_loss = 0.72343969, grad/param norm = 2.8383e-01, time/batch = 15.1411s	
14051/16650 (epoch 42.195), train_loss = 0.66442854, grad/param norm = 3.1352e-01, time/batch = 16.7688s	
14052/16650 (epoch 42.198), train_loss = 0.65140816, grad/param norm = 2.7874e-01, time/batch = 19.0136s	
14053/16650 (epoch 42.201), train_loss = 0.63432401, grad/param norm = 2.7362e-01, time/batch = 17.1735s	
14054/16650 (epoch 42.204), train_loss = 0.72630612, grad/param norm = 2.9297e-01, time/batch = 18.9598s	
14055/16650 (epoch 42.207), train_loss = 0.76804110, grad/param norm = 3.7779e-01, time/batch = 17.5795s	
14056/16650 (epoch 42.210), train_loss = 0.70886541, grad/param norm = 3.2669e-01, time/batch = 17.5910s	
14057/16650 (epoch 42.213), train_loss = 0.76826625, grad/param norm = 3.2505e-01, time/batch = 16.7327s	
14058/16650 (epoch 42.216), train_loss = 0.65281812, grad/param norm = 3.2193e-01, time/batch = 18.5485s	
14059/16650 (epoch 42.219), train_loss = 0.71934915, grad/param norm = 3.1880e-01, time/batch = 19.2938s	
14060/16650 (epoch 42.222), train_loss = 0.73277826, grad/param norm = 2.7505e-01, time/batch = 16.8192s	
14061/16650 (epoch 42.225), train_loss = 0.76567761, grad/param norm = 3.8963e-01, time/batch = 17.5857s	
14062/16650 (epoch 42.228), train_loss = 0.69683328, grad/param norm = 3.6548e-01, time/batch = 18.3494s	
14063/16650 (epoch 42.231), train_loss = 0.65217135, grad/param norm = 3.2027e-01, time/batch = 17.2720s	
14064/16650 (epoch 42.234), train_loss = 0.85119320, grad/param norm = 3.3707e-01, time/batch = 17.9390s	
14065/16650 (epoch 42.237), train_loss = 0.75138583, grad/param norm = 3.5628e-01, time/batch = 18.7713s	
14066/16650 (epoch 42.240), train_loss = 0.74254380, grad/param norm = 2.7301e-01, time/batch = 17.5277s	
14067/16650 (epoch 42.243), train_loss = 0.71836183, grad/param norm = 3.5728e-01, time/batch = 17.3525s	
14068/16650 (epoch 42.246), train_loss = 0.82377594, grad/param norm = 3.6878e-01, time/batch = 18.5349s	
14069/16650 (epoch 42.249), train_loss = 0.61361645, grad/param norm = 2.6718e-01, time/batch = 15.1404s	
14070/16650 (epoch 42.252), train_loss = 0.69616697, grad/param norm = 2.6711e-01, time/batch = 16.0678s	
14071/16650 (epoch 42.255), train_loss = 0.76479276, grad/param norm = 2.9535e-01, time/batch = 18.9504s	
14072/16650 (epoch 42.258), train_loss = 0.78138792, grad/param norm = 2.7817e-01, time/batch = 19.0462s	
14073/16650 (epoch 42.261), train_loss = 0.76197284, grad/param norm = 3.3050e-01, time/batch = 16.0788s	
14074/16650 (epoch 42.264), train_loss = 0.67364224, grad/param norm = 3.1242e-01, time/batch = 17.2627s	
14075/16650 (epoch 42.267), train_loss = 0.69798250, grad/param norm = 3.7476e-01, time/batch = 17.6968s	
14076/16650 (epoch 42.270), train_loss = 0.77768933, grad/param norm = 3.1237e-01, time/batch = 19.7939s	
14077/16650 (epoch 42.273), train_loss = 0.80127083, grad/param norm = 3.3780e-01, time/batch = 16.6563s	
14078/16650 (epoch 42.276), train_loss = 0.76474862, grad/param norm = 3.3743e-01, time/batch = 15.2775s	
14079/16650 (epoch 42.279), train_loss = 0.69659227, grad/param norm = 2.9542e-01, time/batch = 17.3502s	
14080/16650 (epoch 42.282), train_loss = 0.67439483, grad/param norm = 2.8766e-01, time/batch = 17.2741s	
14081/16650 (epoch 42.285), train_loss = 0.69726797, grad/param norm = 2.7070e-01, time/batch = 17.5233s	
14082/16650 (epoch 42.288), train_loss = 0.63506869, grad/param norm = 2.9464e-01, time/batch = 18.0220s	
14083/16650 (epoch 42.291), train_loss = 0.53613932, grad/param norm = 2.4422e-01, time/batch = 15.5899s	
14084/16650 (epoch 42.294), train_loss = 0.63725868, grad/param norm = 2.5632e-01, time/batch = 14.8619s	
14085/16650 (epoch 42.297), train_loss = 0.71460833, grad/param norm = 2.9596e-01, time/batch = 18.1164s	
14086/16650 (epoch 42.300), train_loss = 0.56518145, grad/param norm = 2.5946e-01, time/batch = 18.4668s	
14087/16650 (epoch 42.303), train_loss = 0.60862801, grad/param norm = 2.6063e-01, time/batch = 17.9491s	
14088/16650 (epoch 42.306), train_loss = 0.78260937, grad/param norm = 2.8331e-01, time/batch = 17.7649s	
14089/16650 (epoch 42.309), train_loss = 0.75952825, grad/param norm = 2.7328e-01, time/batch = 16.8580s	
14090/16650 (epoch 42.312), train_loss = 0.59591784, grad/param norm = 3.4361e-01, time/batch = 18.3756s	
14091/16650 (epoch 42.315), train_loss = 0.50331421, grad/param norm = 2.2281e-01, time/batch = 17.3369s	
14092/16650 (epoch 42.318), train_loss = 0.58963990, grad/param norm = 2.8430e-01, time/batch = 18.6265s	
14093/16650 (epoch 42.321), train_loss = 0.77576831, grad/param norm = 3.2805e-01, time/batch = 15.8449s	
14094/16650 (epoch 42.324), train_loss = 0.64301412, grad/param norm = 3.1301e-01, time/batch = 14.4287s	
14095/16650 (epoch 42.327), train_loss = 0.72108555, grad/param norm = 3.2957e-01, time/batch = 14.3111s	
14096/16650 (epoch 42.330), train_loss = 0.71989557, grad/param norm = 3.6786e-01, time/batch = 15.3881s	
14097/16650 (epoch 42.333), train_loss = 0.75166599, grad/param norm = 3.1435e-01, time/batch = 18.0259s	
14098/16650 (epoch 42.336), train_loss = 0.61272858, grad/param norm = 2.7855e-01, time/batch = 16.5993s	
14099/16650 (epoch 42.339), train_loss = 0.64552023, grad/param norm = 3.1736e-01, time/batch = 16.9279s	
14100/16650 (epoch 42.342), train_loss = 0.61122037, grad/param norm = 3.1986e-01, time/batch = 17.7795s	
14101/16650 (epoch 42.345), train_loss = 0.63938667, grad/param norm = 2.8069e-01, time/batch = 18.0066s	
14102/16650 (epoch 42.348), train_loss = 0.73947767, grad/param norm = 2.9700e-01, time/batch = 17.8672s	
14103/16650 (epoch 42.351), train_loss = 0.72958307, grad/param norm = 2.8128e-01, time/batch = 14.8574s	
14104/16650 (epoch 42.354), train_loss = 0.75779428, grad/param norm = 3.1189e-01, time/batch = 18.1962s	
14105/16650 (epoch 42.357), train_loss = 0.72481179, grad/param norm = 2.9244e-01, time/batch = 16.0220s	
14106/16650 (epoch 42.360), train_loss = 0.72739267, grad/param norm = 3.3381e-01, time/batch = 17.9338s	
14107/16650 (epoch 42.363), train_loss = 0.77995409, grad/param norm = 3.3352e-01, time/batch = 17.7659s	
14108/16650 (epoch 42.366), train_loss = 0.84147137, grad/param norm = 3.3031e-01, time/batch = 16.8133s	
14109/16650 (epoch 42.369), train_loss = 0.77075336, grad/param norm = 3.5959e-01, time/batch = 18.4455s	
14110/16650 (epoch 42.372), train_loss = 0.71214430, grad/param norm = 2.8349e-01, time/batch = 18.5330s	
14111/16650 (epoch 42.375), train_loss = 0.72228213, grad/param norm = 2.7997e-01, time/batch = 18.3638s	
14112/16650 (epoch 42.378), train_loss = 0.67769981, grad/param norm = 2.9601e-01, time/batch = 17.6636s	
14113/16650 (epoch 42.381), train_loss = 0.75488434, grad/param norm = 2.9439e-01, time/batch = 16.1732s	
14114/16650 (epoch 42.384), train_loss = 0.82890262, grad/param norm = 3.0176e-01, time/batch = 18.7013s	
14115/16650 (epoch 42.387), train_loss = 0.55778299, grad/param norm = 2.5337e-01, time/batch = 15.3476s	
14116/16650 (epoch 42.390), train_loss = 0.76898837, grad/param norm = 2.8315e-01, time/batch = 18.1948s	
14117/16650 (epoch 42.393), train_loss = 0.68999897, grad/param norm = 3.0459e-01, time/batch = 18.6939s	
14118/16650 (epoch 42.396), train_loss = 0.82340828, grad/param norm = 3.4069e-01, time/batch = 15.4966s	
14119/16650 (epoch 42.399), train_loss = 0.77788676, grad/param norm = 3.2719e-01, time/batch = 15.9932s	
14120/16650 (epoch 42.402), train_loss = 0.68511953, grad/param norm = 2.9435e-01, time/batch = 18.2683s	
14121/16650 (epoch 42.405), train_loss = 0.56232621, grad/param norm = 2.9491e-01, time/batch = 17.9357s	
14122/16650 (epoch 42.408), train_loss = 0.75006522, grad/param norm = 3.1230e-01, time/batch = 16.2663s	
14123/16650 (epoch 42.411), train_loss = 0.64825144, grad/param norm = 3.1235e-01, time/batch = 17.6872s	
14124/16650 (epoch 42.414), train_loss = 0.64318198, grad/param norm = 3.1964e-01, time/batch = 18.7753s	
14125/16650 (epoch 42.417), train_loss = 0.61630405, grad/param norm = 3.3781e-01, time/batch = 14.8138s	
14126/16650 (epoch 42.420), train_loss = 0.64014617, grad/param norm = 2.8168e-01, time/batch = 17.4967s	
14127/16650 (epoch 42.423), train_loss = 0.52467546, grad/param norm = 2.6826e-01, time/batch = 16.7931s	
14128/16650 (epoch 42.426), train_loss = 0.61259814, grad/param norm = 2.8424e-01, time/batch = 18.1192s	
14129/16650 (epoch 42.429), train_loss = 0.77434209, grad/param norm = 3.1959e-01, time/batch = 16.8318s	
14130/16650 (epoch 42.432), train_loss = 0.77038494, grad/param norm = 3.1993e-01, time/batch = 17.1071s	
14131/16650 (epoch 42.435), train_loss = 0.86019279, grad/param norm = 3.1948e-01, time/batch = 16.3656s	
14132/16650 (epoch 42.438), train_loss = 0.85593775, grad/param norm = 3.5599e-01, time/batch = 18.1891s	
14133/16650 (epoch 42.441), train_loss = 0.66927313, grad/param norm = 3.2843e-01, time/batch = 17.1205s	
14134/16650 (epoch 42.444), train_loss = 0.65129811, grad/param norm = 2.7576e-01, time/batch = 15.9900s	
14135/16650 (epoch 42.447), train_loss = 0.64666080, grad/param norm = 2.7679e-01, time/batch = 17.8418s	
14136/16650 (epoch 42.450), train_loss = 0.65092794, grad/param norm = 2.9707e-01, time/batch = 16.6810s	
14137/16650 (epoch 42.453), train_loss = 0.65245864, grad/param norm = 2.7587e-01, time/batch = 18.0331s	
14138/16650 (epoch 42.456), train_loss = 0.62195751, grad/param norm = 2.6489e-01, time/batch = 16.9474s	
14139/16650 (epoch 42.459), train_loss = 0.64134632, grad/param norm = 3.1125e-01, time/batch = 17.6751s	
14140/16650 (epoch 42.462), train_loss = 0.79104588, grad/param norm = 3.2955e-01, time/batch = 16.6537s	
14141/16650 (epoch 42.465), train_loss = 0.66132029, grad/param norm = 3.1999e-01, time/batch = 18.0221s	
14142/16650 (epoch 42.468), train_loss = 0.53231343, grad/param norm = 2.6012e-01, time/batch = 17.3267s	
14143/16650 (epoch 42.471), train_loss = 0.46431525, grad/param norm = 2.3568e-01, time/batch = 16.2560s	
14144/16650 (epoch 42.474), train_loss = 0.61323587, grad/param norm = 2.9511e-01, time/batch = 18.2091s	
14145/16650 (epoch 42.477), train_loss = 0.75086292, grad/param norm = 3.0423e-01, time/batch = 17.7043s	
14146/16650 (epoch 42.480), train_loss = 0.66807132, grad/param norm = 3.3195e-01, time/batch = 16.4165s	
14147/16650 (epoch 42.483), train_loss = 0.74448820, grad/param norm = 2.9307e-01, time/batch = 0.6436s	
14148/16650 (epoch 42.486), train_loss = 0.61353188, grad/param norm = 2.5452e-01, time/batch = 0.6402s	
14149/16650 (epoch 42.489), train_loss = 0.69152379, grad/param norm = 3.1338e-01, time/batch = 0.6387s	
14150/16650 (epoch 42.492), train_loss = 0.69085047, grad/param norm = 2.5692e-01, time/batch = 0.6350s	
14151/16650 (epoch 42.495), train_loss = 0.59660409, grad/param norm = 3.5306e-01, time/batch = 0.6376s	
14152/16650 (epoch 42.498), train_loss = 0.64806842, grad/param norm = 3.5637e-01, time/batch = 0.6381s	
14153/16650 (epoch 42.502), train_loss = 0.83613577, grad/param norm = 3.9608e-01, time/batch = 0.6362s	
14154/16650 (epoch 42.505), train_loss = 0.74939283, grad/param norm = 3.0510e-01, time/batch = 0.6414s	
14155/16650 (epoch 42.508), train_loss = 0.75596955, grad/param norm = 3.7438e-01, time/batch = 0.6425s	
14156/16650 (epoch 42.511), train_loss = 0.74764045, grad/param norm = 3.0185e-01, time/batch = 0.6426s	
14157/16650 (epoch 42.514), train_loss = 0.60521874, grad/param norm = 2.8037e-01, time/batch = 0.6384s	
14158/16650 (epoch 42.517), train_loss = 0.67689437, grad/param norm = 3.4265e-01, time/batch = 0.6385s	
14159/16650 (epoch 42.520), train_loss = 0.60396355, grad/param norm = 3.0485e-01, time/batch = 0.6352s	
14160/16650 (epoch 42.523), train_loss = 0.69468628, grad/param norm = 2.8517e-01, time/batch = 0.6411s	
14161/16650 (epoch 42.526), train_loss = 0.76463715, grad/param norm = 4.7154e-01, time/batch = 0.6379s	
14162/16650 (epoch 42.529), train_loss = 0.77355450, grad/param norm = 3.4195e-01, time/batch = 0.6400s	
14163/16650 (epoch 42.532), train_loss = 0.52303421, grad/param norm = 2.8413e-01, time/batch = 0.6480s	
14164/16650 (epoch 42.535), train_loss = 0.61006050, grad/param norm = 2.9931e-01, time/batch = 0.6366s	
14165/16650 (epoch 42.538), train_loss = 0.55969570, grad/param norm = 2.7364e-01, time/batch = 0.6390s	
14166/16650 (epoch 42.541), train_loss = 0.80321761, grad/param norm = 3.4077e-01, time/batch = 0.6422s	
14167/16650 (epoch 42.544), train_loss = 0.86249800, grad/param norm = 5.4758e-01, time/batch = 0.6371s	
14168/16650 (epoch 42.547), train_loss = 0.60809384, grad/param norm = 2.9208e-01, time/batch = 0.6358s	
14169/16650 (epoch 42.550), train_loss = 0.71172076, grad/param norm = 3.0361e-01, time/batch = 0.6367s	
14170/16650 (epoch 42.553), train_loss = 0.68954145, grad/param norm = 2.9465e-01, time/batch = 0.8608s	
14171/16650 (epoch 42.556), train_loss = 0.60851492, grad/param norm = 2.6386e-01, time/batch = 0.9395s	
14172/16650 (epoch 42.559), train_loss = 0.55098029, grad/param norm = 2.9863e-01, time/batch = 0.9386s	
14173/16650 (epoch 42.562), train_loss = 0.62709692, grad/param norm = 2.9109e-01, time/batch = 0.9406s	
14174/16650 (epoch 42.565), train_loss = 0.53546511, grad/param norm = 2.7120e-01, time/batch = 0.9414s	
14175/16650 (epoch 42.568), train_loss = 0.55909596, grad/param norm = 3.2426e-01, time/batch = 1.3079s	
14176/16650 (epoch 42.571), train_loss = 0.60999043, grad/param norm = 3.2906e-01, time/batch = 1.7656s	
14177/16650 (epoch 42.574), train_loss = 0.61374686, grad/param norm = 3.4042e-01, time/batch = 1.7447s	
14178/16650 (epoch 42.577), train_loss = 0.65058768, grad/param norm = 2.6324e-01, time/batch = 12.3714s	
14179/16650 (epoch 42.580), train_loss = 0.60578788, grad/param norm = 2.5268e-01, time/batch = 18.0806s	
14180/16650 (epoch 42.583), train_loss = 0.69717513, grad/param norm = 2.7856e-01, time/batch = 15.3053s	
14181/16650 (epoch 42.586), train_loss = 0.62082099, grad/param norm = 4.4240e-01, time/batch = 16.4731s	
14182/16650 (epoch 42.589), train_loss = 0.60188259, grad/param norm = 2.6323e-01, time/batch = 17.9460s	
14183/16650 (epoch 42.592), train_loss = 0.67534113, grad/param norm = 2.9311e-01, time/batch = 16.2637s	
14184/16650 (epoch 42.595), train_loss = 0.62454534, grad/param norm = 3.2230e-01, time/batch = 17.6958s	
14185/16650 (epoch 42.598), train_loss = 0.64021774, grad/param norm = 3.0780e-01, time/batch = 15.4167s	
14186/16650 (epoch 42.601), train_loss = 0.62131442, grad/param norm = 5.1206e-01, time/batch = 18.5424s	
14187/16650 (epoch 42.604), train_loss = 0.68900934, grad/param norm = 3.5666e-01, time/batch = 17.1641s	
14188/16650 (epoch 42.607), train_loss = 0.73103957, grad/param norm = 2.7921e-01, time/batch = 17.4312s	
14189/16650 (epoch 42.610), train_loss = 0.62077510, grad/param norm = 2.6333e-01, time/batch = 18.1937s	
14190/16650 (epoch 42.613), train_loss = 0.77621298, grad/param norm = 3.4545e-01, time/batch = 17.5071s	
14191/16650 (epoch 42.616), train_loss = 0.74410346, grad/param norm = 4.4942e-01, time/batch = 16.9354s	
14192/16650 (epoch 42.619), train_loss = 0.57672959, grad/param norm = 2.9744e-01, time/batch = 18.8698s	
14193/16650 (epoch 42.622), train_loss = 0.55854938, grad/param norm = 2.5764e-01, time/batch = 17.0087s	
14194/16650 (epoch 42.625), train_loss = 0.67278363, grad/param norm = 2.8634e-01, time/batch = 14.8853s	
14195/16650 (epoch 42.628), train_loss = 0.63892166, grad/param norm = 3.7101e-01, time/batch = 16.9951s	
14196/16650 (epoch 42.631), train_loss = 0.68422954, grad/param norm = 2.9755e-01, time/batch = 16.1704s	
14197/16650 (epoch 42.634), train_loss = 0.84876092, grad/param norm = 3.1230e-01, time/batch = 17.5976s	
14198/16650 (epoch 42.637), train_loss = 0.81653085, grad/param norm = 2.9791e-01, time/batch = 17.8394s	
14199/16650 (epoch 42.640), train_loss = 0.66353000, grad/param norm = 2.9705e-01, time/batch = 19.1049s	
14200/16650 (epoch 42.643), train_loss = 0.74728515, grad/param norm = 2.9450e-01, time/batch = 16.9189s	
14201/16650 (epoch 42.646), train_loss = 0.71609617, grad/param norm = 3.0666e-01, time/batch = 15.9709s	
14202/16650 (epoch 42.649), train_loss = 0.71413413, grad/param norm = 3.2566e-01, time/batch = 17.7024s	
14203/16650 (epoch 42.652), train_loss = 0.72836757, grad/param norm = 3.0986e-01, time/batch = 18.8687s	
14204/16650 (epoch 42.655), train_loss = 0.68334323, grad/param norm = 3.0317e-01, time/batch = 16.5143s	
14205/16650 (epoch 42.658), train_loss = 0.63997277, grad/param norm = 3.5395e-01, time/batch = 19.0211s	
14206/16650 (epoch 42.661), train_loss = 0.68937797, grad/param norm = 3.3031e-01, time/batch = 17.6688s	
14207/16650 (epoch 42.664), train_loss = 0.67248459, grad/param norm = 3.0079e-01, time/batch = 17.1692s	
14208/16650 (epoch 42.667), train_loss = 0.79367265, grad/param norm = 3.4828e-01, time/batch = 18.6038s	
14209/16650 (epoch 42.670), train_loss = 0.58955878, grad/param norm = 3.0660e-01, time/batch = 19.2866s	
14210/16650 (epoch 42.673), train_loss = 0.61232968, grad/param norm = 2.8983e-01, time/batch = 15.3409s	
14211/16650 (epoch 42.676), train_loss = 0.74668159, grad/param norm = 3.1227e-01, time/batch = 17.3295s	
14212/16650 (epoch 42.679), train_loss = 0.62795380, grad/param norm = 3.2634e-01, time/batch = 17.1903s	
14213/16650 (epoch 42.682), train_loss = 0.68012528, grad/param norm = 3.5029e-01, time/batch = 17.3528s	
14214/16650 (epoch 42.685), train_loss = 0.56422950, grad/param norm = 2.8239e-01, time/batch = 16.2513s	
14215/16650 (epoch 42.688), train_loss = 0.72899172, grad/param norm = 3.1466e-01, time/batch = 18.0368s	
14216/16650 (epoch 42.691), train_loss = 0.69896905, grad/param norm = 2.8956e-01, time/batch = 18.3555s	
14217/16650 (epoch 42.694), train_loss = 0.62781986, grad/param norm = 3.3695e-01, time/batch = 17.2620s	
14218/16650 (epoch 42.697), train_loss = 0.58734846, grad/param norm = 2.4631e-01, time/batch = 17.0071s	
14219/16650 (epoch 42.700), train_loss = 0.71539271, grad/param norm = 3.1745e-01, time/batch = 17.2741s	
14220/16650 (epoch 42.703), train_loss = 0.59803292, grad/param norm = 3.0735e-01, time/batch = 18.8265s	
14221/16650 (epoch 42.706), train_loss = 0.67530012, grad/param norm = 3.4054e-01, time/batch = 15.3927s	
14222/16650 (epoch 42.709), train_loss = 0.57266216, grad/param norm = 2.8683e-01, time/batch = 17.9293s	
14223/16650 (epoch 42.712), train_loss = 0.61446464, grad/param norm = 3.3303e-01, time/batch = 18.0866s	
14224/16650 (epoch 42.715), train_loss = 0.71577009, grad/param norm = 3.7795e-01, time/batch = 17.0703s	
14225/16650 (epoch 42.718), train_loss = 0.74942226, grad/param norm = 3.1161e-01, time/batch = 17.2821s	
14226/16650 (epoch 42.721), train_loss = 0.76000632, grad/param norm = 3.1083e-01, time/batch = 18.1815s	
14227/16650 (epoch 42.724), train_loss = 0.73396322, grad/param norm = 3.2707e-01, time/batch = 18.5200s	
14228/16650 (epoch 42.727), train_loss = 0.75041854, grad/param norm = 2.9892e-01, time/batch = 16.3168s	
14229/16650 (epoch 42.730), train_loss = 0.62849351, grad/param norm = 2.9512e-01, time/batch = 18.1833s	
14230/16650 (epoch 42.733), train_loss = 0.78198703, grad/param norm = 3.2699e-01, time/batch = 17.6887s	
14231/16650 (epoch 42.736), train_loss = 0.56367352, grad/param norm = 2.7289e-01, time/batch = 16.0846s	
14232/16650 (epoch 42.739), train_loss = 0.69271222, grad/param norm = 3.2840e-01, time/batch = 14.5424s	
14233/16650 (epoch 42.742), train_loss = 0.67597156, grad/param norm = 2.7003e-01, time/batch = 17.5157s	
14234/16650 (epoch 42.745), train_loss = 0.54051309, grad/param norm = 3.1550e-01, time/batch = 18.6428s	
14235/16650 (epoch 42.748), train_loss = 0.57452934, grad/param norm = 2.7603e-01, time/batch = 17.5110s	
14236/16650 (epoch 42.751), train_loss = 0.68956699, grad/param norm = 4.0016e-01, time/batch = 15.8683s	
14237/16650 (epoch 42.754), train_loss = 0.83769881, grad/param norm = 3.6876e-01, time/batch = 18.3607s	
14238/16650 (epoch 42.757), train_loss = 0.82932962, grad/param norm = 3.6489e-01, time/batch = 17.0844s	
14239/16650 (epoch 42.760), train_loss = 0.68360536, grad/param norm = 3.2075e-01, time/batch = 16.0860s	
14240/16650 (epoch 42.763), train_loss = 0.65102301, grad/param norm = 3.1296e-01, time/batch = 14.9840s	
14241/16650 (epoch 42.766), train_loss = 0.64417460, grad/param norm = 2.6313e-01, time/batch = 18.7007s	
14242/16650 (epoch 42.769), train_loss = 0.71454633, grad/param norm = 2.9924e-01, time/batch = 16.3264s	
14243/16650 (epoch 42.772), train_loss = 0.69491212, grad/param norm = 2.8913e-01, time/batch = 17.7778s	
14244/16650 (epoch 42.775), train_loss = 0.68775676, grad/param norm = 3.7532e-01, time/batch = 18.1023s	
14245/16650 (epoch 42.778), train_loss = 0.69844084, grad/param norm = 2.6260e-01, time/batch = 16.7452s	
14246/16650 (epoch 42.781), train_loss = 0.82254987, grad/param norm = 3.0508e-01, time/batch = 17.0062s	
14247/16650 (epoch 42.784), train_loss = 0.71773344, grad/param norm = 3.5028e-01, time/batch = 16.6954s	
14248/16650 (epoch 42.787), train_loss = 0.76424326, grad/param norm = 3.7351e-01, time/batch = 17.8809s	
14249/16650 (epoch 42.790), train_loss = 0.78194766, grad/param norm = 2.9980e-01, time/batch = 17.4861s	
14250/16650 (epoch 42.793), train_loss = 0.59145401, grad/param norm = 3.1691e-01, time/batch = 17.6140s	
14251/16650 (epoch 42.796), train_loss = 0.93065467, grad/param norm = 4.2996e-01, time/batch = 18.3572s	
14252/16650 (epoch 42.799), train_loss = 0.81267702, grad/param norm = 3.3384e-01, time/batch = 16.8425s	
14253/16650 (epoch 42.802), train_loss = 0.75767693, grad/param norm = 3.0867e-01, time/batch = 17.6938s	
14254/16650 (epoch 42.805), train_loss = 0.71756083, grad/param norm = 2.9128e-01, time/batch = 18.6952s	
14255/16650 (epoch 42.808), train_loss = 0.76377346, grad/param norm = 3.1243e-01, time/batch = 16.9453s	
14256/16650 (epoch 42.811), train_loss = 0.80625530, grad/param norm = 3.1455e-01, time/batch = 18.9314s	
14257/16650 (epoch 42.814), train_loss = 0.63014072, grad/param norm = 2.7966e-01, time/batch = 18.4529s	
14258/16650 (epoch 42.817), train_loss = 0.63754103, grad/param norm = 2.9567e-01, time/batch = 13.9670s	
14259/16650 (epoch 42.820), train_loss = 0.76642485, grad/param norm = 3.1712e-01, time/batch = 14.1367s	
14260/16650 (epoch 42.823), train_loss = 0.71402623, grad/param norm = 2.8121e-01, time/batch = 13.7199s	
14261/16650 (epoch 42.826), train_loss = 0.65620260, grad/param norm = 3.0696e-01, time/batch = 17.4195s	
14262/16650 (epoch 42.829), train_loss = 0.69197420, grad/param norm = 2.8819e-01, time/batch = 18.2877s	
14263/16650 (epoch 42.832), train_loss = 0.76601963, grad/param norm = 3.1583e-01, time/batch = 15.6930s	
14264/16650 (epoch 42.835), train_loss = 0.77430291, grad/param norm = 4.3825e-01, time/batch = 18.3658s	
14265/16650 (epoch 42.838), train_loss = 0.62668438, grad/param norm = 2.7201e-01, time/batch = 15.6733s	
14266/16650 (epoch 42.841), train_loss = 0.64355980, grad/param norm = 2.7051e-01, time/batch = 16.7566s	
14267/16650 (epoch 42.844), train_loss = 0.67069645, grad/param norm = 2.6821e-01, time/batch = 16.6740s	
14268/16650 (epoch 42.847), train_loss = 0.75970513, grad/param norm = 3.1576e-01, time/batch = 17.7915s	
14269/16650 (epoch 42.850), train_loss = 0.65619763, grad/param norm = 3.5282e-01, time/batch = 18.8520s	
14270/16650 (epoch 42.853), train_loss = 0.67095288, grad/param norm = 2.6687e-01, time/batch = 14.9001s	
14271/16650 (epoch 42.856), train_loss = 0.64092117, grad/param norm = 2.6894e-01, time/batch = 18.6987s	
14272/16650 (epoch 42.859), train_loss = 0.76366074, grad/param norm = 3.2824e-01, time/batch = 17.0373s	
14273/16650 (epoch 42.862), train_loss = 0.72032178, grad/param norm = 3.0501e-01, time/batch = 16.8581s	
14274/16650 (epoch 42.865), train_loss = 0.55084291, grad/param norm = 2.5279e-01, time/batch = 17.1857s	
14275/16650 (epoch 42.868), train_loss = 0.70497980, grad/param norm = 2.8615e-01, time/batch = 17.1100s	
14276/16650 (epoch 42.871), train_loss = 0.72603952, grad/param norm = 3.0358e-01, time/batch = 16.2987s	
14277/16650 (epoch 42.874), train_loss = 0.70427183, grad/param norm = 2.8885e-01, time/batch = 17.6817s	
14278/16650 (epoch 42.877), train_loss = 0.68705048, grad/param norm = 2.7460e-01, time/batch = 18.7113s	
14279/16650 (epoch 42.880), train_loss = 0.63529306, grad/param norm = 2.8314e-01, time/batch = 17.0285s	
14280/16650 (epoch 42.883), train_loss = 0.70621748, grad/param norm = 2.7596e-01, time/batch = 24.9909s	
14281/16650 (epoch 42.886), train_loss = 0.70407646, grad/param norm = 3.4460e-01, time/batch = 21.8008s	
14282/16650 (epoch 42.889), train_loss = 0.58916061, grad/param norm = 3.3962e-01, time/batch = 17.1885s	
14283/16650 (epoch 42.892), train_loss = 0.70557834, grad/param norm = 3.1709e-01, time/batch = 15.2534s	
14284/16650 (epoch 42.895), train_loss = 0.72937608, grad/param norm = 3.3919e-01, time/batch = 18.8421s	
14285/16650 (epoch 42.898), train_loss = 0.70843696, grad/param norm = 3.1512e-01, time/batch = 17.5210s	
14286/16650 (epoch 42.901), train_loss = 0.64133318, grad/param norm = 3.0483e-01, time/batch = 17.1015s	
14287/16650 (epoch 42.904), train_loss = 0.66738415, grad/param norm = 3.3440e-01, time/batch = 14.7335s	
14288/16650 (epoch 42.907), train_loss = 0.71221261, grad/param norm = 3.3366e-01, time/batch = 15.1528s	
14289/16650 (epoch 42.910), train_loss = 0.74204702, grad/param norm = 3.6000e-01, time/batch = 16.4200s	
14290/16650 (epoch 42.913), train_loss = 0.66613574, grad/param norm = 3.2210e-01, time/batch = 17.3291s	
14291/16650 (epoch 42.916), train_loss = 0.62921833, grad/param norm = 3.2001e-01, time/batch = 17.9317s	
14292/16650 (epoch 42.919), train_loss = 0.80399665, grad/param norm = 2.9512e-01, time/batch = 17.6028s	
14293/16650 (epoch 42.922), train_loss = 0.69183203, grad/param norm = 3.4444e-01, time/batch = 16.8382s	
14294/16650 (epoch 42.925), train_loss = 0.64876273, grad/param norm = 2.9708e-01, time/batch = 17.6833s	
14295/16650 (epoch 42.928), train_loss = 0.70277027, grad/param norm = 3.5435e-01, time/batch = 17.7053s	
14296/16650 (epoch 42.931), train_loss = 0.69645740, grad/param norm = 2.9164e-01, time/batch = 18.6169s	
14297/16650 (epoch 42.934), train_loss = 0.57909459, grad/param norm = 3.7725e-01, time/batch = 16.4092s	
14298/16650 (epoch 42.937), train_loss = 0.62786509, grad/param norm = 2.9970e-01, time/batch = 16.4288s	
14299/16650 (epoch 42.940), train_loss = 0.69908207, grad/param norm = 3.5907e-01, time/batch = 16.5278s	
14300/16650 (epoch 42.943), train_loss = 0.71751102, grad/param norm = 3.6642e-01, time/batch = 17.3537s	
14301/16650 (epoch 42.946), train_loss = 0.64338867, grad/param norm = 2.9031e-01, time/batch = 16.2579s	
14302/16650 (epoch 42.949), train_loss = 0.61038449, grad/param norm = 3.1865e-01, time/batch = 19.1980s	
14303/16650 (epoch 42.952), train_loss = 0.60022616, grad/param norm = 3.0764e-01, time/batch = 15.9446s	
14304/16650 (epoch 42.955), train_loss = 0.69394739, grad/param norm = 2.8691e-01, time/batch = 16.6510s	
14305/16650 (epoch 42.958), train_loss = 0.74154615, grad/param norm = 3.8234e-01, time/batch = 16.0858s	
14306/16650 (epoch 42.961), train_loss = 0.67131882, grad/param norm = 2.5303e-01, time/batch = 17.2516s	
14307/16650 (epoch 42.964), train_loss = 0.60296425, grad/param norm = 3.3838e-01, time/batch = 17.6044s	
14308/16650 (epoch 42.967), train_loss = 0.81651270, grad/param norm = 3.7664e-01, time/batch = 17.3545s	
14309/16650 (epoch 42.970), train_loss = 0.65381508, grad/param norm = 3.1053e-01, time/batch = 18.0279s	
14310/16650 (epoch 42.973), train_loss = 0.64863253, grad/param norm = 3.2431e-01, time/batch = 17.3685s	
14311/16650 (epoch 42.976), train_loss = 0.62439630, grad/param norm = 2.9842e-01, time/batch = 16.9332s	
14312/16650 (epoch 42.979), train_loss = 0.71327352, grad/param norm = 3.7908e-01, time/batch = 18.2025s	
14313/16650 (epoch 42.982), train_loss = 0.74072810, grad/param norm = 3.0807e-01, time/batch = 15.0942s	
14314/16650 (epoch 42.985), train_loss = 0.69461000, grad/param norm = 2.7068e-01, time/batch = 16.9082s	
14315/16650 (epoch 42.988), train_loss = 0.71846052, grad/param norm = 3.2684e-01, time/batch = 16.7457s	
14316/16650 (epoch 42.991), train_loss = 0.62511092, grad/param norm = 3.7250e-01, time/batch = 16.9799s	
14317/16650 (epoch 42.994), train_loss = 0.64291564, grad/param norm = 2.8555e-01, time/batch = 16.0105s	
14318/16650 (epoch 42.997), train_loss = 0.64084102, grad/param norm = 3.0382e-01, time/batch = 17.0110s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
14319/16650 (epoch 43.000), train_loss = 0.75456322, grad/param norm = 3.7872e-01, time/batch = 15.6671s	
14320/16650 (epoch 43.003), train_loss = 0.81498641, grad/param norm = 3.6328e-01, time/batch = 18.4473s	
14321/16650 (epoch 43.006), train_loss = 0.78443576, grad/param norm = 3.1206e-01, time/batch = 17.6759s	
14322/16650 (epoch 43.009), train_loss = 0.81057415, grad/param norm = 3.4613e-01, time/batch = 15.9342s	
14323/16650 (epoch 43.012), train_loss = 0.77819979, grad/param norm = 3.0098e-01, time/batch = 16.9370s	
14324/16650 (epoch 43.015), train_loss = 0.69836501, grad/param norm = 3.0701e-01, time/batch = 16.4380s	
14325/16650 (epoch 43.018), train_loss = 0.61128728, grad/param norm = 3.1557e-01, time/batch = 15.3400s	
14326/16650 (epoch 43.021), train_loss = 0.81995513, grad/param norm = 3.5552e-01, time/batch = 18.1035s	
14327/16650 (epoch 43.024), train_loss = 0.69752516, grad/param norm = 3.2958e-01, time/batch = 18.9530s	
14328/16650 (epoch 43.027), train_loss = 0.72834799, grad/param norm = 2.7895e-01, time/batch = 15.5927s	
14329/16650 (epoch 43.030), train_loss = 0.60655604, grad/param norm = 3.1626e-01, time/batch = 17.6941s	
14330/16650 (epoch 43.033), train_loss = 0.67933166, grad/param norm = 2.6524e-01, time/batch = 17.1214s	
14331/16650 (epoch 43.036), train_loss = 0.48104225, grad/param norm = 2.9367e-01, time/batch = 17.7770s	
14332/16650 (epoch 43.039), train_loss = 0.78406466, grad/param norm = 2.9202e-01, time/batch = 25.2983s	
14333/16650 (epoch 43.042), train_loss = 0.73211852, grad/param norm = 3.3991e-01, time/batch = 40.4282s	
14334/16650 (epoch 43.045), train_loss = 0.71758265, grad/param norm = 2.8170e-01, time/batch = 31.5189s	
14335/16650 (epoch 43.048), train_loss = 0.78299690, grad/param norm = 3.5385e-01, time/batch = 37.1776s	
14336/16650 (epoch 43.051), train_loss = 0.69345586, grad/param norm = 3.3585e-01, time/batch = 36.8824s	
14337/16650 (epoch 43.054), train_loss = 0.70471077, grad/param norm = 3.2162e-01, time/batch = 33.8934s	
14338/16650 (epoch 43.057), train_loss = 0.69043895, grad/param norm = 3.4174e-01, time/batch = 29.8607s	
14339/16650 (epoch 43.060), train_loss = 0.58545549, grad/param norm = 2.7896e-01, time/batch = 35.1695s	
14340/16650 (epoch 43.063), train_loss = 0.64721055, grad/param norm = 2.7968e-01, time/batch = 39.0191s	
14341/16650 (epoch 43.066), train_loss = 0.82495624, grad/param norm = 3.0594e-01, time/batch = 38.0786s	
14342/16650 (epoch 43.069), train_loss = 0.74531863, grad/param norm = 3.4329e-01, time/batch = 35.2910s	
14343/16650 (epoch 43.072), train_loss = 0.70781444, grad/param norm = 3.4498e-01, time/batch = 21.1424s	
14344/16650 (epoch 43.075), train_loss = 0.77304009, grad/param norm = 2.9779e-01, time/batch = 14.4468s	
14345/16650 (epoch 43.078), train_loss = 0.76868869, grad/param norm = 3.8250e-01, time/batch = 14.8080s	
14346/16650 (epoch 43.081), train_loss = 0.71833265, grad/param norm = 3.2533e-01, time/batch = 15.4994s	
14347/16650 (epoch 43.084), train_loss = 0.70873811, grad/param norm = 3.1786e-01, time/batch = 17.3592s	
14348/16650 (epoch 43.087), train_loss = 0.73051938, grad/param norm = 3.2266e-01, time/batch = 16.9477s	
14349/16650 (epoch 43.090), train_loss = 0.68726628, grad/param norm = 3.3176e-01, time/batch = 17.8337s	
14350/16650 (epoch 43.093), train_loss = 0.80844785, grad/param norm = 3.8079e-01, time/batch = 18.1020s	
14351/16650 (epoch 43.096), train_loss = 0.64746563, grad/param norm = 3.0469e-01, time/batch = 18.4309s	
14352/16650 (epoch 43.099), train_loss = 0.71334717, grad/param norm = 3.0783e-01, time/batch = 15.9197s	
14353/16650 (epoch 43.102), train_loss = 0.72394828, grad/param norm = 3.3901e-01, time/batch = 15.8353s	
14354/16650 (epoch 43.105), train_loss = 0.69857087, grad/param norm = 3.2228e-01, time/batch = 18.5840s	
14355/16650 (epoch 43.108), train_loss = 0.74644104, grad/param norm = 3.2640e-01, time/batch = 16.6043s	
14356/16650 (epoch 43.111), train_loss = 0.78680992, grad/param norm = 3.0879e-01, time/batch = 17.2565s	
14357/16650 (epoch 43.114), train_loss = 0.74436456, grad/param norm = 4.5768e-01, time/batch = 18.1899s	
14358/16650 (epoch 43.117), train_loss = 0.83887751, grad/param norm = 3.3997e-01, time/batch = 17.4253s	
14359/16650 (epoch 43.120), train_loss = 0.71784699, grad/param norm = 2.7753e-01, time/batch = 16.3655s	
14360/16650 (epoch 43.123), train_loss = 0.66835626, grad/param norm = 2.7102e-01, time/batch = 16.8442s	
14361/16650 (epoch 43.126), train_loss = 0.74836421, grad/param norm = 3.0489e-01, time/batch = 15.8316s	
14362/16650 (epoch 43.129), train_loss = 0.76458008, grad/param norm = 3.5343e-01, time/batch = 16.4051s	
14363/16650 (epoch 43.132), train_loss = 0.69686109, grad/param norm = 3.2340e-01, time/batch = 17.0819s	
14364/16650 (epoch 43.135), train_loss = 0.80173756, grad/param norm = 2.9648e-01, time/batch = 17.1174s	
14365/16650 (epoch 43.138), train_loss = 0.78178402, grad/param norm = 3.4163e-01, time/batch = 16.3475s	
14366/16650 (epoch 43.141), train_loss = 0.75716274, grad/param norm = 4.1227e-01, time/batch = 15.9095s	
14367/16650 (epoch 43.144), train_loss = 0.75325739, grad/param norm = 3.3491e-01, time/batch = 15.9589s	
14368/16650 (epoch 43.147), train_loss = 0.83592986, grad/param norm = 3.6896e-01, time/batch = 15.9373s	
14369/16650 (epoch 43.150), train_loss = 0.93306706, grad/param norm = 9.4506e-01, time/batch = 16.5211s	
14370/16650 (epoch 43.153), train_loss = 0.73574092, grad/param norm = 3.2761e-01, time/batch = 15.3273s	
14371/16650 (epoch 43.156), train_loss = 0.73689691, grad/param norm = 3.4287e-01, time/batch = 16.5110s	
14372/16650 (epoch 43.159), train_loss = 0.77790238, grad/param norm = 4.3004e-01, time/batch = 17.0298s	
14373/16650 (epoch 43.162), train_loss = 0.84620707, grad/param norm = 3.6618e-01, time/batch = 16.9267s	
14374/16650 (epoch 43.165), train_loss = 0.82020854, grad/param norm = 3.3489e-01, time/batch = 16.4521s	
14375/16650 (epoch 43.168), train_loss = 0.60803883, grad/param norm = 2.5931e-01, time/batch = 15.9689s	
14376/16650 (epoch 43.171), train_loss = 0.79438778, grad/param norm = 3.7195e-01, time/batch = 17.1845s	
14377/16650 (epoch 43.174), train_loss = 0.58976612, grad/param norm = 2.8425e-01, time/batch = 16.1737s	
14378/16650 (epoch 43.177), train_loss = 0.70855385, grad/param norm = 3.5053e-01, time/batch = 14.9786s	
14379/16650 (epoch 43.180), train_loss = 0.81802124, grad/param norm = 3.2441e-01, time/batch = 16.2122s	
14380/16650 (epoch 43.183), train_loss = 0.94579717, grad/param norm = 4.1070e-01, time/batch = 16.4458s	
14381/16650 (epoch 43.186), train_loss = 0.76538602, grad/param norm = 3.9312e-01, time/batch = 17.0099s	
14382/16650 (epoch 43.189), train_loss = 0.67016577, grad/param norm = 2.7846e-01, time/batch = 18.1327s	
14383/16650 (epoch 43.192), train_loss = 0.70954092, grad/param norm = 3.0249e-01, time/batch = 16.0365s	
14384/16650 (epoch 43.195), train_loss = 0.66367181, grad/param norm = 3.8484e-01, time/batch = 16.0887s	
14385/16650 (epoch 43.198), train_loss = 0.63173831, grad/param norm = 2.4622e-01, time/batch = 17.7529s	
14386/16650 (epoch 43.201), train_loss = 0.63582041, grad/param norm = 3.0441e-01, time/batch = 15.9242s	
14387/16650 (epoch 43.204), train_loss = 0.73833283, grad/param norm = 3.4784e-01, time/batch = 17.3713s	
14388/16650 (epoch 43.207), train_loss = 0.77919122, grad/param norm = 3.7138e-01, time/batch = 16.0114s	
14389/16650 (epoch 43.210), train_loss = 0.71169539, grad/param norm = 3.7217e-01, time/batch = 17.1247s	
14390/16650 (epoch 43.213), train_loss = 0.77291801, grad/param norm = 3.5248e-01, time/batch = 16.8717s	
14391/16650 (epoch 43.216), train_loss = 0.64748903, grad/param norm = 3.4230e-01, time/batch = 16.3518s	
14392/16650 (epoch 43.219), train_loss = 0.71100989, grad/param norm = 3.3652e-01, time/batch = 16.0218s	
14393/16650 (epoch 43.222), train_loss = 0.73010659, grad/param norm = 2.7609e-01, time/batch = 15.6727s	
14394/16650 (epoch 43.225), train_loss = 0.74603519, grad/param norm = 3.6073e-01, time/batch = 15.5200s	
14395/16650 (epoch 43.228), train_loss = 0.67123769, grad/param norm = 3.2789e-01, time/batch = 14.9075s	
14396/16650 (epoch 43.231), train_loss = 0.65730229, grad/param norm = 3.7659e-01, time/batch = 17.6106s	
14397/16650 (epoch 43.234), train_loss = 0.85274954, grad/param norm = 3.5622e-01, time/batch = 17.5371s	
14398/16650 (epoch 43.237), train_loss = 0.74304883, grad/param norm = 3.1741e-01, time/batch = 16.2815s	
14399/16650 (epoch 43.240), train_loss = 0.73966927, grad/param norm = 2.7227e-01, time/batch = 15.7476s	
14400/16650 (epoch 43.243), train_loss = 0.71239554, grad/param norm = 4.1719e-01, time/batch = 17.1954s	
14401/16650 (epoch 43.246), train_loss = 0.83209709, grad/param norm = 4.0267e-01, time/batch = 17.2906s	
14402/16650 (epoch 43.249), train_loss = 0.60079224, grad/param norm = 2.3035e-01, time/batch = 15.3983s	
14403/16650 (epoch 43.252), train_loss = 0.69895107, grad/param norm = 3.2484e-01, time/batch = 16.0225s	
14404/16650 (epoch 43.255), train_loss = 0.75176454, grad/param norm = 3.3697e-01, time/batch = 15.3916s	
14405/16650 (epoch 43.258), train_loss = 0.79276581, grad/param norm = 3.1565e-01, time/batch = 17.5363s	
14406/16650 (epoch 43.261), train_loss = 0.74405614, grad/param norm = 3.3408e-01, time/batch = 15.8381s	
14407/16650 (epoch 43.264), train_loss = 0.65398325, grad/param norm = 2.7601e-01, time/batch = 17.6163s	
14408/16650 (epoch 43.267), train_loss = 0.69171820, grad/param norm = 3.2887e-01, time/batch = 17.0981s	
14409/16650 (epoch 43.270), train_loss = 0.76383213, grad/param norm = 3.3290e-01, time/batch = 17.0340s	
14410/16650 (epoch 43.273), train_loss = 0.78913894, grad/param norm = 2.9855e-01, time/batch = 16.7512s	
14411/16650 (epoch 43.276), train_loss = 0.76367817, grad/param norm = 3.0079e-01, time/batch = 15.5860s	
14412/16650 (epoch 43.279), train_loss = 0.69283709, grad/param norm = 2.8740e-01, time/batch = 16.4193s	
14413/16650 (epoch 43.282), train_loss = 0.66733321, grad/param norm = 2.8901e-01, time/batch = 16.8600s	
14414/16650 (epoch 43.285), train_loss = 0.69370471, grad/param norm = 3.1989e-01, time/batch = 16.3776s	
14415/16650 (epoch 43.288), train_loss = 0.61988417, grad/param norm = 2.8368e-01, time/batch = 17.2100s	
14416/16650 (epoch 43.291), train_loss = 0.51411852, grad/param norm = 2.3002e-01, time/batch = 14.0631s	
14417/16650 (epoch 43.294), train_loss = 0.64110613, grad/param norm = 2.8121e-01, time/batch = 14.9263s	
14418/16650 (epoch 43.297), train_loss = 0.70029454, grad/param norm = 2.8847e-01, time/batch = 17.1197s	
14419/16650 (epoch 43.300), train_loss = 0.54531042, grad/param norm = 2.3962e-01, time/batch = 17.5363s	
14420/16650 (epoch 43.303), train_loss = 0.60810377, grad/param norm = 2.7839e-01, time/batch = 17.4307s	
14421/16650 (epoch 43.306), train_loss = 0.77105300, grad/param norm = 2.7167e-01, time/batch = 16.6987s	
14422/16650 (epoch 43.309), train_loss = 0.75320892, grad/param norm = 3.1674e-01, time/batch = 18.2961s	
14423/16650 (epoch 43.312), train_loss = 0.58784220, grad/param norm = 3.0499e-01, time/batch = 16.2594s	
14424/16650 (epoch 43.315), train_loss = 0.51289740, grad/param norm = 2.9766e-01, time/batch = 14.8078s	
14425/16650 (epoch 43.318), train_loss = 0.59437161, grad/param norm = 4.0734e-01, time/batch = 16.5434s	
14426/16650 (epoch 43.321), train_loss = 0.79403703, grad/param norm = 4.0378e-01, time/batch = 17.9443s	
14427/16650 (epoch 43.324), train_loss = 0.65220785, grad/param norm = 3.4830e-01, time/batch = 17.0439s	
14428/16650 (epoch 43.327), train_loss = 0.71989053, grad/param norm = 3.5184e-01, time/batch = 15.4965s	
14429/16650 (epoch 43.330), train_loss = 0.69881074, grad/param norm = 3.5150e-01, time/batch = 16.7457s	
14430/16650 (epoch 43.333), train_loss = 0.76077194, grad/param norm = 3.6662e-01, time/batch = 16.7816s	
14431/16650 (epoch 43.336), train_loss = 0.61709983, grad/param norm = 3.1531e-01, time/batch = 14.8102s	
14432/16650 (epoch 43.339), train_loss = 0.63443934, grad/param norm = 3.3551e-01, time/batch = 16.1845s	
14433/16650 (epoch 43.342), train_loss = 0.59113593, grad/param norm = 2.9837e-01, time/batch = 17.7058s	
14434/16650 (epoch 43.345), train_loss = 0.63473889, grad/param norm = 2.5867e-01, time/batch = 18.1113s	
14435/16650 (epoch 43.348), train_loss = 0.73446052, grad/param norm = 3.2048e-01, time/batch = 16.0849s	
14436/16650 (epoch 43.351), train_loss = 0.73270229, grad/param norm = 3.3296e-01, time/batch = 17.7109s	
14437/16650 (epoch 43.354), train_loss = 0.75189100, grad/param norm = 3.0554e-01, time/batch = 17.6124s	
14438/16650 (epoch 43.357), train_loss = 0.71416029, grad/param norm = 2.8182e-01, time/batch = 16.7671s	
14439/16650 (epoch 43.360), train_loss = 0.72142733, grad/param norm = 3.5550e-01, time/batch = 14.1902s	
14440/16650 (epoch 43.363), train_loss = 0.78543680, grad/param norm = 3.4813e-01, time/batch = 15.0690s	
14441/16650 (epoch 43.366), train_loss = 0.83486949, grad/param norm = 3.5373e-01, time/batch = 17.4575s	
14442/16650 (epoch 43.369), train_loss = 0.75646680, grad/param norm = 2.9660e-01, time/batch = 15.5709s	
14443/16650 (epoch 43.372), train_loss = 0.72415319, grad/param norm = 3.0911e-01, time/batch = 16.2781s	
14444/16650 (epoch 43.375), train_loss = 0.72479863, grad/param norm = 2.8451e-01, time/batch = 17.5499s	
14445/16650 (epoch 43.378), train_loss = 0.67285776, grad/param norm = 2.9334e-01, time/batch = 16.7930s	
14446/16650 (epoch 43.381), train_loss = 0.78181315, grad/param norm = 3.7097e-01, time/batch = 15.4060s	
14447/16650 (epoch 43.384), train_loss = 0.82998918, grad/param norm = 3.3658e-01, time/batch = 17.0401s	
14448/16650 (epoch 43.387), train_loss = 0.55688565, grad/param norm = 2.4415e-01, time/batch = 16.6113s	
14449/16650 (epoch 43.390), train_loss = 0.76327776, grad/param norm = 3.0131e-01, time/batch = 15.2987s	
14450/16650 (epoch 43.393), train_loss = 0.69796904, grad/param norm = 3.5956e-01, time/batch = 16.8655s	
14451/16650 (epoch 43.396), train_loss = 0.81125370, grad/param norm = 3.0477e-01, time/batch = 16.2790s	
14452/16650 (epoch 43.399), train_loss = 0.76589105, grad/param norm = 3.0209e-01, time/batch = 15.7698s	
14453/16650 (epoch 43.402), train_loss = 0.70118627, grad/param norm = 3.6623e-01, time/batch = 15.3522s	
14454/16650 (epoch 43.405), train_loss = 0.56561494, grad/param norm = 3.3553e-01, time/batch = 17.6214s	
14455/16650 (epoch 43.408), train_loss = 0.74364658, grad/param norm = 3.4968e-01, time/batch = 16.7849s	
14456/16650 (epoch 43.411), train_loss = 0.65500413, grad/param norm = 3.6054e-01, time/batch = 17.1065s	
14457/16650 (epoch 43.414), train_loss = 0.63733495, grad/param norm = 3.5866e-01, time/batch = 14.9990s	
14458/16650 (epoch 43.417), train_loss = 0.60834467, grad/param norm = 3.1162e-01, time/batch = 17.2633s	
14459/16650 (epoch 43.420), train_loss = 0.64311792, grad/param norm = 2.9465e-01, time/batch = 16.7703s	
14460/16650 (epoch 43.423), train_loss = 0.52340215, grad/param norm = 2.6520e-01, time/batch = 16.2603s	
14461/16650 (epoch 43.426), train_loss = 0.60732277, grad/param norm = 2.9317e-01, time/batch = 17.1275s	
14462/16650 (epoch 43.429), train_loss = 0.76954155, grad/param norm = 3.2382e-01, time/batch = 17.3738s	
14463/16650 (epoch 43.432), train_loss = 0.76773207, grad/param norm = 3.4700e-01, time/batch = 17.4474s	
14464/16650 (epoch 43.435), train_loss = 0.83746319, grad/param norm = 3.0678e-01, time/batch = 15.5055s	
14465/16650 (epoch 43.438), train_loss = 0.85917256, grad/param norm = 3.9925e-01, time/batch = 17.0472s	
14466/16650 (epoch 43.441), train_loss = 0.68758134, grad/param norm = 4.0376e-01, time/batch = 16.8545s	
14467/16650 (epoch 43.444), train_loss = 0.67038770, grad/param norm = 4.0258e-01, time/batch = 16.1920s	
14468/16650 (epoch 43.447), train_loss = 0.65698994, grad/param norm = 3.2467e-01, time/batch = 15.1637s	
14469/16650 (epoch 43.450), train_loss = 0.64801621, grad/param norm = 3.0815e-01, time/batch = 17.6783s	
14470/16650 (epoch 43.453), train_loss = 0.63958007, grad/param norm = 2.9230e-01, time/batch = 15.6777s	
14471/16650 (epoch 43.456), train_loss = 0.61024263, grad/param norm = 2.5357e-01, time/batch = 15.8522s	
14472/16650 (epoch 43.459), train_loss = 0.63834188, grad/param norm = 3.0599e-01, time/batch = 15.4836s	
14473/16650 (epoch 43.462), train_loss = 0.79102700, grad/param norm = 3.7880e-01, time/batch = 16.5941s	
14474/16650 (epoch 43.465), train_loss = 0.63692711, grad/param norm = 2.9122e-01, time/batch = 17.6219s	
14475/16650 (epoch 43.468), train_loss = 0.52957198, grad/param norm = 2.7254e-01, time/batch = 16.4376s	
14476/16650 (epoch 43.471), train_loss = 0.46827061, grad/param norm = 2.3818e-01, time/batch = 16.7733s	
14477/16650 (epoch 43.474), train_loss = 0.62486782, grad/param norm = 3.0667e-01, time/batch = 16.6883s	
14478/16650 (epoch 43.477), train_loss = 0.75527420, grad/param norm = 3.7782e-01, time/batch = 16.1809s	
14479/16650 (epoch 43.480), train_loss = 0.65473631, grad/param norm = 3.2674e-01, time/batch = 15.9456s	
14480/16650 (epoch 43.483), train_loss = 0.75943239, grad/param norm = 3.5926e-01, time/batch = 18.0505s	
14481/16650 (epoch 43.486), train_loss = 0.60889865, grad/param norm = 2.5620e-01, time/batch = 18.0424s	
14482/16650 (epoch 43.489), train_loss = 0.68366584, grad/param norm = 2.9227e-01, time/batch = 25.0842s	
14483/16650 (epoch 43.492), train_loss = 0.68573699, grad/param norm = 2.8235e-01, time/batch = 25.6137s	
14484/16650 (epoch 43.495), train_loss = 0.57597015, grad/param norm = 2.9795e-01, time/batch = 16.0128s	
14485/16650 (epoch 43.498), train_loss = 0.65167999, grad/param norm = 3.8057e-01, time/batch = 17.3583s	
14486/16650 (epoch 43.502), train_loss = 0.81568641, grad/param norm = 3.7794e-01, time/batch = 14.6535s	
14487/16650 (epoch 43.505), train_loss = 0.71260483, grad/param norm = 2.7717e-01, time/batch = 18.3640s	
14488/16650 (epoch 43.508), train_loss = 0.76894478, grad/param norm = 3.8557e-01, time/batch = 15.6712s	
14489/16650 (epoch 43.511), train_loss = 0.73522367, grad/param norm = 2.9997e-01, time/batch = 15.7590s	
14490/16650 (epoch 43.514), train_loss = 0.59742848, grad/param norm = 3.0013e-01, time/batch = 17.2610s	
14491/16650 (epoch 43.517), train_loss = 0.65785891, grad/param norm = 3.3111e-01, time/batch = 16.5366s	
14492/16650 (epoch 43.520), train_loss = 0.57911026, grad/param norm = 3.2821e-01, time/batch = 17.0959s	
14493/16650 (epoch 43.523), train_loss = 0.67442833, grad/param norm = 2.9425e-01, time/batch = 17.1838s	
14494/16650 (epoch 43.526), train_loss = 0.74066452, grad/param norm = 2.7689e-01, time/batch = 17.7992s	
14495/16650 (epoch 43.529), train_loss = 0.78153588, grad/param norm = 3.8639e-01, time/batch = 15.9377s	
14496/16650 (epoch 43.532), train_loss = 0.52707707, grad/param norm = 3.0560e-01, time/batch = 15.5918s	
14497/16650 (epoch 43.535), train_loss = 0.62121992, grad/param norm = 4.1634e-01, time/batch = 18.2058s	
14498/16650 (epoch 43.538), train_loss = 0.55361511, grad/param norm = 2.8907e-01, time/batch = 18.0135s	
14499/16650 (epoch 43.541), train_loss = 0.78795830, grad/param norm = 3.1781e-01, time/batch = 16.5241s	
14500/16650 (epoch 43.544), train_loss = 0.82783510, grad/param norm = 4.2163e-01, time/batch = 17.8747s	
14501/16650 (epoch 43.547), train_loss = 0.57161115, grad/param norm = 2.7320e-01, time/batch = 18.1908s	
14502/16650 (epoch 43.550), train_loss = 0.68591382, grad/param norm = 2.9266e-01, time/batch = 14.3957s	
14503/16650 (epoch 43.553), train_loss = 0.68445034, grad/param norm = 3.6408e-01, time/batch = 17.3725s	
14504/16650 (epoch 43.556), train_loss = 0.61977287, grad/param norm = 2.7942e-01, time/batch = 15.9208s	
14505/16650 (epoch 43.559), train_loss = 0.54932548, grad/param norm = 2.9448e-01, time/batch = 16.3490s	
14506/16650 (epoch 43.562), train_loss = 0.61876074, grad/param norm = 2.9463e-01, time/batch = 16.0006s	
14507/16650 (epoch 43.565), train_loss = 0.53145493, grad/param norm = 2.5856e-01, time/batch = 17.1840s	
14508/16650 (epoch 43.568), train_loss = 0.54040905, grad/param norm = 2.7493e-01, time/batch = 18.3655s	
14509/16650 (epoch 43.571), train_loss = 0.60168670, grad/param norm = 3.4497e-01, time/batch = 16.2672s	
14510/16650 (epoch 43.574), train_loss = 0.58832048, grad/param norm = 3.3340e-01, time/batch = 17.6099s	
14511/16650 (epoch 43.577), train_loss = 0.65135594, grad/param norm = 3.1656e-01, time/batch = 17.4476s	
14512/16650 (epoch 43.580), train_loss = 0.61696836, grad/param norm = 2.6595e-01, time/batch = 17.0407s	
14513/16650 (epoch 43.583), train_loss = 0.70305603, grad/param norm = 2.9083e-01, time/batch = 16.8511s	
14514/16650 (epoch 43.586), train_loss = 0.59016059, grad/param norm = 3.4025e-01, time/batch = 17.3108s	
14515/16650 (epoch 43.589), train_loss = 0.59960913, grad/param norm = 2.6970e-01, time/batch = 17.6155s	
14516/16650 (epoch 43.592), train_loss = 0.67298249, grad/param norm = 3.0209e-01, time/batch = 15.9216s	
14517/16650 (epoch 43.595), train_loss = 0.60619699, grad/param norm = 2.9485e-01, time/batch = 17.6815s	
14518/16650 (epoch 43.598), train_loss = 0.64899739, grad/param norm = 3.3198e-01, time/batch = 17.7809s	
14519/16650 (epoch 43.601), train_loss = 0.63236447, grad/param norm = 4.2955e-01, time/batch = 14.5752s	
14520/16650 (epoch 43.604), train_loss = 0.65479313, grad/param norm = 3.2218e-01, time/batch = 16.3409s	
14521/16650 (epoch 43.607), train_loss = 0.71563404, grad/param norm = 2.9002e-01, time/batch = 17.7191s	
14522/16650 (epoch 43.610), train_loss = 0.60543359, grad/param norm = 2.5555e-01, time/batch = 17.1837s	
14523/16650 (epoch 43.613), train_loss = 0.75362905, grad/param norm = 2.8799e-01, time/batch = 16.0667s	
14524/16650 (epoch 43.616), train_loss = 0.71715588, grad/param norm = 3.9725e-01, time/batch = 16.5154s	
14525/16650 (epoch 43.619), train_loss = 0.57823235, grad/param norm = 3.1255e-01, time/batch = 16.6000s	
14526/16650 (epoch 43.622), train_loss = 0.56056847, grad/param norm = 2.5666e-01, time/batch = 18.2785s	
14527/16650 (epoch 43.625), train_loss = 0.65413315, grad/param norm = 2.6664e-01, time/batch = 15.8297s	
14528/16650 (epoch 43.628), train_loss = 0.63220766, grad/param norm = 5.1536e-01, time/batch = 17.7009s	
14529/16650 (epoch 43.631), train_loss = 0.69651759, grad/param norm = 3.9429e-01, time/batch = 17.6153s	
14530/16650 (epoch 43.634), train_loss = 0.83713080, grad/param norm = 3.7049e-01, time/batch = 16.3654s	
14531/16650 (epoch 43.637), train_loss = 0.81222657, grad/param norm = 3.3126e-01, time/batch = 14.7597s	
14532/16650 (epoch 43.640), train_loss = 0.64956089, grad/param norm = 2.9922e-01, time/batch = 16.9473s	
14533/16650 (epoch 43.643), train_loss = 0.73069485, grad/param norm = 2.9006e-01, time/batch = 17.5401s	
14534/16650 (epoch 43.646), train_loss = 0.71459996, grad/param norm = 3.4677e-01, time/batch = 14.9296s	
14535/16650 (epoch 43.649), train_loss = 0.71403193, grad/param norm = 3.1466e-01, time/batch = 16.2358s	
14536/16650 (epoch 43.652), train_loss = 0.71081353, grad/param norm = 3.1032e-01, time/batch = 16.8363s	
14537/16650 (epoch 43.655), train_loss = 0.67260688, grad/param norm = 3.1951e-01, time/batch = 16.8702s	
14538/16650 (epoch 43.658), train_loss = 0.64543405, grad/param norm = 3.9588e-01, time/batch = 17.4313s	
14539/16650 (epoch 43.661), train_loss = 0.68640360, grad/param norm = 3.1236e-01, time/batch = 17.9607s	
14540/16650 (epoch 43.664), train_loss = 0.68464192, grad/param norm = 3.6136e-01, time/batch = 16.7701s	
14541/16650 (epoch 43.667), train_loss = 0.76464355, grad/param norm = 3.0468e-01, time/batch = 15.8488s	
14542/16650 (epoch 43.670), train_loss = 0.58024163, grad/param norm = 2.9809e-01, time/batch = 16.9456s	
14543/16650 (epoch 43.673), train_loss = 0.59024205, grad/param norm = 2.6592e-01, time/batch = 17.8612s	
14544/16650 (epoch 43.676), train_loss = 0.71623640, grad/param norm = 3.1518e-01, time/batch = 16.9367s	
14545/16650 (epoch 43.679), train_loss = 0.62102398, grad/param norm = 3.1951e-01, time/batch = 15.1783s	
14546/16650 (epoch 43.682), train_loss = 0.68675314, grad/param norm = 4.1997e-01, time/batch = 17.7891s	
14547/16650 (epoch 43.685), train_loss = 0.56595787, grad/param norm = 2.9486e-01, time/batch = 16.5252s	
14548/16650 (epoch 43.688), train_loss = 0.73598100, grad/param norm = 3.0747e-01, time/batch = 14.4731s	
14549/16650 (epoch 43.691), train_loss = 0.70371522, grad/param norm = 3.0546e-01, time/batch = 17.9450s	
14550/16650 (epoch 43.694), train_loss = 0.62602219, grad/param norm = 3.0172e-01, time/batch = 17.7878s	
14551/16650 (epoch 43.697), train_loss = 0.58007521, grad/param norm = 2.5055e-01, time/batch = 17.0191s	
14552/16650 (epoch 43.700), train_loss = 0.70288903, grad/param norm = 3.2471e-01, time/batch = 15.5646s	
14553/16650 (epoch 43.703), train_loss = 0.60123887, grad/param norm = 3.6147e-01, time/batch = 15.0848s	
14554/16650 (epoch 43.706), train_loss = 0.66537084, grad/param norm = 3.7306e-01, time/batch = 17.5135s	
14555/16650 (epoch 43.709), train_loss = 0.57777738, grad/param norm = 2.6819e-01, time/batch = 16.7662s	
14556/16650 (epoch 43.712), train_loss = 0.61260576, grad/param norm = 3.8000e-01, time/batch = 17.0365s	
14557/16650 (epoch 43.715), train_loss = 0.67972650, grad/param norm = 2.9419e-01, time/batch = 17.2902s	
14558/16650 (epoch 43.718), train_loss = 0.73336627, grad/param norm = 3.0904e-01, time/batch = 18.1249s	
14559/16650 (epoch 43.721), train_loss = 0.73888670, grad/param norm = 2.8380e-01, time/batch = 15.8416s	
14560/16650 (epoch 43.724), train_loss = 0.73311924, grad/param norm = 3.5440e-01, time/batch = 14.9116s	
14561/16650 (epoch 43.727), train_loss = 0.74461971, grad/param norm = 3.1973e-01, time/batch = 15.2721s	
14562/16650 (epoch 43.730), train_loss = 0.61784178, grad/param norm = 3.1049e-01, time/batch = 17.1250s	
14563/16650 (epoch 43.733), train_loss = 0.76556655, grad/param norm = 3.1077e-01, time/batch = 15.4344s	
14564/16650 (epoch 43.736), train_loss = 0.55809874, grad/param norm = 2.8426e-01, time/batch = 16.8646s	
14565/16650 (epoch 43.739), train_loss = 0.67104531, grad/param norm = 2.9228e-01, time/batch = 17.1173s	
14566/16650 (epoch 43.742), train_loss = 0.67902700, grad/param norm = 2.9593e-01, time/batch = 16.6155s	
14567/16650 (epoch 43.745), train_loss = 0.52973484, grad/param norm = 2.7520e-01, time/batch = 15.5194s	
14568/16650 (epoch 43.748), train_loss = 0.56691911, grad/param norm = 2.9762e-01, time/batch = 16.7840s	
14569/16650 (epoch 43.751), train_loss = 0.67041945, grad/param norm = 4.0832e-01, time/batch = 14.6633s	
14570/16650 (epoch 43.754), train_loss = 0.82966408, grad/param norm = 3.5544e-01, time/batch = 16.1615s	
14571/16650 (epoch 43.757), train_loss = 0.79532409, grad/param norm = 3.1003e-01, time/batch = 18.1121s	
14572/16650 (epoch 43.760), train_loss = 0.68075258, grad/param norm = 3.7005e-01, time/batch = 16.5218s	
14573/16650 (epoch 43.763), train_loss = 0.63660758, grad/param norm = 2.8735e-01, time/batch = 14.5518s	
14574/16650 (epoch 43.766), train_loss = 0.66208548, grad/param norm = 2.7955e-01, time/batch = 15.5809s	
14575/16650 (epoch 43.769), train_loss = 0.72675430, grad/param norm = 4.4192e-01, time/batch = 18.2853s	
14576/16650 (epoch 43.772), train_loss = 0.68657655, grad/param norm = 2.6165e-01, time/batch = 16.6928s	
14577/16650 (epoch 43.775), train_loss = 0.67668153, grad/param norm = 3.0304e-01, time/batch = 16.2801s	
14578/16650 (epoch 43.778), train_loss = 0.70599071, grad/param norm = 2.8360e-01, time/batch = 16.5117s	
14579/16650 (epoch 43.781), train_loss = 0.82533614, grad/param norm = 3.1748e-01, time/batch = 16.2022s	
14580/16650 (epoch 43.784), train_loss = 0.69514395, grad/param norm = 2.9981e-01, time/batch = 17.8673s	
14581/16650 (epoch 43.787), train_loss = 0.75373666, grad/param norm = 3.5633e-01, time/batch = 14.9793s	
14582/16650 (epoch 43.790), train_loss = 0.77391079, grad/param norm = 2.9462e-01, time/batch = 17.1960s	
14583/16650 (epoch 43.793), train_loss = 0.57762990, grad/param norm = 3.4258e-01, time/batch = 16.8703s	
14584/16650 (epoch 43.796), train_loss = 0.90917963, grad/param norm = 3.8174e-01, time/batch = 16.1937s	
14585/16650 (epoch 43.799), train_loss = 0.80482430, grad/param norm = 3.6925e-01, time/batch = 15.7675s	
14586/16650 (epoch 43.802), train_loss = 0.76295408, grad/param norm = 2.9995e-01, time/batch = 17.4395s	
14587/16650 (epoch 43.805), train_loss = 0.71211655, grad/param norm = 2.9580e-01, time/batch = 17.6188s	
14588/16650 (epoch 43.808), train_loss = 0.77287310, grad/param norm = 3.6278e-01, time/batch = 15.3440s	
14589/16650 (epoch 43.811), train_loss = 0.78883418, grad/param norm = 3.0721e-01, time/batch = 17.1269s	
14590/16650 (epoch 43.814), train_loss = 0.62516345, grad/param norm = 2.9108e-01, time/batch = 16.1614s	
14591/16650 (epoch 43.817), train_loss = 0.62719425, grad/param norm = 3.2166e-01, time/batch = 17.1920s	
14592/16650 (epoch 43.820), train_loss = 0.75608979, grad/param norm = 3.2994e-01, time/batch = 15.3113s	
14593/16650 (epoch 43.823), train_loss = 0.71184891, grad/param norm = 2.7735e-01, time/batch = 17.2574s	
14594/16650 (epoch 43.826), train_loss = 0.64767979, grad/param norm = 2.8360e-01, time/batch = 17.8716s	
14595/16650 (epoch 43.829), train_loss = 0.69192379, grad/param norm = 3.8139e-01, time/batch = 16.7636s	
14596/16650 (epoch 43.832), train_loss = 0.75267472, grad/param norm = 3.2606e-01, time/batch = 16.2860s	
14597/16650 (epoch 43.835), train_loss = 0.74002680, grad/param norm = 3.0279e-01, time/batch = 16.9519s	
14598/16650 (epoch 43.838), train_loss = 0.61800271, grad/param norm = 2.7897e-01, time/batch = 16.9433s	
14599/16650 (epoch 43.841), train_loss = 0.63625727, grad/param norm = 2.7151e-01, time/batch = 15.6768s	
14600/16650 (epoch 43.844), train_loss = 0.67452959, grad/param norm = 2.6247e-01, time/batch = 16.3623s	
14601/16650 (epoch 43.847), train_loss = 0.74778872, grad/param norm = 3.1111e-01, time/batch = 17.0262s	
14602/16650 (epoch 43.850), train_loss = 0.63752373, grad/param norm = 3.1897e-01, time/batch = 16.7523s	
14603/16650 (epoch 43.853), train_loss = 0.66430596, grad/param norm = 3.3380e-01, time/batch = 17.3507s	
14604/16650 (epoch 43.856), train_loss = 0.63771511, grad/param norm = 2.7032e-01, time/batch = 15.3165s	
14605/16650 (epoch 43.859), train_loss = 0.75964519, grad/param norm = 3.4477e-01, time/batch = 17.7745s	
14606/16650 (epoch 43.862), train_loss = 0.70256986, grad/param norm = 2.7495e-01, time/batch = 16.1546s	
14607/16650 (epoch 43.865), train_loss = 0.56787283, grad/param norm = 2.7100e-01, time/batch = 16.9273s	
14608/16650 (epoch 43.868), train_loss = 0.69619597, grad/param norm = 3.0684e-01, time/batch = 18.2833s	
14609/16650 (epoch 43.871), train_loss = 0.70334251, grad/param norm = 2.9332e-01, time/batch = 17.3430s	
14610/16650 (epoch 43.874), train_loss = 0.70054001, grad/param norm = 2.8886e-01, time/batch = 15.5633s	
14611/16650 (epoch 43.877), train_loss = 0.66406209, grad/param norm = 2.6691e-01, time/batch = 18.7355s	
14612/16650 (epoch 43.880), train_loss = 0.62022738, grad/param norm = 3.0164e-01, time/batch = 18.7845s	
14613/16650 (epoch 43.883), train_loss = 0.69855540, grad/param norm = 2.6588e-01, time/batch = 17.2580s	
14614/16650 (epoch 43.886), train_loss = 0.68631197, grad/param norm = 3.3400e-01, time/batch = 19.1180s	
14615/16650 (epoch 43.889), train_loss = 0.57659827, grad/param norm = 2.9818e-01, time/batch = 16.5978s	
14616/16650 (epoch 43.892), train_loss = 0.70012996, grad/param norm = 2.9230e-01, time/batch = 16.8287s	
14617/16650 (epoch 43.895), train_loss = 0.71792155, grad/param norm = 2.9998e-01, time/batch = 17.1132s	
14618/16650 (epoch 43.898), train_loss = 0.70124657, grad/param norm = 5.7295e-01, time/batch = 17.8615s	
14619/16650 (epoch 43.901), train_loss = 0.63613766, grad/param norm = 2.9143e-01, time/batch = 16.1637s	
14620/16650 (epoch 43.904), train_loss = 0.66140514, grad/param norm = 3.3719e-01, time/batch = 14.9750s	
14621/16650 (epoch 43.907), train_loss = 0.70717868, grad/param norm = 3.4221e-01, time/batch = 18.2624s	
14622/16650 (epoch 43.910), train_loss = 0.72324216, grad/param norm = 3.1902e-01, time/batch = 18.5249s	
14623/16650 (epoch 43.913), train_loss = 0.65274335, grad/param norm = 2.7867e-01, time/batch = 16.6737s	
14624/16650 (epoch 43.916), train_loss = 0.61612188, grad/param norm = 3.2563e-01, time/batch = 17.3607s	
14625/16650 (epoch 43.919), train_loss = 0.79833180, grad/param norm = 3.1862e-01, time/batch = 15.4930s	
14626/16650 (epoch 43.922), train_loss = 0.70233405, grad/param norm = 3.9444e-01, time/batch = 17.0176s	
14627/16650 (epoch 43.925), train_loss = 0.63153164, grad/param norm = 2.8711e-01, time/batch = 17.5850s	
14628/16650 (epoch 43.928), train_loss = 0.69631436, grad/param norm = 3.0700e-01, time/batch = 18.6990s	
14629/16650 (epoch 43.931), train_loss = 0.70198362, grad/param norm = 3.2718e-01, time/batch = 15.2468s	
14630/16650 (epoch 43.934), train_loss = 0.59003408, grad/param norm = 4.0341e-01, time/batch = 17.0227s	
14631/16650 (epoch 43.937), train_loss = 0.62229535, grad/param norm = 3.2404e-01, time/batch = 19.0185s	
14632/16650 (epoch 43.940), train_loss = 0.71047534, grad/param norm = 2.7800e-01, time/batch = 18.1132s	
14633/16650 (epoch 43.943), train_loss = 0.71150915, grad/param norm = 3.6896e-01, time/batch = 16.8290s	
14634/16650 (epoch 43.946), train_loss = 0.65092884, grad/param norm = 2.9281e-01, time/batch = 18.1038s	
14635/16650 (epoch 43.949), train_loss = 0.58638014, grad/param norm = 2.8539e-01, time/batch = 15.4822s	
14636/16650 (epoch 43.952), train_loss = 0.58119670, grad/param norm = 2.5913e-01, time/batch = 18.1017s	
14637/16650 (epoch 43.955), train_loss = 0.68183978, grad/param norm = 2.7481e-01, time/batch = 16.7596s	
14638/16650 (epoch 43.958), train_loss = 0.72716776, grad/param norm = 3.7548e-01, time/batch = 17.0048s	
14639/16650 (epoch 43.961), train_loss = 0.66138796, grad/param norm = 2.6330e-01, time/batch = 19.1083s	
14640/16650 (epoch 43.964), train_loss = 0.58909999, grad/param norm = 3.9099e-01, time/batch = 17.5172s	
14641/16650 (epoch 43.967), train_loss = 0.80569336, grad/param norm = 3.2816e-01, time/batch = 16.4185s	
14642/16650 (epoch 43.970), train_loss = 0.64222319, grad/param norm = 2.8581e-01, time/batch = 18.7794s	
14643/16650 (epoch 43.973), train_loss = 0.63362788, grad/param norm = 3.0395e-01, time/batch = 18.3622s	
14644/16650 (epoch 43.976), train_loss = 0.62252785, grad/param norm = 3.0445e-01, time/batch = 17.1686s	
14645/16650 (epoch 43.979), train_loss = 0.72291489, grad/param norm = 4.8658e-01, time/batch = 17.9440s	
14646/16650 (epoch 43.982), train_loss = 0.74129550, grad/param norm = 3.5177e-01, time/batch = 17.1933s	
14647/16650 (epoch 43.985), train_loss = 0.70799412, grad/param norm = 3.0844e-01, time/batch = 15.6496s	
14648/16650 (epoch 43.988), train_loss = 0.71086826, grad/param norm = 3.6035e-01, time/batch = 18.9495s	
14649/16650 (epoch 43.991), train_loss = 0.63677023, grad/param norm = 3.6321e-01, time/batch = 16.9518s	
14650/16650 (epoch 43.994), train_loss = 0.63802806, grad/param norm = 2.7729e-01, time/batch = 16.7788s	
14651/16650 (epoch 43.997), train_loss = 0.65059814, grad/param norm = 3.3320e-01, time/batch = 15.4457s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
14652/16650 (epoch 44.000), train_loss = 0.73205264, grad/param norm = 3.2355e-01, time/batch = 15.8153s	
14653/16650 (epoch 44.003), train_loss = 0.79477995, grad/param norm = 3.7954e-01, time/batch = 17.3539s	
14654/16650 (epoch 44.006), train_loss = 0.78955199, grad/param norm = 3.3554e-01, time/batch = 15.9234s	
14655/16650 (epoch 44.009), train_loss = 0.79687938, grad/param norm = 3.2714e-01, time/batch = 18.4325s	
14656/16650 (epoch 44.012), train_loss = 0.77601965, grad/param norm = 2.9482e-01, time/batch = 17.3673s	
14657/16650 (epoch 44.015), train_loss = 0.67935742, grad/param norm = 2.8688e-01, time/batch = 18.1980s	
14658/16650 (epoch 44.018), train_loss = 0.60280110, grad/param norm = 2.8129e-01, time/batch = 17.1699s	
14659/16650 (epoch 44.021), train_loss = 0.80476342, grad/param norm = 3.4508e-01, time/batch = 14.9882s	
14660/16650 (epoch 44.024), train_loss = 0.66946393, grad/param norm = 3.0442e-01, time/batch = 17.6992s	
14661/16650 (epoch 44.027), train_loss = 0.74456079, grad/param norm = 3.8999e-01, time/batch = 16.6614s	
14662/16650 (epoch 44.030), train_loss = 0.58432743, grad/param norm = 2.7959e-01, time/batch = 17.0846s	
14663/16650 (epoch 44.033), train_loss = 0.66359249, grad/param norm = 2.5985e-01, time/batch = 18.7056s	
14664/16650 (epoch 44.036), train_loss = 0.48301486, grad/param norm = 3.4339e-01, time/batch = 15.1651s	
14665/16650 (epoch 44.039), train_loss = 0.77775344, grad/param norm = 2.9462e-01, time/batch = 16.8407s	
14666/16650 (epoch 44.042), train_loss = 0.72250624, grad/param norm = 3.5248e-01, time/batch = 17.9523s	
14667/16650 (epoch 44.045), train_loss = 0.70486570, grad/param norm = 2.9324e-01, time/batch = 18.4499s	
14668/16650 (epoch 44.048), train_loss = 0.75861354, grad/param norm = 3.3814e-01, time/batch = 15.7566s	
14669/16650 (epoch 44.051), train_loss = 0.68012630, grad/param norm = 3.2128e-01, time/batch = 17.9399s	
14670/16650 (epoch 44.054), train_loss = 0.68396237, grad/param norm = 2.9318e-01, time/batch = 17.8388s	
14671/16650 (epoch 44.057), train_loss = 0.68824814, grad/param norm = 3.6909e-01, time/batch = 17.5925s	
14672/16650 (epoch 44.060), train_loss = 0.58149825, grad/param norm = 2.6354e-01, time/batch = 17.0020s	
14673/16650 (epoch 44.063), train_loss = 0.64291430, grad/param norm = 2.7499e-01, time/batch = 18.5907s	
14674/16650 (epoch 44.066), train_loss = 0.82034999, grad/param norm = 3.3426e-01, time/batch = 18.6836s	
14675/16650 (epoch 44.069), train_loss = 0.72081984, grad/param norm = 3.0911e-01, time/batch = 15.7460s	
14676/16650 (epoch 44.072), train_loss = 0.70354167, grad/param norm = 3.3541e-01, time/batch = 18.2465s	
14677/16650 (epoch 44.075), train_loss = 0.74952069, grad/param norm = 3.0976e-01, time/batch = 16.9825s	
14678/16650 (epoch 44.078), train_loss = 0.75867172, grad/param norm = 3.2679e-01, time/batch = 17.9386s	
14679/16650 (epoch 44.081), train_loss = 0.72815684, grad/param norm = 4.9369e-01, time/batch = 17.9309s	
14680/16650 (epoch 44.084), train_loss = 0.70242082, grad/param norm = 3.3452e-01, time/batch = 18.3686s	
14681/16650 (epoch 44.087), train_loss = 0.70559996, grad/param norm = 3.0050e-01, time/batch = 16.8807s	
14682/16650 (epoch 44.090), train_loss = 0.66886200, grad/param norm = 3.4132e-01, time/batch = 16.4088s	
14683/16650 (epoch 44.093), train_loss = 0.80352453, grad/param norm = 3.5186e-01, time/batch = 18.1236s	
14684/16650 (epoch 44.096), train_loss = 0.63635679, grad/param norm = 2.8405e-01, time/batch = 18.5353s	
14685/16650 (epoch 44.099), train_loss = 0.72102374, grad/param norm = 3.8001e-01, time/batch = 16.9219s	
14686/16650 (epoch 44.102), train_loss = 0.69593415, grad/param norm = 3.0877e-01, time/batch = 18.6151s	
14687/16650 (epoch 44.105), train_loss = 0.69730554, grad/param norm = 3.3547e-01, time/batch = 16.5931s	
14688/16650 (epoch 44.108), train_loss = 0.72545542, grad/param norm = 3.3345e-01, time/batch = 15.8874s	
14689/16650 (epoch 44.111), train_loss = 0.77457693, grad/param norm = 3.1990e-01, time/batch = 15.3672s	
14690/16650 (epoch 44.114), train_loss = 0.71095230, grad/param norm = 4.1147e-01, time/batch = 15.5169s	
14691/16650 (epoch 44.117), train_loss = 0.83141434, grad/param norm = 3.2451e-01, time/batch = 16.2036s	
14692/16650 (epoch 44.120), train_loss = 0.70823248, grad/param norm = 2.9509e-01, time/batch = 21.5282s	
14693/16650 (epoch 44.123), train_loss = 0.67176943, grad/param norm = 3.1062e-01, time/batch = 29.1549s	
14694/16650 (epoch 44.126), train_loss = 0.73793921, grad/param norm = 3.1724e-01, time/batch = 17.5979s	
14695/16650 (epoch 44.129), train_loss = 0.75238332, grad/param norm = 3.2658e-01, time/batch = 15.5076s	
14696/16650 (epoch 44.132), train_loss = 0.68441541, grad/param norm = 2.9040e-01, time/batch = 17.9569s	
14697/16650 (epoch 44.135), train_loss = 0.79906142, grad/param norm = 2.7318e-01, time/batch = 16.4301s	
14698/16650 (epoch 44.138), train_loss = 0.76690589, grad/param norm = 3.1285e-01, time/batch = 16.5644s	
14699/16650 (epoch 44.141), train_loss = 0.72705975, grad/param norm = 3.4785e-01, time/batch = 17.2725s	
14700/16650 (epoch 44.144), train_loss = 0.73880310, grad/param norm = 3.5987e-01, time/batch = 18.7651s	
14701/16650 (epoch 44.147), train_loss = 0.82512482, grad/param norm = 3.3436e-01, time/batch = 18.3676s	
14702/16650 (epoch 44.150), train_loss = 0.90158276, grad/param norm = 4.8102e-01, time/batch = 15.1269s	
14703/16650 (epoch 44.153), train_loss = 0.72099366, grad/param norm = 3.3645e-01, time/batch = 18.7741s	
14704/16650 (epoch 44.156), train_loss = 0.71586817, grad/param norm = 3.2376e-01, time/batch = 17.8518s	
14705/16650 (epoch 44.159), train_loss = 0.75040447, grad/param norm = 3.1148e-01, time/batch = 16.8163s	
14706/16650 (epoch 44.162), train_loss = 0.82951823, grad/param norm = 3.1110e-01, time/batch = 17.6918s	
14707/16650 (epoch 44.165), train_loss = 0.79325495, grad/param norm = 3.0174e-01, time/batch = 15.6038s	
14708/16650 (epoch 44.168), train_loss = 0.60587709, grad/param norm = 2.7588e-01, time/batch = 19.0122s	
14709/16650 (epoch 44.171), train_loss = 0.75200378, grad/param norm = 3.0755e-01, time/batch = 15.1557s	
14710/16650 (epoch 44.174), train_loss = 0.58424215, grad/param norm = 3.0303e-01, time/batch = 14.9707s	
14711/16650 (epoch 44.177), train_loss = 0.71940720, grad/param norm = 3.4325e-01, time/batch = 17.6225s	
14712/16650 (epoch 44.180), train_loss = 0.81417760, grad/param norm = 3.1817e-01, time/batch = 16.6039s	
14713/16650 (epoch 44.183), train_loss = 0.95448087, grad/param norm = 4.9995e-01, time/batch = 16.6114s	
14714/16650 (epoch 44.186), train_loss = 0.73041515, grad/param norm = 3.4606e-01, time/batch = 18.2782s	
14715/16650 (epoch 44.189), train_loss = 0.65837953, grad/param norm = 2.7281e-01, time/batch = 17.7068s	
14716/16650 (epoch 44.192), train_loss = 0.70200327, grad/param norm = 2.9605e-01, time/batch = 15.5099s	
14717/16650 (epoch 44.195), train_loss = 0.65460119, grad/param norm = 3.3871e-01, time/batch = 14.2257s	
14718/16650 (epoch 44.198), train_loss = 0.62922331, grad/param norm = 2.6028e-01, time/batch = 17.6113s	
14719/16650 (epoch 44.201), train_loss = 0.62225068, grad/param norm = 2.9613e-01, time/batch = 17.6156s	
14720/16650 (epoch 44.204), train_loss = 0.72244153, grad/param norm = 2.9796e-01, time/batch = 16.3361s	
14721/16650 (epoch 44.207), train_loss = 0.76638058, grad/param norm = 3.9654e-01, time/batch = 17.7146s	
14722/16650 (epoch 44.210), train_loss = 0.71312906, grad/param norm = 3.3972e-01, time/batch = 17.5190s	
14723/16650 (epoch 44.213), train_loss = 0.76638362, grad/param norm = 3.1666e-01, time/batch = 16.2754s	
14724/16650 (epoch 44.216), train_loss = 0.64877235, grad/param norm = 3.5936e-01, time/batch = 17.2024s	
14725/16650 (epoch 44.219), train_loss = 0.69053768, grad/param norm = 3.1664e-01, time/batch = 16.7828s	
14726/16650 (epoch 44.222), train_loss = 0.71692181, grad/param norm = 2.6463e-01, time/batch = 17.2818s	
14727/16650 (epoch 44.225), train_loss = 0.73593378, grad/param norm = 3.5113e-01, time/batch = 15.0500s	
14728/16650 (epoch 44.228), train_loss = 0.66341014, grad/param norm = 3.0024e-01, time/batch = 13.7276s	
14729/16650 (epoch 44.231), train_loss = 0.64841129, grad/param norm = 3.9748e-01, time/batch = 13.5598s	
14730/16650 (epoch 44.234), train_loss = 0.84142094, grad/param norm = 3.5260e-01, time/batch = 13.8881s	
14731/16650 (epoch 44.237), train_loss = 0.73582278, grad/param norm = 3.1936e-01, time/batch = 15.2051s	
14732/16650 (epoch 44.240), train_loss = 0.73415034, grad/param norm = 2.9543e-01, time/batch = 18.2109s	
14733/16650 (epoch 44.243), train_loss = 0.70544817, grad/param norm = 3.4105e-01, time/batch = 16.7130s	
14734/16650 (epoch 44.246), train_loss = 0.80817142, grad/param norm = 3.6393e-01, time/batch = 16.7659s	
14735/16650 (epoch 44.249), train_loss = 0.60041876, grad/param norm = 2.6207e-01, time/batch = 15.5455s	
14736/16650 (epoch 44.252), train_loss = 0.69001041, grad/param norm = 2.9509e-01, time/batch = 18.5466s	
14737/16650 (epoch 44.255), train_loss = 0.74849608, grad/param norm = 2.9986e-01, time/batch = 14.8855s	
14738/16650 (epoch 44.258), train_loss = 0.76894000, grad/param norm = 2.8784e-01, time/batch = 16.6868s	
14739/16650 (epoch 44.261), train_loss = 0.74468157, grad/param norm = 3.2221e-01, time/batch = 16.5221s	
14740/16650 (epoch 44.264), train_loss = 0.66238321, grad/param norm = 2.7604e-01, time/batch = 17.2986s	
14741/16650 (epoch 44.267), train_loss = 0.67095652, grad/param norm = 2.9314e-01, time/batch = 16.2594s	
14742/16650 (epoch 44.270), train_loss = 0.76210021, grad/param norm = 3.2703e-01, time/batch = 17.3555s	
14743/16650 (epoch 44.273), train_loss = 0.80248103, grad/param norm = 3.7651e-01, time/batch = 16.6821s	
14744/16650 (epoch 44.276), train_loss = 0.75216311, grad/param norm = 3.1939e-01, time/batch = 17.5257s	
14745/16650 (epoch 44.279), train_loss = 0.66632023, grad/param norm = 2.8640e-01, time/batch = 15.3456s	
14746/16650 (epoch 44.282), train_loss = 0.65036063, grad/param norm = 2.6149e-01, time/batch = 17.7033s	
14747/16650 (epoch 44.285), train_loss = 0.67793401, grad/param norm = 2.8917e-01, time/batch = 17.1263s	
14748/16650 (epoch 44.288), train_loss = 0.61666472, grad/param norm = 3.2874e-01, time/batch = 15.2499s	
14749/16650 (epoch 44.291), train_loss = 0.51529290, grad/param norm = 2.4347e-01, time/batch = 16.3956s	
14750/16650 (epoch 44.294), train_loss = 0.62612694, grad/param norm = 2.8835e-01, time/batch = 17.2050s	
14751/16650 (epoch 44.297), train_loss = 0.69983662, grad/param norm = 2.7783e-01, time/batch = 16.5443s	
14752/16650 (epoch 44.300), train_loss = 0.54979853, grad/param norm = 2.5848e-01, time/batch = 14.5565s	
14753/16650 (epoch 44.303), train_loss = 0.58544002, grad/param norm = 2.6172e-01, time/batch = 16.6970s	
14754/16650 (epoch 44.306), train_loss = 0.75694803, grad/param norm = 2.8551e-01, time/batch = 17.2874s	
14755/16650 (epoch 44.309), train_loss = 0.74395920, grad/param norm = 3.2261e-01, time/batch = 17.7150s	
14756/16650 (epoch 44.312), train_loss = 0.58191542, grad/param norm = 3.1172e-01, time/batch = 15.6864s	
14757/16650 (epoch 44.315), train_loss = 0.50013020, grad/param norm = 2.3810e-01, time/batch = 16.1907s	
14758/16650 (epoch 44.318), train_loss = 0.57087809, grad/param norm = 2.7104e-01, time/batch = 16.1749s	
14759/16650 (epoch 44.321), train_loss = 0.75566647, grad/param norm = 3.2128e-01, time/batch = 16.1924s	
14760/16650 (epoch 44.324), train_loss = 0.63971377, grad/param norm = 3.6550e-01, time/batch = 15.0444s	
14761/16650 (epoch 44.327), train_loss = 0.71932511, grad/param norm = 4.5850e-01, time/batch = 17.9756s	
14762/16650 (epoch 44.330), train_loss = 0.71751588, grad/param norm = 4.6342e-01, time/batch = 17.7936s	
14763/16650 (epoch 44.333), train_loss = 0.75144878, grad/param norm = 3.5590e-01, time/batch = 16.3578s	
14764/16650 (epoch 44.336), train_loss = 0.60966401, grad/param norm = 3.0983e-01, time/batch = 14.3134s	
14765/16650 (epoch 44.339), train_loss = 0.62557478, grad/param norm = 3.2080e-01, time/batch = 15.7855s	
14766/16650 (epoch 44.342), train_loss = 0.58956203, grad/param norm = 3.1095e-01, time/batch = 16.6227s	
14767/16650 (epoch 44.345), train_loss = 0.63007212, grad/param norm = 2.7085e-01, time/batch = 16.0911s	
14768/16650 (epoch 44.348), train_loss = 0.71747764, grad/param norm = 3.1303e-01, time/batch = 15.7541s	
14769/16650 (epoch 44.351), train_loss = 0.70956628, grad/param norm = 3.2465e-01, time/batch = 17.6900s	
14770/16650 (epoch 44.354), train_loss = 0.74934322, grad/param norm = 3.4828e-01, time/batch = 17.7842s	
14771/16650 (epoch 44.357), train_loss = 0.71614399, grad/param norm = 3.1733e-01, time/batch = 15.6558s	
14772/16650 (epoch 44.360), train_loss = 0.69860842, grad/param norm = 3.1921e-01, time/batch = 18.8673s	
14773/16650 (epoch 44.363), train_loss = 0.75147198, grad/param norm = 3.2521e-01, time/batch = 16.9538s	
14774/16650 (epoch 44.366), train_loss = 0.82635692, grad/param norm = 3.5976e-01, time/batch = 16.5198s	
14775/16650 (epoch 44.369), train_loss = 0.75544122, grad/param norm = 3.3590e-01, time/batch = 17.1805s	
14776/16650 (epoch 44.372), train_loss = 0.70460245, grad/param norm = 3.0497e-01, time/batch = 18.1881s	
14777/16650 (epoch 44.375), train_loss = 0.70514006, grad/param norm = 2.7510e-01, time/batch = 16.6625s	
14778/16650 (epoch 44.378), train_loss = 0.66315415, grad/param norm = 2.9821e-01, time/batch = 18.0197s	
14779/16650 (epoch 44.381), train_loss = 0.76135135, grad/param norm = 3.9528e-01, time/batch = 18.3607s	
14780/16650 (epoch 44.384), train_loss = 0.81123737, grad/param norm = 3.3362e-01, time/batch = 17.6874s	
14781/16650 (epoch 44.387), train_loss = 0.55624337, grad/param norm = 2.9424e-01, time/batch = 16.8300s	
14782/16650 (epoch 44.390), train_loss = 0.75523717, grad/param norm = 3.1721e-01, time/batch = 18.1227s	
14783/16650 (epoch 44.393), train_loss = 0.67747686, grad/param norm = 3.3529e-01, time/batch = 13.8332s	
14784/16650 (epoch 44.396), train_loss = 0.82407178, grad/param norm = 3.8783e-01, time/batch = 13.7762s	
14785/16650 (epoch 44.399), train_loss = 0.74540432, grad/param norm = 2.8658e-01, time/batch = 14.6613s	
14786/16650 (epoch 44.402), train_loss = 0.67301777, grad/param norm = 3.0937e-01, time/batch = 17.2369s	
14787/16650 (epoch 44.405), train_loss = 0.55150742, grad/param norm = 3.1800e-01, time/batch = 17.9427s	
14788/16650 (epoch 44.408), train_loss = 0.73219282, grad/param norm = 2.8948e-01, time/batch = 14.7398s	
14789/16650 (epoch 44.411), train_loss = 0.64635609, grad/param norm = 3.7978e-01, time/batch = 17.0163s	
14790/16650 (epoch 44.414), train_loss = 0.63236526, grad/param norm = 3.5466e-01, time/batch = 18.9567s	
14791/16650 (epoch 44.417), train_loss = 0.60504912, grad/param norm = 3.4206e-01, time/batch = 17.4446s	
14792/16650 (epoch 44.420), train_loss = 0.63555432, grad/param norm = 2.9250e-01, time/batch = 17.2548s	
14793/16650 (epoch 44.423), train_loss = 0.51129698, grad/param norm = 2.8395e-01, time/batch = 16.0008s	
14794/16650 (epoch 44.426), train_loss = 0.59269674, grad/param norm = 3.5412e-01, time/batch = 17.4483s	
14795/16650 (epoch 44.429), train_loss = 0.76472536, grad/param norm = 3.1851e-01, time/batch = 16.9271s	
14796/16650 (epoch 44.432), train_loss = 0.75149983, grad/param norm = 3.3290e-01, time/batch = 17.5998s	
14797/16650 (epoch 44.435), train_loss = 0.83587810, grad/param norm = 3.3149e-01, time/batch = 17.4340s	
14798/16650 (epoch 44.438), train_loss = 0.84098615, grad/param norm = 3.7818e-01, time/batch = 17.1131s	
14799/16650 (epoch 44.441), train_loss = 0.66343936, grad/param norm = 3.4324e-01, time/batch = 17.4913s	
14800/16650 (epoch 44.444), train_loss = 0.64729991, grad/param norm = 2.9196e-01, time/batch = 16.5198s	
14801/16650 (epoch 44.447), train_loss = 0.64015154, grad/param norm = 3.1460e-01, time/batch = 17.5265s	
14802/16650 (epoch 44.450), train_loss = 0.63892433, grad/param norm = 2.9834e-01, time/batch = 16.5072s	
14803/16650 (epoch 44.453), train_loss = 0.63563645, grad/param norm = 2.9680e-01, time/batch = 15.9078s	
14804/16650 (epoch 44.456), train_loss = 0.60719564, grad/param norm = 2.6528e-01, time/batch = 15.9758s	
14805/16650 (epoch 44.459), train_loss = 0.61914186, grad/param norm = 2.8789e-01, time/batch = 18.0174s	
14806/16650 (epoch 44.462), train_loss = 0.77935592, grad/param norm = 3.5159e-01, time/batch = 16.1012s	
14807/16650 (epoch 44.465), train_loss = 0.64218017, grad/param norm = 3.4272e-01, time/batch = 18.7026s	
14808/16650 (epoch 44.468), train_loss = 0.53320689, grad/param norm = 2.9362e-01, time/batch = 17.6103s	
14809/16650 (epoch 44.471), train_loss = 0.45694929, grad/param norm = 2.5457e-01, time/batch = 17.5317s	
14810/16650 (epoch 44.474), train_loss = 0.60659838, grad/param norm = 3.0314e-01, time/batch = 15.2470s	
14811/16650 (epoch 44.477), train_loss = 0.73371893, grad/param norm = 3.4052e-01, time/batch = 16.5822s	
14812/16650 (epoch 44.480), train_loss = 0.65817729, grad/param norm = 3.7402e-01, time/batch = 17.8738s	
14813/16650 (epoch 44.483), train_loss = 0.72828042, grad/param norm = 3.1574e-01, time/batch = 17.7322s	
14814/16650 (epoch 44.486), train_loss = 0.61001764, grad/param norm = 3.0053e-01, time/batch = 17.6878s	
14815/16650 (epoch 44.489), train_loss = 0.68669682, grad/param norm = 3.1648e-01, time/batch = 17.2821s	
14816/16650 (epoch 44.492), train_loss = 0.68002076, grad/param norm = 2.6492e-01, time/batch = 16.4139s	
14817/16650 (epoch 44.495), train_loss = 0.56569936, grad/param norm = 2.8437e-01, time/batch = 17.9408s	
14818/16650 (epoch 44.498), train_loss = 0.62970147, grad/param norm = 3.6809e-01, time/batch = 18.0365s	
14819/16650 (epoch 44.502), train_loss = 0.81135942, grad/param norm = 3.8692e-01, time/batch = 16.8616s	
14820/16650 (epoch 44.505), train_loss = 0.71560580, grad/param norm = 2.9144e-01, time/batch = 16.3333s	
14821/16650 (epoch 44.508), train_loss = 0.74300702, grad/param norm = 3.9534e-01, time/batch = 16.0459s	
14822/16650 (epoch 44.511), train_loss = 0.73145117, grad/param norm = 3.4838e-01, time/batch = 18.0298s	
14823/16650 (epoch 44.514), train_loss = 0.59000467, grad/param norm = 3.0167e-01, time/batch = 15.7549s	
14824/16650 (epoch 44.517), train_loss = 0.65936700, grad/param norm = 3.5540e-01, time/batch = 16.8478s	
14825/16650 (epoch 44.520), train_loss = 0.57869762, grad/param norm = 2.9671e-01, time/batch = 17.8673s	
14826/16650 (epoch 44.523), train_loss = 0.67797884, grad/param norm = 3.0317e-01, time/batch = 16.1605s	
14827/16650 (epoch 44.526), train_loss = 0.73685783, grad/param norm = 2.9822e-01, time/batch = 16.3425s	
14828/16650 (epoch 44.529), train_loss = 0.76012724, grad/param norm = 3.7275e-01, time/batch = 18.2100s	
14829/16650 (epoch 44.532), train_loss = 0.50887864, grad/param norm = 2.6998e-01, time/batch = 16.4107s	
14830/16650 (epoch 44.535), train_loss = 0.60465547, grad/param norm = 3.7101e-01, time/batch = 16.7730s	
14831/16650 (epoch 44.538), train_loss = 0.54257991, grad/param norm = 3.0150e-01, time/batch = 17.5274s	
14832/16650 (epoch 44.541), train_loss = 0.79128145, grad/param norm = 3.3596e-01, time/batch = 17.3699s	
14833/16650 (epoch 44.544), train_loss = 0.82024470, grad/param norm = 4.3570e-01, time/batch = 17.1964s	
14834/16650 (epoch 44.547), train_loss = 0.58327563, grad/param norm = 2.8737e-01, time/batch = 5.0578s	
14835/16650 (epoch 44.550), train_loss = 0.67923961, grad/param norm = 2.8145e-01, time/batch = 0.6171s	
14836/16650 (epoch 44.553), train_loss = 0.67608370, grad/param norm = 3.4313e-01, time/batch = 0.6171s	
14837/16650 (epoch 44.556), train_loss = 0.61768146, grad/param norm = 3.4787e-01, time/batch = 0.6226s	
14838/16650 (epoch 44.559), train_loss = 0.54270951, grad/param norm = 2.7480e-01, time/batch = 0.6173s	
14839/16650 (epoch 44.562), train_loss = 0.60710457, grad/param norm = 2.9907e-01, time/batch = 0.6197s	
14840/16650 (epoch 44.565), train_loss = 0.52118749, grad/param norm = 2.7723e-01, time/batch = 0.6180s	
14841/16650 (epoch 44.568), train_loss = 0.54214487, grad/param norm = 3.1053e-01, time/batch = 0.6227s	
14842/16650 (epoch 44.571), train_loss = 0.58855636, grad/param norm = 4.2046e-01, time/batch = 0.8362s	
14843/16650 (epoch 44.574), train_loss = 0.57738885, grad/param norm = 3.3973e-01, time/batch = 0.9046s	
14844/16650 (epoch 44.577), train_loss = 0.63885817, grad/param norm = 2.8114e-01, time/batch = 0.9114s	
14845/16650 (epoch 44.580), train_loss = 0.59179600, grad/param norm = 2.5665e-01, time/batch = 0.9152s	
14846/16650 (epoch 44.583), train_loss = 0.68592799, grad/param norm = 2.8543e-01, time/batch = 0.9122s	
14847/16650 (epoch 44.586), train_loss = 0.58466978, grad/param norm = 3.3893e-01, time/batch = 1.0995s	
14848/16650 (epoch 44.589), train_loss = 0.57545002, grad/param norm = 2.6655e-01, time/batch = 1.6896s	
14849/16650 (epoch 44.592), train_loss = 0.66107673, grad/param norm = 2.6304e-01, time/batch = 1.7213s	
14850/16650 (epoch 44.595), train_loss = 0.59542730, grad/param norm = 2.7283e-01, time/batch = 6.0586s	
14851/16650 (epoch 44.598), train_loss = 0.63231367, grad/param norm = 3.4048e-01, time/batch = 17.8702s	
14852/16650 (epoch 44.601), train_loss = 0.58741995, grad/param norm = 2.9369e-01, time/batch = 17.0266s	
14853/16650 (epoch 44.604), train_loss = 0.64717442, grad/param norm = 2.9357e-01, time/batch = 16.9223s	
14854/16650 (epoch 44.607), train_loss = 0.72152787, grad/param norm = 3.2595e-01, time/batch = 16.8571s	
14855/16650 (epoch 44.610), train_loss = 0.60548833, grad/param norm = 2.8175e-01, time/batch = 15.4236s	
14856/16650 (epoch 44.613), train_loss = 0.75982939, grad/param norm = 3.2645e-01, time/batch = 16.6835s	
14857/16650 (epoch 44.616), train_loss = 0.70655670, grad/param norm = 3.9161e-01, time/batch = 16.5194s	
14858/16650 (epoch 44.619), train_loss = 0.54991491, grad/param norm = 2.5116e-01, time/batch = 15.7405s	
14859/16650 (epoch 44.622), train_loss = 0.55342702, grad/param norm = 2.8585e-01, time/batch = 17.3767s	
14860/16650 (epoch 44.625), train_loss = 0.66405450, grad/param norm = 2.9423e-01, time/batch = 16.1858s	
14861/16650 (epoch 44.628), train_loss = 0.60619829, grad/param norm = 4.2451e-01, time/batch = 17.9534s	
14862/16650 (epoch 44.631), train_loss = 0.68262293, grad/param norm = 3.7224e-01, time/batch = 15.4358s	
14863/16650 (epoch 44.634), train_loss = 0.84674381, grad/param norm = 3.7449e-01, time/batch = 16.6939s	
14864/16650 (epoch 44.637), train_loss = 0.79183685, grad/param norm = 3.0906e-01, time/batch = 15.4001s	
14865/16650 (epoch 44.640), train_loss = 0.66234981, grad/param norm = 3.2516e-01, time/batch = 17.7027s	
14866/16650 (epoch 44.643), train_loss = 0.73240830, grad/param norm = 2.8955e-01, time/batch = 16.2653s	
14867/16650 (epoch 44.646), train_loss = 0.69782110, grad/param norm = 3.2963e-01, time/batch = 15.6787s	
14868/16650 (epoch 44.649), train_loss = 0.69140491, grad/param norm = 3.2648e-01, time/batch = 16.4477s	
14869/16650 (epoch 44.652), train_loss = 0.70680824, grad/param norm = 3.1228e-01, time/batch = 15.4103s	
14870/16650 (epoch 44.655), train_loss = 0.66005556, grad/param norm = 3.4098e-01, time/batch = 16.5074s	
14871/16650 (epoch 44.658), train_loss = 0.62663415, grad/param norm = 3.3481e-01, time/batch = 16.5809s	
14872/16650 (epoch 44.661), train_loss = 0.66645335, grad/param norm = 3.1922e-01, time/batch = 17.0290s	
14873/16650 (epoch 44.664), train_loss = 0.65614295, grad/param norm = 2.9042e-01, time/batch = 17.7864s	
14874/16650 (epoch 44.667), train_loss = 0.77268019, grad/param norm = 3.0650e-01, time/batch = 15.9871s	
14875/16650 (epoch 44.670), train_loss = 0.57538012, grad/param norm = 2.9488e-01, time/batch = 17.6791s	
14876/16650 (epoch 44.673), train_loss = 0.59513193, grad/param norm = 3.2357e-01, time/batch = 17.5323s	
14877/16650 (epoch 44.676), train_loss = 0.72719939, grad/param norm = 3.2993e-01, time/batch = 16.8813s	
14878/16650 (epoch 44.679), train_loss = 0.59080227, grad/param norm = 2.8178e-01, time/batch = 14.8873s	
14879/16650 (epoch 44.682), train_loss = 0.66027918, grad/param norm = 3.6836e-01, time/batch = 16.6026s	
14880/16650 (epoch 44.685), train_loss = 0.55868518, grad/param norm = 3.2229e-01, time/batch = 16.6790s	
14881/16650 (epoch 44.688), train_loss = 0.71918300, grad/param norm = 3.0330e-01, time/batch = 16.6621s	
14882/16650 (epoch 44.691), train_loss = 0.68305834, grad/param norm = 3.2636e-01, time/batch = 16.6966s	
14883/16650 (epoch 44.694), train_loss = 0.60163364, grad/param norm = 2.7596e-01, time/batch = 17.7052s	
14884/16650 (epoch 44.697), train_loss = 0.57839673, grad/param norm = 2.5436e-01, time/batch = 17.7004s	
14885/16650 (epoch 44.700), train_loss = 0.70661151, grad/param norm = 3.4140e-01, time/batch = 15.4180s	
14886/16650 (epoch 44.703), train_loss = 0.59553331, grad/param norm = 3.8149e-01, time/batch = 17.2909s	
14887/16650 (epoch 44.706), train_loss = 0.65756517, grad/param norm = 3.7637e-01, time/batch = 16.7900s	
14888/16650 (epoch 44.709), train_loss = 0.55995729, grad/param norm = 3.3340e-01, time/batch = 16.4423s	
14889/16650 (epoch 44.712), train_loss = 0.58913956, grad/param norm = 3.1346e-01, time/batch = 16.3658s	
14890/16650 (epoch 44.715), train_loss = 0.69586073, grad/param norm = 3.9372e-01, time/batch = 16.6988s	
14891/16650 (epoch 44.718), train_loss = 0.73123656, grad/param norm = 3.3638e-01, time/batch = 17.4597s	
14892/16650 (epoch 44.721), train_loss = 0.73794174, grad/param norm = 3.0208e-01, time/batch = 16.0065s	
14893/16650 (epoch 44.724), train_loss = 0.72357232, grad/param norm = 3.7834e-01, time/batch = 14.1269s	
14894/16650 (epoch 44.727), train_loss = 0.75577663, grad/param norm = 3.4268e-01, time/batch = 14.0800s	
14895/16650 (epoch 44.730), train_loss = 0.60979813, grad/param norm = 3.0435e-01, time/batch = 17.9489s	
14896/16650 (epoch 44.733), train_loss = 0.77563761, grad/param norm = 3.7957e-01, time/batch = 15.9228s	
14897/16650 (epoch 44.736), train_loss = 0.55681868, grad/param norm = 2.7222e-01, time/batch = 18.1277s	
14898/16650 (epoch 44.739), train_loss = 0.67883691, grad/param norm = 3.3362e-01, time/batch = 16.7060s	
14899/16650 (epoch 44.742), train_loss = 0.66388932, grad/param norm = 2.6944e-01, time/batch = 15.9911s	
14900/16650 (epoch 44.745), train_loss = 0.52524115, grad/param norm = 2.7909e-01, time/batch = 16.6033s	
14901/16650 (epoch 44.748), train_loss = 0.56946850, grad/param norm = 3.1188e-01, time/batch = 17.6226s	
14902/16650 (epoch 44.751), train_loss = 0.66945243, grad/param norm = 4.1684e-01, time/batch = 17.7104s	
14903/16650 (epoch 44.754), train_loss = 0.81790678, grad/param norm = 3.6659e-01, time/batch = 15.4162s	
14904/16650 (epoch 44.757), train_loss = 0.79566541, grad/param norm = 3.4720e-01, time/batch = 16.1675s	
14905/16650 (epoch 44.760), train_loss = 0.65949783, grad/param norm = 3.3119e-01, time/batch = 17.4479s	
14906/16650 (epoch 44.763), train_loss = 0.64666463, grad/param norm = 3.2302e-01, time/batch = 17.1879s	
14907/16650 (epoch 44.766), train_loss = 0.63525596, grad/param norm = 2.9290e-01, time/batch = 15.5785s	
14908/16650 (epoch 44.769), train_loss = 0.69754241, grad/param norm = 3.5391e-01, time/batch = 17.7966s	
14909/16650 (epoch 44.772), train_loss = 0.68291450, grad/param norm = 2.6867e-01, time/batch = 17.1882s	
14910/16650 (epoch 44.775), train_loss = 0.65917976, grad/param norm = 2.8117e-01, time/batch = 15.0622s	
14911/16650 (epoch 44.778), train_loss = 0.69723571, grad/param norm = 2.9290e-01, time/batch = 17.5319s	
14912/16650 (epoch 44.781), train_loss = 0.80579979, grad/param norm = 3.2644e-01, time/batch = 17.2851s	
14913/16650 (epoch 44.784), train_loss = 0.68334379, grad/param norm = 3.5217e-01, time/batch = 16.9453s	
14914/16650 (epoch 44.787), train_loss = 0.74071137, grad/param norm = 3.0716e-01, time/batch = 17.5030s	
14915/16650 (epoch 44.790), train_loss = 0.75561386, grad/param norm = 2.7189e-01, time/batch = 17.2025s	
14916/16650 (epoch 44.793), train_loss = 0.56998091, grad/param norm = 3.1545e-01, time/batch = 17.2096s	
14917/16650 (epoch 44.796), train_loss = 0.90773046, grad/param norm = 3.5483e-01, time/batch = 14.9786s	
14918/16650 (epoch 44.799), train_loss = 0.78504510, grad/param norm = 3.3372e-01, time/batch = 16.6286s	
14919/16650 (epoch 44.802), train_loss = 0.73785121, grad/param norm = 3.0617e-01, time/batch = 17.9551s	
14920/16650 (epoch 44.805), train_loss = 0.69959502, grad/param norm = 2.8932e-01, time/batch = 15.6270s	
14921/16650 (epoch 44.808), train_loss = 0.74342126, grad/param norm = 2.9233e-01, time/batch = 31.2894s	
14922/16650 (epoch 44.811), train_loss = 0.77817951, grad/param norm = 3.1062e-01, time/batch = 16.9518s	
14923/16650 (epoch 44.814), train_loss = 0.61442251, grad/param norm = 2.7365e-01, time/batch = 15.5076s	
14924/16650 (epoch 44.817), train_loss = 0.61956568, grad/param norm = 3.1665e-01, time/batch = 16.8456s	
14925/16650 (epoch 44.820), train_loss = 0.74869817, grad/param norm = 3.4032e-01, time/batch = 15.3269s	
14926/16650 (epoch 44.823), train_loss = 0.70502480, grad/param norm = 3.1860e-01, time/batch = 16.7613s	
14927/16650 (epoch 44.826), train_loss = 0.64618960, grad/param norm = 2.8792e-01, time/batch = 16.4484s	
14928/16650 (epoch 44.829), train_loss = 0.67348959, grad/param norm = 2.7538e-01, time/batch = 16.8498s	
14929/16650 (epoch 44.832), train_loss = 0.73602862, grad/param norm = 2.8912e-01, time/batch = 17.7820s	
14930/16650 (epoch 44.835), train_loss = 0.72844691, grad/param norm = 3.9020e-01, time/batch = 14.6686s	
14931/16650 (epoch 44.838), train_loss = 0.61406974, grad/param norm = 2.6703e-01, time/batch = 16.9300s	
14932/16650 (epoch 44.841), train_loss = 0.63321948, grad/param norm = 2.7868e-01, time/batch = 16.6960s	
14933/16650 (epoch 44.844), train_loss = 0.65789861, grad/param norm = 2.4305e-01, time/batch = 16.9276s	
14934/16650 (epoch 44.847), train_loss = 0.73473531, grad/param norm = 3.2924e-01, time/batch = 14.8919s	
14935/16650 (epoch 44.850), train_loss = 0.63187735, grad/param norm = 3.1578e-01, time/batch = 15.9480s	
14936/16650 (epoch 44.853), train_loss = 0.65839131, grad/param norm = 2.9239e-01, time/batch = 16.7673s	
14937/16650 (epoch 44.856), train_loss = 0.61908555, grad/param norm = 2.5740e-01, time/batch = 17.7962s	
14938/16650 (epoch 44.859), train_loss = 0.73438679, grad/param norm = 3.1268e-01, time/batch = 15.5930s	
14939/16650 (epoch 44.862), train_loss = 0.69533565, grad/param norm = 3.1898e-01, time/batch = 17.3574s	
14940/16650 (epoch 44.865), train_loss = 0.53190796, grad/param norm = 2.3719e-01, time/batch = 16.9402s	
14941/16650 (epoch 44.868), train_loss = 0.68177694, grad/param norm = 2.9401e-01, time/batch = 17.2684s	
14942/16650 (epoch 44.871), train_loss = 0.69317340, grad/param norm = 3.1153e-01, time/batch = 16.2687s	
14943/16650 (epoch 44.874), train_loss = 0.68565705, grad/param norm = 2.8411e-01, time/batch = 16.9515s	
14944/16650 (epoch 44.877), train_loss = 0.65517631, grad/param norm = 2.6707e-01, time/batch = 17.6140s	
14945/16650 (epoch 44.880), train_loss = 0.61867933, grad/param norm = 2.8549e-01, time/batch = 15.2507s	
14946/16650 (epoch 44.883), train_loss = 0.69005096, grad/param norm = 2.9444e-01, time/batch = 16.2496s	
14947/16650 (epoch 44.886), train_loss = 0.68163676, grad/param norm = 3.2500e-01, time/batch = 16.8502s	
14948/16650 (epoch 44.889), train_loss = 0.56614414, grad/param norm = 3.1729e-01, time/batch = 16.7476s	
14949/16650 (epoch 44.892), train_loss = 0.68443320, grad/param norm = 2.5545e-01, time/batch = 16.3141s	
14950/16650 (epoch 44.895), train_loss = 0.71008121, grad/param norm = 3.0336e-01, time/batch = 17.0027s	
14951/16650 (epoch 44.898), train_loss = 0.69155314, grad/param norm = 3.5903e-01, time/batch = 17.4638s	
14952/16650 (epoch 44.901), train_loss = 0.63879517, grad/param norm = 3.1050e-01, time/batch = 15.9158s	
14953/16650 (epoch 44.904), train_loss = 0.64601365, grad/param norm = 3.2163e-01, time/batch = 17.1104s	
14954/16650 (epoch 44.907), train_loss = 0.70060705, grad/param norm = 3.6697e-01, time/batch = 18.2106s	
14955/16650 (epoch 44.910), train_loss = 0.70299393, grad/param norm = 3.1054e-01, time/batch = 16.3677s	
14956/16650 (epoch 44.913), train_loss = 0.64896432, grad/param norm = 3.1656e-01, time/batch = 16.3356s	
14957/16650 (epoch 44.916), train_loss = 0.60996774, grad/param norm = 3.2030e-01, time/batch = 16.1054s	
14958/16650 (epoch 44.919), train_loss = 0.79300983, grad/param norm = 2.8385e-01, time/batch = 16.8522s	
14959/16650 (epoch 44.922), train_loss = 0.67808705, grad/param norm = 3.2348e-01, time/batch = 15.3074s	
14960/16650 (epoch 44.925), train_loss = 0.62388512, grad/param norm = 3.0266e-01, time/batch = 16.5187s	
14961/16650 (epoch 44.928), train_loss = 0.67509237, grad/param norm = 2.9490e-01, time/batch = 15.5887s	
14962/16650 (epoch 44.931), train_loss = 0.68318889, grad/param norm = 3.2257e-01, time/batch = 16.5073s	
14963/16650 (epoch 44.934), train_loss = 0.55461614, grad/param norm = 3.3080e-01, time/batch = 16.0176s	
14964/16650 (epoch 44.937), train_loss = 0.61227459, grad/param norm = 3.0688e-01, time/batch = 16.3500s	
14965/16650 (epoch 44.940), train_loss = 0.67702291, grad/param norm = 3.0253e-01, time/batch = 17.7155s	
14966/16650 (epoch 44.943), train_loss = 0.71189464, grad/param norm = 3.6567e-01, time/batch = 16.0210s	
14967/16650 (epoch 44.946), train_loss = 0.63326495, grad/param norm = 2.9530e-01, time/batch = 15.0112s	
14968/16650 (epoch 44.949), train_loss = 0.57583523, grad/param norm = 2.7391e-01, time/batch = 17.8650s	
14969/16650 (epoch 44.952), train_loss = 0.57718908, grad/param norm = 2.8458e-01, time/batch = 17.4578s	
14970/16650 (epoch 44.955), train_loss = 0.66529991, grad/param norm = 3.2221e-01, time/batch = 15.9936s	
14971/16650 (epoch 44.958), train_loss = 0.72094315, grad/param norm = 3.5241e-01, time/batch = 16.5702s	
14972/16650 (epoch 44.961), train_loss = 0.66391623, grad/param norm = 2.5948e-01, time/batch = 16.6937s	
14973/16650 (epoch 44.964), train_loss = 0.58442553, grad/param norm = 4.0561e-01, time/batch = 17.7095s	
14974/16650 (epoch 44.967), train_loss = 0.78181934, grad/param norm = 3.3226e-01, time/batch = 15.4180s	
14975/16650 (epoch 44.970), train_loss = 0.63308891, grad/param norm = 2.6589e-01, time/batch = 16.7095s	
14976/16650 (epoch 44.973), train_loss = 0.63265154, grad/param norm = 3.6099e-01, time/batch = 15.0043s	
14977/16650 (epoch 44.976), train_loss = 0.61463968, grad/param norm = 2.9144e-01, time/batch = 17.0381s	
14978/16650 (epoch 44.979), train_loss = 0.68591058, grad/param norm = 2.9217e-01, time/batch = 16.4283s	
14979/16650 (epoch 44.982), train_loss = 0.72309196, grad/param norm = 2.8931e-01, time/batch = 16.4472s	
14980/16650 (epoch 44.985), train_loss = 0.68601942, grad/param norm = 2.8440e-01, time/batch = 17.7133s	
14981/16650 (epoch 44.988), train_loss = 0.70399373, grad/param norm = 3.9865e-01, time/batch = 16.0156s	
14982/16650 (epoch 44.991), train_loss = 0.60195483, grad/param norm = 3.6397e-01, time/batch = 17.1942s	
14983/16650 (epoch 44.994), train_loss = 0.62518467, grad/param norm = 2.9892e-01, time/batch = 17.4459s	
14984/16650 (epoch 44.997), train_loss = 0.62930113, grad/param norm = 3.1264e-01, time/batch = 17.4670s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
14985/16650 (epoch 45.000), train_loss = 0.72628949, grad/param norm = 3.3221e-01, time/batch = 16.6089s	
14986/16650 (epoch 45.003), train_loss = 0.79596231, grad/param norm = 3.6070e-01, time/batch = 17.2792s	
14987/16650 (epoch 45.006), train_loss = 0.77473942, grad/param norm = 4.0702e-01, time/batch = 15.3189s	
14988/16650 (epoch 45.009), train_loss = 0.78327746, grad/param norm = 3.2931e-01, time/batch = 16.1703s	
14989/16650 (epoch 45.012), train_loss = 0.76569694, grad/param norm = 3.2157e-01, time/batch = 15.8607s	
14990/16650 (epoch 45.015), train_loss = 0.67725375, grad/param norm = 2.8677e-01, time/batch = 16.5277s	
14991/16650 (epoch 45.018), train_loss = 0.59575753, grad/param norm = 2.9912e-01, time/batch = 16.7567s	
14992/16650 (epoch 45.021), train_loss = 0.79064588, grad/param norm = 3.6161e-01, time/batch = 16.0919s	
14993/16650 (epoch 45.024), train_loss = 0.67921637, grad/param norm = 3.0856e-01, time/batch = 17.2686s	
14994/16650 (epoch 45.027), train_loss = 0.70672159, grad/param norm = 2.8702e-01, time/batch = 17.2964s	
14995/16650 (epoch 45.030), train_loss = 0.57314075, grad/param norm = 2.8155e-01, time/batch = 16.6939s	
14996/16650 (epoch 45.033), train_loss = 0.65725614, grad/param norm = 2.6286e-01, time/batch = 15.1539s	
14997/16650 (epoch 45.036), train_loss = 0.47159433, grad/param norm = 3.4847e-01, time/batch = 15.5023s	
14998/16650 (epoch 45.039), train_loss = 0.75572232, grad/param norm = 2.8137e-01, time/batch = 17.6920s	
14999/16650 (epoch 45.042), train_loss = 0.70717966, grad/param norm = 3.4219e-01, time/batch = 17.3455s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch45.05_2.3594.t7	
15000/16650 (epoch 45.045), train_loss = 0.68922569, grad/param norm = 3.3365e-01, time/batch = 18.8716s	
15001/16650 (epoch 45.048), train_loss = 1.29181757, grad/param norm = 5.2781e-01, time/batch = 18.6972s	
15002/16650 (epoch 45.051), train_loss = 0.68223812, grad/param norm = 3.4238e-01, time/batch = 16.0797s	
15003/16650 (epoch 45.054), train_loss = 0.68812390, grad/param norm = 3.0383e-01, time/batch = 16.2368s	
15004/16650 (epoch 45.057), train_loss = 0.67374758, grad/param norm = 3.9462e-01, time/batch = 16.9407s	
15005/16650 (epoch 45.060), train_loss = 0.56077922, grad/param norm = 2.6724e-01, time/batch = 18.0111s	
15006/16650 (epoch 45.063), train_loss = 0.65570082, grad/param norm = 2.9764e-01, time/batch = 17.7679s	
15007/16650 (epoch 45.066), train_loss = 0.81218723, grad/param norm = 3.4160e-01, time/batch = 18.8578s	
15008/16650 (epoch 45.069), train_loss = 0.72545417, grad/param norm = 3.2821e-01, time/batch = 19.2911s	
15009/16650 (epoch 45.072), train_loss = 0.69794367, grad/param norm = 3.3496e-01, time/batch = 15.0997s	
15010/16650 (epoch 45.075), train_loss = 0.75422950, grad/param norm = 3.7780e-01, time/batch = 18.2928s	
15011/16650 (epoch 45.078), train_loss = 0.75113995, grad/param norm = 3.3764e-01, time/batch = 18.0321s	
15012/16650 (epoch 45.081), train_loss = 0.71390132, grad/param norm = 3.4537e-01, time/batch = 17.0905s	
15013/16650 (epoch 45.084), train_loss = 0.69758078, grad/param norm = 3.0751e-01, time/batch = 18.7682s	
15014/16650 (epoch 45.087), train_loss = 0.69864547, grad/param norm = 2.7608e-01, time/batch = 17.5325s	
15015/16650 (epoch 45.090), train_loss = 0.66465442, grad/param norm = 3.3559e-01, time/batch = 15.5700s	
15016/16650 (epoch 45.093), train_loss = 0.78863722, grad/param norm = 3.6685e-01, time/batch = 16.6803s	
15017/16650 (epoch 45.096), train_loss = 0.64063780, grad/param norm = 3.1194e-01, time/batch = 18.0349s	
15018/16650 (epoch 45.099), train_loss = 0.70650456, grad/param norm = 3.0867e-01, time/batch = 15.5244s	
15019/16650 (epoch 45.102), train_loss = 0.68220953, grad/param norm = 3.2429e-01, time/batch = 16.5074s	
15020/16650 (epoch 45.105), train_loss = 0.69667537, grad/param norm = 3.4611e-01, time/batch = 16.7042s	
15021/16650 (epoch 45.108), train_loss = 0.71176734, grad/param norm = 3.2432e-01, time/batch = 17.2606s	
15022/16650 (epoch 45.111), train_loss = 0.79054522, grad/param norm = 3.1169e-01, time/batch = 17.4555s	
15023/16650 (epoch 45.114), train_loss = 0.72366460, grad/param norm = 5.8438e-01, time/batch = 15.7226s	
15024/16650 (epoch 45.117), train_loss = 0.81611737, grad/param norm = 3.5660e-01, time/batch = 17.2931s	
15025/16650 (epoch 45.120), train_loss = 0.70773346, grad/param norm = 3.0867e-01, time/batch = 16.3007s	
15026/16650 (epoch 45.123), train_loss = 0.67315068, grad/param norm = 3.3330e-01, time/batch = 15.6784s	
15027/16650 (epoch 45.126), train_loss = 0.74284096, grad/param norm = 3.3058e-01, time/batch = 15.5579s	
15028/16650 (epoch 45.129), train_loss = 0.74058608, grad/param norm = 3.3863e-01, time/batch = 14.7533s	
15029/16650 (epoch 45.132), train_loss = 0.66779762, grad/param norm = 3.5319e-01, time/batch = 17.2094s	
15030/16650 (epoch 45.135), train_loss = 0.78482631, grad/param norm = 2.7857e-01, time/batch = 15.1784s	
15031/16650 (epoch 45.138), train_loss = 0.76189880, grad/param norm = 3.3622e-01, time/batch = 17.1504s	
15032/16650 (epoch 45.141), train_loss = 0.71232939, grad/param norm = 3.4665e-01, time/batch = 18.0420s	
15033/16650 (epoch 45.144), train_loss = 0.73797306, grad/param norm = 3.3066e-01, time/batch = 16.8708s	
15034/16650 (epoch 45.147), train_loss = 0.82539942, grad/param norm = 4.0290e-01, time/batch = 16.4287s	
15035/16650 (epoch 45.150), train_loss = 0.87830775, grad/param norm = 3.8801e-01, time/batch = 17.0254s	
15036/16650 (epoch 45.153), train_loss = 0.67562371, grad/param norm = 2.7247e-01, time/batch = 16.7754s	
15037/16650 (epoch 45.156), train_loss = 0.70093498, grad/param norm = 2.7836e-01, time/batch = 16.0172s	
15038/16650 (epoch 45.159), train_loss = 0.73458235, grad/param norm = 3.1370e-01, time/batch = 13.5812s	
15039/16650 (epoch 45.162), train_loss = 0.81342868, grad/param norm = 2.9379e-01, time/batch = 13.5896s	
15040/16650 (epoch 45.165), train_loss = 0.78600495, grad/param norm = 3.1493e-01, time/batch = 13.5248s	
15041/16650 (epoch 45.168), train_loss = 0.60049155, grad/param norm = 2.9426e-01, time/batch = 16.2425s	
15042/16650 (epoch 45.171), train_loss = 0.73695175, grad/param norm = 2.8869e-01, time/batch = 16.4491s	
15043/16650 (epoch 45.174), train_loss = 0.56775693, grad/param norm = 2.7806e-01, time/batch = 18.3008s	
15044/16650 (epoch 45.177), train_loss = 0.69461172, grad/param norm = 3.4863e-01, time/batch = 16.8638s	
15045/16650 (epoch 45.180), train_loss = 0.79457813, grad/param norm = 3.3024e-01, time/batch = 15.9190s	
15046/16650 (epoch 45.183), train_loss = 0.91648931, grad/param norm = 3.7983e-01, time/batch = 17.2965s	
15047/16650 (epoch 45.186), train_loss = 0.73653590, grad/param norm = 3.5536e-01, time/batch = 16.9596s	
15048/16650 (epoch 45.189), train_loss = 0.65216570, grad/param norm = 2.7152e-01, time/batch = 15.1567s	
15049/16650 (epoch 45.192), train_loss = 0.68707051, grad/param norm = 2.8933e-01, time/batch = 16.5148s	
15050/16650 (epoch 45.195), train_loss = 0.63577247, grad/param norm = 3.1398e-01, time/batch = 15.7441s	
15051/16650 (epoch 45.198), train_loss = 0.62065481, grad/param norm = 2.6791e-01, time/batch = 18.4497s	
15052/16650 (epoch 45.201), train_loss = 0.61002567, grad/param norm = 3.0728e-01, time/batch = 14.3918s	
15053/16650 (epoch 45.204), train_loss = 0.71870967, grad/param norm = 3.5192e-01, time/batch = 14.0735s	
15054/16650 (epoch 45.207), train_loss = 0.73258664, grad/param norm = 3.5293e-01, time/batch = 13.9230s	
15055/16650 (epoch 45.210), train_loss = 0.69649533, grad/param norm = 3.6362e-01, time/batch = 15.5910s	
15056/16650 (epoch 45.213), train_loss = 0.75625851, grad/param norm = 3.7471e-01, time/batch = 13.9755s	
15057/16650 (epoch 45.216), train_loss = 0.62050665, grad/param norm = 2.9118e-01, time/batch = 13.9617s	
15058/16650 (epoch 45.219), train_loss = 0.68060022, grad/param norm = 3.2169e-01, time/batch = 13.8296s	
15059/16650 (epoch 45.222), train_loss = 0.71187762, grad/param norm = 2.5705e-01, time/batch = 14.4200s	
15060/16650 (epoch 45.225), train_loss = 0.74408676, grad/param norm = 4.1236e-01, time/batch = 16.4372s	
15061/16650 (epoch 45.228), train_loss = 0.65388909, grad/param norm = 2.8756e-01, time/batch = 16.6949s	
15062/16650 (epoch 45.231), train_loss = 0.63735445, grad/param norm = 3.6202e-01, time/batch = 16.3431s	
15063/16650 (epoch 45.234), train_loss = 0.82827580, grad/param norm = 3.7224e-01, time/batch = 16.6698s	
15064/16650 (epoch 45.237), train_loss = 0.71315895, grad/param norm = 2.8742e-01, time/batch = 16.1955s	
15065/16650 (epoch 45.240), train_loss = 0.72492088, grad/param norm = 2.7451e-01, time/batch = 15.9365s	
15066/16650 (epoch 45.243), train_loss = 0.68815854, grad/param norm = 3.7602e-01, time/batch = 17.7018s	
15067/16650 (epoch 45.246), train_loss = 0.79850475, grad/param norm = 3.5508e-01, time/batch = 16.8705s	
15068/16650 (epoch 45.249), train_loss = 0.59131001, grad/param norm = 2.5722e-01, time/batch = 15.9432s	
15069/16650 (epoch 45.252), train_loss = 0.67185262, grad/param norm = 3.3746e-01, time/batch = 18.2029s	
15070/16650 (epoch 45.255), train_loss = 0.73464827, grad/param norm = 2.8733e-01, time/batch = 13.8107s	
15071/16650 (epoch 45.258), train_loss = 0.76686275, grad/param norm = 3.0762e-01, time/batch = 13.8829s	
15072/16650 (epoch 45.261), train_loss = 0.72326471, grad/param norm = 3.0958e-01, time/batch = 13.6784s	
15073/16650 (epoch 45.264), train_loss = 0.64223080, grad/param norm = 3.1625e-01, time/batch = 14.7475s	
15074/16650 (epoch 45.267), train_loss = 0.66606765, grad/param norm = 3.1801e-01, time/batch = 17.6274s	
15075/16650 (epoch 45.270), train_loss = 0.74855950, grad/param norm = 3.0932e-01, time/batch = 16.5843s	
15076/16650 (epoch 45.273), train_loss = 0.77149748, grad/param norm = 3.2757e-01, time/batch = 15.0267s	
15077/16650 (epoch 45.276), train_loss = 0.75965025, grad/param norm = 3.3735e-01, time/batch = 16.9386s	
15078/16650 (epoch 45.279), train_loss = 0.65821395, grad/param norm = 2.7683e-01, time/batch = 15.7066s	
15079/16650 (epoch 45.282), train_loss = 0.63860240, grad/param norm = 2.6626e-01, time/batch = 15.9010s	
15080/16650 (epoch 45.285), train_loss = 0.66942106, grad/param norm = 2.8130e-01, time/batch = 17.1831s	
15081/16650 (epoch 45.288), train_loss = 0.59484693, grad/param norm = 2.8138e-01, time/batch = 18.7900s	
15082/16650 (epoch 45.291), train_loss = 0.50812245, grad/param norm = 2.8103e-01, time/batch = 16.5064s	
15083/16650 (epoch 45.294), train_loss = 0.62249552, grad/param norm = 2.7488e-01, time/batch = 14.3003s	
15084/16650 (epoch 45.297), train_loss = 0.67761518, grad/param norm = 3.1521e-01, time/batch = 14.3867s	
15085/16650 (epoch 45.300), train_loss = 0.53390822, grad/param norm = 2.5966e-01, time/batch = 18.1836s	
15086/16650 (epoch 45.303), train_loss = 0.59848563, grad/param norm = 2.9129e-01, time/batch = 16.8489s	
15087/16650 (epoch 45.306), train_loss = 0.75107268, grad/param norm = 2.6477e-01, time/batch = 15.5330s	
15088/16650 (epoch 45.309), train_loss = 0.72519263, grad/param norm = 2.7424e-01, time/batch = 18.6973s	
15089/16650 (epoch 45.312), train_loss = 0.56750708, grad/param norm = 2.9397e-01, time/batch = 18.3771s	
15090/16650 (epoch 45.315), train_loss = 0.48463072, grad/param norm = 2.7555e-01, time/batch = 17.2585s	
15091/16650 (epoch 45.318), train_loss = 0.55148128, grad/param norm = 2.7721e-01, time/batch = 17.3707s	
15092/16650 (epoch 45.321), train_loss = 0.74132519, grad/param norm = 3.1966e-01, time/batch = 16.0799s	
15093/16650 (epoch 45.324), train_loss = 0.61889750, grad/param norm = 3.2547e-01, time/batch = 16.5750s	
15094/16650 (epoch 45.327), train_loss = 0.69663986, grad/param norm = 3.0642e-01, time/batch = 18.0271s	
15095/16650 (epoch 45.330), train_loss = 0.69329166, grad/param norm = 3.8537e-01, time/batch = 17.0338s	
15096/16650 (epoch 45.333), train_loss = 0.72345095, grad/param norm = 3.9587e-01, time/batch = 17.4280s	
15097/16650 (epoch 45.336), train_loss = 0.60674505, grad/param norm = 3.1917e-01, time/batch = 16.5802s	
15098/16650 (epoch 45.339), train_loss = 0.63024360, grad/param norm = 3.1946e-01, time/batch = 16.1843s	
15099/16650 (epoch 45.342), train_loss = 0.57768184, grad/param norm = 2.8315e-01, time/batch = 16.5811s	
15100/16650 (epoch 45.345), train_loss = 0.62498291, grad/param norm = 2.7745e-01, time/batch = 16.4206s	
15101/16650 (epoch 45.348), train_loss = 0.72744500, grad/param norm = 3.5739e-01, time/batch = 16.8506s	
15102/16650 (epoch 45.351), train_loss = 0.70229497, grad/param norm = 3.3982e-01, time/batch = 17.0648s	
15103/16650 (epoch 45.354), train_loss = 0.75035880, grad/param norm = 3.2838e-01, time/batch = 17.6123s	
15104/16650 (epoch 45.357), train_loss = 0.72905274, grad/param norm = 3.1630e-01, time/batch = 16.9927s	
15105/16650 (epoch 45.360), train_loss = 0.69235698, grad/param norm = 3.3466e-01, time/batch = 18.2918s	
15106/16650 (epoch 45.363), train_loss = 0.75326057, grad/param norm = 3.2534e-01, time/batch = 17.3377s	
15107/16650 (epoch 45.366), train_loss = 0.81054776, grad/param norm = 3.4176e-01, time/batch = 15.4974s	
15108/16650 (epoch 45.369), train_loss = 0.74129841, grad/param norm = 3.4913e-01, time/batch = 18.6883s	
15109/16650 (epoch 45.372), train_loss = 0.69944322, grad/param norm = 2.9850e-01, time/batch = 18.6189s	
15110/16650 (epoch 45.375), train_loss = 0.70078338, grad/param norm = 2.6934e-01, time/batch = 16.6981s	
15111/16650 (epoch 45.378), train_loss = 0.64333189, grad/param norm = 2.7634e-01, time/batch = 17.4317s	
15112/16650 (epoch 45.381), train_loss = 0.75641387, grad/param norm = 3.2292e-01, time/batch = 17.5124s	
15113/16650 (epoch 45.384), train_loss = 0.80680709, grad/param norm = 3.2624e-01, time/batch = 17.0289s	
15114/16650 (epoch 45.387), train_loss = 0.54944507, grad/param norm = 2.6612e-01, time/batch = 16.2456s	
15115/16650 (epoch 45.390), train_loss = 0.75245593, grad/param norm = 3.0135e-01, time/batch = 17.2048s	
15116/16650 (epoch 45.393), train_loss = 0.68352374, grad/param norm = 3.4254e-01, time/batch = 17.9421s	
15117/16650 (epoch 45.396), train_loss = 0.78887562, grad/param norm = 3.5415e-01, time/batch = 15.0614s	
15118/16650 (epoch 45.399), train_loss = 0.73903160, grad/param norm = 2.8221e-01, time/batch = 17.1742s	
15119/16650 (epoch 45.402), train_loss = 0.66378770, grad/param norm = 2.8530e-01, time/batch = 18.0409s	
15120/16650 (epoch 45.405), train_loss = 0.53621171, grad/param norm = 2.7844e-01, time/batch = 18.0275s	
15121/16650 (epoch 45.408), train_loss = 0.72855492, grad/param norm = 2.8244e-01, time/batch = 17.4281s	
15122/16650 (epoch 45.411), train_loss = 0.63151865, grad/param norm = 3.0929e-01, time/batch = 18.6961s	
15123/16650 (epoch 45.414), train_loss = 0.61109869, grad/param norm = 3.1061e-01, time/batch = 18.6244s	
15124/16650 (epoch 45.417), train_loss = 0.59262296, grad/param norm = 3.0060e-01, time/batch = 16.6893s	
15125/16650 (epoch 45.420), train_loss = 0.61240471, grad/param norm = 2.6595e-01, time/batch = 17.1831s	
15126/16650 (epoch 45.423), train_loss = 0.51388941, grad/param norm = 2.5126e-01, time/batch = 18.2803s	
15127/16650 (epoch 45.426), train_loss = 0.59897732, grad/param norm = 3.1621e-01, time/batch = 16.2557s	
15128/16650 (epoch 45.429), train_loss = 0.76651623, grad/param norm = 3.1582e-01, time/batch = 14.6266s	
15129/16650 (epoch 45.432), train_loss = 0.73692253, grad/param norm = 3.2292e-01, time/batch = 18.1851s	
15130/16650 (epoch 45.435), train_loss = 0.83034145, grad/param norm = 3.4693e-01, time/batch = 16.9384s	
15131/16650 (epoch 45.438), train_loss = 0.83212721, grad/param norm = 4.0007e-01, time/batch = 21.1335s	
15132/16650 (epoch 45.441), train_loss = 0.67045673, grad/param norm = 3.7588e-01, time/batch = 28.6817s	
15133/16650 (epoch 45.444), train_loss = 0.65340013, grad/param norm = 3.4180e-01, time/batch = 17.1985s	
15134/16650 (epoch 45.447), train_loss = 0.63526752, grad/param norm = 3.0189e-01, time/batch = 15.3257s	
15135/16650 (epoch 45.450), train_loss = 0.64280806, grad/param norm = 3.4214e-01, time/batch = 17.3691s	
15136/16650 (epoch 45.453), train_loss = 0.63099581, grad/param norm = 2.8176e-01, time/batch = 17.9316s	
15137/16650 (epoch 45.456), train_loss = 0.58367394, grad/param norm = 2.5403e-01, time/batch = 16.5897s	
15138/16650 (epoch 45.459), train_loss = 0.61564057, grad/param norm = 2.8327e-01, time/batch = 16.1305s	
15139/16650 (epoch 45.462), train_loss = 0.78665960, grad/param norm = 4.2513e-01, time/batch = 18.7145s	
15140/16650 (epoch 45.465), train_loss = 0.62716386, grad/param norm = 2.9376e-01, time/batch = 18.7944s	
15141/16650 (epoch 45.468), train_loss = 0.51694011, grad/param norm = 2.7683e-01, time/batch = 16.0043s	
15142/16650 (epoch 45.471), train_loss = 0.45218388, grad/param norm = 2.3232e-01, time/batch = 18.1105s	
15143/16650 (epoch 45.474), train_loss = 0.58889736, grad/param norm = 2.7563e-01, time/batch = 14.9065s	
15144/16650 (epoch 45.477), train_loss = 0.71998172, grad/param norm = 3.7395e-01, time/batch = 13.9040s	
15145/16650 (epoch 45.480), train_loss = 0.63874323, grad/param norm = 3.7403e-01, time/batch = 14.8129s	
15146/16650 (epoch 45.483), train_loss = 0.72948465, grad/param norm = 3.2950e-01, time/batch = 17.0776s	
15147/16650 (epoch 45.486), train_loss = 0.57451291, grad/param norm = 2.4788e-01, time/batch = 16.5245s	
15148/16650 (epoch 45.489), train_loss = 0.66939296, grad/param norm = 3.6784e-01, time/batch = 15.7422s	
15149/16650 (epoch 45.492), train_loss = 0.68307753, grad/param norm = 2.8481e-01, time/batch = 15.1742s	
15150/16650 (epoch 45.495), train_loss = 0.56742380, grad/param norm = 2.9765e-01, time/batch = 17.4683s	
15151/16650 (epoch 45.498), train_loss = 0.63189234, grad/param norm = 3.7927e-01, time/batch = 15.6790s	
15152/16650 (epoch 45.502), train_loss = 0.81369558, grad/param norm = 4.5819e-01, time/batch = 16.1738s	
15153/16650 (epoch 45.505), train_loss = 0.70505259, grad/param norm = 3.4982e-01, time/batch = 13.9778s	
15154/16650 (epoch 45.508), train_loss = 0.74573662, grad/param norm = 4.5236e-01, time/batch = 14.5940s	
15155/16650 (epoch 45.511), train_loss = 0.71938399, grad/param norm = 3.1238e-01, time/batch = 13.8200s	
15156/16650 (epoch 45.514), train_loss = 0.58501700, grad/param norm = 2.8641e-01, time/batch = 14.8217s	
15157/16650 (epoch 45.517), train_loss = 0.64382348, grad/param norm = 3.2900e-01, time/batch = 15.0677s	
15158/16650 (epoch 45.520), train_loss = 0.56717137, grad/param norm = 3.2980e-01, time/batch = 16.2567s	
15159/16650 (epoch 45.523), train_loss = 0.66725643, grad/param norm = 3.1893e-01, time/batch = 17.2006s	
15160/16650 (epoch 45.526), train_loss = 0.73493902, grad/param norm = 2.7186e-01, time/batch = 16.2726s	
15161/16650 (epoch 45.529), train_loss = 0.74666125, grad/param norm = 3.2892e-01, time/batch = 17.4557s	
15162/16650 (epoch 45.532), train_loss = 0.50337243, grad/param norm = 2.7915e-01, time/batch = 16.4990s	
15163/16650 (epoch 45.535), train_loss = 0.60653180, grad/param norm = 3.4103e-01, time/batch = 16.0093s	
15164/16650 (epoch 45.538), train_loss = 0.53982466, grad/param norm = 3.5402e-01, time/batch = 14.5931s	
15165/16650 (epoch 45.541), train_loss = 0.77827777, grad/param norm = 3.1205e-01, time/batch = 15.4054s	
15166/16650 (epoch 45.544), train_loss = 0.83829962, grad/param norm = 7.0044e-01, time/batch = 17.0838s	
15167/16650 (epoch 45.547), train_loss = 0.56689372, grad/param norm = 2.9527e-01, time/batch = 15.3430s	
15168/16650 (epoch 45.550), train_loss = 0.68526850, grad/param norm = 3.2892e-01, time/batch = 17.2800s	
15169/16650 (epoch 45.553), train_loss = 0.66307790, grad/param norm = 3.4259e-01, time/batch = 16.8764s	
15170/16650 (epoch 45.556), train_loss = 0.60504675, grad/param norm = 2.7804e-01, time/batch = 16.6186s	
15171/16650 (epoch 45.559), train_loss = 0.52865855, grad/param norm = 2.6977e-01, time/batch = 15.9237s	
15172/16650 (epoch 45.562), train_loss = 0.59346467, grad/param norm = 2.9426e-01, time/batch = 15.7276s	
15173/16650 (epoch 45.565), train_loss = 0.52850403, grad/param norm = 3.5678e-01, time/batch = 13.6168s	
15174/16650 (epoch 45.568), train_loss = 0.53656378, grad/param norm = 2.9326e-01, time/batch = 14.7701s	
15175/16650 (epoch 45.571), train_loss = 0.60821410, grad/param norm = 4.0486e-01, time/batch = 14.4881s	
15176/16650 (epoch 45.574), train_loss = 0.60091487, grad/param norm = 3.5377e-01, time/batch = 13.8946s	
15177/16650 (epoch 45.577), train_loss = 0.63404786, grad/param norm = 2.9173e-01, time/batch = 15.8091s	
15178/16650 (epoch 45.580), train_loss = 0.59883668, grad/param norm = 2.7431e-01, time/batch = 16.6923s	
15179/16650 (epoch 45.583), train_loss = 0.68454960, grad/param norm = 2.8253e-01, time/batch = 16.3355s	
15180/16650 (epoch 45.586), train_loss = 0.58797537, grad/param norm = 4.0053e-01, time/batch = 17.2727s	
15181/16650 (epoch 45.589), train_loss = 0.57346244, grad/param norm = 2.9365e-01, time/batch = 15.0820s	
15182/16650 (epoch 45.592), train_loss = 0.65016554, grad/param norm = 2.9014e-01, time/batch = 14.9058s	
15183/16650 (epoch 45.595), train_loss = 0.59023250, grad/param norm = 2.9553e-01, time/batch = 14.9185s	
15184/16650 (epoch 45.598), train_loss = 0.62917274, grad/param norm = 2.9232e-01, time/batch = 16.9334s	
15185/16650 (epoch 45.601), train_loss = 0.60007688, grad/param norm = 3.6015e-01, time/batch = 14.3615s	
15186/16650 (epoch 45.604), train_loss = 0.62966324, grad/param norm = 3.0099e-01, time/batch = 14.3597s	
15187/16650 (epoch 45.607), train_loss = 0.69741907, grad/param norm = 3.2498e-01, time/batch = 13.8827s	
15188/16650 (epoch 45.610), train_loss = 0.60316458, grad/param norm = 3.2183e-01, time/batch = 14.6202s	
15189/16650 (epoch 45.613), train_loss = 0.74970412, grad/param norm = 3.0950e-01, time/batch = 16.0302s	
15190/16650 (epoch 45.616), train_loss = 0.70450428, grad/param norm = 3.8956e-01, time/batch = 16.4290s	
15191/16650 (epoch 45.619), train_loss = 0.55284614, grad/param norm = 2.7554e-01, time/batch = 16.6892s	
15192/16650 (epoch 45.622), train_loss = 0.54213849, grad/param norm = 2.6233e-01, time/batch = 16.5291s	
15193/16650 (epoch 45.625), train_loss = 0.65487990, grad/param norm = 2.7837e-01, time/batch = 16.6107s	
15194/16650 (epoch 45.628), train_loss = 0.60720466, grad/param norm = 3.5720e-01, time/batch = 15.1090s	
15195/16650 (epoch 45.631), train_loss = 0.65454768, grad/param norm = 3.6137e-01, time/batch = 14.4267s	
15196/16650 (epoch 45.634), train_loss = 0.82759659, grad/param norm = 4.1530e-01, time/batch = 15.9179s	
15197/16650 (epoch 45.637), train_loss = 0.78714591, grad/param norm = 3.1674e-01, time/batch = 16.4251s	
15198/16650 (epoch 45.640), train_loss = 0.63904723, grad/param norm = 3.1475e-01, time/batch = 15.0164s	
15199/16650 (epoch 45.643), train_loss = 0.72310528, grad/param norm = 2.9153e-01, time/batch = 14.5963s	
15200/16650 (epoch 45.646), train_loss = 0.68943219, grad/param norm = 3.4772e-01, time/batch = 14.2814s	
15201/16650 (epoch 45.649), train_loss = 0.68768829, grad/param norm = 3.3096e-01, time/batch = 17.0918s	
15202/16650 (epoch 45.652), train_loss = 0.68766366, grad/param norm = 3.0150e-01, time/batch = 15.5637s	
15203/16650 (epoch 45.655), train_loss = 0.65116560, grad/param norm = 3.1962e-01, time/batch = 16.4329s	
15204/16650 (epoch 45.658), train_loss = 0.62006142, grad/param norm = 3.6122e-01, time/batch = 15.3365s	
15205/16650 (epoch 45.661), train_loss = 0.66609634, grad/param norm = 3.2410e-01, time/batch = 16.7641s	
15206/16650 (epoch 45.664), train_loss = 0.65991030, grad/param norm = 3.4342e-01, time/batch = 15.1829s	
15207/16650 (epoch 45.667), train_loss = 0.75632780, grad/param norm = 3.3857e-01, time/batch = 16.2821s	
15208/16650 (epoch 45.670), train_loss = 0.56140227, grad/param norm = 2.7254e-01, time/batch = 17.5142s	
15209/16650 (epoch 45.673), train_loss = 0.57644364, grad/param norm = 2.6453e-01, time/batch = 16.0119s	
15210/16650 (epoch 45.676), train_loss = 0.70316431, grad/param norm = 3.0234e-01, time/batch = 14.2139s	
15211/16650 (epoch 45.679), train_loss = 0.59509922, grad/param norm = 3.0211e-01, time/batch = 14.0949s	
15212/16650 (epoch 45.682), train_loss = 0.64457954, grad/param norm = 2.7604e-01, time/batch = 17.4579s	
15213/16650 (epoch 45.685), train_loss = 0.54056882, grad/param norm = 3.0917e-01, time/batch = 16.4248s	
15214/16650 (epoch 45.688), train_loss = 0.71577609, grad/param norm = 3.2624e-01, time/batch = 17.6759s	
15215/16650 (epoch 45.691), train_loss = 0.67962121, grad/param norm = 3.2233e-01, time/batch = 15.0305s	
15216/16650 (epoch 45.694), train_loss = 0.60340557, grad/param norm = 2.9478e-01, time/batch = 13.9558s	
15217/16650 (epoch 45.697), train_loss = 0.57366713, grad/param norm = 2.7375e-01, time/batch = 15.0917s	
15218/16650 (epoch 45.700), train_loss = 0.68030853, grad/param norm = 3.0776e-01, time/batch = 16.0872s	
15219/16650 (epoch 45.703), train_loss = 0.58727776, grad/param norm = 4.0195e-01, time/batch = 14.7931s	
15220/16650 (epoch 45.706), train_loss = 0.65002579, grad/param norm = 3.5906e-01, time/batch = 15.3791s	
15221/16650 (epoch 45.709), train_loss = 0.57655785, grad/param norm = 3.2810e-01, time/batch = 16.3328s	
15222/16650 (epoch 45.712), train_loss = 0.60034082, grad/param norm = 4.2951e-01, time/batch = 18.6120s	
15223/16650 (epoch 45.715), train_loss = 0.68584013, grad/param norm = 3.7094e-01, time/batch = 17.2830s	
15224/16650 (epoch 45.718), train_loss = 0.72038908, grad/param norm = 3.5049e-01, time/batch = 15.5432s	
15225/16650 (epoch 45.721), train_loss = 0.71838471, grad/param norm = 2.7832e-01, time/batch = 14.4826s	
15226/16650 (epoch 45.724), train_loss = 0.72177827, grad/param norm = 3.9083e-01, time/batch = 17.1630s	
15227/16650 (epoch 45.727), train_loss = 0.73013644, grad/param norm = 3.0490e-01, time/batch = 17.2649s	
15228/16650 (epoch 45.730), train_loss = 0.59775938, grad/param norm = 2.8558e-01, time/batch = 15.2936s	
15229/16650 (epoch 45.733), train_loss = 0.76961566, grad/param norm = 4.0048e-01, time/batch = 14.7754s	
15230/16650 (epoch 45.736), train_loss = 0.55510420, grad/param norm = 2.7621e-01, time/batch = 15.1296s	
15231/16650 (epoch 45.739), train_loss = 0.66284896, grad/param norm = 2.9033e-01, time/batch = 16.6027s	
15232/16650 (epoch 45.742), train_loss = 0.66351918, grad/param norm = 2.8728e-01, time/batch = 14.9581s	
15233/16650 (epoch 45.745), train_loss = 0.52789493, grad/param norm = 3.5286e-01, time/batch = 17.6701s	
15234/16650 (epoch 45.748), train_loss = 0.55627333, grad/param norm = 2.9293e-01, time/batch = 17.2728s	
15235/16650 (epoch 45.751), train_loss = 0.65628213, grad/param norm = 4.6393e-01, time/batch = 17.5042s	
15236/16650 (epoch 45.754), train_loss = 0.80240206, grad/param norm = 3.6461e-01, time/batch = 16.0118s	
15237/16650 (epoch 45.757), train_loss = 0.77846705, grad/param norm = 2.9631e-01, time/batch = 14.3478s	
15238/16650 (epoch 45.760), train_loss = 0.65762374, grad/param norm = 3.2826e-01, time/batch = 16.1540s	
15239/16650 (epoch 45.763), train_loss = 0.63034741, grad/param norm = 3.0131e-01, time/batch = 16.2534s	
15240/16650 (epoch 45.766), train_loss = 0.64436618, grad/param norm = 2.9374e-01, time/batch = 16.8614s	
15241/16650 (epoch 45.769), train_loss = 0.69626668, grad/param norm = 3.9179e-01, time/batch = 18.1179s	
15242/16650 (epoch 45.772), train_loss = 0.66609351, grad/param norm = 2.4368e-01, time/batch = 17.5192s	
15243/16650 (epoch 45.775), train_loss = 0.65028655, grad/param norm = 3.1881e-01, time/batch = 17.4936s	
15244/16650 (epoch 45.778), train_loss = 0.68773063, grad/param norm = 3.1165e-01, time/batch = 17.2358s	
15245/16650 (epoch 45.781), train_loss = 0.80472315, grad/param norm = 3.0224e-01, time/batch = 16.9102s	
15246/16650 (epoch 45.784), train_loss = 0.68136033, grad/param norm = 3.0835e-01, time/batch = 15.0137s	
15247/16650 (epoch 45.787), train_loss = 0.74210761, grad/param norm = 3.3558e-01, time/batch = 16.9472s	
15248/16650 (epoch 45.790), train_loss = 0.75960941, grad/param norm = 3.1664e-01, time/batch = 17.1060s	
15249/16650 (epoch 45.793), train_loss = 0.55787833, grad/param norm = 2.7478e-01, time/batch = 17.4186s	
15250/16650 (epoch 45.796), train_loss = 0.89439016, grad/param norm = 3.3055e-01, time/batch = 16.5183s	
15251/16650 (epoch 45.799), train_loss = 0.77704393, grad/param norm = 3.4594e-01, time/batch = 16.3603s	
15252/16650 (epoch 45.802), train_loss = 0.73844585, grad/param norm = 3.0141e-01, time/batch = 17.6296s	
15253/16650 (epoch 45.805), train_loss = 0.68785370, grad/param norm = 3.0449e-01, time/batch = 15.9344s	
15254/16650 (epoch 45.808), train_loss = 0.73861520, grad/param norm = 3.0409e-01, time/batch = 16.0225s	
15255/16650 (epoch 45.811), train_loss = 0.76397574, grad/param norm = 3.1842e-01, time/batch = 18.2058s	
15256/16650 (epoch 45.814), train_loss = 0.59564304, grad/param norm = 2.7421e-01, time/batch = 16.5317s	
15257/16650 (epoch 45.817), train_loss = 0.58969464, grad/param norm = 2.8119e-01, time/batch = 15.1667s	
15258/16650 (epoch 45.820), train_loss = 0.74211402, grad/param norm = 3.3017e-01, time/batch = 16.7790s	
15259/16650 (epoch 45.823), train_loss = 0.69083828, grad/param norm = 2.8706e-01, time/batch = 17.9720s	
15260/16650 (epoch 45.826), train_loss = 0.63364884, grad/param norm = 2.9822e-01, time/batch = 16.1562s	
15261/16650 (epoch 45.829), train_loss = 0.66223719, grad/param norm = 3.4736e-01, time/batch = 15.3959s	
15262/16650 (epoch 45.832), train_loss = 0.73792342, grad/param norm = 2.9167e-01, time/batch = 15.4491s	
15263/16650 (epoch 45.835), train_loss = 0.73861992, grad/param norm = 5.0703e-01, time/batch = 18.3890s	
15264/16650 (epoch 45.838), train_loss = 0.61986381, grad/param norm = 3.1935e-01, time/batch = 15.5154s	
15265/16650 (epoch 45.841), train_loss = 0.62127528, grad/param norm = 2.8688e-01, time/batch = 15.4319s	
15266/16650 (epoch 45.844), train_loss = 0.66367101, grad/param norm = 2.5774e-01, time/batch = 16.5341s	
15267/16650 (epoch 45.847), train_loss = 0.72572563, grad/param norm = 3.1593e-01, time/batch = 17.6261s	
15268/16650 (epoch 45.850), train_loss = 0.63486692, grad/param norm = 3.4377e-01, time/batch = 15.0666s	
15269/16650 (epoch 45.853), train_loss = 0.64755859, grad/param norm = 2.8906e-01, time/batch = 17.7950s	
15270/16650 (epoch 45.856), train_loss = 0.62424165, grad/param norm = 2.7968e-01, time/batch = 17.7907s	
15271/16650 (epoch 45.859), train_loss = 0.73464456, grad/param norm = 3.3771e-01, time/batch = 15.8287s	
15272/16650 (epoch 45.862), train_loss = 0.69548082, grad/param norm = 2.8720e-01, time/batch = 17.7010s	
15273/16650 (epoch 45.865), train_loss = 0.54315502, grad/param norm = 2.4324e-01, time/batch = 16.6009s	
15274/16650 (epoch 45.868), train_loss = 0.68501669, grad/param norm = 3.2773e-01, time/batch = 17.0317s	
15275/16650 (epoch 45.871), train_loss = 0.68492119, grad/param norm = 2.8531e-01, time/batch = 16.2580s	
15276/16650 (epoch 45.874), train_loss = 0.68186345, grad/param norm = 3.1078e-01, time/batch = 16.4411s	
15277/16650 (epoch 45.877), train_loss = 0.65595833, grad/param norm = 2.9448e-01, time/batch = 17.7091s	
15278/16650 (epoch 45.880), train_loss = 0.60163003, grad/param norm = 3.0021e-01, time/batch = 16.4407s	
15279/16650 (epoch 45.883), train_loss = 0.69053619, grad/param norm = 2.8360e-01, time/batch = 16.4479s	
15280/16650 (epoch 45.886), train_loss = 0.68404749, grad/param norm = 3.3678e-01, time/batch = 15.3519s	
15281/16650 (epoch 45.889), train_loss = 0.57400089, grad/param norm = 3.2955e-01, time/batch = 17.7881s	
15282/16650 (epoch 45.892), train_loss = 0.68333828, grad/param norm = 2.6424e-01, time/batch = 15.1688s	
15283/16650 (epoch 45.895), train_loss = 0.69596372, grad/param norm = 2.7000e-01, time/batch = 17.3797s	
15284/16650 (epoch 45.898), train_loss = 0.68419436, grad/param norm = 3.9108e-01, time/batch = 17.2775s	
15285/16650 (epoch 45.901), train_loss = 0.61973345, grad/param norm = 3.0781e-01, time/batch = 13.9737s	
15286/16650 (epoch 45.904), train_loss = 0.66920920, grad/param norm = 3.8119e-01, time/batch = 15.9992s	
15287/16650 (epoch 45.907), train_loss = 0.68962648, grad/param norm = 3.3435e-01, time/batch = 17.1203s	
15288/16650 (epoch 45.910), train_loss = 0.71184491, grad/param norm = 3.4371e-01, time/batch = 17.6251s	
15289/16650 (epoch 45.913), train_loss = 0.63420825, grad/param norm = 2.8550e-01, time/batch = 15.8439s	
15290/16650 (epoch 45.916), train_loss = 0.59377007, grad/param norm = 3.1340e-01, time/batch = 14.0531s	
15291/16650 (epoch 45.919), train_loss = 0.76908224, grad/param norm = 2.9499e-01, time/batch = 16.4206s	
15292/16650 (epoch 45.922), train_loss = 0.65943911, grad/param norm = 3.1741e-01, time/batch = 16.7994s	
15293/16650 (epoch 45.925), train_loss = 0.62274298, grad/param norm = 3.0479e-01, time/batch = 15.0963s	
15294/16650 (epoch 45.928), train_loss = 0.66434972, grad/param norm = 2.8997e-01, time/batch = 18.0270s	
15295/16650 (epoch 45.931), train_loss = 0.68703061, grad/param norm = 3.4636e-01, time/batch = 17.1115s	
15296/16650 (epoch 45.934), train_loss = 0.55012574, grad/param norm = 3.0598e-01, time/batch = 16.6878s	
15297/16650 (epoch 45.937), train_loss = 0.60575686, grad/param norm = 3.2902e-01, time/batch = 16.6877s	
15298/16650 (epoch 45.940), train_loss = 0.68498326, grad/param norm = 3.0152e-01, time/batch = 15.2569s	
15299/16650 (epoch 45.943), train_loss = 0.70511307, grad/param norm = 3.8292e-01, time/batch = 14.4800s	
15300/16650 (epoch 45.946), train_loss = 0.64122618, grad/param norm = 3.4041e-01, time/batch = 16.4984s	
15301/16650 (epoch 45.949), train_loss = 0.58956843, grad/param norm = 3.8615e-01, time/batch = 17.4179s	
15302/16650 (epoch 45.952), train_loss = 0.57858805, grad/param norm = 2.8397e-01, time/batch = 18.0449s	
15303/16650 (epoch 45.955), train_loss = 0.66259178, grad/param norm = 3.2090e-01, time/batch = 16.4613s	
15304/16650 (epoch 45.958), train_loss = 0.69390918, grad/param norm = 3.6690e-01, time/batch = 15.8381s	
15305/16650 (epoch 45.961), train_loss = 0.65176259, grad/param norm = 2.6746e-01, time/batch = 18.0438s	
15306/16650 (epoch 45.964), train_loss = 0.56938772, grad/param norm = 3.4037e-01, time/batch = 18.1255s	
15307/16650 (epoch 45.967), train_loss = 0.78768825, grad/param norm = 3.6340e-01, time/batch = 16.0190s	
15308/16650 (epoch 45.970), train_loss = 0.63060089, grad/param norm = 2.8678e-01, time/batch = 17.6053s	
15309/16650 (epoch 45.973), train_loss = 0.62457280, grad/param norm = 3.2311e-01, time/batch = 16.6159s	
15310/16650 (epoch 45.976), train_loss = 0.60992620, grad/param norm = 3.2756e-01, time/batch = 15.0838s	
15311/16650 (epoch 45.979), train_loss = 0.67358489, grad/param norm = 2.7913e-01, time/batch = 15.1500s	
15312/16650 (epoch 45.982), train_loss = 0.70209345, grad/param norm = 3.0264e-01, time/batch = 17.2004s	
15313/16650 (epoch 45.985), train_loss = 0.68775967, grad/param norm = 2.9747e-01, time/batch = 17.2837s	
15314/16650 (epoch 45.988), train_loss = 0.70028374, grad/param norm = 3.9411e-01, time/batch = 17.2744s	
15315/16650 (epoch 45.991), train_loss = 0.59138204, grad/param norm = 3.8993e-01, time/batch = 16.0257s	
15316/16650 (epoch 45.994), train_loss = 0.61864859, grad/param norm = 2.9718e-01, time/batch = 17.5375s	
15317/16650 (epoch 45.997), train_loss = 0.61181460, grad/param norm = 3.3857e-01, time/batch = 14.8547s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
15318/16650 (epoch 46.000), train_loss = 0.71514798, grad/param norm = 3.1196e-01, time/batch = 16.3590s	
15319/16650 (epoch 46.003), train_loss = 0.76753738, grad/param norm = 3.4963e-01, time/batch = 15.7414s	
15320/16650 (epoch 46.006), train_loss = 0.78463686, grad/param norm = 3.4191e-01, time/batch = 15.4188s	
15321/16650 (epoch 46.009), train_loss = 0.78429058, grad/param norm = 3.7708e-01, time/batch = 18.3812s	
15322/16650 (epoch 46.012), train_loss = 0.74512346, grad/param norm = 3.1523e-01, time/batch = 15.8370s	
15323/16650 (epoch 46.015), train_loss = 0.66153889, grad/param norm = 3.0135e-01, time/batch = 17.5291s	
15324/16650 (epoch 46.018), train_loss = 0.58082953, grad/param norm = 2.8767e-01, time/batch = 17.5449s	
15325/16650 (epoch 46.021), train_loss = 0.79775908, grad/param norm = 3.8851e-01, time/batch = 16.0836s	
15326/16650 (epoch 46.024), train_loss = 0.67222390, grad/param norm = 3.3455e-01, time/batch = 14.4159s	
15327/16650 (epoch 46.027), train_loss = 0.70336940, grad/param norm = 3.1831e-01, time/batch = 16.2834s	
15328/16650 (epoch 46.030), train_loss = 0.57978440, grad/param norm = 3.2898e-01, time/batch = 16.8662s	
15329/16650 (epoch 46.033), train_loss = 0.64354020, grad/param norm = 2.7652e-01, time/batch = 16.6143s	
15330/16650 (epoch 46.036), train_loss = 0.45626078, grad/param norm = 3.0210e-01, time/batch = 15.4276s	
15331/16650 (epoch 46.039), train_loss = 0.75237494, grad/param norm = 2.9750e-01, time/batch = 17.1274s	
15332/16650 (epoch 46.042), train_loss = 0.70079894, grad/param norm = 3.5624e-01, time/batch = 17.6298s	
15333/16650 (epoch 46.045), train_loss = 0.68991930, grad/param norm = 2.9712e-01, time/batch = 16.6666s	
15334/16650 (epoch 46.048), train_loss = 0.76305981, grad/param norm = 3.3638e-01, time/batch = 17.3728s	
15335/16650 (epoch 46.051), train_loss = 0.66738071, grad/param norm = 3.2947e-01, time/batch = 16.1114s	
15336/16650 (epoch 46.054), train_loss = 0.66548451, grad/param norm = 3.1209e-01, time/batch = 14.9704s	
15337/16650 (epoch 46.057), train_loss = 0.67600238, grad/param norm = 3.9893e-01, time/batch = 15.3024s	
15338/16650 (epoch 46.060), train_loss = 0.56595362, grad/param norm = 2.7790e-01, time/batch = 17.6316s	
15339/16650 (epoch 46.063), train_loss = 0.65472398, grad/param norm = 2.9778e-01, time/batch = 17.4456s	
15340/16650 (epoch 46.066), train_loss = 0.79342595, grad/param norm = 3.1400e-01, time/batch = 15.8618s	
15341/16650 (epoch 46.069), train_loss = 0.71561632, grad/param norm = 3.4701e-01, time/batch = 17.6438s	
15342/16650 (epoch 46.072), train_loss = 0.68057319, grad/param norm = 3.1403e-01, time/batch = 17.5275s	
15343/16650 (epoch 46.075), train_loss = 0.74477640, grad/param norm = 3.1543e-01, time/batch = 16.9351s	
15344/16650 (epoch 46.078), train_loss = 0.73495186, grad/param norm = 3.4945e-01, time/batch = 16.6111s	
15345/16650 (epoch 46.081), train_loss = 0.70271685, grad/param norm = 3.6929e-01, time/batch = 15.9537s	
15346/16650 (epoch 46.084), train_loss = 0.69341892, grad/param norm = 3.1636e-01, time/batch = 17.4511s	
15347/16650 (epoch 46.087), train_loss = 0.69971209, grad/param norm = 3.0333e-01, time/batch = 16.1831s	
15348/16650 (epoch 46.090), train_loss = 0.65769120, grad/param norm = 3.1232e-01, time/batch = 16.9506s	
15349/16650 (epoch 46.093), train_loss = 0.78490074, grad/param norm = 4.0570e-01, time/batch = 17.7004s	
15350/16650 (epoch 46.096), train_loss = 0.62846349, grad/param norm = 3.0211e-01, time/batch = 17.0198s	
15351/16650 (epoch 46.099), train_loss = 0.70548278, grad/param norm = 3.6356e-01, time/batch = 28.2642s	
15352/16650 (epoch 46.102), train_loss = 0.67387157, grad/param norm = 3.1376e-01, time/batch = 17.0836s	
15353/16650 (epoch 46.105), train_loss = 0.68930460, grad/param norm = 3.7730e-01, time/batch = 15.6539s	
15354/16650 (epoch 46.108), train_loss = 0.71375482, grad/param norm = 3.3800e-01, time/batch = 16.1998s	
15355/16650 (epoch 46.111), train_loss = 0.77829736, grad/param norm = 3.5037e-01, time/batch = 16.5995s	
15356/16650 (epoch 46.114), train_loss = 0.67969415, grad/param norm = 3.6961e-01, time/batch = 17.6317s	
15357/16650 (epoch 46.117), train_loss = 0.81223541, grad/param norm = 3.4277e-01, time/batch = 15.7594s	
15358/16650 (epoch 46.120), train_loss = 0.69972763, grad/param norm = 3.0241e-01, time/batch = 17.1996s	
15359/16650 (epoch 46.123), train_loss = 0.65355203, grad/param norm = 3.4224e-01, time/batch = 17.6164s	
15360/16650 (epoch 46.126), train_loss = 0.72272727, grad/param norm = 3.1013e-01, time/batch = 16.8617s	
15361/16650 (epoch 46.129), train_loss = 0.74735785, grad/param norm = 3.7108e-01, time/batch = 16.5235s	
15362/16650 (epoch 46.132), train_loss = 0.66439411, grad/param norm = 2.9444e-01, time/batch = 16.4422s	
15363/16650 (epoch 46.135), train_loss = 0.79805544, grad/param norm = 3.1195e-01, time/batch = 17.1949s	
15364/16650 (epoch 46.138), train_loss = 0.76203670, grad/param norm = 3.2849e-01, time/batch = 15.8281s	
15365/16650 (epoch 46.141), train_loss = 0.72273818, grad/param norm = 4.2027e-01, time/batch = 16.1660s	
15366/16650 (epoch 46.144), train_loss = 0.72837632, grad/param norm = 3.7765e-01, time/batch = 17.7925s	
15367/16650 (epoch 46.147), train_loss = 0.80781949, grad/param norm = 3.6218e-01, time/batch = 17.4502s	
15368/16650 (epoch 46.150), train_loss = 0.86333803, grad/param norm = 3.3656e-01, time/batch = 15.9137s	
15369/16650 (epoch 46.153), train_loss = 0.68150975, grad/param norm = 2.9937e-01, time/batch = 17.4560s	
15370/16650 (epoch 46.156), train_loss = 0.67659848, grad/param norm = 2.9313e-01, time/batch = 17.5531s	
15371/16650 (epoch 46.159), train_loss = 0.72925150, grad/param norm = 3.4254e-01, time/batch = 15.3146s	
15372/16650 (epoch 46.162), train_loss = 0.80467979, grad/param norm = 3.3961e-01, time/batch = 16.9469s	
15373/16650 (epoch 46.165), train_loss = 0.78105125, grad/param norm = 3.1761e-01, time/batch = 14.5254s	
15374/16650 (epoch 46.168), train_loss = 0.59361417, grad/param norm = 2.6845e-01, time/batch = 17.3655s	
15375/16650 (epoch 46.171), train_loss = 0.73988421, grad/param norm = 3.2528e-01, time/batch = 15.7482s	
15376/16650 (epoch 46.174), train_loss = 0.56553373, grad/param norm = 2.8460e-01, time/batch = 17.8563s	
15377/16650 (epoch 46.177), train_loss = 0.68607519, grad/param norm = 3.3545e-01, time/batch = 16.7957s	
15378/16650 (epoch 46.180), train_loss = 0.79746558, grad/param norm = 3.4943e-01, time/batch = 16.4294s	
15379/16650 (epoch 46.183), train_loss = 0.90661162, grad/param norm = 3.6200e-01, time/batch = 17.2012s	
15380/16650 (epoch 46.186), train_loss = 0.71449979, grad/param norm = 2.9287e-01, time/batch = 17.0476s	
15381/16650 (epoch 46.189), train_loss = 0.64698027, grad/param norm = 2.7024e-01, time/batch = 16.8649s	
15382/16650 (epoch 46.192), train_loss = 0.68281129, grad/param norm = 2.8222e-01, time/batch = 16.0013s	
15383/16650 (epoch 46.195), train_loss = 0.62033751, grad/param norm = 2.9989e-01, time/batch = 15.1581s	
15384/16650 (epoch 46.198), train_loss = 0.60805656, grad/param norm = 2.4810e-01, time/batch = 17.8653s	
15385/16650 (epoch 46.201), train_loss = 0.60434634, grad/param norm = 2.8992e-01, time/batch = 16.6116s	
15386/16650 (epoch 46.204), train_loss = 0.68922211, grad/param norm = 2.6892e-01, time/batch = 16.8343s	
15387/16650 (epoch 46.207), train_loss = 0.72420749, grad/param norm = 3.7041e-01, time/batch = 17.8674s	
15388/16650 (epoch 46.210), train_loss = 0.68110691, grad/param norm = 3.6715e-01, time/batch = 17.4551s	
15389/16650 (epoch 46.213), train_loss = 0.74853067, grad/param norm = 3.3743e-01, time/batch = 15.5854s	
15390/16650 (epoch 46.216), train_loss = 0.60991959, grad/param norm = 3.0576e-01, time/batch = 15.4084s	
15391/16650 (epoch 46.219), train_loss = 0.67408684, grad/param norm = 3.2339e-01, time/batch = 17.4277s	
15392/16650 (epoch 46.222), train_loss = 0.70881429, grad/param norm = 2.6986e-01, time/batch = 17.3448s	
15393/16650 (epoch 46.225), train_loss = 0.71746187, grad/param norm = 3.7851e-01, time/batch = 17.0264s	
15394/16650 (epoch 46.228), train_loss = 0.65649975, grad/param norm = 3.1029e-01, time/batch = 15.5046s	
15395/16650 (epoch 46.231), train_loss = 0.62569471, grad/param norm = 3.1461e-01, time/batch = 17.9519s	
15396/16650 (epoch 46.234), train_loss = 0.81730362, grad/param norm = 3.5104e-01, time/batch = 16.1043s	
15397/16650 (epoch 46.237), train_loss = 0.73325980, grad/param norm = 3.7531e-01, time/batch = 15.7883s	
15398/16650 (epoch 46.240), train_loss = 0.71527900, grad/param norm = 2.7890e-01, time/batch = 18.6988s	
15399/16650 (epoch 46.243), train_loss = 0.66740553, grad/param norm = 2.9253e-01, time/batch = 17.1184s	
15400/16650 (epoch 46.246), train_loss = 0.78513259, grad/param norm = 3.4277e-01, time/batch = 16.7470s	
15401/16650 (epoch 46.249), train_loss = 0.57738798, grad/param norm = 2.5723e-01, time/batch = 18.8019s	
15402/16650 (epoch 46.252), train_loss = 0.66816413, grad/param norm = 3.5211e-01, time/batch = 17.2767s	
15403/16650 (epoch 46.255), train_loss = 0.71961571, grad/param norm = 2.9954e-01, time/batch = 16.3233s	
15404/16650 (epoch 46.258), train_loss = 0.75301149, grad/param norm = 2.9239e-01, time/batch = 18.6939s	
15405/16650 (epoch 46.261), train_loss = 0.71030517, grad/param norm = 2.9583e-01, time/batch = 17.0352s	
15406/16650 (epoch 46.264), train_loss = 0.65990764, grad/param norm = 3.2993e-01, time/batch = 15.9313s	
15407/16650 (epoch 46.267), train_loss = 0.66546244, grad/param norm = 3.5045e-01, time/batch = 16.1459s	
15408/16650 (epoch 46.270), train_loss = 0.73727536, grad/param norm = 3.1037e-01, time/batch = 17.0945s	
15409/16650 (epoch 46.273), train_loss = 0.76031157, grad/param norm = 3.4044e-01, time/batch = 17.9563s	
15410/16650 (epoch 46.276), train_loss = 0.73203099, grad/param norm = 3.0567e-01, time/batch = 15.6896s	
15411/16650 (epoch 46.279), train_loss = 0.66192985, grad/param norm = 3.2010e-01, time/batch = 17.2771s	
15412/16650 (epoch 46.282), train_loss = 0.63015852, grad/param norm = 2.6875e-01, time/batch = 17.4407s	
15413/16650 (epoch 46.285), train_loss = 0.66077907, grad/param norm = 2.7474e-01, time/batch = 15.9227s	
15414/16650 (epoch 46.288), train_loss = 0.59968272, grad/param norm = 3.2707e-01, time/batch = 15.4768s	
15415/16650 (epoch 46.291), train_loss = 0.50824969, grad/param norm = 2.6229e-01, time/batch = 17.8811s	
15416/16650 (epoch 46.294), train_loss = 0.61193236, grad/param norm = 2.6768e-01, time/batch = 15.8629s	
15417/16650 (epoch 46.297), train_loss = 0.68186277, grad/param norm = 2.9651e-01, time/batch = 16.2606s	
15418/16650 (epoch 46.300), train_loss = 0.54139130, grad/param norm = 2.8521e-01, time/batch = 17.4460s	
15419/16650 (epoch 46.303), train_loss = 0.58205278, grad/param norm = 2.6421e-01, time/batch = 16.3696s	
15420/16650 (epoch 46.306), train_loss = 0.73734820, grad/param norm = 2.5736e-01, time/batch = 16.6137s	
15421/16650 (epoch 46.309), train_loss = 0.70723983, grad/param norm = 2.5860e-01, time/batch = 15.6497s	
15422/16650 (epoch 46.312), train_loss = 0.56204810, grad/param norm = 3.2117e-01, time/batch = 15.7596s	
15423/16650 (epoch 46.315), train_loss = 0.48025395, grad/param norm = 2.1940e-01, time/batch = 17.9471s	
15424/16650 (epoch 46.318), train_loss = 0.55775568, grad/param norm = 3.1072e-01, time/batch = 16.7679s	
15425/16650 (epoch 46.321), train_loss = 0.73930264, grad/param norm = 3.1658e-01, time/batch = 16.3668s	
15426/16650 (epoch 46.324), train_loss = 0.60006028, grad/param norm = 2.9190e-01, time/batch = 14.1450s	
15427/16650 (epoch 46.327), train_loss = 0.68136204, grad/param norm = 3.3224e-01, time/batch = 17.5767s	
15428/16650 (epoch 46.330), train_loss = 0.68409444, grad/param norm = 4.0807e-01, time/batch = 15.9165s	
15429/16650 (epoch 46.333), train_loss = 0.71211716, grad/param norm = 3.2324e-01, time/batch = 16.1023s	
15430/16650 (epoch 46.336), train_loss = 0.60392996, grad/param norm = 3.1191e-01, time/batch = 17.3632s	
15431/16650 (epoch 46.339), train_loss = 0.59562319, grad/param norm = 3.0256e-01, time/batch = 18.0258s	
15432/16650 (epoch 46.342), train_loss = 0.57028915, grad/param norm = 3.2634e-01, time/batch = 16.3432s	
15433/16650 (epoch 46.345), train_loss = 0.61775388, grad/param norm = 2.7445e-01, time/batch = 15.5977s	
15434/16650 (epoch 46.348), train_loss = 0.70906945, grad/param norm = 3.4262e-01, time/batch = 16.9077s	
15435/16650 (epoch 46.351), train_loss = 0.69077554, grad/param norm = 3.2251e-01, time/batch = 17.0878s	
15436/16650 (epoch 46.354), train_loss = 0.72151596, grad/param norm = 2.9512e-01, time/batch = 16.9310s	
15437/16650 (epoch 46.357), train_loss = 0.70569004, grad/param norm = 3.0364e-01, time/batch = 14.8132s	
15438/16650 (epoch 46.360), train_loss = 0.67587871, grad/param norm = 3.3174e-01, time/batch = 17.9583s	
15439/16650 (epoch 46.363), train_loss = 0.74591198, grad/param norm = 3.6431e-01, time/batch = 19.3972s	
15440/16650 (epoch 46.366), train_loss = 0.80313972, grad/param norm = 3.2419e-01, time/batch = 17.9315s	
15441/16650 (epoch 46.369), train_loss = 0.73096095, grad/param norm = 3.3205e-01, time/batch = 17.0172s	
15442/16650 (epoch 46.372), train_loss = 0.67557916, grad/param norm = 2.8000e-01, time/batch = 19.1832s	
15443/16650 (epoch 46.375), train_loss = 0.71671998, grad/param norm = 2.9465e-01, time/batch = 20.8364s	
15444/16650 (epoch 46.378), train_loss = 0.64376572, grad/param norm = 3.0372e-01, time/batch = 21.3180s	
15445/16650 (epoch 46.381), train_loss = 0.74971300, grad/param norm = 3.4672e-01, time/batch = 18.8069s	
15446/16650 (epoch 46.384), train_loss = 0.79893196, grad/param norm = 3.2697e-01, time/batch = 17.9905s	
15447/16650 (epoch 46.387), train_loss = 0.54609637, grad/param norm = 2.6452e-01, time/batch = 22.3236s	
15448/16650 (epoch 46.390), train_loss = 0.73234161, grad/param norm = 2.8148e-01, time/batch = 20.0645s	
15449/16650 (epoch 46.393), train_loss = 0.66170105, grad/param norm = 3.4487e-01, time/batch = 22.7295s	
15450/16650 (epoch 46.396), train_loss = 0.79153911, grad/param norm = 3.9491e-01, time/batch = 21.3379s	
15451/16650 (epoch 46.399), train_loss = 0.73955142, grad/param norm = 2.9029e-01, time/batch = 19.0737s	
15452/16650 (epoch 46.402), train_loss = 0.67165873, grad/param norm = 3.0418e-01, time/batch = 23.0910s	
15453/16650 (epoch 46.405), train_loss = 0.53020470, grad/param norm = 3.0272e-01, time/batch = 22.3028s	
15454/16650 (epoch 46.408), train_loss = 0.71309252, grad/param norm = 2.9447e-01, time/batch = 18.5323s	
15455/16650 (epoch 46.411), train_loss = 0.62783149, grad/param norm = 3.3812e-01, time/batch = 22.7512s	
15456/16650 (epoch 46.414), train_loss = 0.61794973, grad/param norm = 4.6261e-01, time/batch = 20.5202s	
15457/16650 (epoch 46.417), train_loss = 0.57322780, grad/param norm = 2.9589e-01, time/batch = 20.6483s	
15458/16650 (epoch 46.420), train_loss = 0.63657070, grad/param norm = 3.1749e-01, time/batch = 28.0043s	
15459/16650 (epoch 46.423), train_loss = 0.50421819, grad/param norm = 2.8524e-01, time/batch = 15.6549s	
15460/16650 (epoch 46.426), train_loss = 0.57701998, grad/param norm = 3.0739e-01, time/batch = 17.5135s	
15461/16650 (epoch 46.429), train_loss = 0.75346214, grad/param norm = 3.6035e-01, time/batch = 18.8523s	
15462/16650 (epoch 46.432), train_loss = 0.71301438, grad/param norm = 2.8820e-01, time/batch = 17.3347s	
15463/16650 (epoch 46.435), train_loss = 0.81282093, grad/param norm = 3.7478e-01, time/batch = 16.5304s	
15464/16650 (epoch 46.438), train_loss = 0.82959753, grad/param norm = 3.8233e-01, time/batch = 17.7790s	
15465/16650 (epoch 46.441), train_loss = 0.63894974, grad/param norm = 3.3387e-01, time/batch = 17.5969s	
15466/16650 (epoch 46.444), train_loss = 0.62145171, grad/param norm = 2.9280e-01, time/batch = 16.5791s	
15467/16650 (epoch 46.447), train_loss = 0.61536173, grad/param norm = 2.9135e-01, time/batch = 17.7716s	
15468/16650 (epoch 46.450), train_loss = 0.62157045, grad/param norm = 3.2008e-01, time/batch = 16.5113s	
15469/16650 (epoch 46.453), train_loss = 0.60985686, grad/param norm = 2.8533e-01, time/batch = 14.0445s	
15470/16650 (epoch 46.456), train_loss = 0.58209199, grad/param norm = 2.5026e-01, time/batch = 14.6773s	
15471/16650 (epoch 46.459), train_loss = 0.60066278, grad/param norm = 2.9916e-01, time/batch = 14.3092s	
15472/16650 (epoch 46.462), train_loss = 0.74980279, grad/param norm = 3.1184e-01, time/batch = 16.5060s	
15473/16650 (epoch 46.465), train_loss = 0.61636813, grad/param norm = 3.1316e-01, time/batch = 17.4362s	
15474/16650 (epoch 46.468), train_loss = 0.51347248, grad/param norm = 2.7199e-01, time/batch = 17.1751s	
15475/16650 (epoch 46.471), train_loss = 0.43977918, grad/param norm = 2.2851e-01, time/batch = 18.5394s	
15476/16650 (epoch 46.474), train_loss = 0.58363851, grad/param norm = 2.8936e-01, time/batch = 17.8465s	
15477/16650 (epoch 46.477), train_loss = 0.69876215, grad/param norm = 2.8721e-01, time/batch = 15.5782s	
15478/16650 (epoch 46.480), train_loss = 0.63032801, grad/param norm = 3.6011e-01, time/batch = 15.8220s	
15479/16650 (epoch 46.483), train_loss = 0.71442215, grad/param norm = 3.5905e-01, time/batch = 18.5101s	
15480/16650 (epoch 46.486), train_loss = 0.56816201, grad/param norm = 2.5020e-01, time/batch = 16.9006s	
15481/16650 (epoch 46.489), train_loss = 0.65781642, grad/param norm = 3.0669e-01, time/batch = 17.3501s	
15482/16650 (epoch 46.492), train_loss = 0.66113703, grad/param norm = 2.5248e-01, time/batch = 18.2920s	
15483/16650 (epoch 46.495), train_loss = 0.55256409, grad/param norm = 3.0930e-01, time/batch = 18.5239s	
15484/16650 (epoch 46.498), train_loss = 0.62289808, grad/param norm = 3.7893e-01, time/batch = 16.2558s	
15485/16650 (epoch 46.502), train_loss = 0.76243854, grad/param norm = 3.4967e-01, time/batch = 17.2996s	
15486/16650 (epoch 46.505), train_loss = 0.69940267, grad/param norm = 3.0496e-01, time/batch = 18.6106s	
15487/16650 (epoch 46.508), train_loss = 0.73545760, grad/param norm = 4.1380e-01, time/batch = 16.8334s	
15488/16650 (epoch 46.511), train_loss = 0.70370550, grad/param norm = 2.9291e-01, time/batch = 15.9440s	
15489/16650 (epoch 46.514), train_loss = 0.57475272, grad/param norm = 2.8624e-01, time/batch = 18.1280s	
15490/16650 (epoch 46.517), train_loss = 0.63746954, grad/param norm = 3.5905e-01, time/batch = 17.5326s	
15491/16650 (epoch 46.520), train_loss = 0.56999475, grad/param norm = 3.0051e-01, time/batch = 15.8201s	
15492/16650 (epoch 46.523), train_loss = 0.65749855, grad/param norm = 2.8482e-01, time/batch = 16.7578s	
15493/16650 (epoch 46.526), train_loss = 0.73257118, grad/param norm = 3.4262e-01, time/batch = 16.7496s	
15494/16650 (epoch 46.529), train_loss = 0.73163349, grad/param norm = 4.1528e-01, time/batch = 17.1579s	
15495/16650 (epoch 46.532), train_loss = 0.48591986, grad/param norm = 2.9875e-01, time/batch = 17.6061s	
15496/16650 (epoch 46.535), train_loss = 0.59873849, grad/param norm = 3.2464e-01, time/batch = 14.9886s	
15497/16650 (epoch 46.538), train_loss = 0.53192151, grad/param norm = 3.4653e-01, time/batch = 18.4393s	
15498/16650 (epoch 46.541), train_loss = 0.77310297, grad/param norm = 3.6641e-01, time/batch = 17.0810s	
15499/16650 (epoch 46.544), train_loss = 0.83808893, grad/param norm = 4.7941e-01, time/batch = 16.9415s	
15500/16650 (epoch 46.547), train_loss = 0.56058297, grad/param norm = 2.9302e-01, time/batch = 17.1087s	
15501/16650 (epoch 46.550), train_loss = 0.67031685, grad/param norm = 2.8839e-01, time/batch = 17.5036s	
15502/16650 (epoch 46.553), train_loss = 0.65130272, grad/param norm = 3.1516e-01, time/batch = 16.3417s	
15503/16650 (epoch 46.556), train_loss = 0.58884419, grad/param norm = 2.7698e-01, time/batch = 17.9552s	
15504/16650 (epoch 46.559), train_loss = 0.53063489, grad/param norm = 3.0958e-01, time/batch = 18.8557s	
15505/16650 (epoch 46.562), train_loss = 0.58379622, grad/param norm = 2.8626e-01, time/batch = 15.6861s	
15506/16650 (epoch 46.565), train_loss = 0.50452620, grad/param norm = 2.5377e-01, time/batch = 18.4394s	
15507/16650 (epoch 46.568), train_loss = 0.53717463, grad/param norm = 3.1228e-01, time/batch = 17.4246s	
15508/16650 (epoch 46.571), train_loss = 0.58118755, grad/param norm = 3.0690e-01, time/batch = 16.5495s	
15509/16650 (epoch 46.574), train_loss = 0.56415327, grad/param norm = 3.5715e-01, time/batch = 15.4701s	
15510/16650 (epoch 46.577), train_loss = 0.63229557, grad/param norm = 3.2217e-01, time/batch = 16.1702s	
15511/16650 (epoch 46.580), train_loss = 0.58447705, grad/param norm = 2.7223e-01, time/batch = 14.6692s	
15512/16650 (epoch 46.583), train_loss = 0.67459973, grad/param norm = 3.1069e-01, time/batch = 14.4717s	
15513/16650 (epoch 46.586), train_loss = 0.55981433, grad/param norm = 3.2579e-01, time/batch = 16.7663s	
15514/16650 (epoch 46.589), train_loss = 0.57252874, grad/param norm = 2.7540e-01, time/batch = 17.1951s	
15515/16650 (epoch 46.592), train_loss = 0.64337230, grad/param norm = 2.6888e-01, time/batch = 16.7769s	
15516/16650 (epoch 46.595), train_loss = 0.57980029, grad/param norm = 2.9430e-01, time/batch = 14.7443s	
15517/16650 (epoch 46.598), train_loss = 0.61714286, grad/param norm = 3.1599e-01, time/batch = 16.8603s	
15518/16650 (epoch 46.601), train_loss = 0.57056694, grad/param norm = 3.0312e-01, time/batch = 15.2929s	
15519/16650 (epoch 46.604), train_loss = 0.62807414, grad/param norm = 3.1162e-01, time/batch = 15.7452s	
15520/16650 (epoch 46.607), train_loss = 0.69062083, grad/param norm = 3.1779e-01, time/batch = 15.7518s	
15521/16650 (epoch 46.610), train_loss = 0.59460592, grad/param norm = 2.7024e-01, time/batch = 14.5846s	
15522/16650 (epoch 46.613), train_loss = 0.72237109, grad/param norm = 3.0803e-01, time/batch = 15.9067s	
15523/16650 (epoch 46.616), train_loss = 0.68995933, grad/param norm = 3.6794e-01, time/batch = 15.3274s	
15524/16650 (epoch 46.619), train_loss = 0.54516001, grad/param norm = 3.2644e-01, time/batch = 1.6730s	
15525/16650 (epoch 46.622), train_loss = 0.52878367, grad/param norm = 2.5421e-01, time/batch = 0.6290s	
15526/16650 (epoch 46.625), train_loss = 0.64094399, grad/param norm = 2.9738e-01, time/batch = 0.6402s	
15527/16650 (epoch 46.628), train_loss = 0.58370312, grad/param norm = 3.6736e-01, time/batch = 0.6299s	
15528/16650 (epoch 46.631), train_loss = 0.65891459, grad/param norm = 3.0353e-01, time/batch = 0.6567s	
15529/16650 (epoch 46.634), train_loss = 0.80047555, grad/param norm = 3.5264e-01, time/batch = 0.6412s	
15530/16650 (epoch 46.637), train_loss = 0.77442112, grad/param norm = 2.9628e-01, time/batch = 0.6196s	
15531/16650 (epoch 46.640), train_loss = 0.64227463, grad/param norm = 3.1099e-01, time/batch = 0.6558s	
15532/16650 (epoch 46.643), train_loss = 0.71884056, grad/param norm = 3.6016e-01, time/batch = 0.9461s	
15533/16650 (epoch 46.646), train_loss = 0.68413411, grad/param norm = 3.4263e-01, time/batch = 0.9508s	
15534/16650 (epoch 46.649), train_loss = 0.68569268, grad/param norm = 3.4783e-01, time/batch = 0.9462s	
15535/16650 (epoch 46.652), train_loss = 0.69480959, grad/param norm = 3.4218e-01, time/batch = 0.9449s	
15536/16650 (epoch 46.655), train_loss = 0.64162177, grad/param norm = 3.1353e-01, time/batch = 0.9464s	
15537/16650 (epoch 46.658), train_loss = 0.59628800, grad/param norm = 2.7765e-01, time/batch = 1.5997s	
15538/16650 (epoch 46.661), train_loss = 0.66101364, grad/param norm = 3.6574e-01, time/batch = 1.7546s	
15539/16650 (epoch 46.664), train_loss = 0.64235139, grad/param norm = 3.4045e-01, time/batch = 1.7173s	
15540/16650 (epoch 46.667), train_loss = 0.74261071, grad/param norm = 3.0440e-01, time/batch = 16.1112s	
15541/16650 (epoch 46.670), train_loss = 0.56910331, grad/param norm = 3.1666e-01, time/batch = 16.3487s	
15542/16650 (epoch 46.673), train_loss = 0.57298586, grad/param norm = 3.2276e-01, time/batch = 16.1599s	
15543/16650 (epoch 46.676), train_loss = 0.70388963, grad/param norm = 3.0735e-01, time/batch = 17.6049s	
15544/16650 (epoch 46.679), train_loss = 0.57938052, grad/param norm = 2.8952e-01, time/batch = 16.7062s	
15545/16650 (epoch 46.682), train_loss = 0.63706045, grad/param norm = 3.3613e-01, time/batch = 16.8342s	
15546/16650 (epoch 46.685), train_loss = 0.53189582, grad/param norm = 2.9005e-01, time/batch = 15.3530s	
15547/16650 (epoch 46.688), train_loss = 0.70923855, grad/param norm = 3.0245e-01, time/batch = 17.0337s	
15548/16650 (epoch 46.691), train_loss = 0.66178140, grad/param norm = 3.3240e-01, time/batch = 17.1835s	
15549/16650 (epoch 46.694), train_loss = 0.59848244, grad/param norm = 3.7913e-01, time/batch = 15.6725s	
15550/16650 (epoch 46.697), train_loss = 0.57574119, grad/param norm = 2.7832e-01, time/batch = 16.2642s	
15551/16650 (epoch 46.700), train_loss = 0.68116333, grad/param norm = 3.2458e-01, time/batch = 15.8175s	
15552/16650 (epoch 46.703), train_loss = 0.56555033, grad/param norm = 2.6958e-01, time/batch = 16.7687s	
15553/16650 (epoch 46.706), train_loss = 0.63139821, grad/param norm = 3.3748e-01, time/batch = 15.5972s	
15554/16650 (epoch 46.709), train_loss = 0.55052913, grad/param norm = 3.1410e-01, time/batch = 15.6838s	
15555/16650 (epoch 46.712), train_loss = 0.58247013, grad/param norm = 3.2151e-01, time/batch = 17.0407s	
15556/16650 (epoch 46.715), train_loss = 0.66392473, grad/param norm = 3.3300e-01, time/batch = 16.2639s	
15557/16650 (epoch 46.718), train_loss = 0.73018991, grad/param norm = 3.9102e-01, time/batch = 15.3403s	
15558/16650 (epoch 46.721), train_loss = 0.71631491, grad/param norm = 2.9011e-01, time/batch = 15.2773s	
15559/16650 (epoch 46.724), train_loss = 0.70822167, grad/param norm = 3.4571e-01, time/batch = 16.7791s	
15560/16650 (epoch 46.727), train_loss = 0.71429964, grad/param norm = 3.1417e-01, time/batch = 15.2332s	
15561/16650 (epoch 46.730), train_loss = 0.59990546, grad/param norm = 3.1036e-01, time/batch = 15.6025s	
15562/16650 (epoch 46.733), train_loss = 0.73834340, grad/param norm = 3.3225e-01, time/batch = 14.4063s	
15563/16650 (epoch 46.736), train_loss = 0.54084422, grad/param norm = 3.0713e-01, time/batch = 16.3587s	
15564/16650 (epoch 46.739), train_loss = 0.65735136, grad/param norm = 3.2702e-01, time/batch = 15.1398s	
15565/16650 (epoch 46.742), train_loss = 0.65273942, grad/param norm = 2.7281e-01, time/batch = 16.0768s	
15566/16650 (epoch 46.745), train_loss = 0.51595191, grad/param norm = 2.9619e-01, time/batch = 17.5295s	
15567/16650 (epoch 46.748), train_loss = 0.54768547, grad/param norm = 3.4350e-01, time/batch = 17.9363s	
15568/16650 (epoch 46.751), train_loss = 0.66437239, grad/param norm = 5.0454e-01, time/batch = 17.0754s	
15569/16650 (epoch 46.754), train_loss = 0.80909222, grad/param norm = 4.0534e-01, time/batch = 16.7555s	
15570/16650 (epoch 46.757), train_loss = 0.80728510, grad/param norm = 3.5792e-01, time/batch = 17.5913s	
15571/16650 (epoch 46.760), train_loss = 0.65285975, grad/param norm = 3.2473e-01, time/batch = 15.8402s	
15572/16650 (epoch 46.763), train_loss = 0.63313814, grad/param norm = 3.0407e-01, time/batch = 18.8713s	
15573/16650 (epoch 46.766), train_loss = 0.62490077, grad/param norm = 2.6748e-01, time/batch = 15.8317s	
15574/16650 (epoch 46.769), train_loss = 0.68372423, grad/param norm = 3.5065e-01, time/batch = 16.6589s	
15575/16650 (epoch 46.772), train_loss = 0.66635123, grad/param norm = 3.2249e-01, time/batch = 23.0514s	
15576/16650 (epoch 46.775), train_loss = 0.65666724, grad/param norm = 3.0223e-01, time/batch = 27.3280s	
15577/16650 (epoch 46.778), train_loss = 0.67864136, grad/param norm = 3.0045e-01, time/batch = 15.5832s	
15578/16650 (epoch 46.781), train_loss = 0.79575151, grad/param norm = 3.0552e-01, time/batch = 17.0870s	
15579/16650 (epoch 46.784), train_loss = 0.65939749, grad/param norm = 2.9222e-01, time/batch = 17.4430s	
15580/16650 (epoch 46.787), train_loss = 0.72893623, grad/param norm = 3.4893e-01, time/batch = 17.2846s	
15581/16650 (epoch 46.790), train_loss = 0.74263502, grad/param norm = 2.9962e-01, time/batch = 15.9992s	
15582/16650 (epoch 46.793), train_loss = 0.53783545, grad/param norm = 2.8404e-01, time/batch = 17.1111s	
15583/16650 (epoch 46.796), train_loss = 0.87815195, grad/param norm = 3.6682e-01, time/batch = 18.4411s	
15584/16650 (epoch 46.799), train_loss = 0.76056840, grad/param norm = 3.5263e-01, time/batch = 17.2549s	
15585/16650 (epoch 46.802), train_loss = 0.73571332, grad/param norm = 3.2158e-01, time/batch = 17.6796s	
15586/16650 (epoch 46.805), train_loss = 0.69282240, grad/param norm = 3.2973e-01, time/batch = 17.8659s	
15587/16650 (epoch 46.808), train_loss = 0.74240289, grad/param norm = 3.3110e-01, time/batch = 15.3739s	
15588/16650 (epoch 46.811), train_loss = 0.75191016, grad/param norm = 3.0849e-01, time/batch = 15.8962s	
15589/16650 (epoch 46.814), train_loss = 0.59934230, grad/param norm = 3.5597e-01, time/batch = 17.7848s	
15590/16650 (epoch 46.817), train_loss = 0.59276178, grad/param norm = 3.1016e-01, time/batch = 15.9997s	
15591/16650 (epoch 46.820), train_loss = 0.72937697, grad/param norm = 3.3466e-01, time/batch = 17.5023s	
15592/16650 (epoch 46.823), train_loss = 0.66257553, grad/param norm = 2.7862e-01, time/batch = 16.6930s	
15593/16650 (epoch 46.826), train_loss = 0.62367576, grad/param norm = 2.7920e-01, time/batch = 15.5881s	
15594/16650 (epoch 46.829), train_loss = 0.65497805, grad/param norm = 2.9801e-01, time/batch = 18.8653s	
15595/16650 (epoch 46.832), train_loss = 0.73405758, grad/param norm = 3.1472e-01, time/batch = 14.6358s	
15596/16650 (epoch 46.835), train_loss = 0.72878895, grad/param norm = 4.0771e-01, time/batch = 18.6790s	
15597/16650 (epoch 46.838), train_loss = 0.59304404, grad/param norm = 2.3665e-01, time/batch = 14.9616s	
15598/16650 (epoch 46.841), train_loss = 0.63585681, grad/param norm = 3.0272e-01, time/batch = 17.6058s	
15599/16650 (epoch 46.844), train_loss = 0.65462990, grad/param norm = 2.8747e-01, time/batch = 16.6660s	
15600/16650 (epoch 46.847), train_loss = 0.71664620, grad/param norm = 3.1853e-01, time/batch = 18.6762s	
15601/16650 (epoch 46.850), train_loss = 0.63016003, grad/param norm = 3.2088e-01, time/batch = 17.6744s	
15602/16650 (epoch 46.853), train_loss = 0.63610159, grad/param norm = 2.8470e-01, time/batch = 16.3217s	
15603/16650 (epoch 46.856), train_loss = 0.61686965, grad/param norm = 2.6599e-01, time/batch = 18.6186s	
15604/16650 (epoch 46.859), train_loss = 0.71646041, grad/param norm = 3.2689e-01, time/batch = 16.9334s	
15605/16650 (epoch 46.862), train_loss = 0.68908991, grad/param norm = 2.6667e-01, time/batch = 17.1687s	
15606/16650 (epoch 46.865), train_loss = 0.54983615, grad/param norm = 3.0831e-01, time/batch = 16.9226s	
15607/16650 (epoch 46.868), train_loss = 0.67216457, grad/param norm = 2.9210e-01, time/batch = 19.1985s	
15608/16650 (epoch 46.871), train_loss = 0.67027513, grad/param norm = 3.1359e-01, time/batch = 18.1187s	
15609/16650 (epoch 46.874), train_loss = 0.66618822, grad/param norm = 3.0093e-01, time/batch = 15.6585s	
15610/16650 (epoch 46.877), train_loss = 0.64391451, grad/param norm = 2.8318e-01, time/batch = 18.3548s	
15611/16650 (epoch 46.880), train_loss = 0.60461596, grad/param norm = 2.7342e-01, time/batch = 15.2108s	
15612/16650 (epoch 46.883), train_loss = 0.67466770, grad/param norm = 3.2243e-01, time/batch = 15.4138s	
15613/16650 (epoch 46.886), train_loss = 0.66635259, grad/param norm = 3.3235e-01, time/batch = 17.0220s	
15614/16650 (epoch 46.889), train_loss = 0.54709241, grad/param norm = 3.1811e-01, time/batch = 18.1946s	
15615/16650 (epoch 46.892), train_loss = 0.67116903, grad/param norm = 2.7128e-01, time/batch = 17.8662s	
15616/16650 (epoch 46.895), train_loss = 0.69778458, grad/param norm = 3.1489e-01, time/batch = 16.2430s	
15617/16650 (epoch 46.898), train_loss = 0.66747830, grad/param norm = 3.0591e-01, time/batch = 15.6702s	
15618/16650 (epoch 46.901), train_loss = 0.60678504, grad/param norm = 2.8148e-01, time/batch = 18.6762s	
15619/16650 (epoch 46.904), train_loss = 0.65139947, grad/param norm = 3.5060e-01, time/batch = 16.5202s	
15620/16650 (epoch 46.907), train_loss = 0.67779333, grad/param norm = 3.8212e-01, time/batch = 16.3369s	
15621/16650 (epoch 46.910), train_loss = 0.69446923, grad/param norm = 3.1686e-01, time/batch = 17.8640s	
15622/16650 (epoch 46.913), train_loss = 0.62568092, grad/param norm = 2.9007e-01, time/batch = 17.2755s	
15623/16650 (epoch 46.916), train_loss = 0.59432835, grad/param norm = 3.3175e-01, time/batch = 15.6548s	
15624/16650 (epoch 46.919), train_loss = 0.77052719, grad/param norm = 3.2015e-01, time/batch = 18.4292s	
15625/16650 (epoch 46.922), train_loss = 0.65261623, grad/param norm = 3.0597e-01, time/batch = 17.7980s	
15626/16650 (epoch 46.925), train_loss = 0.62012120, grad/param norm = 3.4163e-01, time/batch = 16.6699s	
15627/16650 (epoch 46.928), train_loss = 0.65952863, grad/param norm = 2.9134e-01, time/batch = 18.1095s	
15628/16650 (epoch 46.931), train_loss = 0.67075793, grad/param norm = 2.9226e-01, time/batch = 17.1957s	
15629/16650 (epoch 46.934), train_loss = 0.52967979, grad/param norm = 2.7372e-01, time/batch = 17.6871s	
15630/16650 (epoch 46.937), train_loss = 0.59569768, grad/param norm = 3.4491e-01, time/batch = 14.8476s	
15631/16650 (epoch 46.940), train_loss = 0.67164470, grad/param norm = 2.8875e-01, time/batch = 16.8531s	
15632/16650 (epoch 46.943), train_loss = 0.70702962, grad/param norm = 3.5823e-01, time/batch = 18.9389s	
15633/16650 (epoch 46.946), train_loss = 0.63197702, grad/param norm = 3.0971e-01, time/batch = 17.2568s	
15634/16650 (epoch 46.949), train_loss = 0.57469899, grad/param norm = 3.4634e-01, time/batch = 15.1399s	
15635/16650 (epoch 46.952), train_loss = 0.55859928, grad/param norm = 2.8736e-01, time/batch = 15.2976s	
15636/16650 (epoch 46.955), train_loss = 0.65459040, grad/param norm = 2.8221e-01, time/batch = 17.5342s	
15637/16650 (epoch 46.958), train_loss = 0.70806443, grad/param norm = 3.6115e-01, time/batch = 15.5257s	
15638/16650 (epoch 46.961), train_loss = 0.64198264, grad/param norm = 2.7071e-01, time/batch = 18.6983s	
15639/16650 (epoch 46.964), train_loss = 0.56035910, grad/param norm = 3.2556e-01, time/batch = 18.0935s	
15640/16650 (epoch 46.967), train_loss = 0.76447133, grad/param norm = 3.4057e-01, time/batch = 16.9809s	
15641/16650 (epoch 46.970), train_loss = 0.61109860, grad/param norm = 2.7570e-01, time/batch = 17.2895s	
15642/16650 (epoch 46.973), train_loss = 0.60391545, grad/param norm = 3.4148e-01, time/batch = 18.4474s	
15643/16650 (epoch 46.976), train_loss = 0.59224108, grad/param norm = 2.8035e-01, time/batch = 17.8676s	
15644/16650 (epoch 46.979), train_loss = 0.65401445, grad/param norm = 2.6904e-01, time/batch = 16.0446s	
15645/16650 (epoch 46.982), train_loss = 0.69039598, grad/param norm = 2.8335e-01, time/batch = 16.2344s	
15646/16650 (epoch 46.985), train_loss = 0.66541590, grad/param norm = 2.7273e-01, time/batch = 17.1723s	
15647/16650 (epoch 46.988), train_loss = 0.66975352, grad/param norm = 3.1362e-01, time/batch = 15.9310s	
15648/16650 (epoch 46.991), train_loss = 0.58797780, grad/param norm = 3.3798e-01, time/batch = 16.9271s	
15649/16650 (epoch 46.994), train_loss = 0.60226201, grad/param norm = 2.5925e-01, time/batch = 19.4559s	
15650/16650 (epoch 46.997), train_loss = 0.61419285, grad/param norm = 3.2930e-01, time/batch = 18.7745s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
15651/16650 (epoch 47.000), train_loss = 0.70805316, grad/param norm = 3.1566e-01, time/batch = 17.8332s	
15652/16650 (epoch 47.003), train_loss = 0.75867100, grad/param norm = 3.3516e-01, time/batch = 18.1106s	
15653/16650 (epoch 47.006), train_loss = 0.77818204, grad/param norm = 4.2151e-01, time/batch = 17.7635s	
15654/16650 (epoch 47.009), train_loss = 0.73842790, grad/param norm = 3.0909e-01, time/batch = 15.6180s	
15655/16650 (epoch 47.012), train_loss = 0.74325500, grad/param norm = 3.2581e-01, time/batch = 19.0303s	
15656/16650 (epoch 47.015), train_loss = 0.65484305, grad/param norm = 2.7683e-01, time/batch = 16.1732s	
15657/16650 (epoch 47.018), train_loss = 0.59340219, grad/param norm = 3.2476e-01, time/batch = 16.9312s	
15658/16650 (epoch 47.021), train_loss = 0.77854546, grad/param norm = 3.6284e-01, time/batch = 16.4195s	
15659/16650 (epoch 47.024), train_loss = 0.66217210, grad/param norm = 3.7577e-01, time/batch = 17.6878s	
15660/16650 (epoch 47.027), train_loss = 0.68609226, grad/param norm = 3.1248e-01, time/batch = 19.2832s	
15661/16650 (epoch 47.030), train_loss = 0.56266872, grad/param norm = 3.0391e-01, time/batch = 16.6628s	
15662/16650 (epoch 47.033), train_loss = 0.63772763, grad/param norm = 2.8217e-01, time/batch = 16.9394s	
15663/16650 (epoch 47.036), train_loss = 0.44894567, grad/param norm = 3.3521e-01, time/batch = 19.1817s	
15664/16650 (epoch 47.039), train_loss = 0.73345673, grad/param norm = 2.7273e-01, time/batch = 16.7679s	
15665/16650 (epoch 47.042), train_loss = 0.69224590, grad/param norm = 3.7697e-01, time/batch = 18.2016s	
15666/16650 (epoch 47.045), train_loss = 0.69886133, grad/param norm = 3.2946e-01, time/batch = 18.5885s	
15667/16650 (epoch 47.048), train_loss = 0.74079728, grad/param norm = 3.0584e-01, time/batch = 16.1771s	
15668/16650 (epoch 47.051), train_loss = 0.64833471, grad/param norm = 2.9570e-01, time/batch = 16.9046s	
15669/16650 (epoch 47.054), train_loss = 0.66735800, grad/param norm = 2.9072e-01, time/batch = 18.0165s	
15670/16650 (epoch 47.057), train_loss = 0.65527870, grad/param norm = 3.6319e-01, time/batch = 16.5878s	
15671/16650 (epoch 47.060), train_loss = 0.55058291, grad/param norm = 2.8423e-01, time/batch = 16.9213s	
15672/16650 (epoch 47.063), train_loss = 0.63289329, grad/param norm = 3.1159e-01, time/batch = 15.7878s	
15673/16650 (epoch 47.066), train_loss = 0.78323528, grad/param norm = 3.2503e-01, time/batch = 16.6031s	
15674/16650 (epoch 47.069), train_loss = 0.70749097, grad/param norm = 3.6976e-01, time/batch = 18.6118s	
15675/16650 (epoch 47.072), train_loss = 0.68128673, grad/param norm = 3.8382e-01, time/batch = 17.0725s	
15676/16650 (epoch 47.075), train_loss = 0.73376653, grad/param norm = 3.7209e-01, time/batch = 18.2013s	
15677/16650 (epoch 47.078), train_loss = 0.75985460, grad/param norm = 4.5613e-01, time/batch = 18.7919s	
15678/16650 (epoch 47.081), train_loss = 0.69608670, grad/param norm = 4.2484e-01, time/batch = 15.6710s	
15679/16650 (epoch 47.084), train_loss = 0.68078890, grad/param norm = 3.5489e-01, time/batch = 15.8907s	
15680/16650 (epoch 47.087), train_loss = 0.69379267, grad/param norm = 3.3129e-01, time/batch = 17.0929s	
15681/16650 (epoch 47.090), train_loss = 0.63601211, grad/param norm = 3.6149e-01, time/batch = 16.6674s	
15682/16650 (epoch 47.093), train_loss = 0.76532943, grad/param norm = 3.8819e-01, time/batch = 15.1369s	
15683/16650 (epoch 47.096), train_loss = 0.63551136, grad/param norm = 3.3021e-01, time/batch = 17.3603s	
15684/16650 (epoch 47.099), train_loss = 0.68480740, grad/param norm = 3.6909e-01, time/batch = 17.3017s	
15685/16650 (epoch 47.102), train_loss = 0.66568837, grad/param norm = 3.3658e-01, time/batch = 16.4288s	
15686/16650 (epoch 47.105), train_loss = 0.68718823, grad/param norm = 3.5251e-01, time/batch = 18.1860s	
15687/16650 (epoch 47.108), train_loss = 0.69699591, grad/param norm = 3.2696e-01, time/batch = 15.7193s	
15688/16650 (epoch 47.111), train_loss = 0.76156586, grad/param norm = 3.1419e-01, time/batch = 15.2480s	
15689/16650 (epoch 47.114), train_loss = 0.68350649, grad/param norm = 4.7834e-01, time/batch = 16.6698s	
15690/16650 (epoch 47.117), train_loss = 0.79440718, grad/param norm = 3.4696e-01, time/batch = 14.6429s	
15691/16650 (epoch 47.120), train_loss = 0.67750002, grad/param norm = 2.8382e-01, time/batch = 17.1024s	
15692/16650 (epoch 47.123), train_loss = 0.63759768, grad/param norm = 2.8689e-01, time/batch = 16.0276s	
15693/16650 (epoch 47.126), train_loss = 0.71291402, grad/param norm = 3.0641e-01, time/batch = 16.2901s	
15694/16650 (epoch 47.129), train_loss = 0.71390368, grad/param norm = 3.5443e-01, time/batch = 19.0982s	
15695/16650 (epoch 47.132), train_loss = 0.64915735, grad/param norm = 2.9850e-01, time/batch = 14.7431s	
15696/16650 (epoch 47.135), train_loss = 0.76988093, grad/param norm = 2.7783e-01, time/batch = 15.9076s	
15697/16650 (epoch 47.138), train_loss = 0.74227656, grad/param norm = 3.0489e-01, time/batch = 16.4254s	
15698/16650 (epoch 47.141), train_loss = 0.70817330, grad/param norm = 3.7358e-01, time/batch = 17.1483s	
15699/16650 (epoch 47.144), train_loss = 0.72261235, grad/param norm = 3.6408e-01, time/batch = 18.8654s	
15700/16650 (epoch 47.147), train_loss = 0.81821604, grad/param norm = 3.5135e-01, time/batch = 16.4290s	
15701/16650 (epoch 47.150), train_loss = 0.85150978, grad/param norm = 5.3800e-01, time/batch = 18.6916s	
15702/16650 (epoch 47.153), train_loss = 0.69896243, grad/param norm = 3.7279e-01, time/batch = 17.1154s	
15703/16650 (epoch 47.156), train_loss = 0.70259838, grad/param norm = 2.8680e-01, time/batch = 16.3502s	
15704/16650 (epoch 47.159), train_loss = 0.72787862, grad/param norm = 3.7140e-01, time/batch = 16.7639s	
15705/16650 (epoch 47.162), train_loss = 0.80141054, grad/param norm = 3.2712e-01, time/batch = 15.9011s	
15706/16650 (epoch 47.165), train_loss = 0.79082532, grad/param norm = 3.4673e-01, time/batch = 14.6479s	
15707/16650 (epoch 47.168), train_loss = 0.58850701, grad/param norm = 2.6439e-01, time/batch = 15.9048s	
15708/16650 (epoch 47.171), train_loss = 0.73578976, grad/param norm = 3.3874e-01, time/batch = 17.9181s	
15709/16650 (epoch 47.174), train_loss = 0.56761123, grad/param norm = 3.0218e-01, time/batch = 17.8448s	
15710/16650 (epoch 47.177), train_loss = 0.68002500, grad/param norm = 3.1740e-01, time/batch = 16.2485s	
15711/16650 (epoch 47.180), train_loss = 0.78653588, grad/param norm = 3.3229e-01, time/batch = 17.2619s	
15712/16650 (epoch 47.183), train_loss = 0.89247552, grad/param norm = 3.9680e-01, time/batch = 16.5116s	
15713/16650 (epoch 47.186), train_loss = 0.72272078, grad/param norm = 3.5861e-01, time/batch = 18.5183s	
15714/16650 (epoch 47.189), train_loss = 0.64922985, grad/param norm = 2.7040e-01, time/batch = 14.8522s	
15715/16650 (epoch 47.192), train_loss = 0.66299128, grad/param norm = 3.0661e-01, time/batch = 17.3276s	
15716/16650 (epoch 47.195), train_loss = 0.60918646, grad/param norm = 2.9938e-01, time/batch = 16.6107s	
15717/16650 (epoch 47.198), train_loss = 0.60962963, grad/param norm = 2.9863e-01, time/batch = 17.0129s	
15718/16650 (epoch 47.201), train_loss = 0.59862959, grad/param norm = 3.0097e-01, time/batch = 15.4831s	
15719/16650 (epoch 47.204), train_loss = 0.68370773, grad/param norm = 3.0057e-01, time/batch = 18.2739s	
15720/16650 (epoch 47.207), train_loss = 0.70753296, grad/param norm = 3.5527e-01, time/batch = 16.7756s	
15721/16650 (epoch 47.210), train_loss = 0.67698003, grad/param norm = 3.5195e-01, time/batch = 17.8311s	
15722/16650 (epoch 47.213), train_loss = 0.73525354, grad/param norm = 3.2970e-01, time/batch = 17.4395s	
15723/16650 (epoch 47.216), train_loss = 0.58489881, grad/param norm = 2.6028e-01, time/batch = 17.3911s	
15724/16650 (epoch 47.219), train_loss = 0.65639667, grad/param norm = 3.1565e-01, time/batch = 15.3092s	
15725/16650 (epoch 47.222), train_loss = 0.70403964, grad/param norm = 2.7637e-01, time/batch = 17.0404s	
15726/16650 (epoch 47.225), train_loss = 0.72808133, grad/param norm = 4.1227e-01, time/batch = 16.1233s	
15727/16650 (epoch 47.228), train_loss = 0.64665067, grad/param norm = 3.4725e-01, time/batch = 18.1075s	
15728/16650 (epoch 47.231), train_loss = 0.63605148, grad/param norm = 4.0637e-01, time/batch = 17.9268s	
15729/16650 (epoch 47.234), train_loss = 0.81901025, grad/param norm = 3.7400e-01, time/batch = 17.5969s	
15730/16650 (epoch 47.237), train_loss = 0.70489034, grad/param norm = 3.0788e-01, time/batch = 18.1095s	
15731/16650 (epoch 47.240), train_loss = 0.72093688, grad/param norm = 3.1819e-01, time/batch = 17.2652s	
15732/16650 (epoch 47.243), train_loss = 0.66983048, grad/param norm = 3.1146e-01, time/batch = 15.4772s	
15733/16650 (epoch 47.246), train_loss = 0.78475521, grad/param norm = 4.6023e-01, time/batch = 18.9563s	
15734/16650 (epoch 47.249), train_loss = 0.58231735, grad/param norm = 2.5792e-01, time/batch = 18.2527s	
15735/16650 (epoch 47.252), train_loss = 0.66684946, grad/param norm = 3.3755e-01, time/batch = 16.5669s	
15736/16650 (epoch 47.255), train_loss = 0.71522824, grad/param norm = 2.8134e-01, time/batch = 16.6174s	
15737/16650 (epoch 47.258), train_loss = 0.75832646, grad/param norm = 3.2473e-01, time/batch = 16.9408s	
15738/16650 (epoch 47.261), train_loss = 0.69849876, grad/param norm = 2.9811e-01, time/batch = 17.6783s	
15739/16650 (epoch 47.264), train_loss = 0.63444724, grad/param norm = 3.2845e-01, time/batch = 16.4253s	
15740/16650 (epoch 47.267), train_loss = 0.65028472, grad/param norm = 3.1217e-01, time/batch = 18.2679s	
15741/16650 (epoch 47.270), train_loss = 0.72427710, grad/param norm = 3.4786e-01, time/batch = 18.1073s	
15742/16650 (epoch 47.273), train_loss = 0.74959334, grad/param norm = 3.3998e-01, time/batch = 15.4873s	
15743/16650 (epoch 47.276), train_loss = 0.73804854, grad/param norm = 3.5284e-01, time/batch = 17.5192s	
15744/16650 (epoch 47.279), train_loss = 0.65149732, grad/param norm = 2.8837e-01, time/batch = 15.4636s	
15745/16650 (epoch 47.282), train_loss = 0.63443516, grad/param norm = 2.7542e-01, time/batch = 16.9942s	
15746/16650 (epoch 47.285), train_loss = 0.65895008, grad/param norm = 2.9715e-01, time/batch = 16.8447s	
15747/16650 (epoch 47.288), train_loss = 0.57485841, grad/param norm = 2.7006e-01, time/batch = 18.0094s	
15748/16650 (epoch 47.291), train_loss = 0.49509801, grad/param norm = 2.3445e-01, time/batch = 17.0220s	
15749/16650 (epoch 47.294), train_loss = 0.60095765, grad/param norm = 2.9364e-01, time/batch = 16.9028s	
15750/16650 (epoch 47.297), train_loss = 0.68321245, grad/param norm = 2.9526e-01, time/batch = 18.8546s	
15751/16650 (epoch 47.300), train_loss = 0.52253360, grad/param norm = 2.5679e-01, time/batch = 17.8594s	
15752/16650 (epoch 47.303), train_loss = 0.57475685, grad/param norm = 2.7725e-01, time/batch = 16.8470s	
15753/16650 (epoch 47.306), train_loss = 0.73997204, grad/param norm = 2.7508e-01, time/batch = 15.0515s	
15754/16650 (epoch 47.309), train_loss = 0.71382262, grad/param norm = 3.1811e-01, time/batch = 16.3970s	
15755/16650 (epoch 47.312), train_loss = 0.55594769, grad/param norm = 3.0599e-01, time/batch = 14.7018s	
15756/16650 (epoch 47.315), train_loss = 0.47751247, grad/param norm = 2.3941e-01, time/batch = 16.0673s	
15757/16650 (epoch 47.318), train_loss = 0.53638723, grad/param norm = 2.7556e-01, time/batch = 14.3867s	
15758/16650 (epoch 47.321), train_loss = 0.71851605, grad/param norm = 3.1666e-01, time/batch = 17.8255s	
15759/16650 (epoch 47.324), train_loss = 0.60065040, grad/param norm = 2.8994e-01, time/batch = 17.4231s	
15760/16650 (epoch 47.327), train_loss = 0.67377353, grad/param norm = 3.0517e-01, time/batch = 16.3941s	
15761/16650 (epoch 47.330), train_loss = 0.68517753, grad/param norm = 3.7149e-01, time/batch = 17.1295s	
15762/16650 (epoch 47.333), train_loss = 0.69367904, grad/param norm = 3.3191e-01, time/batch = 18.1908s	
15763/16650 (epoch 47.336), train_loss = 0.58854835, grad/param norm = 3.1380e-01, time/batch = 17.1047s	
15764/16650 (epoch 47.339), train_loss = 0.59286169, grad/param norm = 3.2966e-01, time/batch = 18.2668s	
15765/16650 (epoch 47.342), train_loss = 0.55828611, grad/param norm = 3.3743e-01, time/batch = 18.4469s	
15766/16650 (epoch 47.345), train_loss = 0.61705963, grad/param norm = 2.9474e-01, time/batch = 16.9232s	
15767/16650 (epoch 47.348), train_loss = 0.68894662, grad/param norm = 3.0520e-01, time/batch = 18.0177s	
15768/16650 (epoch 47.351), train_loss = 0.67744347, grad/param norm = 3.7832e-01, time/batch = 18.6210s	
15769/16650 (epoch 47.354), train_loss = 0.72331880, grad/param norm = 3.2122e-01, time/batch = 18.4457s	
15770/16650 (epoch 47.357), train_loss = 0.70996748, grad/param norm = 3.4089e-01, time/batch = 14.9654s	
15771/16650 (epoch 47.360), train_loss = 0.68526622, grad/param norm = 3.6366e-01, time/batch = 17.5211s	
15772/16650 (epoch 47.363), train_loss = 0.73677911, grad/param norm = 3.7452e-01, time/batch = 16.6155s	
15773/16650 (epoch 47.366), train_loss = 0.81040801, grad/param norm = 3.8933e-01, time/batch = 17.9081s	
15774/16650 (epoch 47.369), train_loss = 0.72159148, grad/param norm = 3.1097e-01, time/batch = 17.3397s	
15775/16650 (epoch 47.372), train_loss = 0.67929112, grad/param norm = 3.0364e-01, time/batch = 16.4848s	
15776/16650 (epoch 47.375), train_loss = 0.67852839, grad/param norm = 2.6250e-01, time/batch = 18.7904s	
15777/16650 (epoch 47.378), train_loss = 0.61473893, grad/param norm = 2.9124e-01, time/batch = 18.0925s	
15778/16650 (epoch 47.381), train_loss = 0.72956668, grad/param norm = 3.1810e-01, time/batch = 17.1970s	
15779/16650 (epoch 47.384), train_loss = 0.78746919, grad/param norm = 3.3395e-01, time/batch = 16.9455s	
15780/16650 (epoch 47.387), train_loss = 0.55142687, grad/param norm = 3.4816e-01, time/batch = 16.9331s	
15781/16650 (epoch 47.390), train_loss = 0.73677883, grad/param norm = 3.0349e-01, time/batch = 18.0230s	
15782/16650 (epoch 47.393), train_loss = 0.66327703, grad/param norm = 3.2384e-01, time/batch = 18.4612s	
15783/16650 (epoch 47.396), train_loss = 0.78879004, grad/param norm = 4.1954e-01, time/batch = 19.7370s	
15784/16650 (epoch 47.399), train_loss = 0.73724961, grad/param norm = 3.5558e-01, time/batch = 29.0613s	
15785/16650 (epoch 47.402), train_loss = 0.64045197, grad/param norm = 2.7940e-01, time/batch = 16.3237s	
15786/16650 (epoch 47.405), train_loss = 0.52216838, grad/param norm = 2.6061e-01, time/batch = 15.1140s	
15787/16650 (epoch 47.408), train_loss = 0.70723529, grad/param norm = 2.7713e-01, time/batch = 15.3950s	
15788/16650 (epoch 47.411), train_loss = 0.61144034, grad/param norm = 2.9406e-01, time/batch = 14.7837s	
15789/16650 (epoch 47.414), train_loss = 0.61187082, grad/param norm = 3.7289e-01, time/batch = 19.1950s	
15790/16650 (epoch 47.417), train_loss = 0.59159181, grad/param norm = 3.5479e-01, time/batch = 16.4170s	
15791/16650 (epoch 47.420), train_loss = 0.60983193, grad/param norm = 2.9496e-01, time/batch = 18.2746s	
15792/16650 (epoch 47.423), train_loss = 0.49734040, grad/param norm = 2.5298e-01, time/batch = 17.1578s	
15793/16650 (epoch 47.426), train_loss = 0.57027793, grad/param norm = 3.1287e-01, time/batch = 17.0989s	
15794/16650 (epoch 47.429), train_loss = 0.73964269, grad/param norm = 3.8431e-01, time/batch = 19.0539s	
15795/16650 (epoch 47.432), train_loss = 0.72344569, grad/param norm = 3.6458e-01, time/batch = 14.4672s	
15796/16650 (epoch 47.435), train_loss = 0.80231978, grad/param norm = 3.4650e-01, time/batch = 15.9198s	
15797/16650 (epoch 47.438), train_loss = 0.83055596, grad/param norm = 4.2629e-01, time/batch = 17.2505s	
15798/16650 (epoch 47.441), train_loss = 0.63364046, grad/param norm = 3.2051e-01, time/batch = 17.5347s	
15799/16650 (epoch 47.444), train_loss = 0.62245438, grad/param norm = 3.2219e-01, time/batch = 19.3670s	
15800/16650 (epoch 47.447), train_loss = 0.62250859, grad/param norm = 3.1321e-01, time/batch = 16.8329s	
15801/16650 (epoch 47.450), train_loss = 0.61547321, grad/param norm = 3.1873e-01, time/batch = 17.9357s	
15802/16650 (epoch 47.453), train_loss = 0.61146729, grad/param norm = 2.8653e-01, time/batch = 17.8004s	
15803/16650 (epoch 47.456), train_loss = 0.57690365, grad/param norm = 2.6102e-01, time/batch = 17.9390s	
15804/16650 (epoch 47.459), train_loss = 0.60379678, grad/param norm = 3.2102e-01, time/batch = 17.0893s	
15805/16650 (epoch 47.462), train_loss = 0.75286319, grad/param norm = 3.6678e-01, time/batch = 14.7037s	
15806/16650 (epoch 47.465), train_loss = 0.61384627, grad/param norm = 3.2213e-01, time/batch = 18.6969s	
15807/16650 (epoch 47.468), train_loss = 0.49976275, grad/param norm = 2.9228e-01, time/batch = 16.8519s	
15808/16650 (epoch 47.471), train_loss = 0.44048107, grad/param norm = 2.7596e-01, time/batch = 14.9067s	
15809/16650 (epoch 47.474), train_loss = 0.58986294, grad/param norm = 3.2444e-01, time/batch = 14.6487s	
15810/16650 (epoch 47.477), train_loss = 0.69549947, grad/param norm = 3.7905e-01, time/batch = 14.4082s	
15811/16650 (epoch 47.480), train_loss = 0.62085699, grad/param norm = 3.7805e-01, time/batch = 15.2090s	
15812/16650 (epoch 47.483), train_loss = 0.69456639, grad/param norm = 3.1697e-01, time/batch = 14.2945s	
15813/16650 (epoch 47.486), train_loss = 0.57415087, grad/param norm = 2.8298e-01, time/batch = 14.6168s	
15814/16650 (epoch 47.489), train_loss = 0.66280752, grad/param norm = 3.2088e-01, time/batch = 14.0898s	
15815/16650 (epoch 47.492), train_loss = 0.66636538, grad/param norm = 2.8307e-01, time/batch = 15.0537s	
15816/16650 (epoch 47.495), train_loss = 0.55229902, grad/param norm = 3.0972e-01, time/batch = 17.3350s	
15817/16650 (epoch 47.498), train_loss = 0.60527748, grad/param norm = 3.8384e-01, time/batch = 17.6980s	
15818/16650 (epoch 47.502), train_loss = 0.79206839, grad/param norm = 4.1583e-01, time/batch = 17.9599s	
15819/16650 (epoch 47.505), train_loss = 0.67075571, grad/param norm = 2.7668e-01, time/batch = 16.9127s	
15820/16650 (epoch 47.508), train_loss = 0.72264502, grad/param norm = 4.0692e-01, time/batch = 17.6957s	
15821/16650 (epoch 47.511), train_loss = 0.70632827, grad/param norm = 3.4810e-01, time/batch = 18.0450s	
15822/16650 (epoch 47.514), train_loss = 0.57582740, grad/param norm = 3.1146e-01, time/batch = 16.3473s	
15823/16650 (epoch 47.517), train_loss = 0.61607806, grad/param norm = 3.4041e-01, time/batch = 17.9586s	
15824/16650 (epoch 47.520), train_loss = 0.53731047, grad/param norm = 2.7221e-01, time/batch = 17.4560s	
15825/16650 (epoch 47.523), train_loss = 0.64981686, grad/param norm = 3.1267e-01, time/batch = 17.7658s	
15826/16650 (epoch 47.526), train_loss = 0.71806957, grad/param norm = 3.5016e-01, time/batch = 17.5183s	
15827/16650 (epoch 47.529), train_loss = 0.72128836, grad/param norm = 3.4521e-01, time/batch = 18.3665s	
15828/16650 (epoch 47.532), train_loss = 0.50305341, grad/param norm = 3.0122e-01, time/batch = 15.9208s	
15829/16650 (epoch 47.535), train_loss = 0.57934221, grad/param norm = 3.1675e-01, time/batch = 16.8434s	
15830/16650 (epoch 47.538), train_loss = 0.52565928, grad/param norm = 3.2995e-01, time/batch = 16.9367s	
15831/16650 (epoch 47.541), train_loss = 0.76258459, grad/param norm = 3.4381e-01, time/batch = 15.7437s	
15832/16650 (epoch 47.544), train_loss = 0.77993266, grad/param norm = 4.1434e-01, time/batch = 16.4195s	
15833/16650 (epoch 47.547), train_loss = 0.55349646, grad/param norm = 2.8880e-01, time/batch = 17.0908s	
15834/16650 (epoch 47.550), train_loss = 0.65555997, grad/param norm = 2.9026e-01, time/batch = 17.3534s	
15835/16650 (epoch 47.553), train_loss = 0.65422601, grad/param norm = 3.4763e-01, time/batch = 18.7759s	
15836/16650 (epoch 47.556), train_loss = 0.59314893, grad/param norm = 3.2929e-01, time/batch = 16.5735s	
15837/16650 (epoch 47.559), train_loss = 0.52061642, grad/param norm = 3.5087e-01, time/batch = 19.2105s	
15838/16650 (epoch 47.562), train_loss = 0.57692414, grad/param norm = 2.8559e-01, time/batch = 16.4222s	
15839/16650 (epoch 47.565), train_loss = 0.49872497, grad/param norm = 2.9473e-01, time/batch = 17.5874s	
15840/16650 (epoch 47.568), train_loss = 0.53266854, grad/param norm = 3.3485e-01, time/batch = 18.2100s	
15841/16650 (epoch 47.571), train_loss = 0.57284960, grad/param norm = 3.3901e-01, time/batch = 16.3589s	
15842/16650 (epoch 47.574), train_loss = 0.56232626, grad/param norm = 3.4611e-01, time/batch = 18.8528s	
15843/16650 (epoch 47.577), train_loss = 0.61137936, grad/param norm = 2.8037e-01, time/batch = 15.8275s	
15844/16650 (epoch 47.580), train_loss = 0.57764878, grad/param norm = 2.6278e-01, time/batch = 19.6284s	
15845/16650 (epoch 47.583), train_loss = 0.67964288, grad/param norm = 3.1292e-01, time/batch = 17.5352s	
15846/16650 (epoch 47.586), train_loss = 0.56179277, grad/param norm = 4.0976e-01, time/batch = 15.9666s	
15847/16650 (epoch 47.589), train_loss = 0.55232004, grad/param norm = 2.7307e-01, time/batch = 17.9274s	
15848/16650 (epoch 47.592), train_loss = 0.63325760, grad/param norm = 2.8386e-01, time/batch = 16.5788s	
15849/16650 (epoch 47.595), train_loss = 0.59916221, grad/param norm = 3.3319e-01, time/batch = 17.2535s	
15850/16650 (epoch 47.598), train_loss = 0.62375625, grad/param norm = 3.2610e-01, time/batch = 17.3305s	
15851/16650 (epoch 47.601), train_loss = 0.56144991, grad/param norm = 3.1670e-01, time/batch = 17.2713s	
15852/16650 (epoch 47.604), train_loss = 0.61774149, grad/param norm = 3.4311e-01, time/batch = 17.0060s	
15853/16650 (epoch 47.607), train_loss = 0.67993625, grad/param norm = 3.4085e-01, time/batch = 16.5107s	
15854/16650 (epoch 47.610), train_loss = 0.58389135, grad/param norm = 2.7024e-01, time/batch = 18.2861s	
15855/16650 (epoch 47.613), train_loss = 0.71883490, grad/param norm = 3.0580e-01, time/batch = 16.7374s	
15856/16650 (epoch 47.616), train_loss = 0.67537649, grad/param norm = 3.8792e-01, time/batch = 18.0074s	
15857/16650 (epoch 47.619), train_loss = 0.55305783, grad/param norm = 3.0810e-01, time/batch = 17.2502s	
15858/16650 (epoch 47.622), train_loss = 0.51881111, grad/param norm = 2.7364e-01, time/batch = 17.9478s	
15859/16650 (epoch 47.625), train_loss = 0.62140898, grad/param norm = 2.7457e-01, time/batch = 18.3621s	
15860/16650 (epoch 47.628), train_loss = 0.58845322, grad/param norm = 4.1108e-01, time/batch = 16.0896s	
15861/16650 (epoch 47.631), train_loss = 0.64891557, grad/param norm = 3.7338e-01, time/batch = 18.5355s	
15862/16650 (epoch 47.634), train_loss = 0.79723475, grad/param norm = 3.6716e-01, time/batch = 16.4499s	
15863/16650 (epoch 47.637), train_loss = 0.76572495, grad/param norm = 3.1977e-01, time/batch = 17.2503s	
15864/16650 (epoch 47.640), train_loss = 0.63046946, grad/param norm = 3.0848e-01, time/batch = 18.0009s	
15865/16650 (epoch 47.643), train_loss = 0.69957678, grad/param norm = 3.1102e-01, time/batch = 18.0342s	
15866/16650 (epoch 47.646), train_loss = 0.66583227, grad/param norm = 3.3738e-01, time/batch = 17.0969s	
15867/16650 (epoch 47.649), train_loss = 0.65567974, grad/param norm = 2.9410e-01, time/batch = 16.4073s	
15868/16650 (epoch 47.652), train_loss = 0.69057583, grad/param norm = 3.4855e-01, time/batch = 19.1171s	
15869/16650 (epoch 47.655), train_loss = 0.62733404, grad/param norm = 2.9011e-01, time/batch = 18.8717s	
15870/16650 (epoch 47.658), train_loss = 0.58873041, grad/param norm = 3.1632e-01, time/batch = 16.6606s	
15871/16650 (epoch 47.661), train_loss = 0.66122252, grad/param norm = 4.7985e-01, time/batch = 18.4418s	
15872/16650 (epoch 47.664), train_loss = 0.65909725, grad/param norm = 3.8022e-01, time/batch = 16.2296s	
15873/16650 (epoch 47.667), train_loss = 0.74489869, grad/param norm = 3.4218e-01, time/batch = 17.8375s	
15874/16650 (epoch 47.670), train_loss = 0.56761554, grad/param norm = 3.6011e-01, time/batch = 15.3244s	
15875/16650 (epoch 47.673), train_loss = 0.57161472, grad/param norm = 2.9936e-01, time/batch = 17.6749s	
15876/16650 (epoch 47.676), train_loss = 0.68518351, grad/param norm = 3.1596e-01, time/batch = 18.5992s	
15877/16650 (epoch 47.679), train_loss = 0.58685974, grad/param norm = 2.8561e-01, time/batch = 17.1808s	
15878/16650 (epoch 47.682), train_loss = 0.64963041, grad/param norm = 3.4963e-01, time/batch = 18.3756s	
15879/16650 (epoch 47.685), train_loss = 0.52606851, grad/param norm = 2.7496e-01, time/batch = 17.3575s	
15880/16650 (epoch 47.688), train_loss = 0.69367760, grad/param norm = 3.1866e-01, time/batch = 16.6177s	
15881/16650 (epoch 47.691), train_loss = 0.66400444, grad/param norm = 3.2234e-01, time/batch = 18.2066s	
15882/16650 (epoch 47.694), train_loss = 0.58870985, grad/param norm = 3.1177e-01, time/batch = 17.7993s	
15883/16650 (epoch 47.697), train_loss = 0.56550120, grad/param norm = 3.3039e-01, time/batch = 15.4402s	
15884/16650 (epoch 47.700), train_loss = 0.66852483, grad/param norm = 3.2850e-01, time/batch = 14.4597s	
15885/16650 (epoch 47.703), train_loss = 0.56181708, grad/param norm = 2.8990e-01, time/batch = 18.1240s	
15886/16650 (epoch 47.706), train_loss = 0.62287095, grad/param norm = 3.2999e-01, time/batch = 16.5422s	
15887/16650 (epoch 47.709), train_loss = 0.55833033, grad/param norm = 3.1998e-01, time/batch = 17.4431s	
15888/16650 (epoch 47.712), train_loss = 0.57931337, grad/param norm = 3.4414e-01, time/batch = 16.3429s	
15889/16650 (epoch 47.715), train_loss = 0.65117053, grad/param norm = 3.0519e-01, time/batch = 17.6967s	
15890/16650 (epoch 47.718), train_loss = 0.70161942, grad/param norm = 3.4224e-01, time/batch = 17.9596s	
15891/16650 (epoch 47.721), train_loss = 0.71881337, grad/param norm = 3.1929e-01, time/batch = 15.3434s	
15892/16650 (epoch 47.724), train_loss = 0.67716170, grad/param norm = 3.4823e-01, time/batch = 17.7812s	
15893/16650 (epoch 47.727), train_loss = 0.70027593, grad/param norm = 3.4034e-01, time/batch = 16.0862s	
15894/16650 (epoch 47.730), train_loss = 0.58265312, grad/param norm = 2.8143e-01, time/batch = 16.4194s	
15895/16650 (epoch 47.733), train_loss = 0.72926847, grad/param norm = 3.2562e-01, time/batch = 17.1684s	
15896/16650 (epoch 47.736), train_loss = 0.53472230, grad/param norm = 2.7962e-01, time/batch = 18.1939s	
15897/16650 (epoch 47.739), train_loss = 0.64521517, grad/param norm = 3.1011e-01, time/batch = 15.5452s	
15898/16650 (epoch 47.742), train_loss = 0.64656501, grad/param norm = 2.6972e-01, time/batch = 16.4228s	
15899/16650 (epoch 47.745), train_loss = 0.51608553, grad/param norm = 3.0102e-01, time/batch = 17.4364s	
15900/16650 (epoch 47.748), train_loss = 0.54428509, grad/param norm = 2.7998e-01, time/batch = 17.8611s	
15901/16650 (epoch 47.751), train_loss = 0.64647028, grad/param norm = 4.7987e-01, time/batch = 16.3322s	
15902/16650 (epoch 47.754), train_loss = 0.78861155, grad/param norm = 3.4809e-01, time/batch = 17.4883s	
15903/16650 (epoch 47.757), train_loss = 0.77626600, grad/param norm = 3.4330e-01, time/batch = 16.4455s	
15904/16650 (epoch 47.760), train_loss = 0.64828296, grad/param norm = 3.9490e-01, time/batch = 18.4560s	
15905/16650 (epoch 47.763), train_loss = 0.62377028, grad/param norm = 2.8533e-01, time/batch = 16.7555s	
15906/16650 (epoch 47.766), train_loss = 0.60517553, grad/param norm = 2.5978e-01, time/batch = 17.6919s	
15907/16650 (epoch 47.769), train_loss = 0.66474192, grad/param norm = 3.2691e-01, time/batch = 17.1043s	
15908/16650 (epoch 47.772), train_loss = 0.66084920, grad/param norm = 2.5136e-01, time/batch = 17.9449s	
15909/16650 (epoch 47.775), train_loss = 0.64043477, grad/param norm = 2.9574e-01, time/batch = 17.8503s	
15910/16650 (epoch 47.778), train_loss = 0.65794414, grad/param norm = 2.7606e-01, time/batch = 15.6453s	
15911/16650 (epoch 47.781), train_loss = 0.78205488, grad/param norm = 3.0833e-01, time/batch = 18.2058s	
15912/16650 (epoch 47.784), train_loss = 0.65666831, grad/param norm = 3.2043e-01, time/batch = 16.6719s	
15913/16650 (epoch 47.787), train_loss = 0.71435522, grad/param norm = 3.4651e-01, time/batch = 19.2045s	
15914/16650 (epoch 47.790), train_loss = 0.74255297, grad/param norm = 2.9442e-01, time/batch = 17.1221s	
15915/16650 (epoch 47.793), train_loss = 0.54088555, grad/param norm = 2.8357e-01, time/batch = 17.2737s	
15916/16650 (epoch 47.796), train_loss = 0.87744418, grad/param norm = 3.4169e-01, time/batch = 15.4052s	
15917/16650 (epoch 47.799), train_loss = 0.75645917, grad/param norm = 3.1031e-01, time/batch = 17.3345s	
15918/16650 (epoch 47.802), train_loss = 0.71513569, grad/param norm = 2.8952e-01, time/batch = 17.6717s	
15919/16650 (epoch 47.805), train_loss = 0.67050345, grad/param norm = 2.8738e-01, time/batch = 16.9964s	
15920/16650 (epoch 47.808), train_loss = 0.73153229, grad/param norm = 3.2115e-01, time/batch = 17.8702s	
15921/16650 (epoch 47.811), train_loss = 0.75123726, grad/param norm = 3.3099e-01, time/batch = 18.6223s	
15922/16650 (epoch 47.814), train_loss = 0.58848808, grad/param norm = 3.1974e-01, time/batch = 16.7462s	
15923/16650 (epoch 47.817), train_loss = 0.58381864, grad/param norm = 3.7973e-01, time/batch = 17.8703s	
15924/16650 (epoch 47.820), train_loss = 0.72933069, grad/param norm = 3.5516e-01, time/batch = 17.8822s	
15925/16650 (epoch 47.823), train_loss = 0.66627779, grad/param norm = 2.9996e-01, time/batch = 18.3655s	
15926/16650 (epoch 47.826), train_loss = 0.62170450, grad/param norm = 3.2321e-01, time/batch = 16.0814s	
15927/16650 (epoch 47.829), train_loss = 0.64074440, grad/param norm = 2.8683e-01, time/batch = 18.6907s	
15928/16650 (epoch 47.832), train_loss = 0.72509750, grad/param norm = 3.1510e-01, time/batch = 18.8902s	
15929/16650 (epoch 47.835), train_loss = 0.70288661, grad/param norm = 3.3563e-01, time/batch = 16.0170s	
15930/16650 (epoch 47.838), train_loss = 0.58700464, grad/param norm = 2.5755e-01, time/batch = 18.9597s	
15931/16650 (epoch 47.841), train_loss = 0.60472602, grad/param norm = 2.8915e-01, time/batch = 15.9200s	
15932/16650 (epoch 47.844), train_loss = 0.65829795, grad/param norm = 2.8639e-01, time/batch = 16.9234s	
15933/16650 (epoch 47.847), train_loss = 0.70911995, grad/param norm = 3.3570e-01, time/batch = 16.5344s	
15934/16650 (epoch 47.850), train_loss = 0.63096077, grad/param norm = 3.5261e-01, time/batch = 16.3502s	
15935/16650 (epoch 47.853), train_loss = 0.63038091, grad/param norm = 3.0187e-01, time/batch = 18.4521s	
15936/16650 (epoch 47.856), train_loss = 0.60303332, grad/param norm = 2.7388e-01, time/batch = 16.0811s	
15937/16650 (epoch 47.859), train_loss = 0.70032624, grad/param norm = 2.9707e-01, time/batch = 17.3531s	
15938/16650 (epoch 47.862), train_loss = 0.68074978, grad/param norm = 2.8959e-01, time/batch = 17.6128s	
15939/16650 (epoch 47.865), train_loss = 0.53794415, grad/param norm = 2.8235e-01, time/batch = 17.6724s	
15940/16650 (epoch 47.868), train_loss = 0.66079667, grad/param norm = 2.9530e-01, time/batch = 17.1182s	
15941/16650 (epoch 47.871), train_loss = 0.65150175, grad/param norm = 2.8223e-01, time/batch = 16.8715s	
15942/16650 (epoch 47.874), train_loss = 0.66218436, grad/param norm = 2.8452e-01, time/batch = 15.6621s	
15943/16650 (epoch 47.877), train_loss = 0.63610062, grad/param norm = 2.9754e-01, time/batch = 17.3487s	
15944/16650 (epoch 47.880), train_loss = 0.58754222, grad/param norm = 3.1068e-01, time/batch = 17.6100s	
15945/16650 (epoch 47.883), train_loss = 0.66485247, grad/param norm = 2.8911e-01, time/batch = 17.1291s	
15946/16650 (epoch 47.886), train_loss = 0.65333118, grad/param norm = 3.4288e-01, time/batch = 17.5942s	
15947/16650 (epoch 47.889), train_loss = 0.55175221, grad/param norm = 3.7353e-01, time/batch = 15.6367s	
15948/16650 (epoch 47.892), train_loss = 0.67148176, grad/param norm = 2.7019e-01, time/batch = 18.8710s	
15949/16650 (epoch 47.895), train_loss = 0.67728445, grad/param norm = 2.7785e-01, time/batch = 16.2730s	
15950/16650 (epoch 47.898), train_loss = 0.65134711, grad/param norm = 3.0864e-01, time/batch = 16.6838s	
15951/16650 (epoch 47.901), train_loss = 0.60245504, grad/param norm = 2.9616e-01, time/batch = 17.6826s	
15952/16650 (epoch 47.904), train_loss = 0.63126423, grad/param norm = 3.1542e-01, time/batch = 17.2758s	
15953/16650 (epoch 47.907), train_loss = 0.65679456, grad/param norm = 3.2494e-01, time/batch = 16.3286s	
15954/16650 (epoch 47.910), train_loss = 0.68367417, grad/param norm = 3.2388e-01, time/batch = 15.5883s	
15955/16650 (epoch 47.913), train_loss = 0.61584208, grad/param norm = 3.4711e-01, time/batch = 14.9942s	
15956/16650 (epoch 47.916), train_loss = 0.58485237, grad/param norm = 3.2273e-01, time/batch = 17.4357s	
15957/16650 (epoch 47.919), train_loss = 0.75210109, grad/param norm = 3.0086e-01, time/batch = 15.9067s	
15958/16650 (epoch 47.922), train_loss = 0.65062296, grad/param norm = 3.5292e-01, time/batch = 15.4014s	
15959/16650 (epoch 47.925), train_loss = 0.59554109, grad/param norm = 2.7365e-01, time/batch = 16.2699s	
15960/16650 (epoch 47.928), train_loss = 0.65017610, grad/param norm = 3.0341e-01, time/batch = 17.8824s	
15961/16650 (epoch 47.931), train_loss = 0.65994260, grad/param norm = 2.9539e-01, time/batch = 16.1611s	
15962/16650 (epoch 47.934), train_loss = 0.52544792, grad/param norm = 3.3412e-01, time/batch = 17.9609s	
15963/16650 (epoch 47.937), train_loss = 0.57499553, grad/param norm = 3.1811e-01, time/batch = 17.1225s	
15964/16650 (epoch 47.940), train_loss = 0.65872702, grad/param norm = 3.2238e-01, time/batch = 15.8557s	
15965/16650 (epoch 47.943), train_loss = 0.68106393, grad/param norm = 3.8974e-01, time/batch = 17.7902s	
15966/16650 (epoch 47.946), train_loss = 0.60172046, grad/param norm = 2.6492e-01, time/batch = 17.8802s	
15967/16650 (epoch 47.949), train_loss = 0.55551544, grad/param norm = 2.8800e-01, time/batch = 17.7821s	
15968/16650 (epoch 47.952), train_loss = 0.56235629, grad/param norm = 3.3635e-01, time/batch = 16.9414s	
15969/16650 (epoch 47.955), train_loss = 0.64269958, grad/param norm = 3.0367e-01, time/batch = 15.9893s	
15970/16650 (epoch 47.958), train_loss = 0.69872514, grad/param norm = 4.0477e-01, time/batch = 16.7006s	
15971/16650 (epoch 47.961), train_loss = 0.64489833, grad/param norm = 2.8480e-01, time/batch = 15.4323s	
15972/16650 (epoch 47.964), train_loss = 0.55074386, grad/param norm = 4.0243e-01, time/batch = 15.9394s	
15973/16650 (epoch 47.967), train_loss = 0.76859728, grad/param norm = 3.2513e-01, time/batch = 18.0359s	
15974/16650 (epoch 47.970), train_loss = 0.61455936, grad/param norm = 3.1989e-01, time/batch = 17.5440s	
15975/16650 (epoch 47.973), train_loss = 0.60702141, grad/param norm = 3.2545e-01, time/batch = 15.8291s	
15976/16650 (epoch 47.976), train_loss = 0.57919567, grad/param norm = 3.3707e-01, time/batch = 14.4823s	
15977/16650 (epoch 47.979), train_loss = 0.65174476, grad/param norm = 3.2932e-01, time/batch = 14.0064s	
15978/16650 (epoch 47.982), train_loss = 0.68725897, grad/param norm = 2.8463e-01, time/batch = 13.3165s	
15979/16650 (epoch 47.985), train_loss = 0.67595094, grad/param norm = 3.5656e-01, time/batch = 14.1241s	
15980/16650 (epoch 47.988), train_loss = 0.66892215, grad/param norm = 3.2679e-01, time/batch = 15.4316s	
15981/16650 (epoch 47.991), train_loss = 0.58092278, grad/param norm = 3.6426e-01, time/batch = 17.6253s	
15982/16650 (epoch 47.994), train_loss = 0.61499255, grad/param norm = 3.1876e-01, time/batch = 15.6777s	
15983/16650 (epoch 47.997), train_loss = 0.60574648, grad/param norm = 3.2592e-01, time/batch = 15.4717s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
15984/16650 (epoch 48.000), train_loss = 0.69495393, grad/param norm = 3.1185e-01, time/batch = 17.4562s	
15985/16650 (epoch 48.003), train_loss = 0.74007702, grad/param norm = 3.2870e-01, time/batch = 16.8769s	
15986/16650 (epoch 48.006), train_loss = 0.75730311, grad/param norm = 4.2438e-01, time/batch = 16.5219s	
15987/16650 (epoch 48.009), train_loss = 0.73524839, grad/param norm = 3.3532e-01, time/batch = 16.9362s	
15988/16650 (epoch 48.012), train_loss = 0.73630943, grad/param norm = 3.2007e-01, time/batch = 16.0149s	
15989/16650 (epoch 48.015), train_loss = 0.64367066, grad/param norm = 2.8999e-01, time/batch = 17.3701s	
15990/16650 (epoch 48.018), train_loss = 0.57418614, grad/param norm = 2.8728e-01, time/batch = 16.2632s	
15991/16650 (epoch 48.021), train_loss = 0.77310126, grad/param norm = 3.5618e-01, time/batch = 16.1822s	
15992/16650 (epoch 48.024), train_loss = 0.64489725, grad/param norm = 3.2374e-01, time/batch = 17.9504s	
15993/16650 (epoch 48.027), train_loss = 0.69595152, grad/param norm = 4.1162e-01, time/batch = 17.8181s	
15994/16650 (epoch 48.030), train_loss = 0.56455984, grad/param norm = 3.3170e-01, time/batch = 29.7465s	
15995/16650 (epoch 48.033), train_loss = 0.63321801, grad/param norm = 2.7100e-01, time/batch = 18.1227s	
15996/16650 (epoch 48.036), train_loss = 0.45502715, grad/param norm = 4.1001e-01, time/batch = 14.4554s	
15997/16650 (epoch 48.039), train_loss = 0.72917103, grad/param norm = 3.1026e-01, time/batch = 15.5693s	
15998/16650 (epoch 48.042), train_loss = 0.69972338, grad/param norm = 4.4351e-01, time/batch = 14.9322s	
15999/16650 (epoch 48.045), train_loss = 0.69217917, grad/param norm = 3.5156e-01, time/batch = 15.1748s	
evaluating loss over split index 2	
1/18...	
2/18...	
3/18...	
4/18...	
5/18...	
6/18...	
7/18...	
8/18...	
9/18...	
10/18...	
11/18...	
12/18...	
13/18...	
14/18...	
15/18...	
16/18...	
17/18...	
18/18...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nsagov_epoch48.05_2.4114.t7	
16000/16650 (epoch 48.048), train_loss = 0.74612738, grad/param norm = 3.4460e-01, time/batch = 16.7333s	
16001/16650 (epoch 48.051), train_loss = 1.41718249, grad/param norm = 5.9413e-01, time/batch = 17.2690s	
16002/16650 (epoch 48.054), train_loss = 0.65863886, grad/param norm = 3.3957e-01, time/batch = 16.1000s	
16003/16650 (epoch 48.057), train_loss = 0.66492065, grad/param norm = 3.8006e-01, time/batch = 16.0083s	
16004/16650 (epoch 48.060), train_loss = 0.55112163, grad/param norm = 2.6943e-01, time/batch = 15.8358s	
16005/16650 (epoch 48.063), train_loss = 0.63005996, grad/param norm = 3.2116e-01, time/batch = 16.1952s	
16006/16650 (epoch 48.066), train_loss = 0.78561644, grad/param norm = 3.3704e-01, time/batch = 17.1808s	
16007/16650 (epoch 48.069), train_loss = 0.69433162, grad/param norm = 3.0441e-01, time/batch = 16.8325s	
16008/16650 (epoch 48.072), train_loss = 0.67156711, grad/param norm = 3.2562e-01, time/batch = 17.4691s	
16009/16650 (epoch 48.075), train_loss = 0.74008565, grad/param norm = 3.4180e-01, time/batch = 17.3076s	
16010/16650 (epoch 48.078), train_loss = 0.72076409, grad/param norm = 3.7592e-01, time/batch = 16.5963s	
16011/16650 (epoch 48.081), train_loss = 0.69352377, grad/param norm = 4.0864e-01, time/batch = 17.9684s	
16012/16650 (epoch 48.084), train_loss = 0.67053833, grad/param norm = 2.9591e-01, time/batch = 17.0293s	
16013/16650 (epoch 48.087), train_loss = 0.69471491, grad/param norm = 3.4223e-01, time/batch = 17.8912s	
16014/16650 (epoch 48.090), train_loss = 0.63482964, grad/param norm = 3.2544e-01, time/batch = 16.4270s	
16015/16650 (epoch 48.093), train_loss = 0.74872588, grad/param norm = 4.1784e-01, time/batch = 14.0830s	
16016/16650 (epoch 48.096), train_loss = 0.61037822, grad/param norm = 3.2241e-01, time/batch = 17.7051s	
16017/16650 (epoch 48.099), train_loss = 0.67244858, grad/param norm = 3.4586e-01, time/batch = 14.3684s	
16018/16650 (epoch 48.102), train_loss = 0.66285580, grad/param norm = 3.2979e-01, time/batch = 16.5329s	
16019/16650 (epoch 48.105), train_loss = 0.68127744, grad/param norm = 3.4729e-01, time/batch = 17.0398s	
16020/16650 (epoch 48.108), train_loss = 0.68883895, grad/param norm = 3.1376e-01, time/batch = 16.6116s	
16021/16650 (epoch 48.111), train_loss = 0.75776737, grad/param norm = 3.2706e-01, time/batch = 15.4160s	
16022/16650 (epoch 48.114), train_loss = 0.67440947, grad/param norm = 4.2336e-01, time/batch = 17.1987s	
16023/16650 (epoch 48.117), train_loss = 0.77752450, grad/param norm = 3.8002e-01, time/batch = 17.1204s	
16024/16650 (epoch 48.120), train_loss = 0.68187263, grad/param norm = 3.1271e-01, time/batch = 17.2086s	
16025/16650 (epoch 48.123), train_loss = 0.63929596, grad/param norm = 3.1022e-01, time/batch = 15.6770s	
16026/16650 (epoch 48.126), train_loss = 0.70914988, grad/param norm = 3.2512e-01, time/batch = 17.0351s	
16027/16650 (epoch 48.129), train_loss = 0.71750930, grad/param norm = 3.5844e-01, time/batch = 17.0466s	
16028/16650 (epoch 48.132), train_loss = 0.63963692, grad/param norm = 3.1958e-01, time/batch = 15.8409s	
16029/16650 (epoch 48.135), train_loss = 0.76679741, grad/param norm = 2.8122e-01, time/batch = 16.2665s	
16030/16650 (epoch 48.138), train_loss = 0.73355155, grad/param norm = 3.2057e-01, time/batch = 17.4560s	
16031/16650 (epoch 48.141), train_loss = 0.68940343, grad/param norm = 3.3204e-01, time/batch = 18.3045s	
16032/16650 (epoch 48.144), train_loss = 0.71470796, grad/param norm = 4.0309e-01, time/batch = 14.8757s	
16033/16650 (epoch 48.147), train_loss = 0.80315969, grad/param norm = 3.7359e-01, time/batch = 18.3717s	
16034/16650 (epoch 48.150), train_loss = 0.85712242, grad/param norm = 3.9470e-01, time/batch = 17.0342s	
16035/16650 (epoch 48.153), train_loss = 0.66372035, grad/param norm = 3.0618e-01, time/batch = 16.2724s	
16036/16650 (epoch 48.156), train_loss = 0.67139954, grad/param norm = 3.1826e-01, time/batch = 16.0386s	
16037/16650 (epoch 48.159), train_loss = 0.71404700, grad/param norm = 3.4957e-01, time/batch = 17.2839s	
16038/16650 (epoch 48.162), train_loss = 0.77583722, grad/param norm = 3.1926e-01, time/batch = 17.0458s	
16039/16650 (epoch 48.165), train_loss = 0.75535539, grad/param norm = 2.9483e-01, time/batch = 16.0902s	
16040/16650 (epoch 48.168), train_loss = 0.58482589, grad/param norm = 2.8076e-01, time/batch = 16.6973s	
16041/16650 (epoch 48.171), train_loss = 0.71530441, grad/param norm = 2.8176e-01, time/batch = 17.3576s	
16042/16650 (epoch 48.174), train_loss = 0.54796795, grad/param norm = 2.7897e-01, time/batch = 16.2747s	
16043/16650 (epoch 48.177), train_loss = 0.67877099, grad/param norm = 3.1399e-01, time/batch = 14.7404s	
16044/16650 (epoch 48.180), train_loss = 0.78138973, grad/param norm = 3.2735e-01, time/batch = 17.1801s	
16045/16650 (epoch 48.183), train_loss = 0.88897526, grad/param norm = 4.0260e-01, time/batch = 18.0316s	
16046/16650 (epoch 48.186), train_loss = 0.71640483, grad/param norm = 3.7000e-01, time/batch = 15.9325s	
16047/16650 (epoch 48.189), train_loss = 0.64808109, grad/param norm = 2.9376e-01, time/batch = 17.9552s	
16048/16650 (epoch 48.192), train_loss = 0.66125337, grad/param norm = 2.8028e-01, time/batch = 16.6955s	
16049/16650 (epoch 48.195), train_loss = 0.59575153, grad/param norm = 3.1125e-01, time/batch = 15.4902s	
16050/16650 (epoch 48.198), train_loss = 0.60571967, grad/param norm = 2.5218e-01, time/batch = 16.3177s	
16051/16650 (epoch 48.201), train_loss = 0.57520873, grad/param norm = 2.3728e-01, time/batch = 18.1171s	
16052/16650 (epoch 48.204), train_loss = 0.67918159, grad/param norm = 2.9980e-01, time/batch = 17.2116s	
16053/16650 (epoch 48.207), train_loss = 0.71551913, grad/param norm = 3.8546e-01, time/batch = 16.5181s	
16054/16650 (epoch 48.210), train_loss = 0.65927678, grad/param norm = 3.0292e-01, time/batch = 14.4959s	
16055/16650 (epoch 48.213), train_loss = 0.71598396, grad/param norm = 3.5096e-01, time/batch = 17.2807s	
16056/16650 (epoch 48.216), train_loss = 0.58172492, grad/param norm = 2.9364e-01, time/batch = 16.2738s	
16057/16650 (epoch 48.219), train_loss = 0.64360391, grad/param norm = 2.8275e-01, time/batch = 15.3304s	
16058/16650 (epoch 48.222), train_loss = 0.69252454, grad/param norm = 2.8473e-01, time/batch = 17.7142s	
16059/16650 (epoch 48.225), train_loss = 0.69912020, grad/param norm = 3.7594e-01, time/batch = 17.0247s	
16060/16650 (epoch 48.228), train_loss = 0.64671140, grad/param norm = 3.5242e-01, time/batch = 16.5081s	
16061/16650 (epoch 48.231), train_loss = 0.62638547, grad/param norm = 3.3098e-01, time/batch = 16.7663s	
16062/16650 (epoch 48.234), train_loss = 0.79844294, grad/param norm = 3.5509e-01, time/batch = 18.1210s	
16063/16650 (epoch 48.237), train_loss = 0.71055712, grad/param norm = 3.5925e-01, time/batch = 14.8641s	
16064/16650 (epoch 48.240), train_loss = 0.72199702, grad/param norm = 3.1540e-01, time/batch = 15.5789s	
16065/16650 (epoch 48.243), train_loss = 0.65672070, grad/param norm = 3.3554e-01, time/batch = 18.3810s	
16066/16650 (epoch 48.246), train_loss = 0.75986235, grad/param norm = 3.1354e-01, time/batch = 17.5398s	
16067/16650 (epoch 48.249), train_loss = 0.56503951, grad/param norm = 2.5807e-01, time/batch = 14.4905s	
16068/16650 (epoch 48.252), train_loss = 0.65468188, grad/param norm = 3.2328e-01, time/batch = 16.6551s	
16069/16650 (epoch 48.255), train_loss = 0.71069035, grad/param norm = 2.9576e-01, time/batch = 13.8796s	
16070/16650 (epoch 48.258), train_loss = 0.73482944, grad/param norm = 2.9689e-01, time/batch = 16.0185s	
16071/16650 (epoch 48.261), train_loss = 0.69452150, grad/param norm = 2.9476e-01, time/batch = 16.2703s	
16072/16650 (epoch 48.264), train_loss = 0.62092267, grad/param norm = 2.9340e-01, time/batch = 17.7019s	
16073/16650 (epoch 48.267), train_loss = 0.63750740, grad/param norm = 3.1675e-01, time/batch = 18.2882s	
16074/16650 (epoch 48.270), train_loss = 0.72357753, grad/param norm = 3.5076e-01, time/batch = 17.7959s	
16075/16650 (epoch 48.273), train_loss = 0.73507348, grad/param norm = 3.3337e-01, time/batch = 16.2521s	
16076/16650 (epoch 48.276), train_loss = 0.71787467, grad/param norm = 3.0871e-01, time/batch = 17.3650s	
16077/16650 (epoch 48.279), train_loss = 0.63135272, grad/param norm = 2.7061e-01, time/batch = 16.5219s	
16078/16650 (epoch 48.282), train_loss = 0.62811480, grad/param norm = 2.7542e-01, time/batch = 16.5816s	
16079/16650 (epoch 48.285), train_loss = 0.65952529, grad/param norm = 3.0149e-01, time/batch = 16.8685s	
16080/16650 (epoch 48.288), train_loss = 0.59030051, grad/param norm = 3.4408e-01, time/batch = 16.6194s	
16081/16650 (epoch 48.291), train_loss = 0.48543981, grad/param norm = 2.4058e-01, time/batch = 18.2038s	
16082/16650 (epoch 48.294), train_loss = 0.60741036, grad/param norm = 3.3716e-01, time/batch = 14.6289s	
16083/16650 (epoch 48.297), train_loss = 0.66084665, grad/param norm = 3.8090e-01, time/batch = 17.2017s	
16084/16650 (epoch 48.300), train_loss = 0.52318718, grad/param norm = 2.7072e-01, time/batch = 18.0419s	
16085/16650 (epoch 48.303), train_loss = 0.57324879, grad/param norm = 2.5653e-01, time/batch = 17.1103s	
16086/16650 (epoch 48.306), train_loss = 0.72784277, grad/param norm = 2.6843e-01, time/batch = 17.2848s	
16087/16650 (epoch 48.309), train_loss = 0.70034561, grad/param norm = 3.1827e-01, time/batch = 16.5332s	
16088/16650 (epoch 48.312), train_loss = 0.54348527, grad/param norm = 3.1207e-01, time/batch = 16.3137s	
16089/16650 (epoch 48.315), train_loss = 0.47320790, grad/param norm = 2.6949e-01, time/batch = 16.4348s	
16090/16650 (epoch 48.318), train_loss = 0.54170465, grad/param norm = 3.0154e-01, time/batch = 16.5289s	
16091/16650 (epoch 48.321), train_loss = 0.71255768, grad/param norm = 3.1447e-01, time/batch = 15.2377s	
16092/16650 (epoch 48.324), train_loss = 0.59652661, grad/param norm = 3.3063e-01, time/batch = 17.0178s	
16093/16650 (epoch 48.327), train_loss = 0.67811274, grad/param norm = 3.6509e-01, time/batch = 16.3457s	
16094/16650 (epoch 48.330), train_loss = 0.66166860, grad/param norm = 3.5835e-01, time/batch = 14.9266s	
16095/16650 (epoch 48.333), train_loss = 0.69303681, grad/param norm = 3.8790e-01, time/batch = 16.3532s	
16096/16650 (epoch 48.336), train_loss = 0.58471305, grad/param norm = 3.1047e-01, time/batch = 16.3523s	
16097/16650 (epoch 48.339), train_loss = 0.59176752, grad/param norm = 3.0912e-01, time/batch = 15.0828s	
16098/16650 (epoch 48.342), train_loss = 0.55927370, grad/param norm = 3.3331e-01, time/batch = 17.7762s	
16099/16650 (epoch 48.345), train_loss = 0.61599395, grad/param norm = 3.5868e-01, time/batch = 16.1137s	
16100/16650 (epoch 48.348), train_loss = 0.69545944, grad/param norm = 3.2649e-01, time/batch = 15.7569s	
16101/16650 (epoch 48.351), train_loss = 0.67561550, grad/param norm = 3.0844e-01, time/batch = 18.2786s	
16102/16650 (epoch 48.354), train_loss = 0.70204678, grad/param norm = 3.0672e-01, time/batch = 17.6216s	
16103/16650 (epoch 48.357), train_loss = 0.68846510, grad/param norm = 3.5355e-01, time/batch = 16.4353s	
16104/16650 (epoch 48.360), train_loss = 0.65593219, grad/param norm = 3.4897e-01, time/batch = 16.4418s	
16105/16650 (epoch 48.363), train_loss = 0.72300271, grad/param norm = 3.7647e-01, time/batch = 17.7855s	
16106/16650 (epoch 48.366), train_loss = 0.79850732, grad/param norm = 4.2384e-01, time/batch = 18.2097s	
16107/16650 (epoch 48.369), train_loss = 0.72457974, grad/param norm = 3.4421e-01, time/batch = 15.2741s	
16108/16650 (epoch 48.372), train_loss = 0.67011676, grad/param norm = 3.0543e-01, time/batch = 18.1972s	
16109/16650 (epoch 48.375), train_loss = 0.68891705, grad/param norm = 2.8831e-01, time/batch = 14.4055s	
16110/16650 (epoch 48.378), train_loss = 0.63364511, grad/param norm = 3.5703e-01, time/batch = 16.8567s	
16111/16650 (epoch 48.381), train_loss = 0.74127045, grad/param norm = 3.6567e-01, time/batch = 16.3578s	
16112/16650 (epoch 48.384), train_loss = 0.76703957, grad/param norm = 3.3249e-01, time/batch = 17.7973s	
16113/16650 (epoch 48.387), train_loss = 0.53173495, grad/param norm = 2.5793e-01, time/batch = 16.3613s	
16114/16650 (epoch 48.390), train_loss = 0.71072195, grad/param norm = 3.1728e-01, time/batch = 16.1084s	
16115/16650 (epoch 48.393), train_loss = 0.64383439, grad/param norm = 3.4531e-01, time/batch = 16.6080s	
16116/16650 (epoch 48.396), train_loss = 0.77909308, grad/param norm = 3.5455e-01, time/batch = 17.6140s	
16117/16650 (epoch 48.399), train_loss = 0.72343488, grad/param norm = 3.1352e-01, time/batch = 17.6265s	
16118/16650 (epoch 48.402), train_loss = 0.65125747, grad/param norm = 2.8413e-01, time/batch = 16.9273s	
16119/16650 (epoch 48.405), train_loss = 0.52272676, grad/param norm = 2.9796e-01, time/batch = 17.1920s	
16120/16650 (epoch 48.408), train_loss = 0.69982625, grad/param norm = 2.8232e-01, time/batch = 17.1202s	
16121/16650 (epoch 48.411), train_loss = 0.61929296, grad/param norm = 3.3602e-01, time/batch = 15.2184s	
16122/16650 (epoch 48.414), train_loss = 0.59773978, grad/param norm = 3.6422e-01, time/batch = 15.5670s	
16123/16650 (epoch 48.417), train_loss = 0.58084223, grad/param norm = 3.4346e-01, time/batch = 17.7828s	
16124/16650 (epoch 48.420), train_loss = 0.61808555, grad/param norm = 3.1259e-01, time/batch = 18.3649s	
16125/16650 (epoch 48.423), train_loss = 0.49715283, grad/param norm = 2.5767e-01, time/batch = 15.4894s	
16126/16650 (epoch 48.426), train_loss = 0.55352604, grad/param norm = 3.0603e-01, time/batch = 17.3386s	
16127/16650 (epoch 48.429), train_loss = 0.72337636, grad/param norm = 3.2156e-01, time/batch = 17.2808s	
16128/16650 (epoch 48.432), train_loss = 0.71343281, grad/param norm = 3.3576e-01, time/batch = 17.0981s	
16129/16650 (epoch 48.435), train_loss = 0.79584206, grad/param norm = 3.8468e-01, time/batch = 18.0362s	
16130/16650 (epoch 48.438), train_loss = 0.80918032, grad/param norm = 3.8080e-01, time/batch = 16.8754s	
16131/16650 (epoch 48.441), train_loss = 0.63478287, grad/param norm = 3.6447e-01, time/batch = 14.9063s	
16132/16650 (epoch 48.444), train_loss = 0.60645638, grad/param norm = 3.3551e-01, time/batch = 15.3174s	
16133/16650 (epoch 48.447), train_loss = 0.61452743, grad/param norm = 3.3502e-01, time/batch = 15.3308s	
16134/16650 (epoch 48.450), train_loss = 0.60747751, grad/param norm = 3.3119e-01, time/batch = 17.5062s	
16135/16650 (epoch 48.453), train_loss = 0.59423884, grad/param norm = 3.1092e-01, time/batch = 17.2990s	
16136/16650 (epoch 48.456), train_loss = 0.57472216, grad/param norm = 2.8009e-01, time/batch = 16.3397s	
16137/16650 (epoch 48.459), train_loss = 0.59899245, grad/param norm = 3.3422e-01, time/batch = 18.5483s	
16138/16650 (epoch 48.462), train_loss = 0.75938760, grad/param norm = 4.3808e-01, time/batch = 17.3751s	
16139/16650 (epoch 48.465), train_loss = 0.59086991, grad/param norm = 3.2053e-01, time/batch = 15.9341s	
16140/16650 (epoch 48.468), train_loss = 0.50536171, grad/param norm = 2.9193e-01, time/batch = 18.2065s	
16141/16650 (epoch 48.471), train_loss = 0.42487427, grad/param norm = 2.5630e-01, time/batch = 17.4387s	
16142/16650 (epoch 48.474), train_loss = 0.58453559, grad/param norm = 3.2982e-01, time/batch = 16.4461s	
16143/16650 (epoch 48.477), train_loss = 0.68805967, grad/param norm = 3.5777e-01, time/batch = 15.6920s	
16144/16650 (epoch 48.480), train_loss = 0.60465004, grad/param norm = 3.9650e-01, time/batch = 18.4639s	
16145/16650 (epoch 48.483), train_loss = 0.69159922, grad/param norm = 3.3556e-01, time/batch = 17.0391s	
16146/16650 (epoch 48.486), train_loss = 0.56299294, grad/param norm = 2.6852e-01, time/batch = 15.8558s	
16147/16650 (epoch 48.489), train_loss = 0.64957225, grad/param norm = 3.1954e-01, time/batch = 17.2066s	
16148/16650 (epoch 48.492), train_loss = 0.64963005, grad/param norm = 2.8960e-01, time/batch = 18.2973s	
16149/16650 (epoch 48.495), train_loss = 0.53461131, grad/param norm = 3.0160e-01, time/batch = 15.6834s	
16150/16650 (epoch 48.498), train_loss = 0.61293684, grad/param norm = 4.4392e-01, time/batch = 16.4173s	
16151/16650 (epoch 48.502), train_loss = 0.76202524, grad/param norm = 4.1055e-01, time/batch = 17.4468s	
16152/16650 (epoch 48.505), train_loss = 0.68558251, grad/param norm = 2.9240e-01, time/batch = 18.2935s	
16153/16650 (epoch 48.508), train_loss = 0.70912860, grad/param norm = 3.6795e-01, time/batch = 14.8312s	
16154/16650 (epoch 48.511), train_loss = 0.69504049, grad/param norm = 3.2138e-01, time/batch = 15.9198s	
16155/16650 (epoch 48.514), train_loss = 0.56490927, grad/param norm = 2.8348e-01, time/batch = 17.7156s	
16156/16650 (epoch 48.517), train_loss = 0.59626094, grad/param norm = 2.9499e-01, time/batch = 17.4489s	
16157/16650 (epoch 48.520), train_loss = 0.53130191, grad/param norm = 2.8875e-01, time/batch = 15.9099s	
16158/16650 (epoch 48.523), train_loss = 0.64051648, grad/param norm = 2.8144e-01, time/batch = 16.8007s	
16159/16650 (epoch 48.526), train_loss = 0.70673372, grad/param norm = 3.1738e-01, time/batch = 17.8694s	
16160/16650 (epoch 48.529), train_loss = 0.70848758, grad/param norm = 4.1839e-01, time/batch = 14.9766s	
16161/16650 (epoch 48.532), train_loss = 0.48446187, grad/param norm = 2.6830e-01, time/batch = 16.2481s	
16162/16650 (epoch 48.535), train_loss = 0.59211114, grad/param norm = 3.6901e-01, time/batch = 17.5337s	
16163/16650 (epoch 48.538), train_loss = 0.52049277, grad/param norm = 3.6572e-01, time/batch = 16.1726s	
16164/16650 (epoch 48.541), train_loss = 0.75453008, grad/param norm = 3.4790e-01, time/batch = 16.0042s	
16165/16650 (epoch 48.544), train_loss = 0.79523417, grad/param norm = 4.2391e-01, time/batch = 17.4524s	
16166/16650 (epoch 48.547), train_loss = 0.53728319, grad/param norm = 2.7036e-01, time/batch = 17.6181s	
16167/16650 (epoch 48.550), train_loss = 0.66842293, grad/param norm = 3.3825e-01, time/batch = 15.5816s	
16168/16650 (epoch 48.553), train_loss = 0.63368658, grad/param norm = 2.9731e-01, time/batch = 17.0137s	
16169/16650 (epoch 48.556), train_loss = 0.59113357, grad/param norm = 2.9433e-01, time/batch = 16.4457s	
16170/16650 (epoch 48.559), train_loss = 0.51682208, grad/param norm = 2.9471e-01, time/batch = 17.4446s	
16171/16650 (epoch 48.562), train_loss = 0.57844251, grad/param norm = 3.1886e-01, time/batch = 15.7426s	
16172/16650 (epoch 48.565), train_loss = 0.50380189, grad/param norm = 3.2672e-01, time/batch = 16.3255s	
16173/16650 (epoch 48.568), train_loss = 0.52220312, grad/param norm = 3.2260e-01, time/batch = 18.0453s	
16174/16650 (epoch 48.571), train_loss = 0.56509915, grad/param norm = 3.4293e-01, time/batch = 16.7736s	
16175/16650 (epoch 48.574), train_loss = 0.54531944, grad/param norm = 3.3942e-01, time/batch = 18.2829s	
16176/16650 (epoch 48.577), train_loss = 0.59858826, grad/param norm = 2.6708e-01, time/batch = 18.0336s	
16177/16650 (epoch 48.580), train_loss = 0.57617167, grad/param norm = 2.8883e-01, time/batch = 17.4664s	
16178/16650 (epoch 48.583), train_loss = 0.66241782, grad/param norm = 2.9441e-01, time/batch = 16.8426s	
16179/16650 (epoch 48.586), train_loss = 0.55647023, grad/param norm = 3.9784e-01, time/batch = 16.1043s	
16180/16650 (epoch 48.589), train_loss = 0.56290859, grad/param norm = 3.2639e-01, time/batch = 16.1068s	
16181/16650 (epoch 48.592), train_loss = 0.63433326, grad/param norm = 3.3906e-01, time/batch = 15.7467s	
16182/16650 (epoch 48.595), train_loss = 0.57191149, grad/param norm = 3.1200e-01, time/batch = 16.1717s	
16183/16650 (epoch 48.598), train_loss = 0.60183616, grad/param norm = 2.9260e-01, time/batch = 17.1112s	
16184/16650 (epoch 48.601), train_loss = 0.56707439, grad/param norm = 3.6362e-01, time/batch = 18.3040s	
16185/16650 (epoch 48.604), train_loss = 0.58789021, grad/param norm = 2.6413e-01, time/batch = 15.1592s	
16186/16650 (epoch 48.607), train_loss = 0.67148807, grad/param norm = 3.2776e-01, time/batch = 17.0397s	
16187/16650 (epoch 48.610), train_loss = 0.57879953, grad/param norm = 2.4275e-01, time/batch = 18.2147s	
16188/16650 (epoch 48.613), train_loss = 0.71342442, grad/param norm = 3.4784e-01, time/batch = 16.8691s	
16189/16650 (epoch 48.616), train_loss = 0.66094568, grad/param norm = 3.8733e-01, time/batch = 16.5127s	
16190/16650 (epoch 48.619), train_loss = 0.54894057, grad/param norm = 3.1521e-01, time/batch = 17.3698s	
16191/16650 (epoch 48.622), train_loss = 0.53005119, grad/param norm = 3.2141e-01, time/batch = 18.4617s	
16192/16650 (epoch 48.625), train_loss = 0.63582989, grad/param norm = 2.9929e-01, time/batch = 15.5146s	
16193/16650 (epoch 48.628), train_loss = 0.59909520, grad/param norm = 4.1864e-01, time/batch = 16.8701s	
16194/16650 (epoch 48.631), train_loss = 0.64191690, grad/param norm = 3.6136e-01, time/batch = 17.7036s	
16195/16650 (epoch 48.634), train_loss = 0.78494178, grad/param norm = 3.4279e-01, time/batch = 15.4846s	
16196/16650 (epoch 48.637), train_loss = 0.76406398, grad/param norm = 3.3929e-01, time/batch = 16.8418s	
16197/16650 (epoch 48.640), train_loss = 0.62601284, grad/param norm = 2.9388e-01, time/batch = 16.2583s	
16198/16650 (epoch 48.643), train_loss = 0.70234957, grad/param norm = 3.2188e-01, time/batch = 18.4539s	
16199/16650 (epoch 48.646), train_loss = 0.66570678, grad/param norm = 3.5176e-01, time/batch = 16.1761s	
16200/16650 (epoch 48.649), train_loss = 0.67148842, grad/param norm = 3.2549e-01, time/batch = 17.5346s	
16201/16650 (epoch 48.652), train_loss = 0.67235710, grad/param norm = 3.2965e-01, time/batch = 18.1127s	
16202/16650 (epoch 48.655), train_loss = 0.63162999, grad/param norm = 2.8596e-01, time/batch = 19.4217s	
16203/16650 (epoch 48.658), train_loss = 0.59195045, grad/param norm = 3.3280e-01, time/batch = 28.1155s	
16204/16650 (epoch 48.661), train_loss = 0.65353717, grad/param norm = 3.9260e-01, time/batch = 14.9892s	
16205/16650 (epoch 48.664), train_loss = 0.62680516, grad/param norm = 3.3146e-01, time/batch = 17.0915s	
16206/16650 (epoch 48.667), train_loss = 0.72088304, grad/param norm = 3.0763e-01, time/batch = 17.1683s	
16207/16650 (epoch 48.670), train_loss = 0.55156721, grad/param norm = 2.8551e-01, time/batch = 18.3818s	
16208/16650 (epoch 48.673), train_loss = 0.56494681, grad/param norm = 3.1323e-01, time/batch = 18.3713s	
16209/16650 (epoch 48.676), train_loss = 0.68708864, grad/param norm = 3.1746e-01, time/batch = 16.1618s	
16210/16650 (epoch 48.679), train_loss = 0.56502271, grad/param norm = 3.0148e-01, time/batch = 18.0328s	
16211/16650 (epoch 48.682), train_loss = 0.61598579, grad/param norm = 3.1880e-01, time/batch = 18.2767s	
16212/16650 (epoch 48.685), train_loss = 0.52766316, grad/param norm = 3.2219e-01, time/batch = 17.0149s	
16213/16650 (epoch 48.688), train_loss = 0.69671003, grad/param norm = 2.9617e-01, time/batch = 17.6204s	
16214/16650 (epoch 48.691), train_loss = 0.65316767, grad/param norm = 3.2866e-01, time/batch = 17.7072s	
16215/16650 (epoch 48.694), train_loss = 0.57920650, grad/param norm = 2.9047e-01, time/batch = 14.6341s	
16216/16650 (epoch 48.697), train_loss = 0.56028560, grad/param norm = 2.7798e-01, time/batch = 16.9145s	
16217/16650 (epoch 48.700), train_loss = 0.65205245, grad/param norm = 2.8680e-01, time/batch = 18.0203s	
16218/16650 (epoch 48.703), train_loss = 0.55424187, grad/param norm = 2.6958e-01, time/batch = 18.4676s	
16219/16650 (epoch 48.706), train_loss = 0.60692569, grad/param norm = 3.3047e-01, time/batch = 15.9204s	
16220/16650 (epoch 48.709), train_loss = 0.54443535, grad/param norm = 3.7564e-01, time/batch = 16.0145s	
16221/16650 (epoch 48.712), train_loss = 0.57089067, grad/param norm = 4.0899e-01, time/batch = 17.0221s	
16222/16650 (epoch 48.715), train_loss = 0.64869445, grad/param norm = 3.6441e-01, time/batch = 18.1106s	
16223/16650 (epoch 48.718), train_loss = 0.70393140, grad/param norm = 3.5136e-01, time/batch = 15.3092s	
16224/16650 (epoch 48.721), train_loss = 0.69773306, grad/param norm = 3.1635e-01, time/batch = 17.7049s	
16225/16650 (epoch 48.724), train_loss = 0.68743243, grad/param norm = 3.7994e-01, time/batch = 17.3626s	
16226/16650 (epoch 48.727), train_loss = 0.70183204, grad/param norm = 3.5305e-01, time/batch = 17.1019s	
16227/16650 (epoch 48.730), train_loss = 0.58334604, grad/param norm = 3.1234e-01, time/batch = 16.9141s	
16228/16650 (epoch 48.733), train_loss = 0.73044900, grad/param norm = 3.6205e-01, time/batch = 14.8013s	
16229/16650 (epoch 48.736), train_loss = 0.53122932, grad/param norm = 2.9661e-01, time/batch = 17.9414s	
16230/16650 (epoch 48.739), train_loss = 0.62888346, grad/param norm = 3.1533e-01, time/batch = 16.0912s	
16231/16650 (epoch 48.742), train_loss = 0.63732078, grad/param norm = 2.8783e-01, time/batch = 17.8527s	
16232/16650 (epoch 48.745), train_loss = 0.53037506, grad/param norm = 3.7387e-01, time/batch = 17.6980s	
16233/16650 (epoch 48.748), train_loss = 0.53096117, grad/param norm = 2.8459e-01, time/batch = 17.6781s	
16234/16650 (epoch 48.751), train_loss = 0.63208658, grad/param norm = 4.2706e-01, time/batch = 17.5947s	
16235/16650 (epoch 48.754), train_loss = 0.79291302, grad/param norm = 3.8773e-01, time/batch = 17.5247s	
16236/16650 (epoch 48.757), train_loss = 0.78341908, grad/param norm = 3.8597e-01, time/batch = 17.7026s	
16237/16650 (epoch 48.760), train_loss = 0.63358951, grad/param norm = 3.3587e-01, time/batch = 17.0702s	
16238/16650 (epoch 48.763), train_loss = 0.61524217, grad/param norm = 2.9281e-01, time/batch = 17.0017s	
16239/16650 (epoch 48.766), train_loss = 0.60377841, grad/param norm = 2.6598e-01, time/batch = 17.9395s	
16240/16650 (epoch 48.769), train_loss = 0.66143635, grad/param norm = 4.0270e-01, time/batch = 16.9387s	
16241/16650 (epoch 48.772), train_loss = 0.64979230, grad/param norm = 2.6558e-01, time/batch = 17.4332s	
16242/16650 (epoch 48.775), train_loss = 0.63679808, grad/param norm = 4.4338e-01, time/batch = 15.4185s	
16243/16650 (epoch 48.778), train_loss = 0.67130448, grad/param norm = 3.1991e-01, time/batch = 17.8521s	
16244/16650 (epoch 48.781), train_loss = 0.77448123, grad/param norm = 3.1692e-01, time/batch = 16.7596s	
16245/16650 (epoch 48.784), train_loss = 0.65236067, grad/param norm = 2.9549e-01, time/batch = 18.1215s	
16246/16650 (epoch 48.787), train_loss = 0.69114104, grad/param norm = 3.3587e-01, time/batch = 18.4671s	
16247/16650 (epoch 48.790), train_loss = 0.73767007, grad/param norm = 3.4329e-01, time/batch = 15.1200s	
16248/16650 (epoch 48.793), train_loss = 0.52478405, grad/param norm = 2.9530e-01, time/batch = 15.8344s	
16249/16650 (epoch 48.796), train_loss = 0.87612184, grad/param norm = 3.7400e-01, time/batch = 17.3601s	
16250/16650 (epoch 48.799), train_loss = 0.75325134, grad/param norm = 3.7083e-01, time/batch = 17.7906s	
16251/16650 (epoch 48.802), train_loss = 0.72579262, grad/param norm = 2.9899e-01, time/batch = 16.9953s	
16252/16650 (epoch 48.805), train_loss = 0.66977749, grad/param norm = 2.9380e-01, time/batch = 17.3488s	
16253/16650 (epoch 48.808), train_loss = 0.72028996, grad/param norm = 3.2019e-01, time/batch = 17.8702s	
16254/16650 (epoch 48.811), train_loss = 0.74167352, grad/param norm = 3.4100e-01, time/batch = 15.9206s	
16255/16650 (epoch 48.814), train_loss = 0.58217635, grad/param norm = 2.7405e-01, time/batch = 15.3121s	
16256/16650 (epoch 48.817), train_loss = 0.56713605, grad/param norm = 3.0642e-01, time/batch = 17.7884s	
16257/16650 (epoch 48.820), train_loss = 0.70935860, grad/param norm = 3.1442e-01, time/batch = 17.9454s	
16258/16650 (epoch 48.823), train_loss = 0.65066072, grad/param norm = 2.8561e-01, time/batch = 17.0074s	
16259/16650 (epoch 48.826), train_loss = 0.61831570, grad/param norm = 3.0792e-01, time/batch = 17.8503s	
16260/16650 (epoch 48.829), train_loss = 0.63724617, grad/param norm = 3.5188e-01, time/batch = 18.1191s	
16261/16650 (epoch 48.832), train_loss = 0.72783428, grad/param norm = 3.2928e-01, time/batch = 16.6890s	
16262/16650 (epoch 48.835), train_loss = 0.70834564, grad/param norm = 3.9456e-01, time/batch = 17.3523s	
16263/16650 (epoch 48.838), train_loss = 0.58756886, grad/param norm = 2.7241e-01, time/batch = 17.9367s	
16264/16650 (epoch 48.841), train_loss = 0.61236351, grad/param norm = 2.7589e-01, time/batch = 16.9811s	
16265/16650 (epoch 48.844), train_loss = 0.66292796, grad/param norm = 2.8533e-01, time/batch = 17.7860s	
16266/16650 (epoch 48.847), train_loss = 0.69706749, grad/param norm = 3.2721e-01, time/batch = 16.9323s	
16267/16650 (epoch 48.850), train_loss = 0.61226172, grad/param norm = 3.1734e-01, time/batch = 15.8085s	
16268/16650 (epoch 48.853), train_loss = 0.63112680, grad/param norm = 3.0933e-01, time/batch = 15.7553s	
16269/16650 (epoch 48.856), train_loss = 0.60785496, grad/param norm = 2.7624e-01, time/batch = 16.6946s	
16270/16650 (epoch 48.859), train_loss = 0.70026685, grad/param norm = 3.4239e-01, time/batch = 18.6170s	
16271/16650 (epoch 48.862), train_loss = 0.67140783, grad/param norm = 2.9533e-01, time/batch = 17.3378s	
16272/16650 (epoch 48.865), train_loss = 0.52809798, grad/param norm = 2.7204e-01, time/batch = 16.3341s	
16273/16650 (epoch 48.868), train_loss = 0.64017680, grad/param norm = 3.0327e-01, time/batch = 16.0090s	
16274/16650 (epoch 48.871), train_loss = 0.65341177, grad/param norm = 3.1982e-01, time/batch = 18.0307s	
16275/16650 (epoch 48.874), train_loss = 0.65871984, grad/param norm = 3.1247e-01, time/batch = 15.2990s	
16276/16650 (epoch 48.877), train_loss = 0.62910833, grad/param norm = 2.7841e-01, time/batch = 17.7756s	
16277/16650 (epoch 48.880), train_loss = 0.57912388, grad/param norm = 3.2599e-01, time/batch = 17.7750s	
16278/16650 (epoch 48.883), train_loss = 0.66746548, grad/param norm = 3.3037e-01, time/batch = 17.1823s	
16279/16650 (epoch 48.886), train_loss = 0.66715757, grad/param norm = 3.6385e-01, time/batch = 17.0036s	
16280/16650 (epoch 48.889), train_loss = 0.54233576, grad/param norm = 3.3057e-01, time/batch = 18.2785s	
16281/16650 (epoch 48.892), train_loss = 0.65945827, grad/param norm = 2.6264e-01, time/batch = 14.8502s	
16282/16650 (epoch 48.895), train_loss = 0.69406880, grad/param norm = 3.2873e-01, time/batch = 14.0037s	
16283/16650 (epoch 48.898), train_loss = 0.66297950, grad/param norm = 3.7304e-01, time/batch = 14.1593s	
16284/16650 (epoch 48.901), train_loss = 0.60234594, grad/param norm = 3.2725e-01, time/batch = 17.5164s	
16285/16650 (epoch 48.904), train_loss = 0.63209524, grad/param norm = 3.7661e-01, time/batch = 17.3610s	
16286/16650 (epoch 48.907), train_loss = 0.66082938, grad/param norm = 3.3301e-01, time/batch = 16.9272s	
16287/16650 (epoch 48.910), train_loss = 0.66438974, grad/param norm = 3.2250e-01, time/batch = 17.9457s	
16288/16650 (epoch 48.913), train_loss = 0.62270240, grad/param norm = 3.2837e-01, time/batch = 14.7529s	
16289/16650 (epoch 48.916), train_loss = 0.58280577, grad/param norm = 3.5175e-01, time/batch = 13.6116s	
16290/16650 (epoch 48.919), train_loss = 0.75129586, grad/param norm = 3.1592e-01, time/batch = 13.9237s	
16291/16650 (epoch 48.922), train_loss = 0.63851280, grad/param norm = 3.2469e-01, time/batch = 15.1054s	
16292/16650 (epoch 48.925), train_loss = 0.59310197, grad/param norm = 2.8044e-01, time/batch = 18.1895s	
16293/16650 (epoch 48.928), train_loss = 0.62910723, grad/param norm = 2.6274e-01, time/batch = 16.7606s	
16294/16650 (epoch 48.931), train_loss = 0.65579488, grad/param norm = 2.9581e-01, time/batch = 17.6169s	
16295/16650 (epoch 48.934), train_loss = 0.50410347, grad/param norm = 2.7280e-01, time/batch = 17.4548s	
16296/16650 (epoch 48.937), train_loss = 0.58550956, grad/param norm = 3.5445e-01, time/batch = 17.9611s	
16297/16650 (epoch 48.940), train_loss = 0.65717446, grad/param norm = 2.5012e-01, time/batch = 16.9962s	
16298/16650 (epoch 48.943), train_loss = 0.67090412, grad/param norm = 3.1973e-01, time/batch = 18.7868s	
16299/16650 (epoch 48.946), train_loss = 0.62098128, grad/param norm = 3.5228e-01, time/batch = 15.5643s	
16300/16650 (epoch 48.949), train_loss = 0.55451921, grad/param norm = 3.4537e-01, time/batch = 15.2993s	
16301/16650 (epoch 48.952), train_loss = 0.54995742, grad/param norm = 3.0767e-01, time/batch = 17.1786s	
16302/16650 (epoch 48.955), train_loss = 0.63531520, grad/param norm = 3.2151e-01, time/batch = 16.4104s	
16303/16650 (epoch 48.958), train_loss = 0.68456628, grad/param norm = 4.3810e-01, time/batch = 17.4419s	
16304/16650 (epoch 48.961), train_loss = 0.64181249, grad/param norm = 2.8294e-01, time/batch = 16.5833s	
16305/16650 (epoch 48.964), train_loss = 0.55362777, grad/param norm = 3.3882e-01, time/batch = 18.3503s	
16306/16650 (epoch 48.967), train_loss = 0.75557876, grad/param norm = 3.4658e-01, time/batch = 17.6226s	
16307/16650 (epoch 48.970), train_loss = 0.59119946, grad/param norm = 2.8629e-01, time/batch = 17.0898s	
16308/16650 (epoch 48.973), train_loss = 0.59614961, grad/param norm = 3.4327e-01, time/batch = 16.6953s	
16309/16650 (epoch 48.976), train_loss = 0.59253044, grad/param norm = 3.3172e-01, time/batch = 15.1521s	
16310/16650 (epoch 48.979), train_loss = 0.63846242, grad/param norm = 2.6716e-01, time/batch = 18.0322s	
16311/16650 (epoch 48.982), train_loss = 0.68802288, grad/param norm = 2.8963e-01, time/batch = 15.8204s	
16312/16650 (epoch 48.985), train_loss = 0.65873611, grad/param norm = 3.0808e-01, time/batch = 16.4165s	
16313/16650 (epoch 48.988), train_loss = 0.65473691, grad/param norm = 3.4154e-01, time/batch = 19.3757s	
16314/16650 (epoch 48.991), train_loss = 0.58541131, grad/param norm = 3.9533e-01, time/batch = 16.9309s	
16315/16650 (epoch 48.994), train_loss = 0.59768775, grad/param norm = 2.5972e-01, time/batch = 16.9323s	
16316/16650 (epoch 48.997), train_loss = 0.60758159, grad/param norm = 3.1027e-01, time/batch = 17.4028s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
16317/16650 (epoch 49.000), train_loss = 0.69835400, grad/param norm = 3.2491e-01, time/batch = 18.0764s	
16318/16650 (epoch 49.003), train_loss = 0.75444666, grad/param norm = 3.4354e-01, time/batch = 16.6730s	
16319/16650 (epoch 49.006), train_loss = 0.75255346, grad/param norm = 3.8740e-01, time/batch = 17.4380s	
16320/16650 (epoch 49.009), train_loss = 0.74394598, grad/param norm = 3.6579e-01, time/batch = 17.8628s	
16321/16650 (epoch 49.012), train_loss = 0.72787150, grad/param norm = 3.4244e-01, time/batch = 16.1652s	
16322/16650 (epoch 49.015), train_loss = 0.65004862, grad/param norm = 2.8066e-01, time/batch = 16.9368s	
16323/16650 (epoch 49.018), train_loss = 0.55838733, grad/param norm = 2.9106e-01, time/batch = 18.3634s	
16324/16650 (epoch 49.021), train_loss = 0.75529954, grad/param norm = 3.7226e-01, time/batch = 18.1914s	
16325/16650 (epoch 49.024), train_loss = 0.63807884, grad/param norm = 3.1503e-01, time/batch = 17.2529s	
16326/16650 (epoch 49.027), train_loss = 0.67790855, grad/param norm = 3.3315e-01, time/batch = 16.9614s	
16327/16650 (epoch 49.030), train_loss = 0.55080880, grad/param norm = 2.8336e-01, time/batch = 16.0153s	
16328/16650 (epoch 49.033), train_loss = 0.62003722, grad/param norm = 2.7165e-01, time/batch = 17.4398s	
16329/16650 (epoch 49.036), train_loss = 0.43164129, grad/param norm = 3.6330e-01, time/batch = 15.3370s	
16330/16650 (epoch 49.039), train_loss = 0.72078686, grad/param norm = 2.8185e-01, time/batch = 14.3642s	
16331/16650 (epoch 49.042), train_loss = 0.67250859, grad/param norm = 3.4267e-01, time/batch = 17.9254s	
16332/16650 (epoch 49.045), train_loss = 0.67769601, grad/param norm = 3.1851e-01, time/batch = 16.0970s	
16333/16650 (epoch 49.048), train_loss = 0.72860153, grad/param norm = 3.5126e-01, time/batch = 18.6092s	
16334/16650 (epoch 49.051), train_loss = 0.65660827, grad/param norm = 3.2787e-01, time/batch = 17.7112s	
16335/16650 (epoch 49.054), train_loss = 0.65442170, grad/param norm = 3.0381e-01, time/batch = 17.4261s	
16336/16650 (epoch 49.057), train_loss = 0.63281071, grad/param norm = 3.7533e-01, time/batch = 16.5180s	
16337/16650 (epoch 49.060), train_loss = 0.53230056, grad/param norm = 2.5944e-01, time/batch = 18.7069s	
16338/16650 (epoch 49.063), train_loss = 0.62444401, grad/param norm = 3.1829e-01, time/batch = 17.4670s	
16339/16650 (epoch 49.066), train_loss = 0.77152150, grad/param norm = 3.4360e-01, time/batch = 14.7972s	
16340/16650 (epoch 49.069), train_loss = 0.69693503, grad/param norm = 3.9441e-01, time/batch = 18.6123s	
16341/16650 (epoch 49.072), train_loss = 0.66607115, grad/param norm = 3.1798e-01, time/batch = 18.4732s	
16342/16650 (epoch 49.075), train_loss = 0.71430655, grad/param norm = 3.4710e-01, time/batch = 16.4244s	
16343/16650 (epoch 49.078), train_loss = 0.71104541, grad/param norm = 3.4735e-01, time/batch = 17.7837s	
16344/16650 (epoch 49.081), train_loss = 0.67449078, grad/param norm = 3.8960e-01, time/batch = 18.0201s	
16345/16650 (epoch 49.084), train_loss = 0.67230579, grad/param norm = 3.5147e-01, time/batch = 14.7907s	
16346/16650 (epoch 49.087), train_loss = 0.68759678, grad/param norm = 3.1659e-01, time/batch = 16.3381s	
16347/16650 (epoch 49.090), train_loss = 0.63474853, grad/param norm = 3.4770e-01, time/batch = 18.6249s	
16348/16650 (epoch 49.093), train_loss = 0.74813812, grad/param norm = 3.7682e-01, time/batch = 18.9782s	
16349/16650 (epoch 49.096), train_loss = 0.61573582, grad/param norm = 2.9767e-01, time/batch = 16.8633s	
16350/16650 (epoch 49.099), train_loss = 0.67474293, grad/param norm = 3.8607e-01, time/batch = 18.1113s	
16351/16650 (epoch 49.102), train_loss = 0.63815956, grad/param norm = 3.2953e-01, time/batch = 18.4505s	
16352/16650 (epoch 49.105), train_loss = 0.68054295, grad/param norm = 3.4618e-01, time/batch = 17.6099s	
16353/16650 (epoch 49.108), train_loss = 0.68535635, grad/param norm = 3.3264e-01, time/batch = 16.5258s	
16354/16650 (epoch 49.111), train_loss = 0.75238295, grad/param norm = 3.3375e-01, time/batch = 14.5867s	
16355/16650 (epoch 49.114), train_loss = 0.66639851, grad/param norm = 4.2797e-01, time/batch = 15.6364s	
16356/16650 (epoch 49.117), train_loss = 0.77870939, grad/param norm = 3.4703e-01, time/batch = 16.8444s	
16357/16650 (epoch 49.120), train_loss = 0.66771663, grad/param norm = 3.0689e-01, time/batch = 18.1220s	
16358/16650 (epoch 49.123), train_loss = 0.62715269, grad/param norm = 3.0569e-01, time/batch = 17.5177s	
16359/16650 (epoch 49.126), train_loss = 0.69500077, grad/param norm = 3.0653e-01, time/batch = 17.5221s	
16360/16650 (epoch 49.129), train_loss = 0.70794653, grad/param norm = 3.8445e-01, time/batch = 16.9972s	
16361/16650 (epoch 49.132), train_loss = 0.63834633, grad/param norm = 3.0383e-01, time/batch = 17.6234s	
16362/16650 (epoch 49.135), train_loss = 0.77177400, grad/param norm = 2.9541e-01, time/batch = 16.7911s	
16363/16650 (epoch 49.138), train_loss = 0.73422314, grad/param norm = 3.5725e-01, time/batch = 15.4172s	
16364/16650 (epoch 49.141), train_loss = 0.69556599, grad/param norm = 3.7522e-01, time/batch = 16.3371s	
16365/16650 (epoch 49.144), train_loss = 0.70898691, grad/param norm = 3.7388e-01, time/batch = 17.3667s	
16366/16650 (epoch 49.147), train_loss = 0.80079446, grad/param norm = 4.2413e-01, time/batch = 15.8428s	
16367/16650 (epoch 49.150), train_loss = 0.84205524, grad/param norm = 3.8714e-01, time/batch = 15.5971s	
16368/16650 (epoch 49.153), train_loss = 0.66436094, grad/param norm = 3.3689e-01, time/batch = 16.4511s	
16369/16650 (epoch 49.156), train_loss = 0.65802361, grad/param norm = 3.4774e-01, time/batch = 16.7001s	
16370/16650 (epoch 49.159), train_loss = 0.68760611, grad/param norm = 3.0140e-01, time/batch = 17.1039s	
16371/16650 (epoch 49.162), train_loss = 0.77501831, grad/param norm = 3.3618e-01, time/batch = 17.2084s	
16372/16650 (epoch 49.165), train_loss = 0.76081508, grad/param norm = 3.1042e-01, time/batch = 17.3005s	
16373/16650 (epoch 49.168), train_loss = 0.58028797, grad/param norm = 2.5447e-01, time/batch = 17.0185s	
16374/16650 (epoch 49.171), train_loss = 0.71206729, grad/param norm = 3.2340e-01, time/batch = 15.2239s	
16375/16650 (epoch 49.174), train_loss = 0.54022403, grad/param norm = 2.8119e-01, time/batch = 17.7866s	
16376/16650 (epoch 49.177), train_loss = 0.65847982, grad/param norm = 3.4219e-01, time/batch = 16.9488s	
16377/16650 (epoch 49.180), train_loss = 0.76996628, grad/param norm = 3.1136e-01, time/batch = 16.6914s	
16378/16650 (epoch 49.183), train_loss = 0.86181949, grad/param norm = 3.5528e-01, time/batch = 16.0958s	
16379/16650 (epoch 49.186), train_loss = 0.71302079, grad/param norm = 3.7348e-01, time/batch = 17.8647s	
16380/16650 (epoch 49.189), train_loss = 0.62825668, grad/param norm = 2.9243e-01, time/batch = 16.7947s	
16381/16650 (epoch 49.192), train_loss = 0.64915431, grad/param norm = 2.9601e-01, time/batch = 15.3071s	
16382/16650 (epoch 49.195), train_loss = 0.60118893, grad/param norm = 3.2109e-01, time/batch = 17.7664s	
16383/16650 (epoch 49.198), train_loss = 0.59926900, grad/param norm = 2.8008e-01, time/batch = 17.5470s	
16384/16650 (epoch 49.201), train_loss = 0.56884113, grad/param norm = 2.5457e-01, time/batch = 17.4501s	
16385/16650 (epoch 49.204), train_loss = 0.68001594, grad/param norm = 3.2202e-01, time/batch = 16.4538s	
16386/16650 (epoch 49.207), train_loss = 0.69666422, grad/param norm = 4.0315e-01, time/batch = 17.8718s	
16387/16650 (epoch 49.210), train_loss = 0.65472679, grad/param norm = 3.2681e-01, time/batch = 17.9704s	
16388/16650 (epoch 49.213), train_loss = 0.72306812, grad/param norm = 3.3668e-01, time/batch = 14.9029s	
16389/16650 (epoch 49.216), train_loss = 0.56792168, grad/param norm = 2.9266e-01, time/batch = 16.3314s	
16390/16650 (epoch 49.219), train_loss = 0.64362820, grad/param norm = 3.0753e-01, time/batch = 16.7115s	
16391/16650 (epoch 49.222), train_loss = 0.68557451, grad/param norm = 2.8583e-01, time/batch = 17.4466s	
16392/16650 (epoch 49.225), train_loss = 0.69869210, grad/param norm = 3.9375e-01, time/batch = 15.7438s	
16393/16650 (epoch 49.228), train_loss = 0.63057428, grad/param norm = 3.4783e-01, time/batch = 17.7035s	
16394/16650 (epoch 49.231), train_loss = 0.62207684, grad/param norm = 3.3912e-01, time/batch = 17.4579s	
16395/16650 (epoch 49.234), train_loss = 0.77981475, grad/param norm = 3.3008e-01, time/batch = 16.7654s	
16396/16650 (epoch 49.237), train_loss = 0.69603646, grad/param norm = 3.1238e-01, time/batch = 17.1765s	
16397/16650 (epoch 49.240), train_loss = 0.70790586, grad/param norm = 2.8877e-01, time/batch = 17.3667s	
16398/16650 (epoch 49.243), train_loss = 0.64605798, grad/param norm = 2.8533e-01, time/batch = 16.4365s	
16399/16650 (epoch 49.246), train_loss = 0.75575144, grad/param norm = 3.2993e-01, time/batch = 15.3276s	
16400/16650 (epoch 49.249), train_loss = 0.55296813, grad/param norm = 2.5027e-01, time/batch = 16.8736s	
16401/16650 (epoch 49.252), train_loss = 0.64329658, grad/param norm = 3.3389e-01, time/batch = 17.4449s	
16402/16650 (epoch 49.255), train_loss = 0.70106559, grad/param norm = 3.2298e-01, time/batch = 16.2672s	
16403/16650 (epoch 49.258), train_loss = 0.72506112, grad/param norm = 2.9816e-01, time/batch = 16.2710s	
16404/16650 (epoch 49.261), train_loss = 0.68804754, grad/param norm = 2.9382e-01, time/batch = 14.3053s	
16405/16650 (epoch 49.264), train_loss = 0.60468323, grad/param norm = 2.9926e-01, time/batch = 17.7143s	
16406/16650 (epoch 49.267), train_loss = 0.64473129, grad/param norm = 3.3809e-01, time/batch = 15.9385s	
16407/16650 (epoch 49.270), train_loss = 0.70412297, grad/param norm = 3.2392e-01, time/batch = 17.6320s	
16408/16650 (epoch 49.273), train_loss = 0.72950335, grad/param norm = 3.3707e-01, time/batch = 16.9523s	
16409/16650 (epoch 49.276), train_loss = 0.71395227, grad/param norm = 3.0616e-01, time/batch = 16.2406s	
16410/16650 (epoch 49.279), train_loss = 0.61802512, grad/param norm = 2.5484e-01, time/batch = 16.0280s	
16411/16650 (epoch 49.282), train_loss = 0.61090952, grad/param norm = 2.5813e-01, time/batch = 14.9239s	
16412/16650 (epoch 49.285), train_loss = 0.63284071, grad/param norm = 2.7360e-01, time/batch = 17.4451s	
16413/16650 (epoch 49.288), train_loss = 0.56928370, grad/param norm = 3.1946e-01, time/batch = 20.6117s	
16414/16650 (epoch 49.291), train_loss = 0.48536577, grad/param norm = 2.5353e-01, time/batch = 26.2310s	
16415/16650 (epoch 49.294), train_loss = 0.58628427, grad/param norm = 2.6992e-01, time/batch = 17.2031s	
16416/16650 (epoch 49.297), train_loss = 0.67258681, grad/param norm = 3.0385e-01, time/batch = 15.2328s	
16417/16650 (epoch 49.300), train_loss = 0.51732965, grad/param norm = 2.8548e-01, time/batch = 15.9359s	
16418/16650 (epoch 49.303), train_loss = 0.56609827, grad/param norm = 2.6689e-01, time/batch = 18.2144s	
16419/16650 (epoch 49.306), train_loss = 0.71990760, grad/param norm = 2.8894e-01, time/batch = 17.5381s	
16420/16650 (epoch 49.309), train_loss = 0.69639884, grad/param norm = 2.9745e-01, time/batch = 15.4345s	
16421/16650 (epoch 49.312), train_loss = 0.54962276, grad/param norm = 3.5272e-01, time/batch = 16.1958s	
16422/16650 (epoch 49.315), train_loss = 0.46703967, grad/param norm = 2.4809e-01, time/batch = 18.2030s	
16423/16650 (epoch 49.318), train_loss = 0.52065255, grad/param norm = 2.9695e-01, time/batch = 15.1527s	
16424/16650 (epoch 49.321), train_loss = 0.69562319, grad/param norm = 3.0264e-01, time/batch = 17.7116s	
16425/16650 (epoch 49.324), train_loss = 0.58285163, grad/param norm = 3.1780e-01, time/batch = 16.3680s	
16426/16650 (epoch 49.327), train_loss = 0.65898973, grad/param norm = 3.3776e-01, time/batch = 16.7882s	
16427/16650 (epoch 49.330), train_loss = 0.64764297, grad/param norm = 4.2221e-01, time/batch = 15.4950s	
16428/16650 (epoch 49.333), train_loss = 0.68896283, grad/param norm = 3.8262e-01, time/batch = 15.9433s	
16429/16650 (epoch 49.336), train_loss = 0.59237926, grad/param norm = 3.6737e-01, time/batch = 15.3377s	
16430/16650 (epoch 49.339), train_loss = 0.58876910, grad/param norm = 3.4070e-01, time/batch = 17.2680s	
16431/16650 (epoch 49.342), train_loss = 0.55094449, grad/param norm = 2.9853e-01, time/batch = 17.3522s	
16432/16650 (epoch 49.345), train_loss = 0.60225233, grad/param norm = 2.5572e-01, time/batch = 17.7688s	
16433/16650 (epoch 49.348), train_loss = 0.68453292, grad/param norm = 3.4890e-01, time/batch = 15.1398s	
16434/16650 (epoch 49.351), train_loss = 0.66230869, grad/param norm = 3.9360e-01, time/batch = 15.4326s	
16435/16650 (epoch 49.354), train_loss = 0.68971610, grad/param norm = 3.1907e-01, time/batch = 15.9388s	
16436/16650 (epoch 49.357), train_loss = 0.70641605, grad/param norm = 3.3084e-01, time/batch = 17.7870s	
16437/16650 (epoch 49.360), train_loss = 0.66627454, grad/param norm = 3.5493e-01, time/batch = 16.2602s	
16438/16650 (epoch 49.363), train_loss = 0.72683097, grad/param norm = 3.8128e-01, time/batch = 16.6697s	
16439/16650 (epoch 49.366), train_loss = 0.78052715, grad/param norm = 3.8102e-01, time/batch = 17.0335s	
16440/16650 (epoch 49.369), train_loss = 0.70537780, grad/param norm = 3.2243e-01, time/batch = 17.7902s	
16441/16650 (epoch 49.372), train_loss = 0.67211029, grad/param norm = 3.4032e-01, time/batch = 15.6920s	
16442/16650 (epoch 49.375), train_loss = 0.67570713, grad/param norm = 2.9175e-01, time/batch = 17.1154s	
16443/16650 (epoch 49.378), train_loss = 0.60843578, grad/param norm = 2.8884e-01, time/batch = 16.7137s	
16444/16650 (epoch 49.381), train_loss = 0.71358997, grad/param norm = 3.3799e-01, time/batch = 17.8702s	
16445/16650 (epoch 49.384), train_loss = 0.76320750, grad/param norm = 3.1323e-01, time/batch = 16.4340s	
16446/16650 (epoch 49.387), train_loss = 0.53476040, grad/param norm = 3.0382e-01, time/batch = 18.1229s	
16447/16650 (epoch 49.390), train_loss = 0.73919089, grad/param norm = 3.0603e-01, time/batch = 17.3700s	
16448/16650 (epoch 49.393), train_loss = 0.64950762, grad/param norm = 3.5364e-01, time/batch = 15.5055s	
16449/16650 (epoch 49.396), train_loss = 0.77579460, grad/param norm = 3.5889e-01, time/batch = 14.5936s	
16450/16650 (epoch 49.399), train_loss = 0.71806227, grad/param norm = 3.0070e-01, time/batch = 16.7435s	
16451/16650 (epoch 49.402), train_loss = 0.64161339, grad/param norm = 2.8123e-01, time/batch = 16.6635s	
16452/16650 (epoch 49.405), train_loss = 0.51712811, grad/param norm = 3.1515e-01, time/batch = 15.0568s	
16453/16650 (epoch 49.408), train_loss = 0.69781398, grad/param norm = 3.0606e-01, time/batch = 16.7509s	
16454/16650 (epoch 49.411), train_loss = 0.60037784, grad/param norm = 3.4555e-01, time/batch = 17.7016s	
16455/16650 (epoch 49.414), train_loss = 0.58367127, grad/param norm = 2.8903e-01, time/batch = 16.9484s	
16456/16650 (epoch 49.417), train_loss = 0.55246690, grad/param norm = 2.8108e-01, time/batch = 17.0257s	
16457/16650 (epoch 49.420), train_loss = 0.60211343, grad/param norm = 2.8435e-01, time/batch = 18.2079s	
16458/16650 (epoch 49.423), train_loss = 0.49456977, grad/param norm = 2.6815e-01, time/batch = 16.7010s	
16459/16650 (epoch 49.426), train_loss = 0.55958530, grad/param norm = 3.3984e-01, time/batch = 14.8025s	
16460/16650 (epoch 49.429), train_loss = 0.71230871, grad/param norm = 3.0520e-01, time/batch = 17.1083s	
16461/16650 (epoch 49.432), train_loss = 0.69723889, grad/param norm = 3.0440e-01, time/batch = 18.3776s	
16462/16650 (epoch 49.435), train_loss = 0.78163264, grad/param norm = 3.3485e-01, time/batch = 17.2822s	
16463/16650 (epoch 49.438), train_loss = 0.80353832, grad/param norm = 3.6990e-01, time/batch = 17.1825s	
16464/16650 (epoch 49.441), train_loss = 0.63517783, grad/param norm = 3.7765e-01, time/batch = 18.2130s	
16465/16650 (epoch 49.444), train_loss = 0.61558278, grad/param norm = 3.4156e-01, time/batch = 16.7733s	
16466/16650 (epoch 49.447), train_loss = 0.61472565, grad/param norm = 3.4153e-01, time/batch = 15.5811s	
16467/16650 (epoch 49.450), train_loss = 0.58867428, grad/param norm = 2.8358e-01, time/batch = 15.2192s	
16468/16650 (epoch 49.453), train_loss = 0.59787482, grad/param norm = 3.6456e-01, time/batch = 16.7865s	
16469/16650 (epoch 49.456), train_loss = 0.57857156, grad/param norm = 2.8182e-01, time/batch = 17.6212s	
16470/16650 (epoch 49.459), train_loss = 0.60142826, grad/param norm = 3.3222e-01, time/batch = 15.5901s	
16471/16650 (epoch 49.462), train_loss = 0.73565965, grad/param norm = 3.3614e-01, time/batch = 16.3408s	
16472/16650 (epoch 49.465), train_loss = 0.59803104, grad/param norm = 4.0989e-01, time/batch = 14.3121s	
16473/16650 (epoch 49.468), train_loss = 0.49393884, grad/param norm = 3.1787e-01, time/batch = 17.2796s	
16474/16650 (epoch 49.471), train_loss = 0.43214270, grad/param norm = 2.3813e-01, time/batch = 17.3481s	
16475/16650 (epoch 49.474), train_loss = 0.57619132, grad/param norm = 3.4023e-01, time/batch = 15.9393s	
16476/16650 (epoch 49.477), train_loss = 0.68222667, grad/param norm = 3.3629e-01, time/batch = 17.8712s	
16477/16650 (epoch 49.480), train_loss = 0.60507367, grad/param norm = 3.9061e-01, time/batch = 15.7860s	
16478/16650 (epoch 49.483), train_loss = 0.69638033, grad/param norm = 3.5512e-01, time/batch = 17.1346s	
16479/16650 (epoch 49.486), train_loss = 0.55747678, grad/param norm = 3.2086e-01, time/batch = 17.2847s	
16480/16650 (epoch 49.489), train_loss = 0.64851387, grad/param norm = 3.4533e-01, time/batch = 15.2467s	
16481/16650 (epoch 49.492), train_loss = 0.64778406, grad/param norm = 2.7139e-01, time/batch = 16.5627s	
16482/16650 (epoch 49.495), train_loss = 0.54010389, grad/param norm = 3.3387e-01, time/batch = 18.0215s	
16483/16650 (epoch 49.498), train_loss = 0.59075396, grad/param norm = 3.9143e-01, time/batch = 17.6911s	
16484/16650 (epoch 49.502), train_loss = 0.75054781, grad/param norm = 3.7547e-01, time/batch = 15.9202s	
16485/16650 (epoch 49.505), train_loss = 0.65835691, grad/param norm = 2.7133e-01, time/batch = 17.6038s	
16486/16650 (epoch 49.508), train_loss = 0.70313863, grad/param norm = 3.4986e-01, time/batch = 17.4596s	
16487/16650 (epoch 49.511), train_loss = 0.68814541, grad/param norm = 3.5164e-01, time/batch = 16.3744s	
16488/16650 (epoch 49.514), train_loss = 0.55651946, grad/param norm = 2.7893e-01, time/batch = 16.3549s	
16489/16650 (epoch 49.517), train_loss = 0.59959279, grad/param norm = 3.5648e-01, time/batch = 17.1187s	
16490/16650 (epoch 49.520), train_loss = 0.53478116, grad/param norm = 2.9412e-01, time/batch = 15.0077s	
16491/16650 (epoch 49.523), train_loss = 0.64640863, grad/param norm = 2.9307e-01, time/batch = 16.5015s	
16492/16650 (epoch 49.526), train_loss = 0.70606310, grad/param norm = 3.0127e-01, time/batch = 16.2073s	
16493/16650 (epoch 49.529), train_loss = 0.70834307, grad/param norm = 3.5252e-01, time/batch = 17.6296s	
16494/16650 (epoch 49.532), train_loss = 0.47627516, grad/param norm = 2.9221e-01, time/batch = 17.6102s	
16495/16650 (epoch 49.535), train_loss = 0.56795662, grad/param norm = 3.1828e-01, time/batch = 14.2821s	
16496/16650 (epoch 49.538), train_loss = 0.51001282, grad/param norm = 3.4983e-01, time/batch = 17.6167s	
16497/16650 (epoch 49.541), train_loss = 0.75307425, grad/param norm = 3.8021e-01, time/batch = 17.7898s	
16498/16650 (epoch 49.544), train_loss = 0.77825482, grad/param norm = 5.2895e-01, time/batch = 15.8188s	
16499/16650 (epoch 49.547), train_loss = 0.54747173, grad/param norm = 3.5103e-01, time/batch = 17.0160s	
16500/16650 (epoch 49.550), train_loss = 0.64487843, grad/param norm = 3.2340e-01, time/batch = 17.2922s	
16501/16650 (epoch 49.553), train_loss = 0.61540807, grad/param norm = 2.8282e-01, time/batch = 17.9513s	
16502/16650 (epoch 49.556), train_loss = 0.56884217, grad/param norm = 3.1096e-01, time/batch = 15.4108s	
16503/16650 (epoch 49.559), train_loss = 0.50003947, grad/param norm = 2.5228e-01, time/batch = 18.2087s	
16504/16650 (epoch 49.562), train_loss = 0.55852951, grad/param norm = 3.1591e-01, time/batch = 14.1635s	
16505/16650 (epoch 49.565), train_loss = 0.48661261, grad/param norm = 2.9242e-01, time/batch = 16.6107s	
16506/16650 (epoch 49.568), train_loss = 0.51505799, grad/param norm = 2.6455e-01, time/batch = 17.3514s	
16507/16650 (epoch 49.571), train_loss = 0.55405366, grad/param norm = 3.4080e-01, time/batch = 15.5964s	
16508/16650 (epoch 49.574), train_loss = 0.54339919, grad/param norm = 3.6547e-01, time/batch = 16.5897s	
16509/16650 (epoch 49.577), train_loss = 0.60588471, grad/param norm = 3.1413e-01, time/batch = 16.5970s	
16510/16650 (epoch 49.580), train_loss = 0.57488545, grad/param norm = 2.7894e-01, time/batch = 15.9167s	
16511/16650 (epoch 49.583), train_loss = 0.65699569, grad/param norm = 3.1325e-01, time/batch = 18.2945s	
16512/16650 (epoch 49.586), train_loss = 0.55430870, grad/param norm = 3.7540e-01, time/batch = 17.1206s	
16513/16650 (epoch 49.589), train_loss = 0.53808726, grad/param norm = 2.7874e-01, time/batch = 17.1840s	
16514/16650 (epoch 49.592), train_loss = 0.60965024, grad/param norm = 2.6482e-01, time/batch = 17.3790s	
16515/16650 (epoch 49.595), train_loss = 0.56882717, grad/param norm = 3.0147e-01, time/batch = 17.2606s	
16516/16650 (epoch 49.598), train_loss = 0.60496872, grad/param norm = 3.2804e-01, time/batch = 15.7107s	
16517/16650 (epoch 49.601), train_loss = 0.55226355, grad/param norm = 3.3039e-01, time/batch = 17.6959s	
16518/16650 (epoch 49.604), train_loss = 0.59096486, grad/param norm = 2.8830e-01, time/batch = 18.6984s	
16519/16650 (epoch 49.607), train_loss = 0.66308151, grad/param norm = 3.2732e-01, time/batch = 17.1013s	
16520/16650 (epoch 49.610), train_loss = 0.56526583, grad/param norm = 3.0406e-01, time/batch = 15.6340s	
16521/16650 (epoch 49.613), train_loss = 0.70945439, grad/param norm = 3.1127e-01, time/batch = 17.6063s	
16522/16650 (epoch 49.616), train_loss = 0.67569937, grad/param norm = 5.5479e-01, time/batch = 18.5384s	
16523/16650 (epoch 49.619), train_loss = 0.52750387, grad/param norm = 2.7601e-01, time/batch = 17.7704s	
16524/16650 (epoch 49.622), train_loss = 0.50892076, grad/param norm = 2.5826e-01, time/batch = 16.5786s	
16525/16650 (epoch 49.625), train_loss = 0.61012688, grad/param norm = 2.8003e-01, time/batch = 17.0562s	
16526/16650 (epoch 49.628), train_loss = 0.56989386, grad/param norm = 4.0853e-01, time/batch = 17.9388s	
16527/16650 (epoch 49.631), train_loss = 0.64047489, grad/param norm = 4.4302e-01, time/batch = 17.1000s	
16528/16650 (epoch 49.634), train_loss = 0.78596453, grad/param norm = 3.9092e-01, time/batch = 17.8744s	
16529/16650 (epoch 49.637), train_loss = 0.75444036, grad/param norm = 3.3847e-01, time/batch = 17.1919s	
16530/16650 (epoch 49.640), train_loss = 0.63044052, grad/param norm = 3.3053e-01, time/batch = 17.1721s	
16531/16650 (epoch 49.643), train_loss = 0.68878386, grad/param norm = 2.7823e-01, time/batch = 16.8266s	
16532/16650 (epoch 49.646), train_loss = 0.64652482, grad/param norm = 3.2267e-01, time/batch = 17.6713s	
16533/16650 (epoch 49.649), train_loss = 0.65583174, grad/param norm = 3.3023e-01, time/batch = 16.6521s	
16534/16650 (epoch 49.652), train_loss = 0.65342516, grad/param norm = 3.3817e-01, time/batch = 17.6914s	
16535/16650 (epoch 49.655), train_loss = 0.62111979, grad/param norm = 2.7194e-01, time/batch = 18.4482s	
16536/16650 (epoch 49.658), train_loss = 0.57821462, grad/param norm = 2.8114e-01, time/batch = 18.4972s	
16537/16650 (epoch 49.661), train_loss = 0.62748340, grad/param norm = 3.5384e-01, time/batch = 17.5858s	
16538/16650 (epoch 49.664), train_loss = 0.63459450, grad/param norm = 3.1742e-01, time/batch = 17.2844s	
16539/16650 (epoch 49.667), train_loss = 0.72467713, grad/param norm = 3.1902e-01, time/batch = 18.6099s	
16540/16650 (epoch 49.670), train_loss = 0.54178728, grad/param norm = 2.8789e-01, time/batch = 16.0372s	
16541/16650 (epoch 49.673), train_loss = 0.55840202, grad/param norm = 3.0189e-01, time/batch = 18.6110s	
16542/16650 (epoch 49.676), train_loss = 0.67652348, grad/param norm = 3.3017e-01, time/batch = 16.4273s	
16543/16650 (epoch 49.679), train_loss = 0.56635144, grad/param norm = 3.2389e-01, time/batch = 17.6903s	
16544/16650 (epoch 49.682), train_loss = 0.61159522, grad/param norm = 3.4473e-01, time/batch = 16.1841s	
16545/16650 (epoch 49.685), train_loss = 0.52598781, grad/param norm = 3.0656e-01, time/batch = 18.7882s	
16546/16650 (epoch 49.688), train_loss = 0.68423533, grad/param norm = 3.1514e-01, time/batch = 19.5338s	
16547/16650 (epoch 49.691), train_loss = 0.65158120, grad/param norm = 2.9668e-01, time/batch = 15.9943s	
16548/16650 (epoch 49.694), train_loss = 0.55510054, grad/param norm = 2.5302e-01, time/batch = 18.6838s	
16549/16650 (epoch 49.697), train_loss = 0.55363079, grad/param norm = 2.9737e-01, time/batch = 18.6108s	
16550/16650 (epoch 49.700), train_loss = 0.65710133, grad/param norm = 3.4124e-01, time/batch = 15.6235s	
16551/16650 (epoch 49.703), train_loss = 0.54192809, grad/param norm = 2.6641e-01, time/batch = 15.5755s	
16552/16650 (epoch 49.706), train_loss = 0.60196217, grad/param norm = 3.2037e-01, time/batch = 19.0328s	
16553/16650 (epoch 49.709), train_loss = 0.54225619, grad/param norm = 2.8133e-01, time/batch = 18.4544s	
16554/16650 (epoch 49.712), train_loss = 0.56078749, grad/param norm = 3.2827e-01, time/batch = 17.7467s	
16555/16650 (epoch 49.715), train_loss = 0.64668387, grad/param norm = 3.3154e-01, time/batch = 17.1897s	
16556/16650 (epoch 49.718), train_loss = 0.68641316, grad/param norm = 3.2636e-01, time/batch = 18.7927s	
16557/16650 (epoch 49.721), train_loss = 0.68423687, grad/param norm = 2.9117e-01, time/batch = 17.2651s	
16558/16650 (epoch 49.724), train_loss = 0.66812888, grad/param norm = 3.3689e-01, time/batch = 17.7688s	
16559/16650 (epoch 49.727), train_loss = 0.69302339, grad/param norm = 3.2928e-01, time/batch = 16.8503s	
16560/16650 (epoch 49.730), train_loss = 0.57560116, grad/param norm = 2.9078e-01, time/batch = 16.8393s	
16561/16650 (epoch 49.733), train_loss = 0.72002011, grad/param norm = 3.8920e-01, time/batch = 16.1452s	
16562/16650 (epoch 49.736), train_loss = 0.52503358, grad/param norm = 3.0316e-01, time/batch = 17.8511s	
16563/16650 (epoch 49.739), train_loss = 0.62816969, grad/param norm = 3.1099e-01, time/batch = 18.6952s	
16564/16650 (epoch 49.742), train_loss = 0.63081398, grad/param norm = 2.5991e-01, time/batch = 17.4199s	
16565/16650 (epoch 49.745), train_loss = 0.50885162, grad/param norm = 3.1215e-01, time/batch = 18.4487s	
16566/16650 (epoch 49.748), train_loss = 0.53398170, grad/param norm = 2.7300e-01, time/batch = 17.9523s	
16567/16650 (epoch 49.751), train_loss = 0.62110096, grad/param norm = 5.6394e-01, time/batch = 16.9166s	
16568/16650 (epoch 49.754), train_loss = 0.76361829, grad/param norm = 3.9411e-01, time/batch = 17.4441s	
16569/16650 (epoch 49.757), train_loss = 0.75498730, grad/param norm = 3.2625e-01, time/batch = 18.6938s	
16570/16650 (epoch 49.760), train_loss = 0.62642735, grad/param norm = 3.5499e-01, time/batch = 17.6926s	
16571/16650 (epoch 49.763), train_loss = 0.61408416, grad/param norm = 2.8882e-01, time/batch = 17.1077s	
16572/16650 (epoch 49.766), train_loss = 0.59940180, grad/param norm = 2.8771e-01, time/batch = 14.5553s	
16573/16650 (epoch 49.769), train_loss = 0.65133653, grad/param norm = 3.5737e-01, time/batch = 19.2102s	
16574/16650 (epoch 49.772), train_loss = 0.64635276, grad/param norm = 2.6568e-01, time/batch = 16.6860s	
16575/16650 (epoch 49.775), train_loss = 0.63981853, grad/param norm = 3.5901e-01, time/batch = 17.9470s	
16576/16650 (epoch 49.778), train_loss = 0.65151823, grad/param norm = 2.9574e-01, time/batch = 16.6810s	
16577/16650 (epoch 49.781), train_loss = 0.76260544, grad/param norm = 2.7883e-01, time/batch = 17.2686s	
16578/16650 (epoch 49.784), train_loss = 0.63753581, grad/param norm = 2.9747e-01, time/batch = 17.0899s	
16579/16650 (epoch 49.787), train_loss = 0.70168832, grad/param norm = 3.5385e-01, time/batch = 17.4609s	
16580/16650 (epoch 49.790), train_loss = 0.71729780, grad/param norm = 3.1352e-01, time/batch = 16.7621s	
16581/16650 (epoch 49.793), train_loss = 0.52724183, grad/param norm = 3.1053e-01, time/batch = 15.6066s	
16582/16650 (epoch 49.796), train_loss = 0.86124314, grad/param norm = 4.1049e-01, time/batch = 16.3455s	
16583/16650 (epoch 49.799), train_loss = 0.74683558, grad/param norm = 3.4050e-01, time/batch = 18.4655s	
16584/16650 (epoch 49.802), train_loss = 0.71794745, grad/param norm = 3.2152e-01, time/batch = 16.8353s	
16585/16650 (epoch 49.805), train_loss = 0.66121317, grad/param norm = 2.8796e-01, time/batch = 16.7655s	
16586/16650 (epoch 49.808), train_loss = 0.71670059, grad/param norm = 3.2839e-01, time/batch = 18.5235s	
16587/16650 (epoch 49.811), train_loss = 0.72961148, grad/param norm = 3.3713e-01, time/batch = 18.9433s	
16588/16650 (epoch 49.814), train_loss = 0.57429385, grad/param norm = 2.9265e-01, time/batch = 14.9983s	
16589/16650 (epoch 49.817), train_loss = 0.56828300, grad/param norm = 3.3961e-01, time/batch = 17.3518s	
16590/16650 (epoch 49.820), train_loss = 0.69574675, grad/param norm = 3.5003e-01, time/batch = 18.2715s	
16591/16650 (epoch 49.823), train_loss = 0.64814135, grad/param norm = 3.1006e-01, time/batch = 17.3456s	
16592/16650 (epoch 49.826), train_loss = 0.60714303, grad/param norm = 3.1933e-01, time/batch = 15.6636s	
16593/16650 (epoch 49.829), train_loss = 0.63499544, grad/param norm = 3.1676e-01, time/batch = 17.9266s	
16594/16650 (epoch 49.832), train_loss = 0.71591184, grad/param norm = 3.0918e-01, time/batch = 17.4393s	
16595/16650 (epoch 49.835), train_loss = 0.68082344, grad/param norm = 2.9717e-01, time/batch = 14.6885s	
16596/16650 (epoch 49.838), train_loss = 0.58725809, grad/param norm = 2.8180e-01, time/batch = 17.4287s	
16597/16650 (epoch 49.841), train_loss = 0.59887183, grad/param norm = 2.8180e-01, time/batch = 18.3693s	
16598/16650 (epoch 49.844), train_loss = 0.65677692, grad/param norm = 2.8624e-01, time/batch = 17.4517s	
16599/16650 (epoch 49.847), train_loss = 0.69581975, grad/param norm = 3.8973e-01, time/batch = 17.5225s	
16600/16650 (epoch 49.850), train_loss = 0.61979138, grad/param norm = 3.1704e-01, time/batch = 17.3695s	
16601/16650 (epoch 49.853), train_loss = 0.60852327, grad/param norm = 2.7839e-01, time/batch = 18.1129s	
16602/16650 (epoch 49.856), train_loss = 0.59949646, grad/param norm = 2.8156e-01, time/batch = 17.5979s	
16603/16650 (epoch 49.859), train_loss = 0.68264875, grad/param norm = 3.3834e-01, time/batch = 18.3644s	
16604/16650 (epoch 49.862), train_loss = 0.68100485, grad/param norm = 2.9383e-01, time/batch = 17.5294s	
16605/16650 (epoch 49.865), train_loss = 0.53098746, grad/param norm = 2.5748e-01, time/batch = 16.5937s	
16606/16650 (epoch 49.868), train_loss = 0.66020579, grad/param norm = 3.0565e-01, time/batch = 15.6677s	
16607/16650 (epoch 49.871), train_loss = 0.64410816, grad/param norm = 3.4797e-01, time/batch = 17.9333s	
16608/16650 (epoch 49.874), train_loss = 0.64132502, grad/param norm = 2.9789e-01, time/batch = 18.5373s	
16609/16650 (epoch 49.877), train_loss = 0.63365589, grad/param norm = 3.0060e-01, time/batch = 16.5022s	
16610/16650 (epoch 49.880), train_loss = 0.58282046, grad/param norm = 2.8742e-01, time/batch = 17.0515s	
16611/16650 (epoch 49.883), train_loss = 0.64451033, grad/param norm = 3.0190e-01, time/batch = 17.7731s	
16612/16650 (epoch 49.886), train_loss = 0.64686651, grad/param norm = 3.2018e-01, time/batch = 16.0930s	
16613/16650 (epoch 49.889), train_loss = 0.52748035, grad/param norm = 3.2503e-01, time/batch = 14.8739s	
16614/16650 (epoch 49.892), train_loss = 0.65737257, grad/param norm = 2.9213e-01, time/batch = 18.5294s	
16615/16650 (epoch 49.895), train_loss = 0.68343749, grad/param norm = 3.1212e-01, time/batch = 18.1097s	
16616/16650 (epoch 49.898), train_loss = 0.63626200, grad/param norm = 3.0952e-01, time/batch = 16.8444s	
16617/16650 (epoch 49.901), train_loss = 0.60200070, grad/param norm = 2.9711e-01, time/batch = 18.1245s	
16618/16650 (epoch 49.904), train_loss = 0.63695187, grad/param norm = 3.4462e-01, time/batch = 14.4643s	
16619/16650 (epoch 49.907), train_loss = 0.65068378, grad/param norm = 3.3132e-01, time/batch = 17.1033s	
16620/16650 (epoch 49.910), train_loss = 0.68727370, grad/param norm = 3.9262e-01, time/batch = 17.3685s	
16621/16650 (epoch 49.913), train_loss = 0.62263986, grad/param norm = 3.6232e-01, time/batch = 18.6908s	
16622/16650 (epoch 49.916), train_loss = 0.56895832, grad/param norm = 3.1701e-01, time/batch = 18.9275s	
